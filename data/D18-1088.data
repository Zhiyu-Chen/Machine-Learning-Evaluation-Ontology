title	SECTITLE_END
Neural	SEC_START
Latent	SEC_CONTENT
Extractive	SEC_CONTENT
Document	SEC_CONTENT
Summarization	SEC_END
abstract	SECTITLE_END
Extractive	SEC_START
summarization	task
models	task
require	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
usually	SEC_CONTENT
created	SEC_CONTENT
heuristically	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
rule	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
methods	SEC_CONTENT
)	SEC_CONTENT
given	SEC_CONTENT
that	SEC_CONTENT
most	SEC_CONTENT
summarization	SEC_CONTENT
datasets	SEC_CONTENT
only	SEC_CONTENT
have	SEC_CONTENT
document	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
these	SEC_CONTENT
labels	SEC_CONTENT
might	SEC_CONTENT
be	SEC_CONTENT
suboptimal	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
where	SEC_CONTENT
sentences	SEC_CONTENT
are	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
and	SEC_CONTENT
sentences	SEC_CONTENT
with	SEC_CONTENT
activated	SEC_CONTENT
variables	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
infer	SEC_CONTENT
gold	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
comes	SEC_CONTENT
directly	SEC_CONTENT
from	SEC_CONTENT
gold	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
Experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CNN	SEC_CONTENT
/	SEC_CONTENT
Dailymail	SEC_CONTENT
dataset	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
improves	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
extractive	SEC_CONTENT
baseline	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
heuristically	SEC_CONTENT
approximated	SEC_CONTENT
labels	SEC_CONTENT
and	SEC_CONTENT
also	SEC_CONTENT
performs	SEC_CONTENT
competitively	SEC_CONTENT
to	SEC_CONTENT
several	SEC_CONTENT
recent	SEC_CONTENT
models	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Document	SEC_START
summarization	task
aims	SEC_CONTENT
to	SEC_CONTENT
automatically	SEC_CONTENT
rewrite	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
shorter	SEC_CONTENT
version	SEC_CONTENT
while	SEC_CONTENT
retaining	SEC_CONTENT
its	SEC_CONTENT
most	SEC_CONTENT
important	SEC_CONTENT
content	SEC_CONTENT
.	SEC_CONTENT
Of	SEC_CONTENT
the	SEC_CONTENT
many	SEC_CONTENT
summarization	SEC_CONTENT
paradigms	SEC_CONTENT
that	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
identified	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
years	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
for	SEC_CONTENT
comprehensive	SEC_CONTENT
overviews	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
two	SEC_CONTENT
have	SEC_CONTENT
consistently	SEC_CONTENT
attracted	SEC_CONTENT
attention	SEC_CONTENT
:	SEC_CONTENT
extractive	SEC_CONTENT
approaches	SEC_CONTENT
generate	SEC_CONTENT
summaries	SEC_CONTENT
by	SEC_CONTENT
copying	SEC_CONTENT
parts	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
document	SEC_CONTENT
(	SEC_CONTENT
usually	SEC_CONTENT
whole	SEC_CONTENT
sentences	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
abstractive	SEC_CONTENT
methods	SEC_CONTENT
may	SEC_CONTENT
generate	SEC_CONTENT
new	SEC_CONTENT
words	SEC_CONTENT
or	SEC_CONTENT
phrases	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
.	SEC_END
A	SEC_START
great	SEC_CONTENT
deal	SEC_CONTENT
of	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
has	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
extractive	task
summarization	task
which	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
modeled	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
ranking	SEC_CONTENT
or	SEC_CONTENT
binary	SEC_CONTENT
classification	SEC_CONTENT
problem	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
sentences	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
top	SEC_CONTENT
ranked	SEC_CONTENT
or	SEC_CONTENT
predicted	SEC_CONTENT
as	SEC_CONTENT
True	SEC_CONTENT
are	SEC_CONTENT
selected	SEC_CONTENT
as	SEC_CONTENT
summaries	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Early	SEC_START
attempts	SEC_CONTENT
mostly	SEC_CONTENT
leverage	SEC_CONTENT
human	SEC_CONTENT
-	SEC_CONTENT
engineered	SEC_CONTENT
features	SEC_CONTENT
)	SEC_CONTENT
coupled	SEC_CONTENT
with	SEC_CONTENT
binary	SEC_CONTENT
classifiers	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
hidden	SEC_CONTENT
Markov	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
graph	SEC_CONTENT
based	SEC_CONTENT
methods	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
integer	SEC_CONTENT
linear	SEC_CONTENT
programming	SEC_CONTENT
.	SEC_END
The	SEC_START
successful	SEC_CONTENT
application	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
availability	SEC_CONTENT
of	SEC_CONTENT
large	task
scale	task
summarization	task
datasets	task
has	SEC_CONTENT
provided	SEC_CONTENT
strong	SEC_CONTENT
impetus	SEC_CONTENT
to	SEC_CONTENT
develop	SEC_CONTENT
data	SEC_CONTENT
-	SEC_CONTENT
driven	SEC_CONTENT
approaches	SEC_CONTENT
which	SEC_CONTENT
take	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
continuousspace	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
hierarchical	SEC_CONTENT
long	SEC_CONTENT
short	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
memory	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
;	SEC_CONTENT
Hochreiter	SEC_CONTENT
and	SEC_CONTENT
Schmidhuber	SEC_CONTENT
1997	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
context	SEC_CONTENT
dependent	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
fora	SEC_CONTENT
document	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
use	SEC_CONTENT
yet	SEC_CONTENT
another	SEC_CONTENT
LSTM	SEC_CONTENT
decoder	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
a	SEC_CONTENT
binary	SEC_CONTENT
label	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
adopt	SEC_CONTENT
a	SEC_CONTENT
similar	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
differ	SEC_CONTENT
in	SEC_CONTENT
their	SEC_CONTENT
neural	SEC_CONTENT
architecture	SEC_CONTENT
for	SEC_CONTENT
sentence	SEC_CONTENT
encoding	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
features	SEC_CONTENT
used	SEC_CONTENT
during	SEC_CONTENT
label	SEC_CONTENT
prediction	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
equip	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
architecture	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
training	SEC_CONTENT
algorithm	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
Abstractive	SEC_CONTENT
models	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
sequenceto	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
learning	SEC_CONTENT
,	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
of	SEC_CONTENT
them	SEC_CONTENT
underperform	SEC_CONTENT
or	SEC_CONTENT
are	SEC_CONTENT
on	SEC_CONTENT
par	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
of	SEC_CONTENT
simply	SEC_CONTENT
selecting	SEC_CONTENT
the	SEC_CONTENT
leading	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
as	SEC_CONTENT
summaries	SEC_CONTENT
(	SEC_CONTENT
but	SEC_CONTENT
see	SEC_CONTENT
for	SEC_CONTENT
exceptions	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Although	SEC_START
seemingly	SEC_CONTENT
more	SEC_CONTENT
successful	SEC_CONTENT
than	SEC_CONTENT
their	SEC_CONTENT
abstractive	SEC_CONTENT
counterparts	SEC_CONTENT
,	SEC_CONTENT
extractive	SEC_CONTENT
models	SEC_CONTENT
require	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
included	SEC_CONTENT
inmost	task
summarization	task
datasets	task
(	SEC_CONTENT
only	SEC_CONTENT
document	SEC_CONTENT
and	SEC_CONTENT
gold	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
are	SEC_CONTENT
available	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Sentence	SEC_CONTENT
labels	SEC_CONTENT
are	SEC_CONTENT
usually	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
rule	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
methods	SEC_CONTENT
or	SEC_CONTENT
by	SEC_CONTENT
maximizing	SEC_CONTENT
the	SEC_CONTENT
ROUGE	SEC_CONTENT
score	SEC_CONTENT
)	SEC_CONTENT
between	SEC_CONTENT
a	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
human	SEC_CONTENT
written	SEC_CONTENT
summaries	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
methods	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
fully	SEC_CONTENT
exploit	SEC_CONTENT
the	SEC_CONTENT
human	SEC_CONTENT
summaries	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
only	SEC_CONTENT
create	SEC_CONTENT
True	SEC_CONTENT
/	SEC_CONTENT
False	SEC_CONTENT
labels	SEC_CONTENT
which	SEC_CONTENT
might	SEC_CONTENT
be	SEC_CONTENT
suboptimal	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
view	SEC_CONTENT
labels	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
as	SEC_CONTENT
binary	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
zeros	SEC_CONTENT
and	SEC_CONTENT
ones	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
of	SEC_CONTENT
maximizing	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
"	SEC_CONTENT
gold	SEC_CONTENT
"	SEC_CONTENT
standard	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
directly	SEC_CONTENT
maximizes	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
human	SEC_CONTENT
summaries	SEC_CONTENT
given	SEC_CONTENT
selected	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
Experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CNN	SEC_CONTENT
/	SEC_CONTENT
Dailymail	SEC_CONTENT
dataset	SEC_CONTENT
(	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
latent	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
improves	SEC_CONTENT
upon	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
extractive	SEC_CONTENT
baseline	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
rulebased	SEC_CONTENT
labels	SEC_CONTENT
and	SEC_CONTENT
also	SEC_CONTENT
performs	SEC_CONTENT
competitively	SEC_CONTENT
to	SEC_CONTENT
several	SEC_CONTENT
recent	SEC_CONTENT
models	SEC_CONTENT
.	SEC_END
Model	SECTITLE_END
We	SEC_START
first	SEC_CONTENT
introduce	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
extractive	SEC_CONTENT
summarization	SEC_CONTENT
model	SEC_CONTENT
upon	SEC_CONTENT
which	SEC_CONTENT
our	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
then	SEC_CONTENT
describe	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
finally	SEC_CONTENT
move	SEC_CONTENT
onto	SEC_CONTENT
present	SEC_CONTENT
the	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
itself	SEC_CONTENT
.	SEC_END
Neural	SECTITLE_START
Extractive	SECTITLE_CONTENT
Summarization	SECTITLE_END
In	SEC_START
extractive	task
summarization	task
,	SEC_CONTENT
a	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
is	SEC_CONTENT
selected	SEC_CONTENT
as	SEC_CONTENT
its	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
model	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
instance	SEC_CONTENT
of	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
is	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
expected	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
a	SEC_CONTENT
True	SEC_CONTENT
or	SEC_CONTENT
False	SEC_CONTENT
label	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
True	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
should	SEC_CONTENT
be	SEC_CONTENT
included	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
assumed	SEC_CONTENT
that	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
sentences	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
labels	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
document	SEC_CONTENT
are	SEC_CONTENT
given	SEC_CONTENT
(	SEC_CONTENT
methods	SEC_CONTENT
for	SEC_CONTENT
obtaining	SEC_CONTENT
these	SEC_CONTENT
labels	SEC_CONTENT
are	SEC_CONTENT
discussed	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
lower	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
three	SEC_CONTENT
parts	SEC_CONTENT
:	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
to	SEC_CONTENT
convert	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
encoder	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
given	SEC_CONTENT
surrounding	SEC_CONTENT
sentences	SEC_CONTENT
as	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
decoder	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
sentence	SEC_CONTENT
labels	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
representations	SEC_CONTENT
learned	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
D	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
S	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
|D|	SEC_CONTENT
)	SEC_CONTENT
denote	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
and	SEC_END
.	SEC_START
.	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
|D|	SEC_CONTENT
)	SEC_CONTENT
denote	SEC_CONTENT
sentence	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
first	SEC_CONTENT
transforms	SEC_CONTENT
Si	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
list	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
(	SEC_CONTENT
h	SEC_CONTENT
i	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
hi	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
hi	SEC_CONTENT
|S	SEC_CONTENT
i	SEC_CONTENT
|	SEC_CONTENT
)	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
Bidirectional	SEC_CONTENT
Long	SEC_CONTENT
Short	SEC_CONTENT
-	SEC_CONTENT
Term	SEC_CONTENT
Memory	SEC_CONTENT
Network	SEC_CONTENT
(	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
;	SEC_CONTENT
Hochreiter	SEC_CONTENT
and	SEC_CONTENT
Schmidhuber	SEC_CONTENT
1997	SEC_CONTENT
;	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
yields	SEC_CONTENT
vi	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
Si	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
averaging	SEC_CONTENT
these	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
(	SEC_CONTENT
also	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
:	SEC_END
In	SEC_START
analogy	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
encoder	SEC_CONTENT
is	SEC_CONTENT
another	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
but	SEC_CONTENT
applies	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
level	SEC_CONTENT
.	SEC_CONTENT
After	SEC_CONTENT
running	SEC_CONTENT
the	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_END
The	SEC_START
document	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
an	SEC_CONTENT
LSTM	SEC_CONTENT
which	SEC_CONTENT
predicts	SEC_CONTENT
sentence	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
each	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
takes	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
dependent	SEC_CONTENT
sentence	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
Si	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
encoder	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
:	SEC_END
where	SEC_START
W	SEC_CONTENT
e	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×2	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
embedding	SEC_CONTENT
matrix	SEC_CONTENT
(	SEC_CONTENT
d	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
dimension	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
decoder	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
y	SEC_CONTENT
i−1	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
at	SEC_CONTENT
time	metric
step	metric
i	SEC_CONTENT
−	SEC_CONTENT
1	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
predicted	SEC_CONTENT
label	SEC_CONTENT
distribution	SEC_CONTENT
for	SEC_CONTENT
y	SEC_CONTENT
i	SEC_CONTENT
is	SEC_CONTENT
:	SEC_END
where	SEC_START
W	SEC_CONTENT
o	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
2×d	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
model	SEC_CONTENT
described	SEC_CONTENT
above	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
trained	SEC_CONTENT
by	SEC_CONTENT
minimizing	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
labels	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
documents	SEC_CONTENT
;	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
almost	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
except	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
long	SEC_CONTENT
short	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
memory	SEC_CONTENT
network	SEC_CONTENT
coupled	SEC_CONTENT
with	SEC_CONTENT
mean	SEC_CONTENT
pooling	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
they	SEC_CONTENT
use	SEC_CONTENT
convolutional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
coupled	SEC_CONTENT
with	SEC_CONTENT
max	SEC_CONTENT
pooling	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Sentence	SECTITLE_START
Compression	SECTITLE_END
We	SEC_START
train	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
map	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
selected	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
evaluate	SEC_CONTENT
the	SEC_CONTENT
quality	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
selected	SEC_CONTENT
sentence	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
degree	SEC_CONTENT
to	SEC_CONTENT
which	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
)	SEC_CONTENT
or	SEC_CONTENT
rewrite	SEC_CONTENT
an	SEC_CONTENT
extracted	SEC_CONTENT
sentence	SEC_CONTENT
according	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
style	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_END
For	SEC_START
our	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
architecture	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
generated	SEC_CONTENT
from	SEC_CONTENT
the	task
same	task
summarization	task
dataset	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
exractive	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
D	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
S	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
|D|	SEC_CONTENT
)	SEC_CONTENT
denote	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
and	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
H	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
|H|	SEC_CONTENT
)	SEC_CONTENT
its	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
view	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
H	SEC_CONTENT
i	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
assume	SEC_CONTENT
that	SEC_CONTENT
its	SEC_CONTENT
corresponding	SEC_CONTENT
source	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
in	SEC_CONTENT
D	SEC_CONTENT
most	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
it	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
measure	SEC_CONTENT
the	SEC_CONTENT
similarity	SEC_CONTENT
between	SEC_CONTENT
source	SEC_CONTENT
sentences	SEC_CONTENT
and	SEC_CONTENT
candidate	SEC_CONTENT
targets	SEC_CONTENT
using	SEC_CONTENT
ROUGE	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
j	SEC_CONTENT
=	SEC_CONTENT
argmax	SEC_CONTENT
S	SEC_CONTENT
j	SEC_CONTENT
ROUGE(S	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
S	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
i	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
training	SEC_CONTENT
instance	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
sentencê	SEC_CONTENT
H	SEC_CONTENT
i	SEC_CONTENT
being	SEC_CONTENT
the	SEC_CONTENT
compression	SEC_CONTENT
ofˆSofˆ	SEC_CONTENT
ofˆS	SEC_CONTENT
j	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
p	SEC_CONTENT
s2s	SEC_CONTENT
(	SEC_CONTENT
ˆ	SEC_CONTENT
H	SEC_CONTENT
i	SEC_CONTENT
|	SEC_CONTENT
ˆ	SEC_CONTENT
S	SEC_CONTENT
j	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
estimated	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
trained	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Latent	SECTITLE_START
Extractive	SECTITLE_CONTENT
Summarization	SECTITLE_END
Training	SEC_START
the	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
2.1	SEC_CONTENT
requires	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
labels	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
obtained	SEC_CONTENT
heuristically	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
model	SEC_CONTENT
views	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
as	SEC_CONTENT
binary	SEC_CONTENT
variables	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
zeros	SEC_CONTENT
and	SEC_CONTENT
ones	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
uses	SEC_CONTENT
sentences	SEC_CONTENT
with	SEC_CONTENT
activated	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
ones	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
infer	SEC_CONTENT
gold	task
summaries	task
.	SEC_CONTENT
The	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
are	SEC_CONTENT
predicted	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
comes	SEC_CONTENT
from	SEC_CONTENT
gold	SEC_CONTENT
summaries	SEC_CONTENT
directly	SEC_CONTENT
.	SEC_END
Let	SEC_START
D	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
S	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
S	SEC_CONTENT
|D|	SEC_CONTENT
)	SEC_CONTENT
denote	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
and	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
H	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
|H|	SEC_CONTENT
)	SEC_CONTENT
its	SEC_CONTENT
human	SEC_CONTENT
summary	SEC_CONTENT
(	SEC_CONTENT
H	SEC_CONTENT
k	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
in	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
assume	SEC_CONTENT
that	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
Si	SEC_CONTENT
indicating	SEC_CONTENT
whether	SEC_CONTENT
Si	SEC_CONTENT
should	SEC_CONTENT
be	SEC_CONTENT
selected	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
entails	SEC_CONTENT
it	SEC_CONTENT
should	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
from	SEC_CONTENT
Section	SEC_CONTENT
2.1	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
for	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
Equation	task
)	SEC_CONTENT
and	SEC_CONTENT
obtain	SEC_CONTENT
them	SEC_CONTENT
by	SEC_CONTENT
sampling	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
∼	SEC_CONTENT
p(z	SEC_CONTENT
i	SEC_CONTENT
|z	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
i−1	SEC_CONTENT
,	SEC_CONTENT
h	SEC_CONTENT
D	SEC_CONTENT
i−1	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
C	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
S	SEC_CONTENT
i	SEC_CONTENT
|z	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
whose	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
equal	SEC_CONTENT
to	SEC_CONTENT
one	SEC_CONTENT
,	SEC_CONTENT
are	SEC_CONTENT
our	SEC_CONTENT
current	SEC_CONTENT
extractive	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
Without	SEC_CONTENT
loss	SEC_CONTENT
of	SEC_CONTENT
generality	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
denote	SEC_CONTENT
C	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
C	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
C	SEC_CONTENT
|C|	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
estimate	SEC_CONTENT
how	SEC_CONTENT
likely	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
infer	SEC_CONTENT
the	SEC_CONTENT
human	SEC_CONTENT
summary	SEC_CONTENT
H	SEC_CONTENT
from	SEC_CONTENT
C.	SEC_CONTENT
We	SEC_CONTENT
estimate	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
summary	SEC_CONTENT
sentence	SEC_CONTENT
H	SEC_CONTENT
l	SEC_CONTENT
given	SEC_CONTENT
document	SEC_CONTENT
sentence	SEC_CONTENT
C	SEC_CONTENT
k	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
introduced	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
2.2	SEC_CONTENT
and	SEC_CONTENT
calculate	SEC_CONTENT
the	SEC_CONTENT
normalized	SEC_CONTENT
1	SEC_CONTENT
probability	SEC_CONTENT
s	SEC_CONTENT
kl	SEC_CONTENT
:	SEC_END
The	SEC_START
score	SEC_CONTENT
R	SEC_CONTENT
p	SEC_CONTENT
measures	SEC_CONTENT
the	SEC_CONTENT
extent	SEC_CONTENT
to	SEC_CONTENT
which	SEC_CONTENT
H	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
inferred	SEC_CONTENT
from	SEC_CONTENT
C	SEC_CONTENT
:	SEC_END
For	SEC_START
simplicity	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
assume	SEC_CONTENT
one	SEC_CONTENT
document	SEC_CONTENT
sentence	SEC_CONTENT
can	SEC_CONTENT
only	SEC_CONTENT
find	SEC_CONTENT
one	SEC_CONTENT
summary	SEC_CONTENT
sentence	SEC_CONTENT
to	SEC_CONTENT
explain	SEC_CONTENT
it	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
H	SEC_CONTENT
l	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
retain	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
evident	SEC_CONTENT
s	SEC_CONTENT
kl	SEC_CONTENT
.	SEC_CONTENT
R	SEC_CONTENT
p	SEC_CONTENT
(	SEC_CONTENT
C	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
precision	SEC_CONTENT
"	SEC_CONTENT
of	SEC_CONTENT
document	SEC_CONTENT
sentences	SEC_CONTENT
with	SEC_CONTENT
regard	SEC_CONTENT
to	SEC_CONTENT
summary	task
sentences	task
.	SEC_CONTENT
Analogously	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
define	SEC_CONTENT
R	SEC_CONTENT
r	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
indicates	SEC_CONTENT
the	SEC_CONTENT
extent	SEC_CONTENT
to	SEC_CONTENT
which	SEC_CONTENT
H	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
covered	SEC_CONTENT
by	SEC_CONTENT
C	SEC_CONTENT
:	SEC_END
R	SEC_START
r	SEC_CONTENT
(	SEC_CONTENT
C	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
recall	SEC_CONTENT
"	SEC_CONTENT
of	SEC_CONTENT
document	SEC_CONTENT
sentences	SEC_CONTENT
with	SEC_CONTENT
regard	SEC_CONTENT
to	SEC_CONTENT
summary	task
sentences	task
.	SEC_CONTENT
The	SEC_CONTENT
final	SEC_CONTENT
score	SEC_CONTENT
R(C	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
weighted	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
:	SEC_END
Our	SEC_START
use	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
terms	SEC_CONTENT
"	SEC_CONTENT
precision	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
recall	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
reminiscent	SEC_CONTENT
of	SEC_CONTENT
relevance	SEC_CONTENT
and	SEC_CONTENT
coverage	SEC_CONTENT
in	SEC_CONTENT
other	task
summarization	task
work	task
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
by	SEC_CONTENT
minimizing	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
expected	SEC_CONTENT
R(C	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
:	SEC_END
where	SEC_START
p(·|D	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
distribution	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
Equation	task
)	SEC_CONTENT
.	SEC_CONTENT
Unfortunately	SEC_CONTENT
,	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
term	SEC_CONTENT
is	SEC_CONTENT
prohibitive	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
possible	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
combinations	SEC_CONTENT
are	SEC_CONTENT
exponential	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
practice	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
approximate	SEC_CONTENT
this	SEC_CONTENT
expectation	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
sample	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
distribution	SEC_CONTENT
of	SEC_CONTENT
p(·|D	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
REIN	SEC_CONTENT
-	SEC_CONTENT
FORCE	SEC_CONTENT
algorithm	SEC_CONTENT
to	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
of	SEC_CONTENT
L(θ	SEC_CONTENT
)	SEC_CONTENT
:	SEC_END
Note	SEC_START
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
described	SEC_CONTENT
above	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
R(C	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
reward	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
reduce	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
gradients	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
introduce	SEC_CONTENT
a	SEC_CONTENT
baseline	SEC_CONTENT
linear	SEC_CONTENT
regression	SEC_CONTENT
2	SEC_CONTENT
model	SEC_CONTENT
bi	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
estimate	SEC_CONTENT
the	SEC_CONTENT
expected	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
R(C	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
avoid	SEC_CONTENT
random	SEC_CONTENT
label	SEC_CONTENT
sequences	SEC_CONTENT
during	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
initialize	SEC_CONTENT
our	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
Dataset	SEC_START
and	SEC_CONTENT
Evaluation	task
We	SEC_CONTENT
conducted	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CNN	SEC_CONTENT
/	SEC_CONTENT
Dailymail	SEC_CONTENT
dataset	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
followed	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
processing	SEC_CONTENT
steps	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
resulting	SEC_CONTENT
dataset	SEC_CONTENT
contains	SEC_CONTENT
287,226	SEC_CONTENT
document	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
13,368	SEC_CONTENT
for	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
11,490	SEC_CONTENT
for	SEC_CONTENT
test	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
create	SEC_CONTENT
sentence	SEC_CONTENT
level	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
a	SEC_CONTENT
strategy	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
label	SEC_CONTENT
the	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
that	SEC_CONTENT
maximizes	SEC_CONTENT
ROUGE	SEC_CONTENT
(	SEC_CONTENT
against	SEC_CONTENT
the	SEC_CONTENT
human	SEC_CONTENT
summary	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
True	SEC_CONTENT
and	SEC_CONTENT
all	SEC_CONTENT
other	SEC_CONTENT
sentences	SEC_CONTENT
as	SEC_CONTENT
False	SEC_CONTENT
.	SEC_CONTENT
Using	SEC_CONTENT
the	SEC_CONTENT
method	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
2.2	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
created	SEC_CONTENT
a	SEC_CONTENT
compression	SEC_CONTENT
dataset	SEC_CONTENT
with	SEC_CONTENT
1,045,492	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
53,434	SEC_CONTENT
for	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
43,382	SEC_CONTENT
for	SEC_CONTENT
testing	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
evaluated	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
using	SEC_CONTENT
full	SEC_CONTENT
length	SEC_CONTENT
F1	SEC_CONTENT
ROUGE	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
official	SEC_CONTENT
ROUGE-1.5.5.pl	SEC_CONTENT
script	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
ROUGE-1	SEC_CONTENT
,	SEC_CONTENT
ROUGE-2	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L.	SEC_END
Implementation	SEC_START
We	SEC_CONTENT
trained	SEC_CONTENT
our	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
an	SEC_CONTENT
Nvidia	SEC_CONTENT
K80	SEC_CONTENT
GPU	SEC_CONTENT
card	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
32	SEC_CONTENT
.	SEC_CONTENT
Model	SEC_CONTENT
parameters	SEC_CONTENT
were	SEC_CONTENT
uniformly	SEC_CONTENT
ini-	SEC_END
]	SEC_START
(	SEC_CONTENT
c	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
columns	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
Adam	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
optimize	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
0.001	SEC_CONTENT
,	SEC_CONTENT
β	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
0.9	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
β	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
0.999	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
our	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
10	SEC_CONTENT
epochs	SEC_CONTENT
and	SEC_CONTENT
selected	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
ROUGE	SEC_CONTENT
on	SEC_CONTENT
the	task
validation	task
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
rescaled	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
when	SEC_CONTENT
its	SEC_CONTENT
norm	SEC_CONTENT
exceeded	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
and	SEC_END
40.34	SEC_START
17.70	SEC_CONTENT
36.57	SEC_CONTENT
LEAD3	SEC_CONTENT
(:	SEC_END
Results	SEC_START
of	SEC_CONTENT
different	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
the	dataset
CNN	dataset
/	dataset
Dailymail	dataset
test	dataset
set	SEC_CONTENT
using	SEC_CONTENT
full	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
F1	SEC_CONTENT
ROUGE-1	SEC_CONTENT
(	SEC_CONTENT
R-1	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
ROUGE-2	SEC_CONTENT
(	SEC_CONTENT
R-2	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
(	SEC_CONTENT
R	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
regularized	SEC_START
all	SEC_CONTENT
LSTMs	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
dropout	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
0.3	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
applied	SEC_CONTENT
word	SEC_CONTENT
dropout	SEC_CONTENT
)	SEC_CONTENT
at	SEC_CONTENT
rate	SEC_CONTENT
0.2	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
unit	SEC_CONTENT
size	SEC_CONTENT
d	SEC_CONTENT
=	SEC_CONTENT
300	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
and	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTMs	SEC_CONTENT
and	SEC_CONTENT
all	SEC_CONTENT
LSTMs	SEC_CONTENT
had	SEC_CONTENT
one	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
300	SEC_CONTENT
dimensional	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
FastText	SEC_CONTENT
vectors	SEC_CONTENT
(	SEC_CONTENT
to	SEC_CONTENT
initialize	SEC_CONTENT
our	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
initialized	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
thus	SEC_CONTENT
both	SEC_CONTENT
models	SEC_CONTENT
have	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
size	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
in	SEC_CONTENT
Equation	task
to	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
SGD	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
0.01	SEC_CONTENT
for	SEC_CONTENT
5	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
inference	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
extractive	SEC_CONTENT
and	SEC_CONTENT
latent	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
rank	SEC_CONTENT
sentences	SEC_CONTENT
with	SEC_CONTENT
p(y	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
True|y	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
i−1	SEC_CONTENT
,	SEC_CONTENT
D	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
select	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
three	SEC_CONTENT
as	SEC_CONTENT
summary	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
also	SEC_CONTENT
Equation	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Comparison	SEC_START
Systems	SEC_CONTENT
We	SEC_CONTENT
compared	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
against	SEC_CONTENT
LEAD3	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
selects	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
three	SEC_CONTENT
leading	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
abstractive	SEC_CONTENT
and	SEC_CONTENT
extractive	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
Abstractive	SEC_CONTENT
models	SEC_CONTENT
include	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
tosequence	SEC_CONTENT
architecture	SEC_CONTENT
(;	SEC_CONTENT
abstract	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
its	SEC_CONTENT
pointer	SEC_CONTENT
generator	SEC_CONTENT
variant	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
two	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
models	SEC_CONTENT
(;	SEC_CONTENT
abstract	SEC_CONTENT
-	SEC_CONTENT
RL	SEC_CONTENT
and	SEC_CONTENT
abstract	SEC_CONTENT
-	SEC_CONTENT
ML+RL	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
compared	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
against	SEC_CONTENT
an	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
hierarchical	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
2.1	SEC_CONTENT
(	SEC_CONTENT
EXTRACT	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
encodes	SEC_CONTENT
sentences	SEC_CONTENT
using	SEC_CONTENT
LSTMs	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
variant	SEC_CONTENT
which	SEC_CONTENT
employs	SEC_CONTENT
CNNs	SEC_CONTENT
instead	SEC_CONTENT
(	SEC_CONTENT
Cheng	SEC_CONTENT
and	SEC_CONTENT
Lapata	SEC_CONTENT
2016	SEC_CONTENT
;	SEC_CONTENT
EXTRACT	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
similar	SEC_CONTENT
system	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
EXTRACT	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
outperforms	SEC_CONTENT
LEAD3	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
wide	SEC_CONTENT
margin	SEC_CONTENT
.	SEC_CONTENT
EXTRACT	SEC_CONTENT
also	SEC_CONTENT
outperforms	SEC_CONTENT
previously	SEC_CONTENT
published	SEC_CONTENT
extractive	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
SummaRuNNer	SEC_CONTENT
,	SEC_CONTENT
EXTRACT	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
REFRESH	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
SummaRuNNer	task
generates	SEC_CONTENT
anonymized	SEC_CONTENT
summaries	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
while	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
generate	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
anonymized	SEC_CONTENT
ones	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
therefore	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
EXTRACT	SEC_CONTENT
and	SEC_CONTENT
SummaRuNNer	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
strictly	SEC_CONTENT
comparable	SEC_CONTENT
(	SEC_CONTENT
also	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
LEAD3	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
different	SEC_CONTENT
in	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Nevertheless	SEC_CONTENT
,	SEC_CONTENT
EXTRACT	SEC_CONTENT
exceeds	SEC_CONTENT
LEAD3	SEC_CONTENT
by	SEC_CONTENT
+0.75	SEC_CONTENT
ROUGE-2	SEC_CONTENT
points	SEC_CONTENT
and	SEC_CONTENT
+0.57	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
SummaRuNNer	SEC_CONTENT
exceeds	SEC_CONTENT
LEAD3	SEC_CONTENT
by	SEC_CONTENT
+0.50	SEC_CONTENT
ROUGE-2	SEC_CONTENT
points	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
worse	SEC_CONTENT
by	SEC_CONTENT
−0.20	SEC_CONTENT
points	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L.	SEC_CONTENT
We	SEC_CONTENT
thus	SEC_CONTENT
conclude	SEC_CONTENT
that	SEC_CONTENT
EXTRACT	SEC_CONTENT
is	SEC_CONTENT
better	SEC_CONTENT
when	SEC_CONTENT
evaluated	SEC_CONTENT
with	SEC_CONTENT
ROUGE-2	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L.	SEC_CONTENT
EXTRACT	SEC_CONTENT
outperforms	SEC_CONTENT
all	SEC_CONTENT
abstractive	SEC_CONTENT
models	SEC_CONTENT
except	SEC_CONTENT
for	SEC_CONTENT
abstract	SEC_CONTENT
-	SEC_CONTENT
RL	SEC_CONTENT
.	SEC_CONTENT
ROUGE-2	SEC_CONTENT
is	SEC_CONTENT
lower	SEC_CONTENT
for	SEC_CONTENT
abstract	SEC_CONTENT
-	SEC_CONTENT
RL	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
competitive	SEC_CONTENT
when	SEC_CONTENT
evaluated	SEC_CONTENT
against	SEC_CONTENT
ROUGE-1	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L.	SEC_END
Results	SECTITLE_START
As	SECTITLE_CONTENT
shown	SECTITLE_CONTENT
in	SECTITLE_END
Our	SEC_START
latent	SEC_CONTENT
variable	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
LATENT	SEC_CONTENT
;	SEC_CONTENT
Section	SEC_CONTENT
2.3	SEC_CONTENT
)	SEC_CONTENT
outperforms	SEC_CONTENT
EXTRACT	SEC_CONTENT
,	SEC_CONTENT
despite	SEC_CONTENT
being	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
baseline	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
loss	SEC_CONTENT
directly	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
gold	task
summaries	task
is	SEC_CONTENT
useful	SEC_CONTENT
.	SEC_CONTENT
Differences	SEC_CONTENT
among	SEC_CONTENT
LEAD3	SEC_CONTENT
,	SEC_CONTENT
EXTRACT	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
LATENT	SEC_CONTENT
are	SEC_CONTENT
all	SEC_CONTENT
significant	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
0.95	SEC_CONTENT
confidence	SEC_CONTENT
interval	SEC_CONTENT
(	SEC_CONTENT
estimated	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
ROUGE	SEC_CONTENT
script	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Interestingly	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
applying	SEC_CONTENT
the	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
from	SEC_CONTENT
Section	SEC_CONTENT
2.2	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
latent	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
LATENT+COMPRESS	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
performance	SEC_CONTENT
drops	SEC_CONTENT
considerably	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
maybe	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
level	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
it	SEC_CONTENT
removes	SEC_CONTENT
phrases	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
important	SEC_CONTENT
for	SEC_CONTENT
creating	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_END
Conclusions	SECTITLE_END
We	SEC_START
proposed	SEC_CONTENT
a	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
extractive	SEC_CONTENT
summarization	SEC_CONTENT
model	SEC_CONTENT
which	SEC_CONTENT
leverages	SEC_CONTENT
human	SEC_CONTENT
summaries	SEC_CONTENT
directly	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
help	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Experimental	SEC_CONTENT
results	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
indeed	SEC_CONTENT
improve	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
extractive	SEC_CONTENT
model	SEC_CONTENT
while	SEC_CONTENT
application	task
of	SEC_CONTENT
the	SEC_CONTENT
compression	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
extractive	SEC_CONTENT
system	SEC_CONTENT
leads	SEC_CONTENT
to	SEC_CONTENT
inferior	SEC_CONTENT
output	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
future	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
plan	SEC_CONTENT
to	SEC_CONTENT
explore	SEC_CONTENT
ways	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
compression	SEC_CONTENT
models	SEC_CONTENT
tailored	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
summarization	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
