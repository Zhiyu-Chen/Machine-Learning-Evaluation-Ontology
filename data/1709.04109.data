title	SECTITLE_END
Empower	SEC_START
Sequence	SEC_CONTENT
Labeling	SEC_CONTENT
with	SEC_CONTENT
Task	SEC_CONTENT
-	SEC_CONTENT
Aware	SEC_CONTENT
Neural	SEC_CONTENT
Language	SEC_CONTENT
Model	SEC_END
abstract	SECTITLE_END
Linguistic	SEC_START
sequence	SEC_CONTENT
labeling	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
general	SEC_CONTENT
approach	SEC_CONTENT
encompassing	SEC_CONTENT
a	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
problems	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
tagging	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_CONTENT
Recent	SEC_CONTENT
advances	SEC_CONTENT
in	SEC_CONTENT
neu	SEC_CONTENT
-	SEC_CONTENT
ral	SEC_CONTENT
networks	SEC_CONTENT
(	SEC_CONTENT
NNs	SEC_CONTENT
)	SEC_CONTENT
make	SEC_CONTENT
it	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
build	SEC_CONTENT
reliable	SEC_CONTENT
models	SEC_CONTENT
without	SEC_CONTENT
handcrafted	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
cases	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
hard	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
sufficient	SEC_CONTENT
annotations	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
these	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
study	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
develop	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
framework	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
knowledge	SEC_CONTENT
from	SEC_CONTENT
raw	SEC_CONTENT
texts	SEC_CONTENT
and	SEC_CONTENT
empower	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
contained	SEC_CONTENT
in	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
incorporated	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
Transfer	SEC_CONTENT
learning	SEC_CONTENT
techniques	SEC_CONTENT
are	SEC_CONTENT
further	SEC_CONTENT
adopted	SEC_CONTENT
to	SEC_CONTENT
mediate	SEC_CONTENT
different	SEC_CONTENT
components	SEC_CONTENT
and	SEC_CONTENT
guide	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
towards	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
Comparing	SEC_CONTENT
to	SEC_CONTENT
previous	SEC_CONTENT
methods	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
knowledge	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
adopt	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
concise	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
conduct	SEC_CONTENT
more	SEC_CONTENT
efficient	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Different	SEC_CONTENT
from	SEC_CONTENT
most	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
methods	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
framework	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
any	SEC_CONTENT
additional	SEC_CONTENT
supervision	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
extracts	SEC_CONTENT
knowledge	SEC_CONTENT
from	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
contained	SEC_CONTENT
order	SEC_CONTENT
information	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_CONTENT
Extensive	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
benchmark	SEC_CONTENT
datasets	SEC_CONTENT
demonstrate	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
leveraging	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
efficiency	SEC_CONTENT
of	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
model	SEC_CONTENT
training	SEC_CONTENT
completes	SEC_CONTENT
in	SEC_CONTENT
about	SEC_CONTENT
6	SEC_CONTENT
hours	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
GPU	SEC_CONTENT
,	SEC_CONTENT
reaching	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
of	SEC_CONTENT
91.71±0.10	SEC_CONTENT
without	SEC_CONTENT
using	SEC_CONTENT
any	SEC_CONTENT
extra	SEC_CONTENT
annotations	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Linguistic	SEC_START
sequence	SEC_CONTENT
labeling	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
fundamental	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
tasks	SEC_CONTENT
including	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
ofspeech	SEC_CONTENT
(	SEC_CONTENT
POS	SEC_CONTENT
)	SEC_CONTENT
tagging	SEC_CONTENT
,	SEC_CONTENT
noun	SEC_CONTENT
phrase	SEC_CONTENT
chunking	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	task
recognition	task
(	SEC_CONTENT
NER	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
tasks	SEC_CONTENT
play	SEC_CONTENT
a	SEC_CONTENT
vital	SEC_CONTENT
role	SEC_CONTENT
in	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
and	SEC_CONTENT
fulfill	SEC_CONTENT
lots	SEC_CONTENT
of	SEC_CONTENT
downstream	SEC_CONTENT
applications	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
relation	SEC_CONTENT
extraction	SEC_CONTENT
,	SEC_CONTENT
syntactic	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
entity	SEC_CONTENT
linking	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Traditional	SEC_START
methods	SEC_CONTENT
employed	SEC_CONTENT
machine	SEC_CONTENT
learning	SEC_CONTENT
models	SEC_CONTENT
like	SEC_CONTENT
Hidden	SEC_CONTENT
Markov	SEC_CONTENT
Models	SEC_CONTENT
(	SEC_CONTENT
HMMs	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
Conditional	SEC_CONTENT
Random	SEC_CONTENT
Fields	SEC_CONTENT
(	SEC_CONTENT
CRFs	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
have	SEC_CONTENT
achieved	SEC_CONTENT
relatively	SEC_CONTENT
high	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
methods	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
heavy	SEC_CONTENT
reliance	SEC_CONTENT
on	SEC_CONTENT
handcrafted	SEC_CONTENT
features	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
whether	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
is	SEC_CONTENT
capitalized	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
language	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
resources	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
gazetteers	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
difficult	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
them	SEC_CONTENT
to	SEC_CONTENT
new	SEC_CONTENT
tasks	SEC_CONTENT
or	SEC_CONTENT
shift	SEC_CONTENT
to	SEC_CONTENT
new	SEC_CONTENT
domains	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
overcome	SEC_CONTENT
this	SEC_CONTENT
drawback	SEC_CONTENT
,	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
(	SEC_CONTENT
NNs	SEC_CONTENT
)	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
proposed	SEC_CONTENT
to	SEC_CONTENT
automatically	SEC_CONTENT
extract	SEC_CONTENT
features	SEC_CONTENT
during	SEC_CONTENT
model	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
Nevertheless	SEC_CONTENT
,	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
overwhelming	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
NNs	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
relatively	SEC_CONTENT
small	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
most	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
annotations	SEC_CONTENT
alone	SEC_CONTENT
may	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
sufficient	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
complicated	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
So	SEC_CONTENT
,	SEC_CONTENT
guiding	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
process	SEC_CONTENT
with	SEC_CONTENT
extra	SEC_CONTENT
knowledge	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
wise	SEC_CONTENT
choice	SEC_CONTENT
.	SEC_END
Accordingly	SEC_START
,	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
and	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
proposed	SEC_CONTENT
to	SEC_CONTENT
incorporate	SEC_CONTENT
such	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
NER	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
improved	SEC_CONTENT
by	SEC_CONTENT
jointly	SEC_CONTENT
conducting	SEC_CONTENT
other	SEC_CONTENT
related	SEC_CONTENT
tasks	SEC_CONTENT
like	SEC_CONTENT
entity	task
linking	task
or	SEC_CONTENT
chunking	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
After	SEC_CONTENT
all	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
approaches	SEC_CONTENT
would	SEC_CONTENT
require	SEC_CONTENT
additional	SEC_CONTENT
supervision	SEC_CONTENT
on	SEC_CONTENT
related	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
might	SEC_CONTENT
be	SEC_CONTENT
hard	SEC_CONTENT
to	SEC_CONTENT
get	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
not	SEC_CONTENT
even	SEC_CONTENT
existent	SEC_CONTENT
for	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
resource	SEC_CONTENT
languages	SEC_CONTENT
or	SEC_CONTENT
special	SEC_CONTENT
domains	SEC_CONTENT
.	SEC_END
Alternatively	SEC_START
,	SEC_CONTENT
abundant	SEC_CONTENT
knowledge	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
raw	SEC_CONTENT
texts	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
enhance	SEC_CONTENT
a	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Word	SEC_CONTENT
embedding	SEC_CONTENT
techniques	SEC_CONTENT
represent	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
continuous	SEC_CONTENT
space	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
retain	SEC_CONTENT
the	task
semantic	task
relations	task
among	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Consequently	SEC_CONTENT
,	SEC_CONTENT
integrating	SEC_CONTENT
these	SEC_CONTENT
embeddings	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
beneficial	SEC_CONTENT
to	SEC_CONTENT
many	SEC_CONTENT
tasks	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Nonetheless	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
embedding	SEC_CONTENT
methods	SEC_CONTENT
take	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
basic	SEC_CONTENT
unit	SEC_CONTENT
,	SEC_CONTENT
thus	SEC_CONTENT
only	SEC_CONTENT
obtaining	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
character	SEC_CONTENT
awareness	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
crucial	SEC_CONTENT
and	SEC_CONTENT
highly	SEC_CONTENT
valued	SEC_CONTENT
inmost	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
ofthe	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
NN	SEC_CONTENT
models	SEC_CONTENT
.	SEC_END
Only	SEC_START
recently	SEC_CONTENT
,	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
leveraged	SEC_CONTENT
and	SEC_CONTENT
empirically	SEC_CONTENT
verified	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
helpful	SEC_CONTENT
in	SEC_CONTENT
numerous	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Directly	SEC_CONTENT
adopting	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
integrated	SEC_CONTENT
as	SEC_CONTENT
context	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
demonstrate	SEC_CONTENT
its	SEC_CONTENT
potential	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
knowledge	SEC_CONTENT
extracted	SEC_CONTENT
through	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
,	SEC_CONTENT
thus	SEC_CONTENT
containing	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
irrelevant	SEC_CONTENT
portion	SEC_CONTENT
.	SEC_CONTENT
So	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
would	SEC_CONTENT
require	SEC_CONTENT
a	SEC_CONTENT
bigger	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
external	SEC_CONTENT
corpus	SEC_CONTENT
and	SEC_CONTENT
longer	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
was	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
32	SEC_CONTENT
GPUs	SEC_CONTENT
for	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
half	SEC_CONTENT
a	SEC_CONTENT
month	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
unrealistic	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
situations	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
an	SEC_CONTENT
effective	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
framework	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
leverages	SEC_CONTENT
both	SEC_CONTENT
wordlevel	SEC_CONTENT
and	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
in	SEC_CONTENT
an	SEC_CONTENT
efficient	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
lstm	SEC_CONTENT
unit	SEC_CONTENT
concat	SEC_CONTENT
unit	SEC_CONTENT
c0	SEC_CONTENT
,	SEC_CONTENT
c1,0	SEC_CONTENT
c1,1	SEC_CONTENT
c1,2	SEC_CONTENT
c1,3	SEC_CONTENT
c1,4	SEC_CONTENT
c1,5	SEC_CONTENT
c1	SEC_CONTENT
,	SEC_CONTENT
c2,0	SEC_CONTENT
c2,1	SEC_CONTENT
c2,2	SEC_CONTENT
c2,3	SEC_CONTENT
c2,4	SEC_CONTENT
c2,5	SEC_CONTENT
c2	SEC_CONTENT
,	SEC_END
backward	SEC_START
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
highway	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
LM	SEC_CONTENT
highway	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
highway	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
LM	SEC_CONTENT
highway	SEC_CONTENT
x	SEC_CONTENT
:	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
Neural	SEC_CONTENT
Architecture	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
conduct	SEC_CONTENT
multitask	SEC_CONTENT
learning	SEC_CONTENT
to	SEC_CONTENT
guide	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
towards	SEC_CONTENT
taskspecific	SEC_CONTENT
key	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
the	SEC_CONTENT
potential	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
better	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
strategy	SEC_CONTENT
also	SEC_CONTENT
poses	SEC_CONTENT
anew	SEC_CONTENT
challenge	SEC_CONTENT
.	SEC_CONTENT
Based	SEC_CONTENT
on	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
discrepant	SEC_CONTENT
,	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
harmful	SEC_CONTENT
to	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
na¨ıvena¨ıve	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
setting	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
this	SEC_CONTENT
reason	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
highway	SEC_CONTENT
networks	SEC_CONTENT
to	SEC_CONTENT
transform	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
into	SEC_CONTENT
different	SEC_CONTENT
semantic	SEC_CONTENT
spaces	SEC_CONTENT
,	SEC_CONTENT
thus	SEC_CONTENT
mediating	SEC_CONTENT
and	SEC_CONTENT
unifying	SEC_CONTENT
these	SEC_CONTENT
two	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
choose	SEC_CONTENT
to	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
or	SEC_CONTENT
pretraining	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
majority	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
come	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
and	SEC_CONTENT
such	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
or	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
cost	SEC_CONTENT
lots	SEC_CONTENT
of	SEC_CONTENT
time	SEC_CONTENT
and	SEC_CONTENT
resources	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
conduct	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL	SEC_CONTENT
2003	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
the	dataset
CoNLL	dataset
2000	dataset
chunking	dataset
task	dataset
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
portion	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
POS	dataset
tagging	dataset
task	dataset
.	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
achieves	SEC_CONTENT
a	SEC_CONTENT
significant	SEC_CONTENT
improvement	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
.	SEC_CONTENT
Also	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
strategy	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
more	SEC_CONTENT
useful	SEC_CONTENT
knowledge	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
smaller	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
thus	SEC_CONTENT
yielding	SEC_CONTENT
much	SEC_CONTENT
better	SEC_CONTENT
efficiency	SEC_CONTENT
without	SEC_CONTENT
loss	SEC_CONTENT
of	SEC_CONTENT
effectiveness	SEC_CONTENT
.	SEC_END
LM	SECTITLE_START
-	SECTITLE_CONTENT
LSTM	SECTITLE_CONTENT
-	SECTITLE_CONTENT
CRF	SECTITLE_CONTENT
Framework	SECTITLE_END
The	SEC_START
neural	SEC_CONTENT
architecture	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
framework	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
visualized	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
with	SEC_CONTENT
annotations	SEC_CONTENT
y	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
y	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
its	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
input	SEC_CONTENT
is	SEC_CONTENT
marked	SEC_CONTENT
as	SEC_CONTENT
x	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
xi	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
ith	SEC_CONTENT
word	SEC_CONTENT
;	SEC_CONTENT
its	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
input	SEC_CONTENT
is	SEC_CONTENT
recorded	SEC_CONTENT
as	SEC_CONTENT
c	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
c	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
1,1	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
1,2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
2,1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
c	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
j	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
j	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
character	SEC_CONTENT
for	SEC_CONTENT
word	SEC_CONTENT
w	SEC_CONTENT
i	SEC_CONTENT
and	SEC_CONTENT
c	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
space	SEC_CONTENT
character	SEC_CONTENT
after	SEC_CONTENT
w	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
notations	SEC_CONTENT
are	SEC_CONTENT
also	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Now	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
discuss	SEC_CONTENT
the	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
strategy	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
introduce	SEC_CONTENT
the	SEC_CONTENT
architecture	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
bottom	SEC_CONTENT
-	SEC_CONTENT
up	SEC_CONTENT
fashion	SEC_CONTENT
.	SEC_END
x	SEC_START
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
input	SEC_END
output	SEC_START
of	SEC_CONTENT
backward	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTM	SEC_CONTENT
at	SEC_CONTENT
c	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
f	SEC_CONTENT
Li	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
LM	SEC_CONTENT
highway	SEC_CONTENT
unit	SEC_CONTENT
r	SEC_CONTENT
Li	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
LM	SEC_CONTENT
highway	SEC_CONTENT
unit	SEC_CONTENT
f	SEC_CONTENT
Ni	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
highway	SEC_CONTENT
unit	SEC_CONTENT
r	SEC_CONTENT
Ni	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
highway	SEC_CONTENT
unit	SEC_CONTENT
vi	SEC_CONTENT
input	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
at	SEC_CONTENT
xi	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
at	SEC_CONTENT
xi	SEC_END
Multi	SECTITLE_START
-	SECTITLE_CONTENT
task	SECTITLE_CONTENT
Learning	SECTITLE_CONTENT
Strategy	SECTITLE_END
As	SEC_START
shown	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
model	SEC_CONTENT
share	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
fits	SEC_CONTENT
the	SEC_CONTENT
setting	SEC_CONTENT
of	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
and	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
different	SEC_CONTENT
from	SEC_CONTENT
typical	SEC_CONTENT
models	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
setting	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
two	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
strongly	SEC_CONTENT
related	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
discordance	SEC_CONTENT
makes	SEC_CONTENT
our	SEC_CONTENT
problem	SEC_CONTENT
more	SEC_CONTENT
challenging	SEC_CONTENT
.	SEC_CONTENT
E.g.	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
a	SEC_CONTENT
naive	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
setting	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
directly	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
from	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
in	SEC_CONTENT
several	SEC_CONTENT
scenarios	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
two	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
would	SEC_CONTENT
hurt	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
phenomenon	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
further	SEC_CONTENT
discussed	SEC_CONTENT
in	SEC_CONTENT
the	task
experiment	task
section	task
.	SEC_END
To	SEC_START
mediate	SEC_CONTENT
these	SEC_CONTENT
two	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
transform	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
into	SEC_CONTENT
different	SEC_CONTENT
semantic	SEC_CONTENT
spaces	SEC_CONTENT
for	SEC_CONTENT
different	SEC_CONTENT
objectives	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
strategy	SEC_CONTENT
allows	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
general	SEC_CONTENT
feature	SEC_CONTENT
extraction	SEC_CONTENT
and	SEC_CONTENT
lets	SEC_CONTENT
the	SEC_CONTENT
transform	SEC_CONTENT
layers	SEC_CONTENT
select	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
Hence	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
provide	SEC_CONTENT
related	SEC_CONTENT
knowledge	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
,	SEC_CONTENT
without	SEC_CONTENT
forcing	SEC_CONTENT
it	SEC_CONTENT
to	SEC_CONTENT
share	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
feature	SEC_CONTENT
space	SEC_CONTENT
.	SEC_END
Character	SECTITLE_START
-	SECTITLE_CONTENT
level	SECTITLE_CONTENT
Layer	SECTITLE_END
Character	SEC_START
-	SEC_CONTENT
level	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
purely	SEC_CONTENT
on	SEC_CONTENT
unannotated	SEC_CONTENT
sequence	SEC_CONTENT
data	SEC_CONTENT
but	SEC_CONTENT
can	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
underlying	SEC_CONTENT
style	SEC_CONTENT
and	SEC_CONTENT
structure	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
mimic	SEC_CONTENT
Shakespeare	SEC_CONTENT
's	SEC_CONTENT
writing	SEC_CONTENT
and	SEC_CONTENT
generate	SEC_CONTENT
sentences	SEC_CONTENT
of	SEC_CONTENT
similar	SEC_CONTENT
styles	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
even	SEC_CONTENT
master	SEC_CONTENT
the	SEC_CONTENT
grammar	SEC_CONTENT
of	SEC_CONTENT
programming	SEC_CONTENT
languages	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
XML	SEC_CONTENT
,	SEC_CONTENT
LA	SEC_CONTENT
T	SEC_CONTENT
E	SEC_CONTENT
X	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
C	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
generate	SEC_CONTENT
syntactically	SEC_CONTENT
correct	SEC_CONTENT
codes	SEC_CONTENT
.	SEC_CONTENT
Accordingly	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopted	SEC_CONTENT
the	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
Long	SEC_CONTENT
Short	SEC_CONTENT
Term	SEC_CONTENT
Memory	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
networks	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
Aiming	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
lexical	SEC_CONTENT
features	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
remembering	SEC_CONTENT
words	SEC_CONTENT
'	SEC_CONTENT
spelling	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adjust	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
character	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTM	SEC_CONTENT
would	SEC_CONTENT
only	SEC_CONTENT
make	SEC_CONTENT
predictions	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
word	SEC_CONTENT
at	SEC_CONTENT
word	SEC_CONTENT
boundaries	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
space	SEC_CONTENT
characters	SEC_CONTENT
orc	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Furthermore	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
coupled	SEC_CONTENT
two	SEC_CONTENT
LSTM	SEC_CONTENT
units	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
both	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
directions	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
it	SEC_CONTENT
seems	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
unit	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
two	SEC_CONTENT
units	SEC_CONTENT
are	SEC_CONTENT
processed	SEC_CONTENT
and	SEC_CONTENT
aligned	SEC_CONTENT
differently	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
record	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
forward	SEC_CONTENT
LSTM	SEC_CONTENT
at	SEC_CONTENT
c	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
f	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
backward	SEC_CONTENT
LSTM	SEC_CONTENT
at	SEC_CONTENT
c	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
r	SEC_CONTENT
i	SEC_CONTENT
.	SEC_END
Highway	SECTITLE_START
Layer	SECTITLE_END
In	SEC_START
computer	SEC_CONTENT
vision	SEC_CONTENT
,	SEC_CONTENT
Convolutional	SEC_CONTENT
Neural	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
CNN	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
proved	SEC_CONTENT
to	SEC_CONTENT
bean	SEC_CONTENT
effective	SEC_CONTENT
feature	SEC_CONTENT
extractor	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
its	SEC_CONTENT
output	SEC_CONTENT
needs	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
further	SEC_CONTENT
transformed	SEC_CONTENT
by	SEC_CONTENT
fully	SEC_CONTENT
-	SEC_CONTENT
connected	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
.	SEC_CONTENT
Bearing	SEC_CONTENT
this	SEC_CONTENT
in	SEC_CONTENT
mind	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
becomes	SEC_CONTENT
natural	SEC_CONTENT
to	SEC_CONTENT
stack	SEC_CONTENT
additional	SEC_CONTENT
layers	SEC_CONTENT
upon	SEC_CONTENT
the	SEC_CONTENT
flat	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTMs	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
specifically	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
highway	SEC_CONTENT
units	SEC_CONTENT
(	SEC_CONTENT
Srivastava	SEC_CONTENT
,	SEC_CONTENT
Greff	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Schmidhuber	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
allow	SEC_CONTENT
unimpeded	SEC_CONTENT
information	SEC_CONTENT
flowing	SEC_CONTENT
across	SEC_CONTENT
several	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
Typically	SEC_CONTENT
,	SEC_CONTENT
highway	SEC_CONTENT
layers	SEC_CONTENT
conduct	SEC_CONTENT
nonlinear	SEC_CONTENT
transformation	SEC_CONTENT
as	SEC_END
is	SEC_START
element	SEC_CONTENT
-	SEC_CONTENT
wise	SEC_CONTENT
product	SEC_CONTENT
,	SEC_CONTENT
g	SEC_CONTENT
(	SEC_CONTENT
·	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
nonlinear	SEC_CONTENT
transformation	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
ReLU	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
σ(W	SEC_CONTENT
T	SEC_CONTENT
n	SEC_CONTENT
+	SEC_CONTENT
b	SEC_CONTENT
T	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
called	SEC_CONTENT
transform	SEC_CONTENT
gate	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
−	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
called	SEC_CONTENT
carry	SEC_CONTENT
gate	SEC_CONTENT
.	SEC_END
In	SEC_START
our	SEC_CONTENT
final	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
four	SEC_CONTENT
highway	SEC_CONTENT
units	SEC_CONTENT
,	SEC_CONTENT
named	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
LM	SEC_CONTENT
,	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
,	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
LM	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
two	SEC_CONTENT
transfer	SEC_CONTENT
f	SEC_CONTENT
i	SEC_CONTENT
into	SEC_CONTENT
f	SEC_CONTENT
Li	SEC_CONTENT
and	SEC_CONTENT
f	SEC_CONTENT
Ni	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
two	SEC_CONTENT
transfer	SEC_CONTENT
r	SEC_CONTENT
i	SEC_CONTENT
into	SEC_CONTENT
r	SEC_CONTENT
Li	SEC_CONTENT
and	SEC_CONTENT
r	SEC_CONTENT
Ni	SEC_CONTENT
.	SEC_CONTENT
f	SEC_CONTENT
Li	SEC_CONTENT
and	SEC_CONTENT
r	SEC_CONTENT
Li	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
f	SEC_CONTENT
Ni	SEC_CONTENT
and	SEC_CONTENT
r	SEC_CONTENT
Ni	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
.	SEC_END
Word	SECTITLE_START
-	SECTITLE_CONTENT
level	SECTITLE_CONTENT
Layer	SECTITLE_END
Bi	SEC_START
-	SEC_CONTENT
LSTM	SEC_CONTENT
is	SEC_CONTENT
adopted	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
structure	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
both	SEC_CONTENT
directions	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
concatenate	SEC_CONTENT
f	SEC_CONTENT
Ni	SEC_CONTENT
and	SEC_CONTENT
r	SEC_CONTENT
N	SEC_CONTENT
i−1	SEC_CONTENT
with	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
feed	SEC_CONTENT
them	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
backward	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
i−1	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
space	SEC_CONTENT
character	SEC_CONTENT
before	SEC_CONTENT
word	SEC_CONTENT
xi	SEC_CONTENT
,	SEC_CONTENT
therefore	SEC_CONTENT
,	SEC_CONTENT
f	SEC_CONTENT
Ni	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
aligned	SEC_CONTENT
and	SEC_CONTENT
concatenated	SEC_CONTENT
with	SEC_CONTENT
r	SEC_CONTENT
N	SEC_CONTENT
i−1	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
r	SEC_CONTENT
Ni	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
'	SEC_CONTENT
Pierre	SEC_CONTENT
'	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
concatenated	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
over	SEC_CONTENT
'	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.Pierre	SEC_CONTENT
'	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
SL	SEC_CONTENT
over	SEC_CONTENT
'	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.erreiP	SEC_CONTENT
'	SEC_CONTENT
.	SEC_END
As	SEC_START
to	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
chose	SEC_CONTENT
to	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_CONTENT
pretrained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
because	SEC_CONTENT
most	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
model	SEC_CONTENT
come	SEC_CONTENT
from	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
finetuning	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
verified	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
in	SEC_CONTENT
leveraging	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
,	SEC_CONTENT
current	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
methods	SEC_CONTENT
can	SEC_CONTENT
easily	SEC_CONTENT
scale	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
large	SEC_CONTENT
corpus	SEC_CONTENT
;	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
available	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
languages	SEC_CONTENT
and	SEC_CONTENT
domains	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
strategy	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
layers	SEC_CONTENT
contains	SEC_CONTENT
very	SEC_CONTENT
few	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
Based	SEC_CONTENT
on	SEC_CONTENT
these	SEC_CONTENT
considerations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
applied	SEC_CONTENT
different	SEC_CONTENT
strategies	SEC_CONTENT
to	SEC_CONTENT
leverage	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
from	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
.	SEC_END
CRF	SECTITLE_START
for	SECTITLE_CONTENT
Sequence	SECTITLE_CONTENT
Labeling	SECTITLE_END
Label	SEC_START
dependencies	SEC_CONTENT
are	SEC_CONTENT
crucial	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
with	SEC_CONTENT
BIOES	SEC_CONTENT
annotation	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
meaningless	SEC_CONTENT
but	SEC_CONTENT
illegal	SEC_CONTENT
to	SEC_CONTENT
annotate	SEC_CONTENT
I	SEC_CONTENT
-	SEC_CONTENT
PER	SEC_CONTENT
after	SEC_CONTENT
B	SEC_CONTENT
-	SEC_CONTENT
ORG	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
mixing	SEC_CONTENT
the	SEC_CONTENT
person	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
organization	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
jointly	SEC_CONTENT
decoding	SEC_CONTENT
a	SEC_CONTENT
chain	SEC_CONTENT
of	SEC_CONTENT
labels	SEC_CONTENT
can	SEC_CONTENT
ensure	SEC_CONTENT
the	SEC_CONTENT
resulting	SEC_CONTENT
label	SEC_CONTENT
sequence	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
meaningful	SEC_CONTENT
.	SEC_CONTENT
Conditional	SEC_CONTENT
random	SEC_CONTENT
field	SEC_CONTENT
(	SEC_CONTENT
CRF	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
included	SEC_CONTENT
inmost	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
such	SEC_CONTENT
information	SEC_CONTENT
and	SEC_CONTENT
further	SEC_CONTENT
avoid	SEC_CONTENT
generating	SEC_CONTENT
illegal	SEC_CONTENT
annotations	SEC_CONTENT
.	SEC_CONTENT
Consequently	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
build	SEC_CONTENT
a	metric
CRF	metric
layer	metric
upon	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_END
For	SEC_START
training	SEC_CONTENT
instance	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
suppose	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
LSTM	SEC_CONTENT
is	SEC_CONTENT
Z	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
i,1	SEC_CONTENT
,	SEC_CONTENT
z	SEC_CONTENT
i,2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
CRF	SEC_CONTENT
models	SEC_CONTENT
describe	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
generating	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
label	SEC_CONTENT
sequence	SEC_CONTENT
with	SEC_CONTENT
regard	SEC_CONTENT
to	SEC_END
is	SEC_START
a	SEC_CONTENT
generic	SEC_CONTENT
label	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
Similar	SEC_CONTENT
to	SEC_CONTENT
(	SEC_CONTENT
Ma	SEC_CONTENT
and	SEC_CONTENT
Hovy	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
define	SEC_CONTENT
this	SEC_CONTENT
probability	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
.	SEC_END
Here	SEC_START
,	SEC_CONTENT
Y(Z	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
generic	SEC_CONTENT
label	SEC_CONTENT
sequences	SEC_CONTENT
,	SEC_CONTENT
φ(y	SEC_CONTENT
j−1	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
z	SEC_CONTENT
j	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
exp(W	SEC_CONTENT
yj−1,yj	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
+	SEC_CONTENT
b	SEC_CONTENT
yj−1,yj	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
W	SEC_CONTENT
yj−1,yj	SEC_CONTENT
and	SEC_CONTENT
b	SEC_CONTENT
yj−1,yj	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
and	SEC_CONTENT
bias	SEC_CONTENT
parameters	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
pair	SEC_CONTENT
(	SEC_CONTENT
y	SEC_CONTENT
j−1	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
j	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
minimize	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
negative	SEC_CONTENT
loglikelihood	SEC_CONTENT
.	SEC_END
And	SEC_START
for	SEC_CONTENT
testing	SEC_CONTENT
or	SEC_CONTENT
decoding	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
want	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
optimal	SEC_CONTENT
sequence	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
that	SEC_CONTENT
maximizes	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
.	SEC_END
Although	SEC_START
the	SEC_CONTENT
denominator	SEC_CONTENT
of	SEC_CONTENT
Eq	SEC_CONTENT
.	SEC_CONTENT
1	SEC_CONTENT
is	SEC_CONTENT
complicated	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
calculate	SEC_CONTENT
Eqs	SEC_CONTENT
.	SEC_CONTENT
2	SEC_CONTENT
and	SEC_CONTENT
3	SEC_CONTENT
efficiently	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
Viterbi	SEC_CONTENT
algorithm	SEC_CONTENT
.	SEC_END
Neural	SECTITLE_START
Language	SECTITLE_CONTENT
Model	SECTITLE_END
The	SEC_START
language	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
family	SEC_CONTENT
of	SEC_CONTENT
models	SEC_CONTENT
describing	SEC_CONTENT
the	SEC_CONTENT
generation	SEC_CONTENT
of	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_CONTENT
Ina	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
generation	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
x	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
direction	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
from	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
right	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_END
.	SEC_START
This	SEC_CONTENT
probability	SEC_CONTENT
is	SEC_CONTENT
assumed	SEC_CONTENT
as	SEC_END
where	SEC_START
w	SEC_CONTENT
xi	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
vector	SEC_CONTENT
for	SEC_CONTENT
predicting	SEC_CONTENT
word	SEC_CONTENT
xi	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
knowledge	SEC_CONTENT
in	SEC_CONTENT
both	SEC_CONTENT
directions	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
adopted	SEC_CONTENT
a	SEC_CONTENT
reversed	SEC_CONTENT
-	SEC_CONTENT
order	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
calculates	SEC_CONTENT
the	SEC_CONTENT
generation	SEC_CONTENT
probability	SEC_CONTENT
from	SEC_CONTENT
right	SEC_CONTENT
to	SEC_CONTENT
left	SEC_CONTENT
as	SEC_END
The	SEC_START
following	SEC_CONTENT
negative	SEC_CONTENT
log	SEC_CONTENT
likelihood	SEC_CONTENT
is	SEC_CONTENT
applied	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Joint	SECTITLE_START
Model	SECTITLE_CONTENT
Learning	SECTITLE_END
By	SEC_START
combining	SEC_CONTENT
Eqs	SEC_CONTENT
.	SEC_CONTENT
2	SEC_CONTENT
and	SEC_CONTENT
4	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
write	SEC_CONTENT
the	SEC_CONTENT
joint	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
as	SEC_END
where	SEC_START
λ	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
parameter	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
λ	SEC_CONTENT
is	SEC_CONTENT
always	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
1	SEC_CONTENT
without	SEC_CONTENT
any	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
efficiently	SEC_CONTENT
,	SEC_CONTENT
stochastic	SEC_CONTENT
optimization	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
adopted	SEC_CONTENT
.	SEC_CONTENT
And	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
iteration	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
sample	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
instances	SEC_CONTENT
and	SEC_CONTENT
perform	SEC_CONTENT
an	SEC_CONTENT
update	SEC_CONTENT
according	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
summand	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
Eq	SEC_CONTENT
.	SEC_CONTENT
5	SEC_CONTENT
:	SEC_END
Experiments	SECTITLE_END
Here	SEC_START
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
the	metric
accuracy	metric
for	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
And	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
two	SEC_CONTENT
datasets	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
the	SEC_CONTENT
official	SEC_CONTENT
evaluation	SEC_CONTENT
metric	SEC_CONTENT
(	SEC_CONTENT
microaveraged	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
BIOES	SEC_CONTENT
scheme	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Also	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
three	SEC_CONTENT
datasets	SEC_CONTENT
,	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
frequency	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
replaced	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
special	SEC_CONTENT
token	SEC_CONTENT
(	SEC_CONTENT
<	SEC_CONTENT
UNK	SEC_CONTENT
>	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Network	SECTITLE_START
Training	SECTITLE_END
For	SEC_START
a	SEC_CONTENT
fair	SEC_CONTENT
comparison	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
n't	SEC_CONTENT
spend	SEC_CONTENT
much	SEC_CONTENT
time	SEC_CONTENT
on	SEC_CONTENT
tuning	SEC_CONTENT
parameters	SEC_CONTENT
but	SEC_CONTENT
borrow	SEC_CONTENT
the	SEC_CONTENT
initialization	SEC_CONTENT
,	SEC_CONTENT
optimization	SEC_CONTENT
method	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
all	SEC_CONTENT
related	SEC_CONTENT
hyper	SEC_CONTENT
-	SEC_CONTENT
parameter	SEC_CONTENT
values	SEC_CONTENT
(	SEC_CONTENT
except	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
expand	SEC_CONTENT
it	SEC_CONTENT
from	SEC_CONTENT
200	SEC_CONTENT
to	SEC_CONTENT
300	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
introducing	SEC_CONTENT
additional	SEC_CONTENT
knowledge	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
larger	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
will	SEC_CONTENT
further	SEC_CONTENT
discuss	SEC_CONTENT
this	SEC_CONTENT
change	SEC_CONTENT
later	SEC_CONTENT
.	SEC_CONTENT
summarizes	SEC_CONTENT
some	SEC_CONTENT
important	SEC_CONTENT
hyperparameters	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
the	SEC_CONTENT
CoNLL00	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
NER	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
experiments	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
parameters	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Initialization	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
GloVe	SEC_CONTENT
100-dimension	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
released	SEC_CONTENT
by	SEC_CONTENT
Stanford	SEC_CONTENT
1	SEC_CONTENT
and	SEC_CONTENT
randomly	SEC_CONTENT
initialize	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
parameters	SEC_CONTENT
(	SEC_CONTENT
Glorot	SEC_CONTENT
and	SEC_CONTENT
Bengio	SEC_CONTENT
2010	SEC_CONTENT
;	SEC_CONTENT
Jozefowicz	SEC_CONTENT
,	SEC_CONTENT
Zaremba	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Sutskever	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Optimization	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
employ	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
with	SEC_CONTENT
momentum	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
momentum	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
are	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
10	SEC_CONTENT
,	SEC_CONTENT
0.9	SEC_CONTENT
and	SEC_CONTENT
η	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
η0	SEC_CONTENT
1+ρt	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
η	SEC_CONTENT
0	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
and	SEC_CONTENT
ρ	SEC_CONTENT
=	SEC_CONTENT
0.05	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
decay	SEC_CONTENT
ratio	SEC_CONTENT
.	SEC_CONTENT
Dropout	SEC_CONTENT
is	SEC_CONTENT
applied	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
ratio	SEC_CONTENT
is	SEC_CONTENT
fixed	SEC_CONTENT
to	SEC_CONTENT
0.5	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
increase	SEC_CONTENT
stability	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
gradient	SEC_CONTENT
clipping	SEC_CONTENT
of	SEC_CONTENT
5.0	SEC_CONTENT
.	SEC_CONTENT
Network	SEC_CONTENT
Structure	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
hyper	SEC_CONTENT
-	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
characterlevel	SEC_CONTENT
LSTM	SEC_CONTENT
are	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
fix	SEC_CONTENT
the	SEC_CONTENT
depth	SEC_CONTENT
of	SEC_CONTENT
highway	SEC_CONTENT
layers	SEC_CONTENT
as	SEC_CONTENT
1	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
an	SEC_CONTENT
over	SEC_CONTENT
-	SEC_CONTENT
complicated	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
some	SEC_CONTENT
baseline	SEC_CONTENT
methods	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
)	SEC_CONTENT
incorporate	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
as	SEC_CONTENT
apart	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
using	SEC_CONTENT
early	SEC_CONTENT
stopping	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
evaluation	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
purely	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Compared	SEC_START
Methods	SEC_CONTENT
We	SEC_CONTENT
consider	SEC_CONTENT
three	SEC_CONTENT
classes	SEC_CONTENT
of	SEC_CONTENT
baseline	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
methods	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_END
•	SEC_START
Performance	SECTITLE_START
Comparison	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
comparisons	SEC_CONTENT
between	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
and	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
arts	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
both	SEC_CONTENT
effectiveness	SEC_CONTENT
and	SEC_CONTENT
efficiency	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
demonstrated	SEC_CONTENT
in	SEC_CONTENT
Tables	SEC_CONTENT
4	SEC_CONTENT
,	SEC_CONTENT
5	SEC_CONTENT
and	SEC_CONTENT
7	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
significantly	SEC_CONTENT
outperforms	SEC_CONTENT
all	SEC_CONTENT
baselines	SEC_CONTENT
without	SEC_CONTENT
additional	SEC_CONTENT
resources	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
for	SEC_CONTENT
those	SEC_CONTENT
baselines	SEC_CONTENT
with	SEC_CONTENT
extra	SEC_CONTENT
resources	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
beats	SEC_CONTENT
most	SEC_CONTENT
of	SEC_CONTENT
them	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
slightly	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
4	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
discover	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
CPU	SEC_CONTENT
,	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
only	SEC_CONTENT
reaches	SEC_CONTENT
90.83	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
NER	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
gets	SEC_CONTENT
91.37	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
when	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
GPU	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
conjecture	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
performance	SEC_CONTENT
gap	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
difference	SEC_CONTENT
of	SEC_CONTENT
runtime	SEC_CONTENT
environments	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
GPU	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
index	SEC_CONTENT
12	SEC_CONTENT
fails	SEC_CONTENT
to	SEC_CONTENT
outperform	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
or	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
.	SEC_CONTENT
The	dataset
reason	dataset
of	SEC_CONTENT
this	SEC_CONTENT
phenomenon	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
complicated	SEC_CONTENT
and	SEC_CONTENT
beyond	SEC_CONTENT
the	SEC_CONTENT
scope	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
verified	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
method	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
demonstrated	SEC_CONTENT
the	SEC_CONTENT
contribution	SEC_CONTENT
of	SEC_CONTENT
outperforming	SEC_CONTENT
these	SEC_CONTENT
baselines	SEC_CONTENT
.	SEC_END
NER	SEC_START
First	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
to	SEC_CONTENT
point	SEC_CONTENT
out	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
index	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
4	SEC_CONTENT
,	SEC_CONTENT
8	SEC_CONTENT
,	SEC_CONTENT
10	SEC_CONTENT
and	SEC_CONTENT
11	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
directly	SEC_CONTENT
comparable	SEC_CONTENT
with	SEC_CONTENT
others	SEC_CONTENT
since	SEC_CONTENT
their	SEC_CONTENT
final	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
others	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
purely	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
mentioned	SEC_CONTENT
before	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
outperforms	SEC_CONTENT
all	SEC_CONTENT
baselines	SEC_CONTENT
except	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
4	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
a	SEC_CONTENT
thorough	SEC_CONTENT
comparison	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
variants	SEC_CONTENT
,	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
10	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
11	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
index	SEC_CONTENT
10	SEC_CONTENT
and	SEC_CONTENT
11	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
dataset	SEC_CONTENT
alone	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
index	SEC_CONTENT
11	SEC_CONTENT
utilizes	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
index	SEC_CONTENT
10	SEC_CONTENT
does	SEC_CONTENT
n't	SEC_CONTENT
.	SEC_CONTENT
Comparing	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
scores	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
two	SEC_CONTENT
settings	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
:	SEC_CONTENT
Training	SEC_CONTENT
statistics	SEC_CONTENT
of	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
4	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
NER	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
11	SEC_START
)	SEC_CONTENT
even	SEC_CONTENT
performs	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
10	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
reveals	SEC_CONTENT
that	SEC_CONTENT
directly	SEC_CONTENT
applying	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
might	SEC_CONTENT
hurt	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
will	SEC_CONTENT
also	SEC_CONTENT
discuss	SEC_CONTENT
this	SEC_CONTENT
challenge	SEC_CONTENT
later	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
Highway	SEC_CONTENT
Layers	SEC_CONTENT
&	SEC_CONTENT
Co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
section	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
,	SEC_CONTENT
changing	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
from	SEC_CONTENT
4096	SEC_CONTENT
-	SEC_CONTENT
8192	SEC_CONTENT
-	SEC_CONTENT
1024	SEC_CONTENT
to	SEC_CONTENT
LSTM-2048	SEC_CONTENT
-	SEC_CONTENT
512	SEC_CONTENT
,	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
gets	SEC_CONTENT
a	SEC_CONTENT
lower	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
of	SEC_CONTENT
91.62±0.23	SEC_CONTENT
.	SEC_CONTENT
Comparing	SEC_CONTENT
this	SEC_CONTENT
score	SEC_CONTENT
to	SEC_CONTENT
ours	SEC_CONTENT
(	SEC_CONTENT
91.71±0.10	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
can	SEC_CONTENT
verify	SEC_CONTENT
that	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
usually	SEC_CONTENT
extracts	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
portion	SEC_CONTENT
of	SEC_CONTENT
unrelated	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
Relieving	SEC_CONTENT
such	SEC_CONTENT
redundancy	SEC_CONTENT
by	SEC_CONTENT
guiding	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
information	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
conduct	SEC_CONTENT
both	SEC_CONTENT
effective	SEC_CONTENT
and	SEC_CONTENT
efficient	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_END
POS	SEC_START
Tagging	task
Similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
outperforms	SEC_CONTENT
all	SEC_CONTENT
baselines	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
portion	SEC_CONTENT
of	SEC_CONTENT
the	task
PTB	task
POS	task
tagging	task
task	task
.	SEC_CONTENT
Although	SEC_CONTENT
the	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
and	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
are	SEC_CONTENT
less	SEC_CONTENT
obvious	SEC_CONTENT
than	SEC_CONTENT
those	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
NER	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
fact	SEC_CONTENT
that	SEC_CONTENT
the	task
POS	task
tagging	task
task	task
is	SEC_CONTENT
believed	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
easier	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
current	SEC_CONTENT
methods	SEC_CONTENT
have	SEC_CONTENT
achieved	SEC_CONTENT
relatively	SEC_CONTENT
high	SEC_CONTENT
performance	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
improvement	SEC_CONTENT
could	SEC_CONTENT
still	SEC_CONTENT
be	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
significant	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
worth	SEC_CONTENT
noting	SEC_CONTENT
that	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
NER	SEC_CONTENT
and	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
achieves	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
higher	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
scores	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
with	SEC_CONTENT
smaller	SEC_CONTENT
variances	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
further	SEC_CONTENT
verifies	SEC_CONTENT
the	SEC_CONTENT
superiority	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
Chunking	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
chunking	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
also	SEC_CONTENT
achieves	SEC_CONTENT
relatively	SEC_CONTENT
high	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
scores	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
with	SEC_CONTENT
slightly	SEC_CONTENT
higher	SEC_CONTENT
variances	SEC_CONTENT
.	SEC_CONTENT
Considering	SEC_CONTENT
the	SEC_CONTENT
fact	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
smaller	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
two	SEC_CONTENT
(	SEC_CONTENT
only	SEC_CONTENT
about	SEC_CONTENT
1/5	SEC_CONTENT
of	SEC_CONTENT
WSJ	SEC_CONTENT
or	SEC_CONTENT
1/2	SEC_CONTENT
of	SEC_CONTENT
CoNLL03	dataset
NER	dataset
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
expect	SEC_CONTENT
more	SEC_CONTENT
variance	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
  	SEC_CONTENT
Efficiency	SEC_CONTENT
We	SEC_CONTENT
implement	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
5	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
PyTorch	SEC_CONTENT
library	SEC_CONTENT
.	SEC_CONTENT
Models	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
one	SEC_CONTENT
GeForce	SEC_CONTENT
GTX	SEC_CONTENT
1080	SEC_CONTENT
GPU	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
recorded	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
In	SEC_START
terms	SEC_CONTENT
of	SEC_CONTENT
efficiency	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
component	SEC_CONTENT
in	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
only	SEC_CONTENT
introduces	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
two	SEC_CONTENT
highway	SEC_CONTENT
units	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
soft	SEC_CONTENT
-	SEC_CONTENT
max	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
may	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
very	SEC_CONTENT
large	SEC_CONTENT
impact	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
efficiency	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
control	SEC_CONTENT
variables	SEC_CONTENT
like	SEC_CONTENT
infrastructures	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
further	SEC_CONTENT
reimplemented	SEC_CONTENT
both	SEC_CONTENT
baselines	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
report	SEC_CONTENT
their	SEC_CONTENT
performance	SEC_CONTENT
together	SEC_CONTENT
with	SEC_CONTENT
original	SEC_CONTENT
implementations	SEC_CONTENT
.	SEC_CONTENT
From	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
implementations	SEC_CONTENT
achieve	SEC_CONTENT
better	SEC_CONTENT
efficiency	SEC_CONTENT
comparing	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
ones	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
yield	SEC_CONTENT
relative	SEC_CONTENT
worse	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
Also	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
performance	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
takes	SEC_CONTENT
twice	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
efficient	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
.	SEC_CONTENT
Empirically	SEC_CONTENT
,	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
difference	SEC_CONTENT
among	SEC_CONTENT
the	SEC_CONTENT
implementations	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
think	SEC_CONTENT
these	SEC_CONTENT
methods	SEC_CONTENT
have	SEC_CONTENT
roughly	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
efficiency	SEC_CONTENT
.	SEC_END
Besides	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
list	SEC_CONTENT
the	SEC_CONTENT
required	SEC_CONTENT
time	SEC_CONTENT
and	SEC_CONTENT
resources	SEC_CONTENT
for	SEC_CONTENT
pretraining	SEC_CONTENT
model	SEC_CONTENT
index	SEC_CONTENT
4	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
in	SEC_CONTENT
Table	SEC_CONTENT
6	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Comparing	SEC_CONTENT
to	SEC_CONTENT
these	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
external	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
no	SEC_CONTENT
such	SEC_CONTENT
reliance	SEC_CONTENT
on	SEC_CONTENT
extensive	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
achieve	SEC_CONTENT
similar	SEC_CONTENT
performance	SEC_CONTENT
with	SEC_CONTENT
much	SEC_CONTENT
more	SEC_CONTENT
concise	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
effi-	SEC_END
Analysis	SECTITLE_END
To	SEC_START
analyze	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
additional	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
NER	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
Hidden	SEC_START
State	SEC_CONTENT
Size	SEC_CONTENT
To	SEC_CONTENT
explore	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
sizes	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
comparison	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
sizes	SEC_CONTENT
to	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
and	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
.	SEC_CONTENT
From	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
can	SEC_CONTENT
easily	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
of	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
keeps	SEC_CONTENT
increasing	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
size	SEC_CONTENT
grows	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
peak	SEC_CONTENT
at	SEC_CONTENT
state	SEC_CONTENT
size	SEC_CONTENT
200	SEC_CONTENT
and	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
drop	SEC_CONTENT
at	SEC_CONTENT
state	SEC_CONTENT
size	SEC_CONTENT
200	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
phenomenon	SEC_CONTENT
further	SEC_CONTENT
verified	SEC_CONTENT
our	SEC_CONTENT
intuition	SEC_CONTENT
of	SEC_CONTENT
employing	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
knowledge	SEC_CONTENT
and	SEC_CONTENT
prevent	SEC_CONTENT
overfitting	SEC_CONTENT
.	SEC_END
Highway	SEC_START
Layers	SEC_CONTENT
&	SEC_CONTENT
Co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
To	SEC_CONTENT
elucidate	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
highway	SEC_CONTENT
units	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
with	SEC_CONTENT
its	SEC_CONTENT
two	SEC_CONTENT
variants	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
NL	SEC_CONTENT
and	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
NH	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
keeps	SEC_CONTENT
highway	SEC_CONTENT
units	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
optimizes	SEC_CONTENT
J	SEC_CONTENT
CRF	SEC_CONTENT
alone	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
jointly	SEC_CONTENT
optimizes	SEC_CONTENT
J	SEC_CONTENT
CRF	SEC_CONTENT
and	SEC_CONTENT
J	SEC_CONTENT
LM	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
without	SEC_CONTENT
highway	SEC_CONTENT
units	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
NH	SEC_CONTENT
yields	SEC_CONTENT
worse	SEC_CONTENT
performance	SEC_CONTENT
than	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
NL	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
observation	SEC_CONTENT
accords	SEC_CONTENT
with	SEC_CONTENT
previous	SEC_CONTENT
comparison	SEC_CONTENT
between	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
10	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
TagLM	SEC_CONTENT
(	SEC_CONTENT
index	SEC_CONTENT
11	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL03	SEC_CONTENT
NER	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
conjecture	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
NER	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
strongly	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
other	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
summary	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
strategy	SEC_CONTENT
is	SEC_CONTENT
effective	SEC_CONTENT
and	SEC_CONTENT
introducing	SEC_CONTENT
the	SEC_CONTENT
highway	SEC_CONTENT
layers	SEC_CONTENT
is	SEC_CONTENT
necessary	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
There	SEC_START
exist	SEC_CONTENT
two	SEC_CONTENT
threads	SEC_CONTENT
of	SEC_CONTENT
related	SEC_CONTENT
work	SEC_CONTENT
regarding	SEC_CONTENT
the	SEC_CONTENT
topics	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
and	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
it	SEC_CONTENT
with	SEC_CONTENT
additional	SEC_CONTENT
information	SEC_CONTENT
..	SEC_CONTENT
These	SEC_CONTENT
models	SEC_CONTENT
all	SEC_CONTENT
incorporate	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
structure	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
report	SEC_CONTENT
meaningful	SEC_CONTENT
improvement	SEC_CONTENT
over	SEC_CONTENT
pure	SEC_CONTENT
wordlevel	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Also	SEC_CONTENT
,	SEC_CONTENT
CRF	SEC_CONTENT
layer	SEC_CONTENT
has	SEC_CONTENT
also	SEC_CONTENT
been	SEC_CONTENT
demonstrated	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
in	SEC_CONTENT
capturing	SEC_CONTENT
the	SEC_CONTENT
dependency	SEC_CONTENT
among	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
success	SEC_CONTENT
of	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
further	SEC_CONTENT
modified	SEC_CONTENT
to	SEC_CONTENT
better	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
char	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
manner	SEC_CONTENT
.	SEC_END
Leveraging	SEC_START
Additional	SEC_CONTENT
Information	SEC_CONTENT
.	SEC_CONTENT
Integrating	SEC_CONTENT
wordlevel	SEC_CONTENT
and	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
proved	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
helpful	SEC_CONTENT
to	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
utilized	SEC_CONTENT
by	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
or	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
strategies	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
none	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
models	SEC_CONTENT
utilizes	SEC_CONTENT
the	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
directly	SEC_CONTENT
adopting	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
helpful	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Such	SEC_CONTENT
pretrained	SEC_CONTENT
knowledge	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
and	SEC_CONTENT
requires	SEC_CONTENT
a	SEC_CONTENT
larger	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
external	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
longer	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
leverages	SEC_CONTENT
both	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
and	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
through	SEC_CONTENT
a	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
strategy	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
leads	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
concise	SEC_CONTENT
,	SEC_CONTENT
effective	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
efficient	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
,	SEC_CONTENT
unlike	SEC_CONTENT
other	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
methods	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
no	SEC_CONTENT
reliance	SEC_CONTENT
on	SEC_CONTENT
any	SEC_CONTENT
extra	SEC_CONTENT
annotation	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
or	SEC_CONTENT
any	SEC_CONTENT
knowledge	SEC_CONTENT
base	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
extracts	SEC_CONTENT
knowledge	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
contained	SEC_CONTENT
order	SEC_CONTENT
information	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
proposed	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
framework	SEC_CONTENT
,	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
effectively	SEC_CONTENT
leverages	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
selfcontained	SEC_CONTENT
order	SEC_CONTENT
information	SEC_CONTENT
.	SEC_CONTENT
Highway	SEC_CONTENT
layers	SEC_CONTENT
are	SEC_CONTENT
incorporated	SEC_CONTENT
to	SEC_CONTENT
overcome	SEC_CONTENT
the	SEC_CONTENT
discordance	SEC_CONTENT
issue	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
naive	SEC_CONTENT
cotraining	SEC_CONTENT
Benefited	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
effectively	SEC_CONTENT
captured	SEC_CONTENT
such	SEC_CONTENT
taskspecific	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
build	SEC_CONTENT
a	SEC_CONTENT
much	SEC_CONTENT
more	SEC_CONTENT
concise	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
thus	SEC_CONTENT
yielding	SEC_CONTENT
much	SEC_CONTENT
better	SEC_CONTENT
efficiency	SEC_CONTENT
without	SEC_CONTENT
loss	SEC_CONTENT
of	SEC_CONTENT
effectiveness	SEC_CONTENT
(	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
three	SEC_CONTENT
benchmark	SEC_CONTENT
datasets	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
future	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
plan	SEC_CONTENT
to	SEC_CONTENT
further	SEC_CONTENT
extract	SEC_CONTENT
and	SEC_CONTENT
incorporate	SEC_CONTENT
knowledge	SEC_CONTENT
from	SEC_CONTENT
other	SEC_CONTENT
"	SEC_CONTENT
unsupervised	SEC_CONTENT
"	SEC_CONTENT
learning	SEC_CONTENT
principles	SEC_CONTENT
and	SEC_CONTENT
empower	SEC_CONTENT
more	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
