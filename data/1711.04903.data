title	SECTITLE_END
Robust	SEC_START
Multilingual	SEC_CONTENT
Part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
Speech	SEC_CONTENT
Tagging	SEC_CONTENT
via	SEC_CONTENT
Adversarial	SEC_CONTENT
Training	SEC_END
abstract	SECTITLE_END
Adversarial	SEC_START
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
1	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
powerful	SEC_CONTENT
reg	SEC_CONTENT
-	SEC_CONTENT
ularization	SEC_CONTENT
method	SEC_CONTENT
for	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
,	SEC_CONTENT
aiming	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
robustness	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	SEC_CONTENT
.	SEC_CONTENT
Yet	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
specific	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
robust	SEC_CONTENT
-	SEC_CONTENT
ness	SEC_CONTENT
obtained	SEC_CONTENT
from	SEC_CONTENT
AT	SEC_CONTENT
are	SEC_CONTENT
still	SEC_CONTENT
unclear	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
and	SEC_CONTENT
analyze	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
exploits	SEC_CONTENT
AT	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
WSJ	dataset
corpus	dataset
and	SEC_CONTENT
the	SEC_CONTENT
Universal	SEC_CONTENT
Dependencies	SEC_CONTENT
(	SEC_CONTENT
UD	dataset
)	SEC_CONTENT
dataset	SEC_CONTENT
(	SEC_CONTENT
27	SEC_CONTENT
languages	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
improves	SEC_CONTENT
the	metric
overall	metric
tagging	metric
accuracy	metric
,	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
prevents	SEC_CONTENT
over	SEC_CONTENT
-	SEC_CONTENT
fitting	SEC_CONTENT
well	SEC_CONTENT
in	SEC_CONTENT
low	SEC_CONTENT
resource	SEC_CONTENT
languages	SEC_CONTENT
and	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
boosts	SEC_CONTENT
tagging	metric
accuracy	metric
for	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
improved	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
AT	SEC_CONTENT
contributes	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
downstream	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
that	SEC_CONTENT
4	SEC_CONTENT
)	SEC_CONTENT
AT	SEC_CONTENT
helps	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
cleaner	SEC_CONTENT
word	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
The	SEC_CONTENT
proposed	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
effective	SEC_CONTENT
in	SEC_CONTENT
different	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
positive	SEC_CONTENT
results	SEC_CONTENT
motivate	SEC_CONTENT
further	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
for	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Recently	SEC_START
,	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approaches	SEC_CONTENT
have	SEC_CONTENT
become	SEC_CONTENT
popular	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
(	SEC_CONTENT
NLP	SEC_CONTENT
)	SEC_CONTENT
tasks	SEC_CONTENT
including	SEC_CONTENT
tagging	SEC_CONTENT
,	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
translation	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
tend	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
locally	SEC_CONTENT
unstable	SEC_CONTENT
and	SEC_CONTENT
even	SEC_CONTENT
tiny	SEC_CONTENT
perturbations	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
inputs	SEC_CONTENT
can	SEC_CONTENT
mislead	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Such	SEC_CONTENT
maliciously	SEC_CONTENT
perturbed	SEC_CONTENT
inputs	SEC_CONTENT
are	SEC_CONTENT
called	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
Adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
aims	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	SEC_CONTENT
by	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
unmodified	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
Previous	SEC_CONTENT
work	SEC_CONTENT
(	SEC_CONTENT
Goodfellow	SEC_CONTENT
We	SEC_CONTENT
distinguish	SEC_CONTENT
AT	SEC_CONTENT
from	SEC_CONTENT
Generative	SEC_CONTENT
Adversarial	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
GANs	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Figure	SEC_START
1	SEC_CONTENT
:	SEC_CONTENT
Illustration	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
architecture	SEC_CONTENT
for	SEC_CONTENT
adversarial	task
POS	task
tagging	task
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
input	SEC_CONTENT
the	SEC_CONTENT
normalized	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
showing	SEC_CONTENT
c	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
3	SEC_CONTENT
for	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
word	SEC_CONTENT
is	SEC_CONTENT
represented	SEC_CONTENT
by	SEC_CONTENT
concatenating	SEC_CONTENT
its	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
output	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
are	SEC_CONTENT
fed	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
network	SEC_CONTENT
for	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
and	SEC_CONTENT
add	SEC_CONTENT
the	SEC_CONTENT
worst	SEC_CONTENT
-	SEC_CONTENT
case	SEC_CONTENT
perturbation	SEC_CONTENT
η	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
regularization	SEC_CONTENT
.	SEC_END
et	SEC_START
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
image	SEC_CONTENT
recognition	SEC_CONTENT
has	SEC_CONTENT
demonstrated	SEC_CONTENT
the	SEC_CONTENT
enhanced	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
their	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
unseen	SEC_CONTENT
images	SEC_CONTENT
via	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
provided	SEC_CONTENT
theoretical	SEC_CONTENT
explanations	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
effects	SEC_CONTENT
.	SEC_END
Despite	SEC_START
its	SEC_CONTENT
potential	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
powerful	SEC_CONTENT
regularizer	SEC_CONTENT
,	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
yet	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
explored	SEC_CONTENT
extensively	SEC_CONTENT
in	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Recently	SEC_CONTENT
,	SEC_CONTENT
applied	SEC_CONTENT
AT	SEC_CONTENT
on	SEC_CONTENT
text	SEC_CONTENT
classification	SEC_CONTENT
,	SEC_CONTENT
achieving	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
accuracy	SEC_CONTENT
.	SEC_CONTENT
Yet	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
specific	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
obtained	SEC_CONTENT
from	SEC_CONTENT
AT	SEC_CONTENT
are	SEC_CONTENT
still	SEC_CONTENT
unclear	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
research	SEC_CONTENT
studies	SEC_CONTENT
have	SEC_CONTENT
yet	SEC_CONTENT
to	SEC_CONTENT
answer	SEC_CONTENT
questions	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
how	SEC_CONTENT
can	SEC_CONTENT
we	SEC_CONTENT
interpret	SEC_CONTENT
perturbations	dataset
or	SEC_CONTENT
robustness	SEC_CONTENT
on	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inputs	SEC_CONTENT
?	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
how	SEC_CONTENT
are	SEC_CONTENT
they	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
linguistic	SEC_CONTENT
factors	SEC_CONTENT
like	SEC_CONTENT
vocabulary	SEC_CONTENT
statistics	SEC_CONTENT
?	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
language	SEC_CONTENT
-	SEC_CONTENT
dependent	SEC_CONTENT
?	SEC_CONTENT
Answering	SEC_CONTENT
such	SEC_CONTENT
questions	SEC_CONTENT
is	SEC_CONTENT
crucial	SEC_CONTENT
to	SEC_CONTENT
understand	SEC_CONTENT
and	SEC_CONTENT
motivate	SEC_CONTENT
the	SEC_CONTENT
application	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
spotlighting	SEC_CONTENT
a	SEC_CONTENT
well	SEC_CONTENT
-	SEC_CONTENT
studied	SEC_CONTENT
core	SEC_CONTENT
problem	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
and	SEC_CONTENT
carefully	SEC_CONTENT
analyze	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
(	SEC_CONTENT
POS	SEC_CONTENT
)	SEC_CONTENT
tagging	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
exploits	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
a	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
model	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
by	SEC_CONTENT
considering	SEC_CONTENT
perturbations	dataset
to	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
demystify	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
multiple	SEC_CONTENT
languages	SEC_CONTENT
using	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
WSJ	dataset
corpus	dataset
(	SEC_CONTENT
Englsih	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
Universal	SEC_CONTENT
Dependencies	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
thorough	SEC_CONTENT
analyses	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
points	SEC_CONTENT
:	SEC_END
•	SEC_START
Effects	SECTITLE_START
on	SECTITLE_CONTENT
different	SECTITLE_CONTENT
target	SECTITLE_CONTENT
languages	SECTITLE_CONTENT
•	SECTITLE_CONTENT
Vocabulary	SECTITLE_CONTENT
statistics	SECTITLE_CONTENT
and	SECTITLE_CONTENT
tagging	SECTITLE_CONTENT
accuracy	SECTITLE_CONTENT
•	SECTITLE_CONTENT
Influence	SECTITLE_CONTENT
on	SECTITLE_CONTENT
downstream	SECTITLE_CONTENT
tasks	SECTITLE_CONTENT
•	SECTITLE_CONTENT
Representation	SECTITLE_CONTENT
learning	SECTITLE_CONTENT
of	SECTITLE_CONTENT
words	SECTITLE_END
In	SEC_START
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
model	SEC_CONTENT
consistently	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
even	SEC_CONTENT
achieves	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
22	SEC_CONTENT
languages	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
analyses	SEC_CONTENT
reveal	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
insights	SEC_CONTENT
into	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
:	SEC_END
•	SEC_START
The	SEC_CONTENT
regularization	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
general	SEC_CONTENT
across	SEC_CONTENT
different	SEC_CONTENT
languages	SEC_CONTENT
.	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
prevent	SEC_CONTENT
overfitting	SEC_CONTENT
especially	SEC_CONTENT
well	SEC_CONTENT
when	SEC_CONTENT
training	SEC_CONTENT
examples	SEC_CONTENT
are	SEC_CONTENT
scarce	SEC_CONTENT
,	SEC_CONTENT
providing	SEC_CONTENT
an	SEC_CONTENT
effective	SEC_CONTENT
tool	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
low	SEC_CONTENT
resource	SEC_CONTENT
languages	SEC_CONTENT
.	SEC_END
•	SEC_START
AT	SEC_CONTENT
can	SEC_CONTENT
boost	SEC_CONTENT
the	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
for	SEC_CONTENT
rare/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
increase	SEC_CONTENT
the	metric
sentence	metric
-	metric
level	metric
accuracy	metric
.	SEC_CONTENT
This	SEC_CONTENT
positively	SEC_CONTENT
affects	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
down	SEC_CONTENT
-	SEC_CONTENT
stream	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
low	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
POS	SEC_CONTENT
accuracy	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
bottleneck	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
•	SEC_START
AT	SEC_CONTENT
helps	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
learn	SEC_CONTENT
cleaner	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
showing	SEC_CONTENT
stronger	SEC_CONTENT
correlations	SEC_CONTENT
with	SEC_CONTENT
their	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
.	SEC_END
We	SEC_START
argue	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
interpreted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
perspective	SEC_CONTENT
of	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
effective	SEC_CONTENT
across	SEC_CONTENT
different	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
work	SEC_CONTENT
therefore	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
motivation	SEC_CONTENT
and	SEC_CONTENT
basis	SEC_CONTENT
for	SEC_CONTENT
utilizing	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
in	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
POS	SECTITLE_START
Tagging	SECTITLE_END
Part	SEC_START
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
(	SEC_CONTENT
POS	SEC_CONTENT
)	SEC_CONTENT
tagging	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
fundamental	SEC_CONTENT
NLP	SEC_CONTENT
task	SEC_CONTENT
that	SEC_CONTENT
facilitates	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
syntactic	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
theart	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
yield	SEC_CONTENT
accuracy	metric
over	SEC_CONTENT
97.5	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
WSJ	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
still	SEC_CONTENT
remain	SEC_CONTENT
issues	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
per	SEC_CONTENT
token	SEC_CONTENT
accuracy	SEC_CONTENT
metric	SEC_CONTENT
is	SEC_CONTENT
easy	SEC_CONTENT
since	SEC_CONTENT
taggers	SEC_CONTENT
can	SEC_CONTENT
easily	SEC_CONTENT
assign	SEC_CONTENT
correct	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
to	SEC_CONTENT
highly	SEC_CONTENT
unambiguous	SEC_CONTENT
tokens	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
punctuation	SEC_CONTENT
.	SEC_CONTENT
Sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
accuracy	SEC_CONTENT
serves	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
realistic	SEC_CONTENT
metric	SEC_CONTENT
for	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
but	SEC_CONTENT
it	SEC_CONTENT
still	SEC_CONTENT
remains	SEC_CONTENT
low	SEC_CONTENT
.	SEC_CONTENT
Another	SEC_CONTENT
problem	SEC_CONTENT
with	SEC_CONTENT
current	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
their	SEC_CONTENT
accuracy	SEC_CONTENT
deteriorates	SEC_CONTENT
drastically	SEC_CONTENT
on	SEC_CONTENT
low	SEC_CONTENT
resource	SEC_CONTENT
languages	SEC_CONTENT
and	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
mitigate	SEC_CONTENT
these	SEC_CONTENT
issues	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
empirically	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
can	SEC_CONTENT
greatly	SEC_CONTENT
affect	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
improvements	SEC_CONTENT
obtained	SEC_CONTENT
from	SEC_CONTENT
our	SEC_CONTENT
AT	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
actually	SEC_CONTENT
contribute	SEC_CONTENT
to	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_CONTENT
Nonetheless	SEC_CONTENT
,	SEC_CONTENT
parsing	SEC_CONTENT
with	SEC_CONTENT
gold	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
still	SEC_CONTENT
yields	SEC_CONTENT
better	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
bolstering	SEC_CONTENT
the	SEC_CONTENT
view	SEC_CONTENT
that	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
essential	SEC_CONTENT
task	SEC_CONTENT
in	SEC_CONTENT
NLP	SEC_CONTENT
that	SEC_CONTENT
needs	SEC_CONTENT
further	SEC_CONTENT
development	SEC_CONTENT
.	SEC_END
Adversarial	SECTITLE_START
Training	SECTITLE_END
The	SEC_START
concept	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
was	SEC_CONTENT
originally	SEC_CONTENT
introduced	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
image	SEC_CONTENT
classification	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
by	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
input	SEC_CONTENT
images	SEC_CONTENT
with	SEC_CONTENT
malicious	SEC_CONTENT
perturbations	SEC_CONTENT
.	SEC_CONTENT
Previous	SEC_CONTENT
work	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
provided	SEC_CONTENT
a	SEC_CONTENT
theoretical	SEC_CONTENT
framework	SEC_CONTENT
to	SEC_CONTENT
understand	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
image	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_END
Recently	SEC_START
,	SEC_CONTENT
applied	SEC_CONTENT
AT	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
text	SEC_CONTENT
classification	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
extending	SEC_CONTENT
the	SEC_CONTENT
concept	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
perturbations	SEC_CONTENT
to	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
further	SEC_CONTENT
explored	SEC_CONTENT
the	SEC_CONTENT
possibility	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
in	SEC_CONTENT
relation	SEC_CONTENT
extraction	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
report	SEC_CONTENT
improved	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
their	SEC_CONTENT
tasks	SEC_CONTENT
via	SEC_CONTENT
AT	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
the	SEC_CONTENT
specific	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
have	SEC_CONTENT
yet	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
analyzed	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
address	SEC_CONTENT
this	SEC_CONTENT
issue	SEC_CONTENT
by	SEC_CONTENT
providing	SEC_CONTENT
detailed	SEC_CONTENT
analyses	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
perspective	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
different	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
vocabulary	SEC_CONTENT
statistics	SEC_CONTENT
,	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
motivate	SEC_CONTENT
future	SEC_CONTENT
research	SEC_CONTENT
that	SEC_CONTENT
exploits	SEC_CONTENT
AT	SEC_CONTENT
in	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
AT	SEC_START
is	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
regularization	SEC_CONTENT
methods	SEC_CONTENT
that	SEC_CONTENT
add	SEC_CONTENT
noise	SEC_CONTENT
to	SEC_CONTENT
data	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
variant	SEC_CONTENT
for	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
word	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
discuss	SEC_CONTENT
various	SEC_CONTENT
data	SEC_CONTENT
noising	SEC_CONTENT
techniques	SEC_CONTENT
for	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
these	SEC_CONTENT
methods	SEC_CONTENT
produce	SEC_CONTENT
random	SEC_CONTENT
noise	SEC_CONTENT
,	SEC_CONTENT
AT	SEC_CONTENT
generates	SEC_CONTENT
perturbations	dataset
that	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
particularly	SEC_CONTENT
vulnerable	SEC_CONTENT
to	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
thus	SEC_CONTENT
is	SEC_CONTENT
claimed	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
It	SEC_START
should	SEC_CONTENT
be	SEC_CONTENT
noted	SEC_CONTENT
that	SEC_CONTENT
while	SEC_CONTENT
related	SEC_CONTENT
in	SEC_CONTENT
name	SEC_CONTENT
,	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
differs	SEC_CONTENT
from	SEC_CONTENT
Generative	SEC_CONTENT
Adversarial	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
GANs	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
GANs	SEC_CONTENT
have	SEC_CONTENT
already	SEC_CONTENT
been	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
dialogue	SEC_CONTENT
generation	SEC_CONTENT
(	SEC_CONTENT
 	SEC_CONTENT
and	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Adversarial	SEC_CONTENT
training	SEC_CONTENT
also	SEC_CONTENT
differs	SEC_CONTENT
from	SEC_CONTENT
adversarial	SEC_CONTENT
evaluation	SEC_CONTENT
,	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
for	SEC_CONTENT
reading	SEC_CONTENT
comprehension	SEC_CONTENT
tasks	SEC_CONTENT
(	SEC_CONTENT
Jia	SEC_CONTENT
and	SEC_CONTENT
Liang	SEC_CONTENT
,	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Method	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
introduce	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
explain	SEC_CONTENT
how	SEC_CONTENT
we	SEC_CONTENT
implement	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
.	SEC_END
Baseline	SECTITLE_START
POS	SECTITLE_CONTENT
Tagging	SECTITLE_CONTENT
Model	SECTITLE_END
Following	SEC_START
the	SEC_CONTENT
recent	SEC_CONTENT
top	SEC_CONTENT
-	SEC_CONTENT
performing	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
a	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
directional	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
model	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
illustration	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Character	SEC_START
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
.	SEC_CONTENT
Prior	SEC_CONTENT
work	SEC_CONTENT
has	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
incorporating	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
representations	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
can	SEC_CONTENT
boost	SEC_CONTENT
POS	task
tagging	task
accuracy	task
by	SEC_CONTENT
capturing	SEC_CONTENT
morphological	SEC_CONTENT
information	SEC_CONTENT
present	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
language	SEC_CONTENT
.	SEC_CONTENT
Major	SEC_CONTENT
neural	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
models	SEC_CONTENT
include	SEC_CONTENT
the	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
CNN	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
Bi)LSTM	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
directional	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
BiLSTM	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
processes	SEC_CONTENT
each	SEC_CONTENT
sequence	SEC_CONTENT
both	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
sequential	SEC_CONTENT
information	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
preventing	SEC_CONTENT
the	SEC_CONTENT
vanishing	SEC_CONTENT
/	SEC_CONTENT
exploding	SEC_CONTENT
gradient	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
observed	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
CNN	SEC_CONTENT
by	SEC_CONTENT
0.1	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
WSJ	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
hence	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
a	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
representation	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
by	SEC_CONTENT
feeding	SEC_CONTENT
its	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
BiLSTM	SEC_CONTENT
and	SEC_CONTENT
obtaining	SEC_CONTENT
the	SEC_CONTENT
concatenated	SEC_CONTENT
final	SEC_CONTENT
states	SEC_CONTENT
.	SEC_END
Word	SEC_START
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
is	SEC_CONTENT
represented	SEC_CONTENT
by	SEC_CONTENT
concatenating	SEC_CONTENT
its	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
are	SEC_CONTENT
fed	SEC_CONTENT
into	SEC_CONTENT
another	SEC_CONTENT
level	SEC_CONTENT
of	SEC_CONTENT
BiLSTM	SEC_CONTENT
(	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
CRF	SEC_START
.	SEC_CONTENT
In	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
beneficial	SEC_CONTENT
to	SEC_CONTENT
consider	SEC_CONTENT
the	SEC_CONTENT
correlations	SEC_CONTENT
between	SEC_CONTENT
neighboring	SEC_CONTENT
labels	SEC_CONTENT
and	SEC_CONTENT
jointly	SEC_CONTENT
decode	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
chain	SEC_CONTENT
of	SEC_CONTENT
labels	SEC_CONTENT
fora	SEC_CONTENT
given	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
this	SEC_CONTENT
motivation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
a	SEC_CONTENT
conditional	SEC_CONTENT
random	SEC_CONTENT
field	SEC_CONTENT
(	SEC_CONTENT
CRF	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
POS	SEC_CONTENT
tag	SEC_CONTENT
inference	SEC_CONTENT
with	SEC_CONTENT
global	SEC_CONTENT
normalization	SEC_CONTENT
,	SEC_CONTENT
addressing	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
label	SEC_CONTENT
bias	SEC_CONTENT
"	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
pass	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
BiLSTM	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
firstorder	SEC_CONTENT
chain	SEC_CONTENT
CRF	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
label	SEC_CONTENT
sequence	SEC_CONTENT
:	SEC_END
where	SEC_START
θ	SEC_CONTENT
represents	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
parameters	SEC_CONTENT
(	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
BiLSTMs	SEC_CONTENT
and	SEC_CONTENT
CRF	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
sand	SEC_CONTENT
y	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
POS	SEC_CONTENT
tag	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
given	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
For	SEC_START
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
minimize	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
loglikelihood	SEC_CONTENT
(	SEC_CONTENT
loss	SEC_CONTENT
function	SEC_CONTENT
)	SEC_END
with	SEC_START
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
Decoding	SEC_CONTENT
searches	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tag	SEC_CONTENT
sequence	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
Viterbi	SEC_CONTENT
algorithm	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
more	SEC_CONTENT
detail	SEC_CONTENT
about	SEC_CONTENT
the	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
formulation	SEC_CONTENT
,	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
Ma	SEC_CONTENT
and	SEC_CONTENT
Hovy	SEC_CONTENT
(	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Adversarial	SECTITLE_START
Training	SECTITLE_END
Adversarial	SEC_START
training	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
powerful	SEC_CONTENT
regularization	SEC_CONTENT
method	SEC_CONTENT
,	SEC_CONTENT
primarily	SEC_CONTENT
explored	SEC_CONTENT
in	SEC_CONTENT
image	SEC_CONTENT
recognition	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
classifiers	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
classifier	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
generate	SEC_CONTENT
input	SEC_CONTENT
examples	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
very	SEC_CONTENT
close	SEC_CONTENT
to	SEC_CONTENT
original	SEC_CONTENT
inputs	SEC_CONTENT
(	SEC_CONTENT
so	SEC_CONTENT
should	SEC_CONTENT
yield	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
labels	SEC_CONTENT
)	SEC_CONTENT
yet	SEC_CONTENT
are	SEC_CONTENT
likely	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
misclassified	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
are	SEC_CONTENT
generated	SEC_CONTENT
by	SEC_CONTENT
adding	SEC_CONTENT
small	SEC_CONTENT
perturbations	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
direction	SEC_CONTENT
that	SEC_CONTENT
significantly	SEC_CONTENT
increases	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
classifier	SEC_CONTENT
(	SEC_CONTENT
worstcase	SEC_CONTENT
perturbations	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
classifier	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
mixture	SEC_CONTENT
of	SEC_CONTENT
clean	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
stability	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
incorporate	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
into	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
,	SEC_CONTENT
aiming	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
better	SEC_CONTENT
regularization	SEC_CONTENT
effects	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
provide	SEC_CONTENT
their	SEC_CONTENT
interpretations	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
.	SEC_END
Generating	SEC_START
adversarial	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
Adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
considers	SEC_CONTENT
continuous	SEC_CONTENT
perturbations	SEC_CONTENT
to	SEC_CONTENT
inputs	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
we	SEC_CONTENT
define	SEC_CONTENT
perturbations	dataset
at	SEC_CONTENT
the	SEC_CONTENT
level	SEC_CONTENT
of	SEC_CONTENT
dense	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
hot	SEC_CONTENT
vector	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
similarly	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
:	SEC_END
To	SEC_START
prepare	SEC_CONTENT
an	SEC_CONTENT
adversarial	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
worst	SEC_CONTENT
-	SEC_CONTENT
case	SEC_CONTENT
perturbation	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
bounded	SEC_CONTENT
norm	SEC_CONTENT
that	SEC_CONTENT
maximizes	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
function	SEC_CONTENT
L	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
model	SEC_CONTENT
:	SEC_END
wherê	SEC_START
θ	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
parameters	SEC_CONTENT
,	SEC_CONTENT
treated	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
constant	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
y	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
the	SEC_CONTENT
exact	SEC_CONTENT
computation	SEC_CONTENT
of	SEC_CONTENT
such	SEC_CONTENT
η	SEC_CONTENT
is	SEC_CONTENT
intractable	SEC_CONTENT
in	SEC_CONTENT
complex	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
the	SEC_CONTENT
Fast	SEC_CONTENT
Gradient	SEC_CONTENT
Method	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
first	SEC_CONTENT
order	SEC_CONTENT
approximation	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
an	SEC_CONTENT
approximate	SEC_CONTENT
worst	SEC_CONTENT
-	SEC_CONTENT
case	SEC_CONTENT
perturbation	SEC_CONTENT
of	SEC_CONTENT
norm	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
gradient	SEC_CONTENT
computation	SEC_CONTENT
:	SEC_END
is	SEC_START
a	SEC_CONTENT
hyperparameter	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
determined	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
perturbation	SEC_CONTENT
η	SEC_CONTENT
is	SEC_CONTENT
generated	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
direction	SEC_CONTENT
that	SEC_CONTENT
significantly	SEC_CONTENT
increases	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
L.	SEC_CONTENT
We	SEC_CONTENT
find	SEC_CONTENT
such	SEC_CONTENT
η	SEC_CONTENT
against	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
model	SEC_CONTENT
parameterized	SEC_CONTENT
byˆθbyˆ	SEC_CONTENT
byˆθ	SEC_CONTENT
,	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
training	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
construct	SEC_CONTENT
an	SEC_CONTENT
adversarial	SEC_CONTENT
example	SEC_CONTENT
by	SEC_CONTENT
s	SEC_CONTENT
adv	SEC_CONTENT
=	SEC_CONTENT
s	SEC_CONTENT
+	SEC_CONTENT
η	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
restrict	SEC_CONTENT
the	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
could	SEC_CONTENT
trivially	SEC_CONTENT
learn	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
large	SEC_CONTENT
norms	SEC_CONTENT
to	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
perturbations	SEC_CONTENT
insignificant	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
prevent	SEC_CONTENT
this	SEC_CONTENT
issue	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
normalize	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
they	SEC_CONTENT
have	SEC_CONTENT
mean	SEC_CONTENT
0	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
1	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
entry	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
normalization	SEC_CONTENT
is	SEC_CONTENT
performed	SEC_CONTENT
every	SEC_CONTENT
time	SEC_CONTENT
we	SEC_CONTENT
feed	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
LSTMs	SEC_CONTENT
and	SEC_CONTENT
generate	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
ensure	SEC_CONTENT
a	SEC_CONTENT
fair	SEC_CONTENT
comparison	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
normalize	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
While	SEC_START
set	SEC_CONTENT
the	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
a	dataset
perturbation	dataset
(	SEC_CONTENT
Eq	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
value	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
input	SEC_CONTENT
sentences	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
entire	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
length	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
include	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
besides	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
perturbation	SEC_CONTENT
size	SEC_CONTENT
adaptive	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
dimension	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
concatenated	SEC_CONTENT
input	SEC_CONTENT
embedding	SEC_CONTENT
s	SEC_CONTENT
∈	SEC_CONTENT
RD	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
α	SEC_END
,	SEC_START
as	SEC_CONTENT
the	SEC_CONTENT
expected	SEC_CONTENT
squared	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
s	SEC_CONTENT
after	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
normalization	SEC_CONTENT
is	SEC_CONTENT
D.	SEC_CONTENT
The	SEC_CONTENT
scaling	SEC_CONTENT
factor	SEC_CONTENT
α	SEC_CONTENT
is	SEC_CONTENT
selected	SEC_CONTENT
from	SEC_CONTENT
{	SEC_CONTENT
0.001	SEC_CONTENT
,	SEC_CONTENT
0.005	SEC_CONTENT
,	SEC_CONTENT
0.01	SEC_CONTENT
,	SEC_CONTENT
0.05	SEC_CONTENT
,	SEC_CONTENT
0.1	SEC_CONTENT
}	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
performance	SEC_CONTENT
in	SEC_CONTENT
each	dataset
treebank	dataset
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
0.01	SEC_CONTENT
for	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
WSJ	SEC_CONTENT
and	SEC_CONTENT
UD	SEC_CONTENT
-	SEC_CONTENT
Spanish	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
0.05	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
rest	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
0	SEC_CONTENT
would	SEC_CONTENT
generate	SEC_CONTENT
no	SEC_CONTENT
noise	SEC_CONTENT
(	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
if	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
generated	SEC_CONTENT
adversarial	SEC_CONTENT
perturbation	SEC_CONTENT
would	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
norm	SEC_CONTENT
comparable	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
embedding	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
could	SEC_CONTENT
change	SEC_CONTENT
the	SEC_CONTENT
semantics	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Hence	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
optimal	SEC_CONTENT
perturbation	SEC_CONTENT
scale	SEC_CONTENT
α	SEC_CONTENT
should	SEC_CONTENT
lie	SEC_CONTENT
in	SEC_CONTENT
between	SEC_CONTENT
and	SEC_CONTENT
be	SEC_CONTENT
small	SEC_CONTENT
enough	SEC_CONTENT
to	SEC_CONTENT
preserve	SEC_CONTENT
the	SEC_CONTENT
semantics	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
input	SEC_CONTENT
.	SEC_END
Adversarial	SEC_START
training	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
each	SEC_CONTENT
training	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
against	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
mixture	SEC_CONTENT
of	SEC_CONTENT
clean	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
robustness	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
this	SEC_CONTENT
end	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
define	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
function	SEC_CONTENT
for	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
as	SEC_CONTENT
:	SEC_END
where	SEC_START
L(θ	SEC_CONTENT
;	SEC_CONTENT
s	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
L(θ	SEC_CONTENT
;	SEC_CONTENT
s	SEC_CONTENT
adv	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
)	SEC_CONTENT
represent	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
clean	SEC_CONTENT
example	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
from	SEC_CONTENT
its	SEC_CONTENT
adversarial	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
γ	SEC_CONTENT
determines	SEC_CONTENT
the	SEC_CONTENT
weighting	SEC_CONTENT
between	SEC_CONTENT
them	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
γ	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
optimized	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
parameters	SEC_CONTENT
θ	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
manner	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
To	SEC_START
fully	SEC_CONTENT
analyze	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
and	SEC_CONTENT
evaluate	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
/	SEC_CONTENT
adversarial	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
English	SEC_CONTENT
dataset	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
multilingual	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
Datasets	SECTITLE_END
As	SEC_START
a	SEC_CONTENT
standard	SEC_CONTENT
English	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
Wall	SEC_CONTENT
Street	SEC_CONTENT
Journal	SEC_CONTENT
(	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
portion	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
(	SEC_CONTENT
PTB	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
containing	SEC_CONTENT
45	SEC_CONTENT
different	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
adopt	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
split	SEC_CONTENT
:	SEC_CONTENT
sections	SEC_CONTENT
0	SEC_CONTENT
-	SEC_CONTENT
18	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
19	SEC_CONTENT
-	SEC_CONTENT
21	SEC_CONTENT
for	SEC_CONTENT
development	SEC_CONTENT
and	SEC_CONTENT
22	SEC_CONTENT
-	SEC_CONTENT
24	SEC_CONTENT
for	SEC_CONTENT
testing	SEC_CONTENT
97.29	SEC_CONTENT
97.50	SEC_CONTENT
97.78	SEC_CONTENT
97.55	SEC_CONTENT
97.55	SEC_CONTENT
97.55	SEC_CONTENT
Ours	SEC_CONTENT
-Baseline	SEC_CONTENT
97.54	SEC_CONTENT
Ours	SEC_CONTENT
-Adversarial	SEC_CONTENT
97.58	SEC_CONTENT
Optimization	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
parameters	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
character	SEC_CONTENT
embeddings	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
(	SEC_CONTENT
SGD	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
10	SEC_CONTENT
,	SEC_CONTENT
momentum	SEC_CONTENT
0.9	SEC_CONTENT
,	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
0.01	SEC_CONTENT
and	SEC_CONTENT
decay	SEC_CONTENT
rate	SEC_CONTENT
0.05	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
gradient	SEC_CONTENT
clipping	SEC_CONTENT
of	SEC_CONTENT
5.0	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
early	SEC_CONTENT
stopping	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
Evaluation	SEC_START
.	SEC_CONTENT
We	SEC_CONTENT
evaluate	SEC_CONTENT
per	SEC_CONTENT
token	metric
tagging	metric
accuracy	metric
on	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
repeat	SEC_CONTENT
the	SEC_CONTENT
experiment	SEC_CONTENT
three	SEC_CONTENT
times	SEC_CONTENT
and	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
statistical	SEC_CONTENT
significance	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
PTB	SEC_START
-	SEC_CONTENT
WSJ	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
expected	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
(	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
)	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
accuracy	metric
97.54	SEC_CONTENT
%	SEC_CONTENT
)	SEC_CONTENT
performs	SEC_CONTENT
on	SEC_CONTENT
par	SEC_CONTENT
with	SEC_CONTENT
other	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
Built	SEC_CONTENT
upon	SEC_CONTENT
this	SEC_CONTENT
baseline	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
model	SEC_CONTENT
reaches	SEC_CONTENT
accuracy	SEC_CONTENT
97.58	SEC_CONTENT
%	SEC_CONTENT
thanks	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
regularization	SEC_CONTENT
power	SEC_CONTENT
,	SEC_CONTENT
outperforming	SEC_CONTENT
recent	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
except	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
improvement	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
is	SEC_CONTENT
statistically	SEC_CONTENT
significant	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
p	SEC_CONTENT
-	SEC_CONTENT
value	SEC_CONTENT
<	SEC_CONTENT
0.05	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
t	SEC_CONTENT
-	SEC_CONTENT
test	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
provide	SEC_CONTENT
additional	SEC_CONTENT
analysis	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
result	SEC_CONTENT
in	SEC_CONTENT
later	SEC_CONTENT
sections	SEC_CONTENT
.	SEC_CONTENT
     	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
rarity	SEC_CONTENT
maybe	SEC_CONTENT
of	SEC_CONTENT
particular	SEC_CONTENT
help	SEC_CONTENT
in	SEC_CONTENT
processing	SEC_CONTENT
morphologically	SEC_CONTENT
complex	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
notably	SEC_CONTENT
large	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
in	SEC_CONTENT
resource	SEC_CONTENT
-	SEC_CONTENT
poor	SEC_CONTENT
languages	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
bottom	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
average	SEC_CONTENT
improvement	SEC_CONTENT
0.35	SEC_CONTENT
%	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
that	SEC_CONTENT
for	SEC_CONTENT
resource	SEC_CONTENT
-	SEC_CONTENT
rich	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
0.20	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
further	SEC_CONTENT
visualize	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
effects	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
curves	SEC_CONTENT
for	SEC_CONTENT
three	SEC_CONTENT
representative	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
English	SEC_CONTENT
(	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
French	SEC_CONTENT
(	SEC_CONTENT
UD	SEC_CONTENT
-	SEC_CONTENT
fr	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
Romanian	SEC_CONTENT
(	SEC_CONTENT
UD	SEC_CONTENT
-	SEC_CONTENT
ro	SEC_CONTENT
,	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
resource	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
loss	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
three	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
red	SEC_CONTENT
solid	SEC_CONTENT
line	SEC_CONTENT
)	SEC_CONTENT
prevents	SEC_CONTENT
overfitting	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
(	SEC_CONTENT
black	SEC_CONTENT
dotted	SEC_CONTENT
line	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
advantage	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
significant	SEC_CONTENT
in	SEC_CONTENT
low	SEC_CONTENT
resource	SEC_CONTENT
languages	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
Romanian	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
model	SEC_CONTENT
starts	SEC_CONTENT
to	SEC_CONTENT
increase	SEC_CONTENT
development	SEC_CONTENT
loss	SEC_CONTENT
after	SEC_CONTENT
1,000	SEC_CONTENT
iterations	SEC_CONTENT
even	SEC_CONTENT
with	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
whereas	SEC_CONTENT
the	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
keeps	SEC_CONTENT
improving	SEC_CONTENT
until	SEC_CONTENT
2,500	SEC_CONTENT
iterations	SEC_CONTENT
,	SEC_CONTENT
achieving	SEC_CONTENT
notably	SEC_CONTENT
lower	SEC_CONTENT
development	SEC_CONTENT
loss	SEC_CONTENT
(	SEC_CONTENT
0.4	SEC_CONTENT
down	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
results	SEC_CONTENT
illustrate	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
prevent	SEC_CONTENT
overfitting	SEC_CONTENT
especially	SEC_CONTENT
well	SEC_CONTENT
on	SEC_CONTENT
small	SEC_CONTENT
datasets	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
augment	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
power	SEC_CONTENT
beyond	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
effective	SEC_CONTENT
means	SEC_CONTENT
of	SEC_CONTENT
data	SEC_CONTENT
augmenta-	SEC_CONTENT
 	SEC_CONTENT
tion	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
with	SEC_CONTENT
new	SEC_CONTENT
examples	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
particularly	SEC_CONTENT
vulnerable	SEC_CONTENT
to	SEC_CONTENT
at	SEC_CONTENT
every	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
enhancing	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
therefore	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
promising	SEC_CONTENT
tool	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
low	SEC_CONTENT
resource	SEC_CONTENT
languages	SEC_CONTENT
.	SEC_END
Our	SECTITLE_START
Models	SECTITLE_END
Analysis	SECTITLE_END
In	SEC_START
the	SEC_CONTENT
previous	SEC_CONTENT
sections	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
demonstrated	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
different	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
overall	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
and	SEC_CONTENT
learning	SEC_CONTENT
curves	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
further	SEC_CONTENT
analyses	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
from	SEC_CONTENT
NLP	SEC_CONTENT
specific	SEC_CONTENT
aspects	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word	SEC_CONTENT
statistics	SEC_CONTENT
,	SEC_CONTENT
sequence	SEC_CONTENT
modeling	SEC_CONTENT
,	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
boost	SEC_CONTENT
tagging	metric
accuracy	metric
on	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
neighbors	SEC_CONTENT
of	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
§	SEC_CONTENT
5.1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
robustness	SEC_CONTENT
against	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
leads	SEC_CONTENT
to	SEC_CONTENT
better	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
accuracy	SEC_CONTENT
and	SEC_CONTENT
downstream	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
(	SEC_CONTENT
§	SEC_CONTENT
5.2	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
illustrate	SEC_CONTENT
these	SEC_CONTENT
findings	SEC_CONTENT
using	SEC_CONTENT
two	SEC_CONTENT
major	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
English	SEC_CONTENT
(	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
French	SEC_CONTENT
(	SEC_CONTENT
UD	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
have	SEC_CONTENT
substantially	SEC_CONTENT
large	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
testing	SEC_CONTENT
data	SEC_CONTENT
to	SEC_CONTENT
discuss	SEC_CONTENT
vocabulary	SEC_CONTENT
statistics	SEC_CONTENT
and	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
study	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
§	SEC_CONTENT
5.3	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
applicability	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
to	SEC_CONTENT
different	SEC_CONTENT
sequential	SEC_CONTENT
tasks	SEC_CONTENT
(	SEC_CONTENT
§	SEC_CONTENT
5.4	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Word	SECTITLE_START
-	SECTITLE_CONTENT
level	SECTITLE_CONTENT
Analysis	SECTITLE_END
Poor	SEC_START
tagging	metric
accuracy	metric
on	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
is	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
bottlenecks	SEC_CONTENT
in	SEC_CONTENT
current	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
.	SEC_CONTENT
Aiming	SEC_CONTENT
to	SEC_CONTENT
reveal	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
on	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
analyze	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
level	SEC_CONTENT
,	SEC_CONTENT
considering	SEC_CONTENT
vocabulary	SEC_CONTENT
statistics	SEC_CONTENT
.	SEC_END
Word	SEC_START
frequency	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
define	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
's	SEC_CONTENT
frequency	SEC_CONTENT
of	SEC_CONTENT
occurrence	metric
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
categorize	SEC_CONTENT
all	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
frequency	SEC_CONTENT
and	SEC_CONTENT
study	SEC_CONTENT
the	metric
test	metric
tagging	metric
accuracy	metric
for	SEC_CONTENT
each	SEC_CONTENT
group	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
both	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
large	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
on	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
frequency	SEC_CONTENT
1	SEC_CONTENT
-	SEC_CONTENT
10	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
opposed	SEC_CONTENT
to	SEC_CONTENT
more	SEC_CONTENT
frequent	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
result	SEC_CONTENT
again	SEC_CONTENT
corroborates	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
augmentation	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
under	SEC_CONTENT
small	SEC_CONTENT
training	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
hand	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
observe	SEC_CONTENT
meaningful	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
frequency	SEC_CONTENT
0	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
possible	SEC_CONTENT
explanation	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
facilitate	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
with	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
occurrences	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
particularly	SEC_CONTENT
effective	SEC_CONTENT
in	SEC_CONTENT
inferring	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
for	SEC_CONTENT
which	SEC_CONTENT
no	SEC_CONTENT
training	SEC_CONTENT
examples	SEC_CONTENT
are	SEC_CONTENT
given	SEC_CONTENT
(	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Neighboring	SEC_START
words	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
important	SEC_CONTENT
characteristic	SEC_CONTENT
of	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
tasks	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sequential	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
inputs	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
influences	SEC_CONTENT
the	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
neighboring	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
uses	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
for	SEC_CONTENT
that	SEC_CONTENT
reason	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
study	SEC_CONTENT
the	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
neighbors	SEC_CONTENT
of	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
analyze	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
mind	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
cluster	SEC_CONTENT
all	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
their	SEC_CONTENT
frequency	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
again	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
consider	SEC_CONTENT
the	metric
tagging	metric
accuracy	metric
on	SEC_CONTENT
the	SEC_CONTENT
neighbors	SEC_CONTENT
(	SEC_CONTENT
left	SEC_CONTENT
and	SEC_CONTENT
right	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
text	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
tends	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
large	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
neighbors	SEC_CONTENT
of	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
training	SEC_CONTENT
frequency	SEC_CONTENT
0	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
neighbors	SEC_CONTENT
of	SEC_CONTENT
more	SEC_CONTENT
frequent	SEC_CONTENT
words	SEC_CONTENT
remain	SEC_CONTENT
moderate	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
thus	SEC_CONTENT
exhibits	SEC_CONTENT
strong	SEC_CONTENT
stability	SEC_CONTENT
to	SEC_CONTENT
uncertain	SEC_CONTENT
neighbors	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
suspect	SEC_CONTENT
that	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
against	SEC_CONTENT
entire	SEC_CONTENT
input	SEC_CONTENT
sentences	SEC_CONTENT
,	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
makes	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
more	SEC_CONTENT
robust	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
to	SEC_CONTENT
perturbations	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
to	SEC_CONTENT
perturbations	SEC_CONTENT
in	SEC_CONTENT
its	SEC_CONTENT
neighbor-	SEC_CONTENT
 	SEC_CONTENT
ing	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
leading	SEC_CONTENT
to	SEC_CONTENT
greater	SEC_CONTENT
stability	SEC_CONTENT
to	SEC_CONTENT
uncertain	SEC_CONTENT
neighbors	SEC_CONTENT
.	SEC_END
Sentence	SECTITLE_START
-	SECTITLE_CONTENT
level	SECTITLE_CONTENT
&	SECTITLE_CONTENT
Downstream	SECTITLE_CONTENT
Analysis	SECTITLE_END
In	SEC_START
the	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
analysis	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
can	SEC_CONTENT
boost	SEC_CONTENT
tagging	metric
accuracy	metric
on	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
neighbors	SEC_CONTENT
of	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
enhancing	SEC_CONTENT
overall	SEC_CONTENT
robustness	SEC_CONTENT
on	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
discuss	SEC_CONTENT
the	SEC_CONTENT
benefit	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
improved	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
major	SEC_CONTENT
downstream	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
recent	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
take	SEC_CONTENT
predicted	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
;	SEC_CONTENT
;	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
 	SEC_CONTENT
empirically	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
their	SEC_CONTENT
dependency	SEC_CONTENT
parser	SEC_CONTENT
gains	SEC_CONTENT
significant	SEC_CONTENT
improvements	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
predicted	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
predicted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
UDPipe	SEC_CONTENT
tagger	SEC_CONTENT
(	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
contribute	SEC_CONTENT
to	SEC_CONTENT
parsing	SEC_CONTENT
performance	SEC_CONTENT
as	SEC_CONTENT
much	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
observation	SEC_CONTENT
illustrates	SEC_CONTENT
that	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
great	SEC_CONTENT
influence	SEC_CONTENT
on	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
motivating	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tagging	SEC_CONTENT
improvements	SEC_CONTENT
gained	SEC_CONTENT
from	SEC_CONTENT
our	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
help	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_END
To	SEC_START
test	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
three	SEC_CONTENT
settings	SEC_CONTENT
in	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
of	SEC_CONTENT
English	SEC_CONTENT
and	SEC_CONTENT
French	SEC_CONTENT
:	SEC_CONTENT
using	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
predicted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
predicted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
using	SEC_CONTENT
gold	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
English	SEC_CONTENT
(	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
convert	SEC_CONTENT
the	dataset
treebank	dataset
into	SEC_CONTENT
Stanford	SEC_CONTENT
Dependencies	SEC_CONTENT
(	SEC_CONTENT
SD	SEC_CONTENT
)	SEC_CONTENT
using	SEC_CONTENT
Stanford	SEC_CONTENT
CoreNLP	SEC_CONTENT
(	SEC_CONTENT
ver	SEC_CONTENT
3.8.0	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
apply	SEC_CONTENT
two	SEC_CONTENT
wellknown	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
:	SEC_CONTENT
Stanford	SEC_CONTENT
Parser	SEC_CONTENT
(	SEC_CONTENT
ver	SEC_CONTENT
3.5.0	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
Parsey	SEC_CONTENT
McParseface	SEC_CONTENT
(	SEC_CONTENT
SyntaxNet	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
  	SEC_CONTENT
and	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
corresponding	dataset
treebanks	dataset
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
observe	SEC_CONTENT
improvements	SEC_CONTENT
in	SEC_CONTENT
both	SEC_CONTENT
languages	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
predicted	SEC_CONTENT
by	SEC_CONTENT
our	SEC_CONTENT
AT	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
Manning	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
points	SEC_CONTENT
out	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
predicted	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
downstream	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
bad	SEC_CONTENT
mistake	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
can	SEC_CONTENT
greatly	SEC_CONTENT
damage	SEC_CONTENT
the	SEC_CONTENT
usefulness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
robustness	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
AT	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
against	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
helps	SEC_CONTENT
to	SEC_CONTENT
mitigate	SEC_CONTENT
such	SEC_CONTENT
an	SEC_CONTENT
issue	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
advantage	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
observed	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
AT	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
's	SEC_CONTENT
notably	SEC_CONTENT
higher	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
accuracy	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
left	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Nonetheless	SEC_CONTENT
,	SEC_CONTENT
gold	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
still	SEC_CONTENT
yield	SEC_CONTENT
better	SEC_CONTENT
parsing	SEC_CONTENT
results	SEC_CONTENT
as	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
/	SEC_CONTENT
AT	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
,	SEC_CONTENT
supporting	SEC_CONTENT
the	SEC_CONTENT
claim	SEC_CONTENT
that	SEC_CONTENT
POS	task
tagging	task
needs	SEC_CONTENT
further	SEC_CONTENT
improvement	SEC_CONTENT
for	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Effects	SECTITLE_START
on	SECTITLE_CONTENT
Representation	SECTITLE_CONTENT
Learning	SECTITLE_END
Next	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
perform	SEC_CONTENT
an	SEC_CONTENT
analysis	SEC_CONTENT
on	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
English	SEC_CONTENT
(	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
French	SEC_CONTENT
(	SEC_CONTENT
UD	SEC_CONTENT
)	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
helps	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
better	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tag	SEC_CONTENT
prediction	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
influenced	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
perturbation	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
embedding	SEC_CONTENT
.	SEC_END
To	SEC_START
verify	SEC_CONTENT
this	SEC_CONTENT
hypothesis	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
cluster	SEC_CONTENT
all	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
their	SEC_CONTENT
correct	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
4	SEC_CONTENT
and	SEC_CONTENT
evaluate	SEC_CONTENT
the	SEC_CONTENT
tightness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
vector	SEC_CONTENT
distribution	SEC_CONTENT
within	SEC_CONTENT
each	SEC_CONTENT
cluster	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compare	SEC_CONTENT
this	SEC_CONTENT
clustering	SEC_CONTENT
quality	SEC_CONTENT
among	SEC_CONTENT
the	SEC_CONTENT
three	SEC_CONTENT
settings	SEC_CONTENT
:	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
beginning	SEC_CONTENT
(	SEC_CONTENT
initialized	SEC_CONTENT
with	SEC_CONTENT
GloVe	SEC_CONTENT
or	SEC_CONTENT
Polyglot	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
after	SEC_CONTENT
baseline	task
training	task
(	SEC_CONTENT
50	SEC_CONTENT
epochs	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
after	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
50	SEC_CONTENT
epochs	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
study	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
evaluating	SEC_CONTENT
the	SEC_CONTENT
tightness	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
vector	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
the	SEC_CONTENT
cosine	SEC_CONTENT
similarity	SEC_CONTENT
metric	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
widely	SEC_CONTENT
used	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
measure	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
closeness	SEC_CONTENT
between	SEC_CONTENT
two	SEC_CONTENT
word	SEC_CONTENT
vectors	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
;	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
measure	SEC_CONTENT
the	SEC_CONTENT
tightness	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
cluster	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
cosine	SEC_CONTENT
similarity	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
pair	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
within	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
take	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
tightness	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
clusters	SEC_CONTENT
.	SEC_END
The	SEC_START
evaluation	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
Table	SEC_CONTENT
6	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
tightness	SEC_CONTENT
scores	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
four	SEC_CONTENT
major	SEC_CONTENT
clusters	SEC_CONTENT
:	SEC_CONTENT
noun	SEC_CONTENT
,	SEC_CONTENT
verb	SEC_CONTENT
,	SEC_CONTENT
adjective	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
adverb	SEC_CONTENT
(	SEC_CONTENT
from	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
right	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
table	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
cleaner	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
distributions	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
higher	SEC_CONTENT
cosine	SEC_CONTENT
similarity	SEC_CONTENT
within	SEC_CONTENT
each	SEC_CONTENT
POS	SEC_CONTENT
cluster	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
clear	SEC_CONTENT
advantage	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
tightness	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
clusters	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
learned	SEC_CONTENT
word	SEC_CONTENT
vectors	SEC_CONTENT
show	SEC_CONTENT
stronger	SEC_CONTENT
correlations	SEC_CONTENT
with	SEC_CONTENT
their	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
result	SEC_CONTENT
confirms	SEC_CONTENT
that	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
adversarial	SEC_CONTENT
examples	SEC_CONTENT
can	SEC_CONTENT
help	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
cleaner	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
meaning	SEC_CONTENT
/	SEC_CONTENT
grammatical	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
altered	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
perturbation	SEC_CONTENT
in	SEC_CONTENT
its	SEC_CONTENT
embedding	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
analysis	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
means	SEC_CONTENT
to	SEC_CONTENT
interpret	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	SEC_CONTENT
,	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
perspective	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
.	SEC_END
Relation	SEC_START
with	SEC_CONTENT
perturbation	SEC_CONTENT
size	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
study	SEC_CONTENT
how	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
added	SEC_CONTENT
perturbations	SEC_CONTENT
influences	SEC_CONTENT
word	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
in	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Recall	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
a	dataset
perturbation	dataset
to	SEC_CONTENT
be	SEC_CONTENT
α	SEC_CONTENT
√	SEC_CONTENT
D	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
Dis	SEC_CONTENT
the	SEC_CONTENT
dimension	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
concatenated	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
§	SEC_CONTENT
3.2	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
instance	SEC_CONTENT
,	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
0	SEC_CONTENT
would	SEC_CONTENT
produce	SEC_CONTENT
no	SEC_CONTENT
noise	SEC_CONTENT
;	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
would	SEC_CONTENT
generate	SEC_CONTENT
a	dataset
perturbation	dataset
of	SEC_CONTENT
a	SEC_CONTENT
norm	SEC_CONTENT
equivalent	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
facilitates	SEC_CONTENT
word	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
when	SEC_CONTENT
α	SEC_CONTENT
is	SEC_CONTENT
small	SEC_CONTENT
enough	SEC_CONTENT
to	SEC_CONTENT
preserve	SEC_CONTENT
the	SEC_CONTENT
semantics	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
can	SEC_CONTENT
hinder	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
when	SEC_CONTENT
α	SEC_CONTENT
is	SEC_CONTENT
too	SEC_CONTENT
large	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
test	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
repeat	SEC_CONTENT
the	SEC_CONTENT
clustering	SEC_CONTENT
evaluation	SEC_CONTENT
for	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
varied	SEC_CONTENT
perturbation	SEC_CONTENT
scale	SEC_CONTENT
α	SEC_CONTENT
:	SEC_CONTENT
93.81	SEC_CONTENT
94.32	SEC_CONTENT
94.66	SEC_CONTENT
95.15	SEC_CONTENT
 	SEC_CONTENT
95.56	SEC_CONTENT
95.77	SEC_CONTENT
96.37	SEC_END
Ours	SEC_START
-Baseline	SEC_CONTENT
95.18	SEC_CONTENT
Ours	SEC_CONTENT
-Adversarial	SEC_CONTENT
95.25	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
quality	SEC_CONTENT
of	SEC_CONTENT
learned	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
distribution	SEC_CONTENT
keeps	SEC_CONTENT
improving	SEC_CONTENT
as	SEC_CONTENT
α	SEC_CONTENT
goes	SEC_CONTENT
up	SEC_CONTENT
from	SEC_CONTENT
0	SEC_CONTENT
to	SEC_CONTENT
0.1	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
starts	SEC_CONTENT
to	SEC_CONTENT
drop	SEC_CONTENT
around	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
optimal	SEC_CONTENT
α	SEC_CONTENT
in	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
0.1	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
larger	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
α	SEC_CONTENT
which	SEC_CONTENT
yielded	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
tagging	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
development	SEC_CONTENT
sets	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
0.01	SEC_CONTENT
or	SEC_CONTENT
0.05	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
possible	SEC_CONTENT
explanation	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
while	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
can	SEC_CONTENT
adapt	SEC_CONTENT
to	SEC_CONTENT
relatively	SEC_CONTENT
large	SEC_CONTENT
α	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
0.1	SEC_CONTENT
)	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
adversarial	SEC_CONTENT
perturbations	SEC_CONTENT
are	SEC_CONTENT
generated	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
level	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
α	SEC_CONTENT
could	SEC_CONTENT
change	SEC_CONTENT
the	SEC_CONTENT
semantics	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
tagging	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
perspective	SEC_CONTENT
and	SEC_CONTENT
hinder	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
tagging	SEC_CONTENT
.	SEC_END
Other	SECTITLE_START
Sequence	SECTITLE_CONTENT
Labeling	SECTITLE_CONTENT
Tasks	SECTITLE_END
Finally	SEC_START
,	SEC_CONTENT
to	SEC_CONTENT
further	SEC_CONTENT
confirm	SEC_CONTENT
the	SEC_CONTENT
applicability	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
experiment	SEC_CONTENT
with	SEC_CONTENT
our	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
different	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_CONTENT
chunking	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
(	SEC_CONTENT
NER	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Chunking	SEC_START
can	SEC_CONTENT
be	SEC_CONTENT
performed	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
task	SEC_CONTENT
that	SEC_CONTENT
assigns	SEC_CONTENT
a	SEC_CONTENT
chunking	SEC_CONTENT
tag	SEC_CONTENT
(	SEC_CONTENT
B	SEC_CONTENT
-	SEC_CONTENT
NP	SEC_CONTENT
,	SEC_CONTENT
I	SEC_CONTENT
-	SEC_CONTENT
VP	SEC_CONTENT
,	SEC_CONTENT
etc	SEC_CONTENT
.	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
conduct	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL	SEC_CONTENT
2000	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
data	SEC_CONTENT
split	SEC_CONTENT
:	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
WSJ	SEC_CONTENT
Sections	SEC_CONTENT
15	SEC_CONTENT
-	SEC_CONTENT
18	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
20	SEC_CONTENT
for	SEC_CONTENT
testing	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
Section	SEC_CONTENT
19	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
employ	SEC_CONTENT
the	SEC_CONTENT
IOBES	SEC_CONTENT
tagging	SEC_CONTENT
scheme	SEC_CONTENT
,	SEC_CONTENT
following	SEC_CONTENT
.	SEC_CONTENT
NER	SEC_CONTENT
aims	SEC_CONTENT
to	SEC_CONTENT
assign	SEC_CONTENT
an	SEC_CONTENT
entity	SEC_CONTENT
type	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
person	SEC_CONTENT
,	SEC_CONTENT
location	SEC_CONTENT
,	SEC_CONTENT
organization	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
misc	SEC_CONTENT
.	SEC_END
We	SEC_START
conduct	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2003	SEC_CONTENT
(	SEC_CONTENT
English	SEC_CONTENT
)	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
adopting	SEC_CONTENT
the	SEC_CONTENT
IOBES	SEC_CONTENT
tagging	SEC_CONTENT
scheme	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
The	SEC_START
results	SEC_CONTENT
are	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
and	SEC_CONTENT
9	SEC_CONTENT
.	SEC_CONTENT
AT	SEC_CONTENT
enhanced	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
95.18	SEC_CONTENT
to	SEC_CONTENT
95.25	SEC_CONTENT
for	SEC_CONTENT
chunking	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
from	SEC_CONTENT
91.22	SEC_CONTENT
to	SEC_CONTENT
91.56	SEC_CONTENT
for	SEC_CONTENT
NER	SEC_CONTENT
,	SEC_CONTENT
also	SEC_CONTENT
significantly	SEC_CONTENT
outperforming	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
improvements	SEC_CONTENT
made	SEC_CONTENT
by	SEC_CONTENT
AT	SEC_CONTENT
are	SEC_CONTENT
bigger	SEC_CONTENT
than	SEC_CONTENT
that	SEC_CONTENT
for	SEC_CONTENT
English	task
POS	task
tagging	task
,	SEC_CONTENT
most	SEC_CONTENT
likely	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
larger	SEC_CONTENT
room	SEC_CONTENT
for	SEC_CONTENT
improvement	SEC_CONTENT
in	SEC_CONTENT
chunking	SEC_CONTENT
and	SEC_CONTENT
NER	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
improvements	SEC_CONTENT
are	SEC_CONTENT
again	SEC_CONTENT
statistically	SEC_CONTENT
significant	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
p	SEC_CONTENT
-	SEC_CONTENT
value	SEC_CONTENT
<	SEC_CONTENT
0.05	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
t	SEC_CONTENT
-	SEC_CONTENT
test	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
experimental	SEC_CONTENT
results	SEC_CONTENT
suggest	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
scheme	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
effective	SEC_CONTENT
across	SEC_CONTENT
different	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Our	SEC_START
BiLSTM	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
reach	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
's	SEC_CONTENT
multitask	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
's	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
theart	SEC_CONTENT
system	SEC_CONTENT
that	SEC_CONTENT
incorporates	SEC_CONTENT
pretrained	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
interesting	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
to	SEC_CONTENT
combine	SEC_CONTENT
the	SEC_CONTENT
strengths	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
joint	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
syntactic	SEC_CONTENT
and	SEC_CONTENT
semantic	SEC_CONTENT
aids	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
robustness	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
proposed	SEC_CONTENT
and	SEC_CONTENT
carefully	SEC_CONTENT
analyzed	SEC_CONTENT
a	task
POS	task
tagging	task
model	task
that	SEC_CONTENT
exploits	SEC_CONTENT
adversarial	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
AT	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
multilingual	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
AT	SEC_CONTENT
achieves	SEC_CONTENT
substantial	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
languages	SEC_CONTENT
tested	SEC_CONTENT
,	SEC_CONTENT
especially	SEC_CONTENT
on	SEC_CONTENT
low	SEC_CONTENT
resource	SEC_CONTENT
ones	SEC_CONTENT
.	SEC_CONTENT
AT	SEC_CONTENT
also	SEC_CONTENT
enhances	SEC_CONTENT
the	SEC_CONTENT
robustness	SEC_CONTENT
to	SEC_CONTENT
rare	SEC_CONTENT
/	SEC_CONTENT
unseen	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
accuracy	SEC_CONTENT
,	SEC_CONTENT
alleviating	SEC_CONTENT
the	SEC_CONTENT
major	SEC_CONTENT
issues	SEC_CONTENT
of	SEC_CONTENT
current	SEC_CONTENT
POS	SEC_CONTENT
taggers	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
contributing	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
downstream	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
analyses	SEC_CONTENT
on	SEC_CONTENT
different	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
word	SEC_CONTENT
/	SEC_CONTENT
neighbor	SEC_CONTENT
statistics	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
reveal	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
AT	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
perspective	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
proposed	SEC_CONTENT
AT	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
applicable	SEC_CONTENT
to	SEC_CONTENT
general	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
work	SEC_CONTENT
therefore	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
basis	SEC_CONTENT
and	SEC_CONTENT
motivation	SEC_CONTENT
for	SEC_CONTENT
utilizing	SEC_CONTENT
AT	SEC_CONTENT
in	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
