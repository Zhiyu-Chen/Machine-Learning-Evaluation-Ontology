clin27.paper	title\tagSECTITLE_END	MoNoise\tagSEC_START	:\tagSEC_CONTENT	Modeling\tagSEC_CONTENT	Noise\tagSEC_CONTENT	Using\tagSEC_CONTENT	a\tagtask	Modular\tagtask	Normalization\tagtask	System\tagtask	.\tagSEC_CONTENT	Gertjan\tagSEC_CONTENT	van\tagSEC_CONTENT	Noord\tagSEC_END	abstract\tagSECTITLE_END	We\tagSEC_START	propose\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	:\tagSEC_CONTENT	a\tagtask	normalization\tagtask	model\tagtask	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	generalizability\tagSEC_CONTENT	and\tagSEC_CONTENT	efficiency\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	aims\tagSEC_CONTENT	at\tagSEC_CONTENT	being\tagSEC_CONTENT	easily\tagSEC_CONTENT	reusable\tagSEC_CONTENT	and\tagSEC_CONTENT	adaptable\tagSEC_CONTENT	.\tagSEC_CONTENT	Normalization\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	translating\tagSEC_CONTENT	texts\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	canonical\tagSEC_CONTENT	domain\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	canonical\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	case\tagSEC_CONTENT	:\tagSEC_CONTENT	from\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	data\tagSEC_CONTENT	to\tagSEC_CONTENT	standard\tagSEC_CONTENT	language\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	modular\tagSEC_CONTENT	candidate\tagSEC_CONTENT	generation\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	each\tagSEC_CONTENT	module\tagSEC_CONTENT	is\tagSEC_CONTENT	responsible\tagSEC_CONTENT	fora\tagSEC_CONTENT	different\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	normalization\tagSEC_CONTENT	action\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	generation\tagSEC_CONTENT	modules\tagSEC_CONTENT	area\tagSEC_CONTENT	spelling\tagSEC_CONTENT	correction\tagSEC_CONTENT	system\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_CONTENT	Depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	definition\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	normalization\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	static\tagSEC_CONTENT	lookup\tagSEC_CONTENT	list\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	crucial\tagSEC_CONTENT	for\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	train\tagSEC_CONTENT	a\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	to\tagSEC_CONTENT	rank\tagSEC_CONTENT	the\tagSEC_CONTENT	candidates\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	generalizes\tagSEC_CONTENT	well\tagSEC_CONTENT	to\tagSEC_CONTENT	all\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	normaliza\tagSEC_CONTENT	-\tagSEC_CONTENT	tion\tagSEC_CONTENT	actions\tagSEC_CONTENT	.\tagSEC_CONTENT	Most\tagSEC_CONTENT	features\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	originate\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	generation\tagSEC_CONTENT	modules\tagSEC_CONTENT	;\tagSEC_CONTENT	besides\tagSEC_CONTENT	these\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	features\tagSEC_CONTENT	prove\tagSEC_CONTENT	to\tagSEC_CONTENT	bean\tagSEC_CONTENT	important\tagSEC_CONTENT	source\tagSEC_CONTENT	of\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	beats\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	on\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	for\tagSEC_CONTENT	English\tagSEC_CONTENT	and\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	all\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	normalization\tagSEC_CONTENT	slightly\tagSEC_CONTENT	different\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	The\tagSEC_START	spontaneous\tagSEC_CONTENT	and\tagSEC_CONTENT	diverse\tagSEC_CONTENT	nature\tagSEC_CONTENT	of\tagSEC_CONTENT	language\tagSEC_CONTENT	use\tagSEC_CONTENT	on\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	many\tagSEC_CONTENT	problems\tagSEC_CONTENT	for\tagSEC_CONTENT	existing\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	processing\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Most\tagSEC_CONTENT	existing\tagSEC_CONTENT	models\tagSEC_CONTENT	are\tagSEC_CONTENT	developed\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	focus\tagSEC_CONTENT	on\tagSEC_CONTENT	more\tagSEC_CONTENT	canonical\tagSEC_CONTENT	language\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	models\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	cope\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	disfluencies\tagSEC_CONTENT	and\tagSEC_CONTENT	unknown\tagSEC_CONTENT	phenomena\tagSEC_CONTENT	occurring\tagSEC_CONTENT	in\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	known\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	problem\tagSEC_CONTENT	of\tagSEC_CONTENT	domain\tagSEC_CONTENT	adaptation\tagSEC_CONTENT	:\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	try\tagSEC_CONTENT	to\tagSEC_CONTENT	adapt\tagSEC_CONTENT	a\tagSEC_CONTENT	model\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	source\tagSEC_CONTENT	domain\tagSEC_CONTENT	to\tagSEC_CONTENT	another\tagSEC_CONTENT	target\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	Solutions\tagSEC_CONTENT	for\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	broadly\tagSEC_CONTENT	divided\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	strategies\tagSEC_CONTENT	:\tagSEC_CONTENT	adapting\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	adapting\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_END	Domain\tagSEC_START	adaptation\tagSEC_CONTENT	by\tagSEC_CONTENT	adapting\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	domain\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	done\tagSEC_CONTENT	in\tagSEC_CONTENT	different\tagSEC_CONTENT	ways\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	most\tagSEC_CONTENT	straightforward\tagSEC_CONTENT	method\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	annotated\tagSEC_CONTENT	data\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	Newly\tagSEC_CONTENT	annotated\tagSEC_CONTENT	data\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	obtained\tagSEC_CONTENT	by\tagSEC_CONTENT	hiring\tagSEC_CONTENT	human\tagSEC_CONTENT	annotators\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	cheaper\tagSEC_CONTENT	to\tagSEC_CONTENT	annotate\tagSEC_CONTENT	data\tagSEC_CONTENT	automatically\tagSEC_CONTENT	using\tagSEC_CONTENT	an\tagSEC_CONTENT	existing\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	called\tagSEC_CONTENT	self\tagSEC_CONTENT	-\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	up\tagSEC_CONTENT	-\tagSEC_CONTENT	training\tagSEC_CONTENT	if\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	is\tagSEC_CONTENT	annotated\tagSEC_CONTENT	by\tagSEC_CONTENT	an\tagSEC_CONTENT	external\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	adding\tagSEC_CONTENT	this\tagSEC_CONTENT	newly\tagSEC_CONTENT	annotated\tagSEC_CONTENT	data\tagSEC_CONTENT	depends\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	nature\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	new\tagSEC_CONTENT	data\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	and\tagSEC_CONTENT	source\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	added\tagSEC_CONTENT	data\tagSEC_CONTENT	should\tagSEC_CONTENT	be\tagSEC_CONTENT	annotated\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagmetric	high\tagmetric	accuracy\tagmetric	,\tagSEC_CONTENT	so\tagSEC_CONTENT	it\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	be\tagSEC_CONTENT	too\tagSEC_CONTENT	distant\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	should\tagSEC_CONTENT	add\tagSEC_CONTENT	some\tagtask	information\tagtask	inherent\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	There\tagSEC_CONTENT	is\tagSEC_CONTENT	ample\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	direction\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	different\tagSEC_CONTENT	strategies\tagSEC_CONTENT	of\tagSEC_CONTENT	up\tagSEC_CONTENT	-\tagSEC_CONTENT	training\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	other\tagSEC_CONTENT	strategy\tagSEC_CONTENT	for\tagSEC_CONTENT	domain\tagSEC_CONTENT	adaptation\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	convert\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	domain\tagSEC_CONTENT	;\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	strategy\tagSEC_CONTENT	explored\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	task\tagSEC_CONTENT	is\tagSEC_CONTENT	often\tagSEC_CONTENT	referred\tagSEC_CONTENT	to\tagSEC_CONTENT	as\tagSEC_CONTENT	normalization\tagtask	,\tagSEC_CONTENT	because\tagSEC_CONTENT	we\tagSEC_CONTENT	aim\tagSEC_CONTENT	to\tagSEC_CONTENT	convert\tagSEC_CONTENT	data\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	domain\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	more\tagSEC_CONTENT	'\tagSEC_CONTENT	normal\tagSEC_CONTENT	'\tagSEC_CONTENT	source\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	which\tagSEC_CONTENT	a\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	already\tagSEC_CONTENT	available\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	main\tagSEC_CONTENT	advantage\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	approach\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	only\tagSEC_CONTENT	need\tagSEC_CONTENT	one\tagSEC_CONTENT	normalization\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	use\tagSEC_CONTENT	as\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	step\tagSEC_CONTENT	for\tagSEC_CONTENT	multiple\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	processing\tagSEC_CONTENT	systems\tagSEC_CONTENT	.\tagSEC_CONTENT	Normalization\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	subjective\tagSEC_CONTENT	task\tagSEC_CONTENT	;\tagSEC_CONTENT	the\tagSEC_CONTENT	goal\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	convert\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	normal\tagSEC_CONTENT	'\tagSEC_CONTENT	language\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	must\tagSEC_CONTENT	preserve\tagSEC_CONTENT	the\tagSEC_CONTENT	meaning\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	utterance\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	task\tagSEC_CONTENT	comprises\tagSEC_CONTENT	the\tagSEC_CONTENT	correction\tagSEC_CONTENT	of\tagSEC_CONTENT	unintentional\tagSEC_CONTENT	anomalies\tagSEC_CONTENT	(\tagSEC_CONTENT	spell\tagSEC_CONTENT	correction\tagSEC_CONTENT	)\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	intentional\tagSEC_CONTENT	anomalies\tagSEC_CONTENT	(\tagSEC_CONTENT	domain\tagSEC_CONTENT	specific\tagSEC_CONTENT	language\tagSEC_CONTENT	phenomena\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Annotator\tagSEC_CONTENT	disagreement\tagSEC_CONTENT	can\tagSEC_CONTENT	thus\tagSEC_CONTENT	have\tagSEC_CONTENT	two\tagSEC_CONTENT	sources\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	decision\tagSEC_CONTENT	whether\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	should\tagSEC_CONTENT	be\tagSEC_CONTENT	normalized\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	choice\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	normalization\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	discuss\tagSEC_CONTENT	these\tagSEC_CONTENT	problems\tagSEC_CONTENT	in\tagSEC_CONTENT	more\tagSEC_CONTENT	depth\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3.1\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	rest\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	term\tagSEC_CONTENT	'\tagSEC_CONTENT	anomaly\tagSEC_CONTENT	'\tagSEC_CONTENT	for\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	need\tagSEC_CONTENT	of\tagSEC_CONTENT	normalization\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	annotators\tagSEC_CONTENT	.\tagSEC_CONTENT	Example\tagSEC_CONTENT	1\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	normalization\tagSEC_CONTENT	task\tagSEC_CONTENT	comprises\tagSEC_CONTENT	of\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	transformations\tagSEC_CONTENT	.\tagSEC_CONTENT	Replacements\tagSEC_CONTENT	like\tagSEC_CONTENT	'\tagSEC_CONTENT	bein\tagSEC_CONTENT	'\tagSEC_CONTENT	→\tagSEC_CONTENT	'\tagSEC_CONTENT	being\tagSEC_CONTENT	'\tagSEC_CONTENT	are\tagSEC_CONTENT	quite\tagSEC_CONTENT	similar\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	surface\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	'\tagSEC_CONTENT	tmr\tagSEC_CONTENT	'\tagSEC_CONTENT	→\tagSEC_CONTENT	tomorrow\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	need\tagSEC_CONTENT	more\tagSEC_CONTENT	than\tagSEC_CONTENT	edit\tagSEC_CONTENT	distances\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	character\tagSEC_CONTENT	level\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	example\tagSEC_CONTENT	includes\tagSEC_CONTENT	a\tagSEC_CONTENT	1-N\tagSEC_CONTENT	replacement\tagSEC_CONTENT	(\tagSEC_CONTENT	I\tagSEC_CONTENT	m\tagSEC_CONTENT	a\tagSEC_CONTENT	→\tagSEC_CONTENT	'\tagSEC_CONTENT	I\tagSEC_CONTENT	'm\tagSEC_CONTENT	going\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	meaning\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	token\tagSEC_CONTENT	is\tagSEC_CONTENT	mapped\tagSEC_CONTENT	to\tagSEC_CONTENT	multiple\tagSEC_CONTENT	tokens\tagSEC_CONTENT	.\tagSEC_CONTENT	Not\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	annotated\tagSEC_CONTENT	corpora\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	include\tagSEC_CONTENT	annotation\tagSEC_CONTENT	for\tagSEC_CONTENT	these\tagSEC_CONTENT	cases\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	Section\tagSEC_CONTENT	3.1\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	1-N\tagSEC_CONTENT	replacements\tagSEC_CONTENT	show\tagSEC_CONTENT	a\tagSEC_CONTENT	strong\tagSEC_CONTENT	Zipfian\tagSEC_CONTENT	distribution\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	corpora\tagSEC_CONTENT	that\tagSEC_CONTENT	include\tagSEC_CONTENT	them\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	expansion\tagSEC_CONTENT	of\tagSEC_CONTENT	phrasal\tagSEC_CONTENT	abbreviations\tagSEC_CONTENT	like\tagSEC_CONTENT	'\tagSEC_CONTENT	lol\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	idk\tagSEC_CONTENT	'\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	very\tagSEC_CONTENT	common\tagSEC_CONTENT	.\tagSEC_CONTENT	Some\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	corpora\tagSEC_CONTENT	also\tagSEC_CONTENT	include\tagSEC_CONTENT	N-1\tagSEC_CONTENT	replacements\tagSEC_CONTENT	,\tagSEC_CONTENT	meaning\tagSEC_CONTENT	the\tagSEC_CONTENT	merging\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	consecutive\tagSEC_CONTENT	words\tagSEC_CONTENT	;\tagSEC_CONTENT	however\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	very\tagSEC_CONTENT	rare\tagSEC_CONTENT	phenomenon\tagSEC_CONTENT	.\tagSEC_END	Because\tagSEC_START	the\tagtask	normalization\tagtask	problem\tagtask	comprises\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	actions\tagSEC_CONTENT	required\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	anomalies\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	to\tagSEC_CONTENT	tackle\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	modular\tagSEC_CONTENT	way\tagSEC_CONTENT	.\tagSEC_CONTENT	Different\tagSEC_CONTENT	modules\tagSEC_CONTENT	can\tagSEC_CONTENT	then\tagSEC_CONTENT	be\tagSEC_CONTENT	designed\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	anomalies\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	modules\tagSEC_CONTENT	are\tagSEC_CONTENT	:\tagSEC_CONTENT	a\tagSEC_CONTENT	spell\tagSEC_CONTENT	correction\tagSEC_CONTENT	module\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	module\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	static\tagSEC_CONTENT	lookup\tagSEC_CONTENT	list\tagSEC_CONTENT	generated\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	generation\tagSEC_CONTENT	modules\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	additional\tagSEC_CONTENT	features\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	decides\tagSEC_CONTENT	which\tagSEC_CONTENT	candidate\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	normalization\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	experiment\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	additional\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	of\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	features\tagSEC_CONTENT	are\tagSEC_CONTENT	by\tagSEC_CONTENT	far\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	predictor\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	rest\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	is\tagSEC_CONTENT	structured\tagSEC_CONTENT	as\tagSEC_CONTENT	follows\tagSEC_CONTENT	:\tagSEC_CONTENT	We\tagSEC_CONTENT	first\tagSEC_CONTENT	discuss\tagSEC_CONTENT	related\tagSEC_CONTENT	work\tagSEC_CONTENT	(\tagSEC_CONTENT	Section\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	after\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	shortly\tagSEC_CONTENT	describe\tagSEC_CONTENT	the\tagSEC_CONTENT	used\tagSEC_CONTENT	data\tagSEC_CONTENT	(\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Next\tagSEC_CONTENT	follows\tagSEC_CONTENT	the\tagSEC_CONTENT	methodology\tagSEC_CONTENT	section\tagSEC_CONTENT	(\tagSEC_CONTENT	4\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	section\tagSEC_CONTENT	(\tagSEC_CONTENT	5\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	both\tagSEC_CONTENT	splitted\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	system\tagSEC_CONTENT	;\tagSEC_CONTENT	candidate\tagSEC_CONTENT	generation\tagSEC_CONTENT	and\tagSEC_CONTENT	candidate\tagSEC_CONTENT	ranking\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	conclude\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagmetric	6\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	The\tagSEC_START	first\tagSEC_CONTENT	attempts\tagSEC_CONTENT	at\tagSEC_CONTENT	normalizing\tagSEC_CONTENT	user\tagSEC_CONTENT	generated\tagSEC_CONTENT	content\tagSEC_CONTENT	were\tagSEC_CONTENT	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	SMS\tagSEC_CONTENT	data\tagSEC_CONTENT	;\tagSEC_CONTENT	annotated\tagSEC_CONTENT	a\tagSEC_CONTENT	dataset\tagSEC_CONTENT	for\tagSEC_CONTENT	this\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	reported\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	Hidden\tagSEC_CONTENT	Markov\tagSEC_CONTENT	Model\tagSEC_CONTENT	encoding\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	characters\tagSEC_CONTENT	and\tagSEC_CONTENT	phonemic\tagSEC_CONTENT	transcriptions\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	the\tagtask	word\tagtask	variation\tagtask	in\tagSEC_CONTENT	SMS\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	Viterbi\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	find\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	likely\tagSEC_CONTENT	replacement\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	position\tagSEC_CONTENT	.\tagSEC_END	Later\tagSEC_START	,\tagSEC_CONTENT	focus\tagSEC_CONTENT	shifted\tagSEC_CONTENT	towards\tagSEC_CONTENT	normalization\tagtask	for\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	,\tagSEC_CONTENT	more\tagSEC_CONTENT	specifically\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	Twitter\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	first\tagSEC_CONTENT	work\tagSEC_CONTENT	on\tagSEC_CONTENT	normalization\tagSEC_CONTENT	for\tagSEC_CONTENT	this\tagSEC_CONTENT	domain\tagSEC_CONTENT	was\tagSEC_CONTENT	from\tagSEC_CONTENT	Han\tagSEC_CONTENT	and\tagSEC_CONTENT	Baldwin\tagSEC_CONTENT	(\tagSEC_CONTENT	2011\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	released\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	549\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	annotated\tagSEC_CONTENT	with\tagSEC_CONTENT	their\tagSEC_CONTENT	normalization\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	level\tagSEC_CONTENT	.\tagSEC_CONTENT	Annotation\tagSEC_CONTENT	is\tagSEC_CONTENT	restricted\tagSEC_CONTENT	to\tagSEC_CONTENT	word\tagSEC_CONTENT	to\tagSEC_CONTENT	word\tagSEC_CONTENT	replacements\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	words\tagSEC_CONTENT	like\tagSEC_CONTENT	'\tagSEC_CONTENT	gon\tagSEC_CONTENT	na\tagSEC_CONTENT	'\tagSEC_CONTENT	are\tagSEC_CONTENT	kept\tagSEC_CONTENT	untouched\tagSEC_CONTENT	.\tagSEC_CONTENT	also\tagSEC_CONTENT	reported\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	train\tagSEC_CONTENT	a\tagSEC_CONTENT	support\tagSEC_CONTENT	vector\tagSEC_CONTENT	machine\tagSEC_CONTENT	which\tagSEC_CONTENT	predicts\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	needs\tagSEC_CONTENT	normalization\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	context\tagSEC_CONTENT	;\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	arcs\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	head\tagSEC_CONTENT	words\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	predictors\tagSEC_CONTENT	.\tagSEC_CONTENT	After\tagSEC_CONTENT	this\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	generate\tagSEC_CONTENT	candidates\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	lexical\tagSEC_CONTENT	and\tagSEC_CONTENT	phonetic\tagSEC_CONTENT	edit\tagSEC_CONTENT	distances\tagSEC_CONTENT	.\tagSEC_CONTENT	Candidates\tagSEC_CONTENT	are\tagSEC_CONTENT	ranked\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	lookup\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	similarity\tagSEC_CONTENT	and\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	probabilities\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	gold\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	is\tagSEC_CONTENT	usually\tagSEC_CONTENT	assumed\tagSEC_CONTENT	,\tagSEC_CONTENT	accuracy\tagSEC_CONTENT	is\tagSEC_CONTENT	reported\tagSEC_CONTENT	on\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	that\tagSEC_CONTENT	need\tagSEC_CONTENT	normalization\tagSEC_CONTENT	.\tagSEC_END	Over\tagSEC_START	the\tagSEC_CONTENT	years\tagSEC_CONTENT	,\tagSEC_CONTENT	many\tagSEC_CONTENT	different\tagSEC_CONTENT	approaches\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	benchmarked\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	;\tagSEC_CONTENT	Li\tagSEC_CONTENT	and\tagSEC_CONTENT	Liu\tagSEC_CONTENT	(\tagSEC_CONTENT	2012\tagSEC_CONTENT	)\tagSEC_CONTENT	experiment\tagSEC_CONTENT	with\tagSEC_CONTENT	character\tagSEC_CONTENT	based\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	.\tagSEC_CONTENT	use\tagSEC_CONTENT	random\tagSEC_CONTENT	walks\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	bipartite\tagSEC_CONTENT	graph\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	their\tagSEC_CONTENT	contexts\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	normalization\tagtask	candidates\tagtask	,\tagSEC_CONTENT	which\tagSEC_CONTENT	they\tagSEC_CONTENT	rank\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	Viterbi\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	model\tagSEC_CONTENT	was\tagSEC_CONTENT	explored\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	use\tagSEC_CONTENT	sequential\tagSEC_CONTENT	Monte\tagSEC_CONTENT	Carlo\tagSEC_CONTENT	to\tagSEC_CONTENT	approximate\tagSEC_CONTENT	feature\tagSEC_CONTENT	expectation\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	rank\tagSEC_CONTENT	them\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	Viterbi\tagSEC_CONTENT	-\tagSEC_CONTENT	encoding\tagSEC_CONTENT	.\tagSEC_CONTENT	Whereas\tagSEC_CONTENT	most\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	normalizes\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	level\tagSEC_CONTENT	or\tagSEC_CONTENT	character\tagSEC_CONTENT	level\tagSEC_CONTENT	,\tagSEC_CONTENT	attempt\tagSEC_CONTENT	to\tagSEC_CONTENT	normalize\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	syllable\tagSEC_CONTENT	level\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	translate\tagSEC_CONTENT	noisy\tagSEC_CONTENT	words\tagSEC_CONTENT	to\tagSEC_CONTENT	sequences\tagSEC_CONTENT	of\tagSEC_CONTENT	syllables\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	then\tagSEC_CONTENT	be\tagSEC_CONTENT	normalized\tagSEC_CONTENT	to\tagSEC_CONTENT	canonical\tagSEC_CONTENT	syllables\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	in\tagSEC_CONTENT	turn\tagSEC_CONTENT	be\tagSEC_CONTENT	merged\tagSEC_CONTENT	back\tagSEC_CONTENT	to\tagSEC_CONTENT	form\tagSEC_CONTENT	normalization\tagSEC_CONTENT	candidates\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	the\tagSEC_CONTENT	best\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	,\tagSEC_CONTENT	reported\tagSEC_CONTENT	the\tagmetric	highest\tagmetric	accuracy\tagmetric	on\tagSEC_CONTENT	the\tagdataset	LexNorm\tagdataset	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	rerank\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	of\tagSEC_CONTENT	six\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	systems\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	systems\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	character\tagSEC_CONTENT	sequence\tagSEC_CONTENT	labeling\tagSEC_CONTENT	model\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	spellchecker\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	normalization\tagSEC_CONTENT	system\tagSEC_CONTENT	suggests\tagSEC_CONTENT	one\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	Viterbi\tagSEC_CONTENT	decoding\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	candidates\tagSEC_CONTENT	and\tagSEC_CONTENT	their\tagSEC_CONTENT	possible\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	rank\tagSEC_CONTENT	the\tagSEC_CONTENT	candidates\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	joint\tagSEC_CONTENT	approach\tagSEC_CONTENT	is\tagSEC_CONTENT	beneficial\tagSEC_CONTENT	for\tagSEC_CONTENT	both\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	More\tagSEC_START	recently\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	2015\tagSEC_CONTENT	Workshop\tagSEC_CONTENT	on\tagSEC_CONTENT	Noisy\tagSEC_CONTENT	User\tagSEC_CONTENT	-\tagSEC_CONTENT	generated\tagSEC_CONTENT	Text\tagSEC_CONTENT	hosted\tagSEC_CONTENT	a\tagSEC_CONTENT	shared\tagSEC_CONTENT	task\tagSEC_CONTENT	on\tagSEC_CONTENT	lexical\tagtask	normalization\tagtask	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	defined\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	slightly\tagSEC_CONTENT	different\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	Annotation\tagSEC_CONTENT	included\tagSEC_CONTENT	1-N\tagSEC_CONTENT	and\tagSEC_CONTENT	N-1\tagSEC_CONTENT	replacements\tagSEC_CONTENT	.\tagSEC_CONTENT	N-1\tagSEC_CONTENT	replacements\tagSEC_CONTENT	indicate\tagSEC_CONTENT	merging\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	occurs\tagSEC_CONTENT	very\tagSEC_CONTENT	rarely\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	shared\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	gold\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	was\tagSEC_CONTENT	not\tagSEC_CONTENT	assumed\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	was\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	total\tagSEC_CONTENT	of\tagSEC_CONTENT	10\tagSEC_CONTENT	teams\tagSEC_CONTENT	participated\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	shared\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	wide\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	approaches\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	generation\tagSEC_CONTENT	of\tagSEC_CONTENT	candidates\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	commonly\tagSEC_CONTENT	used\tagSEC_CONTENT	methods\tagSEC_CONTENT	include\tagSEC_CONTENT	:\tagSEC_CONTENT	character\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	grams\tagSEC_CONTENT	,\tagSEC_CONTENT	edit\tagSEC_CONTENT	-\tagSEC_CONTENT	distances\tagSEC_CONTENT	and\tagSEC_CONTENT	lookup\tagSEC_CONTENT	lists\tagSEC_CONTENT	.\tagSEC_CONTENT	Ranking\tagSEC_CONTENT	was\tagSEC_CONTENT	most\tagSEC_CONTENT	often\tagSEC_CONTENT	done\tagSEC_CONTENT	by\tagSEC_CONTENT	conditional\tagSEC_CONTENT	random\tagSEC_CONTENT	fields\tagSEC_CONTENT	,\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagSEC_CONTENT	Viterbi\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	best\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	new\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	were\tagSEC_CONTENT	obtained\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	generates\tagSEC_CONTENT	candidates\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	lookup\tagSEC_CONTENT	list\tagSEC_CONTENT	,\tagSEC_CONTENT	all\tagSEC_CONTENT	possible\tagSEC_CONTENT	splits\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	similarity\tagSEC_CONTENT	index\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	Jaccard\tagSEC_CONTENT	index\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	character\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	grams\tagSEC_CONTENT	and\tagSEC_CONTENT	character\tagSEC_CONTENT	skip\tagSEC_CONTENT	-\tagSEC_CONTENT	grams\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	novel\tagSEC_CONTENT	similarity\tagSEC_CONTENT	index\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	find\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	similar\tagSEC_CONTENT	candidates\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	compiled\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	golden\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	also\tagSEC_CONTENT	tests\tagSEC_CONTENT	if\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	beneficial\tagSEC_CONTENT	to\tagSEC_CONTENT	find\tagSEC_CONTENT	similar\tagSEC_CONTENT	candidates\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	concludes\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	over\tagtask	-\tagtask	normalization\tagtask	.\tagSEC_CONTENT	The\tagSEC_CONTENT	candidates\tagSEC_CONTENT	are\tagSEC_CONTENT	ranked\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	features\tagSEC_CONTENT	:\tagSEC_CONTENT	frequency\tagSEC_CONTENT	counts\tagSEC_CONTENT	in\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	similarity\tagSEC_CONTENT	index\tagSEC_CONTENT	and\tagSEC_CONTENT	POS\tagSEC_CONTENT	tagging\tagSEC_CONTENT	confidence\tagSEC_CONTENT	.\tagSEC_END	Most\tagSEC_START	of\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	English\tagSEC_CONTENT	language\tagSEC_CONTENT	,\tagSEC_CONTENT	although\tagSEC_CONTENT	there\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	some\tagSEC_CONTENT	work\tagSEC_CONTENT	on\tagSEC_CONTENT	other\tagSEC_CONTENT	languages\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	will\tagSEC_CONTENT	consider\tagSEC_CONTENT	normalization\tagtask	for\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	to\tagSEC_CONTENT	test\tagSEC_CONTENT	if\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	effective\tagSEC_CONTENT	for\tagSEC_CONTENT	other\tagSEC_CONTENT	languages\tagSEC_CONTENT	.\tagSEC_CONTENT	There\tagSEC_CONTENT	has\tagSEC_CONTENT	already\tagSEC_CONTENT	been\tagSEC_CONTENT	some\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	on\tagSEC_CONTENT	normalization\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	language\tagSEC_CONTENT	.\tagSEC_CONTENT	De\tagSEC_CONTENT	Clercq\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	2014b\tagSEC_CONTENT	)\tagSEC_CONTENT	annotated\tagSEC_CONTENT	a\tagSEC_CONTENT	normalization\tagSEC_CONTENT	corpus\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	three\tagSEC_CONTENT	user\tagSEC_CONTENT	generated\tagSEC_CONTENT	domains\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	experiment\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	data\tagSEC_CONTENT	with\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	and\tagSEC_CONTENT	character\tagSEC_CONTENT	level\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	report\tagSEC_CONTENT	a\tagSEC_CONTENT	20\tagSEC_CONTENT	%\tagSEC_CONTENT	gain\tagSEC_CONTENT	in\tagSEC_CONTENT	BLEU\tagSEC_CONTENT	score\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	tokenization\tagSEC_CONTENT	corrections\tagSEC_CONTENT	.\tagSEC_CONTENT	Building\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	built\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	modular\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	each\tagSEC_CONTENT	module\tagSEC_CONTENT	accounts\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	problems\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	:\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	modules\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	lookup\tagSEC_CONTENT	list\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	spellchecker\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	also\tagSEC_CONTENT	report\tagSEC_CONTENT	improved\tagSEC_CONTENT	results\tagSEC_CONTENT	for\tagSEC_CONTENT	extrinsic\tagSEC_CONTENT	evaluations\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	tasks\tagSEC_CONTENT	:\tagSEC_CONTENT	POS\tagSEC_CONTENT	tagging\tagSEC_CONTENT	,\tagSEC_CONTENT	lemmatization\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	entity\tagSEC_CONTENT	recognition\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	proposed\tagSEC_CONTENT	system\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	Jin\tagSEC_CONTENT	(\tagSEC_CONTENT	2015\tagSEC_CONTENT	)\tagSEC_CONTENT	;\tagSEC_CONTENT	however\tagSEC_CONTENT	,\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	many\tagSEC_CONTENT	differences\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	main\tagSEC_CONTENT	differences\tagSEC_CONTENT	are\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	generation\tagtask	and\tagSEC_CONTENT	include\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	grams\tagSEC_CONTENT	features\tagSEC_CONTENT	for\tagSEC_CONTENT	ranking\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	easily\tagSEC_CONTENT	be\tagSEC_CONTENT	obtained\tagSEC_CONTENT	from\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	makes\tagSEC_CONTENT	the\tagSEC_CONTENT	system\tagSEC_CONTENT	more\tagSEC_CONTENT	general\tagSEC_CONTENT	and\tagSEC_CONTENT	easier\tagSEC_CONTENT	adaptable\tagSEC_CONTENT	to\tagSEC_CONTENT	new\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	system\tagSEC_CONTENT	from\tagSEC_CONTENT	Jin\tagSEC_CONTENT	(\tagSEC_CONTENT	2015\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	focused\tagSEC_CONTENT	towards\tagSEC_CONTENT	the\tagSEC_CONTENT	given\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	might\tagSEC_CONTENT	have\tagSEC_CONTENT	more\tagSEC_CONTENT	difficulties\tagSEC_CONTENT	on\tagSEC_CONTENT	data\tagSEC_CONTENT	from\tagSEC_CONTENT	another\tagSEC_CONTENT	time\tagSEC_CONTENT	span\tagSEC_CONTENT	or\tagSEC_CONTENT	another\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_END	Data\tagSECTITLE_END	The\tagSEC_START	data\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	divided\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	parts\tagSEC_CONTENT	:\tagSEC_CONTENT	data\tagSEC_CONTENT	annotated\tagSEC_CONTENT	for\tagSEC_CONTENT	normalization\tagtask	,\tagSEC_CONTENT	and\tagSEC_CONTENT	other\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_END	Normalization\tagSECTITLE_START	Corpora\tagSECTITLE_END	The\tagSEC_START	normalization\tagtask	task\tagtask	can\tagSEC_CONTENT	be\tagSEC_CONTENT	seen\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	rather\tagSEC_CONTENT	subjective\tagSEC_CONTENT	task\tagSEC_CONTENT	;\tagSEC_CONTENT	the\tagSEC_CONTENT	annotators\tagSEC_CONTENT	are\tagSEC_CONTENT	asked\tagSEC_CONTENT	to\tagSEC_CONTENT	convert\tagSEC_CONTENT	noisy\tagSEC_CONTENT	texts\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	normal\tagSEC_CONTENT	'\tagSEC_CONTENT	language\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	annotation\tagSEC_CONTENT	guidelines\tagSEC_CONTENT	are\tagSEC_CONTENT	usually\tagSEC_CONTENT	quite\tagSEC_CONTENT	limited\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	leaving\tagSEC_CONTENT	space\tagSEC_CONTENT	for\tagSEC_CONTENT	interpretation\tagSEC_CONTENT	;\tagSEC_CONTENT	which\tagSEC_CONTENT	might\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	inconsistent\tagSEC_CONTENT	annotation\tagSEC_CONTENT	.\tagSEC_CONTENT	Pennell\tagSEC_CONTENT	and\tagSEC_CONTENT	Liu\tagSEC_CONTENT	 \tagSEC_CONTENT	need\tagSEC_CONTENT	of\tagSEC_CONTENT	normalization\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	also\tagSEC_CONTENT	shared\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	efforts\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	annotator\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	this\tagSEC_CONTENT	data\tagSEC_CONTENT	to\tagSEC_CONTENT	calculate\tagSEC_CONTENT	the\tagSEC_CONTENT	pairwise\tagSEC_CONTENT	human\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	choice\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	normalization\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	revealed\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	annotators\tagSEC_CONTENT	agree\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	choice\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	normalized\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	98.73\tagSEC_CONTENT	%\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	cases\tagSEC_CONTENT	.\tagSEC_END	Note\tagSEC_START	that\tagSEC_CONTENT	this\tagSEC_CONTENT	percentage\tagSEC_CONTENT	is\tagSEC_CONTENT	calculated\tagSEC_CONTENT	assuming\tagSEC_CONTENT	gold\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	.\tagSEC_CONTENT	report\tagSEC_CONTENT	a\tagSEC_CONTENT	Cohen\tagSEC_CONTENT	's\tagSEC_CONTENT	κ\tagSEC_CONTENT	of\tagSEC_CONTENT	0.5854\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagtask	complete\tagtask	normalization\tagtask	task\tagtask	,\tagSEC_CONTENT	a\tagSEC_CONTENT	lot\tagSEC_CONTENT	lower\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	.\tagSEC_CONTENT	Hence\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	conclude\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	inter\tagSEC_CONTENT	-\tagSEC_CONTENT	annotator\tagSEC_CONTENT	agreement\tagSEC_CONTENT	is\tagSEC_CONTENT	quite\tagSEC_CONTENT	dependent\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	guidelines\tagSEC_CONTENT	.\tagSEC_CONTENT	After\tagSEC_CONTENT	the\tagSEC_CONTENT	decision\tagSEC_CONTENT	whether\tagSEC_CONTENT	to\tagSEC_CONTENT	normalize\tagSEC_CONTENT	,\tagSEC_CONTENT	annotator\tagSEC_CONTENT	agreement\tagSEC_CONTENT	is\tagSEC_CONTENT	quite\tagSEC_CONTENT	high\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	choice\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	main\tagSEC_CONTENT	differences\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	corpora\tagSEC_CONTENT	are\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm1.2\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	contains\tagSEC_CONTENT	some\tagSEC_CONTENT	annotation\tagSEC_CONTENT	improvements\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	LexNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	GhentNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	only\tagSEC_CONTENT	corpus\tagSEC_CONTENT	fully\tagSEC_CONTENT	annotated\tagSEC_CONTENT	with\tagSEC_CONTENT	capitals\tagSEC_CONTENT	,\tagSEC_CONTENT	even\tagSEC_CONTENT	though\tagSEC_CONTENT	the\tagSEC_CONTENT	capital\tagSEC_CONTENT	-\tagSEC_CONTENT	use\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	corrected\tagSEC_CONTENT	;\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	preserved\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	utterance\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	multiword\tagSEC_CONTENT	column\tagSEC_CONTENT	represents\tagSEC_CONTENT	whether\tagSEC_CONTENT	1-N\tagSEC_CONTENT	and\tagSEC_CONTENT	N-1\tagSEC_CONTENT	replacements\tagSEC_CONTENT	are\tagSEC_CONTENT	included\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	guidelines\tagSEC_CONTENT	;\tagSEC_CONTENT	the\tagSEC_CONTENT	corpora\tagSEC_CONTENT	which\tagSEC_CONTENT	do\tagSEC_CONTENT	include\tagSEC_CONTENT	this\tagSEC_CONTENT	,\tagSEC_CONTENT	also\tagSEC_CONTENT	include\tagSEC_CONTENT	expansions\tagSEC_CONTENT	of\tagSEC_CONTENT	commonly\tagSEC_CONTENT	used\tagSEC_CONTENT	phrasal\tagSEC_CONTENT	abbreviations\tagSEC_CONTENT	as\tagSEC_CONTENT	'\tagSEC_CONTENT	lol\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	lmao\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	N-1\tagSEC_CONTENT	replacements\tagSEC_CONTENT	are\tagSEC_CONTENT	extremely\tagSEC_CONTENT	rare\tagSEC_CONTENT	.\tagSEC_CONTENT	There\tagSEC_CONTENT	is\tagSEC_CONTENT	some\tagSEC_CONTENT	difference\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	percentage\tagSEC_CONTENT	of\tagSEC_CONTENT	tokens\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	normalized\tagSEC_CONTENT	,\tagSEC_CONTENT	probably\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	differences\tagSEC_CONTENT	in\tagSEC_CONTENT	filtering\tagSEC_CONTENT	and\tagSEC_CONTENT	annotation\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	give\tagSEC_CONTENT	a\tagSEC_CONTENT	better\tagSEC_CONTENT	idea\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	nature\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	and\tagSEC_CONTENT	annotation\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	discuss\tagSEC_CONTENT	some\tagSEC_CONTENT	example\tagSEC_CONTENT	sentences\tagSEC_CONTENT	below\tagSEC_CONTENT	.\tagSEC_CONTENT	Example\tagSEC_CONTENT	2\tagSEC_CONTENT	comes\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	LiLiu\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	example\tagSEC_CONTENT	contains\tagSEC_CONTENT	two\tagSEC_CONTENT	replacements\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	replacements\tagSEC_CONTENT	are\tagSEC_CONTENT	subsequent\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	uncommon\tagSEC_CONTENT	;\tagSEC_CONTENT	this\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	problems\tagSEC_CONTENT	for\tagSEC_CONTENT	using\tagSEC_CONTENT	context\tagSEC_CONTENT	directly\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	replacement\tagSEC_CONTENT	'\tagSEC_CONTENT	b\tagSEC_CONTENT	'\tagSEC_CONTENT	→\tagSEC_CONTENT	'\tagSEC_CONTENT	be\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	grammatically\tagSEC_CONTENT	close\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	the\tagSEC_CONTENT	replacement\tagSEC_CONTENT	of\tagSEC_CONTENT	'\tagSEC_CONTENT	sumthn\tagSEC_CONTENT	'\tagSEC_CONTENT	→\tagSEC_CONTENT	'\tagSEC_CONTENT	something\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	distant\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	would\tagSEC_CONTENT	be\tagSEC_CONTENT	harder\tagSEC_CONTENT	to\tagSEC_CONTENT	solve\tagSEC_CONTENT	with\tagSEC_CONTENT	traditional\tagSEC_CONTENT	spelling\tagSEC_CONTENT	correction\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	.\tagSEC_CONTENT	Example\tagSEC_CONTENT	3\tagSEC_CONTENT	is\tagSEC_CONTENT	taken\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm2015\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	annotation\tagSEC_CONTENT	also\tagSEC_CONTENT	include\tagSEC_CONTENT	1-N\tagSEC_CONTENT	replacements\tagSEC_CONTENT	;\tagSEC_CONTENT	'\tagSEC_CONTENT	no1s\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	lol\tagSEC_CONTENT	'\tagSEC_CONTENT	are\tagSEC_CONTENT	expanded\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	'\tagSEC_CONTENT	no1s\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	splitted\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	contains\tagSEC_CONTENT	a\tagSEC_CONTENT	substitution\tagSEC_CONTENT	of\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	number\tagSEC_CONTENT	to\tagSEC_CONTENT	it\tagSEC_CONTENT	's\tagSEC_CONTENT	written\tagSEC_CONTENT	form\tagSEC_CONTENT	;\tagSEC_CONTENT	two\tagSEC_CONTENT	actions\tagSEC_CONTENT	are\tagSEC_CONTENT	necessary\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	contrast\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	here\tagSEC_CONTENT	the\tagSEC_CONTENT	token\tagSEC_CONTENT	'\tagSEC_CONTENT	lol\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	expanded\tagSEC_CONTENT	;\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	matter\tagSEC_CONTENT	of\tagSEC_CONTENT	differences\tagSEC_CONTENT	in\tagSEC_CONTENT	annotation\tagSEC_CONTENT	guidelines\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	annotator\tagSEC_CONTENT	decided\tagSEC_CONTENT	to\tagSEC_CONTENT	leave\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	'\tagSEC_CONTENT	wifey\tagSEC_CONTENT	'\tagSEC_CONTENT	as\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	it\tagSEC_CONTENT	could\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	normalized\tagSEC_CONTENT	to\tagSEC_CONTENT	wife\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	reflects\tagSEC_CONTENT	the\tagSEC_CONTENT	suggested\tagSEC_CONTENT	conservativity\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	guidelines\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Example\tagSEC_CONTENT	4\tagSEC_CONTENT	comes\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	GhentNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	word\tagSEC_CONTENT	'\tagSEC_CONTENT	ik\tagSEC_CONTENT	'\tagSEC_CONTENT	(\tagSEC_CONTENT	I\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	often\tagSEC_CONTENT	abbreviated\tagSEC_CONTENT	and\tagSEC_CONTENT	merged\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	verb\tagSEC_CONTENT	in\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	,\tagSEC_CONTENT	leading\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	kzal\tagSEC_CONTENT	'\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	correctly\tagSEC_CONTENT	splitted\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	ik\tagSEC_CONTENT	zal\tagSEC_CONTENT	'\tagSEC_CONTENT	(\tagSEC_CONTENT	I\tagSEC_CONTENT	will\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	no\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	probably\tagSEC_CONTENT	a\tagSEC_CONTENT	typographical\tagSEC_CONTENT	mistake\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	'\tagSEC_CONTENT	es\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	shortening\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	pronunciation\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm\tagSEC_CONTENT	2015\tagSEC_CONTENT	annotation\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	phrasal\tagSEC_CONTENT	abbreviation\tagSEC_CONTENT	'\tagSEC_CONTENT	lol\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	expanded\tagSEC_CONTENT	.\tagSEC_END	Other\tagSECTITLE_START	Data\tagSECTITLE_END	In\tagSEC_START	addition\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	use\tagSEC_CONTENT	some\tagSEC_CONTENT	external\tagSEC_CONTENT	data\tagSEC_CONTENT	for\tagSEC_CONTENT	our\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionaries\tagSEC_CONTENT	for\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	and\tagSEC_CONTENT	English\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	-\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	the\tagSEC_CONTENT	expansions\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	Furthermore\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	two\tagSEC_CONTENT	large\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	databases\tagSEC_CONTENT	;\tagSEC_CONTENT	one\tagSEC_CONTENT	with\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	one\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	canonical\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	Dutch\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	collection\tagSEC_CONTENT	of\tagSEC_CONTENT	1,545,871,819\tagSEC_CONTENT	unique\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	collected\tagSEC_CONTENT	between\tagSEC_CONTENT	2010\tagSEC_CONTENT	and\tagSEC_CONTENT	2016\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	were\tagSEC_CONTENT	collected\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	frequent\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	tokens\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	infrequent\tagSEC_CONTENT	in\tagSEC_CONTENT	other\tagSEC_CONTENT	languages\tagSEC_CONTENT	(\tagSEC_CONTENT	Tjong\tagSEC_CONTENT	Kim\tagSEC_CONTENT	Sang\tagSEC_CONTENT	and\tagSEC_CONTENT	van\tagSEC_CONTENT	den\tagSEC_CONTENT	Bosch\tagSEC_CONTENT	2013\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	English\tagSEC_CONTENT	we\tagSEC_CONTENT	collected\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	throughout\tagSEC_CONTENT	2016\tagSEC_CONTENT	,\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	100\tagSEC_CONTENT	most\tagSEC_CONTENT	frequent\tagSEC_CONTENT	words\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	Oxford\tagSEC_CONTENT	English\tagSEC_CONTENT	Corpus\tagSEC_CONTENT	3\tagSEC_CONTENT	,\tagSEC_CONTENT	resulting\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	dataset\tagSEC_CONTENT	of\tagSEC_CONTENT	760,744,676\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	some\tagmetric	preprocessing\tagmetric	to\tagSEC_CONTENT	reduce\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	types\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	smaller\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	thus\tagSEC_CONTENT	faster\tagSEC_CONTENT	processing\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	replace\tagSEC_CONTENT	usernames\tagSEC_CONTENT	and\tagSEC_CONTENT	urls\tagSEC_CONTENT	by\tagSEC_CONTENT	<\tagSEC_CONTENT	USERNAME\tagSEC_CONTENT	>\tagSEC_CONTENT	and\tagSEC_CONTENT	<\tagSEC_CONTENT	URL\tagSEC_CONTENT	>\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	canonical\tagSEC_CONTENT	raw\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	Wikipedia\tagSEC_CONTENT	dumps\tagSEC_CONTENT	4\tagSEC_CONTENT	for\tagSEC_CONTENT	both\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	and\tagSEC_CONTENT	English\tagSEC_CONTENT	.\tagSEC_END	Method\tagSECTITLE_END	The\tagSEC_START	normalization\tagtask	task\tagtask	can\tagSEC_CONTENT	be\tagSEC_CONTENT	split\tagSEC_CONTENT	into\tagSEC_CONTENT	two\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	tasks\tagSEC_CONTENT	:\tagSEC_END	•\tagSEC_START	Candidate\tagSEC_CONTENT	generation\tagSEC_CONTENT	:\tagSEC_CONTENT	generate\tagSEC_CONTENT	possible\tagtask	normalization\tagtask	candidates\tagtask	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_END	This\tagSEC_START	step\tagSEC_CONTENT	is\tagSEC_CONTENT	responsible\tagSEC_CONTENT	for\tagSEC_CONTENT	an\tagSEC_CONTENT	uppperbound\tagSEC_CONTENT	on\tagSEC_CONTENT	recall\tagmetric	;\tagSEC_CONTENT	but\tagSEC_CONTENT	care\tagSEC_CONTENT	should\tagSEC_CONTENT	also\tagSEC_CONTENT	betaken\tagSEC_CONTENT	to\tagSEC_CONTENT	not\tagSEC_CONTENT	generate\tagSEC_CONTENT	too\tagSEC_CONTENT	many\tagSEC_CONTENT	candidates\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	this\tagSEC_CONTENT	could\tagSEC_CONTENT	complicate\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Candidate\tagSEC_CONTENT	ranking\tagSEC_CONTENT	:\tagSEC_CONTENT	takes\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	candidate\tagSEC_CONTENT	list\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	tasks\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	tries\tagSEC_CONTENT	to\tagSEC_CONTENT	extract\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidate\tagSEC_CONTENT	by\tagSEC_CONTENT	ranking\tagSEC_CONTENT	the\tagSEC_CONTENT	candidates\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	our\tagSEC_CONTENT	setup\tagSEC_CONTENT	we\tagSEC_CONTENT	score\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	candidates\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	top\tagSEC_CONTENT	-\tagSEC_CONTENT	N\tagSEC_CONTENT	candidates\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	outputted\tagSEC_CONTENT	.\tagSEC_END	Most\tagSEC_START	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	includes\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	as\tagSEC_CONTENT	first\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	only\tagSEC_CONTENT	explores\tagSEC_CONTENT	the\tagSEC_CONTENT	possibilities\tagSEC_CONTENT	for\tagSEC_CONTENT	normalization\tagtask	of\tagSEC_CONTENT	words\tagSEC_CONTENT	detected\tagSEC_CONTENT	as\tagSEC_CONTENT	anomaly\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	postpone\tagSEC_CONTENT	this\tagSEC_CONTENT	decision\tagSEC_CONTENT	by\tagSEC_CONTENT	adding\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	informed\tagSEC_CONTENT	decision\tagSEC_CONTENT	whether\tagSEC_CONTENT	to\tagSEC_CONTENT	normalize\tagSEC_CONTENT	or\tagSEC_CONTENT	not\tagSEC_CONTENT	at\tagSEC_CONTENT	ranking\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	will\tagSEC_CONTENT	discuss\tagSEC_CONTENT	the\tagSEC_CONTENT	methods\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	tasks\tagSEC_CONTENT	separately\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	subsections\tagSEC_CONTENT	.\tagSEC_END	Candidate\tagSECTITLE_START	Generation\tagSECTITLE_END	We\tagSEC_START	use\tagSEC_CONTENT	different\tagSEC_CONTENT	modules\tagSEC_CONTENT	for\tagSEC_CONTENT	candidate\tagSEC_CONTENT	generation\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	module\tagSEC_CONTENT	is\tagSEC_CONTENT	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	different\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	anomaly\tagSEC_CONTENT	.\tagSEC_END	Original\tagSEC_START	token\tagSEC_CONTENT	Because\tagSEC_CONTENT	we\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	include\tagSEC_CONTENT	an\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	need\tagSEC_CONTENT	to\tagSEC_CONTENT	include\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	token\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	list\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	module\tagSEC_CONTENT	should\tagSEC_CONTENT	provide\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidate\tagSEC_CONTENT	in\tagSEC_CONTENT	90\tagSEC_CONTENT	%\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	cases\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	corpora\tagSEC_CONTENT	.\tagSEC_END	Word\tagSEC_START	embeddings\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	model\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	social\tagSEC_CONTENT	media\tagSEC_CONTENT	domain\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagmetric	3.2\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	we\tagSEC_CONTENT	find\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	40\tagSEC_CONTENT	closest\tagSEC_CONTENT	candidates\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	vector\tagSEC_CONTENT	space\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distance\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	train\tagSEC_CONTENT	a\tagSEC_CONTENT	skip\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	5\tagSEC_CONTENT	iterations\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	vector\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	400\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	window\tagSEC_CONTENT	of\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_END	Aspell\tagSEC_START	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	spellchecker\tagSEC_CONTENT	to\tagSEC_CONTENT	repair\tagSEC_CONTENT	typographical\tagSEC_CONTENT	errors\tagSEC_CONTENT	.\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	uses\tagSEC_CONTENT	a\tagtask	combination\tagtask	of\tagSEC_CONTENT	character\tagSEC_CONTENT	edit\tagSEC_CONTENT	distance\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	phonetic\tagSEC_CONTENT	distance\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	similar\tagSEC_CONTENT	looking\tagSEC_CONTENT	and\tagSEC_CONTENT	similar\tagSEC_CONTENT	sounding\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	will\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	normal\tagSEC_CONTENT	'\tagSEC_CONTENT	mode\tagSEC_CONTENT	as\tagSEC_CONTENT	default\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	experiment\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	-\tagSEC_CONTENT	spellers\tagSEC_CONTENT	'\tagSEC_CONTENT	mode\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	allows\tagSEC_CONTENT	for\tagSEC_CONTENT	candidates\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	larger\tagSEC_CONTENT	distance\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	resulting\tagSEC_CONTENT	in\tagSEC_CONTENT	much\tagSEC_CONTENT	bigger\tagSEC_CONTENT	candidate\tagSEC_CONTENT	lists\tagSEC_CONTENT	.\tagSEC_CONTENT	 \tagSEC_CONTENT	Lookup\tagSEC_CONTENT	-\tagSEC_CONTENT	list\tagSEC_CONTENT	We\tagSEC_CONTENT	generate\tagSEC_CONTENT	a\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	all\tagSEC_CONTENT	replacement\tagSEC_CONTENT	pairs\tagSEC_CONTENT	occurring\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	we\tagSEC_CONTENT	encounter\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	that\tagSEC_CONTENT	occurs\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	list\tagSEC_CONTENT	,\tagSEC_CONTENT	every\tagSEC_CONTENT	normalization\tagSEC_CONTENT	replacement\tagSEC_CONTENT	occurring\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	is\tagSEC_CONTENT	added\tagSEC_CONTENT	as\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_END	Word\tagSEC_START	.\tagSEC_CONTENT	*\tagSEC_CONTENT	As\tagSEC_CONTENT	a\tagSEC_CONTENT	result\tagSEC_CONTENT	of\tagSEC_CONTENT	space\tagmetric	restrictions\tagmetric	and\tagSEC_CONTENT	input\tagSEC_CONTENT	devices\tagSEC_CONTENT	native\tagSEC_CONTENT	to\tagSEC_CONTENT	this\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	users\tagSEC_CONTENT	often\tagSEC_CONTENT	use\tagSEC_CONTENT	abbreviated\tagSEC_CONTENT	versions\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	capture\tagSEC_CONTENT	this\tagSEC_CONTENT	phenomenon\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	include\tagSEC_CONTENT	a\tagSEC_CONTENT	generation\tagSEC_CONTENT	module\tagSEC_CONTENT	that\tagSEC_CONTENT	simply\tagSEC_CONTENT	searches\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	which\tagSEC_CONTENT	start\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	character\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	avoid\tagSEC_CONTENT	large\tagSEC_CONTENT	candidate\tagSEC_CONTENT	lists\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	only\tagSEC_CONTENT	activate\tagSEC_CONTENT	this\tagSEC_CONTENT	module\tagSEC_CONTENT	for\tagSEC_CONTENT	words\tagSEC_CONTENT	longer\tagSEC_CONTENT	than\tagSEC_CONTENT	two\tagSEC_CONTENT	characters\tagSEC_CONTENT	.\tagSEC_END	Split\tagSEC_START	We\tagSEC_CONTENT	generate\tagSEC_CONTENT	word\tagSEC_CONTENT	splits\tagSEC_CONTENT	by\tagSEC_CONTENT	splitting\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	on\tagSEC_CONTENT	every\tagSEC_CONTENT	possible\tagSEC_CONTENT	position\tagSEC_CONTENT	and\tagSEC_CONTENT	checking\tagSEC_CONTENT	if\tagSEC_CONTENT	both\tagSEC_CONTENT	resulting\tagSEC_CONTENT	words\tagSEC_CONTENT	are\tagSEC_CONTENT	canonical\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	avoid\tagSEC_CONTENT	over\tagSEC_CONTENT	-\tagSEC_CONTENT	generation\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	only\tagSEC_CONTENT	considered\tagSEC_CONTENT	for\tagSEC_CONTENT	input\tagSEC_CONTENT	words\tagSEC_CONTENT	larger\tagSEC_CONTENT	than\tagSEC_CONTENT	three\tagSEC_CONTENT	characters\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	illustrate\tagSEC_CONTENT	the\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	generation\tagSEC_CONTENT	modules\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	3\tagSEC_CONTENT	candidates\tagSEC_CONTENT	each\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	modules\tagSEC_CONTENT	generate\tagSEC_CONTENT	for\tagSEC_CONTENT	our\tagSEC_CONTENT	example\tagSEC_CONTENT	sentence\tagSEC_CONTENT	are\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	examples\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	multiple\tagSEC_CONTENT	modules\tagSEC_CONTENT	complement\tagSEC_CONTENT	each\tagSEC_CONTENT	other\tagSEC_CONTENT	rather\tagSEC_CONTENT	well\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	all\tagSEC_CONTENT	handle\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	anomalies\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	modules\tagSEC_CONTENT	are\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	separately\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagmetric	5.1\tagSEC_END	Candidate\tagSECTITLE_START	Ranking\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	section\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	first\tagSEC_CONTENT	describe\tagSEC_CONTENT	the\tagSEC_CONTENT	features\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	ranking\tagSEC_CONTENT	,\tagSEC_CONTENT	starting\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	features\tagSEC_CONTENT	which\tagSEC_CONTENT	originate\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	generation\tagSEC_CONTENT	step\tagSEC_CONTENT	.\tagSEC_CONTENT	After\tagSEC_CONTENT	this\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	discuss\tagSEC_CONTENT	the\tagSEC_CONTENT	used\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_END	Original\tagSEC_START	A\tagSEC_CONTENT	binary\tagSEC_CONTENT	feature\tagSEC_CONTENT	which\tagSEC_CONTENT	indicates\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	token\tagSEC_CONTENT	.\tagSEC_END	Word\tagSEC_START	embeddings\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distance\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	vector\tagSEC_CONTENT	space\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	feature\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	returned\tagSEC_CONTENT	list\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	feature\tagSEC_CONTENT	.\tagSEC_END	Aspell\tagSEC_START	Aspell\tagSEC_CONTENT	returns\tagSEC_CONTENT	a\tagSEC_CONTENT	ranked\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	correction\tagSEC_CONTENT	candidates\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	rank\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	list\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	feature\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	internal\tagSEC_CONTENT	calculated\tagSEC_CONTENT	distance\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	;\tagSEC_CONTENT	this\tagSEC_CONTENT	distance\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	lexical\tagtask	and\tagtask	phonetical\tagtask	edit\tagtask	distances\tagtask	.\tagSEC_CONTENT	The\tagSEC_CONTENT	internal\tagSEC_CONTENT	edit\tagSEC_CONTENT	distance\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	obtained\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	library\tagSEC_CONTENT	using\tagSEC_CONTENT	C++\tagSEC_CONTENT	function\tagSEC_CONTENT	calls\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	both\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	features\tagSEC_CONTENT	are\tagSEC_CONTENT	only\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	candidates\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_END	Lookup\tagSEC_START	-\tagSEC_CONTENT	list\tagSEC_CONTENT	In\tagSEC_CONTENT	our\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	we\tagSEC_CONTENT	count\tagSEC_CONTENT	the\tagSEC_CONTENT	occurrences\tagSEC_CONTENT	of\tagSEC_CONTENT	every\tagSEC_CONTENT	correction\tagSEC_CONTENT	pair\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	count\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	feature\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	include\tagSEC_CONTENT	counts\tagSEC_CONTENT	for\tagSEC_CONTENT	unchanged\tagSEC_CONTENT	pairs\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	;\tagSEC_CONTENT	this\tagSEC_CONTENT	strengthens\tagSEC_CONTENT	the\tagmetric	decision\tagmetric	whether\tagSEC_CONTENT	to\tagSEC_CONTENT	keep\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_END	Word\tagSEC_START	.\tagSEC_CONTENT	*\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	binary\tagSEC_CONTENT	feature\tagSEC_CONTENT	to\tagSEC_CONTENT	indicate\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	is\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	this\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_END	N\tagSEC_START	-\tagSEC_CONTENT	grams\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	models\tagSEC_CONTENT	from\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	calculate\tagSEC_CONTENT	the\tagSEC_CONTENT	unigram\tagSEC_CONTENT	probability\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	bigram\tagSEC_CONTENT	probability\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	bigram\tagSEC_CONTENT	probability\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	first\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	Twitter\tagSEC_CONTENT	data\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	more\tagSEC_CONTENT	canonical\tagSEC_CONTENT	Wikipedia\tagSEC_CONTENT	data\tagSEC_CONTENT	(\tagSEC_CONTENT	Section\tagmetric	3.2\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Dictionary\tagSEC_START	lookup\tagSEC_CONTENT	A\tagSEC_CONTENT	binary\tagSEC_CONTENT	feature\tagSEC_CONTENT	indicating\tagSEC_CONTENT	if\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	found\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	.\tagSEC_END	Character\tagSEC_START	order\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	include\tagSEC_CONTENT	a\tagSEC_CONTENT	binary\tagSEC_CONTENT	feature\tagSEC_CONTENT	indicating\tagSEC_CONTENT	if\tagSEC_CONTENT	the\tagSEC_CONTENT	characters\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	token\tagSEC_CONTENT	occur\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	order\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_END	Length\tagSEC_START	One\tagSEC_CONTENT	feature\tagSEC_CONTENT	indicates\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	one\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_END	ContainsAlpha\tagSEC_START	A\tagSEC_CONTENT	binary\tagSEC_CONTENT	feature\tagSEC_CONTENT	indicating\tagSEC_CONTENT	whether\tagSEC_CONTENT	a\tagSEC_CONTENT	token\tagSEC_CONTENT	contains\tagSEC_CONTENT	any\tagSEC_CONTENT	alphabetical\tagSEC_CONTENT	characters\tagSEC_CONTENT	;\tagSEC_CONTENT	in\tagSEC_CONTENT	some\tagSEC_CONTENT	annotation\tagSEC_CONTENT	guidelines\tagSEC_CONTENT	tokens\tagSEC_CONTENT	which\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	fit\tagSEC_CONTENT	this\tagSEC_CONTENT	restriction\tagSEC_CONTENT	are\tagSEC_CONTENT	kept\tagSEC_CONTENT	untouched\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	task\tagSEC_CONTENT	of\tagSEC_CONTENT	picking\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidate\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	seen\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	binary\tagSEC_CONTENT	classification\tagSEC_CONTENT	task\tagSEC_CONTENT	;\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	is\tagSEC_CONTENT	either\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidate\tagSEC_CONTENT	or\tagSEC_CONTENT	not\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	binary\tagSEC_CONTENT	classifier\tagSEC_CONTENT	directly\tagSEC_CONTENT	;\tagSEC_CONTENT	because\tagSEC_CONTENT	we\tagSEC_CONTENT	need\tagSEC_CONTENT	exactly\tagSEC_CONTENT	one\tagSEC_CONTENT	instance\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	correct\tagSEC_CONTENT	'\tagSEC_CONTENT	class\tagSEC_CONTENT	.\tagSEC_CONTENT	Whereas\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	might\tagSEC_CONTENT	classify\tagSEC_CONTENT	multiple\tagSEC_CONTENT	or\tagSEC_CONTENT	zero\tagSEC_CONTENT	candidates\tagSEC_CONTENT	per\tagSEC_CONTENT	position\tagmetric	as\tagSEC_CONTENT	correct\tagSEC_CONTENT	.\tagSEC_CONTENT	Instead\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	confidence\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	belongs\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	correct\tagSEC_CONTENT	'\tagSEC_CONTENT	class\tagSEC_CONTENT	to\tagSEC_CONTENT	rank\tagSEC_CONTENT	the\tagSEC_CONTENT	candidates\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	has\tagSEC_CONTENT	the\tagSEC_CONTENT	additional\tagSEC_CONTENT	advantage\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	enables\tagSEC_CONTENT	the\tagSEC_CONTENT	system\tagSEC_CONTENT	to\tagSEC_CONTENT	output\tagSEC_CONTENT	lists\tagSEC_CONTENT	of\tagSEC_CONTENT	top\tagSEC_CONTENT	-\tagSEC_CONTENT	N\tagSEC_CONTENT	candidates\tagSEC_CONTENT	for\tagSEC_CONTENT	use\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	pipeline\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	choose\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	of\tagSEC_CONTENT	candidates\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	choose\tagSEC_CONTENT	this\tagSEC_CONTENT	classifier\tagSEC_CONTENT	because\tagSEC_CONTENT	the\tagSEC_CONTENT	problem\tagSEC_CONTENT	of\tagSEC_CONTENT	normalization\tagtask	can\tagSEC_CONTENT	be\tagSEC_CONTENT	divided\tagSEC_CONTENT	in\tagSEC_CONTENT	multiple\tagSEC_CONTENT	normalization\tagSEC_CONTENT	actions\tagSEC_CONTENT	which\tagSEC_CONTENT	behave\tagSEC_CONTENT	differently\tagSEC_CONTENT	feature\tagSEC_CONTENT	wise\tagSEC_CONTENT	,\tagSEC_CONTENT	however\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	setup\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	all\tagSEC_CONTENT	classified\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	class\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	makes\tagSEC_CONTENT	decisions\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	multiple\tagSEC_CONTENT	trees\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	might\tagSEC_CONTENT	take\tagSEC_CONTENT	into\tagSEC_CONTENT	account\tagSEC_CONTENT	different\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	hypothesis\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	builds\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	trees\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	actions\tagSEC_CONTENT	.\tagSEC_CONTENT	More\tagSEC_CONTENT	concretely\tagSEC_CONTENT	:\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	scores\tagSEC_CONTENT	high\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	feature\tagSEC_CONTENT	(\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	low\tagSEC_CONTENT	edit\tagSEC_CONTENT	distance\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	can\tagSEC_CONTENT	bean\tagSEC_CONTENT	indicator\tagSEC_CONTENT	fora\tagSEC_CONTENT	specific\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	trees\tagSEC_CONTENT	to\tagSEC_CONTENT	give\tagSEC_CONTENT	this\tagSEC_CONTENT	candidate\tagSEC_CONTENT	a\tagSEC_CONTENT	high\tagSEC_CONTENT	score\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	still\tagSEC_CONTENT	give\tagSEC_CONTENT	very\tagSEC_CONTENT	high\tagSEC_CONTENT	scores\tagSEC_CONTENT	to\tagSEC_CONTENT	candidates\tagSEC_CONTENT	with\tagSEC_CONTENT	low\tagSEC_CONTENT	values\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	implementation\tagSEC_CONTENT	of\tagSEC_CONTENT	Ranger\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	default\tagSEC_CONTENT	parameters\tagSEC_CONTENT	.\tagSEC_CONTENT	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	might\tagSEC_CONTENT	have\tagSEC_CONTENT	a\tagSEC_CONTENT	negative\tagSEC_CONTENT	effect\tagSEC_CONTENT	on\tagSEC_CONTENT	performance\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	candidates\tagSEC_CONTENT	that\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	occur\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	this\tagSEC_CONTENT	reason\tagSEC_CONTENT	we\tagSEC_CONTENT	add\tagSEC_CONTENT	an\tagSEC_CONTENT	option\tagSEC_CONTENT	to\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	to\tagSEC_CONTENT	filter\tagSEC_CONTENT	candidates\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	list\tagSEC_CONTENT	generated\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	we\tagSEC_CONTENT	add\tagSEC_CONTENT	an\tagSEC_CONTENT	option\tagSEC_CONTENT	to\tagSEC_CONTENT	filter\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	words\tagSEC_CONTENT	occurring\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	complemented\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	;\tagSEC_CONTENT	these\tagSEC_CONTENT	settings\tagSEC_CONTENT	are\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	in\tagSEC_CONTENT	more\tagSEC_CONTENT	detail\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	5.3\tagSEC_CONTENT	.\tagSEC_END	Evaluation\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	different\tagSEC_CONTENT	aspects\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagtask	normalization\tagtask	systems\tagtask	.\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	:\tagSEC_END	•\tagSEC_START	LexNorm1.2\tagSEC_CONTENT	:\tagSEC_CONTENT	for\tagSEC_CONTENT	testing\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	LexNorm\tagdataset	corpus\tagdataset	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	2,000\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	from\tagSEC_CONTENT	LiLiu\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	Section\tagmetric	3.1\tagSEC_CONTENT	)\tagSEC_CONTENT	as\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	577\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	as\tagSEC_CONTENT	development\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	   \tagSEC_CONTENT	•\tagdataset	LexNorm2015\tagdataset	:\tagSEC_CONTENT	Consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	2,950\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	1,967\tagSEC_CONTENT	for\tagSEC_CONTENT	testing\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	950\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	as\tagSEC_CONTENT	development\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	GhentNorm\tagdataset	:\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	previous\tagmetric	work\tagmetric	,\tagSEC_CONTENT	we\tagSEC_CONTENT	split\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	in\tagSEC_CONTENT	60\tagSEC_CONTENT	%\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	both\tagSEC_CONTENT	20\tagSEC_CONTENT	%\tagSEC_CONTENT	development\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	all\tagSEC_CONTENT	these\tagSEC_CONTENT	three\tagSEC_CONTENT	datasets\tagSEC_CONTENT	we\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	modules\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	generation\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagtask	evaluation\tagtask	in\tagSEC_CONTENT	this\tagSEC_CONTENT	section\tagSEC_CONTENT	is\tagSEC_CONTENT	done\tagSEC_CONTENT	with\tagSEC_CONTENT	all\tagSEC_CONTENT	words\tagSEC_CONTENT	lowercased\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	inline\tagSEC_CONTENT	with\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	and\tagSEC_CONTENT	capitalization\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	consistently\tagSEC_CONTENT	annotated\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	available\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_END	Candidate\tagSECTITLE_START	Generation\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	section\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	first\tagSEC_CONTENT	compare\tagSEC_CONTENT	each\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	modules\tagSEC_CONTENT	in\tagSEC_CONTENT	isolation\tagtask	.\tagSEC_CONTENT	Next\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	test\tagSEC_CONTENT	how\tagSEC_CONTENT	many\tagSEC_CONTENT	unique\tagSEC_CONTENT	correct\tagSEC_CONTENT	normalization\tagSEC_CONTENT	candidates\tagSEC_CONTENT	each\tagSEC_CONTENT	module\tagSEC_CONTENT	contributes\tagSEC_CONTENT	in\tagSEC_CONTENT	an\tagSEC_CONTENT	ablation\tagSEC_CONTENT	experiment\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	recall\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	generation\tagSEC_CONTENT	modules\tagSEC_CONTENT	in\tagSEC_CONTENT	isolation\tagSEC_CONTENT	are\tagSEC_CONTENT	plotted\tagSEC_CONTENT	in\tagSEC_CONTENT	;\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	candidates\tagSEC_CONTENT	each\tagSEC_CONTENT	module\tagSEC_CONTENT	generates\tagSEC_CONTENT	on\tagSEC_CONTENT	average\tagSEC_CONTENT	overall\tagSEC_CONTENT	datasets\tagSEC_CONTENT	is\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	best\tagSEC_CONTENT	performing\tagSEC_CONTENT	modules\tagSEC_CONTENT	in\tagSEC_CONTENT	isolation\tagSEC_CONTENT	are\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	lookup\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	lookup\tagSEC_CONTENT	module\tagSEC_CONTENT	performs\tagSEC_CONTENT	especially\tagSEC_CONTENT	well\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm2015\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	couple\tagSEC_CONTENT	of\tagSEC_CONTENT	correction\tagSEC_CONTENT	pairs\tagSEC_CONTENT	which\tagSEC_CONTENT	occur\tagSEC_CONTENT	very\tagSEC_CONTENT	frequently\tagSEC_CONTENT	(\tagSEC_CONTENT	u\tagSEC_CONTENT	,\tagSEC_CONTENT	lol\tagSEC_CONTENT	,\tagSEC_CONTENT	idk\tagSEC_CONTENT	,\tagSEC_CONTENT	bro\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	*\tagSEC_CONTENT	module\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	perform\tagSEC_CONTENT	very\tagSEC_CONTENT	well\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	over\tagSEC_CONTENT	-\tagSEC_CONTENT	generates\tagSEC_CONTENT	mainly\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	GhentNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	(\tagSEC_CONTENT	average\tagSEC_CONTENT	of\tagSEC_CONTENT	48\tagSEC_CONTENT	candidates\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	split\tagSEC_CONTENT	module\tagSEC_CONTENT	can\tagSEC_CONTENT	only\tagSEC_CONTENT	generate\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidates\tagSEC_CONTENT	for\tagSEC_CONTENT	corpora\tagSEC_CONTENT	that\tagSEC_CONTENT	contain\tagSEC_CONTENT	1-n\tagSEC_CONTENT	word\tagSEC_CONTENT	replacements\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	these\tagSEC_CONTENT	corpora\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	generates\tagSEC_CONTENT	a\tagSEC_CONTENT	few\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidates\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	performances\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	ablation\tagSEC_CONTENT	experiments\tagSEC_CONTENT	are\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	experiment\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	modules\tagSEC_CONTENT	are\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	lookup\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	contribute\tagSEC_CONTENT	less\tagSEC_CONTENT	unique\tagSEC_CONTENT	candidates\tagSEC_CONTENT	;\tagSEC_CONTENT	presumably\tagSEC_CONTENT	because\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	overlap\tagSEC_CONTENT	:\tagSEC_CONTENT	Recall\tagmetric	achieved\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	-\tagSEC_CONTENT	N\tagSEC_CONTENT	candidates\tagSEC_CONTENT	for\tagSEC_CONTENT	our\tagSEC_CONTENT	different\tagSEC_CONTENT	development\tagSEC_CONTENT	data\tagSEC_CONTENT	sets\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	overall\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	also\tagSEC_CONTENT	words\tagSEC_CONTENT	not\tagSEC_CONTENT	needing\tagSEC_CONTENT	normalization\tagtask	.\tagSEC_END	with\tagSEC_START	both\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	modules\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	differences\tagSEC_CONTENT	between\tagSEC_CONTENT	corpora\tagSEC_CONTENT	are\tagSEC_CONTENT	also\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	experiment\tagSEC_CONTENT	;\tagSEC_CONTENT	the\tagSEC_CONTENT	lookup\tagSEC_CONTENT	list\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	generating\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	unique\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidates\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagdataset	LexNorm2015\tagdataset	corpus\tagdataset	.\tagSEC_CONTENT	Furthermore\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	graph\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	*\tagSEC_CONTENT	still\tagSEC_CONTENT	generates\tagSEC_CONTENT	some\tagSEC_CONTENT	unique\tagSEC_CONTENT	candidates\tagSEC_CONTENT	,\tagSEC_CONTENT	especially\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	GhentNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	suggests\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	way\tagSEC_CONTENT	of\tagSEC_CONTENT	abbreviating\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	common\tagSEC_CONTENT	in\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	.\tagSEC_END	Candidate\tagSECTITLE_START	Ranking\tagSECTITLE_END	Since\tagSEC_START	candidate\tagSEC_CONTENT	ranking\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	section\tagSEC_CONTENT	discusses\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	whole\tagSEC_CONTENT	system\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	compare\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	system\tagSEC_CONTENT	with\tagSEC_CONTENT	different\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	we\tagSEC_CONTENT	consider\tagSEC_CONTENT	the\tagdataset	LexNorm\tagdataset	corpus\tagdataset	,\tagSEC_CONTENT	for\tagSEC_CONTENT	which\tagSEC_CONTENT	most\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	assumed\tagSEC_CONTENT	gold\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	our\tagSEC_CONTENT	results\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	assume\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	test\tagSEC_CONTENT	our\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	LexNorm2015\tagdataset	,\tagSEC_CONTENT	which\tagSEC_CONTENT	was\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	shared\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	2015\tagSEC_CONTENT	workshop\tagSEC_CONTENT	on\tagSEC_CONTENT	Noisy\tagSEC_CONTENT	User\tagSEC_CONTENT	-\tagSEC_CONTENT	generated\tagSEC_CONTENT	Text\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	,\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	was\tagSEC_CONTENT	included\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	hence\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	also\tagSEC_CONTENT	use\tagSEC_CONTENT	automatic\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	by\tagSEC_CONTENT	including\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	token\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	importance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	feature\tagSEC_CONTENT	groups\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	LiLiu\tagSEC_CONTENT	development\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	feature\tagSEC_CONTENT	for\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	Except\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	split\tagSEC_CONTENT	module\tagSEC_CONTENT	(\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	included\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	annotation\tagSEC_CONTENT	)\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	features\tagSEC_CONTENT	contribute\tagSEC_CONTENT	to\tagSEC_CONTENT	obtaining\tagSEC_CONTENT	the\tagSEC_CONTENT	highest\tagSEC_CONTENT	score\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	F1\tagSEC_CONTENT	scores\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	ablation\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm2015\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	setup\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	differences\tagSEC_CONTENT	are\tagSEC_CONTENT	smaller\tagSEC_CONTENT	,\tagSEC_CONTENT	except\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	lookup\tagSEC_CONTENT	module\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	generates\tagSEC_CONTENT	many\tagSEC_CONTENT	unique\tagSEC_CONTENT	phrasal\tagSEC_CONTENT	abbreviations\tagSEC_CONTENT	(\tagSEC_CONTENT	lol\tagSEC_CONTENT	,\tagSEC_CONTENT	idk\tagSEC_CONTENT	,\tagSEC_CONTENT	smh\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Perhaps\tagSEC_CONTENT	surprisingly\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	show\tagSEC_CONTENT	a\tagSEC_CONTENT	relatively\tagSEC_CONTENT	small\tagSEC_CONTENT	effect\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	module\tagSEC_CONTENT	proves\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	very\tagSEC_CONTENT	valuable\tagSEC_CONTENT	for\tagSEC_CONTENT	this\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	beyond\tagSEC_CONTENT	the\tagSEC_CONTENT	top-1\tagSEC_CONTENT	candidate\tagSEC_CONTENT	,\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	recall\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	-\tagSEC_CONTENT	N\tagSEC_CONTENT	candidates\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	table\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	most\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	mistakes\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	makes\tagSEC_CONTENT	are\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	candidate\tagSEC_CONTENT	.\tagSEC_CONTENT	Manual\tagSEC_CONTENT	inspection\tagSEC_CONTENT	revealed\tagSEC_CONTENT	that\tagSEC_CONTENT	many\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	are\tagSEC_CONTENT	confusions\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	token\tagSEC_CONTENT	;\tagSEC_CONTENT	thus\tagSEC_CONTENT	the\tagSEC_CONTENT	decision\tagSEC_CONTENT	whether\tagSEC_CONTENT	normalization\tagSEC_CONTENT	is\tagSEC_CONTENT	necessary\tagSEC_CONTENT	at\tagSEC_CONTENT	all\tagSEC_CONTENT	.\tagSEC_CONTENT	Beyond\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	candidate\tagSEC_CONTENT	,\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	only\tagSEC_CONTENT	a\tagSEC_CONTENT	few\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidates\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	found\tagSEC_CONTENT	.\tagSEC_END	Additional\tagSECTITLE_START	Experiments\tagSECTITLE_END	We\tagSEC_START	test\tagSEC_CONTENT	the\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	largest\tagSEC_CONTENT	datasets\tagSEC_CONTENT	:\tagSEC_CONTENT	LiLiu\tagSEC_CONTENT	and\tagSEC_CONTENT	LexNorm2015\tagdataset	.\tagSEC_CONTENT	The\tagSEC_CONTENT	results\tagSEC_CONTENT	are\tagSEC_CONTENT	plotted\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	higher\tagSEC_CONTENT	F1\tagSEC_CONTENT	scores\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm2015\tagSEC_CONTENT	dataset\tagSEC_CONTENT	are\tagSEC_CONTENT	probably\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	common\tagSEC_CONTENT	phrasal\tagSEC_CONTENT	abbreviations\tagSEC_CONTENT	.\tagSEC_CONTENT	Based\tagSEC_CONTENT	on\tagSEC_CONTENT	these\tagSEC_CONTENT	graphs\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	conclude\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	reasonable\tagSEC_CONTENT	performance\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	achieved\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	around\tagSEC_CONTENT	500\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	still\tagSEC_CONTENT	improves\tagSEC_CONTENT	at\tagSEC_CONTENT	a\tagSEC_CONTENT	training\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	2,000\tagSEC_CONTENT	Tweets\tagSEC_CONTENT	.\tagSEC_END	As\tagSEC_START	explained\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagmetric	4\tagSEC_CONTENT	we\tagSEC_CONTENT	included\tagSEC_CONTENT	two\tagSEC_CONTENT	options\tagSEC_CONTENT	to\tagSEC_CONTENT	tune\tagSEC_CONTENT	the\tagSEC_CONTENT	speed\tagSEC_CONTENT	-\tagSEC_CONTENT	performance\tagSEC_CONTENT	ratio\tagSEC_CONTENT	.\tagSEC_CONTENT	Firstly\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	allow\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	larger\tagSEC_CONTENT	lists\tagSEC_CONTENT	of\tagSEC_CONTENT	candidates\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	-\tagSEC_CONTENT	spellers\tagSEC_CONTENT	'\tagSEC_CONTENT	mode\tagSEC_CONTENT	.\tagSEC_CONTENT	Secondly\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	filter\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	candidates\tagSEC_CONTENT	,\tagSEC_CONTENT	keeping\tagSEC_CONTENT	only\tagSEC_CONTENT	candidates\tagSEC_CONTENT	which\tagSEC_CONTENT	occur\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	or\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	times\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	combinations\tagSEC_CONTENT	of\tagSEC_CONTENT	parameters\tagSEC_CONTENT	take\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	and\tagSEC_CONTENT	run\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	LexNorm2015\tagdataset	dataset\tagdataset	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	candidates\tagSEC_CONTENT	generated\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	best\tagSEC_CONTENT	performance\tagSEC_CONTENT	is\tagSEC_CONTENT	achieved\tagSEC_CONTENT	by\tagSEC_CONTENT	filtering\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	words\tagSEC_CONTENT	occurring\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	combined\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	Aspell\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	and\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	normal\tagSEC_CONTENT	'\tagSEC_CONTENT	mode\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	-\tagSEC_CONTENT	spellers\tagSEC_CONTENT	'\tagSEC_CONTENT	mode\tagSEC_CONTENT	without\tagSEC_CONTENT	filtering\tagSEC_CONTENT	reaches\tagSEC_CONTENT	on\tagSEC_CONTENT	par\tagSEC_CONTENT	performance\tagSEC_CONTENT	and\tagSEC_CONTENT	might\tagSEC_CONTENT	be\tagSEC_CONTENT	the\tagSEC_CONTENT	preferable\tagSEC_CONTENT	option\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	it\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	more\tagSEC_CONTENT	robust\tagSEC_CONTENT	to\tagSEC_CONTENT	data\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	different\tagSEC_CONTENT	time\tagSEC_CONTENT	period\tagSEC_CONTENT	or\tagSEC_CONTENT	different\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	:\tagSEC_CONTENT	Results\tagSEC_CONTENT	on\tagSEC_CONTENT	test\tagSEC_CONTENT	data\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	.\tagSEC_END	Aspell\tagSECTITLE_START	mode\tagSECTITLE_CONTENT	Filter\tagSECTITLE_END	Test\tagSECTITLE_START	Data\tagSECTITLE_END	The\tagSEC_START	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	system\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	data\tagSEC_CONTENT	sets\tagSEC_CONTENT	is\tagSEC_CONTENT	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	existing\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	systems\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	different\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	metrics\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	with\tagSEC_CONTENT	previous\tagmetric	work\tagmetric	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm1.2\tagSEC_CONTENT	corpus\tagSEC_CONTENT	we\tagSEC_CONTENT	assume\tagSEC_CONTENT	gold\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	,\tagSEC_CONTENT	inline\tagSEC_CONTENT	with\tagSEC_CONTENT	previous\tagmetric	work\tagmetric	;\tagSEC_CONTENT	for\tagSEC_CONTENT	more\tagSEC_CONTENT	details\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	metrics\tagSEC_CONTENT	we\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	papers\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	settings\tagSEC_CONTENT	;\tagSEC_CONTENT	meaning\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	-\tagSEC_CONTENT	spellers\tagSEC_CONTENT	'\tagSEC_CONTENT	mode\tagSEC_CONTENT	,\tagSEC_CONTENT	no\tagSEC_CONTENT	filtering\tagSEC_CONTENT	and\tagSEC_CONTENT	including\tagSEC_CONTENT	all\tagSEC_CONTENT	feature\tagSEC_CONTENT	groups\tagSEC_CONTENT	.\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	reaches\tagSEC_CONTENT	anew\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	difference\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	LexNorm\tagdataset	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	rather\tagSEC_CONTENT	small\tagSEC_CONTENT	;\tagSEC_CONTENT	however\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	much\tagSEC_CONTENT	simpler\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	ensemble\tagSEC_CONTENT	system\tagSEC_CONTENT	used\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	performance\tagSEC_CONTENT	gap\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	LexNorm2015\tagSEC_CONTENT	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	bit\tagSEC_CONTENT	bigger\tagSEC_CONTENT	,\tagSEC_CONTENT	showing\tagSEC_CONTENT	that\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	doing\tagSEC_CONTENT	well\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	error\tagSEC_CONTENT	detection\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	Word\tagSEC_CONTENT	Error\tagSEC_CONTENT	Rate\tagSEC_CONTENT	(\tagSEC_CONTENT	WER\tagSEC_CONTENT	)\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Dutch\tagSEC_CONTENT	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	lower\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	directly\tagSEC_CONTENT	comparable\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	different\tagSEC_CONTENT	random\tagSEC_CONTENT	splits\tagSEC_CONTENT	.\tagSEC_END	Additionally\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	report\tagSEC_CONTENT	the\tagSEC_CONTENT	recall\tagSEC_CONTENT	,\tagSEC_CONTENT	precision\tagSEC_CONTENT	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	these\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	metrics\tagSEC_CONTENT	because\tagSEC_CONTENT	it\tagSEC_CONTENT	allows\tagSEC_CONTENT	fora\tagSEC_CONTENT	direct\tagSEC_CONTENT	interpretation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	and\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	inline\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	default\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	recent\tagSEC_CONTENT	dataset\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	first\tagSEC_CONTENT	categorize\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	as\tagSEC_CONTENT	follows\tagSEC_CONTENT	:\tagSEC_END	T\tagSEC_START	P\tagSEC_CONTENT	=\tagSEC_CONTENT	annotators\tagSEC_CONTENT	normalized\tagSEC_CONTENT	,\tagSEC_CONTENT	systems\tagSEC_CONTENT	ranks\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	candidate\tagSEC_CONTENT	highest\tagSEC_CONTENT	F\tagSEC_CONTENT	P\tagSEC_CONTENT	=\tagSEC_CONTENT	annotators\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	normalize\tagSEC_CONTENT	,\tagSEC_CONTENT	system\tagSEC_CONTENT	normalized\tagSEC_CONTENT	TN\tagSEC_CONTENT	=\tagSEC_CONTENT	annotators\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	normalize\tagSEC_CONTENT	,\tagSEC_CONTENT	system\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	normalize\tagSEC_CONTENT	F\tagSEC_CONTENT	N\tagSEC_CONTENT	=\tagSEC_CONTENT	annotators\tagSEC_CONTENT	normalized\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	system\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	normalize\tagSEC_CONTENT	Then\tagSEC_CONTENT	we\tagSEC_CONTENT	calculate\tagSEC_CONTENT	recall\tagSEC_CONTENT	,\tagSEC_CONTENT	precision\tagSEC_CONTENT	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	:\tagSEC_END	Recall+P\tagSECTITLE_START	recision\tagSECTITLE_END	The\tagSEC_START	results\tagSEC_CONTENT	are\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	;\tagSEC_CONTENT	our\tagSEC_CONTENT	system\tagSEC_CONTENT	scores\tagSEC_CONTENT	better\tagSEC_CONTENT	on\tagSEC_CONTENT	precision\tagmetric	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	recall\tagSEC_CONTENT	.\tagSEC_CONTENT	Arguably\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	desirable\tagSEC_CONTENT	result\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	we\tagSEC_CONTENT	want\tagSEC_CONTENT	to\tagSEC_CONTENT	avoid\tagSEC_CONTENT	over\tagtask	-\tagtask	normalization\tagtask	.\tagSEC_CONTENT	For\tagSEC_CONTENT	cases\tagSEC_CONTENT	where\tagSEC_CONTENT	high\tagSEC_CONTENT	recall\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	important\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	introduce\tagSEC_CONTENT	a\tagSEC_CONTENT	weight\tagSEC_CONTENT	parameter\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	token\tagSEC_CONTENT	;\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	way\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	control\tagSEC_CONTENT	the\tagSEC_CONTENT	aggressiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	tuning\tagSEC_CONTENT	this\tagSEC_CONTENT	weight\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	result\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	higher\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	scores\tagSEC_CONTENT	lower\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	GhentNorm\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	partly\tagSEC_CONTENT	an\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	having\tagSEC_CONTENT	less\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	explain\tagSEC_CONTENT	the\tagSEC_CONTENT	complete\tagSEC_CONTENT	performance\tagSEC_CONTENT	difference\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	other\tagSEC_CONTENT	explaining\tagSEC_CONTENT	factors\tagSEC_CONTENT	include\tagSEC_CONTENT	differences\tagSEC_CONTENT	in\tagSEC_CONTENT	language\tagSEC_CONTENT	and\tagSEC_CONTENT	annotation\tagSEC_CONTENT	.\tagSEC_CONTENT	:\tagSEC_CONTENT	Recall\tagSEC_CONTENT	,\tagSEC_CONTENT	Precision\tagSEC_CONTENT	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	test\tagSEC_CONTENT	sets\tagSEC_CONTENT	.\tagSEC_END	Extrinsic\tagSECTITLE_START	Evaluation\tagSECTITLE_END	To\tagSEC_START	test\tagSEC_CONTENT	if\tagSEC_CONTENT	this\tagtask	normalization\tagtask	model\tagtask	can\tagSEC_CONTENT	be\tagSEC_CONTENT	useful\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	domain\tagSEC_CONTENT	adaptation\tagSEC_CONTENT	setup\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	it\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	step\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	Berkeley\tagSEC_CONTENT	parser\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	resulting\tagSEC_CONTENT	best\tagSEC_CONTENT	normalization\tagSEC_CONTENT	sequence\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	experimented\tagSEC_CONTENT	with\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	-\tagSEC_CONTENT	n\tagSEC_CONTENT	candidates\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	observed\tagSEC_CONTENT	an\tagSEC_CONTENT	improvement\tagSEC_CONTENT	in\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	of\tagSEC_CONTENT	0.68\tagSEC_CONTENT	%\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	Twitter\tagSEC_CONTENT	treebank\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	when\tagSEC_CONTENT	using\tagSEC_CONTENT	only\tagtask	the\tagtask	best\tagtask	normalization\tagtask	sequence\tagtask	and\tagSEC_CONTENT	a\tagSEC_CONTENT	grammar\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	more\tagSEC_CONTENT	canonical\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	Whereas\tagSEC_CONTENT	,\tagSEC_CONTENT	giving\tagSEC_CONTENT	the\tagSEC_CONTENT	parser\tagSEC_CONTENT	access\tagSEC_CONTENT	to\tagSEC_CONTENT	more\tagSEC_CONTENT	candidates\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	an\tagSEC_CONTENT	improvement\tagSEC_CONTENT	of\tagSEC_CONTENT	1.26\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	Twitter\tagSEC_CONTENT	treebank\tagSEC_CONTENT	is\tagSEC_CONTENT	less\tagSEC_CONTENT	noisy\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	our\tagSEC_CONTENT	normalization\tagSEC_CONTENT	corpora\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	makes\tagSEC_CONTENT	the\tagSEC_CONTENT	effects\tagSEC_CONTENT	of\tagSEC_CONTENT	normalization\tagSEC_CONTENT	smaller\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	more\tagSEC_CONTENT	details\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	experiment\tagSEC_CONTENT	we\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	paper\tagSEC_CONTENT	(\tagSEC_CONTENT	van\tagSEC_CONTENT	der\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Additionally\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	tested\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	POS\tagSEC_CONTENT	tagger\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	train\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	datasets\tagSEC_CONTENT	from\tagSEC_CONTENT	from\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	model\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagmetric	3.2\tagSEC_CONTENT	to\tagSEC_CONTENT	initialize\tagSEC_CONTENT	Bilty\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	character\tagSEC_CONTENT	level\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	POS\tagSEC_CONTENT	tagging\tagSEC_CONTENT	model\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	already\tagSEC_CONTENT	adapted\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	domain\tagSEC_CONTENT	to\tagSEC_CONTENT	some\tagSEC_CONTENT	extent\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	as\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	still\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	an\tagSEC_CONTENT	improvement\tagSEC_CONTENT	inaccuracy\tagSEC_CONTENT	from\tagSEC_CONTENT	88.53\tagSEC_CONTENT	to\tagSEC_CONTENT	89.63\tagSEC_CONTENT	and\tagSEC_CONTENT	90.02\tagSEC_CONTENT	to\tagSEC_CONTENT	90.25\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	test\tagSEC_CONTENT	sets\tagSEC_CONTENT	.\tagSEC_CONTENT	More\tagSEC_CONTENT	details\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	found\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	paper\tagSEC_CONTENT	(\tagSEC_CONTENT	van\tagSEC_CONTENT	der\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Conclusion\tagSECTITLE_END	We\tagSEC_START	have\tagSEC_CONTENT	proposed\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	;\tagSEC_CONTENT	a\tagtask	universal\tagtask	,\tagtask	modular\tagtask	normalization\tagtask	model\tagtask	,\tagSEC_CONTENT	which\tagSEC_CONTENT	beats\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	ofthe\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	on\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	easily\tagSEC_CONTENT	extendable\tagSEC_CONTENT	with\tagSEC_CONTENT	new\tagSEC_CONTENT	modules\tagSEC_CONTENT	,\tagSEC_CONTENT	although\tagSEC_CONTENT	the\tagSEC_CONTENT	existing\tagSEC_CONTENT	modules\tagSEC_CONTENT	should\tagSEC_CONTENT	cover\tagSEC_CONTENT	most\tagSEC_CONTENT	cases\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	normalization\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	reaches\tagSEC_CONTENT	anew\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	different\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	,\tagSEC_CONTENT	proving\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	can\tagSEC_CONTENT	generalize\tagSEC_CONTENT	over\tagSEC_CONTENT	different\tagSEC_CONTENT	annotation\tagSEC_CONTENT	efforts\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	more\tagSEC_CONTENT	detailed\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	traditional\tagSEC_CONTENT	spelling\tagSEC_CONTENT	correction\tagSEC_CONTENT	complemented\tagSEC_CONTENT	with\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	combine\tagSEC_CONTENT	to\tagSEC_CONTENT	provide\tagSEC_CONTENT	robust\tagSEC_CONTENT	candidate\tagSEC_CONTENT	generation\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	normalization\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	If\tagSEC_CONTENT	the\tagSEC_CONTENT	expansion\tagSEC_CONTENT	of\tagSEC_CONTENT	common\tagSEC_CONTENT	phrasal\tagSEC_CONTENT	abbreviations\tagSEC_CONTENT	like\tagSEC_CONTENT	'\tagSEC_CONTENT	lol\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	lmao\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	included\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	lookup\tagSEC_CONTENT	list\tagSEC_CONTENT	is\tagSEC_CONTENT	necessary\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	competitive\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	conclude\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	can\tagSEC_CONTENT	learn\tagSEC_CONTENT	to\tagSEC_CONTENT	generalize\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	normalization\tagSEC_CONTENT	actions\tagSEC_CONTENT	quite\tagSEC_CONTENT	well\tagSEC_CONTENT	.\tagSEC_CONTENT	Besides\tagSEC_CONTENT	the\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	generation\tagSEC_CONTENT	,\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	features\tagSEC_CONTENT	prove\tagSEC_CONTENT	to\tagSEC_CONTENT	bean\tagSEC_CONTENT	important\tagSEC_CONTENT	predictor\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_END	Future\tagSEC_START	work\tagSEC_CONTENT	includes\tagSEC_CONTENT	more\tagtask	exploration\tagtask	concerning\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	word\tagSEC_CONTENT	normalizations\tagSEC_CONTENT	,\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	on\tagSEC_CONTENT	different\tagSEC_CONTENT	domains\tagSEC_CONTENT	and\tagSEC_CONTENT	languages\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	in\tagSEC_CONTENT	-\tagSEC_CONTENT	depth\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	replacements\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	usefulness\tagSEC_CONTENT	of\tagSEC_CONTENT	using\tagSEC_CONTENT	normalization\tagSEC_CONTENT	as\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	.\tagSEC_CONTENT	Furthermore\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	would\tagSEC_CONTENT	be\tagSEC_CONTENT	interesting\tagSEC_CONTENT	to\tagSEC_CONTENT	explore\tagSEC_CONTENT	how\tagSEC_CONTENT	well\tagSEC_CONTENT	an\tagSEC_CONTENT	unsupervised\tagSEC_CONTENT	ranking\tagSEC_CONTENT	method\tagSEC_CONTENT	would\tagSEC_CONTENT	compete\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	random\tagSEC_CONTENT	forest\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	code\tagSEC_CONTENT	of\tagSEC_CONTENT	MoNoise\tagSEC_CONTENT	is\tagSEC_CONTENT	publicly\tagSEC_CONTENT	available\tagSEC_CONTENT	6\tagSEC_CONTENT	.\tagSEC_END	6\tagSEC_START	.\tagSEC_CONTENT	https://bitbucket.org/robvanderg/monoise\tagSEC_CONTENT	;\tagSEC_CONTENT	all\tagSEC_CONTENT	results\tagSEC_CONTENT	reported\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	reproduced\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	command\tagSEC_CONTENT	./scripts\tagSEC_CONTENT	/\tagSEC_CONTENT	clin\tagSEC_CONTENT	/\tagSEC_CONTENT	all.sh\tagSEC_END	
K16-1028	title\tagSECTITLE_END	Abstractive\tagSEC_START	Text\tagtask	Summarization\tagtask	using\tagSEC_CONTENT	Sequence\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	sequence\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	and\tagSEC_CONTENT	Beyond\tagSEC_END	abstract\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	model\tagSEC_CONTENT	abstractive\tagtask	text\tagtask	summarization\tagtask	using\tagSEC_CONTENT	Attentional\tagSEC_CONTENT	Encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	Decoder\tagSEC_CONTENT	Recurrent\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Networks\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	they\tagSEC_CONTENT	achieve\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	corpora\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	propose\tagSEC_CONTENT	several\tagSEC_CONTENT	novel\tagSEC_CONTENT	models\tagSEC_CONTENT	that\tagSEC_CONTENT	address\tagSEC_CONTENT	critical\tagSEC_CONTENT	problems\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	adequately\tagSEC_CONTENT	modeled\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	architecture\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	modeling\tagSEC_CONTENT	keywords\tagSEC_CONTENT	,\tagSEC_CONTENT	capturing\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchy\tagSEC_CONTENT	of\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	word\tagSEC_CONTENT	structure\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	emitting\tagSEC_CONTENT	words\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	rare\tagSEC_CONTENT	or\tagSEC_CONTENT	unseen\tagSEC_CONTENT	at\tagSEC_CONTENT	training\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	work\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	many\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	models\tagSEC_CONTENT	contribute\tagSEC_CONTENT	to\tagSEC_CONTENT	further\tagSEC_CONTENT	improvement\tagSEC_CONTENT	in\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	propose\tagSEC_CONTENT	anew\tagSEC_CONTENT	dataset\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	summaries\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	establish\tagSEC_CONTENT	performance\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	for\tagSEC_CONTENT	further\tagSEC_CONTENT	research\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	Abstractive\tagSEC_START	text\tagtask	summarization\tagtask	is\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	generating\tagSEC_CONTENT	a\tagSEC_CONTENT	headline\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	short\tagSEC_CONTENT	summary\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	few\tagSEC_CONTENT	sentences\tagSEC_CONTENT	that\tagSEC_CONTENT	captures\tagSEC_CONTENT	the\tagSEC_CONTENT	salient\tagSEC_CONTENT	ideas\tagSEC_CONTENT	of\tagSEC_CONTENT	an\tagSEC_CONTENT	article\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	passage\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	adjective\tagSEC_CONTENT	'\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	'\tagSEC_CONTENT	to\tagSEC_CONTENT	denote\tagSEC_CONTENT	a\tagSEC_CONTENT	summary\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	a\tagSEC_CONTENT	mere\tagSEC_CONTENT	selection\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	few\tagSEC_CONTENT	existing\tagSEC_CONTENT	passages\tagSEC_CONTENT	or\tagSEC_CONTENT	sentences\tagSEC_CONTENT	extracted\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	a\tagSEC_CONTENT	compressed\tagSEC_CONTENT	paraphrasing\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	contents\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	potentially\tagSEC_CONTENT	using\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	unseen\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_END	This\tagSEC_START	task\tagSEC_CONTENT	can\tagSEC_CONTENT	also\tagSEC_CONTENT	be\tagSEC_CONTENT	naturally\tagSEC_CONTENT	cast\tagSEC_CONTENT	as\tagSEC_CONTENT	mapping\tagSEC_CONTENT	an\tagSEC_CONTENT	input\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagdataset	in\tagSEC_CONTENT	a\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	target\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	called\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	recent\tagSEC_CONTENT	past\tagSEC_CONTENT	,\tagSEC_CONTENT	deep\tagSEC_CONTENT	-\tagSEC_CONTENT	learning\tagSEC_CONTENT	based\tagSEC_CONTENT	models\tagSEC_CONTENT	that\tagSEC_CONTENT	map\tagSEC_CONTENT	an\tagSEC_CONTENT	input\tagSEC_CONTENT	sequence\tagSEC_CONTENT	into\tagSEC_CONTENT	another\tagSEC_CONTENT	output\tagSEC_CONTENT	sequence\tagSEC_CONTENT	,\tagSEC_CONTENT	called\tagSEC_CONTENT	sequence\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	sequence\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	successful\tagSEC_CONTENT	in\tagSEC_CONTENT	many\tagSEC_CONTENT	problems\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	speech\tagSEC_CONTENT	recognition\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	video\tagSEC_CONTENT	captioning\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	framework\tagSEC_CONTENT	of\tagSEC_CONTENT	sequence\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	sequence\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	very\tagSEC_CONTENT	relevant\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	our\tagSEC_CONTENT	task\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	attentional\tagSEC_CONTENT	Recurrent\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	RNN\tagSEC_CONTENT	)\tagSEC_CONTENT	encoderdecoder\tagSEC_CONTENT	model\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	has\tagSEC_CONTENT	produced\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	in\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	(\tagSEC_CONTENT	MT\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	a\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_END	Despite\tagSEC_START	the\tagSEC_CONTENT	similarities\tagSEC_CONTENT	,\tagSEC_CONTENT	abstractive\tagtask	summarization\tagtask	is\tagSEC_CONTENT	a\tagSEC_CONTENT	very\tagSEC_CONTENT	different\tagSEC_CONTENT	problem\tagSEC_CONTENT	from\tagSEC_CONTENT	MT\tagSEC_CONTENT	.\tagSEC_CONTENT	Unlike\tagSEC_CONTENT	in\tagSEC_CONTENT	MT\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	(\tagSEC_CONTENT	summary\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	typically\tagSEC_CONTENT	very\tagSEC_CONTENT	short\tagSEC_CONTENT	and\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	depend\tagSEC_CONTENT	very\tagSEC_CONTENT	much\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	(\tagSEC_CONTENT	document\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	key\tagSEC_CONTENT	challenge\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	optimally\tagSEC_CONTENT	compress\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	document\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	lossy\tagSEC_CONTENT	manner\tagSEC_CONTENT	such\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	concepts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	document\tagSEC_CONTENT	are\tagSEC_CONTENT	preserved\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	in\tagSEC_CONTENT	MT\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	translation\tagSEC_CONTENT	is\tagSEC_CONTENT	expected\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	loss\tagSEC_CONTENT	-\tagSEC_CONTENT	less\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	translation\tagSEC_CONTENT	,\tagSEC_CONTENT	there\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	strong\tagSEC_CONTENT	notion\tagSEC_CONTENT	of\tagSEC_CONTENT	almost\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	one\tagSEC_CONTENT	wordlevel\tagSEC_CONTENT	alignment\tagSEC_CONTENT	between\tagSEC_CONTENT	source\tagSEC_CONTENT	and\tagSEC_CONTENT	target\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	less\tagSEC_CONTENT	obvious\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	make\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	main\tagSEC_CONTENT	contributions\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	:\tagSEC_CONTENT	(\tagSEC_CONTENT	i\tagSEC_CONTENT	)\tagSEC_CONTENT	We\tagSEC_CONTENT	apply\tagSEC_CONTENT	the\tagSEC_CONTENT	off\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	shelf\tagSEC_CONTENT	attentional\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	RNN\tagSEC_CONTENT	that\tagSEC_CONTENT	was\tagSEC_CONTENT	originally\tagSEC_CONTENT	developed\tagSEC_CONTENT	for\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	to\tagSEC_CONTENT	summarization\tagtask	,\tagSEC_CONTENT	and\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	already\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	stateof\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	systems\tagSEC_CONTENT	on\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	English\tagSEC_CONTENT	corpora\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	ii\tagSEC_CONTENT	)\tagSEC_CONTENT	Motivated\tagSEC_CONTENT	by\tagSEC_CONTENT	concrete\tagSEC_CONTENT	problems\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	sufficiently\tagSEC_CONTENT	addressed\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	based\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	novel\tagSEC_CONTENT	models\tagSEC_CONTENT	and\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	they\tagSEC_CONTENT	provide\tagSEC_CONTENT	additional\tagSEC_CONTENT	improvement\tagSEC_CONTENT	in\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	iii\tagSEC_CONTENT	)\tagSEC_CONTENT	We\tagSEC_CONTENT	propose\tagSEC_CONTENT	anew\tagSEC_CONTENT	dataset\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	document\tagSEC_CONTENT	into\tagSEC_CONTENT	multiple\tagSEC_CONTENT	sentences\tagSEC_CONTENT	and\tagSEC_CONTENT	establish\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	rest\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	paper\tagSEC_CONTENT	is\tagSEC_CONTENT	organized\tagSEC_CONTENT	as\tagSEC_CONTENT	follows\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	Section\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	describe\tagSEC_CONTENT	each\tagSEC_CONTENT	specific\tagSEC_CONTENT	problem\tagSEC_CONTENT	in\tagSEC_CONTENT	abstractive\tagtask	summarization\tagtask	that\tagSEC_CONTENT	we\tagSEC_CONTENT	aim\tagSEC_CONTENT	to\tagSEC_CONTENT	solve\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	present\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	model\tagSEC_CONTENT	that\tagSEC_CONTENT	addresses\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_CONTENT	Sec\tagSEC_CONTENT	-\tagSEC_CONTENT	tion\tagSEC_CONTENT	3\tagSEC_CONTENT	contextualizes\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	closely\tagSEC_CONTENT	related\tagSEC_CONTENT	work\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	topic\tagSEC_CONTENT	of\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	text\tagSEC_CONTENT	summarization\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	present\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	different\tagSEC_CONTENT	data\tagSEC_CONTENT	sets\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	present\tagSEC_CONTENT	some\tagSEC_CONTENT	qualitative\tagSEC_CONTENT	analysis\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	from\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	5\tagSEC_CONTENT	before\tagSEC_CONTENT	concluding\tagSEC_CONTENT	the\tagSEC_CONTENT	paper\tagSEC_CONTENT	with\tagSEC_CONTENT	remarks\tagSEC_CONTENT	on\tagSEC_CONTENT	our\tagSEC_CONTENT	future\tagSEC_CONTENT	direction\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	6\tagSEC_CONTENT	.\tagSEC_END	Models\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	first\tagSEC_CONTENT	describe\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	encoderdecoder\tagSEC_CONTENT	RNN\tagSEC_CONTENT	that\tagSEC_CONTENT	serves\tagSEC_CONTENT	as\tagSEC_CONTENT	our\tagSEC_CONTENT	baseline\tagSEC_CONTENT	and\tagSEC_CONTENT	then\tagSEC_CONTENT	propose\tagSEC_CONTENT	several\tagSEC_CONTENT	novel\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	summarization\tagtask	,\tagSEC_CONTENT	each\tagSEC_CONTENT	addressing\tagSEC_CONTENT	a\tagSEC_CONTENT	specific\tagSEC_CONTENT	weakness\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	.\tagSEC_END	Encoder\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_CONTENT	RNN\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Large\tagSECTITLE_CONTENT	Vocabulary\tagSECTITLE_CONTENT	Trick\tagSECTITLE_END	Our\tagSEC_START	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	neural\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	model\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	encoder\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	GRU\tagSEC_CONTENT	-\tagSEC_CONTENT	RNN\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	uni\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	GRU\tagSEC_CONTENT	-\tagSEC_CONTENT	RNN\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	hidden\tagSEC_CONTENT	-\tagSEC_CONTENT	state\tagSEC_CONTENT	size\tagSEC_CONTENT	as\tagSEC_CONTENT	that\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	an\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	-\tagSEC_CONTENT	hidden\tagSEC_CONTENT	states\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	soft\tagSEC_CONTENT	-\tagSEC_CONTENT	max\tagSEC_CONTENT	layer\tagSEC_CONTENT	over\tagSEC_CONTENT	target\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	words\tagdataset	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	interest\tagSEC_CONTENT	of\tagSEC_CONTENT	space\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	refer\tagSEC_CONTENT	the\tagSEC_CONTENT	reader\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	paper\tagSEC_CONTENT	fora\tagSEC_CONTENT	detailed\tagSEC_CONTENT	treatment\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	addition\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	adapted\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	summarization\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	large\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	'\tagSEC_CONTENT	trick\tagSEC_CONTENT	'\tagSEC_CONTENT	(\tagSEC_CONTENT	LVT\tagSEC_CONTENT	)\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	mini\tagSEC_CONTENT	-\tagSEC_CONTENT	batch\tagSEC_CONTENT	is\tagSEC_CONTENT	restricted\tagSEC_CONTENT	to\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	documents\tagSEC_CONTENT	of\tagSEC_CONTENT	that\tagSEC_CONTENT	batch\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	addition\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	frequent\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	dictionary\tagSEC_CONTENT	are\tagSEC_CONTENT	added\tagSEC_CONTENT	until\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	reaches\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	size\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	aim\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	technique\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	reduce\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	soft\tagSEC_CONTENT	-\tagSEC_CONTENT	max\tagSEC_CONTENT	layer\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	computational\tagSEC_CONTENT	bottleneck\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	addition\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	technique\tagSEC_CONTENT	also\tagSEC_CONTENT	speeds\tagSEC_CONTENT	up\tagSEC_CONTENT	convergence\tagSEC_CONTENT	by\tagSEC_CONTENT	focusing\tagSEC_CONTENT	the\tagSEC_CONTENT	modeling\tagSEC_CONTENT	effort\tagSEC_CONTENT	only\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	essential\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	given\tagSEC_CONTENT	example\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	technique\tagSEC_CONTENT	is\tagSEC_CONTENT	particularly\tagSEC_CONTENT	well\tagSEC_CONTENT	suited\tagSEC_CONTENT	to\tagSEC_CONTENT	summarization\tagSEC_CONTENT	since\tagSEC_CONTENT	a\tagSEC_CONTENT	large\tagSEC_CONTENT	proportion\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	come\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	in\tagSEC_CONTENT	any\tagSEC_CONTENT	case\tagSEC_CONTENT	.\tagSEC_END	Capturing\tagSECTITLE_START	Keywords\tagSECTITLE_CONTENT	using\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	rich\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	In\tagSEC_START	summarization\tagtask	,\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	challenges\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	concepts\tagSEC_CONTENT	and\tagSEC_CONTENT	key\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	around\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	story\tagSEC_CONTENT	revolves\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	accomplish\tagSEC_CONTENT	this\tagSEC_CONTENT	goal\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	may\tagSEC_CONTENT	need\tagSEC_CONTENT	to\tagSEC_CONTENT	go\tagSEC_CONTENT	beyond\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	document\tagSEC_CONTENT	and\tagSEC_CONTENT	capture\tagSEC_CONTENT	additional\tagSEC_CONTENT	linguistic\tagSEC_CONTENT	features\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	parts\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	speech\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	named\tagSEC_CONTENT	-\tagSEC_CONTENT	entity\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	TF\tagSEC_CONTENT	and\tagSEC_CONTENT	IDF\tagSEC_CONTENT	statistics\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	therefore\tagSEC_CONTENT	create\tagSEC_CONTENT	additional\tagSEC_CONTENT	look\tagSEC_CONTENT	-\tagSEC_CONTENT	up\tagSEC_CONTENT	based\tagSEC_CONTENT	embedding\tagSEC_CONTENT	matrices\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	tag\tagSEC_CONTENT	-\tagSEC_CONTENT	type\tagSEC_CONTENT	,\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	continuous\tagSEC_CONTENT	features\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	TF\tagSEC_CONTENT	and\tagSEC_CONTENT	IDF\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	convert\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	categorical\tagSEC_CONTENT	values\tagSEC_CONTENT	by\tagSEC_CONTENT	discretizing\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	bins\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	use\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	representations\tagSEC_CONTENT	to\tagSEC_CONTENT	indicate\tagSEC_CONTENT	the\tagSEC_CONTENT	bin\tagSEC_CONTENT	number\tagSEC_CONTENT	they\tagSEC_CONTENT	fall\tagSEC_CONTENT	into\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	allows\tagSEC_CONTENT	us\tagSEC_CONTENT	to\tagSEC_CONTENT	map\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	an\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	matrix\tagSEC_CONTENT	like\tagSEC_CONTENT	any\tagSEC_CONTENT	other\tagSEC_CONTENT	tag\tagSEC_CONTENT	-\tagSEC_CONTENT	type\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	simply\tagSEC_CONTENT	look\tagSEC_CONTENT	-\tagSEC_CONTENT	up\tagSEC_CONTENT	its\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	from\tagSEC_CONTENT	all\tagSEC_CONTENT	of\tagSEC_CONTENT	its\tagSEC_CONTENT	associated\tagSEC_CONTENT	tags\tagSEC_CONTENT	and\tagSEC_CONTENT	concatenate\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	long\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	side\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	continue\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	only\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	representation\tagSEC_CONTENT	.\tagSEC_END	Modeling\tagSECTITLE_START	Rare\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Unseen\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	using\tagSECTITLE_CONTENT	Switching\tagSECTITLE_CONTENT	Generator\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Pointer\tagSECTITLE_END	Often\tagSEC_START	-\tagSEC_CONTENT	times\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagtask	,\tagSEC_CONTENT	the\tagSEC_CONTENT	keywords\tagSEC_CONTENT	or\tagSEC_CONTENT	named\tagSEC_CONTENT	-\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	test\tagSEC_CONTENT	document\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	central\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	may\tagSEC_CONTENT	actually\tagSEC_CONTENT	be\tagSEC_CONTENT	unseen\tagSEC_CONTENT	or\tagSEC_CONTENT	rare\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	is\tagSEC_CONTENT	fixed\tagSEC_CONTENT	at\tagSEC_CONTENT	training\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	emit\tagSEC_CONTENT	these\tagSEC_CONTENT	unseen\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	Instead\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	most\tagSEC_CONTENT	common\tagSEC_CONTENT	way\tagSEC_CONTENT	of\tagSEC_CONTENT	handling\tagSEC_CONTENT	these\tagSEC_CONTENT	out\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	(\tagSEC_CONTENT	OOV\tagSEC_CONTENT	)\tagSEC_CONTENT	words\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	emit\tagSEC_CONTENT	an\tagSEC_CONTENT	'\tagSEC_CONTENT	UNK\tagSEC_CONTENT	'\tagSEC_CONTENT	token\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	placeholder\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	this\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	result\tagSEC_CONTENT	in\tagSEC_CONTENT	legible\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	summarization\tagtask	,\tagSEC_CONTENT	an\tagSEC_CONTENT	intuitive\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	handle\tagSEC_CONTENT	such\tagSEC_CONTENT	OOV\tagSEC_CONTENT	words\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	simply\tagSEC_CONTENT	point\tagSEC_CONTENT	to\tagSEC_CONTENT	their\tagSEC_CONTENT	location\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	instead\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	model\tagSEC_CONTENT	this\tagSEC_CONTENT	no\tagSEC_CONTENT	-\tagSEC_CONTENT	tion\tagSEC_CONTENT	using\tagSEC_CONTENT	our\tagSEC_CONTENT	novel\tagSEC_CONTENT	switching\tagSEC_CONTENT	decoder\tagSEC_CONTENT	/\tagSEC_CONTENT	pointer\tagSEC_CONTENT	architecture\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	graphically\tagSEC_CONTENT	represented\tagSEC_CONTENT	in\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	is\tagSEC_CONTENT	equipped\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	'\tagSEC_CONTENT	switch\tagSEC_CONTENT	'\tagSEC_CONTENT	that\tagSEC_CONTENT	decides\tagSEC_CONTENT	between\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	generator\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	pointer\tagSEC_CONTENT	at\tagSEC_CONTENT	every\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	.\tagSEC_CONTENT	If\tagSEC_CONTENT	the\tagSEC_CONTENT	switch\tagSEC_CONTENT	is\tagSEC_CONTENT	turned\tagSEC_CONTENT	on\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	produces\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	from\tagSEC_CONTENT	its\tagSEC_CONTENT	target\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	normal\tagSEC_CONTENT	fashion\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	if\tagSEC_CONTENT	the\tagSEC_CONTENT	switch\tagSEC_CONTENT	is\tagSEC_CONTENT	turned\tagSEC_CONTENT	off\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	instead\tagSEC_CONTENT	generates\tagSEC_CONTENT	a\tagSEC_CONTENT	pointer\tagSEC_CONTENT	to\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	positions\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	word\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	pointer\tagSEC_CONTENT	-\tagSEC_CONTENT	location\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	copied\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	switch\tagSEC_CONTENT	is\tagSEC_CONTENT	modeled\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sigmoid\tagSEC_CONTENT	activation\tagSEC_CONTENT	function\tagSEC_CONTENT	over\tagSEC_CONTENT	a\tagSEC_CONTENT	linear\tagSEC_CONTENT	layer\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	entire\tagSEC_CONTENT	available\tagSEC_CONTENT	context\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	timestep\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	below\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	the\tagSEC_CONTENT	above\tagSEC_CONTENT	equation\tagSEC_CONTENT	,\tagSEC_CONTENT	pi\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	pointer\tagSEC_CONTENT	value\tagSEC_CONTENT	at\tagSEC_CONTENT	i\tagSEC_CONTENT	th\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	position\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	sampled\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	distribution\tagSEC_CONTENT	Pa\tagSEC_CONTENT	i\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	positions\tagSEC_CONTENT	j\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	Nd\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	Pa\tagSEC_CONTENT	i\tagSEC_CONTENT	(\tagSEC_CONTENT	j\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	i\tagSEC_CONTENT	th\tagSEC_CONTENT	time\tagmetric	-\tagmetric	step\tagmetric	in\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	pointing\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	j\tagSEC_CONTENT	th\tagSEC_CONTENT	position\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	h\tagSEC_CONTENT	d\tagSEC_CONTENT	j\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	's\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	at\tagSEC_CONTENT	position\tagSEC_CONTENT	j.\tagSEC_END	At\tagSEC_START	training\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	provide\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	explicit\tagSEC_CONTENT	pointer\tagSEC_CONTENT	information\tagSEC_CONTENT	whenever\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	word\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	exist\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	the\tagSEC_CONTENT	OOV\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	summary\tagtask	occurs\tagSEC_CONTENT	in\tagSEC_CONTENT	multiple\tagSEC_CONTENT	document\tagSEC_CONTENT	positions\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	break\tagSEC_CONTENT	the\tagSEC_CONTENT	tie\tagSEC_CONTENT	in\tagSEC_CONTENT	favor\tagSEC_CONTENT	of\tagSEC_CONTENT	its\tagSEC_CONTENT	first\tagSEC_CONTENT	occurrence\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	training\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	optimize\tagSEC_CONTENT	the\tagSEC_CONTENT	conditional\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	shown\tagSEC_CONTENT	below\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	additional\tagSEC_CONTENT	regularization\tagSEC_CONTENT	penalties\tagSEC_CONTENT	.\tagSEC_END	where\tagSEC_START	y\tagSEC_CONTENT	and\tagSEC_CONTENT	x\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	and\tagSEC_CONTENT	document\tagSEC_CONTENT	words\tagdataset	respectively\tagSEC_CONTENT	,\tagSEC_CONTENT	g\tagSEC_CONTENT	i\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	indicator\tagSEC_CONTENT	function\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	0\tagSEC_CONTENT	whenever\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	at\tagSEC_CONTENT	position\tagSEC_CONTENT	i\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	is\tagSEC_CONTENT	OOV\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	test\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	decides\tagSEC_CONTENT	automatically\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	whether\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	or\tagSEC_CONTENT	to\tagSEC_CONTENT	point\tagSEC_CONTENT	,\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	estimated\tagSEC_CONTENT	switch\tagSEC_CONTENT	probability\tagSEC_CONTENT	P\tagSEC_CONTENT	(\tagSEC_CONTENT	s\tagSEC_CONTENT	i\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	simply\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	arg\tagSEC_CONTENT	max\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	posterior\tagSEC_CONTENT	probability\tagSEC_CONTENT	of\tagSEC_CONTENT	generation\tagSEC_CONTENT	or\tagSEC_CONTENT	pointing\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	output\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	pointer\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	maybe\tagSEC_CONTENT	more\tagSEC_CONTENT	robust\tagSEC_CONTENT	in\tagSEC_CONTENT	handling\tagSEC_CONTENT	rare\tagdataset	words\tagdataset	because\tagSEC_CONTENT	it\tagSEC_CONTENT	uses\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	's\tagSEC_CONTENT	hidden\tagSEC_CONTENT	-\tagSEC_CONTENT	state\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	rare\tagSEC_CONTENT	words\tagSEC_CONTENT	to\tagSEC_CONTENT	decide\tagSEC_CONTENT	which\tagSEC_CONTENT	word\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	to\tagSEC_CONTENT	point\tagSEC_CONTENT	to\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	depends\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	entire\tagSEC_CONTENT	context\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	accurately\tagSEC_CONTENT	point\tagSEC_CONTENT	to\tagSEC_CONTENT	unseen\tagSEC_CONTENT	words\tagSEC_CONTENT	although\tagSEC_CONTENT	they\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	appear\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	.\tagSEC_END	Capturing\tagSECTITLE_START	Hierarchical\tagSECTITLE_CONTENT	Document\tagSECTITLE_CONTENT	Structure\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Hierarchical\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	In\tagSEC_START	datasets\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	is\tagSEC_CONTENT	very\tagSEC_CONTENT	long\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	addition\tagtask	to\tagSEC_CONTENT	identifying\tagSEC_CONTENT	the\tagSEC_CONTENT	keywords\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	important\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	drawn\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	aims\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	this\tagSEC_CONTENT	notion\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	levels\tagSEC_CONTENT	of\tagSEC_CONTENT	importance\tagSEC_CONTENT	using\tagSEC_CONTENT	two\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	side\tagSEC_CONTENT	,\tagSEC_CONTENT	one\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	level\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	level\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	operates\tagSEC_CONTENT	at\tagSEC_CONTENT	both\tagSEC_CONTENT	levels\tagSEC_CONTENT	simultaneously\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	attention\tagSEC_CONTENT	is\tagSEC_CONTENT	further\tagSEC_CONTENT	re\tagSEC_CONTENT	-\tagSEC_CONTENT	weighted\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	attention\tagSEC_CONTENT	and\tagSEC_CONTENT	renormalized\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	below\tagSEC_CONTENT	:\tagSEC_END	,\tagSEC_START	where\tagSEC_CONTENT	Pa\tagSEC_CONTENT	w\tagSEC_CONTENT	(\tagSEC_CONTENT	j\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	attention\tagSEC_CONTENT	weight\tagSEC_CONTENT	at\tagSEC_CONTENT	j\tagSEC_CONTENT	th\tagSEC_CONTENT	position\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	s(j\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	ID\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	at\tagSEC_CONTENT	j\tagSEC_CONTENT	th\tagSEC_CONTENT	word\tagSEC_CONTENT	position\tagSEC_CONTENT	,\tagSEC_CONTENT	Pa\tagSEC_CONTENT	s\tagSEC_CONTENT	(\tagSEC_CONTENT	l\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	attention\tagSEC_CONTENT	weight\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	l\tagSEC_CONTENT	th\tagSEC_CONTENT	sentence\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	,\tagSEC_CONTENT	Nd\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagdataset	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Pa\tagSEC_CONTENT	(\tagSEC_CONTENT	j\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	re\tagSEC_CONTENT	-\tagSEC_CONTENT	scaled\tagSEC_CONTENT	attention\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	j\tagSEC_CONTENT	th\tagSEC_CONTENT	word\tagSEC_CONTENT	position\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	re\tagSEC_CONTENT	-\tagSEC_CONTENT	scaled\tagSEC_CONTENT	attention\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	attentionweighted\tagSEC_CONTENT	context\tagSEC_CONTENT	vector\tagSEC_CONTENT	that\tagSEC_CONTENT	goes\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	.\tagSEC_CONTENT	Further\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	concatenate\tagSEC_CONTENT	additional\tagSEC_CONTENT	positional\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	RNN\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	positional\tagSEC_CONTENT	importance\tagSEC_CONTENT	of\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	architecture\tagSEC_CONTENT	therefore\tagSEC_CONTENT	models\tagSEC_CONTENT	key\tagSEC_CONTENT	sentences\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	keywords\tagSEC_CONTENT	within\tagSEC_CONTENT	those\tagSEC_CONTENT	sentences\tagSEC_CONTENT	jointly\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	graphical\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	displayed\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	A\tagSEC_START	vast\tagSEC_CONTENT	majority\tagSEC_CONTENT	of\tagSEC_CONTENT	past\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagtask	has\tagSEC_CONTENT	been\tagSEC_CONTENT	extractive\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	identifying\tagSEC_CONTENT	key\tagSEC_CONTENT	sentences\tagSEC_CONTENT	or\tagSEC_CONTENT	passages\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	and\tagSEC_CONTENT	reproducing\tagSEC_CONTENT	them\tagSEC_CONTENT	as\tagSEC_CONTENT	summary\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	Humans\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	hand\tagSEC_CONTENT	,\tagSEC_CONTENT	tend\tagSEC_CONTENT	to\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	story\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	own\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	such\tagSEC_CONTENT	,\tagSEC_CONTENT	human\tagSEC_CONTENT	summaries\tagSEC_CONTENT	are\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	in\tagSEC_CONTENT	nature\tagSEC_CONTENT	and\tagSEC_CONTENT	seldom\tagSEC_CONTENT	consist\tagSEC_CONTENT	of\tagSEC_CONTENT	reproduction\tagSEC_CONTENT	of\tagSEC_CONTENT	original\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	standardized\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	competitions\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	data\tagSEC_CONTENT	for\tagSEC_CONTENT	these\tagSEC_CONTENT	tasks\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	news\tagSEC_CONTENT	stories\tagSEC_CONTENT	from\tagSEC_CONTENT	various\tagSEC_CONTENT	topics\tagSEC_CONTENT	with\tagSEC_CONTENT	multiple\tagSEC_CONTENT	reference\tagSEC_CONTENT	summaries\tagSEC_CONTENT	per\tagSEC_CONTENT	story\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	humans\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	best\tagSEC_CONTENT	performing\tagSEC_CONTENT	system\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	DUC-2004\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	called\tagSEC_CONTENT	TOPIARY\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	linguistically\tagSEC_CONTENT	motivated\tagSEC_CONTENT	compression\tagSEC_CONTENT	techniques\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	an\tagSEC_CONTENT	unsupervised\tagSEC_CONTENT	topic\tagSEC_CONTENT	detection\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	that\tagSEC_CONTENT	appends\tagSEC_CONTENT	keywords\tagSEC_CONTENT	extracted\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	article\tagSEC_CONTENT	onto\tagSEC_CONTENT	the\tagSEC_CONTENT	compressed\tagSEC_CONTENT	output\tagSEC_CONTENT	.\tagSEC_CONTENT	Some\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	notable\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	includes\tagSEC_CONTENT	using\tagSEC_CONTENT	traditional\tagSEC_CONTENT	phrase\tagSEC_CONTENT	-\tagSEC_CONTENT	table\tagSEC_CONTENT	based\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	approaches\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	compression\tagSEC_CONTENT	using\tagSEC_CONTENT	weighted\tagSEC_CONTENT	tree\tagSEC_CONTENT	-\tagSEC_CONTENT	transformation\tagSEC_CONTENT	rules\tagSEC_CONTENT	and\tagSEC_CONTENT	quasi\tagSEC_CONTENT	-\tagSEC_CONTENT	synchronous\tagSEC_CONTENT	grammar\tagSEC_CONTENT	approaches\tagSEC_CONTENT	.\tagSEC_CONTENT	With\tagSEC_CONTENT	the\tagSEC_CONTENT	emergence\tagSEC_CONTENT	of\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	viable\tagSEC_CONTENT	alternative\tagSEC_CONTENT	for\tagSEC_CONTENT	many\tagSEC_CONTENT	NLP\tagSEC_CONTENT	tasks\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	researchers\tagSEC_CONTENT	have\tagSEC_CONTENT	started\tagSEC_CONTENT	considering\tagSEC_CONTENT	this\tagSEC_CONTENT	framework\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	attractive\tagSEC_CONTENT	,\tagSEC_CONTENT	fully\tagSEC_CONTENT	data\tagSEC_CONTENT	-\tagSEC_CONTENT	driven\tagSEC_CONTENT	alternative\tagSEC_CONTENT	to\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	authors\tagSEC_CONTENT	use\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	context\tagSEC_CONTENT	-\tagSEC_CONTENT	sensitive\tagSEC_CONTENT	attentional\tagSEC_CONTENT	feed\tagSEC_CONTENT	-\tagSEC_CONTENT	forward\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	producing\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	and\tagSEC_CONTENT	DUC\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	an\tagSEC_CONTENT	extension\tagSEC_CONTENT	to\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	similar\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	replaced\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	with\tagSEC_CONTENT	an\tagSEC_CONTENT	RNN\tagSEC_CONTENT	,\tagSEC_CONTENT	producing\tagSEC_CONTENT	further\tagSEC_CONTENT	improvement\tagSEC_CONTENT	in\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	another\tagSEC_CONTENT	paper\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	closely\tagSEC_CONTENT	related\tagSEC_CONTENT	to\tagSEC_CONTENT	our\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	introduce\tagSEC_CONTENT	a\tagSEC_CONTENT	large\tagSEC_CONTENT	dataset\tagSEC_CONTENT	for\tagSEC_CONTENT	Chinese\tagSEC_CONTENT	short\tagSEC_CONTENT	text\tagSEC_CONTENT	summarization\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	show\tagSEC_CONTENT	promising\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	their\tagSEC_CONTENT	Chinese\tagSEC_CONTENT	dataset\tagSEC_CONTENT	using\tagSEC_CONTENT	an\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	RNN\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	report\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	English\tagSEC_CONTENT	corpora\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	another\tagSEC_CONTENT	very\tagSEC_CONTENT	recent\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	 \tagSEC_CONTENT	used\tagSEC_CONTENT	RNN\tagSEC_CONTENT	based\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	for\tagSEC_CONTENT	extractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	of\tagSEC_CONTENT	documents\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	work\tagSEC_CONTENT	starts\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	framework\tagSEC_CONTENT	as\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	we\tagSEC_CONTENT	go\tagSEC_CONTENT	beyond\tagSEC_CONTENT	the\tagSEC_CONTENT	stan\tagSEC_CONTENT	-\tagSEC_CONTENT	dard\tagSEC_CONTENT	architecture\tagSEC_CONTENT	and\tagSEC_CONTENT	propose\tagSEC_CONTENT	novel\tagSEC_CONTENT	models\tagSEC_CONTENT	that\tagSEC_CONTENT	address\tagSEC_CONTENT	critical\tagSEC_CONTENT	problems\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagtask	.\tagSEC_CONTENT	We\tagSEC_CONTENT	analyze\tagSEC_CONTENT	the\tagSEC_CONTENT	similarities\tagSEC_CONTENT	and\tagSEC_CONTENT	differences\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	related\tagSEC_CONTENT	work\tagSEC_CONTENT	on\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	below\tagSEC_CONTENT	.\tagSEC_CONTENT	Feature\tagSEC_CONTENT	-\tagSEC_CONTENT	rich\tagSEC_CONTENT	encoder\tagSEC_CONTENT	(\tagSEC_CONTENT	Sec\tagSEC_CONTENT	.\tagSEC_CONTENT	2.2\tagSEC_CONTENT	)\tagSEC_CONTENT	:\tagSEC_CONTENT	Linguistic\tagSEC_CONTENT	features\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	-\tagSEC_CONTENT	entities\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	TF\tagSEC_CONTENT	and\tagSEC_CONTENT	IDF\tagSEC_CONTENT	information\tagSEC_CONTENT	were\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	many\tagSEC_CONTENT	extractive\tagSEC_CONTENT	approaches\tagSEC_CONTENT	to\tagSEC_CONTENT	summarization\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	novel\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	of\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	approaches\tagSEC_CONTENT	for\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	.\tagSEC_CONTENT	Switching\tagSEC_CONTENT	generator\tagSEC_CONTENT	-\tagSEC_CONTENT	pointer\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	Sec\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	the\tagSEC_CONTENT	novel\tagSEC_CONTENT	addition\tagSEC_CONTENT	of\tagSEC_CONTENT	switch\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	allows\tagSEC_CONTENT	it\tagSEC_CONTENT	to\tagSEC_CONTENT	strike\tagSEC_CONTENT	a\tagSEC_CONTENT	balance\tagSEC_CONTENT	between\tagSEC_CONTENT	when\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	faithful\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	source\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	named\tagSEC_CONTENT	entities\tagSEC_CONTENT	and\tagSEC_CONTENT	OOV\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	when\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	allowed\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	creative\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	believe\tagSEC_CONTENT	such\tagSEC_CONTENT	a\tagSEC_CONTENT	process\tagSEC_CONTENT	arguably\tagSEC_CONTENT	mimics\tagSEC_CONTENT	how\tagSEC_CONTENT	human\tagSEC_CONTENT	produces\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	detailed\tagSEC_CONTENT	treatment\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	multiple\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	please\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	parallel\tagSEC_CONTENT	work\tagSEC_CONTENT	published\tagSEC_CONTENT	by\tagSEC_CONTENT	some\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	authors\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	Sec\tagSEC_CONTENT	.\tagSEC_CONTENT	2.4\tagSEC_CONTENT	)\tagSEC_CONTENT	:\tagSEC_CONTENT	Previously\tagSEC_CONTENT	proposed\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	models\tagSEC_CONTENT	use\tagSEC_CONTENT	attention\tagSEC_CONTENT	only\tagSEC_CONTENT	at\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	novelty\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	lies\tagSEC_CONTENT	in\tagSEC_CONTENT	joint\tagSEC_CONTENT	modeling\tagSEC_CONTENT	of\tagSEC_CONTENT	attention\tagSEC_CONTENT	at\tagSEC_CONTENT	both\tagSEC_CONTENT	sentence\tagSEC_CONTENT	and\tagSEC_CONTENT	word\tagSEC_CONTENT	levels\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	attention\tagSEC_CONTENT	is\tagSEC_CONTENT	further\tagSEC_CONTENT	influenced\tagSEC_CONTENT	by\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	attention\tagSEC_CONTENT	,\tagSEC_CONTENT	thus\tagSEC_CONTENT	capturing\tagSEC_CONTENT	the\tagSEC_CONTENT	notion\tagSEC_CONTENT	of\tagSEC_CONTENT	important\tagSEC_CONTENT	sentences\tagSEC_CONTENT	and\tagSEC_CONTENT	important\tagSEC_CONTENT	words\tagSEC_CONTENT	within\tagSEC_CONTENT	those\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_CONTENT	Concatenation\tagSEC_CONTENT	of\tagSEC_CONTENT	positional\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	at\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	new\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Gigaword\tagSECTITLE_START	Corpus\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	series\tagSEC_CONTENT	of\tagSEC_CONTENT	experiments\tagSEC_CONTENT	3\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	annotated\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	as\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	scripts\tagSEC_CONTENT	made\tagSEC_CONTENT	available\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	authors\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	4\tagSEC_CONTENT	to\tagSEC_CONTENT	preprocess\tagSEC_CONTENT	the\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	resulted\tagSEC_CONTENT	in\tagSEC_CONTENT	about\tagSEC_CONTENT	3.8\tagSEC_CONTENT	M\tagSEC_CONTENT	training\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	script\tagSEC_CONTENT	also\tagSEC_CONTENT	produces\tagSEC_CONTENT	about\tagSEC_CONTENT	400\tagSEC_CONTENT	K\tagSEC_CONTENT	validation\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	examples\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	we\tagSEC_CONTENT	created\tagSEC_CONTENT	a\tagSEC_CONTENT	randomly\tagSEC_CONTENT	sampled\tagSEC_CONTENT	subset\tagSEC_CONTENT	of\tagSEC_CONTENT	2000\tagSEC_CONTENT	examples\tagSEC_CONTENT	each\tagSEC_CONTENT	for\tagSEC_CONTENT	validation\tagSEC_CONTENT	and\tagSEC_CONTENT	testing\tagSEC_CONTENT	purposes\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	report\tagSEC_CONTENT	our\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	Further\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	acquired\tagSEC_CONTENT	the\tagSEC_CONTENT	exact\tagSEC_CONTENT	test\tagSEC_CONTENT	sample\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	to\tagSEC_CONTENT	make\tagSEC_CONTENT	precise\tagSEC_CONTENT	comparison\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	theirs\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	made\tagSEC_CONTENT	small\tagtask	modifications\tagtask	to\tagSEC_CONTENT	the\tagSEC_CONTENT	script\tagSEC_CONTENT	to\tagSEC_CONTENT	extract\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	tokenized\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	systemgenerated\tagSEC_CONTENT	parts\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	speech\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	-\tagSEC_CONTENT	entity\tagSEC_CONTENT	tags\tagSEC_CONTENT	.\tagSEC_CONTENT	Training\tagSEC_CONTENT	:\tagSEC_CONTENT	For\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	we\tagSEC_CONTENT	discuss\tagSEC_CONTENT	below\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	200\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	word2vec\tagSEC_CONTENT	vectors\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	corpus\tagSEC_CONTENT	to\tagSEC_CONTENT	initialize\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	we\tagSEC_CONTENT	allowed\tagSEC_CONTENT	them\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	updated\tagSEC_CONTENT	during\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	dimension\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	and\tagSEC_CONTENT	decoder\tagSEC_CONTENT	was\tagSEC_CONTENT	fixed\tagSEC_CONTENT	at\tagSEC_CONTENT	400\tagSEC_CONTENT	in\tagSEC_CONTENT	all\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	sentence\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	done\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	size\tagSEC_CONTENT	was\tagSEC_CONTENT	119,505\tagSEC_CONTENT	and\tagSEC_CONTENT	that\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	stood\tagSEC_CONTENT	at\tagSEC_CONTENT	68,885\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	Adadelta\tagSEC_CONTENT	(\tagSEC_CONTENT	Zeiler\tagSEC_CONTENT	,\tagSEC_CONTENT	2012\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	an\tagSEC_CONTENT	initial\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	of\tagSEC_CONTENT	0.001\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	batch\tagSEC_CONTENT	-\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	50\tagSEC_CONTENT	and\tagSEC_CONTENT	randomly\tagSEC_CONTENT	shuffled\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	at\tagSEC_CONTENT	every\tagSEC_CONTENT	epoch\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	sorting\tagSEC_CONTENT	every\tagSEC_CONTENT	10\tagSEC_CONTENT	batches\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	their\tagSEC_CONTENT	lengths\tagSEC_CONTENT	to\tagSEC_CONTENT	speedup\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	use\tagSEC_CONTENT	any\tagSEC_CONTENT	dropout\tagSEC_CONTENT	or\tagSEC_CONTENT	regularization\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	applied\tagSEC_CONTENT	gradient\tagSEC_CONTENT	clipping\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	early\tagSEC_CONTENT	stopping\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	and\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	report\tagSEC_CONTENT	all\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	numbers\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	all\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	employ\tagSEC_CONTENT	the\tagSEC_CONTENT	large\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	trick\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	we\tagSEC_CONTENT	restrict\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	size\tagSEC_CONTENT	to\tagSEC_CONTENT	2,000\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	it\tagSEC_CONTENT	cuts\tagSEC_CONTENT	down\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	time\tagSEC_CONTENT	per\tagSEC_CONTENT	epoch\tagSEC_CONTENT	by\tagSEC_CONTENT	nearly\tagSEC_CONTENT	three\tagSEC_CONTENT	times\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	helps\tagSEC_CONTENT	this\tagSEC_CONTENT	and\tagSEC_CONTENT	all\tagSEC_CONTENT	subsequent\tagSEC_CONTENT	models\tagSEC_CONTENT	converge\tagSEC_CONTENT	in\tagSEC_CONTENT	only\tagSEC_CONTENT	50%-75\tagSEC_CONTENT	%\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	epochs\tagSEC_CONTENT	needed\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	full\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	.\tagSEC_CONTENT	Decoding\tagSEC_CONTENT	:\tagSEC_CONTENT	At\tagSEC_CONTENT	decode\tagSEC_CONTENT	-\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	beam\tagSEC_CONTENT	search\tagSEC_CONTENT	of\tagSEC_CONTENT	size\tagSEC_CONTENT	5\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	limited\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	summary\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	maximum\tagSEC_CONTENT	of\tagSEC_CONTENT	30\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	maximum\tagSEC_CONTENT	size\tagSEC_CONTENT	we\tagSEC_CONTENT	noticed\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sampled\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	average\tagSEC_CONTENT	system\tagSEC_CONTENT	summary\tagSEC_CONTENT	length\tagSEC_CONTENT	from\tagSEC_CONTENT	all\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	(\tagSEC_CONTENT	7.8\tagSEC_CONTENT	to\tagSEC_CONTENT	8.3\tagSEC_CONTENT	)\tagSEC_CONTENT	agrees\tagSEC_CONTENT	very\tagSEC_CONTENT	closely\tagSEC_CONTENT	with\tagSEC_CONTENT	that\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	(\tagSEC_CONTENT	about\tagSEC_CONTENT	8.7\tagSEC_CONTENT	words\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	without\tagSEC_CONTENT	any\tagSEC_CONTENT	specific\tagSEC_CONTENT	tuning\tagSEC_CONTENT	.\tagSEC_END	Computational\tagSEC_START	costs\tagSEC_CONTENT	:\tagSEC_CONTENT	We\tagSEC_CONTENT	trained\tagSEC_CONTENT	all\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	Tesla\tagSEC_CONTENT	K40\tagSEC_CONTENT	GPU\tagSEC_CONTENT	.\tagSEC_CONTENT	Most\tagSEC_CONTENT	models\tagSEC_CONTENT	took\tagSEC_CONTENT	about\tagSEC_CONTENT	10\tagSEC_CONTENT	hours\tagSEC_CONTENT	per\tagSEC_CONTENT	epoch\tagSEC_CONTENT	on\tagSEC_CONTENT	an\tagSEC_CONTENT	average\tagSEC_CONTENT	except\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	took\tagSEC_CONTENT	12\tagSEC_CONTENT	hours\tagSEC_CONTENT	per\tagSEC_CONTENT	epoch\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	models\tagSEC_CONTENT	typically\tagSEC_CONTENT	converged\tagSEC_CONTENT	within\tagSEC_CONTENT	15\tagSEC_CONTENT	epochs\tagSEC_CONTENT	using\tagSEC_CONTENT	our\tagSEC_CONTENT	early\tagSEC_CONTENT	stopping\tagSEC_CONTENT	criterion\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	cost\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	wall\tagSEC_CONTENT	-\tagSEC_CONTENT	clock\tagSEC_CONTENT	training\tagSEC_CONTENT	time\tagSEC_CONTENT	until\tagSEC_CONTENT	convergence\tagSEC_CONTENT	therefore\tagSEC_CONTENT	varies\tagSEC_CONTENT	between\tagSEC_CONTENT	6\tagSEC_CONTENT	-\tagSEC_CONTENT	8\tagSEC_CONTENT	days\tagSEC_CONTENT	depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Generating\tagSEC_CONTENT	summaries\tagSEC_CONTENT	attest\tagSEC_CONTENT	time\tagSEC_CONTENT	is\tagSEC_CONTENT	reasonably\tagSEC_CONTENT	fast\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	throughput\tagSEC_CONTENT	of\tagSEC_CONTENT	about\tagSEC_CONTENT	20\tagSEC_CONTENT	summaries\tagSEC_CONTENT	per\tagSEC_CONTENT	second\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	GPU\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	batch\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_CONTENT	Evaluation\tagSEC_CONTENT	metrics\tagSEC_CONTENT	:\tagSEC_CONTENT	In\tagSEC_CONTENT	Rush\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	authors\tagSEC_CONTENT	used\tagSEC_CONTENT	full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	version\tagSEC_CONTENT	of\tagSEC_CONTENT	Rouge\tagmetric	recall\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	their\tagSEC_CONTENT	systems\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	recall\tagSEC_CONTENT	favors\tagSEC_CONTENT	longer\tagSEC_CONTENT	summaries\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	it\tagSEC_CONTENT	may\tagSEC_CONTENT	not\tagSEC_CONTENT	be\tagSEC_CONTENT	fair\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	this\tagSEC_CONTENT	metric\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	two\tagSEC_CONTENT	systems\tagSEC_CONTENT	that\tagSEC_CONTENT	differ\tagSEC_CONTENT	in\tagSEC_CONTENT	summary\tagSEC_CONTENT	lengths\tagSEC_CONTENT	.\tagSEC_CONTENT	Full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	F1\tagSEC_CONTENT	solves\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	since\tagSEC_CONTENT	it\tagSEC_CONTENT	can\tagSEC_CONTENT	penalize\tagSEC_CONTENT	longer\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	F1\tagSEC_CONTENT	scores\tagSEC_CONTENT	from\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	2\tagSEC_CONTENT	and\tagSEC_CONTENT	L\tagSEC_CONTENT	variants\tagSEC_CONTENT	of\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	official\tagSEC_CONTENT	script\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	systems\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	interest\tagSEC_CONTENT	of\tagSEC_CONTENT	fair\tagSEC_CONTENT	comparison\tagSEC_CONTENT	with\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	report\tagSEC_CONTENT	full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	recall\tagSEC_CONTENT	scores\tagSEC_CONTENT	where\tagSEC_CONTENT	necessary\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	addition\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	report\tagSEC_CONTENT	the\tagSEC_CONTENT	percentage\tagSEC_CONTENT	of\tagSEC_CONTENT	tokens\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	system\tagSEC_CONTENT	summary\tagSEC_CONTENT	that\tagSEC_CONTENT	occur\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	(\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	call\tagSEC_CONTENT	'\tagSEC_CONTENT	src\tagSEC_CONTENT	.\tagSEC_CONTENT	copy\tagSEC_CONTENT	rate\tagSEC_CONTENT	'\tagSEC_CONTENT	in\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	describe\tagSEC_CONTENT	all\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	and\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	below\tagSEC_CONTENT	.\tagSEC_CONTENT	words\tagSEC_CONTENT	-\tagSEC_CONTENT	lvt2k-1sent\tagSEC_CONTENT	:\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	attentional\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	large\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	trick\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	trained\tagSEC_CONTENT	only\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	sentence\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	done\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	words\tagSEC_CONTENT	-\tagSEC_CONTENT	lvt2k-2sent\tagSEC_CONTENT	:\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	identical\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	above\tagSEC_CONTENT	except\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	adding\tagSEC_CONTENT	the\tagSEC_CONTENT	additional\tagSEC_CONTENT	sentence\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	does\tagSEC_CONTENT	seem\tagSEC_CONTENT	to\tagSEC_CONTENT	aid\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	tried\tagSEC_CONTENT	adding\tagSEC_CONTENT	more\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	dropped\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	probably\tagSEC_CONTENT	because\tagSEC_CONTENT	the\tagSEC_CONTENT	latter\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	pertinent\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	words\tagSEC_CONTENT	-\tagSEC_CONTENT	lvt2k-2sent\tagSEC_CONTENT	-\tagSEC_CONTENT	hieratt\tagSEC_CONTENT	:\tagSEC_CONTENT	Since\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	trained\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	Sec\tagSEC_CONTENT	2.4\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	improves\tagSEC_CONTENT	perfor\tagSEC_CONTENT	-\tagSEC_CONTENT	mance\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	its\tagSEC_CONTENT	flatter\tagSEC_CONTENT	counterpart\tagSEC_CONTENT	by\tagSEC_CONTENT	learning\tagSEC_CONTENT	the\tagSEC_CONTENT	relative\tagSEC_CONTENT	importance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	automatically\tagSEC_CONTENT	.\tagSEC_END	feats\tagSEC_START	-\tagSEC_CONTENT	lvt2k-2sent\tagSEC_CONTENT	:\tagSEC_CONTENT	Here\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	still\tagSEC_CONTENT	train\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	we\tagSEC_CONTENT	exploit\tagSEC_CONTENT	the\tagSEC_CONTENT	parts\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	speech\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	-\tagSEC_CONTENT	entity\tagSEC_CONTENT	tags\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	annotated\tagSEC_CONTENT	gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	TF\tagSEC_CONTENT	,\tagSEC_CONTENT	IDF\tagSEC_CONTENT	values\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	augment\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	side\tagSEC_CONTENT	as\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Sec\tagSEC_CONTENT	2.2\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	total\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	embedding\tagSEC_CONTENT	vector\tagSEC_CONTENT	grew\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	100\tagSEC_CONTENT	to\tagSEC_CONTENT	155\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	produced\tagSEC_CONTENT	incremental\tagSEC_CONTENT	gains\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	its\tagSEC_CONTENT	counterpart\tagSEC_CONTENT	wordslvt2k-2sent\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	demonstrating\tagSEC_CONTENT	the\tagSEC_CONTENT	utility\tagSEC_CONTENT	of\tagSEC_CONTENT	syntax\tagSEC_CONTENT	based\tagSEC_CONTENT	features\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_END	feats\tagSEC_START	-\tagSEC_CONTENT	lvt2k-2sent\tagSEC_CONTENT	-\tagSEC_CONTENT	ptr\tagSEC_CONTENT	:\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	switching\tagSEC_CONTENT	generator\tagSEC_CONTENT	/\tagSEC_CONTENT	pointer\tagSEC_CONTENT	model\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Sec\tagSEC_CONTENT	.\tagSEC_CONTENT	2.3\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	in\tagSEC_CONTENT	addition\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	use\tagSEC_CONTENT	feature\tagSEC_CONTENT	-\tagSEC_CONTENT	rich\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	side\tagSEC_CONTENT	as\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	above\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	indicate\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	new\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	achieve\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	our\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	by\tagSEC_CONTENT	all\tagSEC_CONTENT	three\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	variants\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_END	Comparison\tagSEC_START	with\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	:\tagSEC_CONTENT	(\tagSEC_CONTENT	Rush\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	2015\tagSEC_CONTENT	)\tagSEC_CONTENT	reported\tagSEC_CONTENT	recall\tagSEC_CONTENT	-\tagSEC_CONTENT	only\tagSEC_CONTENT	from\tagSEC_CONTENT	full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	version\tagSEC_CONTENT	of\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	the\tagSEC_CONTENT	authors\tagSEC_CONTENT	kindly\tagSEC_CONTENT	provided\tagSEC_CONTENT	us\tagSEC_CONTENT	with\tagSEC_CONTENT	their\tagSEC_CONTENT	F1\tagSEC_CONTENT	numbers\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	their\tagSEC_CONTENT	test\tagSEC_CONTENT	sample\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	compared\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	wordslvt2k-1sent\tagSEC_CONTENT	with\tagSEC_CONTENT	their\tagSEC_CONTENT	best\tagSEC_CONTENT	system\tagSEC_CONTENT	on\tagSEC_CONTENT	their\tagSEC_CONTENT	sample\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	Recall\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	F1\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	displayed\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	reason\tagSEC_CONTENT	we\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	models\tagSEC_CONTENT	here\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	consisted\tagSEC_CONTENT	of\tagSEC_CONTENT	only\tagSEC_CONTENT	1\tagSEC_CONTENT	sentence\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	include\tagSEC_CONTENT	NLP\tagSEC_CONTENT	annotations\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	needed\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	table\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	despite\tagSEC_CONTENT	this\tagSEC_CONTENT	fact\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	model\tagSEC_CONTENT	of\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	recall\tagSEC_CONTENT	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	statistical\tagSEC_CONTENT	significance\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	addition\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	exhibit\tagSEC_CONTENT	better\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	ability\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	src\tagSEC_CONTENT	.\tagSEC_CONTENT	copy\tagSEC_CONTENT	rate\tagSEC_CONTENT	metric\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	column\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	table\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	believe\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	RNN\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	captures\tagSEC_CONTENT	richer\tagSEC_CONTENT	contextual\tagSEC_CONTENT	information\tagSEC_CONTENT	of\tagSEC_CONTENT	every\tagSEC_CONTENT	word\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	bag\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	representation\tagSEC_CONTENT	used\tagSEC_CONTENT	by\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	and\tagSEC_CONTENT	attentional\tagSEC_CONTENT	encoders\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	might\tagSEC_CONTENT	explain\tagSEC_CONTENT	our\tagSEC_CONTENT	superior\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	Further\tagSEC_CONTENT	,\tagSEC_CONTENT	explicit\tagSEC_CONTENT	modeling\tagSEC_CONTENT	of\tagSEC_CONTENT	important\tagSEC_CONTENT	information\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	multiple\tagSEC_CONTENT	source\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	linguistic\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	switch\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	to\tagSEC_CONTENT	point\tagSEC_CONTENT	to\tagSEC_CONTENT	source\tagSEC_CONTENT	words\tagdataset	when\tagSEC_CONTENT	needed\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	,\tagSEC_CONTENT	solve\tagSEC_CONTENT	specific\tagSEC_CONTENT	problems\tagSEC_CONTENT	in\tagSEC_CONTENT	summarization\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	boosting\tagSEC_CONTENT	performance\tagSEC_CONTENT	incrementally\tagSEC_CONTENT	.\tagSEC_END	#\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	name\tagSECTITLE_END	Rouge-1\tagSEC_START	Rouge-2\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	Src\tagSEC_CONTENT	.\tagSEC_CONTENT	copy\tagSEC_CONTENT	rate\tagSEC_CONTENT	(\tagSEC_CONTENT	%\tagSEC_CONTENT	)\tagSEC_CONTENT	Full\tagSEC_CONTENT	length\tagSEC_CONTENT	F1\tagSEC_CONTENT	on\tagSEC_CONTENT	our\tagSEC_CONTENT	internal\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	1\tagdataset	words\tagdataset	-\tagSEC_CONTENT	lvt2k-1sent\tagSEC_END	34\tagSEC_START	 \tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	its\tagSEC_CONTENT	dataset\tagSEC_CONTENT	as\tagSEC_CONTENT	given\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	95\tagSEC_CONTENT	%\tagSEC_CONTENT	confidence\tagSEC_CONTENT	interval\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	official\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	script\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	report\tagSEC_CONTENT	statistical\tagSEC_CONTENT	significance\tagSEC_CONTENT	only\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	performing\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	src\tagSEC_CONTENT	.\tagSEC_CONTENT	copy\tagSEC_CONTENT	rate\tagSEC_CONTENT	'\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	reference\tagSEC_CONTENT	data\tagSEC_CONTENT	on\tagSEC_CONTENT	our\tagSEC_CONTENT	validation\tagSEC_CONTENT	sample\tagSEC_CONTENT	is\tagSEC_CONTENT	45\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	Please\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	Section\tagSEC_CONTENT	4\tagSEC_CONTENT	for\tagSEC_CONTENT	explanation\tagSEC_CONTENT	of\tagSEC_CONTENT	notation\tagSEC_CONTENT	.\tagSEC_END	DUC\tagSECTITLE_START	Corpus\tagSECTITLE_END	The\tagSEC_START	DUC\tagSEC_CONTENT	corpus\tagSEC_CONTENT	8\tagSEC_CONTENT	comes\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	parts\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	2003\tagSEC_CONTENT	corpus\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	624\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	summary\tagtask	pairs\tagtask	and\tagSEC_CONTENT	the\tagSEC_CONTENT	2004\tagSEC_CONTENT	corpus\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	500\tagSEC_CONTENT	pairs\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	these\tagSEC_CONTENT	corpora\tagSEC_CONTENT	are\tagSEC_CONTENT	too\tagSEC_CONTENT	small\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	large\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	on\tagSEC_CONTENT	,\tagSEC_CONTENT	Rush\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	trained\tagSEC_CONTENT	their\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	combined\tagSEC_CONTENT	it\tagSEC_CONTENT	with\tagSEC_CONTENT	an\tagSEC_CONTENT	additional\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	extractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	handcrafted\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	DUC\tagSEC_CONTENT	2003\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	call\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	neural\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	the\tagSEC_CONTENT	ABS\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	combined\tagSEC_CONTENT	model\tagSEC_CONTENT	ABS+\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	latter\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	current\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	since\tagSEC_CONTENT	it\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	all\tagSEC_CONTENT	previously\tagSEC_CONTENT	published\tagSEC_CONTENT	baselines\tagSEC_CONTENT	including\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	based\tagSEC_CONTENT	extractive\tagSEC_CONTENT	and\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	systems\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	measured\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	official\tagSEC_CONTENT	DUC\tagSEC_CONTENT	metric\tagSEC_CONTENT	of\tagSEC_CONTENT	limited\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	recall\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	these\tagSEC_CONTENT	experiments\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	metric\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	too\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	we\tagSEC_CONTENT	omit\tagSEC_CONTENT	reporting\tagSEC_CONTENT	numbers\tagSEC_CONTENT	from\tagSEC_CONTENT	other\tagSEC_CONTENT	systems\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	interest\tagSEC_CONTENT	of\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	our\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	simply\tagSEC_CONTENT	run\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	without\tagSEC_CONTENT	tuning\tagSEC_CONTENT	it\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	DUC\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	only\tagSEC_CONTENT	change\tagSEC_CONTENT	we\tagSEC_CONTENT	made\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	suppress\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	from\tagSEC_CONTENT	emitting\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	summary\tagSEC_CONTENT	tag\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	force\tagSEC_CONTENT	it\tagSEC_CONTENT	to\tagSEC_CONTENT	emit\tagSEC_CONTENT	exactly\tagSEC_CONTENT	30\tagSEC_CONTENT	words\tagSEC_CONTENT	for\tagSEC_CONTENT	every\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	the\tagSEC_CONTENT	official\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	limitedlength\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	recall\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	too\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	we\tagSEC_CONTENT	have\tagSEC_CONTENT	only\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	sentence\tagSEC_CONTENT	from\tagSEC_CONTENT	source\tagSEC_CONTENT	and\tagSEC_CONTENT	no\tagSEC_CONTENT	NLP\tagSEC_CONTENT	annotations\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	ran\tagSEC_CONTENT	just\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	wordslvt2k-1sent\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	is\tagSEC_CONTENT	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	ABS\tagSEC_CONTENT	and\tagSEC_CONTENT	ABS+\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	TOPIARY\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	performing\tagSEC_CONTENT	system\tagSEC_CONTENT	on\tagSEC_CONTENT	DUC-2004\tagdataset	in\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	note\tagSEC_CONTENT	that\tagSEC_CONTENT	although\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	8\tagSEC_CONTENT	http://duc.nist.gov/duc2004/tasks.html\tagSEC_CONTENT	consistently\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	ABS+\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	three\tagSEC_CONTENT	variants\tagSEC_CONTENT	of\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	differences\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	statistically\tagSEC_CONTENT	significant\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	when\tagSEC_CONTENT	the\tagSEC_CONTENT	comparison\tagSEC_CONTENT	is\tagSEC_CONTENT	made\tagSEC_CONTENT	with\tagSEC_CONTENT	ABS\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	really\tagSEC_CONTENT	the\tagSEC_CONTENT	true\tagSEC_CONTENT	un\tagSEC_CONTENT	-\tagSEC_CONTENT	tuned\tagSEC_CONTENT	counterpart\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	are\tagSEC_CONTENT	indeed\tagSEC_CONTENT	statistically\tagSEC_CONTENT	significant\tagSEC_CONTENT	.\tagSEC_END	Model\tagSECTITLE_END	Rouge\tagSEC_START	 \tagSEC_CONTENT	We\tagSEC_CONTENT	would\tagSEC_CONTENT	also\tagSEC_CONTENT	like\tagSEC_CONTENT	to\tagSEC_CONTENT	bring\tagSEC_CONTENT	the\tagSEC_CONTENT	reader\tagSEC_CONTENT	's\tagSEC_CONTENT	attention\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	concurrently\tagSEC_CONTENT	published\tagSEC_CONTENT	work\tagSEC_CONTENT	of\tagSEC_CONTENT	where\tagSEC_CONTENT	they\tagSEC_CONTENT	also\tagSEC_CONTENT	used\tagSEC_CONTENT	an\tagSEC_CONTENT	RNN\tagSEC_CONTENT	based\tagSEC_CONTENT	decoder\tagSEC_CONTENT	for\tagSEC_CONTENT	summary\tagSEC_CONTENT	generation\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	their\tagSEC_CONTENT	numbers\tagSEC_CONTENT	on\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	are\tagSEC_CONTENT	slightly\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	three\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	F1\tagSEC_CONTENT	metrics\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	performance\tagSEC_CONTENT	is\tagSEC_CONTENT	marginally\tagSEC_CONTENT	higher\tagSEC_CONTENT	on\tagSEC_CONTENT	DUC-2004\tagSEC_CONTENT	corpus\tagSEC_CONTENT	on\tagSEC_CONTENT	Rouge-2\tagSEC_CONTENT	and\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	-\tagSEC_CONTENT	L.\tagSEC_CONTENT	We\tagSEC_CONTENT	believe\tagSEC_CONTENT	their\tagSEC_CONTENT	work\tagSEC_CONTENT	also\tagSEC_CONTENT	confirms\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	RNN\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	text\tagSEC_CONTENT	summarization\tagSEC_CONTENT	.\tagSEC_END	CNN\tagSECTITLE_START	/\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	Corpus\tagSECTITLE_END	The\tagSEC_START	existing\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	text\tagSEC_CONTENT	summarization\tagSEC_CONTENT	corpora\tagSEC_CONTENT	including\tagSEC_CONTENT	Gigaword\tagdataset	and\tagSEC_CONTENT	DUC\tagSEC_CONTENT	consist\tagSEC_CONTENT	of\tagSEC_CONTENT	only\tagSEC_CONTENT	one\tagSEC_CONTENT	sentence\tagSEC_CONTENT	in\tagSEC_CONTENT	each\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	present\tagSEC_CONTENT	anew\tagSEC_CONTENT	corpus\tagSEC_CONTENT	that\tagSEC_CONTENT	comprises\tagSEC_CONTENT	multisentence\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	produce\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	modify\tagSEC_CONTENT	an\tagSEC_CONTENT	existing\tagSEC_CONTENT	corpus\tagSEC_CONTENT	that\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	used\tagSEC_CONTENT	  \tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	passage\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	authors\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	generated\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summary\tagSEC_CONTENT	bullets\tagSEC_CONTENT	from\tagSEC_CONTENT	new\tagSEC_CONTENT	-\tagSEC_CONTENT	stories\tagSEC_CONTENT	in\tagSEC_CONTENT	CNN\tagSEC_CONTENT	and\tagSEC_CONTENT	Daily\tagSEC_CONTENT	Mail\tagSEC_CONTENT	websites\tagSEC_CONTENT	as\tagSEC_CONTENT	questions\tagSEC_CONTENT	(\tagSEC_CONTENT	with\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	entities\tagSEC_CONTENT	hidden\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	stories\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	passages\tagSEC_CONTENT	from\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	system\tagSEC_CONTENT	is\tagSEC_CONTENT	expected\tagSEC_CONTENT	to\tagSEC_CONTENT	answer\tagSEC_CONTENT	the\tagSEC_CONTENT	fill\tagSEC_CONTENT	-\tagSEC_CONTENT	in\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	blank\tagSEC_CONTENT	question\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	authors\tagSEC_CONTENT	released\tagSEC_CONTENT	the\tagSEC_CONTENT	scripts\tagSEC_CONTENT	that\tagSEC_CONTENT	crawl\tagSEC_CONTENT	,\tagSEC_CONTENT	extract\tagSEC_CONTENT	and\tagSEC_CONTENT	generate\tagSEC_CONTENT	pairs\tagSEC_CONTENT	of\tagSEC_CONTENT	passages\tagSEC_CONTENT	and\tagSEC_CONTENT	questions\tagSEC_CONTENT	from\tagSEC_CONTENT	these\tagSEC_CONTENT	websites\tagSEC_CONTENT	.\tagSEC_CONTENT	With\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	modification\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	script\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	restored\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	bullets\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	story\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	each\tagSEC_CONTENT	bullet\tagSEC_CONTENT	is\tagSEC_CONTENT	treated\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	all\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	has\tagSEC_CONTENT	286,817\tagSEC_CONTENT	training\tagSEC_CONTENT	pairs\tagSEC_CONTENT	,\tagSEC_CONTENT	13,368\tagSEC_CONTENT	validation\tagSEC_CONTENT	pairs\tagSEC_CONTENT	and\tagSEC_CONTENT	11,487\tagSEC_CONTENT	test\tagSEC_CONTENT	pairs\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	defined\tagSEC_CONTENT	by\tagSEC_CONTENT	their\tagSEC_CONTENT	scripts\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	source\tagSEC_CONTENT	documents\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	have\tagSEC_CONTENT	766\tagSEC_CONTENT	words\tagSEC_CONTENT	spanning\tagSEC_CONTENT	29.74\tagSEC_CONTENT	sentences\tagSEC_CONTENT	on\tagSEC_CONTENT	an\tagSEC_CONTENT	average\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	summaries\tagSEC_CONTENT	consist\tagSEC_CONTENT	of\tagSEC_CONTENT	53\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	3.72\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	unique\tagSEC_CONTENT	characteristics\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	long\tagSEC_CONTENT	documents\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	ordered\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	summaries\tagSEC_CONTENT	present\tagSEC_CONTENT	interesting\tagSEC_CONTENT	challenges\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	hope\tagSEC_CONTENT	will\tagSEC_CONTENT	attract\tagSEC_CONTENT	future\tagSEC_CONTENT	researchers\tagSEC_CONTENT	to\tagSEC_CONTENT	build\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	novel\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	released\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	versions\tagSEC_CONTENT	:\tagSEC_CONTENT	one\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	actual\tagSEC_CONTENT	entity\tagSEC_CONTENT	names\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	entity\tagSEC_CONTENT	occurrences\tagSEC_CONTENT	are\tagSEC_CONTENT	replaced\tagSEC_CONTENT	with\tagSEC_CONTENT	document\tagSEC_CONTENT	-\tagSEC_CONTENT	specific\tagSEC_CONTENT	integer\tagSEC_CONTENT	-\tagSEC_CONTENT	ids\tagSEC_CONTENT	beginning\tagSEC_CONTENT	from\tagSEC_CONTENT	0\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	size\tagSEC_CONTENT	is\tagSEC_CONTENT	smaller\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagdataset	anonymized\tagdataset	version\tagdataset	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	it\tagSEC_CONTENT	in\tagSEC_CONTENT	all\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	below\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	limited\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	size\tagSEC_CONTENT	to\tagSEC_CONTENT	150\tagSEC_CONTENT	K\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	to\tagSEC_CONTENT	60\tagSEC_CONTENT	K\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	and\tagSEC_CONTENT	target\tagSEC_CONTENT	lengths\tagSEC_CONTENT	to\tagSEC_CONTENT	at\tagSEC_CONTENT	most\tagSEC_CONTENT	800\tagSEC_CONTENT	and\tagSEC_CONTENT	100\tagSEC_CONTENT	words\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	100-dimensional\tagSEC_CONTENT	word2vec\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	fixed\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	size\tagSEC_CONTENT	at\tagSEC_CONTENT	200\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	created\tagSEC_CONTENT	explicit\tagSEC_CONTENT	pointers\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	by\tagSEC_CONTENT	matching\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	anonymized\tagSEC_CONTENT	entityids\tagSEC_CONTENT	between\tagSEC_CONTENT	source\tagSEC_CONTENT	and\tagSEC_CONTENT	target\tagSEC_CONTENT	on\tagSEC_CONTENT	similar\tagSEC_CONTENT	lines\tagSEC_CONTENT	as\tagSEC_CONTENT	we\tagSEC_CONTENT	did\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	OOV\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_END	Computational\tagSEC_START	costs\tagSEC_CONTENT	:\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	Tesla\tagSEC_CONTENT	K-40\tagSEC_CONTENT	GPU\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	the\tagSEC_CONTENT	flat\tagSEC_CONTENT	models\tagSEC_CONTENT	(\tagSEC_CONTENT	words\tagdataset	-\tagSEC_CONTENT	lvt2k\tagSEC_CONTENT	and\tagSEC_CONTENT	wordslvt2k\tagSEC_CONTENT	-\tagSEC_CONTENT	ptr\tagSEC_CONTENT	)\tagSEC_CONTENT	took\tagSEC_CONTENT	under\tagSEC_CONTENT	5\tagSEC_CONTENT	hours\tagSEC_CONTENT	per\tagSEC_CONTENT	epoch\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	was\tagSEC_CONTENT	very\tagSEC_CONTENT	expensive\tagSEC_CONTENT	,\tagSEC_CONTENT	consuming\tagSEC_CONTENT	nearly\tagSEC_CONTENT	12.5\tagSEC_CONTENT	hours\tagSEC_CONTENT	per\tagSEC_CONTENT	epoch\tagSEC_CONTENT	.\tagSEC_CONTENT	Convergence\tagSEC_CONTENT	of\tagSEC_CONTENT	all\tagSEC_CONTENT	models\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	slower\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	,\tagSEC_CONTENT	taking\tagSEC_CONTENT	nearly\tagSEC_CONTENT	35\tagSEC_CONTENT	epochs\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Thus\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	wall\tagSEC_CONTENT	-\tagSEC_CONTENT	clock\tagSEC_CONTENT	time\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	until\tagSEC_CONTENT	convergence\tagSEC_CONTENT	is\tagSEC_CONTENT	about\tagSEC_CONTENT	7\tagSEC_CONTENT	days\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	flat\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	nearly\tagSEC_CONTENT	18\tagSEC_CONTENT	days\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Decoding\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	slower\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	throughput\tagSEC_CONTENT	of\tagSEC_CONTENT	2\tagSEC_CONTENT	examples\tagSEC_CONTENT	per\tagSEC_CONTENT	second\tagSEC_CONTENT	for\tagSEC_CONTENT	flat\tagSEC_CONTENT	models\tagSEC_CONTENT	and\tagSEC_CONTENT	1.5\tagSEC_CONTENT	examples\tagSEC_CONTENT	per\tagSEC_CONTENT	second\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	when\tagSEC_CONTENT	run\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	GPU\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	batch\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_CONTENT	Evaluation\tagSEC_CONTENT	:\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	full\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	F1\tagSEC_CONTENT	metric\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	employed\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	with\tagSEC_CONTENT	one\tagSEC_CONTENT	notable\tagSEC_CONTENT	difference\tagSEC_CONTENT	:\tagSEC_CONTENT	in\tagSEC_CONTENT	both\tagSEC_CONTENT	system\tagSEC_CONTENT	and\tagSEC_CONTENT	gold\tagSEC_CONTENT	summaries\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	considered\tagSEC_CONTENT	each\tagSEC_CONTENT	highlight\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	separate\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	Results\tagSEC_CONTENT	:\tagSEC_CONTENT	Results\tagSEC_CONTENT	from\tagSEC_CONTENT	three\tagSEC_CONTENT	models\tagSEC_CONTENT	we\tagSEC_CONTENT	ran\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	corpus\tagSEC_CONTENT	are\tagSEC_CONTENT	displayed\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	smaller\tagSEC_CONTENT	and\tagSEC_CONTENT	more\tagSEC_CONTENT	complex\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	interesting\tagSEC_CONTENT	to\tagSEC_CONTENT	note\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	numbers\tagSEC_CONTENT	are\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	range\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	switching\tagSEC_CONTENT	pointer\tagSEC_CONTENT	/\tagSEC_CONTENT	generator\tagSEC_CONTENT	model\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Sec\tagSEC_CONTENT	.\tagSEC_CONTENT	2.4\tagSEC_CONTENT	fail\tagSEC_CONTENT	to\tagSEC_CONTENT	outperform\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	attentional\tagSEC_CONTENT	decoder\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	that\tagSEC_CONTENT	further\tagSEC_CONTENT	research\tagSEC_CONTENT	and\tagSEC_CONTENT	experimentation\tagSEC_CONTENT	needs\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	done\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	results\tagSEC_CONTENT	,\tagSEC_CONTENT	although\tagSEC_CONTENT	preliminary\tagSEC_CONTENT	,\tagSEC_CONTENT	should\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	good\tagSEC_CONTENT	baseline\tagSEC_CONTENT	for\tagSEC_CONTENT	future\tagSEC_CONTENT	researchers\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	their\tagSEC_CONTENT	models\tagSEC_CONTENT	against\tagSEC_CONTENT	.\tagSEC_CONTENT	presents\tagSEC_CONTENT	a\tagSEC_CONTENT	few\tagSEC_CONTENT	high\tagSEC_CONTENT	quality\tagSEC_CONTENT	and\tagSEC_CONTENT	poor\tagSEC_CONTENT	quality\tagSEC_CONTENT	output\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	from\tagSEC_CONTENT	feats\tagSEC_CONTENT	-\tagSEC_CONTENT	lvt2k-2sent\tagSEC_CONTENT	,\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	performing\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Even\tagSEC_CONTENT	when\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	differs\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	its\tagSEC_CONTENT	summaries\tagSEC_CONTENT	tend\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	very\tagSEC_CONTENT	meaningful\tagSEC_CONTENT	and\tagSEC_CONTENT	relevant\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	phenomenon\tagSEC_CONTENT	not\tagSEC_CONTENT	captured\tagSEC_CONTENT	by\tagSEC_CONTENT	word\tagSEC_CONTENT	/\tagSEC_CONTENT	phrase\tagSEC_CONTENT	matching\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	metrics\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	Rouge\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	hand\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	sometimes\tagSEC_CONTENT	'\tagSEC_CONTENT	misinterprets\tagSEC_CONTENT	'\tagSEC_CONTENT	the\tagSEC_CONTENT	semantics\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	and\tagSEC_CONTENT	generates\tagSEC_CONTENT	a\tagSEC_CONTENT	summary\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	comical\tagSEC_CONTENT	interpretation\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	poor\tagSEC_CONTENT	quality\tagSEC_CONTENT	examples\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	table\tagSEC_CONTENT	.\tagSEC_CONTENT	Clearly\tagSEC_CONTENT	,\tagSEC_CONTENT	capturing\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	meaning\tagSEC_CONTENT	'\tagSEC_CONTENT	of\tagSEC_CONTENT	complex\tagSEC_CONTENT	sentences\tagSEC_CONTENT	remains\tagSEC_CONTENT	a\tagSEC_CONTENT	weakness\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	Our\tagSEC_START	next\tagSEC_CONTENT	example\tagSEC_CONTENT	output\tagSEC_CONTENT	,\tagSEC_CONTENT	presented\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	displays\tagSEC_CONTENT	the\tagSEC_CONTENT	sample\tagSEC_CONTENT	output\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	switching\tagSEC_CONTENT	generator\tagSEC_CONTENT	/\tagSEC_CONTENT	pointer\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	Gigaword\tagdataset	corpus\tagdataset	.\tagSEC_END	Good\tagSEC_START	quality\tagSEC_CONTENT	summary\tagSEC_CONTENT	output\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	a\tagSEC_CONTENT	man\tagSEC_CONTENT	charged\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	murder\tagSEC_CONTENT	last\tagSEC_CONTENT	year\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	british\tagSEC_CONTENT	backpacker\tagSEC_CONTENT	confessed\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	slaying\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	night\tagSEC_CONTENT	he\tagSEC_CONTENT	was\tagSEC_CONTENT	charged\tagSEC_CONTENT	with\tagSEC_CONTENT	her\tagSEC_CONTENT	killing\tagSEC_CONTENT	,\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	police\tagSEC_CONTENT	evidence\tagSEC_CONTENT	presented\tagSEC_CONTENT	at\tagSEC_CONTENT	a\tagSEC_CONTENT	court\tagSEC_CONTENT	hearing\tagSEC_CONTENT	tuesday\tagSEC_CONTENT	.\tagSEC_CONTENT	ian\tagSEC_CONTENT	douglas\tagSEC_CONTENT	previte\tagSEC_CONTENT	,\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	charged\tagSEC_CONTENT	with\tagSEC_CONTENT	murdering\tagSEC_CONTENT	caroline\tagSEC_CONTENT	stuttle\tagSEC_CONTENT	,\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	,\tagSEC_CONTENT	of\tagSEC_CONTENT	yorkshire\tagSEC_CONTENT	,\tagSEC_CONTENT	england\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	man\tagSEC_CONTENT	charged\tagSEC_CONTENT	with\tagSEC_CONTENT	british\tagSEC_CONTENT	backpacker\tagSEC_CONTENT	's\tagSEC_CONTENT	death\tagSEC_CONTENT	confessed\tagSEC_CONTENT	to\tagSEC_CONTENT	crime\tagSEC_CONTENT	police\tagSEC_CONTENT	officer\tagSEC_CONTENT	claims\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	man\tagSEC_CONTENT	charged\tagSEC_CONTENT	with\tagSEC_CONTENT	murdering\tagSEC_CONTENT	british\tagSEC_CONTENT	backpacker\tagSEC_CONTENT	confessed\tagSEC_CONTENT	to\tagSEC_CONTENT	murder\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	following\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	leading\tagSEC_CONTENT	scorers\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	english\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	after\tagSEC_CONTENT	saturday\tagSEC_CONTENT	's\tagSEC_CONTENT	matches\tagSEC_CONTENT	:\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	-alan\tagSEC_CONTENT	shearer\tagSEC_CONTENT	-lrbnewcastle\tagSEC_CONTENT	united\tagSEC_CONTENT	-rrb-\tagSEC_CONTENT	,\tagSEC_CONTENT	james\tagSEC_CONTENT	beattie\tagSEC_CONTENT	.\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	leading\tagSEC_CONTENT	scorers\tagSEC_CONTENT	in\tagSEC_CONTENT	english\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	english\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	leading\tagSEC_CONTENT	scorers\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	volume\tagSEC_CONTENT	of\tagSEC_CONTENT	transactions\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	nigerian\tagSEC_CONTENT	stock\tagSEC_CONTENT	exchange\tagSEC_CONTENT	has\tagSEC_CONTENT	continued\tagSEC_CONTENT	its\tagSEC_CONTENT	decline\tagSEC_CONTENT	since\tagSEC_CONTENT	last\tagSEC_CONTENT	week\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	nse\tagSEC_CONTENT	official\tagSEC_CONTENT	said\tagSEC_CONTENT	thursday\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	latest\tagSEC_CONTENT	statistics\tagSEC_CONTENT	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	total\tagSEC_CONTENT	of\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	.\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	million\tagSEC_CONTENT	shares\tagSEC_CONTENT	valued\tagSEC_CONTENT	at\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	.\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	million\tagSEC_CONTENT	naira\tagSEC_CONTENT	-lrb\tagSEC_CONTENT	-\tagSEC_CONTENT	about\tagSEC_CONTENT	#\tagSEC_CONTENT	.\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	million\tagSEC_CONTENT	us\tagSEC_CONTENT	dollars\tagSEC_CONTENT	-rrb\tagSEC_CONTENT	-\tagSEC_CONTENT	were\tagSEC_CONTENT	traded\tagSEC_CONTENT	on\tagSEC_CONTENT	wednesday\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	deals\tagSEC_CONTENT	.\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	transactions\tagSEC_CONTENT	dip\tagSEC_CONTENT	at\tagSEC_CONTENT	nigerian\tagSEC_CONTENT	stock\tagSEC_CONTENT	exchange\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	transactions\tagSEC_CONTENT	at\tagSEC_CONTENT	nigerian\tagSEC_CONTENT	stock\tagSEC_CONTENT	exchange\tagSEC_CONTENT	down\tagSEC_CONTENT	Poor\tagSEC_CONTENT	quality\tagSEC_CONTENT	summary\tagSEC_CONTENT	output\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	broccoli\tagSEC_CONTENT	and\tagSEC_CONTENT	broccoli\tagSEC_CONTENT	sprouts\tagSEC_CONTENT	contain\tagSEC_CONTENT	a\tagSEC_CONTENT	chemical\tagSEC_CONTENT	that\tagSEC_CONTENT	kills\tagSEC_CONTENT	the\tagSEC_CONTENT	bacteria\tagSEC_CONTENT	responsible\tagSEC_CONTENT	for\tagSEC_CONTENT	most\tagSEC_CONTENT	stomach\tagSEC_CONTENT	cancer\tagSEC_CONTENT	,\tagSEC_CONTENT	say\tagSEC_CONTENT	researchers\tagSEC_CONTENT	,\tagSEC_CONTENT	confirming\tagSEC_CONTENT	the\tagSEC_CONTENT	dietary\tagSEC_CONTENT	advice\tagSEC_CONTENT	that\tagSEC_CONTENT	moms\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	handing\tagSEC_CONTENT	out\tagSEC_CONTENT	for\tagSEC_CONTENT	years\tagSEC_CONTENT	.\tagSEC_CONTENT	in\tagSEC_CONTENT	laboratory\tagSEC_CONTENT	tests\tagSEC_CONTENT	the\tagSEC_CONTENT	chemical\tagSEC_CONTENT	,\tagSEC_CONTENT	<\tagSEC_CONTENT	unk\tagSEC_CONTENT	>\tagSEC_CONTENT	,\tagSEC_CONTENT	killed\tagSEC_CONTENT	helicobacter\tagSEC_CONTENT	pylori\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	bacteria\tagSEC_CONTENT	that\tagSEC_CONTENT	causes\tagSEC_CONTENT	stomach\tagSEC_CONTENT	ulcers\tagSEC_CONTENT	and\tagSEC_CONTENT	often\tagSEC_CONTENT	fatal\tagSEC_CONTENT	stomach\tagSEC_CONTENT	cancers\tagSEC_CONTENT	.\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	for\tagSEC_CONTENT	release\tagSEC_CONTENT	at\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	#\tagSEC_CONTENT	<\tagSEC_CONTENT	unk\tagSEC_CONTENT	>\tagSEC_CONTENT	mom\tagSEC_CONTENT	was\tagSEC_CONTENT	right\tagSEC_CONTENT	broccoli\tagSEC_CONTENT	is\tagSEC_CONTENT	good\tagSEC_CONTENT	for\tagSEC_CONTENT	you\tagSEC_CONTENT	say\tagSEC_CONTENT	cancer\tagSEC_CONTENT	researchers\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	broccoli\tagSEC_CONTENT	sprouts\tagSEC_CONTENT	contain\tagSEC_CONTENT	deadly\tagSEC_CONTENT	bacteria\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	norway\tagSEC_CONTENT	delivered\tagSEC_CONTENT	a\tagSEC_CONTENT	diplomatic\tagSEC_CONTENT	protest\tagSEC_CONTENT	to\tagSEC_CONTENT	russia\tagSEC_CONTENT	on\tagSEC_CONTENT	monday\tagSEC_CONTENT	after\tagSEC_CONTENT	three\tagSEC_CONTENT	norwegian\tagSEC_CONTENT	fisheries\tagSEC_CONTENT	research\tagSEC_CONTENT	expeditions\tagSEC_CONTENT	were\tagSEC_CONTENT	barred\tagSEC_CONTENT	from\tagSEC_CONTENT	russian\tagSEC_CONTENT	waters\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	norwegian\tagSEC_CONTENT	research\tagSEC_CONTENT	ships\tagSEC_CONTENT	were\tagSEC_CONTENT	to\tagSEC_CONTENT	continue\tagSEC_CONTENT	an\tagSEC_CONTENT	annual\tagSEC_CONTENT	program\tagSEC_CONTENT	of\tagSEC_CONTENT	charting\tagSEC_CONTENT	fish\tagSEC_CONTENT	resources\tagSEC_CONTENT	shared\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	countries\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	barents\tagSEC_CONTENT	sea\tagSEC_CONTENT	region\tagSEC_CONTENT	.\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	norway\tagSEC_CONTENT	protests\tagSEC_CONTENT	russia\tagSEC_CONTENT	barring\tagSEC_CONTENT	fisheries\tagSEC_CONTENT	research\tagSEC_CONTENT	ships\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	norway\tagSEC_CONTENT	grants\tagSEC_CONTENT	diplomatic\tagSEC_CONTENT	protest\tagSEC_CONTENT	to\tagSEC_CONTENT	russia\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	j.p\tagSEC_CONTENT	.\tagSEC_CONTENT	morgan\tagSEC_CONTENT	chase\tagSEC_CONTENT	's\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	recover\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	slew\tagSEC_CONTENT	of\tagSEC_CONTENT	recent\tagSEC_CONTENT	losses\tagSEC_CONTENT	rests\tagSEC_CONTENT	largely\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	hands\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	men\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	are\tagSEC_CONTENT	both\tagSEC_CONTENT	looking\tagSEC_CONTENT	to\tagSEC_CONTENT	restore\tagSEC_CONTENT	tarnished\tagSEC_CONTENT	reputations\tagSEC_CONTENT	and\tagSEC_CONTENT	maybe\tagSEC_CONTENT	considered\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	job\tagSEC_CONTENT	someday\tagSEC_CONTENT	.\tagSEC_CONTENT	geoffrey\tagSEC_CONTENT	<\tagSEC_CONTENT	unk\tagSEC_CONTENT	>\tagSEC_CONTENT	,\tagSEC_CONTENT	now\tagSEC_CONTENT	the\tagSEC_CONTENT	co\tagSEC_CONTENT	-\tagSEC_CONTENT	head\tagSEC_CONTENT	of\tagSEC_CONTENT	j.p\tagSEC_CONTENT	.\tagSEC_CONTENT	morgan\tagSEC_CONTENT	's\tagSEC_CONTENT	investment\tagSEC_CONTENT	bank\tagSEC_CONTENT	,\tagSEC_CONTENT	left\tagSEC_CONTENT	goldman\tagSEC_CONTENT	,\tagSEC_CONTENT	sachs\tagSEC_CONTENT	&\tagSEC_CONTENT	co.\tagSEC_CONTENT	more\tagSEC_CONTENT	than\tagSEC_CONTENT	a\tagSEC_CONTENT	decade\tagSEC_CONTENT	ago\tagSEC_CONTENT	after\tagSEC_CONTENT	executives\tagSEC_CONTENT	say\tagSEC_CONTENT	he\tagSEC_CONTENT	lost\tagSEC_CONTENT	out\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	bid\tagSEC_CONTENT	to\tagSEC_CONTENT	lead\tagSEC_CONTENT	that\tagSEC_CONTENT	firm\tagSEC_CONTENT	.\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	#\tagSEC_CONTENT	executives\tagSEC_CONTENT	to\tagSEC_CONTENT	lead\tagSEC_CONTENT	j.p\tagSEC_CONTENT	.\tagSEC_CONTENT	morgan\tagSEC_CONTENT	chase\tagSEC_CONTENT	on\tagSEC_CONTENT	road\tagSEC_CONTENT	to\tagSEC_CONTENT	recovery\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	j.p\tagSEC_CONTENT	.\tagSEC_CONTENT	morgan\tagSEC_CONTENT	chase\tagSEC_CONTENT	maybe\tagSEC_CONTENT	considered\tagSEC_CONTENT	for\tagSEC_CONTENT	top\tagSEC_CONTENT	job\tagSEC_CONTENT	:\tagSEC_CONTENT	Examples\tagSEC_CONTENT	of\tagSEC_CONTENT	generated\tagSEC_CONTENT	summaries\tagSEC_CONTENT	from\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	Gigaword\tagdataset	corpus\tagdataset	.\tagSEC_CONTENT	S\tagSEC_CONTENT	:\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	T\tagSEC_CONTENT	:\tagSEC_CONTENT	target\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	O\tagSEC_CONTENT	:\tagSEC_CONTENT	system\tagSEC_CONTENT	output\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	we\tagSEC_CONTENT	displayed\tagSEC_CONTENT	equal\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	good\tagSEC_CONTENT	quality\tagSEC_CONTENT	and\tagSEC_CONTENT	poor\tagSEC_CONTENT	quality\tagSEC_CONTENT	summaries\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	table\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	good\tagSEC_CONTENT	ones\tagSEC_CONTENT	are\tagSEC_CONTENT	far\tagSEC_CONTENT	more\tagSEC_CONTENT	prevalent\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	poor\tagSEC_CONTENT	ones\tagSEC_CONTENT	.\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	An\tagSEC_CONTENT	arrow\tagSEC_CONTENT	indicates\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	pointer\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	position\tagSEC_CONTENT	was\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	summary\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_END	It\tagSEC_START	is\tagSEC_CONTENT	apparent\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	examples\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	learns\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	pointers\tagSEC_CONTENT	very\tagSEC_CONTENT	accurately\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	for\tagSEC_CONTENT	named\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	for\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	word\tagSEC_CONTENT	phrases\tagSEC_CONTENT	.\tagSEC_CONTENT	Despite\tagSEC_CONTENT	its\tagSEC_CONTENT	accuracy\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	improvement\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	overall\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	significant\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	believe\tagSEC_CONTENT	the\tagSEC_CONTENT	impact\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	maybe\tagSEC_CONTENT	more\tagSEC_CONTENT	pronounced\tagSEC_CONTENT	in\tagSEC_CONTENT	other\tagSEC_CONTENT	settings\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	heavier\tagSEC_CONTENT	tail\tagSEC_CONTENT	distribution\tagSEC_CONTENT	of\tagSEC_CONTENT	rare\tagdataset	words\tagdataset	.\tagSEC_CONTENT	We\tagSEC_CONTENT	intend\tagSEC_CONTENT	to\tagSEC_CONTENT	carryout\tagSEC_CONTENT	more\tagSEC_CONTENT	experiments\tagSEC_CONTENT	with\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	future\tagSEC_CONTENT	.\tagSEC_END	On\tagSEC_START	CNN\tagdataset	/\tagdataset	Daily\tagdataset	Mail\tagdataset	data\tagdataset	,\tagSEC_CONTENT	although\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	are\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	produce\tagSEC_CONTENT	good\tagSEC_CONTENT	quality\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	summaries\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	notice\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	sentence\tagSEC_CONTENT	or\tagSEC_CONTENT	phrase\tagSEC_CONTENT	often\tagSEC_CONTENT	gets\tagSEC_CONTENT	repeated\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	believe\tagSEC_CONTENT	models\tagSEC_CONTENT	that\tagSEC_CONTENT	incorporate\tagSEC_CONTENT	intra\tagSEC_CONTENT	-\tagSEC_CONTENT	attention\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	 \tagSEC_CONTENT	can\tagSEC_CONTENT	fix\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	by\tagSEC_CONTENT	encouraging\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	remember\tagSEC_CONTENT	'\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	already\tagSEC_CONTENT	produced\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	past\tagSEC_CONTENT	.\tagSEC_END	Conclusion\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	apply\tagSEC_CONTENT	the\tagSEC_CONTENT	attentional\tagSEC_CONTENT	encoderdecoder\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	abstractive\tagtask	summarization\tagtask	with\tagSEC_CONTENT	very\tagSEC_CONTENT	promising\tagSEC_CONTENT	results\tagSEC_CONTENT	,\tagSEC_CONTENT	outperforming\tagSEC_CONTENT	stateof\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	results\tagSEC_CONTENT	significantly\tagSEC_CONTENT	on\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	novel\tagSEC_CONTENT	models\tagSEC_CONTENT	addresses\tagSEC_CONTENT	a\tagSEC_CONTENT	specific\tagSEC_CONTENT	problem\tagSEC_CONTENT	in\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	,\tagSEC_CONTENT	yielding\tagSEC_CONTENT	further\tagSEC_CONTENT	improvement\tagSEC_CONTENT	in\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	propose\tagSEC_CONTENT	anew\tagSEC_CONTENT	dataset\tagSEC_CONTENT	for\tagSEC_CONTENT	multisentence\tagSEC_CONTENT	summarization\tagSEC_CONTENT	and\tagSEC_CONTENT	establish\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	numbers\tagSEC_CONTENT	on\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	future\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	plan\tagSEC_CONTENT	to\tagSEC_CONTENT	focus\tagSEC_CONTENT	our\tagSEC_CONTENT	efforts\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	data\tagSEC_CONTENT	and\tagSEC_CONTENT	build\tagSEC_CONTENT	more\tagSEC_CONTENT	robust\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	summaries\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	multiple\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_END	
1605.07725	title\tagSECTITLE_END	ADVERSARIAL\tagSEC_START	TRAINING\tagSEC_CONTENT	METHODS\tagSEC_CONTENT	FOR\tagSEC_CONTENT	SEMI\tagSEC_CONTENT	-\tagSEC_CONTENT	SUPERVISED\tagSEC_CONTENT	TEXT\tagSEC_CONTENT	CLASSIFICATION\tagSEC_END	abstract\tagSECTITLE_END	Adversarial\tagSEC_START	training\tagSEC_CONTENT	provides\tagSEC_CONTENT	a\tagSEC_CONTENT	means\tagSEC_CONTENT	of\tagSEC_CONTENT	regularizing\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	while\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	extend\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	setting\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	both\tagSEC_CONTENT	methods\tagSEC_CONTENT	require\tagSEC_CONTENT	making\tagSEC_CONTENT	small\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	to\tagSEC_CONTENT	numerous\tagSEC_CONTENT	entries\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	inappropriate\tagSEC_CONTENT	for\tagSEC_CONTENT	sparse\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	inputs\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	word\tagSEC_CONTENT	representations\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	extend\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	domain\tagSEC_CONTENT	by\tagSEC_CONTENT	applying\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	input\tagSEC_CONTENT	itself\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	proposed\tagSEC_CONTENT	method\tagSEC_CONTENT	achieves\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	multiple\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	and\tagSEC_CONTENT	purely\tagSEC_CONTENT	supervised\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	provide\tagSEC_CONTENT	visualizations\tagSEC_CONTENT	and\tagSEC_CONTENT	analysis\tagtask	showing\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	learned\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	have\tagSEC_CONTENT	improved\tagSEC_CONTENT	in\tagSEC_CONTENT	quality\tagSEC_CONTENT	and\tagSEC_CONTENT	that\tagSEC_CONTENT	while\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	less\tagSEC_CONTENT	prone\tagSEC_CONTENT	to\tagSEC_CONTENT	overfitting\tagSEC_CONTENT	.\tagSEC_END	INTRODUCTION\tagSECTITLE_END	Adversarial\tagSEC_START	examples\tagSEC_CONTENT	are\tagSEC_CONTENT	examples\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	created\tagSEC_CONTENT	by\tagSEC_CONTENT	making\tagSEC_CONTENT	small\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	designed\tagSEC_CONTENT	to\tagSEC_CONTENT	significantly\tagSEC_CONTENT	increase\tagSEC_CONTENT	the\tagSEC_CONTENT	loss\tagSEC_CONTENT	incurred\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	machine\tagSEC_CONTENT	learning\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Several\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	,\tagSEC_CONTENT	lack\tagSEC_CONTENT	the\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	classify\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	examples\tagSEC_CONTENT	correctly\tagSEC_CONTENT	,\tagSEC_CONTENT	sometimes\tagSEC_CONTENT	even\tagSEC_CONTENT	when\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	is\tagSEC_CONTENT	constrained\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	so\tagSEC_CONTENT	small\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	human\tagSEC_CONTENT	observer\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	perceive\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	process\tagSEC_CONTENT	of\tagSEC_CONTENT	training\tagSEC_CONTENT	a\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	correctly\tagSEC_CONTENT	classify\tagSEC_CONTENT	both\tagSEC_CONTENT	unmodified\tagSEC_CONTENT	examples\tagSEC_CONTENT	and\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	improves\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	robustness\tagSEC_CONTENT	to\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	examples\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	generalization\tagSEC_CONTENT	performance\tagSEC_CONTENT	for\tagSEC_CONTENT	original\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	requires\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	labels\tagSEC_CONTENT	when\tagSEC_CONTENT	training\tagSEC_CONTENT	models\tagSEC_CONTENT	that\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	supervised\tagSEC_CONTENT	cost\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	the\tagSEC_CONTENT	label\tagSEC_CONTENT	appears\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	cost\tagSEC_CONTENT	function\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	is\tagSEC_CONTENT	designed\tagSEC_CONTENT	to\tagSEC_CONTENT	maximize\tagSEC_CONTENT	.\tagSEC_CONTENT	Virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	extends\tagSEC_CONTENT	the\tagSEC_CONTENT	idea\tagSEC_CONTENT	of\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	regime\tagSEC_CONTENT	and\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	done\tagSEC_CONTENT	by\tagSEC_CONTENT	regularizing\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	so\tagSEC_CONTENT	that\tagSEC_CONTENT	given\tagSEC_CONTENT	an\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	will\tagSEC_CONTENT	produce\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	output\tagSEC_CONTENT	distribution\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	produces\tagSEC_CONTENT	on\tagSEC_CONTENT	an\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	of\tagSEC_CONTENT	that\tagSEC_CONTENT	example\tagSEC_CONTENT	.\tagSEC_CONTENT	Virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	achieves\tagSEC_CONTENT	good\tagSEC_CONTENT	generalization\tagSEC_CONTENT	performance\tagSEC_CONTENT	for\tagSEC_CONTENT	both\tagSEC_CONTENT	supervised\tagSEC_CONTENT	and\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	Previous\tagSEC_START	work\tagSEC_CONTENT	has\tagSEC_CONTENT	primarily\tagSEC_CONTENT	applied\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	to\tagSEC_CONTENT	image\tagSEC_CONTENT	classification\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	extend\tagSEC_CONTENT	these\tagSEC_CONTENT	techniques\tagSEC_CONTENT	to\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	tasks\tagSEC_CONTENT	and\tagSEC_CONTENT	sequence\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	typically\tagSEC_CONTENT	consist\tagSEC_CONTENT	of\tagSEC_CONTENT	making\tagSEC_CONTENT	small\tagSEC_CONTENT	modifications\tagSEC_CONTENT	to\tagSEC_CONTENT	very\tagSEC_CONTENT	many\tagSEC_CONTENT	real\tagSEC_CONTENT	-\tagSEC_CONTENT	valued\tagSEC_CONTENT	inputs\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	is\tagSEC_CONTENT	discrete\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	usually\tagSEC_CONTENT	represented\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	series\tagSEC_CONTENT	of\tagSEC_CONTENT	highdimensional\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	Because\tagSEC_CONTENT	the\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	vectors\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	admit\tagSEC_CONTENT	infinitesimal\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	on\tagSEC_CONTENT	continuous\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	instead\tagSEC_CONTENT	of\tagSEC_CONTENT	discrete\tagSEC_CONTENT	word\tagSEC_CONTENT	inputs\tagSEC_CONTENT	.\tagSEC_CONTENT	Traditional\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	interpreted\tagSEC_CONTENT	both\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	regularization\tagSEC_CONTENT	strategy\tagSEC_CONTENT	(\tagSEC_CONTENT	and\tagSEC_CONTENT	as\tagSEC_CONTENT	defense\tagSEC_CONTENT	against\tagSEC_CONTENT	an\tagSEC_CONTENT	adversary\tagSEC_CONTENT	who\tagSEC_CONTENT	can\tagSEC_CONTENT	supply\tagSEC_CONTENT	malicious\tagSEC_CONTENT	inputs\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	the\tagSEC_CONTENT	perturbed\tagSEC_CONTENT	embedding\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	map\tagSEC_CONTENT	to\tagSEC_CONTENT	any\tagSEC_CONTENT	word\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	adversary\tagSEC_CONTENT	presumably\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	have\tagSEC_CONTENT	access\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	training\tagSEC_CONTENT	strategy\tagSEC_CONTENT	is\tagSEC_CONTENT	no\tagSEC_CONTENT	longer\tagSEC_CONTENT	intended\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	defense\tagSEC_CONTENT	against\tagSEC_CONTENT	an\tagSEC_CONTENT	adversary\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	thus\tagSEC_CONTENT	propose\tagSEC_CONTENT	this\tagSEC_CONTENT	approach\tagSEC_CONTENT	exclusively\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	means\tagSEC_CONTENT	of\tagSEC_CONTENT	regularizing\tagSEC_CONTENT	a\tagSEC_CONTENT	text\tagSEC_CONTENT	classifier\tagSEC_CONTENT	by\tagSEC_CONTENT	stabilizing\tagSEC_CONTENT	the\tagSEC_CONTENT	classification\tagSEC_CONTENT	function\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	show\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	with\tagSEC_CONTENT	neural\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	unsupervised\tagSEC_CONTENT	pretraining\tagSEC_CONTENT	as\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	achieves\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	for\tagSEC_CONTENT	multiple\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	sentiment\tagtask	classification\tagtask	and\tagSEC_CONTENT	topic\tagSEC_CONTENT	classification\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	emphasize\tagSEC_CONTENT	that\tagSEC_CONTENT	optimization\tagSEC_CONTENT	of\tagSEC_CONTENT	only\tagSEC_CONTENT	one\tagSEC_CONTENT	additional\tagSEC_CONTENT	hyperparameter\tagSEC_CONTENT	ǫ\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	norm\tagSEC_CONTENT	constraint\tagSEC_CONTENT	limiting\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	,\tagSEC_CONTENT	achieved\tagSEC_CONTENT	such\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	results\tagSEC_CONTENT	strongly\tagSEC_CONTENT	encourage\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	method\tagSEC_CONTENT	for\tagSEC_CONTENT	other\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	believe\tagSEC_CONTENT	that\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	ideal\tagSEC_CONTENT	setting\tagSEC_CONTENT	for\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	because\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	abundant\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	corpora\tagSEC_CONTENT	for\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	to\tagSEC_CONTENT	leverage\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	work\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	work\tagSEC_CONTENT	we\tagSEC_CONTENT	know\tagSEC_CONTENT	of\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	a\tagSEC_CONTENT	text\tagSEC_CONTENT	or\tagSEC_CONTENT	RNN\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	analyzed\tagSEC_CONTENT	the\tagSEC_CONTENT	trained\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	qualitatively\tagSEC_CONTENT	characterize\tagSEC_CONTENT	the\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	improved\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_END	MODEL\tagSECTITLE_END	We\tagSEC_START	denote\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	T\tagSEC_CONTENT	words\tagSEC_CONTENT	as\tagSEC_CONTENT	{\tagSEC_CONTENT	w\tagSEC_CONTENT	(\tagSEC_CONTENT	t\tagSEC_CONTENT	)\tagSEC_CONTENT	|t\tagSEC_CONTENT	=\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	T\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	target\tagSEC_CONTENT	as\tagSEC_CONTENT	y.\tagSEC_CONTENT	To\tagSEC_CONTENT	transform\tagSEC_CONTENT	a\tagSEC_CONTENT	discrete\tagSEC_CONTENT	word\tagSEC_CONTENT	input\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	continuous\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	matrix\tagSEC_CONTENT	V\tagSEC_CONTENT	∈\tagSEC_CONTENT	R\tagSEC_CONTENT	(\tagSEC_CONTENT	K+1)×D\tagSEC_CONTENT	where\tagSEC_CONTENT	K\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	and\tagSEC_CONTENT	each\tagSEC_CONTENT	row\tagSEC_CONTENT	v\tagSEC_CONTENT	k\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	i\tagSEC_CONTENT	-\tagSEC_CONTENT	th\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	(\tagSEC_CONTENT	K\tagSEC_CONTENT	+\tagSEC_CONTENT	1)-th\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	an\tagSEC_CONTENT	'\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	sequence\tagSEC_CONTENT	(\tagSEC_CONTENT	eos\tagSEC_CONTENT	)\tagSEC_CONTENT	'\tagSEC_CONTENT	token\tagSEC_CONTENT	,\tagSEC_CONTENT	v\tagSEC_CONTENT	eos\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	a\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	t\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	discrete\tagSEC_CONTENT	word\tagSEC_CONTENT	w\tagSEC_CONTENT	(\tagSEC_CONTENT	t\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	is\tagSEC_CONTENT	v\tagSEC_CONTENT	(\tagSEC_CONTENT	t\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	additionally\tagSEC_CONTENT	tried\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_END	w\tagSEC_START	 \tagSEC_CONTENT	LSTM\tagSEC_CONTENT	architecture\tagSEC_CONTENT	)\tagSEC_CONTENT	since\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	method\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	constructing\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	add\tagSEC_CONTENT	an\tagSEC_CONTENT	additional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	reversed\tagSEC_CONTENT	sequence\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	model\tagSEC_CONTENT	then\tagSEC_CONTENT	predicts\tagSEC_CONTENT	the\tagSEC_CONTENT	label\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	concatenated\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	outputs\tagSEC_CONTENT	of\tagSEC_CONTENT	both\tagSEC_CONTENT	ends\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	train\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	robust\tagSEC_CONTENT	to\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	are\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	present\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	sufficient\tagSEC_CONTENT	to\tagSEC_CONTENT	understand\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	are\tagSEC_CONTENT	of\tagSEC_CONTENT	bounded\tagSEC_CONTENT	norm\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	model\tagSEC_CONTENT	could\tagSEC_CONTENT	trivially\tagSEC_CONTENT	learn\tagSEC_CONTENT	to\tagSEC_CONTENT	make\tagSEC_CONTENT	the\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	insignificant\tagSEC_CONTENT	by\tagSEC_CONTENT	learning\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	with\tagSEC_CONTENT	very\tagSEC_CONTENT	large\tagSEC_CONTENT	norm\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	prevent\tagSEC_CONTENT	this\tagSEC_CONTENT	pathological\tagSEC_CONTENT	solution\tagSEC_CONTENT	,\tagSEC_CONTENT	when\tagSEC_CONTENT	we\tagSEC_CONTENT	apply\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	we\tagSEC_CONTENT	defined\tagSEC_CONTENT	above\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	replace\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	v\tagSEC_CONTENT	k\tagSEC_CONTENT	with\tagSEC_CONTENT	normalized\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	¯\tagSEC_CONTENT	v\tagSEC_CONTENT	k\tagSEC_CONTENT	,\tagSEC_CONTENT	defined\tagSEC_CONTENT	as\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	f\tagSEC_CONTENT	i\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	frequency\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	i\tagSEC_CONTENT	-\tagSEC_CONTENT	th\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	calculated\tagSEC_CONTENT	within\tagSEC_CONTENT	all\tagSEC_CONTENT	training\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_END	ADVERSARIAL\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	VIRTUAL\tagSECTITLE_CONTENT	ADVERSARIAL\tagSECTITLE_CONTENT	TRAINING\tagSECTITLE_END	Adversarial\tagSEC_START	training\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	regularization\tagSEC_CONTENT	method\tagSEC_CONTENT	for\tagSEC_CONTENT	classifiers\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	robustness\tagSEC_CONTENT	to\tagSEC_CONTENT	small\tagSEC_CONTENT	,\tagSEC_CONTENT	approximately\tagSEC_CONTENT	worst\tagSEC_CONTENT	case\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	.\tagSEC_CONTENT	Let\tagSEC_CONTENT	us\tagSEC_CONTENT	denote\tagSEC_CONTENT	x\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	and\tagSEC_CONTENT	θ\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	parameters\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	classifier\tagSEC_CONTENT	,\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	adds\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	term\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	cost\tagSEC_CONTENT	function\tagSEC_CONTENT	:\tagSEC_END	−\tagSEC_START	log\tagSEC_CONTENT	p(y\tagSEC_CONTENT	|\tagSEC_CONTENT	x\tagSEC_CONTENT	+\tagSEC_CONTENT	r\tagSEC_CONTENT	adv\tagSEC_CONTENT	;\tagSEC_CONTENT	θ\tagSEC_CONTENT	)\tagSEC_CONTENT	where\tagSEC_CONTENT	r\tagSEC_CONTENT	adv\tagSEC_CONTENT	=\tagSEC_CONTENT	arg\tagSEC_CONTENT	min\tagSEC_CONTENT	r,񮽙r≤ǫ\tagSEC_END	where\tagSEC_START	r\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	andˆθandˆ\tagSEC_CONTENT	andˆθ\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	constant\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	parameters\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	constant\tagSEC_CONTENT	copyˆθcopyˆ\tagSEC_CONTENT	copyˆθ\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	θ\tagSEC_CONTENT	indicates\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	backpropagation\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	should\tagSEC_CONTENT	not\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	propagate\tagSEC_CONTENT	gradients\tagSEC_CONTENT	through\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	example\tagSEC_CONTENT	construction\tagSEC_CONTENT	process\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	each\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	worst\tagSEC_CONTENT	case\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	r\tagSEC_CONTENT	adv\tagSEC_CONTENT	against\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	model\tagSEC_CONTENT	p(y|x\tagSEC_CONTENT	;\tagSEC_CONTENT	ˆ\tagSEC_CONTENT	θ\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	train\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	robust\tagSEC_CONTENT	to\tagSEC_CONTENT	such\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	through\tagSEC_CONTENT	minimizing\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	θ\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	calculate\tagSEC_CONTENT	this\tagSEC_CONTENT	value\tagSEC_CONTENT	exactly\tagSEC_CONTENT	in\tagSEC_CONTENT	general\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	exact\tagSEC_CONTENT	minimization\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	tor\tagSEC_CONTENT	is\tagSEC_CONTENT	intractable\tagSEC_CONTENT	for\tagSEC_CONTENT	many\tagSEC_CONTENT	interesting\tagSEC_CONTENT	models\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	to\tagSEC_CONTENT	approximate\tagSEC_CONTENT	this\tagSEC_CONTENT	value\tagSEC_CONTENT	by\tagSEC_CONTENT	linearizing\tagSEC_CONTENT	log\tagSEC_CONTENT	p(y\tagSEC_CONTENT	|\tagSEC_CONTENT	x\tagSEC_CONTENT	;\tagSEC_CONTENT	ˆ\tagSEC_CONTENT	θ\tagSEC_CONTENT	)\tagSEC_CONTENT	around\tagSEC_CONTENT	x.\tagSEC_CONTENT	With\tagSEC_CONTENT	a\tagSEC_CONTENT	linear\tagSEC_CONTENT	approximation\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	L\tagSEC_CONTENT	2\tagSEC_CONTENT	norm\tagSEC_CONTENT	constraint\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq.(2\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	resulting\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	is\tagSEC_END	This\tagSEC_START	perturbation\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	easily\tagSEC_CONTENT	computed\tagSEC_CONTENT	using\tagSEC_CONTENT	backpropagation\tagSEC_CONTENT	in\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_END	Virtual\tagSEC_START	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	regularization\tagSEC_CONTENT	method\tagSEC_CONTENT	closely\tagSEC_CONTENT	related\tagSEC_CONTENT	to\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	additional\tagSEC_CONTENT	cost\tagSEC_CONTENT	introduced\tagSEC_CONTENT	by\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	r\tagSEC_CONTENT	v\tagSEC_CONTENT	-\tagSEC_CONTENT	adv\tagSEC_CONTENT	=\tagSEC_CONTENT	arg\tagSEC_CONTENT	max\tagSEC_END	where\tagSEC_START	KL[p||q\tagSEC_CONTENT	]\tagSEC_CONTENT	denotes\tagSEC_CONTENT	the\tagSEC_CONTENT	KL\tagSEC_CONTENT	divergence\tagSEC_CONTENT	between\tagSEC_CONTENT	distributions\tagSEC_CONTENT	p\tagSEC_CONTENT	and\tagSEC_CONTENT	q.\tagSEC_CONTENT	By\tagSEC_CONTENT	minimizing\tagSEC_CONTENT	Eq.(3\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	classifier\tagSEC_CONTENT	is\tagSEC_CONTENT	trained\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	smooth\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	considered\tagSEC_CONTENT	as\tagSEC_CONTENT	making\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	resistant\tagSEC_CONTENT	to\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	in\tagSEC_CONTENT	directions\tagSEC_CONTENT	to\tagSEC_CONTENT	which\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	most\tagSEC_CONTENT	sensitive\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	model\tagSEC_CONTENT	p(y|x\tagSEC_CONTENT	;\tagSEC_CONTENT	ˆ\tagSEC_CONTENT	θ\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	Eq.(3\tagSEC_CONTENT	)\tagSEC_CONTENT	requires\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	x\tagSEC_CONTENT	and\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	require\tagSEC_CONTENT	the\tagSEC_CONTENT	actual\tagSEC_CONTENT	label\tagSEC_CONTENT	y\tagSEC_CONTENT	while\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	defined\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq.(2\tagSEC_CONTENT	)\tagSEC_CONTENT	requires\tagSEC_CONTENT	the\tagSEC_CONTENT	label\tagSEC_CONTENT	y.\tagSEC_CONTENT	This\tagSEC_CONTENT	makes\tagSEC_CONTENT	it\tagSEC_CONTENT	possible\tagSEC_CONTENT	to\tagSEC_CONTENT	apply\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	to\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	in\tagSEC_CONTENT	general\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	analytically\tagSEC_CONTENT	calculate\tagSEC_CONTENT	the\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	,\tagSEC_CONTENT	proposed\tagSEC_CONTENT	to\tagSEC_CONTENT	calculate\tagSEC_CONTENT	the\tagSEC_CONTENT	approximated\tagSEC_CONTENT	Eq.(3\tagSEC_CONTENT	)\tagSEC_CONTENT	efficiently\tagSEC_CONTENT	with\tagSEC_CONTENT	backpropagation\tagSEC_CONTENT	.\tagSEC_END	As\tagSEC_START	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Sec\tagSEC_CONTENT	.\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	apply\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	to\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	directly\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	define\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	let\tagSEC_CONTENT	us\tagSEC_CONTENT	denote\tagSEC_CONTENT	a\tagSEC_CONTENT	concatenation\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	(\tagSEC_CONTENT	normalized\tagSEC_CONTENT	)\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	vectors\tagSEC_END	]\tagSEC_START	ass\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	conditional\tagSEC_CONTENT	probability\tagSEC_CONTENT	of\tagSEC_CONTENT	y\tagSEC_CONTENT	given\tagSEC_CONTENT	s\tagSEC_CONTENT	as\tagSEC_CONTENT	p(y|s\tagSEC_CONTENT	;\tagSEC_CONTENT	θ\tagSEC_CONTENT	)\tagSEC_CONTENT	where\tagSEC_CONTENT	θ\tagSEC_CONTENT	are\tagSEC_CONTENT	model\tagSEC_CONTENT	parameters\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	r\tagSEC_CONTENT	adv\tagSEC_CONTENT	on\tagSEC_CONTENT	s\tagSEC_CONTENT	as\tagSEC_CONTENT	:\tagSEC_END	To\tagSEC_START	be\tagSEC_CONTENT	robust\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	defined\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	by\tagSEC_END	where\tagSEC_START	N\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	labeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	,\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	refers\tagSEC_CONTENT	to\tagSEC_CONTENT	minimizing\tagSEC_CONTENT	the\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	plus\tagSEC_CONTENT	L\tagSEC_CONTENT	adv\tagSEC_CONTENT	with\tagSEC_CONTENT	stochastic\tagSEC_CONTENT	gradient\tagSEC_CONTENT	descent\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	on\tagSEC_CONTENT	our\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	training\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	calculate\tagSEC_CONTENT	the\tagSEC_CONTENT	below\tagSEC_CONTENT	approximated\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	dis\tagSEC_CONTENT	a\tagSEC_CONTENT	T\tagSEC_CONTENT	D\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	small\tagSEC_CONTENT	random\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	approximation\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	2nd\tagSEC_CONTENT	-\tagSEC_CONTENT	order\tagSEC_CONTENT	Taylor\tagSEC_CONTENT	expansion\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	iteration\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	power\tagSEC_CONTENT	method\tagSEC_CONTENT	on\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	as\tagSEC_CONTENT	in\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	the\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	is\tagSEC_CONTENT	defined\tagSEC_CONTENT	as\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	N\tagSEC_CONTENT	′\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	both\tagSEC_CONTENT	labeled\tagSEC_CONTENT	and\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_END	See\tagSEC_START	fora\tagSEC_CONTENT	recent\tagSEC_CONTENT	review\tagSEC_CONTENT	of\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	dataset\tagSEC_CONTENT	of\tagSEC_CONTENT	Wikipedia\tagSEC_CONTENT	pages\tagSEC_CONTENT	for\tagSEC_CONTENT	category\tagSEC_CONTENT	classification\tagSEC_CONTENT	.\tagSEC_CONTENT	Because\tagSEC_CONTENT	the\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	dataset\tagSEC_CONTENT	has\tagSEC_CONTENT	no\tagSEC_CONTENT	additional\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	are\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	task\tagSEC_CONTENT	only\tagSEC_CONTENT	.\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	news\tagSEC_CONTENT	articles\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	Reuters\tagSEC_CONTENT	Corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	followed\tagSEC_CONTENT	previous\tagSEC_CONTENT	works\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	conducted\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	topic\tagSEC_CONTENT	classification\tagSEC_CONTENT	task\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	level\tagSEC_CONTENT	topics\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	division\tagSEC_CONTENT	into\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	test\tagSEC_CONTENT	and\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	sets\tagSEC_CONTENT	as\tagSEC_CONTENT	.\tagSEC_CONTENT	Regarding\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	processing\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	treated\tagSEC_CONTENT	any\tagSEC_CONTENT	punctuation\tagSEC_CONTENT	as\tagSEC_CONTENT	spaces\tagSEC_CONTENT	.\tagSEC_END	EXPERIMENTAL\tagSECTITLE_START	SETTINGS\tagSECTITLE_END	We\tagSEC_START	converted\tagSEC_CONTENT	all\tagSEC_CONTENT	words\tagSEC_CONTENT	to\tagSEC_CONTENT	lower\tagSEC_CONTENT	-\tagSEC_CONTENT	case\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Rotten\tagSEC_CONTENT	Tomatoes\tagSEC_CONTENT	,\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	removed\tagSEC_CONTENT	words\tagSEC_CONTENT	which\tagSEC_CONTENT	appear\tagSEC_CONTENT	in\tagSEC_CONTENT	only\tagSEC_CONTENT	one\tagSEC_CONTENT	document\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	removed\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	English\tagSEC_CONTENT	stop\tagSEC_CONTENT	-\tagSEC_CONTENT	words\tagSEC_CONTENT	list\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	both\tagSEC_CONTENT	labeled\tagSEC_CONTENT	and\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	layer\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	with\tagSEC_CONTENT	1024\tagSEC_CONTENT	hidden\tagSEC_CONTENT	units\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dimension\tagSEC_CONTENT	D\tagSEC_CONTENT	was\tagSEC_CONTENT	256\tagSEC_CONTENT	on\tagSEC_CONTENT	IMDB\tagdataset	and\tagSEC_CONTENT	512\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	sampled\tagSEC_CONTENT	softmax\tagSEC_CONTENT	loss\tagSEC_CONTENT	with\tagSEC_CONTENT	1024\tagSEC_CONTENT	candidate\tagSEC_CONTENT	samples\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	optimization\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	Adam\tagSEC_CONTENT	optimizer\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	batch\tagSEC_CONTENT	size\tagSEC_CONTENT	256\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	initial\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	of\tagSEC_CONTENT	0.001\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	0.9999\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	exponential\tagSEC_CONTENT	decay\tagSEC_CONTENT	factor\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	training\tagSEC_CONTENT	step\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	trained\tagSEC_CONTENT	for\tagSEC_CONTENT	100,000\tagSEC_CONTENT	steps\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	applied\tagSEC_CONTENT	gradient\tagSEC_CONTENT	clipping\tagSEC_CONTENT	with\tagSEC_CONTENT	norm\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	1.0\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	parameters\tagSEC_CONTENT	except\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	reduce\tagSEC_CONTENT	runtime\tagSEC_CONTENT	on\tagSEC_CONTENT	GPU\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	truncated\tagSEC_CONTENT	backpropagation\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	400\tagSEC_CONTENT	words\tagSEC_CONTENT	from\tagSEC_CONTENT	each\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	regularization\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	applied\tagSEC_CONTENT	dropout\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	with\tagSEC_CONTENT	0.5\tagSEC_CONTENT	dropout\tagSEC_CONTENT	rate\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	512\tagSEC_CONTENT	hidden\tagSEC_CONTENT	units\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	for\tagSEC_CONTENT	both\tagSEC_CONTENT	the\tagSEC_CONTENT	standard\tagSEC_CONTENT	order\tagSEC_CONTENT	and\tagSEC_CONTENT	reversed\tagSEC_CONTENT	order\tagSEC_CONTENT	sequences\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	256\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	shared\tagSEC_CONTENT	with\tagSEC_CONTENT	both\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	LSTMs\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	other\tagSEC_CONTENT	hyperparameters\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	as\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	tested\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	IMDB\tagdataset	,\tagSEC_CONTENT	Elec\tagSEC_CONTENT	and\tagSEC_CONTENT	RCV\tagSEC_CONTENT	because\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	relatively\tagSEC_CONTENT	long\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_END	Pretraining\tagSEC_START	with\tagSEC_CONTENT	a\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	was\tagSEC_CONTENT	very\tagSEC_CONTENT	effective\tagSEC_CONTENT	on\tagSEC_CONTENT	classification\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	datasets\tagSEC_CONTENT	we\tagSEC_CONTENT	tested\tagSEC_CONTENT	on\tagSEC_CONTENT	and\tagSEC_CONTENT	so\tagSEC_CONTENT	our\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	5\tagSEC_CONTENT	are\tagSEC_CONTENT	with\tagSEC_CONTENT	this\tagSEC_CONTENT	pretraining\tagSEC_CONTENT	.\tagSEC_END	TRAINING\tagSECTITLE_START	CLASSIFICATION\tagSECTITLE_CONTENT	MODELS\tagSECTITLE_END	After\tagSEC_START	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	trained\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	model\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	with\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	as\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	.\tagSEC_CONTENT	Between\tagSEC_CONTENT	the\tagSEC_CONTENT	softmax\tagSEC_CONTENT	layer\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	y\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	added\tagSEC_CONTENT	a\tagSEC_CONTENT	hidden\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	has\tagSEC_CONTENT	dimension\tagSEC_CONTENT	30\tagSEC_CONTENT	on\tagSEC_CONTENT	IMDB\tagdataset	,\tagSEC_CONTENT	Elec\tagSEC_CONTENT	and\tagSEC_CONTENT	Rotten\tagSEC_CONTENT	Tomatoes\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	128\tagSEC_CONTENT	on\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	and\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	activation\tagSEC_CONTENT	function\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	layer\tagSEC_CONTENT	was\tagSEC_CONTENT	ReLU\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	optimization\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	again\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	Adam\tagSEC_CONTENT	optimizer\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	0.0005\tagSEC_CONTENT	initial\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	0.9998\tagSEC_CONTENT	exponential\tagSEC_CONTENT	decay\tagSEC_CONTENT	.\tagSEC_CONTENT	Batch\tagSEC_CONTENT	sizes\tagSEC_CONTENT	are\tagSEC_CONTENT	64\tagSEC_CONTENT	on\tagSEC_CONTENT	IMDB\tagdataset	,\tagSEC_CONTENT	Elec\tagSEC_CONTENT	,\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	128\tagSEC_CONTENT	on\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	Rotten\tagSEC_CONTENT	Tomatoes\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	take\tagSEC_CONTENT	a\tagSEC_CONTENT	batch\tagSEC_CONTENT	of\tagSEC_CONTENT	size\tagSEC_CONTENT	64\tagSEC_CONTENT	for\tagSEC_CONTENT	calculating\tagSEC_CONTENT	the\tagSEC_CONTENT	loss\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	and\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	512\tagSEC_CONTENT	for\tagSEC_CONTENT	calculating\tagSEC_CONTENT	the\tagSEC_CONTENT	loss\tagSEC_CONTENT	of\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	Also\tagSEC_CONTENT	for\tagSEC_CONTENT	Rotten\tagSEC_CONTENT	Tomatoes\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	texts\tagSEC_CONTENT	with\tagSEC_CONTENT	lengths\tagSEC_CONTENT	T\tagSEC_CONTENT	less\tagSEC_CONTENT	than\tagSEC_CONTENT	25\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	iterated\tagSEC_CONTENT	10,000\tagSEC_CONTENT	training\tagSEC_CONTENT	stepson\tagSEC_CONTENT	all\tagSEC_CONTENT	datasets\tagSEC_CONTENT	except\tagSEC_CONTENT	IMDB\tagdataset	and\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	used\tagSEC_CONTENT	15,000\tagSEC_CONTENT	and\tagSEC_CONTENT	20,000\tagSEC_CONTENT	training\tagSEC_CONTENT	steps\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	again\tagSEC_CONTENT	applied\tagSEC_CONTENT	gradient\tagSEC_CONTENT	clipping\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	norm\tagSEC_CONTENT	as\tagSEC_CONTENT	1.0\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	parameters\tagSEC_CONTENT	except\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	used\tagSEC_CONTENT	truncated\tagSEC_CONTENT	backpropagation\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	400\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	also\tagSEC_CONTENT	generated\tagSEC_CONTENT	the\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	400\tagSEC_CONTENT	words\tagSEC_CONTENT	from\tagSEC_CONTENT	each\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	found\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	to\tagSEC_CONTENT	converge\tagSEC_CONTENT	more\tagSEC_CONTENT	slowly\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	we\tagSEC_CONTENT	iterated\tagSEC_CONTENT	for\tagSEC_CONTENT	15,000\tagSEC_CONTENT	training\tagSEC_CONTENT	steps\tagSEC_CONTENT	when\tagSEC_CONTENT	training\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	classification\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	each\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	divided\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	into\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	and\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	roughly\tagSEC_CONTENT	optimized\tagSEC_CONTENT	some\tagSEC_CONTENT	hyperparameters\tagSEC_CONTENT	shared\tagSEC_CONTENT	with\tagSEC_CONTENT	all\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	methods\tagSEC_CONTENT	;\tagSEC_CONTENT	(\tagSEC_CONTENT	model\tagSEC_CONTENT	architecture\tagSEC_CONTENT	,\tagSEC_CONTENT	batchsize\tagSEC_CONTENT	,\tagSEC_CONTENT	training\tagSEC_CONTENT	steps\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	base\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dropout\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	each\tagSEC_CONTENT	method\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	optimized\tagSEC_CONTENT	two\tagSEC_CONTENT	scalar\tagSEC_CONTENT	hyperparameters\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	were\tagSEC_CONTENT	the\tagSEC_CONTENT	dropout\tagSEC_CONTENT	rate\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	norm\tagSEC_CONTENT	constraint\tagSEC_CONTENT	ǫ\tagSEC_CONTENT	of\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	for\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	generate\tagSEC_CONTENT	the\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	after\tagSEC_CONTENT	applying\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dropout\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	performed\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	do\tagSEC_CONTENT	early\tagSEC_CONTENT	stopping\tagSEC_CONTENT	with\tagSEC_CONTENT	these\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	method\tagSEC_CONTENT	with\tagSEC_CONTENT	only\tagSEC_CONTENT	pretraining\tagSEC_CONTENT	and\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dropout\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	(\tagSEC_CONTENT	referred\tagSEC_CONTENT	to\tagSEC_CONTENT	as\tagSEC_CONTENT	Baseline\tagSEC_CONTENT	in\tagSEC_CONTENT	each\tagSEC_CONTENT	table\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	learning\tagSEC_CONTENT	curves\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	IMDB\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	(\tagSEC_CONTENT	only\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dropout\tagSEC_CONTENT	and\tagSEC_CONTENT	pretraining\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	in\tagSEC_CONTENT	Figure\tagSEC_CONTENT	2a\tagSEC_CONTENT	that\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	achieved\tagSEC_CONTENT	lower\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	.\tagSEC_CONTENT	Furthermore\tagSEC_CONTENT	,\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	utilize\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	maintained\tagSEC_CONTENT	this\tagSEC_CONTENT	low\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	methods\tagSEC_CONTENT	began\tagSEC_CONTENT	to\tagSEC_CONTENT	overfit\tagSEC_CONTENT	later\tagSEC_CONTENT	in\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	Regarding\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	in\tagSEC_CONTENT	and\tagSEC_CONTENT	2c\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	seethe\tagSEC_CONTENT	same\tagSEC_CONTENT	tendency\tagSEC_CONTENT	as\tagSEC_CONTENT	for\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	;\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	was\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	keep\tagSEC_CONTENT	these\tagSEC_CONTENT	values\tagSEC_CONTENT	lower\tagSEC_CONTENT	than\tagSEC_CONTENT	other\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_CONTENT	Because\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	operates\tagSEC_CONTENT	only\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	labeled\tagSEC_CONTENT	subset\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	eventually\tagSEC_CONTENT	overfits\tagSEC_CONTENT	even\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	resisting\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	IMDB\tagdataset	with\tagSEC_CONTENT	each\tagSEC_CONTENT	training\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	+\tagSEC_CONTENT	Virtual\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	'\tagSEC_CONTENT	means\tagSEC_CONTENT	the\tagSEC_CONTENT	method\tagSEC_CONTENT	with\tagSEC_CONTENT	both\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	shared\tagSEC_CONTENT	norm\tagSEC_CONTENT	constraint\tagSEC_CONTENT	ǫ\tagSEC_CONTENT	.\tagSEC_CONTENT	With\tagSEC_CONTENT	only\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dropout\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	achieved\tagSEC_CONTENT	a\tagSEC_CONTENT	7.39\tagSEC_CONTENT	%\tagSEC_CONTENT	error\tagSEC_CONTENT	rate\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	improved\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	relative\tagSEC_CONTENT	to\tagSEC_CONTENT	our\tagSEC_CONTENT	baseline\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	achieved\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	par\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	,\tagSEC_CONTENT	5.91\tagSEC_CONTENT	%\tagSEC_CONTENT	error\tagSEC_CONTENT	rate\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	despite\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	model\tagSEC_CONTENT	requires\tagSEC_CONTENT	training\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	whereas\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	only\tagSEC_CONTENT	uses\tagSEC_CONTENT	a\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	show\tagSEC_CONTENT	results\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	has\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	performance\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	with\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_END	RESULTS\tagSECTITLE_END	TEST\tagSECTITLE_START	PERFORMANCE\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	IMDB\tagSECTITLE_CONTENT	DATASET\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_CONTENT	ANALYSIS\tagSECTITLE_END	A\tagSEC_START	common\tagSEC_CONTENT	misconception\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	is\tagSEC_CONTENT	equivalent\tagSEC_CONTENT	to\tagSEC_CONTENT	training\tagSEC_CONTENT	on\tagSEC_CONTENT	noisy\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	Noise\tagSEC_CONTENT	is\tagSEC_CONTENT	actually\tagSEC_CONTENT	afar\tagSEC_CONTENT	weaker\tagSEC_CONTENT	regularizer\tagSEC_CONTENT	than\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	because\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	high\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	input\tagSEC_CONTENT	spaces\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	average\tagSEC_CONTENT	noise\tagSEC_CONTENT	vector\tagSEC_CONTENT	is\tagSEC_CONTENT	approximately\tagSEC_CONTENT	orthogonal\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	cost\tagSEC_CONTENT	gradient\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	are\tagSEC_CONTENT	explicitly\tagSEC_CONTENT	chosen\tagSEC_CONTENT	to\tagSEC_CONTENT	consistently\tagSEC_CONTENT	increase\tagSEC_CONTENT	the\tagSEC_CONTENT	cost\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	the\tagSEC_CONTENT	superiority\tagSEC_CONTENT	of\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	addition\tagSEC_CONTENT	of\tagSEC_CONTENT	noise\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	include\tagSEC_CONTENT	control\tagSEC_CONTENT	experiments\tagSEC_CONTENT	which\tagSEC_CONTENT	replaced\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	with\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	multivariate\tagSEC_CONTENT	Gaussian\tagSEC_CONTENT	with\tagSEC_CONTENT	scaled\tagSEC_CONTENT	norm\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	each\tagSEC_CONTENT	embedding\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	Random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	with\tagSEC_CONTENT	labeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	method\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	replace\tagSEC_CONTENT	r\tagSEC_CONTENT	adv\tagSEC_CONTENT	with\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	Random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	with\tagSEC_CONTENT	labeled\tagSEC_CONTENT	and\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	method\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	replace\tagSEC_CONTENT	r\tagSEC_CONTENT	v\tagSEC_CONTENT	-\tagSEC_CONTENT	adv\tagSEC_CONTENT	with\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	.\tagSEC_CONTENT	Every\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	method\tagSEC_CONTENT	outperformed\tagSEC_CONTENT	every\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	visualize\tagSEC_CONTENT	the\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	on\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	examined\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	trained\tagSEC_CONTENT	using\tagSEC_CONTENT	each\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	10\tagSEC_CONTENT	top\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbors\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	with\tagSEC_CONTENT	trained\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	baseline\tagSEC_CONTENT	and\tagSEC_CONTENT	random\tagSEC_CONTENT	methods\tagSEC_CONTENT	are\tagSEC_CONTENT	both\tagSEC_CONTENT	strongly\tagSEC_CONTENT	influenced\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	grammatical\tagSEC_CONTENT	structure\tagSEC_CONTENT	of\tagSEC_CONTENT	language\tagSEC_CONTENT	,\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	pretraining\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	strongly\tagSEC_CONTENT	influenced\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	semantics\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	appears\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbors\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_CONTENT	Both\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	are\tagSEC_CONTENT	adjectives\tagSEC_CONTENT	that\tagSEC_CONTENT	can\tagSEC_CONTENT	modify\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	nouns\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	reasonable\tagSEC_CONTENT	fora\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	assign\tagSEC_CONTENT	them\tagSEC_CONTENT	similar\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	this\tagSEC_CONTENT	clearly\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	convey\tagSEC_CONTENT	much\tagSEC_CONTENT	information\tagSEC_CONTENT	about\tagSEC_CONTENT	the\tagSEC_CONTENT	actual\tagSEC_CONTENT	meaning\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	ensures\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	meaning\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	be\tagSEC_CONTENT	inverted\tagSEC_CONTENT	via\tagSEC_CONTENT	a\tagSEC_CONTENT	small\tagSEC_CONTENT	change\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	these\tagSEC_CONTENT	words\tagSEC_CONTENT	with\tagSEC_CONTENT	similar\tagSEC_CONTENT	grammatical\tagSEC_CONTENT	role\tagSEC_CONTENT	but\tagSEC_CONTENT	different\tagSEC_CONTENT	meaning\tagSEC_CONTENT	become\tagSEC_CONTENT	separated\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	using\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	no\tagSEC_CONTENT	longer\tagSEC_CONTENT	appears\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	10\tagSEC_CONTENT	top\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbors\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	falls\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	19th\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	for\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	21st\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	for\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distances\tagSEC_CONTENT	of\tagSEC_CONTENT	0.463\tagSEC_CONTENT	and\tagSEC_CONTENT	0.464\tagSEC_CONTENT	,\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	and\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	method\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distances\tagSEC_CONTENT	were\tagSEC_CONTENT	0.361\tagSEC_CONTENT	and\tagSEC_CONTENT	0.377\tagSEC_CONTENT	,\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	direction\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbors\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	included\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	4th\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	and\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	both\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	methods\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	drops\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	36th\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	of\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	also\tagSEC_CONTENT	investigated\tagSEC_CONTENT	the\tagSEC_CONTENT	15\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbors\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	great\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	its\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distances\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	trained\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	saw\tagSEC_CONTENT	that\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distance\tagSEC_CONTENT	on\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	(\tagSEC_CONTENT	0.159\tagSEC_CONTENT	-\tagSEC_CONTENT	0.331\tagSEC_CONTENT	)\tagSEC_CONTENT	were\tagSEC_CONTENT	much\tagSEC_CONTENT	smaller\tagSEC_CONTENT	than\tagSEC_CONTENT	ones\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	and\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	method\tagSEC_CONTENT	(\tagSEC_CONTENT	0.244\tagSEC_CONTENT	-\tagSEC_CONTENT	0.399\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	9.99\tagSEC_CONTENT	%\tagSEC_CONTENT	NBSVM\tagSEC_CONTENT	-\tagSEC_CONTENT	bigrams\tagSEC_CONTENT	(\tagSEC_CONTENT	8.78\tagSEC_CONTENT	%\tagSEC_CONTENT	Paragraph\tagSEC_CONTENT	Vectors\tagSEC_CONTENT	7.42\tagSEC_CONTENT	%\tagSEC_CONTENT	SA\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	7.24\tagSEC_CONTENT	%\tagSEC_CONTENT	One\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	*\tagSEC_CONTENT	5.94\tagSEC_CONTENT	%\tagSEC_CONTENT	:\tagSEC_CONTENT	10\tagSEC_CONTENT	top\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbors\tagSEC_CONTENT	to\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	bad\tagSEC_CONTENT	'\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	each\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	used\tagSEC_CONTENT	cosine\tagSEC_CONTENT	distance\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	metric\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	Baseline\tagSEC_CONTENT	'\tagSEC_CONTENT	means\tagSEC_CONTENT	training\tagSEC_CONTENT	with\tagSEC_CONTENT	embedding\tagSEC_CONTENT	dropout\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	Random\tagSEC_CONTENT	'\tagSEC_CONTENT	means\tagSEC_CONTENT	training\tagSEC_CONTENT	with\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	with\tagSEC_CONTENT	labeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	'\tagSEC_CONTENT	and\tagSEC_CONTENT	'\tagSEC_CONTENT	Virtual\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	'\tagSEC_CONTENT	mean\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	much\tagSEC_CONTENT	weaker\tagSEC_CONTENT	positive\tagSEC_CONTENT	word\tagSEC_CONTENT	'\tagSEC_CONTENT	good\tagSEC_CONTENT	'\tagSEC_CONTENT	also\tagSEC_CONTENT	moved\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	3rd\tagSEC_CONTENT	nearest\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	15th\tagSEC_CONTENT	after\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Elec\tagSEC_CONTENT	and\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	method\tagSEC_CONTENT	improved\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	and\tagSEC_CONTENT	achieved\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	even\tagSEC_CONTENT	though\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	method\tagSEC_CONTENT	uses\tagSEC_CONTENT	a\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	CNN\tagSEC_CONTENT	and\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	improves\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	method\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	further\tagSEC_CONTENT	improves\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	reason\tagSEC_CONTENT	why\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	models\tagSEC_CONTENT	have\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	dataset\tagSEC_CONTENT	would\tagSEC_CONTENT	be\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	RCV1\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	some\tagSEC_CONTENT	very\tagSEC_CONTENT	long\tagSEC_CONTENT	sentences\tagSEC_CONTENT	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	model\tagSEC_CONTENT	could\tagSEC_CONTENT	better\tagSEC_CONTENT	handle\tagSEC_CONTENT	such\tagSEC_CONTENT	long\tagSEC_CONTENT	sentences\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	shorter\tagSEC_CONTENT	dependencies\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	reverse\tagSEC_CONTENT	order\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	Rotten\tagSEC_CONTENT	Tomatoes\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	Adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	was\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	with\tagSEC_CONTENT	both\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	cost\tagSEC_CONTENT	,\tagSEC_CONTENT	achieved\tagSEC_CONTENT	almost\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	performance\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	only\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	was\tagSEC_CONTENT	worse\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	speculate\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	because\tagSEC_CONTENT	the\tagSEC_CONTENT	Rotten\tagSEC_CONTENT	Tomatoes\tagSEC_CONTENT	dataset\tagSEC_CONTENT	has\tagSEC_CONTENT	very\tagSEC_CONTENT	few\tagSEC_CONTENT	labeled\tagSEC_CONTENT	sentences\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	labeled\tagSEC_CONTENT	sentences\tagSEC_CONTENT	are\tagSEC_CONTENT	very\tagSEC_CONTENT	short\tagSEC_CONTENT	.\tagSEC_CONTENT	5.55\tagSEC_CONTENT	%\tagSEC_CONTENT	8.52\tagSEC_CONTENT	%\tagSEC_END	TEST\tagSECTITLE_START	PERFORMANCE\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	ELEC\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	RCV1\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	ROTTEN\tagSECTITLE_CONTENT	TOMATOES\tagSECTITLE_CONTENT	DATASET\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	case\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	loss\tagSEC_CONTENT	on\tagSEC_CONTENT	unlabeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	overwhelmed\tagSEC_CONTENT	the\tagSEC_CONTENT	supervised\tagSEC_CONTENT	loss\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	prioritized\tagSEC_CONTENT	being\tagSEC_CONTENT	robust\tagSEC_CONTENT	to\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	obtaining\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	answer\tagSEC_CONTENT	.\tagSEC_CONTENT	NBSVM\tagSEC_CONTENT	-\tagSEC_CONTENT	bigrams\tagSEC_CONTENT	(\tagSEC_CONTENT	20.6\tagSEC_CONTENT	%\tagSEC_CONTENT	CNN\tagSEC_CONTENT	*\tagSEC_CONTENT	18.5\tagSEC_CONTENT	%\tagSEC_CONTENT	AdaSent\tagSEC_CONTENT	*\tagSEC_CONTENT	(\tagSEC_CONTENT	 \tagSEC_CONTENT	16.9\tagSEC_CONTENT	%\tagSEC_CONTENT	SA\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	†\tagSEC_CONTENT	16.7\tagSEC_CONTENT	%\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	method\tagSEC_CONTENT	on\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	'\tagSEC_CONTENT	Random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	'\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	method\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	'\tagSEC_CONTENT	Random\tagSEC_CONTENT	perturbation\tagSEC_CONTENT	with\tagSEC_CONTENT	labeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	'\tagSEC_CONTENT	explained\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	5.1\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	that\tagSEC_CONTENT	DBpedia\tagSEC_CONTENT	has\tagSEC_CONTENT	only\tagSEC_CONTENT	labeled\tagSEC_CONTENT	examples\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	we\tagSEC_CONTENT	explained\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	this\tagSEC_CONTENT	task\tagSEC_CONTENT	is\tagSEC_CONTENT	purely\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	has\tagSEC_CONTENT	already\tagSEC_CONTENT	achieved\tagSEC_CONTENT	nearly\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	method\tagSEC_CONTENT	improves\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	.\tagSEC_END	PERFORMANCE\tagSECTITLE_START	ON\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	DBPEDIA\tagSECTITLE_CONTENT	PURELY\tagSECTITLE_CONTENT	SUPERVISED\tagSECTITLE_CONTENT	CLASSIFICATION\tagSECTITLE_CONTENT	TASK\tagSECTITLE_END	6\tagSEC_START	RELATED\tagSEC_CONTENT	WORKS\tagSEC_CONTENT	Dropout\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	regularization\tagSEC_CONTENT	method\tagSEC_CONTENT	widely\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	many\tagSEC_CONTENT	domains\tagSEC_CONTENT	including\tagSEC_CONTENT	text\tagSEC_CONTENT	.\tagSEC_CONTENT	There\tagSEC_CONTENT	are\tagSEC_CONTENT	some\tagSEC_CONTENT	previous\tagSEC_CONTENT	works\tagSEC_CONTENT	adding\tagSEC_CONTENT	random\tagSEC_CONTENT	noise\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	and\tagSEC_CONTENT	hidden\tagSEC_CONTENT	layer\tagSEC_CONTENT	during\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	prevent\tagSEC_CONTENT	overfitting\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	and\tagSEC_CONTENT	in\tagSEC_CONTENT	previous\tagSEC_CONTENT	works\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	training\tagSEC_CONTENT	with\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	outperformed\tagSEC_CONTENT	the\tagSEC_CONTENT	method\tagSEC_CONTENT	with\tagSEC_CONTENT	random\tagSEC_CONTENT	perturbations\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	with\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	common\tagSEC_CONTENT	approach\tagSEC_CONTENT	,\tagSEC_CONTENT	especially\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	image\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	a\tagSEC_CONTENT	generative\tagSEC_CONTENT	model\tagSEC_CONTENT	whose\tagSEC_CONTENT	latent\tagSEC_CONTENT	features\tagSEC_CONTENT	maybe\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	features\tagSEC_CONTENT	for\tagSEC_CONTENT	classification\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	models\tagSEC_CONTENT	now\tagSEC_CONTENT	achieve\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	1.73\tagSEC_CONTENT	%\tagSEC_CONTENT	SA\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM(word\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	)\tagSEC_CONTENT	1.41\tagSEC_CONTENT	%\tagSEC_CONTENT	N\tagSEC_CONTENT	-\tagSEC_CONTENT	grams\tagSEC_CONTENT	TFIDF\tagSEC_CONTENT	(\tagSEC_CONTENT	1.31\tagSEC_CONTENT	%\tagSEC_CONTENT	SA\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM(character\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	)\tagSEC_CONTENT	1.19\tagSEC_CONTENT	%\tagSEC_CONTENT	Word\tagSEC_CONTENT	CNN\tagSEC_CONTENT	0.84\tagSEC_CONTENT	%\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	image\tagSEC_CONTENT	domain\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	these\tagSEC_CONTENT	methods\tagSEC_CONTENT	require\tagSEC_CONTENT	numerous\tagSEC_CONTENT	additional\tagSEC_CONTENT	hyperparameters\tagSEC_CONTENT	with\tagSEC_CONTENT	generative\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	conditions\tagSEC_CONTENT	under\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	generative\tagSEC_CONTENT	model\tagSEC_CONTENT	will\tagSEC_CONTENT	provide\tagSEC_CONTENT	good\tagSEC_CONTENT	supervised\tagSEC_CONTENT	learning\tagSEC_CONTENT	performance\tagSEC_CONTENT	are\tagSEC_CONTENT	poorly\tagSEC_CONTENT	understood\tagSEC_CONTENT	.\tagSEC_CONTENT	By\tagSEC_CONTENT	comparison\tagSEC_CONTENT	,\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	requires\tagSEC_CONTENT	only\tagSEC_CONTENT	one\tagSEC_CONTENT	hyperparameter\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	straightforward\tagSEC_CONTENT	interpretation\tagSEC_CONTENT	as\tagSEC_CONTENT	robust\tagSEC_CONTENT	optimization\tagSEC_CONTENT	.\tagSEC_END	Adversarial\tagSEC_START	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	resemble\tagSEC_CONTENT	some\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	or\tagSEC_CONTENT	transductive\tagSEC_CONTENT	SVM\tagSEC_CONTENT	approaches\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	that\tagSEC_CONTENT	both\tagSEC_CONTENT	families\tagSEC_CONTENT	of\tagSEC_CONTENT	methods\tagSEC_CONTENT	push\tagSEC_CONTENT	the\tagSEC_CONTENT	decision\tagSEC_CONTENT	boundary\tagSEC_CONTENT	far\tagSEC_CONTENT	from\tagSEC_CONTENT	training\tagSEC_CONTENT	examples\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	case\tagSEC_CONTENT	of\tagSEC_CONTENT	transductive\tagSEC_CONTENT	SVMs\tagSEC_CONTENT	,\tagSEC_CONTENT	test\tagSEC_CONTENT	examples\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	methods\tagSEC_CONTENT	insist\tagSEC_CONTENT	on\tagSEC_CONTENT	margins\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	space\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	SVMs\tagSEC_CONTENT	insist\tagSEC_CONTENT	on\tagSEC_CONTENT	margins\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	feature\tagSEC_CONTENT	space\tagSEC_CONTENT	defined\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	kernel\tagSEC_CONTENT	function\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	property\tagSEC_CONTENT	allows\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	methods\tagSEC_CONTENT	to\tagSEC_CONTENT	achieve\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	flexible\tagSEC_CONTENT	function\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	space\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	margins\tagSEC_CONTENT	are\tagSEC_CONTENT	imposed\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	,\tagSEC_CONTENT	4\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	,\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	achieve\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	than\tagSEC_CONTENT	SVM\tagSEC_CONTENT	based\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_END	There\tagSEC_START	has\tagSEC_CONTENT	also\tagSEC_CONTENT	been\tagSEC_CONTENT	semi\tagSEC_CONTENT	-\tagSEC_CONTENT	supervised\tagSEC_CONTENT	approaches\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	with\tagSEC_CONTENT	both\tagSEC_CONTENT	CNNs\tagSEC_CONTENT	and\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	approaches\tagSEC_CONTENT	utilize\tagSEC_CONTENT	'\tagSEC_CONTENT	view\tagSEC_CONTENT	-\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	'\tagSEC_CONTENT	)\tagSEC_CONTENT	which\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	around\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	its\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	these\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	pretrained\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	classification\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	found\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	generalization\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	methods\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	are\tagSEC_CONTENT	complementary\tagSEC_CONTENT	as\tagSEC_CONTENT	we\tagSEC_CONTENT	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	improved\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	pretrained\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_END	CONCLUSION\tagSECTITLE_END	In\tagSEC_START	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	have\tagSEC_CONTENT	good\tagSEC_CONTENT	regularization\tagSEC_CONTENT	performance\tagSEC_CONTENT	in\tagSEC_CONTENT	sequence\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	text\tagSEC_CONTENT	classification\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	all\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	method\tagSEC_CONTENT	exceeded\tagSEC_CONTENT	or\tagSEC_CONTENT	was\tagSEC_CONTENT	on\tagSEC_CONTENT	par\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	and\tagSEC_CONTENT	virtual\tagSEC_CONTENT	adversarial\tagSEC_CONTENT	training\tagSEC_CONTENT	improved\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	classification\tagSEC_CONTENT	performance\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	the\tagSEC_CONTENT	quality\tagSEC_CONTENT	of\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	results\tagSEC_CONTENT	suggest\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	method\tagSEC_CONTENT	is\tagSEC_CONTENT	promising\tagSEC_CONTENT	for\tagSEC_CONTENT	other\tagSEC_CONTENT	text\tagSEC_CONTENT	domain\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	learning\tagSEC_CONTENT	distributed\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	or\tagSEC_CONTENT	paragraphs\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	approach\tagSEC_CONTENT	could\tagSEC_CONTENT	also\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	other\tagSEC_CONTENT	general\tagSEC_CONTENT	sequential\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	for\tagSEC_CONTENT	video\tagSEC_CONTENT	or\tagSEC_CONTENT	speech\tagSEC_CONTENT	.\tagSEC_END	
N18-1150	title\tagSECTITLE_END	Deep\tagSEC_START	Communicating\tagSEC_CONTENT	Agents\tagSEC_CONTENT	for\tagSEC_CONTENT	Abstractive\tagtask	Summarization\tagSEC_END	abstract\tagSECTITLE_END	We\tagSEC_START	present\tagSEC_CONTENT	deep\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agents\tagSEC_CONTENT	in\tagSEC_CONTENT	an\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	architecture\tagSEC_CONTENT	to\tagSEC_CONTENT	address\tagSEC_CONTENT	the\tagSEC_CONTENT	challenges\tagSEC_CONTENT	of\tagSEC_CONTENT	representing\tagSEC_CONTENT	along\tagSEC_CONTENT	document\tagSEC_CONTENT	for\tagSEC_CONTENT	abstractive\tagtask	summariza\tagtask	-\tagtask	tion\tagtask	.\tagSEC_CONTENT	With\tagSEC_CONTENT	deep\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agents\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	encoding\tagSEC_CONTENT	along\tagSEC_CONTENT	text\tagSEC_CONTENT	is\tagSEC_CONTENT	divided\tagSEC_CONTENT	across\tagSEC_CONTENT	multiple\tagSEC_CONTENT	collaborating\tagSEC_CONTENT	agents\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	in\tagSEC_CONTENT	charge\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	subsection\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	text\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	encoders\tagSEC_CONTENT	are\tagSEC_CONTENT	connected\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	decoder\tagSEC_CONTENT	,\tagSEC_CONTENT	trained\tagSEC_CONTENT	end\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	end\tagSEC_CONTENT	using\tagSEC_CONTENT	reinforcement\tagSEC_CONTENT	learning\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	a\tagSEC_CONTENT	focused\tagSEC_CONTENT	and\tagSEC_CONTENT	coherent\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	Empirical\tagSEC_CONTENT	results\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	that\tagSEC_CONTENT	multiple\tagSEC_CONTENT	communicating\tagSEC_CONTENT	encoders\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	higher\tagSEC_CONTENT	quality\tagSEC_CONTENT	summary\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	several\tagSEC_CONTENT	strong\tagSEC_CONTENT	baselines\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	those\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	encoder\tagSEC_CONTENT	or\tagSEC_CONTENT	multiple\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	communicating\tagSEC_CONTENT	encoders\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	We\tagSEC_START	focus\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	abstractive\tagtask	summarization\tagtask	of\tagSEC_CONTENT	along\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	contrast\tagSEC_CONTENT	to\tagSEC_CONTENT	extractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	a\tagSEC_CONTENT	summary\tagSEC_CONTENT	is\tagSEC_CONTENT	composed\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	subset\tagSEC_CONTENT	of\tagSEC_CONTENT	sentences\tagSEC_CONTENT	or\tagSEC_CONTENT	words\tagSEC_CONTENT	lifted\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	text\tagSEC_CONTENT	as\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	requires\tagSEC_CONTENT	the\tagSEC_CONTENT	generative\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	rephrase\tagSEC_CONTENT	and\tagSEC_CONTENT	restructure\tagSEC_CONTENT	sentences\tagSEC_CONTENT	to\tagSEC_CONTENT	compose\tagSEC_CONTENT	a\tagSEC_CONTENT	coherent\tagSEC_CONTENT	and\tagSEC_CONTENT	concise\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	(\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	)\tagSEC_CONTENT	are\tagSEC_CONTENT	capable\tagSEC_CONTENT	of\tagSEC_CONTENT	generating\tagSEC_CONTENT	fluent\tagSEC_CONTENT	language\tagSEC_CONTENT	,\tagSEC_CONTENT	variants\tagSEC_CONTENT	of\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	have\tagSEC_CONTENT	shown\tagSEC_CONTENT	promising\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	task\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	fundamental\tagSEC_CONTENT	challenge\tagSEC_CONTENT	,\tagSEC_CONTENT	however\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	strong\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	neural\tagSEC_CONTENT	models\tagSEC_CONTENT	at\tagSEC_CONTENT	encoding\tagSEC_CONTENT	short\tagSEC_CONTENT	text\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	generalize\tagSEC_CONTENT	well\tagSEC_CONTENT	to\tagSEC_CONTENT	long\tagSEC_CONTENT	text\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagtask	motivation\tagtask	behind\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	dynamically\tagSEC_CONTENT	attend\tagSEC_CONTENT	to\tagSEC_CONTENT	different\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	salient\tagSEC_CONTENT	facts\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	recent\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	sum-\tagSEC_CONTENT	marization\tagSEC_CONTENT	addresses\tagSEC_CONTENT	these\tagSEC_CONTENT	issues\tagSEC_CONTENT	using\tagSEC_CONTENT	improved\tagSEC_CONTENT	attention\tagSEC_CONTENT	models\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	pointer\tagSEC_CONTENT	networks\tagSEC_CONTENT	with\tagSEC_CONTENT	coverage\tagSEC_CONTENT	mechanisms\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	coherence\tagSEC_CONTENT	-\tagSEC_CONTENT	focused\tagSEC_CONTENT	training\tagSEC_CONTENT	objectives\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	effective\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	for\tagSEC_CONTENT	representing\tagSEC_CONTENT	along\tagSEC_CONTENT	document\tagSEC_CONTENT	remains\tagSEC_CONTENT	a\tagSEC_CONTENT	challenge\tagSEC_CONTENT	.\tagSEC_END	Simultaneous\tagSEC_START	work\tagSEC_CONTENT	has\tagSEC_CONTENT	investigated\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	deep\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agents\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	collaborative\tagSEC_CONTENT	tasks\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	logic\tagSEC_CONTENT	puzzles\tagSEC_CONTENT	,\tagSEC_CONTENT	visual\tagSEC_CONTENT	dialog\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	reference\tagSEC_CONTENT	games\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	work\tagSEC_CONTENT	builds\tagSEC_CONTENT	on\tagSEC_CONTENT	these\tagSEC_CONTENT	approaches\tagSEC_CONTENT	to\tagSEC_CONTENT	propose\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	study\tagSEC_CONTENT	on\tagSEC_CONTENT	using\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agents\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	long\tagSEC_CONTENT	text\tagSEC_CONTENT	for\tagSEC_CONTENT	summarization\tagtask	.\tagSEC_END	The\tagSEC_START	key\tagSEC_CONTENT	idea\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	divide\tagSEC_CONTENT	the\tagSEC_CONTENT	hard\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	encoding\tagSEC_CONTENT	along\tagSEC_CONTENT	text\tagSEC_CONTENT	across\tagSEC_CONTENT	multiple\tagSEC_CONTENT	collaborating\tagSEC_CONTENT	encoder\tagSEC_CONTENT	agents\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	in\tagSEC_CONTENT	charge\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	different\tagSEC_CONTENT	subsection\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	agents\tagSEC_CONTENT	encodes\tagSEC_CONTENT	their\tagSEC_CONTENT	assigned\tagSEC_CONTENT	text\tagSEC_CONTENT	independently\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	broadcasts\tagSEC_CONTENT	their\tagSEC_CONTENT	encoding\tagSEC_CONTENT	to\tagSEC_CONTENT	others\tagSEC_CONTENT	,\tagSEC_CONTENT	allowing\tagSEC_CONTENT	agents\tagSEC_CONTENT	to\tagSEC_CONTENT	share\tagSEC_CONTENT	global\tagSEC_CONTENT	context\tagSEC_CONTENT	information\tagSEC_CONTENT	with\tagSEC_CONTENT	one\tagSEC_CONTENT	another\tagSEC_CONTENT	about\tagSEC_CONTENT	different\tagSEC_CONTENT	sections\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	agents\tagSEC_CONTENT	then\tagSEC_CONTENT	adapt\tagSEC_CONTENT	the\tagSEC_CONTENT	encoding\tagSEC_CONTENT	of\tagSEC_CONTENT	their\tagSEC_CONTENT	assigned\tagSEC_CONTENT	text\tagSEC_CONTENT	in\tagSEC_CONTENT	light\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	global\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	re-\tagSEC_CONTENT	Figure\tagSEC_CONTENT	2\tagSEC_CONTENT	:\tagSEC_CONTENT	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	-\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	overview\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	agent\tagSEC_CONTENT	a\tagSEC_CONTENT	encodes\tagSEC_CONTENT	a\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	local\tagSEC_CONTENT	encoder\tagSEC_CONTENT	followed\tagSEC_CONTENT	by\tagSEC_CONTENT	multiple\tagSEC_CONTENT	contextual\tagSEC_CONTENT	layers\tagSEC_CONTENT	with\tagSEC_CONTENT	agent\tagSEC_CONTENT	communication\tagSEC_CONTENT	through\tagSEC_CONTENT	concentrated\tagSEC_CONTENT	messages\tagSEC_CONTENT	z\tagSEC_CONTENT	(\tagSEC_CONTENT	k\tagSEC_CONTENT	)\tagSEC_CONTENT	a\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	layer\tagSEC_CONTENT	k.\tagSEC_CONTENT	Communication\tagSEC_CONTENT	is\tagSEC_CONTENT	illustrated\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagmetric	word\tagmetric	context\tagSEC_CONTENT	vectors\tagSEC_CONTENT	ct\tagSEC_CONTENT	a\tagSEC_CONTENT	are\tagSEC_CONTENT	condensed\tagSEC_CONTENT	into\tagSEC_CONTENT	agent\tagSEC_CONTENT	context\tagSEC_CONTENT	c\tagSEC_CONTENT	*\tagSEC_CONTENT	t\tagSEC_CONTENT	.\tagSEC_CONTENT	Agent\tagSEC_CONTENT	specific\tagSEC_CONTENT	generation\tagSEC_CONTENT	probabilities\tagSEC_CONTENT	,\tagSEC_CONTENT	pt\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	enable\tagSEC_CONTENT	voting\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	suitable\tagSEC_CONTENT	out\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	words\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	yen\tagSEC_CONTENT	'\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	distribution\tagSEC_CONTENT	.\tagSEC_END	peat\tagSEC_START	the\tagSEC_CONTENT	process\tagSEC_CONTENT	across\tagSEC_CONTENT	multiple\tagSEC_CONTENT	layers\tagSEC_CONTENT	,\tagSEC_CONTENT	generating\tagSEC_CONTENT	new\tagSEC_CONTENT	messages\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	Once\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	completes\tagSEC_CONTENT	encoding\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	deliver\tagSEC_CONTENT	their\tagSEC_CONTENT	information\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	contextual\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Contextual\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	enables\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	to\tagSEC_CONTENT	integrate\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	agents\tagSEC_CONTENT	smoothly\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	decoding\tagSEC_CONTENT	step\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	trained\tagSEC_CONTENT	end\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	end\tagSEC_CONTENT	using\tagSEC_CONTENT	self\tagSEC_CONTENT	-\tagSEC_CONTENT	critical\tagSEC_CONTENT	reinforcement\tagSEC_CONTENT	learning\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	focused\tagSEC_CONTENT	and\tagSEC_CONTENT	coherent\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_END	Empirical\tagSEC_START	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	CNN\tagdataset	/\tagdataset	DailyMail\tagdataset	and\tagdataset	New\tagdataset	York\tagdataset	Times\tagdataset	datasets\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	that\tagSEC_CONTENT	multiple\tagSEC_CONTENT	communicating\tagSEC_CONTENT	encoders\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	higher\tagSEC_CONTENT	quality\tagSEC_CONTENT	summaries\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	strong\tagSEC_CONTENT	baselines\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	those\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	encoder\tagSEC_CONTENT	or\tagSEC_CONTENT	multiple\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	communicating\tagSEC_CONTENT	encoders\tagSEC_CONTENT	.\tagSEC_CONTENT	Human\tagSEC_CONTENT	evaluations\tagSEC_CONTENT	indicate\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	produce\tagSEC_CONTENT	more\tagSEC_CONTENT	focused\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	agents\tagSEC_CONTENT	gather\tagSEC_CONTENT	salient\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	areas\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	communicate\tagSEC_CONTENT	their\tagSEC_CONTENT	information\tagSEC_CONTENT	with\tagSEC_CONTENT	one\tagSEC_CONTENT	another\tagSEC_CONTENT	,\tagSEC_CONTENT	thus\tagSEC_CONTENT	reducing\tagSEC_CONTENT	common\tagSEC_CONTENT	mistakes\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	missing\tagSEC_CONTENT	key\tagSEC_CONTENT	facts\tagSEC_CONTENT	,\tagSEC_CONTENT	repeating\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	content\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	including\tagSEC_CONTENT	unnecessary\tagSEC_CONTENT	details\tagSEC_CONTENT	.\tagSEC_CONTENT	Further\tagSEC_CONTENT	analysis\tagSEC_CONTENT	reveals\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	attains\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	when\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	interacts\tagSEC_CONTENT	with\tagSEC_CONTENT	multiple\tagSEC_CONTENT	agents\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	balanced\tagSEC_CONTENT	way\tagSEC_CONTENT	,\tagSEC_CONTENT	confirming\tagSEC_CONTENT	the\tagSEC_CONTENT	benefit\tagSEC_CONTENT	of\tagSEC_CONTENT	representing\tagSEC_CONTENT	along\tagSEC_CONTENT	document\tagSEC_CONTENT	with\tagSEC_CONTENT	multiple\tagSEC_CONTENT	encoding\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_END	Model\tagSECTITLE_END	We\tagSEC_START	extend\tagSEC_CONTENT	the\tagSEC_CONTENT	CommNet\tagSEC_CONTENT	model\tagSEC_CONTENT	of\tagSEC_CONTENT	for\tagSEC_CONTENT	sequence\tagSEC_CONTENT	generation\tagSEC_CONTENT	.\tagSEC_END	Notation\tagSEC_START	Each\tagSEC_CONTENT	document\tagSEC_CONTENT	dis\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	paragraphs\tagSEC_CONTENT	x\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	split\tagSEC_CONTENT	across\tagSEC_CONTENT	multiple\tagSEC_CONTENT	encoding\tagSEC_CONTENT	agents\tagSEC_CONTENT	a=1,\tagSEC_CONTENT	..\tagSEC_CONTENT	,M\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	agent-1\tagSEC_CONTENT	encodes\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	x\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	agent-2\tagmetric	the\tagSEC_CONTENT	second\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	x\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	on\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	x\tagSEC_CONTENT	a\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	w\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	i\tagSEC_CONTENT	}\tagSEC_CONTENT	I\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	I\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	construct\tagSEC_CONTENT	a\tagSEC_CONTENT	V\tagSEC_CONTENT	-sized\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	documents\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	frequently\tagSEC_CONTENT	appearing\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	word\tagSEC_CONTENT	w\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	i\tagSEC_CONTENT	is\tagSEC_CONTENT	embedded\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	n\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	vector\tagSEC_CONTENT	e\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	i\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	W\tagSEC_CONTENT	variables\tagSEC_CONTENT	are\tagSEC_CONTENT	linear\tagSEC_CONTENT	projection\tagSEC_CONTENT	matrices\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Agent\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	Each\tagSEC_START	agent\tagSEC_CONTENT	encodes\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	sequences\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	two\tagSEC_CONTENT	stacked\tagSEC_CONTENT	encoders\tagSEC_CONTENT	.\tagSEC_CONTENT	Local\tagSEC_CONTENT	Encoder\tagSEC_CONTENT	The\tagSEC_CONTENT	first\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	local\tagSEC_CONTENT	encoder\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	tokens\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	x\tagSEC_CONTENT	a\tagSEC_CONTENT	are\tagSEC_CONTENT	fed\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	layer\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	(\tagSEC_CONTENT	bLSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	producing\tagSEC_CONTENT	the\tagSEC_CONTENT	local\tagSEC_CONTENT	encoder\tagSEC_CONTENT	hidden\tagSEC_CONTENT	states\tagSEC_CONTENT	,\tagSEC_CONTENT	h\tagSEC_END	where\tagSEC_START	H\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	dimensionality\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	local\tagSEC_CONTENT	encoder\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	fed\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	contextual\tagSEC_CONTENT	encoder\tagSEC_CONTENT	.\tagSEC_CONTENT	Contextual\tagSEC_CONTENT	Encoder\tagSEC_CONTENT	Our\tagSEC_CONTENT	framework\tagSEC_CONTENT	enables\tagSEC_CONTENT	agent\tagSEC_CONTENT	communication\tagSEC_CONTENT	cycles\tagSEC_CONTENT	across\tagSEC_CONTENT	multiple\tagSEC_CONTENT	encoding\tagSEC_CONTENT	layers\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	contextual\tagSEC_CONTENT	encoder\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	adapted\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	agent\tagSEC_CONTENT	's\tagSEC_CONTENT	encoded\tagSEC_CONTENT	information\tagSEC_CONTENT	conditioned\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	information\tagSEC_CONTENT	received\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	each\tagSEC_CONTENT	layer\tagSEC_CONTENT	k=1,\tagSEC_CONTENT	..\tagSEC_CONTENT	,K\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	a\tagSEC_CONTENT	jointly\tagSEC_CONTENT	encodes\tagSEC_CONTENT	the\tagSEC_CONTENT	information\tagSEC_CONTENT	received\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	layer\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	cell\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	(\tagSEC_CONTENT	k+1)th\tagSEC_CONTENT	contextual\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	bLSTM\tagSEC_CONTENT	that\tagSEC_CONTENT	takes\tagSEC_CONTENT	three\tagSEC_CONTENT	inputs\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	states\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	adjacent\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	cells\tagSEC_CONTENT	,\tagSEC_END	i+1\tagSEC_START	∈R\tagSEC_CONTENT	H\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	layer\tagSEC_CONTENT	h\tagSEC_END	where\tagSEC_START	i=1\tagSEC_CONTENT	..\tagSEC_CONTENT	I\tagSEC_CONTENT	indicates\tagSEC_CONTENT	the\tagSEC_CONTENT	index\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	token\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	message\tagSEC_CONTENT	z\tagSEC_CONTENT	(\tagSEC_CONTENT	k\tagSEC_CONTENT	)\tagSEC_CONTENT	received\tagSEC_CONTENT	by\tagSEC_CONTENT	any\tagSEC_CONTENT	agent\tagSEC_CONTENT	a\tagSEC_CONTENT	in\tagSEC_CONTENT	layer\tagSEC_CONTENT	k\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	average\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	outputs\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	agents\tagSEC_CONTENT	from\tagSEC_CONTENT	layer\tagSEC_CONTENT	k\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	h\tagSEC_CONTENT	(\tagSEC_CONTENT	k\tagSEC_CONTENT	)\tagSEC_CONTENT	m\tagSEC_CONTENT	,\tagSEC_CONTENT	I\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	output\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	kth\tagSEC_CONTENT	contextual\tagSEC_CONTENT	layer\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	where\tagSEC_CONTENT	m\tagSEC_CONTENT	=\tagSEC_CONTENT	a.\tagSEC_CONTENT	Here\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	take\tagSEC_CONTENT	the\tagSEC_CONTENT	average\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	messages\tagSEC_CONTENT	received\tagSEC_CONTENT	from\tagSEC_CONTENT	other\tagSEC_CONTENT	encoder\tagSEC_CONTENT	agents\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	a\tagSEC_CONTENT	parametric\tagSEC_CONTENT	function\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	feed\tagSEC_CONTENT	forward\tagSEC_CONTENT	model\tagSEC_CONTENT	or\tagSEC_CONTENT	an\tagSEC_CONTENT	attention\tagSEC_CONTENT	over\tagSEC_CONTENT	messages\tagSEC_CONTENT	could\tagSEC_CONTENT	also\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	message\tagSEC_CONTENT	z\tagSEC_CONTENT	(\tagSEC_CONTENT	k\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	projected\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	agent\tagSEC_CONTENT	's\tagSEC_CONTENT	previous\tagSEC_CONTENT	encoding\tagSEC_CONTENT	of\tagSEC_CONTENT	its\tagSEC_CONTENT	document\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	v\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	W\tagSEC_CONTENT	3\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	W\tagSEC_CONTENT	4\tagSEC_CONTENT	are\tagSEC_CONTENT	learned\tagSEC_CONTENT	parameters\tagmetric	shared\tagSEC_CONTENT	by\tagSEC_CONTENT	every\tagSEC_CONTENT	agent\tagSEC_CONTENT	.\tagSEC_CONTENT	Equation\tagtask	(\tagSEC_CONTENT	7\tagSEC_CONTENT	)\tagSEC_CONTENT	combines\tagSEC_CONTENT	the\tagSEC_CONTENT	information\tagSEC_CONTENT	sent\tagSEC_CONTENT	by\tagSEC_CONTENT	other\tagSEC_CONTENT	agents\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	token\tagSEC_CONTENT	from\tagSEC_CONTENT	this\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	yields\tagSEC_CONTENT	different\tagSEC_CONTENT	features\tagSEC_CONTENT	about\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	context\tagSEC_CONTENT	in\tagSEC_CONTENT	relation\tagSEC_CONTENT	to\tagSEC_CONTENT	other\tagSEC_CONTENT	topics\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_END	At\tagSEC_START	each\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	agent\tagSEC_CONTENT	modifies\tagSEC_CONTENT	its\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	its\tagSEC_CONTENT	own\tagSEC_CONTENT	context\tagSEC_CONTENT	relative\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	information\tagSEC_CONTENT	received\tagSEC_CONTENT	from\tagSEC_CONTENT	other\tagSEC_CONTENT	agents\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	updates\tagSEC_CONTENT	the\tagSEC_CONTENT	information\tagSEC_CONTENT	it\tagSEC_CONTENT	sends\tagSEC_CONTENT	to\tagSEC_CONTENT	other\tagSEC_CONTENT	agents\tagSEC_CONTENT	accordingly\tagSEC_CONTENT	.\tagSEC_CONTENT	a\tagSEC_CONTENT	as\tagSEC_CONTENT	additional\tagSEC_CONTENT	input\tagSEC_CONTENT	to\tagSEC_CONTENT	its\tagSEC_CONTENT	next\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_END	Decoder\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Agent\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	The\tagSEC_START	output\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	contextual\tagSEC_CONTENT	encoder\tagSEC_CONTENT	layer\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	{\tagSEC_CONTENT	h\tagSEC_END	a\tagSEC_START	,\tagSEC_CONTENT	i\tagSEC_CONTENT	}\tagSEC_CONTENT	I\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	vectors\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	token\tagSEC_CONTENT	i\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	sent\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	to\tagSEC_CONTENT	calculate\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	attention\tagSEC_CONTENT	distributions\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	layer\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	and\tagSEC_CONTENT	feed\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	agent\tagSEC_END	1,I\tagSEC_START	as\tagSEC_CONTENT	the\tagSEC_CONTENT	initial\tagSEC_CONTENT	state\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	t\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	predicts\tagSEC_CONTENT	anew\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagtask	summary\tagtask	wt\tagtask	and\tagSEC_CONTENT	computes\tagSEC_CONTENT	anew\tagSEC_CONTENT	state\tagSEC_CONTENT	st\tagSEC_CONTENT	by\tagSEC_CONTENT	attending\tagSEC_CONTENT	to\tagSEC_CONTENT	relevant\tagSEC_CONTENT	input\tagSEC_CONTENT	context\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	decoder\tagSEC_CONTENT	uses\tagSEC_CONTENT	anew\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	attention\tagSEC_CONTENT	distribution\tagSEC_CONTENT	l\tagSEC_CONTENT	ta\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	computed\tagSEC_CONTENT	over\tagSEC_CONTENT	every\tagSEC_CONTENT	token\tagSEC_CONTENT	{\tagSEC_CONTENT	h\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	i\tagSEC_CONTENT	}\tagSEC_CONTENT	I\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	a\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	l\tagSEC_CONTENT	ta\tagSEC_CONTENT	∈[0\tagSEC_CONTENT	,\tagSEC_CONTENT	1\tagSEC_CONTENT	]\tagSEC_CONTENT	I\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	overall\tagSEC_CONTENT	tokens\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	x\tagSEC_CONTENT	a\tagSEC_CONTENT	and\tagSEC_CONTENT	v\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	W\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	W\tagSEC_CONTENT	6\tagSEC_CONTENT	,\tagSEC_CONTENT	b\tagSEC_CONTENT	1\tagSEC_CONTENT	are\tagSEC_CONTENT	learned\tagSEC_CONTENT	parameters\tagmetric	.\tagSEC_CONTENT	For\tagSEC_CONTENT	each\tagSEC_CONTENT	decoding\tagSEC_CONTENT	step\tagSEC_CONTENT	t\tagSEC_CONTENT	,\tagSEC_CONTENT	anew\tagSEC_CONTENT	decoder\tagSEC_CONTENT	context\tagSEC_CONTENT	is\tagSEC_CONTENT	calculated\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	:\tagSEC_END	which\tagSEC_START	is\tagSEC_CONTENT	the\tagSEC_CONTENT	weighted\tagSEC_CONTENT	sum\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	encoder\tagSEC_CONTENT	hidden\tagSEC_CONTENT	states\tagSEC_CONTENT	of\tagSEC_CONTENT	agent\tagSEC_CONTENT	a.\tagSEC_CONTENT	Each\tagSEC_CONTENT	word\tagSEC_CONTENT	context\tagSEC_CONTENT	vector\tagSEC_CONTENT	represents\tagSEC_CONTENT	the\tagSEC_CONTENT	information\tagSEC_CONTENT	extracted\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	agent\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	read\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	has\tagSEC_CONTENT	to\tagSEC_CONTENT	decide\tagSEC_CONTENT	which\tagSEC_CONTENT	information\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	relevant\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	decoding\tagSEC_CONTENT	step\tagSEC_CONTENT	t.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	done\tagSEC_CONTENT	by\tagSEC_CONTENT	weighting\tagSEC_CONTENT	each\tagSEC_CONTENT	context\tagSEC_CONTENT	vector\tagSEC_CONTENT	by\tagSEC_CONTENT	an\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	yielding\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	global\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	distribution\tagSEC_CONTENT	gt\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	)\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	v\tagSEC_CONTENT	3\tagSEC_CONTENT	,\tagSEC_CONTENT	W\tagSEC_CONTENT	7\tagSEC_CONTENT	,\tagSEC_CONTENT	W\tagSEC_CONTENT	8\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	b\tagSEC_CONTENT	2\tagSEC_CONTENT	are\tagSEC_CONTENT	learned\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_END	Then\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	agent\tagSEC_CONTENT	context\tagSEC_CONTENT	vector\tagSEC_CONTENT	c\tagSEC_CONTENT	*\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_END	The\tagSEC_START	agent\tagSEC_CONTENT	context\tagSEC_CONTENT	c\tagSEC_CONTENT	*\tagSEC_CONTENT	t\tagSEC_CONTENT	∈R\tagSEC_CONTENT	H\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	length\tagSEC_CONTENT	vector\tagSEC_CONTENT	encoding\tagSEC_CONTENT	salient\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	entire\tagSEC_CONTENT	document\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	concatenated\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	state\tagSEC_CONTENT	st\tagSEC_CONTENT	and\tagSEC_CONTENT	fed\tagSEC_CONTENT	through\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	layer\tagSEC_CONTENT	perception\tagSEC_CONTENT	to\tagSEC_CONTENT	produce\tagSEC_CONTENT	a\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	distribution\tagSEC_CONTENT	(\tagSEC_CONTENT	over\tagSEC_CONTENT	all\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	words\tagSEC_CONTENT	)\tagSEC_CONTENT	at\tagSEC_CONTENT	time\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_END	To\tagSEC_START	keep\tagSEC_CONTENT	the\tagSEC_CONTENT	topics\tagSEC_CONTENT	of\tagSEC_CONTENT	generated\tagSEC_CONTENT	sentences\tagSEC_CONTENT	intact\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	reasonable\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	utilize\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	agents\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	course\tagSEC_CONTENT	of\tagSEC_CONTENT	short\tagSEC_CONTENT	sequences\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	within\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Because\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	is\tagSEC_CONTENT	designed\tagSEC_CONTENT	to\tagSEC_CONTENT	select\tagSEC_CONTENT	which\tagSEC_CONTENT	agent\tagSEC_CONTENT	to\tagSEC_CONTENT	attend\tagSEC_CONTENT	to\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	introduce\tagSEC_CONTENT	contextual\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	(\tagSEC_CONTENT	caa\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	prevent\tagSEC_CONTENT	it\tagSEC_CONTENT	from\tagSEC_CONTENT	frequently\tagSEC_CONTENT	switching\tagSEC_CONTENT	between\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	previous\tagSEC_CONTENT	step\tagSEC_CONTENT	's\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	c\tagSEC_CONTENT	*\tagSEC_CONTENT	t−1\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	additional\tagSEC_CONTENT	information\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	decoding\tagSEC_CONTENT	step\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	a\tagtask	distribution\tagtask	over\tagSEC_CONTENT	words\tagSEC_CONTENT	:\tagSEC_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Agent\tagSECTITLE_CONTENT	Pointer\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Similar\tagSEC_START	to\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	allow\tagSEC_CONTENT	for\tagSEC_CONTENT	copying\tagSEC_CONTENT	candidate\tagSEC_CONTENT	words\tagSEC_CONTENT	from\tagSEC_CONTENT	different\tagSEC_CONTENT	paragraphs\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	by\tagSEC_CONTENT	computing\tagSEC_CONTENT	a\tagSEC_CONTENT	generation\tagSEC_CONTENT	probability\tagSEC_CONTENT	value\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	pt\tagSEC_CONTENT	a\tagSEC_CONTENT	∈[0,1\tagSEC_CONTENT	]\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	timestep\tagSEC_CONTENT	t\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	vector\tagSEC_CONTENT	ct\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	decoder\tagSEC_CONTENT	state\tagSEC_CONTENT	st\tagSEC_CONTENT	and\tagSEC_CONTENT	decoder\tagSEC_CONTENT	input\tagSEC_CONTENT	y\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	b\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	learned\tagSEC_CONTENT	scalar\tagSEC_CONTENT	,\tagSEC_CONTENT	y\tagSEC_CONTENT	t\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	groundtruth\tagSEC_CONTENT	/\tagSEC_CONTENT	predicted\tagSEC_CONTENT	output\tagSEC_CONTENT	(\tagSEC_CONTENT	depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	/\tagSEC_CONTENT	testing\tagSEC_CONTENT	time\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	generation\tagSEC_CONTENT	probability\tagSEC_CONTENT	determines\tagSEC_CONTENT	whether\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	by\tagSEC_CONTENT	sampling\tagSEC_CONTENT	from\tagSEC_CONTENT	P\tagSEC_CONTENT	voc\tagSEC_CONTENT	(\tagSEC_CONTENT	w|\tagSEC_CONTENT	·\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	copying\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	agent\tagSEC_CONTENT	's\tagSEC_CONTENT	input\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	x\tagSEC_CONTENT	a\tagSEC_CONTENT	by\tagSEC_CONTENT	sampling\tagSEC_CONTENT	from\tagSEC_CONTENT	its\tagSEC_CONTENT	attention\tagSEC_CONTENT	distribution\tagSEC_CONTENT	l\tagSEC_CONTENT	ta\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	produces\tagSEC_CONTENT	an\tagSEC_CONTENT	extended\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	that\tagSEC_CONTENT	includes\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	considered\tagSEC_CONTENT	out\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	(\tagSEC_CONTENT	OOV\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	probability\tagSEC_CONTENT	distribution\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	extended\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	is\tagSEC_CONTENT	computed\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	u\tagSEC_CONTENT	t\tagSEC_CONTENT	a\tagSEC_CONTENT	,\tagSEC_CONTENT	w\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	sum\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	instances\tagSEC_CONTENT	where\tagSEC_CONTENT	w\tagSEC_CONTENT	appears\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	final\tagSEC_CONTENT	distribution\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	extended\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	,\tagSEC_CONTENT	from\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	sample\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	obtained\tagSEC_CONTENT	by\tagSEC_CONTENT	weighting\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	by\tagSEC_CONTENT	their\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	values\tagSEC_CONTENT	gt\tagSEC_CONTENT	a\tagSEC_CONTENT	:\tagSEC_END	In\tagSEC_START	contrast\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	baseline\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	allows\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	to\tagSEC_CONTENT	vote\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	OOV\tagSEC_CONTENT	words\tagSEC_CONTENT	at\tagSEC_CONTENT	time\tagSEC_CONTENT	t\tagSEC_CONTENT	(\tagtask	Equation\tagtask	)\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	such\tagSEC_CONTENT	a\tagSEC_CONTENT	case\tagSEC_CONTENT	,\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	relevant\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	summary\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	time\tagSEC_CONTENT	t\tagSEC_CONTENT	is\tagSEC_CONTENT	collaboratively\tagSEC_CONTENT	voted\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	result\tagSEC_CONTENT	of\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	probability\tagSEC_CONTENT	gt\tagSEC_CONTENT	a\tagSEC_CONTENT	.\tagSEC_END	Mixed\tagSECTITLE_START	Objective\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	To\tagSEC_START	train\tagSEC_CONTENT	the\tagSEC_CONTENT	deep\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agents\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	mixed\tagSEC_CONTENT	training\tagSEC_CONTENT	objective\tagSEC_CONTENT	that\tagSEC_CONTENT	jointly\tagSEC_CONTENT	optimizes\tagSEC_CONTENT	multiple\tagSEC_CONTENT	losses\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	describe\tagSEC_CONTENT	below\tagSEC_CONTENT	.\tagSEC_END	MLE\tagSEC_START	Our\tagSEC_CONTENT	baseline\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	uses\tagSEC_CONTENT	maximum\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	training\tagSEC_CONTENT	for\tagSEC_CONTENT	sequence\tagSEC_CONTENT	generation\tagSEC_CONTENT	.\tagSEC_CONTENT	Given\tagSEC_CONTENT	y\tagSEC_CONTENT	*\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	y\tagSEC_CONTENT	*\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	y\tagSEC_CONTENT	*\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	...\tagSEC_CONTENT	,\tagSEC_CONTENT	y\tagSEC_CONTENT	*\tagSEC_CONTENT	T\tagSEC_CONTENT	}\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	groundtruth\tagSEC_CONTENT	output\tagSEC_CONTENT	sequence\tagSEC_CONTENT	(\tagSEC_CONTENT	human\tagSEC_CONTENT	summary\tagSEC_CONTENT	word\tagSEC_CONTENT	sequences\tagSEC_CONTENT	)\tagSEC_CONTENT	fora\tagSEC_CONTENT	given\tagSEC_CONTENT	input\tagSEC_CONTENT	document\tagSEC_CONTENT	d\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	minimize\tagSEC_CONTENT	the\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	word\tagSEC_CONTENT	sequence\tagSEC_CONTENT	:\tagSEC_END	Semantic\tagSEC_START	Cohesion\tagSEC_CONTENT	To\tagSEC_CONTENT	encourage\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	informative\tagSEC_CONTENT	without\tagSEC_CONTENT	repetition\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	include\tagSEC_CONTENT	a\tagSEC_CONTENT	semantic\tagSEC_CONTENT	cohesion\tagSEC_CONTENT	loss\tagSEC_CONTENT	to\tagSEC_CONTENT	integrate\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	semantics\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	learning\tagSEC_CONTENT	objective\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	generates\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	word\tagSEC_CONTENT	sequence\tagSEC_CONTENT	{\tagSEC_CONTENT	y\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	y\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	y\tagSEC_CONTENT	T\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	keeps\tagSEC_CONTENT	track\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	sentence\tagSEC_CONTENT	delimiter\tagSEC_CONTENT	token\tagSEC_CONTENT	(\tagSEC_CONTENT	'\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	)\tagSEC_CONTENT	indices\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	vectors\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	sentence\tagSEC_CONTENT	sq\tagSEC_CONTENT	,\tagSEC_CONTENT	q=1\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	sq\tagSEC_CONTENT	∈{s\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_CONTENT	y\tagSEC_CONTENT	t\tagSEC_CONTENT	=\tagSEC_CONTENT	'\tagSEC_CONTENT	·\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	1≤t≤T\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	cosine\tagSEC_CONTENT	similarity\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	consecutively\tagSEC_CONTENT	generated\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	minimize\tagSEC_CONTENT	the\tagSEC_CONTENT	similarity\tagSEC_CONTENT	between\tagSEC_CONTENT	end\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	hidden\tagSEC_CONTENT	states\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	a\tagSEC_CONTENT	semantic\tagSEC_CONTENT	cohesion\tagSEC_CONTENT	loss\tagSEC_CONTENT	:\tagSEC_END	The\tagSEC_START	final\tagSEC_CONTENT	training\tagSEC_CONTENT	objective\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	λ\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	tunable\tagSEC_CONTENT	hyperparameter\tagSEC_CONTENT	.\tagSEC_END	Reinforcement\tagSEC_START	Learning\tagSEC_CONTENT	(\tagSEC_CONTENT	RL\tagSEC_CONTENT	)\tagSEC_CONTENT	Loss\tagSEC_CONTENT	Policy\tagSEC_CONTENT	gradient\tagSEC_CONTENT	methods\tagSEC_CONTENT	can\tagSEC_CONTENT	directly\tagSEC_CONTENT	optimize\tagSEC_CONTENT	discrete\tagSEC_CONTENT	target\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	metrics\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	ROUGE\tagmetric	that\tagSEC_CONTENT	are\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	differentiable\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	At\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	viewed\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	action\tagSEC_CONTENT	taken\tagSEC_CONTENT	by\tagSEC_CONTENT	an\tagSEC_CONTENT	RL\tagSEC_CONTENT	agent\tagSEC_CONTENT	.\tagSEC_CONTENT	Once\tagSEC_CONTENT	the\tagSEC_CONTENT	full\tagSEC_CONTENT	sequencê\tagSEC_CONTENT	y\tagSEC_CONTENT	is\tagSEC_CONTENT	generated\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	compared\tagSEC_CONTENT	against\tagSEC_CONTENT	the\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	sequence\tagSEC_CONTENT	y\tagSEC_CONTENT	*\tagSEC_CONTENT	to\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	reward\tagSEC_CONTENT	r(ˆ\tagSEC_CONTENT	y\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	model\tagSEC_CONTENT	learns\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	self\tagSEC_CONTENT	-\tagSEC_CONTENT	critical\tagSEC_CONTENT	training\tagSEC_CONTENT	approach\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	learns\tagSEC_CONTENT	by\tagSEC_CONTENT	exploring\tagSEC_CONTENT	new\tagSEC_CONTENT	sequences\tagSEC_CONTENT	and\tagSEC_CONTENT	comparing\tagSEC_CONTENT	them\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	greedily\tagSEC_CONTENT	decoded\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	each\tagSEC_CONTENT	training\tagSEC_CONTENT	exampled\tagSEC_CONTENT	,\tagSEC_CONTENT	two\tagSEC_CONTENT	output\tagSEC_CONTENT	sequences\tagSEC_CONTENT	are\tagSEC_CONTENT	generated\tagSEC_CONTENT	:\tagSEC_CONTENT	ˆ\tagSEC_CONTENT	y\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	sampled\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	distribution\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	p(ˆ\tagSEC_CONTENT	y\tagSEC_CONTENT	t\tagSEC_CONTENT	|ˆy|ˆy\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	ˆ\tagSEC_CONTENT	y\tagSEC_CONTENT	t−1\tagSEC_CONTENT	,\tagSEC_CONTENT	d\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and˜yand˜\tagSEC_CONTENT	and˜y\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	output\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	greedily\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	argmax\tagSEC_CONTENT	decoding\tagSEC_CONTENT	from\tagSEC_CONTENT	p(˜\tagSEC_CONTENT	y\tagSEC_CONTENT	t\tagSEC_CONTENT	|˜y|˜y\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	training\tagSEC_CONTENT	objective\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	to\tagSEC_CONTENT	minimize\tagSEC_CONTENT	:\tagSEC_END	This\tagSEC_START	loss\tagSEC_CONTENT	ensures\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	better\tagSEC_CONTENT	exploration\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	learns\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	sequencesˆysequencesˆ\tagSEC_CONTENT	sequencesˆy\tagSEC_CONTENT	that\tagSEC_CONTENT	receive\tagSEC_CONTENT	higher\tagSEC_CONTENT	rewards\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline˜ybaseline˜\tagSEC_CONTENT	baseline˜y\tagSEC_CONTENT	,\tagSEC_CONTENT	increasing\tagSEC_CONTENT	overall\tagSEC_CONTENT	reward\tagSEC_CONTENT	expectation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_END	Mixed\tagSECTITLE_START	Loss\tagSECTITLE_END	While\tagSEC_START	training\tagSEC_CONTENT	with\tagSEC_CONTENT	only\tagSEC_CONTENT	MLE\tagSEC_CONTENT	loss\tagSEC_CONTENT	will\tagSEC_CONTENT	learn\tagSEC_CONTENT	a\tagSEC_CONTENT	better\tagSEC_CONTENT	language\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	may\tagSEC_CONTENT	not\tagSEC_CONTENT	guarantee\tagSEC_CONTENT	better\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	global\tagSEC_CONTENT	performance\tagSEC_CONTENT	measures\tagSEC_CONTENT	.\tagSEC_CONTENT	Similarly\tagSEC_CONTENT	,\tagSEC_CONTENT	optimizing\tagSEC_CONTENT	with\tagSEC_CONTENT	only\tagSEC_CONTENT	RL\tagSEC_CONTENT	loss\tagSEC_CONTENT	may\tagSEC_CONTENT	increase\tagSEC_CONTENT	the\tagSEC_CONTENT	reward\tagSEC_CONTENT	gathered\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	expense\tagSEC_CONTENT	of\tagSEC_CONTENT	diminished\tagSEC_CONTENT	readability\tagSEC_CONTENT	and\tagSEC_CONTENT	fluency\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	summary\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagtask	combination\tagtask	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	objectives\tagSEC_CONTENT	can\tagSEC_CONTENT	yield\tagSEC_CONTENT	improved\tagSEC_CONTENT	task\tagSEC_CONTENT	-\tagSEC_CONTENT	specific\tagSEC_CONTENT	scores\tagSEC_CONTENT	while\tagSEC_CONTENT	maintaining\tagSEC_CONTENT	fluency\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	γ\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	tunable\tagSEC_CONTENT	hyperparameter\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	balance\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	objective\tagSEC_CONTENT	functions\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	train\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	MLE\tagSEC_CONTENT	loss\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	then\tagSEC_CONTENT	switch\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	mixed\tagSEC_CONTENT	loss\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	also\tagSEC_CONTENT	add\tagSEC_CONTENT	the\tagSEC_CONTENT	semantic\tagSEC_CONTENT	cohesion\tagSEC_CONTENT	loss\tagSEC_CONTENT	term\tagSEC_CONTENT	:\tagSEC_END	to\tagSEC_START	analyze\tagSEC_CONTENT	its\tagSEC_CONTENT	impact\tagSEC_CONTENT	in\tagSEC_CONTENT	RL\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_END	Intermediate\tagSEC_START	Rewards\tagSEC_CONTENT	We\tagSEC_CONTENT	introduce\tagSEC_CONTENT	sentencebased\tagSEC_CONTENT	rewards\tagSEC_CONTENT	as\tagSEC_CONTENT	opposed\tagSEC_CONTENT	to\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	summary\tagSEC_CONTENT	rewards\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	differential\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	metrics\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	promote\tagSEC_CONTENT	generating\tagSEC_CONTENT	diverse\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_CONTENT	Rather\tagSEC_CONTENT	than\tagSEC_CONTENT	rewarding\tagSEC_CONTENT	sentences\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	scores\tagSEC_CONTENT	obtained\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	compute\tagSEC_CONTENT	incremental\tagSEC_CONTENT	rouge\tagSEC_CONTENT	scores\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	generated\tagSEC_CONTENT	sentencê\tagSEC_CONTENT	o\tagSEC_CONTENT	q\tagSEC_CONTENT	:\tagSEC_END	Sentences\tagSEC_START	are\tagSEC_CONTENT	rewarded\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	increase\tagSEC_CONTENT	in\tagSEC_CONTENT	ROUGE\tagmetric	they\tagSEC_CONTENT	contribute\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	full\tagSEC_CONTENT	sequence\tagSEC_CONTENT	,\tagSEC_CONTENT	ensuring\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	sentence\tagSEC_CONTENT	contributed\tagSEC_CONTENT	novel\tagSEC_CONTENT	information\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	overall\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Datasets\tagSEC_START	We\tagSEC_CONTENT	conducted\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	two\tagtask	summarization\tagtask	datasets\tagtask	:\tagSEC_CONTENT	CNN\tagSEC_CONTENT	/\tagSEC_CONTENT	DailyMail\tagSEC_CONTENT	(\tagSEC_CONTENT	and\tagSEC_CONTENT	New\tagSEC_CONTENT	York\tagSEC_CONTENT	Times\tagSEC_CONTENT	(\tagSEC_CONTENT	NYT\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	replicate\tagSEC_CONTENT	the\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	data\tagSEC_CONTENT	splits\tagSEC_CONTENT	,\tagSEC_CONTENT	except\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	anonymize\tagSEC_CONTENT	named\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	our\tagSEC_CONTENT	DCA\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	initialize\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	agents\tagSEC_CONTENT	before\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	partition\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	among\tagSEC_CONTENT	the\tagSEC_CONTENT	agents\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	,\tagSEC_CONTENT	three\tagSEC_CONTENT	agent\tagSEC_CONTENT	→\tagSEC_CONTENT	three\tagSEC_CONTENT	paragraphs\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Additional\tagSEC_CONTENT	details\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	found\tagSEC_CONTENT	in\tagSEC_CONTENT	Appendix\tagSEC_CONTENT	A.1\tagSEC_CONTENT	.\tagSEC_END	Training\tagSEC_START	Details\tagSEC_CONTENT	During\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	testing\tagSEC_CONTENT	we\tagSEC_CONTENT	truncate\tagSEC_CONTENT	the\tagSEC_CONTENT	article\tagSEC_CONTENT	to\tagSEC_CONTENT	800\tagSEC_CONTENT	tokens\tagSEC_CONTENT	and\tagSEC_CONTENT	limit\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	to\tagSEC_CONTENT	100\tagSEC_CONTENT	tokens\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	110\tagSEC_CONTENT	tokens\tagSEC_CONTENT	attest\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	distribute\tagSEC_CONTENT	the\tagSEC_CONTENT	truncated\tagSEC_CONTENT	articles\tagSEC_CONTENT	among\tagSEC_CONTENT	agents\tagSEC_CONTENT	for\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	preserving\tagSEC_CONTENT	the\tagSEC_CONTENT	paragraph\tagSEC_CONTENT	and\tagSEC_CONTENT	sentences\tagSEC_CONTENT	as\tagSEC_CONTENT	possible\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	limit\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	and\tagSEC_CONTENT	output\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	size\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	50,000\tagSEC_CONTENT	most\tagSEC_CONTENT	frequent\tagSEC_CONTENT	tokens\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	train\tagSEC_CONTENT	with\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	two\tagSEC_CONTENT	contextual\tagSEC_CONTENT	layers\tagSEC_CONTENT	in\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	DCA\tagSEC_CONTENT	models\tagSEC_CONTENT	as\tagSEC_CONTENT	more\tagSEC_CONTENT	layers\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	provide\tagSEC_CONTENT	additional\tagSEC_CONTENT	performance\tagSEC_CONTENT	gains\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	fix\tagSEC_CONTENT	γ\tagSEC_CONTENT	=\tagSEC_CONTENT	0.97\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	RL\tagSEC_CONTENT	term\tagSEC_CONTENT	in\tagSEC_CONTENT	Equation\tagtask	and\tagSEC_CONTENT	λ\tagSEC_CONTENT	=\tagSEC_CONTENT	0.1\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	SEM\tagSEC_CONTENT	term\tagSEC_CONTENT	in\tagSEC_CONTENT	MLE\tagSEC_CONTENT	and\tagSEC_CONTENT	MIXED\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	Additional\tagSEC_CONTENT	details\tagSEC_CONTENT	are\tagSEC_CONTENT	provided\tagSEC_CONTENT	in\tagSEC_CONTENT	Appendix\tagSEC_CONTENT	A.2\tagSEC_CONTENT	.\tagSEC_END	Evaluation\tagSEC_START	We\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	system\tagSEC_CONTENT	using\tagSEC_CONTENT	ROUGE-1\tagmetric	(\tagSEC_CONTENT	unigram\tagSEC_CONTENT	recall\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	ROUGE-2\tagSEC_CONTENT	(\tagSEC_CONTENT	bigram\tagSEC_CONTENT	recall\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	(\tagSEC_CONTENT	longest\tagSEC_CONTENT	common\tagSEC_CONTENT	sequence\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	select\tagSEC_CONTENT	the\tagSEC_CONTENT	MLE\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	lowest\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	MLE+RL\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	highest\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	scores\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	sample\tagSEC_CONTENT	of\tagSEC_CONTENT	validation\tagSEC_CONTENT	data\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	Model\tagSEC_CONTENT	ROUGE-1\tagSEC_CONTENT	ROUGE-2\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	SummaRuNNer\tagSEC_CONTENT	(\tagSEC_CONTENT	39.60\tagSEC_CONTENT	16.20\tagSEC_CONTENT	35.30\tagSEC_CONTENT	graph\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	attention\tagSEC_CONTENT	38.01\tagSEC_CONTENT	13.90\tagSEC_CONTENT	34.00\tagSEC_CONTENT	pointer\tagSEC_CONTENT	generator\tagSEC_CONTENT	(\tagSEC_CONTENT	36\tagSEC_CONTENT	  \tagSEC_CONTENT	The\tagSEC_CONTENT	rest\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	use\tagSEC_CONTENT	3\tagSEC_CONTENT	agents\tagSEC_CONTENT	and\tagSEC_CONTENT	incrementally\tagSEC_CONTENT	add\tagSEC_CONTENT	one\tagSEC_CONTENT	component\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	add\tagSEC_CONTENT	the\tagSEC_CONTENT	semantic\tagSEC_CONTENT	cohesion\tagSEC_CONTENT	loss\tagSEC_CONTENT	(\tagSEC_CONTENT	m4\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	add\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	pointer\tagSEC_CONTENT	networks\tagSEC_CONTENT	(\tagSEC_CONTENT	mpgen\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	agent\tagSEC_CONTENT	communication\tagSEC_CONTENT	(\tagSEC_CONTENT	m5\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	add\tagSEC_CONTENT	contextual\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	(\tagSEC_CONTENT	caa\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	m6\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	train\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	mixed\tagSEC_CONTENT	MLE+RL+SEM\tagSEC_CONTENT	loss\tagSEC_CONTENT	(\tagSEC_CONTENT	m7\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	DCA\tagSEC_CONTENT	models\tagSEC_CONTENT	use\tagSEC_CONTENT	pointer\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_END	Results\tagSECTITLE_END	Quantitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	We\tagSEC_START	show\tagSEC_CONTENT	our\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	/\tagSEC_CONTENT	DailyMail\tagSEC_CONTENT	and\tagSEC_CONTENT	NYT\tagSEC_CONTENT	datasets\tagSEC_CONTENT	in\tagSEC_CONTENT	and\tagSEC_CONTENT	2\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	Overall\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	(\tagSEC_CONTENT	m6\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	(\tagSEC_CONTENT	m7\tagSEC_CONTENT	)\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	multiagent\tagSEC_CONTENT	encoders\tagSEC_CONTENT	,\tagSEC_CONTENT	pointer\tagSEC_CONTENT	generation\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	communication\tagtask	are\tagSEC_CONTENT	the\tagSEC_CONTENT	strongest\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	ROUGE-1\tagSEC_CONTENT	and\tagSEC_CONTENT	ROUGE-2\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	weaker\tagSEC_CONTENT	on\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	RL\tagSEC_CONTENT	model\tagSEC_CONTENT	from\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	evaluations\tagSEC_CONTENT	in\tagSEC_CONTENT	that\tagSEC_CONTENT	work\tagSEC_CONTENT	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	their\tagSEC_CONTENT	model\tagSEC_CONTENT	received\tagSEC_CONTENT	lower\tagSEC_CONTENT	readability\tagSEC_CONTENT	and\tagSEC_CONTENT	relevance\tagSEC_CONTENT	scores\tagSEC_CONTENT	than\tagSEC_CONTENT	a\tagSEC_CONTENT	model\tagSEC_CONTENT	trained\tagSEC_CONTENT	with\tagSEC_CONTENT	MLE\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	the\tagSEC_CONTENT	additional\tagSEC_CONTENT	boost\tagSEC_CONTENT	in\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	was\tagSEC_CONTENT	not\tagSEC_CONTENT	correlated\tagSEC_CONTENT	with\tagSEC_CONTENT	summary\tagSEC_CONTENT	quality\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	result\tagSEC_CONTENT	can\tagSEC_CONTENT	also\tagSEC_CONTENT	account\tagSEC_CONTENT	for\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	models\tagSEC_CONTENT	being\tagSEC_CONTENT	more\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	models\tagSEC_CONTENT	use\tagSEC_CONTENT	mixed\tagSEC_CONTENT	loss\tagSEC_CONTENT	not\tagSEC_CONTENT	just\tagSEC_CONTENT	to\tagSEC_CONTENT	op\tagSEC_CONTENT	-\tagSEC_CONTENT	timize\tagSEC_CONTENT	for\tagSEC_CONTENT	sentence\tagSEC_CONTENT	level\tagSEC_CONTENT	structure\tagSEC_CONTENT	similarity\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	reference\tagSEC_CONTENT	summary\tagSEC_CONTENT	(\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	higher\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	as\tagSEC_CONTENT	reward\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	parameters\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	semantic\tagSEC_CONTENT	coherence\tagSEC_CONTENT	,\tagSEC_CONTENT	promoting\tagSEC_CONTENT	higher\tagSEC_CONTENT	abstraction\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	and\tagSEC_CONTENT	Appendix\tagSEC_CONTENT	B\tagSEC_CONTENT	for\tagSEC_CONTENT	generated\tagSEC_CONTENT	summary\tagSEC_CONTENT	examples\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	 \tagSEC_CONTENT	Single\tagSEC_CONTENT	vs.\tagSEC_CONTENT	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	Agents\tagSEC_CONTENT	All\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	models\tagSEC_CONTENT	show\tagSEC_CONTENT	improvements\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	baselines\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	/\tagSEC_CONTENT	DailyMail\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	MLE\tagSEC_CONTENT	published\tagSEC_CONTENT	baselines\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	improve\tagSEC_CONTENT	across\tagSEC_CONTENT	all\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	scores\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	3-agent\tagSEC_CONTENT	models\tagSEC_CONTENT	generally\tagSEC_CONTENT	outperformed\tagSEC_CONTENT	both\tagSEC_CONTENT	2-and\tagSEC_CONTENT	5-agent\tagSEC_CONTENT	models\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	in\tagSEC_CONTENT	part\tagSEC_CONTENT	because\tagSEC_CONTENT	we\tagSEC_CONTENT	truncate\tagSEC_CONTENT	documents\tagSEC_CONTENT	before\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	larger\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	agents\tagSEC_CONTENT	might\tagSEC_CONTENT	be\tagSEC_CONTENT	more\tagSEC_CONTENT	efficient\tagSEC_CONTENT	for\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	document\tagSEC_CONTENT	summarization\tagSEC_CONTENT	.\tagSEC_END	Model\tagSECTITLE_END	Independent\tagSEC_START	vs.\tagSEC_CONTENT	Communicating\tagSEC_CONTENT	Agents\tagSEC_CONTENT	When\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	multiple\tagSEC_CONTENT	agents\tagSEC_CONTENT	with\tagSEC_CONTENT	no\tagtask	communication\tagtask	(\tagSEC_CONTENT	m4\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	DCA\tagSEC_CONTENT	models\tagSEC_CONTENT	is\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	baselines\tagSEC_CONTENT	(\tagSEC_CONTENT	m1\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	(\tagSEC_CONTENT	m3\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	With\tagSEC_CONTENT	communication\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	biggest\tagSEC_CONTENT	jump\tagSEC_CONTENT	in\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	is\tagSEC_CONTENT	seen\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	/\tagSEC_CONTENT	DailyMail\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	encoders\tagSEC_CONTENT	can\tagSEC_CONTENT	better\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	facts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	,\tagSEC_CONTENT	thereby\tagSEC_CONTENT	avoiding\tagSEC_CONTENT	unnecessary\tagSEC_CONTENT	details\tagSEC_CONTENT	.\tagSEC_END	Contextual\tagSEC_START	Agent\tagSEC_CONTENT	Attention\tagSEC_CONTENT	(\tagSEC_CONTENT	caa\tagSEC_CONTENT	)\tagSEC_CONTENT	Compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	no\tagSEC_CONTENT	contextualized\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	(\tagSEC_CONTENT	m5\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	(\tagSEC_CONTENT	m6\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	yields\tagSEC_CONTENT	better\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	scores\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	stability\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	caa\tagSEC_CONTENT	helps\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	avoid\tagSEC_CONTENT	frequent\tagSEC_CONTENT	switches\tagSEC_CONTENT	between\tagSEC_CONTENT	agents\tagSEC_CONTENT	that\tagSEC_CONTENT	would\tagSEC_CONTENT	dilute\tagSEC_CONTENT	the\tagSEC_CONTENT	topical\tagSEC_CONTENT	signal\tagSEC_CONTENT	captured\tagSEC_CONTENT	by\tagSEC_CONTENT	each\tagSEC_CONTENT	encoder\tagSEC_CONTENT	.\tagSEC_END	Repetition\tagSEC_START	Penalty\tagSEC_CONTENT	As\tagSEC_CONTENT	neurally\tagSEC_CONTENT	generated\tagSEC_CONTENT	summaries\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	redundant\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	introduced\tagSEC_CONTENT	the\tagSEC_CONTENT	semantic\tagSEC_CONTENT	cohesion\tagSEC_CONTENT	penalty\tagSEC_CONTENT	and\tagSEC_CONTENT	incremental\tagSEC_CONTENT	rewards\tagSEC_CONTENT	for\tagSEC_CONTENT	RL\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	semantically\tagSEC_CONTENT	diverse\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	optimized\tagSEC_CONTENT	together\tagSEC_CONTENT	with\tagSEC_CONTENT	SEM\tagSEC_CONTENT	loss\tagSEC_CONTENT	(\tagSEC_CONTENT	m2\tagSEC_CONTENT	)\tagSEC_CONTENT	improves\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	scores\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	(\tagSEC_CONTENT	m1\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Similarly\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	trained\tagSEC_CONTENT	with\tagSEC_CONTENT	reinforcement\tagSEC_CONTENT	learning\tagSEC_CONTENT	uses\tagSEC_CONTENT	sentence\tagSEC_CONTENT	based\tagSEC_CONTENT	intermediate\tagSEC_CONTENT	rewards\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	also\tagSEC_CONTENT	improves\tagSEC_CONTENT	ROUGE\tagmetric	scores\tagmetric	across\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_END	Human\tagSECTITLE_START	Evaluations\tagSECTITLE_END	We\tagSEC_START	perform\tagSEC_CONTENT	human\tagtask	evaluations\tagtask	to\tagSEC_CONTENT	establish\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	's\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	improvements\tagSEC_CONTENT	are\tagSEC_CONTENT	correlated\tagSEC_CONTENT	with\tagSEC_CONTENT	human\tagSEC_CONTENT	judgments\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	measure\tagSEC_CONTENT	the\tagSEC_CONTENT	communicative\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	contextual\tagSEC_CONTENT	agent\tagSEC_CONTENT	attention\tagSEC_CONTENT	in\tagSEC_CONTENT	comparison\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	no\tagSEC_CONTENT	communication\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	as\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	criteria\tagSEC_CONTENT	for\tagSEC_CONTENT	generated\tagSEC_CONTENT	summaries\tagSEC_CONTENT	:\tagSEC_CONTENT	(\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	redundancy\tagSEC_CONTENT	,\tagSEC_CONTENT	fewer\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	ideas\tagSEC_CONTENT	are\tagSEC_CONTENT	repeated\tagSEC_CONTENT	,\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	coherence\tagSEC_CONTENT	,\tagSEC_CONTENT	ideas\tagSEC_CONTENT	are\tagSEC_CONTENT	expressed\tagSEC_CONTENT	clearly\tagSEC_CONTENT	;\tagSEC_CONTENT	(\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	focus\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	ideas\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	are\tagSEC_CONTENT	shared\tagSEC_CONTENT	while\tagSEC_CONTENT	avoiding\tagSEC_CONTENT	superfluous\tagSEC_CONTENT	details\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	(\tagSEC_CONTENT	4\tagSEC_CONTENT	)\tagSEC_CONTENT	overall\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	effectively\tagSEC_CONTENT	communicates\tagSEC_CONTENT	the\tagSEC_CONTENT	article\tagSEC_CONTENT	's\tagSEC_CONTENT	content\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	focus\tagSEC_CONTENT	and\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	redundancy\tagSEC_CONTENT	dimensions\tagSEC_CONTENT	help\tagSEC_CONTENT	quantify\tagSEC_CONTENT	the\tagSEC_CONTENT	impact\tagSEC_CONTENT	of\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	communication\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	coherence\tagSEC_CONTENT	helps\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	impact\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	reward\tagSEC_CONTENT	based\tagSEC_CONTENT	learning\tagSEC_CONTENT	and\tagSEC_CONTENT	repetition\tagSEC_CONTENT	penalty\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	proposed\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_END	Evaluation\tagSEC_START	Procedure\tagSEC_CONTENT	We\tagSEC_CONTENT	randomly\tagSEC_CONTENT	selected\tagSEC_CONTENT	100\tagSEC_CONTENT	samples\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagdataset	CNN\tagdataset	/\tagdataset	DailyMail\tagdataset	test\tagdataset	set\tagSEC_CONTENT	and\tagSEC_CONTENT	use\tagSEC_CONTENT	workers\tagSEC_CONTENT	from\tagSEC_CONTENT	Amazon\tagSEC_CONTENT	Mechanical\tagSEC_CONTENT	Turk\tagSEC_CONTENT	as\tagSEC_CONTENT	judges\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	them\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	four\tagSEC_CONTENT	criteria\tagSEC_CONTENT	defined\tagSEC_CONTENT	above\tagSEC_CONTENT	.\tagSEC_CONTENT	Judges\tagSEC_CONTENT	are\tagSEC_CONTENT	shown\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	two\tagSEC_CONTENT	model\tagSEC_CONTENT	summaries\tagSEC_CONTENT	and\tagSEC_CONTENT	are\tagSEC_CONTENT	asked\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	each\tagSEC_CONTENT	summary\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	four\tagSEC_CONTENT	criteria\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	Likert\tagSEC_CONTENT	scale\tagSEC_CONTENT	from\tagSEC_CONTENT	1\tagSEC_CONTENT	(\tagSEC_CONTENT	worst\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	5\tagSEC_CONTENT	(\tagSEC_CONTENT	best\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	and\tagSEC_CONTENT	model\tagSEC_CONTENT	summaries\tagSEC_CONTENT	are\tagSEC_CONTENT	presented\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	judges\tagSEC_CONTENT	in\tagSEC_CONTENT	random\tagSEC_CONTENT	order\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	summary\tagSEC_CONTENT	is\tagSEC_CONTENT	rated\tagSEC_CONTENT	by\tagSEC_CONTENT	5\tagSEC_CONTENT	judges\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	are\tagSEC_CONTENT	averaged\tagSEC_CONTENT	across\tagSEC_CONTENT	all\tagSEC_CONTENT	examples\tagSEC_CONTENT	and\tagSEC_CONTENT	judges\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	also\tagSEC_CONTENT	performed\tagSEC_CONTENT	a\tagSEC_CONTENT	head\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	head\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	(\tagSEC_CONTENT	more\tagSEC_CONTENT	common\tagSEC_CONTENT	in\tagSEC_CONTENT	DUC\tagSEC_CONTENT	style\tagSEC_CONTENT	evaluations\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	randomly\tagSEC_CONTENT	show\tagSEC_CONTENT	two\tagSEC_CONTENT	model\tagSEC_CONTENT	generated\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	ask\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	annotators\tagSEC_CONTENT	to\tagSEC_CONTENT	rate\tagSEC_CONTENT	each\tagSEC_CONTENT	summary\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	metrics\tagSEC_CONTENT	as\tagSEC_CONTENT	before\tagSEC_CONTENT	without\tagSEC_CONTENT	seeing\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	document\tagSEC_CONTENT	or\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_END	Results\tagSEC_START	Human\tagSEC_CONTENT	evaluators\tagSEC_CONTENT	significantly\tagSEC_CONTENT	prefer\tagSEC_CONTENT	summaries\tagtask	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	communicating\tagSEC_CONTENT	encoders\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	rating\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	evaluators\tagSEC_CONTENT	preferred\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	summaries\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	cases\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	metrics\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	head\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	head\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	,\tagSEC_CONTENT	humans\tagSEC_CONTENT	consistently\tagSEC_CONTENT	preferred\tagSEC_CONTENT	the\tagSEC_CONTENT	DCA\tagSEC_CONTENT	summaries\tagSEC_CONTENT	to\tagSEC_CONTENT	those\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	both\tagSEC_CONTENT	the\tagSEC_CONTENT	head\tagSEC_CONTENT	-\tagSEC_CONTENT	to\tagSEC_CONTENT	-\tagSEC_CONTENT	head\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	rating\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	largest\tagSEC_CONTENT	improvement\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	DCA\tagSEC_CONTENT	model\tagSEC_CONTENT	was\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	focus\tagSEC_CONTENT	question\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	learns\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	summaries\tagSEC_CONTENT	with\tagSEC_CONTENT	more\tagSEC_CONTENT	pertinent\tagSEC_CONTENT	details\tagSEC_CONTENT	by\tagSEC_CONTENT	capturing\tagSEC_CONTENT	salient\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	later\tagSEC_CONTENT	portions\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_END	Human\tagSEC_START	Mr\tagSEC_CONTENT	Turnbull\tagSEC_CONTENT	was\tagSEC_CONTENT	interviewed\tagSEC_CONTENT	about\tagSEC_CONTENT	his\tagSEC_CONTENT	childhood\tagSEC_CONTENT	and\tagSEC_CONTENT	his\tagSEC_CONTENT	political\tagSEC_CONTENT	stance\tagSEC_CONTENT	.\tagSEC_CONTENT	He\tagSEC_CONTENT	also\tagSEC_CONTENT	admitted\tagSEC_CONTENT	he\tagSEC_CONTENT	planned\tagSEC_CONTENT	to\tagSEC_CONTENT	run\tagSEC_CONTENT	for\tagSEC_CONTENT	prime\tagSEC_CONTENT	minister\tagSEC_CONTENT	if\tagSEC_CONTENT	Tony\tagSEC_CONTENT	Abbott\tagSEC_CONTENT	had\tagSEC_CONTENT	been\tagSEC_CONTENT	successfully\tagSEC_CONTENT	toppled\tagSEC_CONTENT	in\tagSEC_CONTENT	February\tagSEC_CONTENT	's\tagSEC_CONTENT	leadership\tagSEC_CONTENT	spill\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	words\tagSEC_CONTENT	'\tagSEC_CONTENT	primed\tagSEC_CONTENT	minister\tagSEC_CONTENT	'\tagSEC_CONTENT	were\tagSEC_CONTENT	controversially\tagSEC_CONTENT	also\tagSEC_CONTENT	printed\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagmetric	cover\tagmetric	.\tagSEC_CONTENT	Single\tagSEC_END	Malcolm\tagSEC_START	Turnbull\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	feature\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	front\tagSEC_CONTENT	cover\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	GQ\tagSEC_CONTENT	Australia\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	bold\tagSEC_CONTENT	move\tagSEC_CONTENT	that\tagSEC_CONTENT	will\tagSEC_CONTENT	no\tagSEC_CONTENT	doubt\tagSEC_CONTENT	set\tagSEC_CONTENT	senators\tagSEC_CONTENT	'\tagSEC_CONTENT	tongues\tagSEC_CONTENT	wagging\tagSEC_CONTENT	.\tagSEC_CONTENT	Posing\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	suave\tagSEC_CONTENT	blue\tagSEC_CONTENT	suit\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	pinstriped\tagSEC_CONTENT	shirt\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	contrasting\tagSEC_CONTENT	red\tagSEC_CONTENT	tie\tagSEC_CONTENT	,\tagSEC_CONTENT	Mr\tagSEC_CONTENT	Turnbull\tagSEC_CONTENT	's\tagSEC_CONTENT	confident\tagSEC_CONTENT	demeanour\tagSEC_CONTENT	is\tagSEC_CONTENT	complimented\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	bold\tagSEC_CONTENT	,\tagSEC_CONTENT	confronting\tagSEC_CONTENT	words\tagSEC_CONTENT	printed\tagSEC_CONTENT	across\tagSEC_CONTENT	the\tagSEC_CONTENT	page\tagSEC_CONTENT	:\tagSEC_CONTENT	'\tagSEC_CONTENT	primed\tagSEC_CONTENT	minister\tagSEC_CONTENT	'\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_END	Malcolm\tagSEC_START	Turnbull\tagSEC_CONTENT	was\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	run\tagSEC_CONTENT	for\tagSEC_CONTENT	prime\tagSEC_CONTENT	minister\tagSEC_CONTENT	if\tagSEC_CONTENT	Tony\tagSEC_CONTENT	Abbott\tagSEC_CONTENT	had\tagSEC_CONTENT	been\tagSEC_CONTENT	successfully\tagSEC_CONTENT	toppled\tagSEC_CONTENT	in\tagSEC_CONTENT	February\tagSEC_CONTENT	's\tagSEC_CONTENT	leadership\tagSEC_CONTENT	spill\tagSEC_CONTENT	.\tagSEC_CONTENT	He\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	feature\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	front\tagSEC_CONTENT	cover\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	liberal\tagSEC_CONTENT	party\tagSEC_CONTENT	's\tagSEC_CONTENT	newsletter\tagSEC_CONTENT	.\tagSEC_CONTENT	Human\tagSEC_CONTENT	Daphne\tagSEC_CONTENT	Selfe\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	modelling\tagSEC_CONTENT	since\tagSEC_CONTENT	the\tagSEC_CONTENT	fifties\tagSEC_CONTENT	.\tagSEC_CONTENT	She\tagSEC_CONTENT	has\tagSEC_CONTENT	recently\tagSEC_CONTENT	landed\tagSEC_CONTENT	anew\tagSEC_CONTENT	campaign\tagSEC_CONTENT	with\tagSEC_CONTENT	vans\tagSEC_CONTENT	and\tagSEC_CONTENT	&\tagSEC_CONTENT	other\tagSEC_CONTENT	stories\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	86-year\tagSEC_CONTENT	-\tagSEC_CONTENT	old\tagSEC_CONTENT	commands\tagSEC_CONTENT	1,000\tagSEC_CONTENT	a\tagSEC_CONTENT	day\tagSEC_CONTENT	for\tagSEC_CONTENT	her\tagSEC_CONTENT	work\tagSEC_CONTENT	.\tagSEC_CONTENT	Single\tagSEC_END	Daphne\tagSEC_START	Selfe\tagSEC_CONTENT	,\tagSEC_CONTENT	86\tagSEC_CONTENT	,\tagSEC_CONTENT	shows\tagSEC_CONTENT	off\tagSEC_CONTENT	the\tagSEC_CONTENT	collaboration\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	footwearsuper\tagSEC_CONTENT	-\tagSEC_CONTENT	brandand\tagSEC_CONTENT	theetherealhigh\tagSEC_CONTENT	street\tagSEC_CONTENT	store\tagSEC_CONTENT	with\tagSEC_CONTENT	uncompromisinggrace\tagSEC_CONTENT	.\tagSEC_CONTENT	Daphne\tagSEC_CONTENT	said\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	collection\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	she\tagSEC_CONTENT	appears\tagSEC_CONTENT	with\tagSEC_CONTENT	22-year\tagSEC_CONTENT	-\tagSEC_CONTENT	old\tagSEC_CONTENT	flo\tagSEC_CONTENT	dron\tagSEC_CONTENT	:\tagSEC_CONTENT	'\tagSEC_CONTENT	the\tagSEC_CONTENT	&\tagSEC_CONTENT	other\tagSEC_CONTENT	stories\tagSEC_CONTENT	collection\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	featured\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	story\tagSEC_CONTENT	is\tagSEC_CONTENT	truly\tagSEC_CONTENT	relaxed\tagSEC_CONTENT	and\tagSEC_CONTENT	timeless\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	modern\tagSEC_CONTENT	twist\tagSEC_CONTENT	'\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	shoes\tagSEC_CONTENT	are\tagSEC_CONTENT	then\tagSEC_CONTENT	worn\tagSEC_CONTENT	with\tagSEC_CONTENT	pieces\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	brands\tagSEC_CONTENT	ss2015\tagSEC_CONTENT	collection\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_END	Communication\tagSECTITLE_START	improves\tagSECTITLE_CONTENT	focus\tagSECTITLE_END	To\tagSEC_START	investigate\tagSEC_CONTENT	how\tagSEC_CONTENT	much\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	models\tagSEC_CONTENT	discover\tagSEC_CONTENT	salient\tagSEC_CONTENT	concepts\tagSEC_CONTENT	in\tagSEC_CONTENT	comparison\tagtask	to\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	analyze\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	scores\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	average\tagSEC_CONTENT	attention\tagSEC_CONTENT	received\tagSEC_CONTENT	by\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	average\tagSEC_CONTENT	attention\tagSEC_CONTENT	received\tagSEC_CONTENT	by\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	per\tagSEC_CONTENT	decoding\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	for\tagSEC_CONTENT	every\tagSEC_CONTENT	generated\tagSEC_CONTENT	summary\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	/\tagSEC_CONTENT	Daily\tagSEC_CONTENT	Mail\tagSEC_CONTENT	test\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	bin\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	-\tagSEC_CONTENT	summary\tagSEC_CONTENT	pairs\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	received\tagSEC_CONTENT	by\tagSEC_CONTENT	each\tagSEC_CONTENT	agent\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	average\tagSEC_CONTENT	the\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	scores\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	summaries\tagSEC_CONTENT	in\tagSEC_CONTENT	each\tagSEC_CONTENT	bin\tagSEC_CONTENT	.\tagSEC_CONTENT	outlines\tagSEC_CONTENT	two\tagSEC_CONTENT	interesting\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	summaries\tagSEC_CONTENT	generated\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	distributed\tagSEC_CONTENT	attention\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	agents\tagSEC_CONTENT	yield\tagSEC_CONTENT	higher\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	scores\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	that\tagSEC_CONTENT	attending\tagSEC_CONTENT	to\tagSEC_CONTENT	multiple\tagSEC_CONTENT	areas\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	allows\tagSEC_CONTENT	the\tagSEC_CONTENT	discovery\tagSEC_CONTENT	of\tagSEC_CONTENT	salient\tagSEC_CONTENT	concepts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	later\tagSEC_CONTENT	sections\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	.\tagSEC_CONTENT	Second\tagSEC_CONTENT	,\tagSEC_CONTENT	if\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	bins\tagSEC_CONTENT	and\tagSEC_CONTENT	generate\tagSEC_CONTENT	summaries\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	documents\tagSEC_CONTENT	in\tagSEC_CONTENT	each\tagSEC_CONTENT	bin\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	singleagent\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	average\tagSEC_CONTENT	ROUGE\tagSEC_CONTENT	-\tagSEC_CONTENT	L\tagSEC_CONTENT	scores\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	summaries\tagSEC_CONTENT	are\tagSEC_CONTENT	lower\tagSEC_CONTENT	than\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	cor-\tagSEC_CONTENT	responding\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	summaries\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	that\tagSEC_CONTENT	even\tagSEC_CONTENT	in\tagSEC_CONTENT	cases\tagSEC_CONTENT	where\tagSEC_CONTENT	one\tagSEC_CONTENT	agent\tagSEC_CONTENT	dominates\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	,\tagSEC_CONTENT	communication\tagSEC_CONTENT	between\tagSEC_CONTENT	agents\tagSEC_CONTENT	allows\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	more\tagSEC_CONTENT	focused\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	Qualitatively\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	see\tagSEC_CONTENT	this\tagSEC_CONTENT	effect\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	we\tagSEC_CONTENT	compare\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	generated\tagSEC_CONTENT	summaries\tagSEC_CONTENT	against\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	m3\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	m7\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Model\tagSEC_CONTENT	(\tagSEC_CONTENT	m3\tagSEC_CONTENT	)\tagSEC_CONTENT	generates\tagSEC_CONTENT	good\tagSEC_CONTENT	summaries\tagSEC_CONTENT	but\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	capture\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	facts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	summary\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	(\tagSEC_CONTENT	m7\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	include\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	facts\tagSEC_CONTENT	with\tagSEC_CONTENT	few\tagSEC_CONTENT	extra\tagSEC_CONTENT	details\tagSEC_CONTENT	,\tagSEC_CONTENT	generating\tagSEC_CONTENT	more\tagSEC_CONTENT	relevant\tagSEC_CONTENT	and\tagSEC_CONTENT	diverse\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Several\tagSEC_START	recent\tagSEC_CONTENT	works\tagSEC_CONTENT	investigate\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanisms\tagSEC_CONTENT	for\tagSEC_CONTENT	encoder\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	sharpen\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	should\tagSEC_CONTENT	focus\tagSEC_CONTENT	on\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	encoding\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	proposes\tagSEC_CONTENT	global\tagSEC_CONTENT	and\tagSEC_CONTENT	local\tagSEC_CONTENT	attention\tagSEC_CONTENT	networks\tagSEC_CONTENT	for\tagSEC_CONTENT	machine\tagSEC_CONTENT	translation\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	others\tagSEC_CONTENT	investigate\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	attention\tagSEC_CONTENT	networks\tagSEC_CONTENT	for\tagSEC_CONTENT	document\tagSEC_CONTENT	classification\tagSEC_CONTENT	,\tagSEC_CONTENT	sentiment\tagSEC_CONTENT	classification\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	dialog\tagSEC_CONTENT	response\tagSEC_CONTENT	selection\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_END	Attention\tagSEC_START	mechanisms\tagSEC_CONTENT	have\tagSEC_CONTENT	shown\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	crucial\tagSEC_CONTENT	for\tagSEC_CONTENT	summarization\tagtask	as\tagSEC_CONTENT	well\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	pointer\tagSEC_CONTENT	networks\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	particular\tagSEC_CONTENT	,\tagSEC_CONTENT	help\tagSEC_CONTENT	address\tagSEC_CONTENT	redundancy\tagSEC_CONTENT	and\tagSEC_CONTENT	saliency\tagSEC_CONTENT	in\tagSEC_CONTENT	generated\tagSEC_CONTENT	summaries\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	we\tagSEC_CONTENT	share\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	motivation\tagSEC_CONTENT	as\tagSEC_CONTENT	these\tagSEC_CONTENT	works\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	work\tagSEC_CONTENT	uniquely\tagSEC_CONTENT	presents\tagSEC_CONTENT	an\tagSEC_CONTENT	approach\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	CommNet\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	deep\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agent\tagSEC_CONTENT	framework\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Compared\tagSEC_CONTENT	to\tagSEC_CONTENT	prior\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	works\tagSEC_CONTENT	on\tagSEC_CONTENT	logic\tagSEC_CONTENT	puzzles\tagSEC_CONTENT	,\tagSEC_CONTENT	language\tagSEC_CONTENT	learning\tagSEC_CONTENT	(\tagSEC_CONTENT	and\tagSEC_CONTENT	starcraft\tagSEC_CONTENT	games\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	present\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	study\tagSEC_CONTENT	in\tagSEC_CONTENT	using\tagSEC_CONTENT	this\tagSEC_CONTENT	framework\tagSEC_CONTENT	for\tagSEC_CONTENT	long\tagSEC_CONTENT	text\tagSEC_CONTENT	generation\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	related\tagSEC_CONTENT	to\tagSEC_CONTENT	prior\tagSEC_CONTENT	works\tagSEC_CONTENT	that\tagSEC_CONTENT	address\tagSEC_CONTENT	repetitions\tagSEC_CONTENT	in\tagSEC_CONTENT	generating\tagSEC_CONTENT	long\tagSEC_CONTENT	text\tagSEC_CONTENT	.\tagSEC_CONTENT	introduce\tagSEC_CONTENT	a\tagSEC_CONTENT	post\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	coverage\tagSEC_CONTENT	network\tagSEC_CONTENT	to\tagSEC_CONTENT	penalize\tagSEC_CONTENT	repeated\tagSEC_CONTENT	attentions\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	regions\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	use\tagSEC_CONTENT	intra\tagSEC_CONTENT	-\tagSEC_CONTENT	decoder\tagSEC_CONTENT	attention\tagSEC_CONTENT	to\tagSEC_CONTENT	punish\tagSEC_CONTENT	generating\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	contrast\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	anew\tagSEC_CONTENT	semantic\tagSEC_CONTENT	coherence\tagSEC_CONTENT	loss\tagSEC_CONTENT	and\tagSEC_CONTENT	intermediate\tagSEC_CONTENT	sentencebased\tagSEC_CONTENT	rewards\tagSEC_CONTENT	for\tagSEC_CONTENT	reinforcement\tagSEC_CONTENT	learning\tagSEC_CONTENT	to\tagSEC_CONTENT	discourage\tagSEC_CONTENT	semantically\tagSEC_CONTENT	similar\tagSEC_CONTENT	generations\tagSEC_CONTENT	(\tagSEC_CONTENT	§\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Conclusions\tagSECTITLE_END	We\tagSEC_START	investigated\tagSEC_CONTENT	the\tagSEC_CONTENT	problem\tagSEC_CONTENT	of\tagSEC_CONTENT	encoding\tagSEC_CONTENT	long\tagSEC_CONTENT	text\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summaries\tagSEC_CONTENT	and\tagSEC_CONTENT	demonstrated\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	deep\tagSEC_CONTENT	communicating\tagSEC_CONTENT	agents\tagSEC_CONTENT	can\tagSEC_CONTENT	improve\tagSEC_CONTENT	summarization\tagtask	by\tagSEC_CONTENT	both\tagSEC_CONTENT	automatic\tagSEC_CONTENT	and\tagSEC_CONTENT	manual\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	.\tagSEC_CONTENT	Analysis\tagSEC_CONTENT	demonstrates\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	improvement\tagSEC_CONTENT	is\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	improved\tagSEC_CONTENT	ability\tagSEC_CONTENT	of\tagSEC_CONTENT	covering\tagSEC_CONTENT	all\tagSEC_CONTENT	and\tagSEC_CONTENT	only\tagSEC_CONTENT	salient\tagSEC_CONTENT	concepts\tagSEC_CONTENT	and\tagSEC_CONTENT	maintaining\tagSEC_CONTENT	semantic\tagSEC_CONTENT	coherence\tagSEC_CONTENT	in\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	collection\tagSEC_CONTENT	of\tagSEC_CONTENT	online\tagSEC_CONTENT	news\tagSEC_CONTENT	articles\tagSEC_CONTENT	along\tagSEC_CONTENT	with\tagSEC_CONTENT	multisentence\tagSEC_CONTENT	summaries\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	data\tagSEC_CONTENT	splits\tagSEC_CONTENT	as\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	earlier\tagSEC_CONTENT	work\tagSEC_CONTENT	anonymized\tagSEC_CONTENT	entities\tagSEC_CONTENT	by\tagSEC_CONTENT	replacing\tagSEC_CONTENT	each\tagSEC_CONTENT	named\tagSEC_CONTENT	entity\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	unique\tagSEC_CONTENT	identifier\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	Dominican\tagSEC_CONTENT	Republic→entity15\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	opted\tagSEC_CONTENT	for\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	anonymized\tagSEC_CONTENT	version\tagSEC_CONTENT	.\tagSEC_END	A\tagSECTITLE_START	Supplementary\tagSECTITLE_CONTENT	Material\tagSECTITLE_END	New\tagSEC_START	York\tagSEC_CONTENT	Times\tagSEC_CONTENT	(\tagSEC_CONTENT	NYT\tagSEC_CONTENT	)\tagSEC_CONTENT	:\tagSEC_CONTENT	Although\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	has\tagSEC_CONTENT	mainly\tagSEC_CONTENT	been\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	extractive\tagtask	summarization\tagtask	systems\tagtask	,\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	recently\tagSEC_CONTENT	been\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	abstractive\tagSEC_CONTENT	summarization\tagSEC_CONTENT	task\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	NYT\tagSEC_CONTENT	dataset\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	collection\tagSEC_CONTENT	of\tagSEC_CONTENT	articles\tagSEC_CONTENT	published\tagSEC_CONTENT	between\tagSEC_CONTENT	1996\tagSEC_CONTENT	and\tagSEC_CONTENT	2007\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	scripts\tagSEC_CONTENT	provided\tagSEC_CONTENT	in\tagSEC_CONTENT	to\tagSEC_CONTENT	extract\tagSEC_CONTENT	and\tagSEC_CONTENT	preprocess\tagSEC_CONTENT	the\tagSEC_CONTENT	NYT\tagSEC_CONTENT	dataset\tagSEC_CONTENT	with\tagSEC_CONTENT	some\tagSEC_CONTENT	modifications\tagSEC_CONTENT	in\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	replicate\tagSEC_CONTENT	the\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	processing\tagSEC_CONTENT	steps\tagSEC_CONTENT	presented\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	to\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	sorted\tagSEC_CONTENT	the\tagSEC_CONTENT	documents\tagSEC_CONTENT	by\tagSEC_CONTENT	their\tagSEC_CONTENT	publication\tagSEC_CONTENT	date\tagSEC_CONTENT	in\tagSEC_CONTENT	chronological\tagSEC_CONTENT	order\tagSEC_CONTENT	and\tagSEC_CONTENT	used\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	90\tagSEC_CONTENT	%\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	5\tagSEC_CONTENT	%\tagSEC_CONTENT	for\tagSEC_CONTENT	validation\tagSEC_CONTENT	and\tagSEC_CONTENT	last\tagSEC_CONTENT	5\tagSEC_CONTENT	%\tagSEC_CONTENT	for\tagSEC_CONTENT	testing\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	also\tagSEC_CONTENT	use\tagSEC_CONTENT	pointer\tagSEC_CONTENT	supervision\tagSEC_CONTENT	by\tagSEC_CONTENT	replacing\tagSEC_CONTENT	all\tagSEC_CONTENT	named\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	abstract\tagSEC_CONTENT	if\tagSEC_CONTENT	the\tagSEC_CONTENT	type\tagSEC_CONTENT	is\tagSEC_CONTENT	"\tagSEC_CONTENT	PERSON\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	LOCA\tagSEC_CONTENT	-\tagSEC_CONTENT	TION\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	ORGANIZATION\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	MISC\tagSEC_CONTENT	"\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	Stanford\tagSEC_CONTENT	named\tagSEC_CONTENT	entity\tagSEC_CONTENT	recognizer\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	By\tagSEC_CONTENT	contrast\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	anonymize\tagSEC_CONTENT	the\tagSEC_CONTENT	NYT\tagSEC_CONTENT	dataset\tagSEC_CONTENT	to\tagSEC_CONTENT	reduce\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	processing\tagSEC_CONTENT	.\tagSEC_END	A.2\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	We\tagSEC_START	train\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	an\tagSEC_CONTENT	NVIDIA\tagSEC_CONTENT	P100\tagSEC_CONTENT	GPU\tagSEC_CONTENT	machine\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	set\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	encoders\tagSEC_CONTENT	and\tagSEC_CONTENT	decoders\tagSEC_CONTENT	to\tagSEC_CONTENT	128\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	limit\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	and\tagSEC_CONTENT	output\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	size\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	50,000\tagSEC_CONTENT	most\tagSEC_CONTENT	frequent\tagSEC_CONTENT	tokens\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	initialize\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	with\tagSEC_CONTENT	200-d\tagSEC_CONTENT	GloVe\tagSEC_CONTENT	vectors\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	finetune\tagSEC_CONTENT	them\tagSEC_CONTENT	during\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	train\tagSEC_CONTENT	using\tagSEC_CONTENT	Adam\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	of\tagSEC_CONTENT	0.001\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	MLE\tagSEC_CONTENT	models\tagSEC_CONTENT	and\tagSEC_CONTENT	10\tagSEC_CONTENT	−5\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	MLE+RL\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	tune\tagSEC_CONTENT	the\tagSEC_CONTENT	gamma\tagSEC_CONTENT	hyper\tagSEC_CONTENT	-\tagSEC_CONTENT	parameter\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	mixed\tagSEC_CONTENT	loss\tagSEC_CONTENT	by\tagSEC_CONTENT	iterating\tagSEC_CONTENT	γ={0.95\tagSEC_CONTENT	,\tagSEC_CONTENT	0.97\tagSEC_CONTENT	,\tagSEC_CONTENT	0.99\tagSEC_CONTENT	}\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	almost\tagSEC_CONTENT	all\tagSEC_CONTENT	DCA\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	0.97\tagSEC_CONTENT	value\tagSEC_CONTENT	yielded\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	gains\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	train\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	200,000\tagSEC_CONTENT	iterations\tagSEC_CONTENT	.\tagSEC_CONTENT	which\tagSEC_CONTENT	took\tagSEC_CONTENT	4\tagSEC_CONTENT	-\tagSEC_CONTENT	5\tagSEC_CONTENT	days\tagSEC_CONTENT	for\tagSEC_CONTENT	2\tagSEC_CONTENT	-\tagSEC_CONTENT	3\tagSEC_CONTENT	agents\tagSEC_CONTENT	and\tagSEC_CONTENT	5\tagSEC_CONTENT	-\tagSEC_CONTENT	6\tagSEC_CONTENT	days\tagSEC_CONTENT	for\tagSEC_CONTENT	5\tagSEC_CONTENT	agents\tagSEC_CONTENT	since\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	more\tagSEC_CONTENT	encoder\tagSEC_CONTENT	parameters\tagSEC_CONTENT	to\tagSEC_CONTENT	tune\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	avoid\tagSEC_CONTENT	repetition\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	prevent\tagSEC_CONTENT	the\tagSEC_CONTENT	decoder\tagSEC_CONTENT	from\tagSEC_CONTENT	generating\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	trigram\tagSEC_CONTENT	more\tagSEC_CONTENT	than\tagSEC_CONTENT	once\tagSEC_CONTENT	during\tagSEC_CONTENT	test\tagSEC_CONTENT	,\tagSEC_CONTENT	following\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	addition\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	every\tagSEC_CONTENT	predicted\tagSEC_CONTENT	out\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	token\tagSEC_CONTENT	(\tagSEC_CONTENT	UNK\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	replace\tagSEC_CONTENT	it\tagSEC_CONTENT	with\tagSEC_CONTENT	its\tagSEC_CONTENT	most\tagSEC_CONTENT	likely\tagSEC_CONTENT	origin\tagSEC_CONTENT	by\tagSEC_CONTENT	choosing\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	word\tagSEC_CONTENT	w\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	largest\tagSEC_CONTENT	cascaded\tagSEC_CONTENT	attention\tagSEC_CONTENT	w\tagSEC_CONTENT	:\tagSEC_CONTENT	=\tagSEC_CONTENT	arg\tagSEC_CONTENT	max\tagSEC_CONTENT	,\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	B\tagSECTITLE_START	Generated\tagSECTITLE_CONTENT	Summary\tagSECTITLE_CONTENT	Examples\tagSECTITLE_END	This\tagSEC_START	appendix\tagSEC_CONTENT	provides\tagSEC_CONTENT	example\tagSEC_CONTENT	documents\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	side\tagSEC_CONTENT	-\tagSEC_CONTENT	by\tagSEC_CONTENT	-\tagSEC_CONTENT	side\tagSEC_CONTENT	comparisons\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	generated\tagSEC_CONTENT	(\tagSEC_CONTENT	golden\tagSEC_CONTENT	)\tagSEC_CONTENT	summaries\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagtask	summaries\tagtask	produced\tagSEC_CONTENT	by\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Baseline\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	trained\tagSEC_CONTENT	with\tagSEC_CONTENT	MLE+RL\tagSEC_CONTENT	loss\tagSEC_CONTENT	,\tagSEC_CONTENT	(\tagSEC_CONTENT	m3\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	our\tagSEC_CONTENT	best\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	optimized\tagSEC_CONTENT	by\tagSEC_CONTENT	mixed\tagSEC_CONTENT	MLE+SEM+RL\tagSEC_CONTENT	loss\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	(\tagSEC_CONTENT	m7\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	red\tagSEC_CONTENT	highlights\tagSEC_CONTENT	:\tagSEC_CONTENT	indicate\tagSEC_CONTENT	details\tagSEC_CONTENT	that\tagSEC_CONTENT	should\tagSEC_CONTENT	not\tagSEC_CONTENT	appear\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	but\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	generated\tagSEC_CONTENT	them\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	red\tagSEC_CONTENT	:\tagSEC_CONTENT	indicates\tagSEC_CONTENT	factual\tagSEC_CONTENT	errors\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	green\tagSEC_CONTENT	highlights\tagSEC_CONTENT	:\tagSEC_CONTENT	indicate\tagSEC_CONTENT	key\tagSEC_CONTENT	facts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	human\tagSEC_CONTENT	(\tagSEC_CONTENT	gold\tagSEC_CONTENT	)\tagSEC_CONTENT	summary\tagSEC_CONTENT	that\tagSEC_CONTENT	only\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	manage\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	.\tagSEC_END	Document\tagSEC_START	model\tagSEC_CONTENT	abbey\tagSEC_CONTENT	clancy\tagSEC_CONTENT	is\tagSEC_CONTENT	helping\tagSEC_CONTENT	to\tagSEC_CONTENT	target\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	striking\tagSEC_CONTENT	a\tagSEC_CONTENT	sultry\tagSEC_CONTENT	pose\tagSEC_CONTENT	in\tagSEC_CONTENT	anew\tagSEC_CONTENT	charity\tagSEC_CONTENT	campaign\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	winner\tagSEC_CONTENT	of\tagSEC_CONTENT	2013\tagSEC_CONTENT	's\tagSEC_CONTENT	strictly\tagSEC_CONTENT	come\tagSEC_CONTENT	dancing\tagSEC_CONTENT	joins\tagSEC_CONTENT	singer\tagSEC_CONTENT	foxes\tagSEC_CONTENT	,\tagSEC_CONTENT	25\tagSEC_CONTENT	,\tagSEC_CONTENT	victoria\tagSEC_CONTENT	's\tagSEC_CONTENT	secret\tagSEC_CONTENT	angel\tagSEC_CONTENT	lily\tagSEC_CONTENT	donaldson\tagSEC_CONTENT	,\tagSEC_CONTENT	28\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	model\tagSEC_CONTENT	alice\tagSEC_CONTENT	dellal\tagSEC_CONTENT	,\tagSEC_CONTENT	27\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	new\tagSEC_CONTENT	series\tagSEC_CONTENT	of\tagSEC_CONTENT	pictures\tagSEC_CONTENT	by\tagSEC_CONTENT	photographer\tagSEC_CONTENT	simon\tagSEC_CONTENT	emmett\tagSEC_CONTENT	for\tagSEC_CONTENT	fashion\tagSEC_CONTENT	targets\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	.\tagSEC_CONTENT	clancy\tagSEC_CONTENT	,\tagSEC_CONTENT	29\tagSEC_CONTENT	,\tagSEC_CONTENT	looks\tagSEC_CONTENT	chic\tagSEC_CONTENT	as\tagSEC_CONTENT	she\tagSEC_CONTENT	shows\tagSEC_CONTENT	off\tagSEC_CONTENT	her\tagSEC_CONTENT	famous\tagSEC_CONTENT	legs\tagSEC_CONTENT	,\tagSEC_CONTENT	wearing\tagSEC_CONTENT	just\tagSEC_CONTENT	a\tagSEC_CONTENT	plain\tagSEC_CONTENT	white\tagSEC_CONTENT	shirt\tagSEC_CONTENT	.\tagSEC_CONTENT	abbey\tagSEC_CONTENT	clancy\tagSEC_CONTENT	leads\tagSEC_CONTENT	the\tagSEC_CONTENT	glamour\tagSEC_CONTENT	as\tagSEC_CONTENT	she\tagSEC_CONTENT	joins\tagSEC_CONTENT	forces\tagSEC_CONTENT	with\tagSEC_CONTENT	her\tagSEC_CONTENT	famous\tagSEC_CONTENT	friends\tagSEC_CONTENT	to\tagSEC_CONTENT	target\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	striking\tagSEC_CONTENT	a\tagSEC_CONTENT	sultry\tagSEC_CONTENT	pose\tagSEC_CONTENT	in\tagSEC_CONTENT	anew\tagSEC_CONTENT	charity\tagSEC_CONTENT	campaign\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	is\tagSEC_CONTENT	mother\tagmetric	to\tagSEC_CONTENT	four\tagSEC_CONTENT	-year\tagSEC_CONTENT	-old\tagSEC_CONTENT	daughter\tagSEC_CONTENT	sophia\tagSEC_CONTENT	with\tagSEC_CONTENT	footballer\tagSEC_CONTENT	husband\tagSEC_CONTENT	peter\tagSEC_CONTENT	crouch\tagSEC_CONTENT	,\tagSEC_CONTENT	said\tagSEC_CONTENT	:\tagSEC_CONTENT	'\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	mum\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	makes\tagSEC_CONTENT	me\tagSEC_CONTENT	proud\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	campaign\tagSEC_CONTENT	that\tagSEC_CONTENT	funds\tagSEC_CONTENT	vital\tagSEC_CONTENT	work\tagSEC_CONTENT	towards\tagSEC_CONTENT	ensuring\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	generation\tagSEC_CONTENT	of\tagSEC_CONTENT	young\tagSEC_CONTENT	women\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	have\tagSEC_CONTENT	be\tagSEC_CONTENT	afraid\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	diagnosis\tagSEC_CONTENT	of\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	i\tagSEC_CONTENT	'm\tagSEC_CONTENT	wearing\tagSEC_CONTENT	my\tagSEC_CONTENT	support\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	i\tagSEC_CONTENT	want\tagSEC_CONTENT	everyone\tagSEC_CONTENT	across\tagSEC_CONTENT	the\tagSEC_CONTENT	uk\tagSEC_CONTENT	to\tagSEC_CONTENT	do\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	and\tagSEC_CONTENT	get\tagSEC_CONTENT	behind\tagSEC_CONTENT	this\tagSEC_CONTENT	campaign\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	holding\tagSEC_CONTENT	onto\tagSEC_CONTENT	heaven\tagSEC_CONTENT	singer\tagSEC_CONTENT	foxes\tagSEC_CONTENT	looks\tagSEC_CONTENT	foxy\tagSEC_CONTENT	in\tagSEC_CONTENT	cropped\tagSEC_CONTENT	stripy\tagSEC_CONTENT	top\tagSEC_CONTENT	and\tagSEC_CONTENT	jeans\tagSEC_CONTENT	.\tagSEC_CONTENT	abbey\tagSEC_CONTENT	says\tagSEC_CONTENT	she\tagSEC_CONTENT	is\tagSEC_CONTENT	proud\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	campaign\tagSEC_CONTENT	that\tagSEC_CONTENT	funds\tagSEC_CONTENT	vital\tagSEC_CONTENT	work\tagSEC_CONTENT	towards\tagSEC_CONTENT	ensuring\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	generation\tagSEC_CONTENT	of\tagSEC_CONTENT	young\tagSEC_CONTENT	women\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	have\tagSEC_CONTENT	be\tagSEC_CONTENT	afraid\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	diagnosis\tagSEC_CONTENT	of\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	victoria\tagSEC_CONTENT	's\tagSEC_CONTENT	secret\tagSEC_CONTENT	angel\tagSEC_CONTENT	lily\tagSEC_CONTENT	donaldson\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	industry\tagSEC_CONTENT	for\tagSEC_CONTENT	years\tagSEC_CONTENT	,\tagSEC_CONTENT	also\tagSEC_CONTENT	adds\tagSEC_CONTENT	some\tagSEC_CONTENT	glamour\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	charity\tagSEC_CONTENT	campaign\tagSEC_CONTENT	holding\tagSEC_CONTENT	onto\tagSEC_CONTENT	heaven\tagSEC_CONTENT	singer\tagSEC_CONTENT	foxes\tagSEC_CONTENT	dons\tagSEC_CONTENT	a\tagSEC_CONTENT	stripy\tagSEC_CONTENT	top\tagSEC_CONTENT	and\tagSEC_CONTENT	jeans\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	campaign\tagSEC_CONTENT	she\tagSEC_CONTENT	says\tagSEC_CONTENT	she\tagSEC_CONTENT	's\tagSEC_CONTENT	'\tagSEC_CONTENT	honoured\tagSEC_CONTENT	'\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	apart\tagSEC_CONTENT	of\tagSEC_CONTENT	she\tagSEC_CONTENT	said\tagSEC_CONTENT	:\tagSEC_CONTENT	'\tagSEC_CONTENT	i\tagSEC_CONTENT	'm\tagSEC_CONTENT	so\tagSEC_CONTENT	honoured\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	taking\tagSEC_CONTENT	part\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	year\tagSEC_CONTENT	's\tagSEC_CONTENT	fashion\tagSEC_CONTENT	targets\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	becoming\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	campaign\tagSEC_CONTENT	's\tagSEC_CONTENT	awesome\tagSEC_CONTENT	heritage\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	fashion\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	huge\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	my\tagSEC_CONTENT	life\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	if\tagSEC_CONTENT	by\tagSEC_CONTENT	taking\tagSEC_CONTENT	part\tagSEC_CONTENT	i\tagSEC_CONTENT	can\tagSEC_CONTENT	inspire\tagSEC_CONTENT	women\tagSEC_CONTENT	to\tagSEC_CONTENT	wear\tagSEC_CONTENT	their\tagSEC_CONTENT	support\tagSEC_CONTENT	,\tagSEC_CONTENT	join\tagSEC_CONTENT	the\tagSEC_CONTENT	fight\tagSEC_CONTENT	and\tagSEC_CONTENT	take\tagSEC_CONTENT	on\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	head\tagSEC_CONTENT	on\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	that\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	something\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	really\tagSEC_CONTENT	proud\tagSEC_CONTENT	of\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	now\tagSEC_CONTENT	in\tagSEC_CONTENT	its\tagSEC_CONTENT	19th\tagSEC_CONTENT	year\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	campaign\tagSEC_CONTENT	has\tagSEC_CONTENT	so\tagSEC_CONTENT	far\tagSEC_CONTENT	raised\tagSEC_CONTENT	13\tagSEC_CONTENT	.\tagSEC_CONTENT	5\tagSEC_CONTENT	m\tagSEC_CONTENT	for\tagSEC_CONTENT	breakthrough\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	's\tagSEC_CONTENT	research\tagSEC_CONTENT	funding\tagSEC_CONTENT	.\tagSEC_CONTENT	this\tagSEC_CONTENT	year\tagSEC_CONTENT	the\tagSEC_CONTENT	range\tagSEC_CONTENT	of\tagSEC_CONTENT	clothes\tagSEC_CONTENT	and\tagSEC_CONTENT	accessories\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	produced\tagSEC_CONTENT	in\tagSEC_CONTENT	conjunction\tagSEC_CONTENT	with\tagSEC_CONTENT	high\tagSEC_CONTENT	street\tagSEC_CONTENT	partners\tagSEC_CONTENT	m&s\tagSEC_CONTENT	,\tagSEC_CONTENT	river\tagSEC_CONTENT	island\tagSEC_CONTENT	,\tagSEC_CONTENT	warehouse\tagSEC_CONTENT	,\tagSEC_CONTENT	topshop\tagSEC_CONTENT	,\tagSEC_CONTENT	laura\tagSEC_CONTENT	ashley\tagSEC_CONTENT	,\tagSEC_CONTENT	debenhams\tagSEC_CONTENT	,\tagSEC_CONTENT	superga\tagSEC_CONTENT	,\tagSEC_CONTENT	baukjen\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	cambridge\tagSEC_CONTENT	satchel\tagSEC_CONTENT	company\tagSEC_CONTENT	.\tagSEC_CONTENT	they\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	viewed\tagSEC_CONTENT	online\tagSEC_CONTENT	at\tagSEC_CONTENT	www\tagSEC_CONTENT	.\tagSEC_CONTENT	fashiontargetsbreastcancer\tagSEC_CONTENT	.\tagSEC_CONTENT	org\tagSEC_CONTENT	.\tagSEC_CONTENT	uk\tagSEC_CONTENT	/\tagSEC_CONTENT	lookbook\tagSEC_CONTENT	the\tagSEC_CONTENT	campaign\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	also\tagSEC_CONTENT	stars\tagSEC_CONTENT	alice\tagSEC_CONTENT	dellal\tagSEC_CONTENT	,\tagSEC_CONTENT	has\tagSEC_CONTENT	so\tagSEC_CONTENT	far\tagSEC_CONTENT	raised\tagSEC_CONTENT	13\tagSEC_CONTENT	.\tagSEC_CONTENT	5\tagSEC_CONTENT	m\tagSEC_CONTENT	for\tagSEC_CONTENT	breakthrough\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	's\tagSEC_CONTENT	research\tagSEC_CONTENT	funding\tagSEC_CONTENT	Human\tagSEC_CONTENT	(\tagSEC_CONTENT	Gold\tagSEC_CONTENT	)\tagSEC_CONTENT	models\tagSEC_CONTENT	abbey\tagSEC_CONTENT	and\tagSEC_CONTENT	lily\tagSEC_CONTENT	are\tagSEC_CONTENT	joined\tagSEC_CONTENT	by\tagSEC_CONTENT	alice\tagSEC_CONTENT	dellal\tagSEC_CONTENT	and\tagSEC_CONTENT	singer\tagSEC_CONTENT	foxes\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	women\tagSEC_CONTENT	are\tagSEC_CONTENT	pictured\tagSEC_CONTENT	'\tagSEC_CONTENT	wearing\tagSEC_CONTENT	'\tagSEC_CONTENT	their\tagSEC_CONTENT	support\tagSEC_CONTENT	.\tagSEC_CONTENT	abbey\tagSEC_CONTENT	,\tagSEC_CONTENT	29\tagSEC_CONTENT	,\tagSEC_CONTENT	says\tagSEC_CONTENT	she\tagSEC_CONTENT	is\tagSEC_CONTENT	proud\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	campaign\tagSEC_CONTENT	that\tagSEC_CONTENT	funds\tagSEC_CONTENT	vital\tagSEC_CONTENT	work\tagSEC_CONTENT	.\tagSEC_CONTENT	campaign\tagSEC_CONTENT	has\tagSEC_CONTENT	raised\tagSEC_CONTENT	13\tagSEC_CONTENT	.\tagSEC_CONTENT	5\tagSEC_CONTENT	m\tagSEC_CONTENT	for\tagSEC_CONTENT	breakthrough\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	's\tagSEC_CONTENT	research\tagSEC_CONTENT	.\tagSEC_END	Single\tagSEC_START	Agent\tagSEC_CONTENT	Baseline\tagSEC_CONTENT	strictly\tagSEC_CONTENT	come\tagSEC_CONTENT	dancing\tagSEC_CONTENT	joins\tagSEC_CONTENT	singer\tagSEC_CONTENT	foxes\tagSEC_CONTENT	,\tagSEC_CONTENT	25\tagSEC_CONTENT	,\tagSEC_CONTENT	victoria\tagSEC_CONTENT	's\tagSEC_CONTENT	secret\tagSEC_CONTENT	angel\tagSEC_CONTENT	lily\tagSEC_CONTENT	donaldson\tagSEC_CONTENT	,\tagSEC_CONTENT	28\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	model\tagSEC_CONTENT	alice\tagSEC_CONTENT	dellal\tagSEC_CONTENT	,\tagSEC_CONTENT	27\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	new\tagSEC_CONTENT	series\tagSEC_CONTENT	of\tagSEC_CONTENT	pictures\tagSEC_CONTENT	by\tagSEC_CONTENT	photographer\tagSEC_CONTENT	simon\tagSEC_CONTENT	emmett\tagSEC_CONTENT	for\tagSEC_CONTENT	fashion\tagSEC_CONTENT	targets\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	.\tagSEC_CONTENT	clancy\tagSEC_CONTENT	,\tagSEC_CONTENT	29\tagSEC_CONTENT	,\tagSEC_CONTENT	looks\tagSEC_CONTENT	chic\tagSEC_CONTENT	as\tagSEC_CONTENT	she\tagSEC_CONTENT	shows\tagSEC_CONTENT	off\tagSEC_CONTENT	her\tagSEC_CONTENT	famous\tagSEC_CONTENT	legs\tagSEC_CONTENT	,\tagSEC_CONTENT	wearing\tagSEC_CONTENT	just\tagSEC_CONTENT	a\tagSEC_CONTENT	plain\tagSEC_CONTENT	white\tagSEC_CONTENT	shirt\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_START	Agent\tagSECTITLE_END	abbey\tagSEC_START	says\tagSEC_CONTENT	she\tagSEC_CONTENT	is\tagSEC_CONTENT	proud\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	campaign\tagSEC_CONTENT	that\tagSEC_CONTENT	funds\tagSEC_CONTENT	vital\tagSEC_CONTENT	work\tagSEC_CONTENT	towards\tagSEC_CONTENT	ensuring\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	generation\tagSEC_CONTENT	of\tagSEC_CONTENT	young\tagSEC_CONTENT	women\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	afraid\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	diagnosis\tagSEC_CONTENT	of\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	campaign\tagSEC_CONTENT	has\tagSEC_CONTENT	raised\tagSEC_CONTENT	13\tagSEC_CONTENT	.\tagSEC_CONTENT	5\tagSEC_CONTENT	m\tagSEC_CONTENT	for\tagSEC_CONTENT	breakthrough\tagSEC_CONTENT	breast\tagSEC_CONTENT	cancer\tagSEC_CONTENT	's\tagSEC_CONTENT	research\tagSEC_CONTENT	.\tagSEC_CONTENT	:\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	example\tagSEC_CONTENT	both\tagSEC_CONTENT	single\tagSEC_CONTENT	-\tagSEC_CONTENT	and\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	models\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	extractive\tagSEC_CONTENT	behaviors\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	select\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	different\tagSEC_CONTENT	sections\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	model\tagSEC_CONTENT	extracts\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	third\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	successfully\tagSEC_CONTENT	selects\tagSEC_CONTENT	salient\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	sentences\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	further\tagSEC_CONTENT	down\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	,\tagSEC_CONTENT	specifically\tagSEC_CONTENT	sentence\tagSEC_CONTENT	8\tagSEC_CONTENT	and\tagSEC_CONTENT	10\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	attributed\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	that\tagSEC_CONTENT	agents\tagSEC_CONTENT	can\tagSEC_CONTENT	successfully\tagSEC_CONTENT	encode\tagSEC_CONTENT	salient\tagSEC_CONTENT	aspects\tagSEC_CONTENT	distributed\tagSEC_CONTENT	in\tagSEC_CONTENT	distant\tagSEC_CONTENT	sections\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_CONTENT	An\tagSEC_CONTENT	interesting\tagSEC_CONTENT	result\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	even\tagSEC_CONTENT	though\tagSEC_CONTENT	the\tagSEC_CONTENT	multiagent\tagSEC_CONTENT	model\tagSEC_CONTENT	shows\tagSEC_CONTENT	extractive\tagSEC_CONTENT	behaviour\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	successfully\tagSEC_CONTENT	selects\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	salient\tagSEC_CONTENT	sentences\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	includes\tagSEC_CONTENT	superfluous\tagSEC_CONTENT	details\tagSEC_CONTENT	.\tagSEC_CONTENT	Document\tagSEC_CONTENT	michelle\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	latest\tagSEC_CONTENT	hollywood\tagSEC_CONTENT	star\tagSEC_CONTENT	preparing\tagSEC_CONTENT	to\tagSEC_CONTENT	hit\tagSEC_CONTENT	the\tagSEC_CONTENT	small\tagSEC_CONTENT	screen\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	oscar\tagSEC_CONTENT	nominated\tagSEC_CONTENT	star\tagSEC_CONTENT	known\tagSEC_CONTENT	for\tagSEC_CONTENT	her\tagSEC_CONTENT	roles\tagSEC_CONTENT	in\tagSEC_CONTENT	iconic\tagSEC_CONTENT	films\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	scarface\tagSEC_CONTENT	,\tagSEC_CONTENT	dangerous\tagSEC_CONTENT	liaisons\tagSEC_CONTENT	andthe\tagSEC_CONTENT	age\tagSEC_CONTENT	of\tagSEC_CONTENT	innocence\tagSEC_CONTENT	,\tagSEC_CONTENT	has\tagSEC_CONTENT	teamed\tagSEC_CONTENT	up\tagSEC_CONTENT	with\tagSEC_CONTENT	katie\tagSEC_CONTENT	couric\tagSEC_CONTENT	to\tagSEC_CONTENT	pitch\tagSEC_CONTENT	anew\tagSEC_CONTENT	television\tagSEC_CONTENT	comedy\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	morning\tagSEC_CONTENT	news\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_CONTENT	also\tagSEC_CONTENT	involved\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	is\tagSEC_CONTENT	attached\tagSEC_CONTENT	to\tagSEC_CONTENT	star\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	diane\tagSEC_CONTENT	english\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	creator\tagSEC_CONTENT	of\tagSEC_CONTENT	murphy\tagSEC_CONTENT	brown\tagSEC_CONTENT	.\tagSEC_CONTENT	scroll\tagSEC_CONTENT	down\tagSEC_CONTENT	for\tagSEC_CONTENT	video\tagSEC_CONTENT	michelle\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	(\tagSEC_CONTENT	left\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	star\tagSEC_CONTENT	in\tagSEC_CONTENT	anew\tagSEC_CONTENT	television\tagSEC_CONTENT	comedy\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	morning\tagSEC_CONTENT	news\tagSEC_CONTENT	program\tagSEC_CONTENT	produced\tagSEC_CONTENT	by\tagSEC_CONTENT	katie\tagSEC_CONTENT	couric\tagSEC_CONTENT	(\tagSEC_CONTENT	right\tagSEC_CONTENT	)\tagSEC_CONTENT	the\tagSEC_CONTENT	series\tagSEC_CONTENT	was\tagSEC_CONTENT	created\tagSEC_CONTENT	by\tagSEC_CONTENT	diane\tagSEC_CONTENT	english\tagSEC_CONTENT	(\tagSEC_CONTENT	above\tagSEC_CONTENT	with\tagSEC_CONTENT	candice\tagSEC_CONTENT	bergen\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	was\tagSEC_CONTENT	behind\tagSEC_CONTENT	the\tagSEC_CONTENT	show\tagSEC_CONTENT	murphy\tagSEC_CONTENT	brown\tagSEC_CONTENT	,\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	female\tagSEC_CONTENT	news\tagSEC_CONTENT	anchor\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	variety\tagSEC_CONTENT	,\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	's\tagSEC_CONTENT	role\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	that\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	morning\tagSEC_CONTENT	news\tagSEC_CONTENT	anchor\tagSEC_CONTENT	,\tagSEC_CONTENT	making\tagSEC_CONTENT	it\tagSEC_CONTENT	very\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	life\tagSEC_CONTENT	role\tagSEC_CONTENT	couric\tagSEC_CONTENT	played\tagSEC_CONTENT	as\tagSEC_CONTENT	co\tagSEC_CONTENT	-host\tagSEC_CONTENT	of\tagSEC_CONTENT	today\tagSEC_CONTENT	for\tagSEC_CONTENT	15\tagSEC_CONTENT	years\tagSEC_CONTENT	.\tagSEC_CONTENT	couric\tagSEC_CONTENT	will\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	executive\tagSEC_CONTENT	producer\tagSEC_CONTENT	and\tagSEC_CONTENT	help\tagSEC_CONTENT	'\tagSEC_CONTENT	ensure\tagSEC_CONTENT	the\tagSEC_CONTENT	series\tagSEC_CONTENT	strikes\tagSEC_CONTENT	realistic\tagSEC_CONTENT	notes\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	the\tagSEC_CONTENT	creator\tagSEC_CONTENT	behind\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	,\tagSEC_CONTENT	english\tagSEC_CONTENT	,\tagSEC_CONTENT	was\tagSEC_CONTENT	previously\tagSEC_CONTENT	the\tagSEC_CONTENT	brains\tagSEC_CONTENT	behind\tagSEC_CONTENT	brown\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	show\tagSEC_CONTENT	starring\tagSEC_CONTENT	candice\tagSEC_CONTENT	bergen\tagSEC_CONTENT	that\tagSEC_CONTENT	centered\tagSEC_CONTENT	around\tagSEC_CONTENT	a\tagSEC_CONTENT	female\tagSEC_CONTENT	news\tagSEC_CONTENT	anchor\tagSEC_CONTENT	and\tagSEC_CONTENT	ran\tagSEC_CONTENT	for\tagSEC_CONTENT	ten\tagSEC_CONTENT	seasons\tagSEC_CONTENT	,\tagSEC_CONTENT	winning\tagSEC_CONTENT	18\tagSEC_CONTENT	emmys\tagSEC_CONTENT	.\tagSEC_CONTENT	english\tagSEC_CONTENT	would\tagSEC_CONTENT	also\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	writer\tagSEC_CONTENT	,\tagSEC_CONTENT	producer\tagmetric	and\tagSEC_CONTENT	showrunner\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	ladies\tagSEC_CONTENT	are\tagSEC_CONTENT	currently\tagSEC_CONTENT	in\tagSEC_CONTENT	talks\tagSEC_CONTENT	with\tagSEC_CONTENT	hbo\tagSEC_CONTENT	,\tagSEC_CONTENT	showtime\tagSEC_CONTENT	,\tagSEC_CONTENT	amc\tagSEC_CONTENT	,\tagSEC_CONTENT	netflix\tagSEC_CONTENT	and\tagSEC_CONTENT	amazon\tagSEC_CONTENT	to\tagSEC_CONTENT	pickup\tagSEC_CONTENT	the\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_CONTENT	couric\tagSEC_CONTENT	will\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	executive\tagSEC_CONTENT	producer\tagSEC_CONTENT	,\tagSEC_CONTENT	drawing\tagSEC_CONTENT	on\tagSEC_CONTENT	her\tagSEC_CONTENT	experience\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	anchor\tagSEC_CONTENT	on\tagSEC_CONTENT	today\tagSEC_CONTENT	for\tagSEC_CONTENT	15\tagSEC_CONTENT	years\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	would\tagSEC_CONTENT	be\tagSEC_CONTENT	the\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	biggest\tagSEC_CONTENT	stars\tagSEC_CONTENT	yet\tagSEC_CONTENT	to\tagSEC_CONTENT	move\tagSEC_CONTENT	to\tagSEC_CONTENT	television\tagSEC_CONTENT	,\tagSEC_CONTENT	joining\tagSEC_CONTENT	a\tagSEC_CONTENT	group\tagSEC_CONTENT	that\tagSEC_CONTENT	now\tagSEC_CONTENT	includes\tagSEC_CONTENT	house\tagSEC_CONTENT	of\tagSEC_CONTENT	cards\tagSEC_CONTENT	stars\tagSEC_CONTENT	robin\tagSEC_CONTENT	wright\tagSEC_CONTENT	and\tagSEC_CONTENT	kevin\tagSEC_CONTENT	spacey\tagSEC_CONTENT	,\tagSEC_CONTENT	true\tagSEC_CONTENT	detective\tagSEC_CONTENT	leads\tagSEC_CONTENT	matthew\tagSEC_CONTENT	mcconaughey\tagSEC_CONTENT	and\tagSEC_CONTENT	woody\tagSEC_CONTENT	harrelson\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	even\tagSEC_CONTENT	lady\tagSEC_CONTENT	gaga\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	recently\tagSEC_CONTENT	announced\tagSEC_CONTENT	she\tagSEC_CONTENT	would\tagSEC_CONTENT	be\tagSEC_CONTENT	appearing\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	season\tagSEC_CONTENT	of\tagSEC_CONTENT	american\tagSEC_CONTENT	horror\tagSEC_CONTENT	story\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	actress\tagSEC_CONTENT	has\tagSEC_CONTENT	kept\tagSEC_CONTENT	a\tagSEC_CONTENT	low\tagSEC_CONTENT	profile\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	past\tagSEC_CONTENT	20\tagSEC_CONTENT	years\tagSEC_CONTENT	since\tagSEC_CONTENT	becoming\tagSEC_CONTENT	a\tagSEC_CONTENT	mother\tagSEC_CONTENT	,\tagSEC_CONTENT	only\tagSEC_CONTENT	doing\tagSEC_CONTENT	a\tagSEC_CONTENT	handful\tagSEC_CONTENT	of\tagSEC_CONTENT	films\tagSEC_CONTENT	in\tagSEC_CONTENT	that\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	she\tagSEC_CONTENT	most\tagSEC_CONTENT	recently\tagSEC_CONTENT	appeared\tagSEC_CONTENT	alongside\tagSEC_CONTENT	robert\tagSEC_CONTENT	de\tagSEC_CONTENT	niro\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	mob\tagSEC_CONTENT	comedy\tagSEC_CONTENT	'\tagSEC_CONTENT	the\tagSEC_CONTENT	family\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_END	michelle\tagSEC_START	pfeiffer\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	star\tagSEC_CONTENT	in\tagSEC_CONTENT	anew\tagSEC_CONTENT	television\tagSEC_CONTENT	comedy\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	morning\tagSEC_CONTENT	news\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_CONTENT	katie\tagSEC_CONTENT	couric\tagSEC_CONTENT	will\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	executive\tagSEC_CONTENT	producer\tagSEC_CONTENT	,\tagSEC_CONTENT	drawing\tagSEC_CONTENT	on\tagSEC_CONTENT	her\tagSEC_CONTENT	experience\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	anchor\tagSEC_CONTENT	on\tagSEC_CONTENT	today\tagSEC_CONTENT	for\tagSEC_CONTENT	15\tagSEC_CONTENT	years\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	series\tagSEC_CONTENT	was\tagSEC_CONTENT	created\tagSEC_CONTENT	by\tagSEC_CONTENT	diane\tagSEC_CONTENT	english\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	was\tagSEC_CONTENT	behind\tagSEC_CONTENT	the\tagSEC_CONTENT	show\tagSEC_CONTENT	murphy\tagSEC_CONTENT	brown\tagSEC_CONTENT	,\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	female\tagSEC_CONTENT	news\tagSEC_CONTENT	anchor\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	ladies\tagSEC_CONTENT	are\tagSEC_CONTENT	currently\tagSEC_CONTENT	in\tagSEC_CONTENT	talks\tagSEC_CONTENT	with\tagSEC_CONTENT	hbo\tagSEC_CONTENT	,\tagSEC_CONTENT	showtime\tagSEC_CONTENT	,\tagSEC_CONTENT	amc\tagSEC_CONTENT	,\tagSEC_CONTENT	netflix\tagSEC_CONTENT	and\tagSEC_CONTENT	amazon\tagtask	to\tagSEC_CONTENT	pickup\tagSEC_CONTENT	the\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_END	Single\tagSEC_START	Agent\tagSEC_CONTENT	Baseline\tagSEC_CONTENT	the\tagSEC_CONTENT	oscar\tagSEC_CONTENT	nominated\tagSEC_CONTENT	star\tagSEC_CONTENT	known\tagSEC_CONTENT	for\tagSEC_CONTENT	her\tagSEC_CONTENT	roles\tagSEC_CONTENT	in\tagSEC_CONTENT	iconic\tagSEC_CONTENT	filmssuch\tagSEC_CONTENT	as\tagSEC_CONTENT	scarface\tagSEC_CONTENT	,\tagSEC_CONTENT	dangerous\tagSEC_CONTENT	liaisons\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	age\tagSEC_CONTENT	of\tagSEC_CONTENT	innocence\tagSEC_CONTENT	,\tagSEC_CONTENT	has\tagSEC_CONTENT	teamed\tagSEC_CONTENT	up\tagSEC_CONTENT	with\tagSEC_CONTENT	katie\tagSEC_CONTENT	couric\tagSEC_CONTENT	to\tagSEC_CONTENT	pitch\tagSEC_CONTENT	anew\tagSEC_CONTENT	television\tagSEC_CONTENT	comedy\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	morning\tagSEC_CONTENT	news\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_CONTENT	also\tagSEC_CONTENT	involved\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	is\tagSEC_CONTENT	attached\tagSEC_CONTENT	to\tagSEC_CONTENT	star\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	diane\tagSEC_CONTENT	english\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	creator\tagSEC_CONTENT	of\tagSEC_CONTENT	murphy\tagSEC_CONTENT	brown\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_START	Agent\tagSECTITLE_END	michelle\tagSEC_START	pfeiffer\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	star\tagSEC_CONTENT	in\tagSEC_CONTENT	anew\tagSEC_CONTENT	tv\tagSEC_CONTENT	comedy\tagSEC_CONTENT	about\tagSEC_CONTENT	a\tagSEC_CONTENT	morning\tagSEC_CONTENT	news\tagSEC_CONTENT	program\tagSEC_CONTENT	.\tagSEC_CONTENT	couric\tagSEC_CONTENT	will\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	executive\tagSEC_CONTENT	producer\tagSEC_CONTENT	and\tagSEC_CONTENT	showrunner\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	series\tagSEC_CONTENT	was\tagSEC_CONTENT	created\tagSEC_CONTENT	by\tagSEC_CONTENT	diane\tagSEC_CONTENT	english\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	creator\tagSEC_CONTENT	of\tagSEC_CONTENT	murphy\tagSEC_CONTENT	brown\tagSEC_CONTENT	.\tagSEC_CONTENT	pfeiffer\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	biggest\tagSEC_CONTENT	stars\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	generates\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	coherent\tagSEC_CONTENT	summary\tagSEC_CONTENT	that\tagSEC_CONTENT	references\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	character\tagSEC_CONTENT	"\tagSEC_CONTENT	Michelle\tagSEC_CONTENT	Pfeiffer\tagSEC_CONTENT	"\tagSEC_CONTENT	in\tagSEC_CONTENT	an\tagSEC_CONTENT	ambiguous\tagSEC_CONTENT	way\tagSEC_CONTENT	towards\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	summary\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	contrast\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	successfully\tagSEC_CONTENT	captures\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	character\tagSEC_CONTENT	including\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	facts\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	interesting\tagSEC_CONTENT	feature\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	showcases\tagSEC_CONTENT	is\tagSEC_CONTENT	its\tagSEC_CONTENT	simplification\tagSEC_CONTENT	property\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	accounts\tagSEC_CONTENT	for\tagSEC_CONTENT	its\tagSEC_CONTENT	strength\tagSEC_CONTENT	in\tagSEC_CONTENT	abstraction\tagtask	.\tagSEC_CONTENT	Specifically\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	simplified\tagSEC_CONTENT	the\tagSEC_CONTENT	bold\tagSEC_CONTENT	long\tagSEC_CONTENT	sentence\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	starting\tagSEC_CONTENT	with\tagSEC_CONTENT	"\tagSEC_CONTENT	couric\tagSEC_CONTENT	will\tagSEC_CONTENT	...\tagSEC_CONTENT	and\tagSEC_CONTENT	only\tagSEC_CONTENT	generated\tagSEC_CONTENT	the\tagSEC_CONTENT	salient\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_END	Document\tagSEC_START	everton\tagSEC_CONTENT	manager\tagSEC_CONTENT	roberto\tagSEC_CONTENT	martinez\tagSEC_CONTENT	was\tagSEC_CONTENT	forced\tagSEC_CONTENT	to\tagSEC_CONTENT	defend\tagSEC_CONTENT	another\tagSEC_CONTENT	penalty\tagSEC_CONTENT	fiasco\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	club\tagSEC_CONTENT	after\tagSEC_CONTENT	ross\tagSEC_CONTENT	barkley\tagSEC_CONTENT	missed\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	spot\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	1\tagSEC_CONTENT	-0\tagSEC_CONTENT	win\tagSEC_CONTENT	against\tagSEC_CONTENT	burnley\tagSEC_CONTENT	at\tagSEC_CONTENT	goodison\tagSEC_CONTENT	park\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	untried\tagSEC_CONTENT	barkley\tagSEC_CONTENT	inexplicably\tagSEC_CONTENT	took\tagSEC_CONTENT	the\tagSEC_CONTENT	10th\tagSEC_CONTENT	minute\tagSEC_CONTENT	kick\tagSEC_CONTENT	awarded\tagSEC_CONTENT	fora\tagSEC_CONTENT	foul\tagSEC_CONTENT	by\tagSEC_CONTENT	david\tagSEC_CONTENT	jones\tagSEC_CONTENT	on\tagSEC_CONTENT	aaron\tagSEC_CONTENT	lennon\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	leighton\tagSEC_CONTENT	baines\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	has\tagSEC_CONTENT	scored\tagSEC_CONTENT	15\tagSEC_CONTENT	penalties\tagSEC_CONTENT	from\tagSEC_CONTENT	16\tagSEC_CONTENT	attempts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	.\tagSEC_CONTENT	although\tagSEC_CONTENT	there\tagSEC_CONTENT	was\tagSEC_CONTENT	no\tagSEC_CONTENT	dispute\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	team\tagSEC_CONTENT	-mates\tagSEC_CONTENT	this\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	brought\tagSEC_CONTENT	back\tagSEC_CONTENT	memories\tagmetric	of\tagSEC_CONTENT	everton\tagSEC_CONTENT	's\tagSEC_CONTENT	match\tagSEC_CONTENT	against\tagSEC_CONTENT	west\tagSEC_CONTENT	brom\tagSEC_CONTENT	in\tagSEC_CONTENT	january\tagSEC_CONTENT	when\tagSEC_CONTENT	kevin\tagSEC_CONTENT	mirallas\tagSEC_CONTENT	grabbed\tagSEC_CONTENT	the\tagSEC_CONTENT	ball\tagSEC_CONTENT	from\tagSEC_CONTENT	baines\tagSEC_CONTENT	to\tagSEC_CONTENT	take\tagSEC_CONTENT	a\tagSEC_CONTENT	penalty\tagSEC_CONTENT	-and\tagSEC_CONTENT	missed\tagSEC_CONTENT	.\tagSEC_CONTENT	ross\tagSEC_CONTENT	barkley\tagSEC_CONTENT	steps\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	take\tagSEC_CONTENT	a\tagSEC_CONTENT	10th\tagSEC_CONTENT	minute\tagSEC_CONTENT	penalty\tagSEC_CONTENT	despite\tagSEC_CONTENT	the\tagSEC_CONTENT	presence\tagSEC_CONTENT	of\tagSEC_CONTENT	leighton\tagSEC_CONTENT	baines\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	pitch\tagSEC_CONTENT	barkley\tagSEC_CONTENT	's\tagSEC_CONTENT	effort\tagSEC_CONTENT	is\tagSEC_CONTENT	saved\tagSEC_CONTENT	byburnley\tagSEC_CONTENT	goalkeeper\tagSEC_CONTENT	tom\tagSEC_CONTENT	heaton\tagSEC_CONTENT	at\tagSEC_CONTENT	goodison\tagSEC_CONTENT	park\tagSEC_CONTENT	martinez\tagtask	insisted\tagSEC_CONTENT	barkley\tagSEC_CONTENT	was\tagSEC_CONTENT	within\tagSEC_CONTENT	his\tagSEC_CONTENT	rights\tagSEC_CONTENT	to\tagSEC_CONTENT	request\tagSEC_CONTENT	penalty\tagSEC_CONTENT	-taking\tagSEC_CONTENT	duties\tagSEC_CONTENT	on\tagSEC_CONTENT	saturday\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	if\tagSEC_CONTENT	romelu\tagSEC_CONTENT	lukaku\tagSEC_CONTENT	had\tagSEC_CONTENT	been\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	pitch\tagSEC_CONTENT	,\tagSEC_CONTENT	he\tagSEC_CONTENT	would\tagSEC_CONTENT	have\tagSEC_CONTENT	taken\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_CONTENT	otherwise\tagSEC_CONTENT	,\tagSEC_CONTENT	i\tagSEC_CONTENT	am\tagSEC_CONTENT	happy\tagSEC_CONTENT	to\tagSEC_CONTENT	have\tagSEC_CONTENT	three\tagSEC_CONTENT	or\tagSEC_CONTENT	four\tagSEC_CONTENT	players\tagSEC_CONTENT	who\tagSEC_CONTENT	can\tagSEC_CONTENT	take\tagSEC_CONTENT	penalties\tagSEC_CONTENT	and\tagSEC_CONTENT	let\tagSEC_CONTENT	it\tagSEC_CONTENT	depend\tagSEC_CONTENT	on\tagSEC_CONTENT	how\tagSEC_CONTENT	they\tagSEC_CONTENT	feel\tagSEC_CONTENT	at\tagSEC_CONTENT	that\tagSEC_CONTENT	moment\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	argued\tagSEC_CONTENT	the\tagSEC_CONTENT	everton\tagSEC_CONTENT	manager\tagSEC_CONTENT	.\tagSEC_CONTENT	baines\tagSEC_CONTENT	(\tagSEC_CONTENT	left\tagSEC_CONTENT	)\tagSEC_CONTENT	has\tagSEC_CONTENT	scored\tagSEC_CONTENT	15\tagSEC_CONTENT	penalties\tagSEC_CONTENT	from\tagSEC_CONTENT	16\tagSEC_CONTENT	attempts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	'\tagSEC_CONTENT	ross\tagSEC_CONTENT	showed\tagSEC_CONTENT	incredible\tagSEC_CONTENT	responsibility\tagSEC_CONTENT	to\tagSEC_CONTENT	take\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_CONTENT	i\tagSEC_CONTENT	love\tagSEC_CONTENT	seeing\tagSEC_CONTENT	players\tagSEC_CONTENT	take\tagSEC_CONTENT	control\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	big\tagSEC_CONTENT	moments\tagSEC_CONTENT	and\tagSEC_CONTENT	leighton\tagSEC_CONTENT	was\tagSEC_CONTENT	happy\tagSEC_CONTENT	to\tagSEC_CONTENT	given\tagSEC_CONTENT	him\tagSEC_CONTENT	that\tagSEC_CONTENT	responsibility\tagSEC_CONTENT	.\tagSEC_CONTENT	'\tagSEC_CONTENT	barkley\tagSEC_CONTENT	's\tagSEC_CONTENT	penalty\tagSEC_CONTENT	was\tagSEC_CONTENT	well\tagSEC_CONTENT	-struck\tagSEC_CONTENT	but\tagSEC_CONTENT	was\tagSEC_CONTENT	n't\tagSEC_CONTENT	put\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	corner\tagSEC_CONTENT	and\tagSEC_CONTENT	burnley\tagSEC_CONTENT	goalkeeper\tagSEC_CONTENT	tom\tagSEC_CONTENT	heaton\tagSEC_CONTENT	dived\tagSEC_CONTENT	to\tagSEC_CONTENT	his\tagSEC_CONTENT	right\tagSEC_CONTENT	to\tagSEC_CONTENT	save\tagSEC_CONTENT	.\tagSEC_CONTENT	fortunately\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	young\tagSEC_CONTENT	england\tagSEC_CONTENT	player\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	did\tagSEC_CONTENT	n't\tagSEC_CONTENT	prove\tagSEC_CONTENT	costly\tagSEC_CONTENT	as\tagSEC_CONTENT	mirallas\tagSEC_CONTENT	went\tagSEC_CONTENT	onto\tagSEC_CONTENT	score\tagSEC_CONTENT	the\tagSEC_CONTENT	only\tagSEC_CONTENT	goal\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	game\tagSEC_CONTENT	after\tagSEC_CONTENT	29\tagSEC_CONTENT	minutes\tagSEC_CONTENT	.\tagSEC_CONTENT	everton\tagSEC_CONTENT	boss\tagSEC_CONTENT	roberto\tagSEC_CONTENT	martinez\tagSEC_CONTENT	issues\tagSEC_CONTENT	instructions\tagSEC_CONTENT	to\tagSEC_CONTENT	his\tagSEC_CONTENT	players\tagSEC_CONTENT	during\tagSEC_CONTENT	a\tagSEC_CONTENT	break\tagSEC_CONTENT	in\tagSEC_CONTENT	play\tagSEC_CONTENT	against\tagSEC_CONTENT	burnley\tagSEC_CONTENT	everton\tagSEC_CONTENT	defeated\tagSEC_CONTENT	burnley\tagSEC_CONTENT	1\tagSEC_CONTENT	-0\tagSEC_CONTENT	at\tagSEC_CONTENT	goodison\tagSEC_CONTENT	park\tagSEC_CONTENT	on\tagSEC_CONTENT	saturday\tagSEC_CONTENT	.\tagSEC_CONTENT	kevin\tagSEC_CONTENT	mirallas\tagSEC_CONTENT	scored\tagSEC_CONTENT	the\tagSEC_CONTENT	only\tagSEC_CONTENT	goal\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	game\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	29th\tagSEC_CONTENT	minute\tagSEC_CONTENT	.\tagSEC_CONTENT	ross\tagSEC_CONTENT	barkley\tagSEC_CONTENT	had\tagSEC_CONTENT	earlier\tagSEC_CONTENT	missed\tagSEC_CONTENT	a\tagSEC_CONTENT	10th\tagSEC_CONTENT	-minute\tagSEC_CONTENT	penalty\tagSEC_CONTENT	.\tagSEC_CONTENT	leighton\tagSEC_CONTENT	baines\tagSEC_CONTENT	has\tagSEC_CONTENT	scored\tagSEC_CONTENT	15\tagSEC_CONTENT	penalties\tagSEC_CONTENT	from\tagSEC_CONTENT	16\tagSEC_CONTENT	attempts\tagSEC_CONTENT	this\tagSEC_CONTENT	season\tagSEC_CONTENT	.\tagSEC_END	Single\tagSECTITLE_START	Agent\tagSECTITLE_CONTENT	Baseline\tagSECTITLE_END	everton\tagSEC_START	manager\tagSEC_CONTENT	roberto\tagSEC_CONTENT	martinez\tagSEC_CONTENT	was\tagSEC_CONTENT	forced\tagSEC_CONTENT	to\tagSEC_CONTENT	defend\tagSEC_CONTENT	another\tagSEC_CONTENT	penalty\tagSEC_CONTENT	fiasco\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	club\tagSEC_CONTENT	after\tagSEC_CONTENT	ross\tagSEC_CONTENT	barkley\tagSEC_CONTENT	missed\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	spot\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	1\tagSEC_CONTENT	-0\tagSEC_CONTENT	win\tagSEC_CONTENT	against\tagSEC_CONTENT	burnley\tagSEC_CONTENT	at\tagSEC_CONTENT	goodison\tagSEC_CONTENT	park\tagSEC_CONTENT	.\tagSEC_CONTENT	the\tagSEC_CONTENT	untried\tagSEC_CONTENT	barkley\tagSEC_CONTENT	inexplicably\tagSEC_CONTENT	took\tagSEC_CONTENT	the\tagSEC_CONTENT	10th\tagSEC_CONTENT	minute\tagSEC_CONTENT	kick\tagSEC_CONTENT	awarded\tagSEC_CONTENT	fora\tagSEC_CONTENT	foul\tagSEC_CONTENT	by\tagSEC_CONTENT	david\tagSEC_CONTENT	jones\tagSEC_CONTENT	on\tagSEC_CONTENT	aaron\tagSEC_CONTENT	lennon\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	leighton\tagSEC_CONTENT	baines\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	has\tagSEC_CONTENT	scored\tagSEC_CONTENT	15\tagSEC_CONTENT	penalties\tagSEC_CONTENT	from\tagSEC_CONTENT	16\tagSEC_CONTENT	attempts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_START	Agent\tagSECTITLE_END	everton\tagSEC_START	beat\tagSEC_CONTENT	burnley\tagSEC_CONTENT	1\tagSEC_CONTENT	-0\tagSEC_CONTENT	at\tagSEC_CONTENT	goodison\tagSEC_CONTENT	park\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	premier\tagSEC_CONTENT	league\tagSEC_CONTENT	.\tagSEC_CONTENT	ross\tagSEC_CONTENT	barkley\tagSEC_CONTENT	steps\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	take\tagSEC_CONTENT	a\tagSEC_CONTENT	10th\tagSEC_CONTENT	minute\tagSEC_CONTENT	penalty\tagSEC_CONTENT	but\tagSEC_CONTENT	missed\tagSEC_CONTENT	it\tagSEC_CONTENT	.\tagSEC_CONTENT	barkley\tagSEC_CONTENT	has\tagSEC_CONTENT	scored\tagSEC_CONTENT	15\tagSEC_CONTENT	penalties\tagSEC_CONTENT	from\tagSEC_CONTENT	16\tagSEC_CONTENT	attempts\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	pitch\tagSEC_CONTENT	.\tagSEC_CONTENT	:\tagSEC_CONTENT	The\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	generates\tagSEC_CONTENT	summary\tagtask	with\tagSEC_CONTENT	superfluous\tagSEC_CONTENT	details\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	facts\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	clearly\tagSEC_CONTENT	expressed\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	it\tagSEC_CONTENT	was\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	statistics\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	player\tagSEC_CONTENT	correctly\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	15\tagSEC_CONTENT	penalties\tagSEC_CONTENT	,\tagSEC_CONTENT	16\tagSEC_CONTENT	attempts\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	still\tagSEC_CONTENT	missed\tagSEC_CONTENT	the\tagSEC_CONTENT	player\tagSEC_CONTENT	who\tagSEC_CONTENT	scored\tagSEC_CONTENT	the\tagSEC_CONTENT	only\tagSEC_CONTENT	goal\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	game\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	,\tagSEC_CONTENT	kevin\tagSEC_CONTENT	mirallas\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	hand\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	was\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	a\tagSEC_CONTENT	concise\tagSEC_CONTENT	summary\tagSEC_CONTENT	with\tagSEC_CONTENT	several\tagSEC_CONTENT	key\tagSEC_CONTENT	facts\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	single\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	missed\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	player\tagSEC_CONTENT	who\tagSEC_CONTENT	scored\tagSEC_CONTENT	the\tagSEC_CONTENT	only\tagSEC_CONTENT	goal\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	game\tagSEC_CONTENT	.\tagSEC_CONTENT	Interestingly\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	contains\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	"\tagSEC_CONTENT	defeated\tagSEC_CONTENT	'\tagSEC_CONTENT	but\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	agent\tagSEC_CONTENT	model\tagSEC_CONTENT	chose\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	beat\tagSEC_CONTENT	instead\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	exist\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	document\tagSEC_CONTENT	.\tagSEC_END	
P16-1072	title\tagSECTITLE_END	Bidirectional\tagSEC_START	Recurrent\tagSEC_CONTENT	Convolutional\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network\tagSEC_CONTENT	for\tagSEC_CONTENT	Relation\tagtask	Classification\tagSEC_END	abstract\tagSECTITLE_END	Relation\tagSEC_START	classification\tagtask	is\tagSEC_CONTENT	an\tagSEC_CONTENT	important\tagSEC_CONTENT	semantic\tagSEC_CONTENT	processing\tagSEC_CONTENT	task\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	field\tagSEC_CONTENT	of\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	processing\tagSEC_CONTENT	(\tagSEC_CONTENT	NLP\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	present\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	model\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	to\tagSEC_CONTENT	classify\tagSEC_CONTENT	the\tagtask	relation\tagtask	of\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	Some\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	systems\tagSEC_CONTENT	concentrate\tagSEC_CONTENT	on\tagSEC_CONTENT	modeling\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	(\tagSEC_CONTENT	SDP\tagSEC_CONTENT	)\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	leveraging\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	or\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neu\tagSEC_CONTENT	-\tagSEC_CONTENT	ral\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	further\tagSEC_CONTENT	explore\tagSEC_CONTENT	how\tagSEC_CONTENT	to\tagSEC_CONTENT	make\tagSEC_CONTENT	full\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagtask	dependency\tagtask	relations\tagtask	information\tagtask	in\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	combining\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	and\tagSEC_CONTENT	two\tagSEC_CONTENT	-\tagSEC_CONTENT	channel\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	with\tagSEC_CONTENT	long\tagSEC_CONTENT	short\tagSEC_CONTENT	term\tagSEC_CONTENT	memory\tagSEC_CONTENT	(\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	units\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	architecture\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	relation\tagtask	representations\tagtask	with\tagSEC_CONTENT	directional\tagtask	information\tagtask	along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	forwards\tagSEC_CONTENT	and\tagSEC_CONTENT	backwards\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	benefits\tagSEC_CONTENT	classifying\tagSEC_CONTENT	the\tagSEC_CONTENT	direction\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	approaches\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	Task\tagdataset	8\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	Relation\tagSEC_START	classification\tagtask	aims\tagSEC_CONTENT	to\tagSEC_CONTENT	classify\tagSEC_CONTENT	the\tagSEC_CONTENT	semantic\tagSEC_CONTENT	relations\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	instance\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	"\tagSEC_CONTENT	The\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	caused\tagSEC_CONTENT	by\tagSEC_CONTENT	water\tagSEC_CONTENT	hammer\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	entities\tagSEC_CONTENT	burst\tagSEC_CONTENT	and\tagSEC_CONTENT	pressure\tagSEC_CONTENT	are\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagtask	CauseEffect(e\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Relation\tagtask	classification\tagtask	plays\tagSEC_CONTENT	a\tagSEC_CONTENT	key\tagSEC_CONTENT	role\tagSEC_CONTENT	in\tagSEC_CONTENT	robust\tagtask	knowledge\tagtask	extraction\tagtask	,\tagSEC_CONTENT	and\tagSEC_CONTENT	has\tagSEC_CONTENT	become\tagSEC_CONTENT	a\tagSEC_CONTENT	hot\tagSEC_CONTENT	research\tagSEC_CONTENT	topic\tagSEC_CONTENT	in\tagSEC_CONTENT	recent\tagSEC_CONTENT	years\tagSEC_CONTENT	.\tagSEC_END	Nowadays\tagSEC_START	,\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	techniques\tagSEC_CONTENT	have\tagSEC_CONTENT	made\tagSEC_CONTENT	significant\tagSEC_CONTENT	improvement\tagSEC_CONTENT	in\tagSEC_CONTENT	relation\tagtask	classification\tagtask	,\tagSEC_CONTENT	*\tagSEC_CONTENT	Corresponding\tagSEC_CONTENT	author\tagSEC_CONTENT	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	traditional\tagSEC_CONTENT	relation\tagSEC_CONTENT	classification\tagSEC_CONTENT	approaches\tagSEC_CONTENT	focusing\tagSEC_CONTENT	on\tagSEC_CONTENT	designing\tagSEC_CONTENT	effective\tagSEC_CONTENT	features\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	kernels\tagSEC_CONTENT	)\tagSEC_CONTENT	Although\tagSEC_CONTENT	traditional\tagSEC_CONTENT	approaches\tagSEC_CONTENT	are\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	exploit\tagSEC_CONTENT	the\tagSEC_CONTENT	symbolic\tagSEC_CONTENT	structures\tagSEC_CONTENT	in\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	still\tagSEC_CONTENT	suffer\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	difficulty\tagSEC_CONTENT	to\tagSEC_CONTENT	generalize\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	unseen\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	Some\tagSEC_CONTENT	recent\tagSEC_CONTENT	works\tagSEC_CONTENT	learn\tagSEC_CONTENT	features\tagSEC_CONTENT	automatically\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	(\tagSEC_CONTENT	NN\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	employing\tagSEC_CONTENT	continuous\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	(\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	NN\tagSEC_CONTENT	research\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	has\tagSEC_CONTENT	centered\tagSEC_CONTENT	around\tagSEC_CONTENT	two\tagSEC_CONTENT	main\tagSEC_CONTENT	network\tagSEC_CONTENT	architectures\tagSEC_CONTENT	:\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	and\tagSEC_CONTENT	recursive\tagSEC_CONTENT	/\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	Convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	aims\tagSEC_CONTENT	to\tagSEC_CONTENT	generalize\tagSEC_CONTENT	the\tagSEC_CONTENT	local\tagSEC_CONTENT	and\tagSEC_CONTENT	consecutive\tagSEC_CONTENT	context\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagtask	relation\tagtask	mentions\tagtask	,\tagSEC_CONTENT	while\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	adaptively\tagSEC_CONTENT	accumulate\tagSEC_CONTENT	the\tagtask	context\tagtask	information\tagtask	in\tagSEC_CONTENT	the\tagSEC_CONTENT	whole\tagSEC_CONTENT	sentence\tagSEC_CONTENT	via\tagSEC_CONTENT	memory\tagSEC_CONTENT	units\tagSEC_CONTENT	,\tagSEC_CONTENT	thereby\tagSEC_CONTENT	encoding\tagSEC_CONTENT	the\tagSEC_CONTENT	global\tagSEC_CONTENT	and\tagSEC_CONTENT	possibly\tagSEC_CONTENT	unconsecutive\tagSEC_CONTENT	patterns\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	learned\tagSEC_CONTENT	compositional\tagSEC_CONTENT	vector\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	sentences\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	customizaition\tagSEC_CONTENT	of\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	position\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_END	Recently\tagSEC_START	,\tagSEC_CONTENT	more\tagSEC_CONTENT	attentions\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	paid\tagSEC_CONTENT	to\tagSEC_CONTENT	modeling\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	(\tagSEC_CONTENT	SDP\tagSEC_CONTENT	)\tagSEC_CONTENT	of\tagSEC_CONTENT	sentences\tagSEC_CONTENT	.\tagSEC_CONTENT	developed\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	a\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	features\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	path\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	designed\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	subtrees\tagSEC_CONTENT	.\tagSEC_CONTENT	applied\tagSEC_CONTENT	long\tagSEC_CONTENT	short\tagSEC_CONTENT	term\tagSEC_CONTENT	memory\tagSEC_CONTENT	(\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	based\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	(\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	)\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	SDP\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	special\tagSEC_CONTENT	structure\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	every\tagSEC_CONTENT	two\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	words\tagSEC_CONTENT	are\tagSEC_CONTENT	separated\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	Previous\tagSEC_CONTENT	works\tagSEC_CONTENT	treated\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	way\tagSEC_CONTENT	as\tagSEC_CONTENT	words\tagSEC_CONTENT	or\tagSEC_CONTENT	some\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	features\tagSEC_CONTENT	like\tagSEC_CONTENT	partof\tagSEC_CONTENT	-\tagSEC_CONTENT	speech\tagSEC_CONTENT	(\tagSEC_CONTENT	POS\tagSEC_CONTENT	)\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagtask	limitations\tagtask	of\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	and\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	first\tagSEC_CONTENT	contribution\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	(\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	the\tagSEC_CONTENT	global\tagSEC_CONTENT	pattern\tagSEC_CONTENT	in\tagSEC_CONTENT	SDP\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	a\tagSEC_CONTENT	two\tagSEC_CONTENT	-\tagSEC_CONTENT	channel\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	based\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	and\tagSEC_CONTENT	capture\tagSEC_CONTENT	local\tagSEC_CONTENT	features\tagSEC_CONTENT	of\tagSEC_CONTENT	every\tagSEC_CONTENT	two\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	words\tagSEC_CONTENT	linked\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relation\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	a\tagSEC_CONTENT	convolution\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	further\tagSEC_CONTENT	observe\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagtask	relationship\tagtask	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	are\tagSEC_CONTENT	directed\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	instance\tagSEC_CONTENT	,\tagSEC_CONTENT	shows\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	path\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	"\tagSEC_CONTENT	The\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	caused\tagSEC_CONTENT	by\tagSEC_CONTENT	water\tagSEC_CONTENT	hammer\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	"\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	relation\tagtask	CauseEffect(e\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	SDP\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	also\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	relation\tagSEC_CONTENT	Cause\tagSEC_CONTENT	-\tagSEC_CONTENT	Effect(e\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	refers\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	entity\tagSEC_CONTENT	at\tagSEC_CONTENT	front\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	SDP\tagSEC_CONTENT	and\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	refers\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	entity\tagSEC_CONTENT	at\tagSEC_CONTENT	back\tagSEC_CONTENT	end\tagSEC_CONTENT	of\tagSEC_CONTENT	SDP\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	inverse\tagSEC_CONTENT	SDP\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	relation\tagtask	Cause\tagtask	-\tagtask	Effect(e\tagtask	1\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Previous\tagSEC_CONTENT	work\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	simply\tagSEC_CONTENT	transforms\tagSEC_CONTENT	a\tagSEC_CONTENT	(\tagSEC_CONTENT	K+1)-relation\tagSEC_CONTENT	task\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	K\tagSEC_CONTENT	+\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	classification\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	1\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	Other\tagSEC_CONTENT	relation\tagSEC_CONTENT	and\tagSEC_CONTENT	K\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	Besides\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	biased\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	later\tagSEC_CONTENT	inputs\tagSEC_CONTENT	are\tagSEC_CONTENT	more\tagSEC_CONTENT	dominant\tagSEC_CONTENT	than\tagSEC_CONTENT	earlier\tagSEC_CONTENT	inputs\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	could\tagSEC_CONTENT	reduce\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	when\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	semantics\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	whole\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	,\tagSEC_CONTENT	because\tagSEC_CONTENT	key\tagSEC_CONTENT	components\tagSEC_CONTENT	could\tagSEC_CONTENT	appear\tagSEC_CONTENT	anywhere\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	SDP\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	second\tagSEC_CONTENT	contribution\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	(\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	representations\tagtask	with\tagSEC_CONTENT	bidirectional\tagtask	information\tagtask	along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	forwards\tagSEC_CONTENT	and\tagSEC_CONTENT	backwards\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	also\tagSEC_CONTENT	strengthen\tagSEC_CONTENT	the\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	classifying\tagSEC_CONTENT	directions\tagSEC_CONTENT	of\tagSEC_CONTENT	relationships\tagtask	between\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	significantly\tagSEC_CONTENT	improves\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	relation\tagdataset	classification\tagdataset	task\tagdataset	,\tagSEC_CONTENT	and\tagSEC_CONTENT	achieve\tagSEC_CONTENT	a\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	ofthe\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	86.3\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	The\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	Method\tagSECTITLE_END	In\tagSEC_START	this\tagtask	section\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	describe\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	.\tagSEC_CONTENT	Subsection\tagSEC_CONTENT	2.1\tagSEC_CONTENT	provides\tagSEC_CONTENT	an\tagSEC_CONTENT	overall\tagSEC_CONTENT	picture\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	BCRNN\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Subsection\tagSEC_CONTENT	2.2\tagSEC_CONTENT	presents\tagSEC_CONTENT	the\tagSEC_CONTENT	rationale\tagSEC_CONTENT	of\tagSEC_CONTENT	using\tagSEC_CONTENT	SDPs\tagSEC_CONTENT	and\tagSEC_CONTENT	some\tagSEC_CONTENT	characteristics\tagSEC_CONTENT	of\tagSEC_CONTENT	SDP\tagSEC_CONTENT	.\tagSEC_CONTENT	Subsection\tagSEC_CONTENT	2.3\tagSEC_CONTENT	describes\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	-\tagSEC_CONTENT	channel\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	introduced\tagSEC_CONTENT	in\tagSEC_CONTENT	Subsection\tagSEC_CONTENT	2.4\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	present\tagSEC_CONTENT	our\tagSEC_CONTENT	training\tagSEC_CONTENT	objective\tagSEC_CONTENT	in\tagSEC_CONTENT	Subsection\tagSEC_CONTENT	2.5\tagSEC_CONTENT	.\tagSEC_END	Framework\tagSECTITLE_END	Our\tagSEC_START	BCRNN\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	representations\tagtask	with\tagSEC_CONTENT	bidirectional\tagtask	information\tagtask	along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	forwards\tagSEC_CONTENT	and\tagSEC_CONTENT	backwards\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	depicts\tagSEC_CONTENT	the\tagSEC_CONTENT	overall\tagSEC_CONTENT	architecture\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_END	Given\tagSEC_START	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	and\tagSEC_CONTENT	its\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	build\tagSEC_CONTENT	our\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	on\tagSEC_CONTENT	its\tagSEC_CONTENT	SDP\tagSEC_CONTENT	extracted\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	tree\tagSEC_CONTENT	.\tagSEC_CONTENT	Along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	,\tagSEC_CONTENT	two\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	with\tagSEC_CONTENT	long\tagSEC_CONTENT	short\tagSEC_CONTENT	term\tagSEC_CONTENT	memory\tagSEC_CONTENT	units\tagSEC_CONTENT	are\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	hidden\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	convolution\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	local\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	hidden\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	every\tagSEC_CONTENT	two\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	between\tagSEC_CONTENT	them\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	max\tagSEC_CONTENT	pooling\tagSEC_CONTENT	layer\tagSEC_CONTENT	thereafter\tagSEC_CONTENT	gathers\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	local\tagSEC_CONTENT	features\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagSEC_CONTENT	inverse\tagSEC_CONTENT	SDP\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	have\tagSEC_CONTENT	a\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	output\tagSEC_CONTENT	layer\tagSEC_CONTENT	after\tagSEC_CONTENT	pooling\tagSEC_CONTENT	layer\tagSEC_CONTENT	for\tagSEC_CONTENT	classification\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	model\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	.\tagSEC_END	On\tagSEC_START	the\tagSEC_CONTENT	basis\tagSEC_CONTENT	of\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	build\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	architecture\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	taking\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	inverse\tagSEC_CONTENT	SDP\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	During\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	stage\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	(\tagSEC_CONTENT	K+1)-relation\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	two\tagSEC_CONTENT	fine\tagSEC_CONTENT	-\tagSEC_CONTENT	grained\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	classifiers\tagSEC_CONTENT	of\tagSEC_CONTENT	RCNNs\tagSEC_CONTENT	do\tagSEC_CONTENT	a\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	K\tagSEC_CONTENT	+\tagSEC_CONTENT	1)-class\tagSEC_CONTENT	classification\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	pooling\tagSEC_CONTENT	layers\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	RCNNs\tagSEC_CONTENT	are\tagSEC_CONTENT	concatenated\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	coarse\tagSEC_CONTENT	-\tagSEC_CONTENT	grained\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	output\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	followed\tagSEC_CONTENT	to\tagSEC_CONTENT	do\tagSEC_CONTENT	a\tagSEC_CONTENT	(\tagSEC_CONTENT	K\tagSEC_CONTENT	+\tagSEC_CONTENT	1)-class\tagSEC_CONTENT	classification\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	final\tagSEC_CONTENT	(\tagSEC_CONTENT	2K+1)-class\tagSEC_CONTENT	distribution\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	(\tagSEC_CONTENT	2K+1)-class\tagSEC_CONTENT	distributions\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	finegrained\tagSEC_CONTENT	classifiers\tagSEC_CONTENT	respectively\tagSEC_CONTENT	during\tagSEC_CONTENT	the\tagSEC_CONTENT	testing\tagSEC_CONTENT	stage\tagSEC_CONTENT	.\tagSEC_END	The\tagSECTITLE_START	Shortest\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Path\tagSECTITLE_END	If\tagSEC_START	e\tagSEC_CONTENT	1\tagSEC_CONTENT	and\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	mentioned\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	sentence\tagSEC_CONTENT	such\tagSEC_CONTENT	that\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	observed\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagtask	relationship\tagtask	R\tagtask	,\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	path\tagSEC_CONTENT	between\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	and\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	condenses\tagSEC_CONTENT	most\tagSEC_CONTENT	illuminating\tagSEC_CONTENT	information\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagtask	relationship\tagtask	R(e\tagtask	1\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	is\tagSEC_CONTENT	because\tagSEC_CONTENT	(\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	if\tagSEC_CONTENT	entities\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	and\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	are\tagSEC_CONTENT	arguments\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	predicate\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	path\tagSEC_CONTENT	between\tagSEC_CONTENT	them\tagSEC_CONTENT	will\tagSEC_CONTENT	pass\tagSEC_CONTENT	through\tagSEC_CONTENT	the\tagSEC_CONTENT	predicate\tagSEC_CONTENT	;\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	if\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	and\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	belong\tagSEC_CONTENT	to\tagSEC_CONTENT	different\tagSEC_CONTENT	predicate\tagSEC_CONTENT	-\tagSEC_CONTENT	argument\tagSEC_CONTENT	structures\tagSEC_CONTENT	that\tagSEC_CONTENT	share\tagSEC_CONTENT	a\tagSEC_CONTENT	common\tagSEC_CONTENT	argument\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	path\tagSEC_CONTENT	will\tagSEC_CONTENT	pass\tagSEC_CONTENT	through\tagSEC_CONTENT	this\tagSEC_CONTENT	argument\tagSEC_CONTENT	.\tagSEC_CONTENT	first\tagSEC_CONTENT	used\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	paths\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	predicate\tagSEC_CONTENT	-\tagSEC_CONTENT	argument\tagSEC_CONTENT	sequences\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	provided\tagSEC_CONTENT	strong\tagSEC_CONTENT	evidence\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	captured\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	paths\tagSEC_CONTENT	separated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	common\tagSEC_CONTENT	ancestor\tagSEC_CONTENT	node\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	paths\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	is\tagSEC_CONTENT	usually\tagSEC_CONTENT	short\tagSEC_CONTENT	(\tagSEC_CONTENT	∼4\tagSEC_CONTENT	on\tagSEC_CONTENT	average\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	common\tagSEC_CONTENT	ancestor\tagSEC_CONTENT	of\tagSEC_CONTENT	some\tagSEC_CONTENT	SDPs\tagSEC_CONTENT	is\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	ore\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	imbalance\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	paths\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	observe\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	two\tagSEC_CONTENT	neighbor\tagSEC_CONTENT	words\tagSEC_CONTENT	w\tagSEC_CONTENT	a\tagSEC_CONTENT	and\tagSEC_CONTENT	w\tagSEC_CONTENT	bare\tagSEC_CONTENT	linked\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relation\tagSEC_CONTENT	r\tagSEC_CONTENT	ab\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	between\tagSEC_CONTENT	a\tagSEC_CONTENT	governing\tagSEC_CONTENT	word\tagSEC_CONTENT	and\tagSEC_CONTENT	its\tagSEC_CONTENT	children\tagSEC_CONTENT	make\tagSEC_CONTENT	a\tagSEC_CONTENT	difference\tagSEC_CONTENT	in\tagSEC_CONTENT	meaning\tagSEC_CONTENT	.\tagSEC_CONTENT	Besides\tagSEC_CONTENT	,\tagSEC_CONTENT	if\tagSEC_CONTENT	we\tagSEC_CONTENT	inverse\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagtask	same\tagtask	relationship\tagtask	with\tagSEC_CONTENT	an\tagSEC_CONTENT	opposite\tagSEC_CONTENT	direction\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	path\tagSEC_CONTENT	is\tagSEC_CONTENT	composed\tagSEC_CONTENT	of\tagSEC_CONTENT	some\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	structure\tagSEC_CONTENT	like\tagSEC_CONTENT	"\tagSEC_CONTENT	burst\tagSEC_CONTENT	nsub\tagSEC_CONTENT	jpass\tagSEC_CONTENT	−\tagSEC_CONTENT	−−−−−−−\tagSEC_CONTENT	→\tagSEC_CONTENT	caused\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Following\tagSEC_CONTENT	the\tagSEC_CONTENT	above\tagSEC_CONTENT	intuition\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	design\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	capture\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	local\tagSEC_CONTENT	substructures\tagSEC_CONTENT	and\tagSEC_CONTENT	inversely\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_END	Two\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Channel\tagSECTITLE_CONTENT	Recurrent\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Long\tagSECTITLE_CONTENT	Short\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	Units\tagSECTITLE_END	The\tagSEC_START	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	suitable\tagSEC_CONTENT	for\tagSEC_CONTENT	modeling\tagSEC_CONTENT	sequential\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	keeps\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	vector\tagSEC_CONTENT	h\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	changes\tagSEC_CONTENT	with\tagSEC_CONTENT	input\tagSEC_CONTENT	data\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	step\tagSEC_CONTENT	accordingly\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	make\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	for\tagSEC_CONTENT	relations\tagtask	classification\tagtask	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	call\tagSEC_CONTENT	them\tagSEC_CONTENT	channels\tagSEC_CONTENT	as\tagSEC_CONTENT	these\tagSEC_CONTENT	information\tagSEC_CONTENT	sources\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	interact\tagSEC_CONTENT	during\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	propagation\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	word\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relation\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	given\tagSEC_CONTENT	sentence\tagSEC_CONTENT	is\tagSEC_CONTENT	mapped\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	real\tagSEC_CONTENT	-\tagSEC_CONTENT	valued\tagSEC_CONTENT	vector\tagSEC_CONTENT	by\tagSEC_CONTENT	looking\tagSEC_CONTENT	up\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	embedding\tagSEC_CONTENT	table\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	are\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	large\tagSEC_CONTENT	corpus\tagSEC_CONTENT	unsupervisedly\tagSEC_CONTENT	and\tagSEC_CONTENT	are\tagSEC_CONTENT	thought\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	their\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	and\tagSEC_CONTENT	semantic\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	are\tagSEC_CONTENT	initialized\tagSEC_CONTENT	randomly\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	ht\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	t\tagSEC_CONTENT	-\tagSEC_CONTENT	th\tagSEC_CONTENT	input\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	function\tagSEC_CONTENT	of\tagSEC_CONTENT	its\tagSEC_CONTENT	previous\tagSEC_CONTENT	state\tagSEC_CONTENT	h\tagSEC_CONTENT	t−1\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	x\tagSEC_CONTENT	t\tagSEC_CONTENT	of\tagSEC_CONTENT	current\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	Traditional\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	networks\tagSEC_CONTENT	have\tagSEC_CONTENT	a\tagtask	basic\tagtask	interaction\tagtask	,\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	is\tagSEC_CONTENT	linearly\tagSEC_CONTENT	transformed\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	weight\tagSEC_CONTENT	matrix\tagSEC_CONTENT	and\tagSEC_CONTENT	nonlinearly\tagSEC_CONTENT	squashed\tagSEC_CONTENT	by\tagSEC_CONTENT	an\tagSEC_CONTENT	activation\tagSEC_CONTENT	function\tagSEC_CONTENT	.\tagSEC_CONTENT	Formally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	have\tagSEC_END	where\tagSEC_START	W\tagSEC_CONTENT	in\tagSEC_CONTENT	and\tagSEC_CONTENT	W\tagSEC_CONTENT	rec\tagSEC_CONTENT	are\tagSEC_CONTENT	weight\tagSEC_CONTENT	matrices\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	and\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	connections\tagSEC_CONTENT	,\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	b\tagSEC_CONTENT	h\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	bias\tagSEC_CONTENT	term\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	fa\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	activation\tagSEC_CONTENT	function\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	was\tagSEC_CONTENT	difficult\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	RNNs\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	longterm\tagSEC_CONTENT	dependencies\tagSEC_CONTENT	because\tagSEC_CONTENT	the\tagSEC_CONTENT	gradients\tagSEC_CONTENT	tend\tagSEC_CONTENT	to\tagSEC_CONTENT	either\tagSEC_CONTENT	vanish\tagSEC_CONTENT	or\tagSEC_CONTENT	explode\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	some\tagSEC_CONTENT	more\tagSEC_CONTENT	sophisticated\tagSEC_CONTENT	activation\tagSEC_CONTENT	function\tagSEC_CONTENT	with\tagSEC_CONTENT	gating\tagSEC_CONTENT	units\tagSEC_CONTENT	were\tagSEC_CONTENT	designed\tagSEC_CONTENT	.\tagSEC_CONTENT	Long\tagSEC_CONTENT	short\tagSEC_CONTENT	term\tagSEC_CONTENT	memory\tagSEC_CONTENT	units\tagSEC_CONTENT	are\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	to\tagSEC_CONTENT	overcome\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	main\tagSEC_CONTENT	idea\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	introduce\tagSEC_CONTENT	an\tagSEC_CONTENT	adaptive\tagSEC_CONTENT	gating\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	decides\tagSEC_CONTENT	the\tagSEC_CONTENT	degree\tagSEC_CONTENT	to\tagSEC_CONTENT	which\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	units\tagSEC_CONTENT	keep\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	state\tagSEC_CONTENT	and\tagSEC_CONTENT	memorize\tagSEC_CONTENT	the\tagSEC_CONTENT	extracted\tagSEC_CONTENT	features\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	data\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	Many\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	variants\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	proposed\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	adopt\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	a\tagSEC_CONTENT	variant\tagSEC_CONTENT	introduced\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	Concretely\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	comprises\tagSEC_CONTENT	four\tagSEC_CONTENT	components\tagSEC_CONTENT	:\tagSEC_CONTENT	an\tagSEC_CONTENT	input\tagSEC_CONTENT	gate\tagSEC_CONTENT	it\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	forget\tagSEC_CONTENT	gate\tagSEC_CONTENT	ft\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	output\tagSEC_CONTENT	gate\tagSEC_CONTENT	o\tagSEC_CONTENT	t\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	memory\tagSEC_CONTENT	cell\tagSEC_CONTENT	ct\tagSEC_CONTENT	.\tagSEC_END	First\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	values\tagSEC_CONTENT	for\tagSEC_CONTENT	it\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	gate\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	gt\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	value\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	states\tagSEC_CONTENT	of\tagSEC_CONTENT	  \tagSEC_CONTENT	the\tagSEC_CONTENT	memory\tagSEC_CONTENT	cells\tagSEC_CONTENT	at\tagSEC_CONTENT	time\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_END	Second\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	value\tagSEC_CONTENT	for\tagSEC_CONTENT	ft\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	activations\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	memory\tagSEC_CONTENT	cells\tagSEC_CONTENT	'\tagSEC_CONTENT	forget\tagSEC_CONTENT	gates\tagSEC_CONTENT	at\tagSEC_CONTENT	time\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_END	Given\tagSEC_START	the\tagSEC_CONTENT	value\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	gate\tagSEC_CONTENT	activations\tagSEC_CONTENT	it\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	forget\tagSEC_CONTENT	gate\tagSEC_CONTENT	activation\tagSEC_CONTENT	ft\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	state\tagSEC_CONTENT	value\tagSEC_CONTENT	gt\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	compute\tagSEC_CONTENT	ct\tagSEC_CONTENT	the\tagSEC_CONTENT	memory\tagSEC_CONTENT	cells\tagSEC_CONTENT	'\tagSEC_CONTENT	new\tagSEC_CONTENT	state\tagSEC_CONTENT	at\tagSEC_CONTENT	time\tagSEC_CONTENT	t\tagSEC_CONTENT	:\tagSEC_END	With\tagSEC_START	the\tagSEC_CONTENT	new\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	memory\tagSEC_CONTENT	cells\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	compute\tagSEC_CONTENT	the\tagSEC_CONTENT	value\tagSEC_CONTENT	of\tagSEC_CONTENT	their\tagSEC_CONTENT	output\tagSEC_CONTENT	gates\tagSEC_CONTENT	and\tagSEC_CONTENT	,\tagSEC_CONTENT	subsequently\tagSEC_CONTENT	,\tagSEC_CONTENT	their\tagSEC_CONTENT	outputs\tagSEC_CONTENT	:\tagSEC_END	In\tagSEC_START	the\tagSEC_CONTENT	above\tagSEC_CONTENT	equations\tagSEC_CONTENT	,\tagSEC_CONTENT	σ\tagSEC_CONTENT	denotes\tagSEC_CONTENT	a\tagSEC_CONTENT	sigmoid\tagSEC_CONTENT	function\tagSEC_CONTENT	;\tagSEC_CONTENT	⊗\tagSEC_CONTENT	denotes\tagSEC_CONTENT	element\tagSEC_CONTENT	-\tagSEC_CONTENT	wise\tagSEC_CONTENT	multiplication\tagSEC_CONTENT	.\tagSEC_END	Bidirectional\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	Convolutional\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	We\tagSEC_START	observe\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	governing\tagSEC_CONTENT	word\tagSEC_CONTENT	w\tagSEC_CONTENT	a\tagSEC_CONTENT	and\tagSEC_CONTENT	its\tagSEC_CONTENT	children\tagSEC_CONTENT	w\tagSEC_CONTENT	bare\tagSEC_CONTENT	linked\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relation\tagSEC_CONTENT	r\tagSEC_CONTENT	ab\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	makes\tagSEC_CONTENT	a\tagSEC_CONTENT	difference\tagSEC_CONTENT	in\tagSEC_CONTENT	meaning\tagSEC_CONTENT	.\tagSEC_END	where\tagSEC_START	W\tagSEC_CONTENT	con\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	weight\tagSEC_CONTENT	matrix\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	convolution\tagSEC_CONTENT	layer\tagSEC_CONTENT	and\tagSEC_CONTENT	b\tagSEC_CONTENT	con\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	bias\tagSEC_CONTENT	term\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	f\tagmetric	is\tagSEC_CONTENT	a\tagtask	non\tagtask	-\tagtask	linear\tagtask	activation\tagtask	function(tanh\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	pooling\tagSEC_CONTENT	layer\tagSEC_CONTENT	thereafter\tagSEC_CONTENT	gather\tagSEC_CONTENT	global\tagSEC_CONTENT	information\tagSEC_CONTENT	G\tagSEC_CONTENT	from\tagSEC_CONTENT	local\tagSEC_CONTENT	features\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	units\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	de-\tagSEC_END	where\tagSEC_START	the\tagSEC_CONTENT	max\tagSEC_CONTENT	function\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	element\tagSEC_CONTENT	-\tagSEC_CONTENT	wise\tagSEC_CONTENT	function\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Dis\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	units\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	advantage\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	-\tagSEC_CONTENT	channel\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	better\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	contextual\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	adaptively\tagSEC_CONTENT	accumulating\tagSEC_CONTENT	the\tagtask	context\tagtask	information\tagtask	the\tagSEC_CONTENT	whole\tagSEC_CONTENT	path\tagSEC_CONTENT	via\tagSEC_CONTENT	memory\tagSEC_CONTENT	units\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	biased\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	later\tagSEC_CONTENT	inputs\tagSEC_CONTENT	are\tagSEC_CONTENT	more\tagSEC_CONTENT	dominant\tagSEC_CONTENT	than\tagSEC_CONTENT	earlier\tagSEC_CONTENT	inputs\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	could\tagSEC_CONTENT	reduce\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	when\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	features\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	,\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	entities\tagSEC_CONTENT	are\tagSEC_CONTENT	located\tagSEC_CONTENT	at\tagSEC_CONTENT	both\tagSEC_CONTENT	ends\tagSEC_CONTENT	of\tagSEC_CONTENT	SDP\tagSEC_CONTENT	and\tagSEC_CONTENT	key\tagSEC_CONTENT	components\tagSEC_CONTENT	could\tagSEC_CONTENT	appear\tagSEC_CONTENT	anywhere\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	SDP\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	end\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	tackle\tagSEC_CONTENT	the\tagSEC_CONTENT	problem\tagSEC_CONTENT	with\tagSEC_CONTENT	Bidirectional\tagSEC_CONTENT	Convolutional\tagSEC_CONTENT	Recurrent\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network\tagSEC_CONTENT	.\tagSEC_END	On\tagSEC_START	the\tagSEC_CONTENT	basis\tagSEC_CONTENT	of\tagSEC_CONTENT	observation\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	make\tagSEC_CONTENT	a\tagSEC_CONTENT	hypothesis\tagSEC_CONTENT	that\tagSEC_CONTENT	SDP\tagSEC_CONTENT	is\tagSEC_CONTENT	asymmetrical\tagSEC_CONTENT	structure\tagSEC_CONTENT	.\tagSEC_END	Where\tagSEC_START	W\tagSEC_CONTENT	c\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	transformation\tagSEC_CONTENT	matrix\tagSEC_CONTENT	and\tagSEC_CONTENT	b\tagSEC_CONTENT	c\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	bias\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	Coarse\tagSEC_CONTENT	-\tagSEC_CONTENT	grained\tagSEC_CONTENT	classifier\tagSEC_CONTENT	makes\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	representation\tagtask	with\tagSEC_CONTENT	bidirectional\tagtask	information\tagtask	ignoring\tagSEC_CONTENT	the\tagSEC_CONTENT	direction\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	,\tagSEC_CONTENT	which\tagSEC_CONTENT	learns\tagSEC_CONTENT	the\tagtask	inherent\tagtask	correlation\tagtask	between\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations\tagSEC_CONTENT	with\tagSEC_CONTENT	opposite\tagSEC_CONTENT	directions\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	Rx\tagSEC_CONTENT	(\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	Rx\tagSEC_CONTENT	(\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Two\tagSEC_CONTENT	fine\tagSEC_CONTENT	-\tagSEC_CONTENT	grained\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	classifiers\tagSEC_CONTENT	are\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	G\tagSEC_CONTENT	and\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	G\tagSEC_CONTENT	with\tagSEC_CONTENT	linear\tagSEC_CONTENT	transformation\tagSEC_CONTENT	to\tagSEC_CONTENT	give\tagSEC_CONTENT	the\tagSEC_CONTENT	(\tagSEC_CONTENT	2K+1)-class\tagSEC_CONTENT	distribution\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	y\tagSEC_CONTENT	and\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	y\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	Formally\tagSEC_CONTENT	,\tagSEC_END	where\tagSEC_START	W\tagSEC_CONTENT	f\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	transformation\tagSEC_CONTENT	matrix\tagSEC_CONTENT	and\tagSEC_CONTENT	bf\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	bias\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	Classifying\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	Sand\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	S\tagSEC_CONTENT	respecitvely\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	can\tagSEC_CONTENT	strengthen\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	judge\tagSEC_CONTENT	the\tagSEC_CONTENT	direction\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	.\tagSEC_END	Training\tagSECTITLE_START	Objective\tagSECTITLE_END	The\tagSEC_START	(\tagSEC_CONTENT	K\tagSEC_CONTENT	+\tagSEC_CONTENT	1)-class\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	classifier\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	estimate\tagSEC_CONTENT	probability\tagSEC_CONTENT	that\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	Sand\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	S\tagSEC_CONTENT	are\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagtask	R\tagtask	.\tagSEC_CONTENT	The\tagSEC_CONTENT	two\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	K\tagSEC_CONTENT	+\tagSEC_CONTENT	1)-class\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	classifiers\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	estimate\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	that\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	Sand\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	S\tagSEC_CONTENT	are\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagtask	−\tagtask	→\tagSEC_CONTENT	Rand\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	R\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	data\tagSEC_CONTENT	sample\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	objective\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	penalized\tagSEC_CONTENT	cross\tagSEC_CONTENT	-\tagSEC_CONTENT	entropy\tagSEC_CONTENT	of\tagSEC_CONTENT	three\tagSEC_CONTENT	classifiers\tagSEC_CONTENT	,\tagSEC_CONTENT	given\tagSEC_CONTENT	by\tagSEC_END	where\tagSEC_START	t\tagSEC_CONTENT	∈\tagSEC_CONTENT	R\tagSEC_CONTENT	K+1\tagSEC_CONTENT	,\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	t\tagSEC_CONTENT	and\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	t\tagSEC_CONTENT	∈\tagSEC_CONTENT	R\tagSEC_CONTENT	2K+1\tagSEC_CONTENT	,\tagSEC_CONTENT	indicating\tagSEC_CONTENT	the\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	represented\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	.\tagSEC_CONTENT	y\tagSEC_CONTENT	,\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	y\tagSEC_CONTENT	and\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	y\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	estimated\tagSEC_CONTENT	probabilities\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	class\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	section\tagSEC_CONTENT	2.4\tagSEC_CONTENT	.\tagSEC_CONTENT	θ\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	model\tagSEC_CONTENT	parameters\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	learned\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	λ\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagtask	regularization\tagtask	coefficient\tagtask	.\tagSEC_END	where\tagSEC_START	α\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagtask	fraction\tagtask	of\tagSEC_CONTENT	the\tagSEC_CONTENT	composition\tagSEC_CONTENT	of\tagSEC_CONTENT	distributions\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	value\tagSEC_CONTENT	0.65\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	validation\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	During\tagSEC_CONTENT	the\tagtask	implementation\tagtask	of\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	,\tagSEC_CONTENT	elements\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	class\tagSEC_CONTENT	distributions\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	position\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	Cause\tagSEC_CONTENT	-\tagSEC_CONTENT	Effect(e\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	y\tagSEC_CONTENT	should\tagSEC_CONTENT	correspond\tagSEC_CONTENT	to\tagSEC_CONTENT	Cause\tagSEC_CONTENT	-\tagSEC_CONTENT	Effect(e\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	y\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	apply\tagSEC_CONTENT	a\tagSEC_CONTENT	function\tagSEC_CONTENT	z\tagSEC_CONTENT	to\tagSEC_CONTENT	transform\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	y\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	forward\tagSEC_CONTENT	distribution\tagSEC_CONTENT	like\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	y\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	We\tagSEC_START	evaluated\tagSEC_CONTENT	our\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	Task\tagdataset	8\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	established\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	The\tagSEC_CONTENT	dataset\tagSEC_CONTENT	has\tagSEC_CONTENT	(\tagSEC_CONTENT	K+1)=10\tagSEC_CONTENT	distinguished\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	follows\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Cause\tagSEC_CONTENT	-\tagSEC_CONTENT	Effect\tagSEC_END	The\tagSEC_START	former\tagSEC_CONTENT	K=9\tagSEC_CONTENT	relations\tagSEC_CONTENT	are\tagSEC_CONTENT	directed\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	the\tagSEC_CONTENT	Other\tagSEC_CONTENT	class\tagSEC_CONTENT	is\tagSEC_CONTENT	undirected\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	have\tagSEC_CONTENT	(\tagSEC_CONTENT	2K+1)=19\tagSEC_CONTENT	different\tagSEC_CONTENT	classes\tagSEC_CONTENT	for\tagSEC_CONTENT	10\tagtask	relations\tagtask	.\tagSEC_CONTENT	All\tagSEC_CONTENT	baseline\tagSEC_CONTENT	systems\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	official\tagSEC_CONTENT	macroaveraged\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	model\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	official\tagSEC_CONTENT	measurement\tagSEC_CONTENT	excludes\tagSEC_CONTENT	the\tagSEC_CONTENT	Other\tagSEC_CONTENT	relation\tagSEC_CONTENT	.\tagSEC_END	Hyperparameter\tagSECTITLE_START	Settings\tagSECTITLE_END	In\tagSEC_START	our\tagSEC_CONTENT	experiment\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	were\tagSEC_CONTENT	200-dimensional\tagSEC_CONTENT	as\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	trained\tagSEC_CONTENT	on\tagSEC_CONTENT	Gigaword\tagSEC_CONTENT	with\tagSEC_CONTENT	word2vec\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	Embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagtask	are\tagSEC_CONTENT	50-dimensional\tagSEC_CONTENT	and\tagSEC_CONTENT	initialized\tagSEC_CONTENT	randomly\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	hidden\tagSEC_CONTENT	layers\tagSEC_CONTENT	in\tagSEC_CONTENT	each\tagSEC_CONTENT	channel\tagSEC_CONTENT	had\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	units\tagSEC_CONTENT	as\tagSEC_CONTENT	their\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	(\tagSEC_CONTENT	200\tagSEC_CONTENT	or\tagSEC_CONTENT	50\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	convolution\tagSEC_CONTENT	layer\tagSEC_CONTENT	was\tagSEC_CONTENT	200-dimensional\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	above\tagSEC_CONTENT	values\tagSEC_CONTENT	were\tagSEC_CONTENT	chosen\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_END	As\tagSEC_START	we\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relation\tagSEC_CONTENT	r\tagSEC_CONTENT	"\tagSEC_END	Experiment\tagSEC_START	results\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	BR\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	is\tagSEC_CONTENT	improved\tagSEC_CONTENT	if\tagSEC_CONTENT	rand\tagSEC_CONTENT	r\tagSEC_CONTENT	−1\tagSEC_CONTENT	correspond\tagSEC_CONTENT	to\tagSEC_CONTENT	different\tagSEC_CONTENT	relations\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	a\tagSEC_CONTENT	same\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	notice\tagSEC_CONTENT	that\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	contain\tagSEC_CONTENT	much\tagSEC_CONTENT	fewer\tagSEC_CONTENT	symbols\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	contained\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	initialize\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	randomly\tagSEC_CONTENT	for\tagSEC_CONTENT	they\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	adequately\tagSEC_CONTENT	tuned\tagSEC_CONTENT	during\tagSEC_CONTENT	supervised\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	add\tagSEC_CONTENT	l\tagSEC_CONTENT	2\tagSEC_CONTENT	penalty\tagSEC_CONTENT	for\tagSEC_CONTENT	weights\tagSEC_CONTENT	with\tagSEC_CONTENT	coefficient\tagSEC_CONTENT	10\tagSEC_CONTENT	−5\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	dropout\tagSEC_CONTENT	of\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	with\tagSEC_CONTENT	rate\tagSEC_CONTENT	0.5\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	applied\tagSEC_CONTENT	AdaDelta\tagSEC_CONTENT	for\tagSEC_CONTENT	optimization\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	gradients\tagSEC_CONTENT	are\tagSEC_CONTENT	computed\tagSEC_CONTENT	with\tagSEC_CONTENT	an\tagSEC_CONTENT	adaptive\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	.\tagSEC_CONTENT	by\tagSEC_CONTENT	traditional\tagSEC_CONTENT	feature\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_CONTENT	fed\tagSEC_CONTENT	a\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	handcrafted\tagSEC_CONTENT	features\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	SVM\tagSEC_CONTENT	classifier\tagSEC_CONTENT	and\tagSEC_CONTENT	achieve\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	82.2\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	Results\tagSECTITLE_END	Recent\tagSEC_START	performance\tagSEC_CONTENT	improvements\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	are\tagSEC_CONTENT	mostly\tagSEC_CONTENT	achieved\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	help\tagSEC_CONTENT	of\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	built\tagSEC_CONTENT	a\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	and\tagSEC_CONTENT	achieved\tagSEC_CONTENT	a\tagSEC_CONTENT	comparable\tagSEC_CONTENT	performance\tagSEC_CONTENT	with\tagSEC_CONTENT	.\tagSEC_CONTENT	Further\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	extended\tagSEC_CONTENT	their\tagSEC_CONTENT	recursive\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	matrix\tagtask	-\tagtask	vector\tagtask	interaction\tagtask	and\tagSEC_CONTENT	elevated\tagSEC_CONTENT	the\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	to\tagSEC_CONTENT	82.4\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	first\tagSEC_CONTENT	introduced\tagSEC_CONTENT	a\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	gated\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	(\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	into\tagSEC_CONTENT	this\tagSEC_CONTENT	task\tagSEC_CONTENT	and\tagSEC_CONTENT	raised\tagSEC_CONTENT	the\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	to\tagSEC_CONTENT	83.7\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	From\tagSEC_START	the\tagSEC_CONTENT	perspective\tagSEC_CONTENT	of\tagSEC_CONTENT	convolution\tagSEC_CONTENT	,\tagSEC_CONTENT	constructed\tagSEC_CONTENT	a\tagSEC_CONTENT	CNN\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	sequence\tagSEC_CONTENT	;\tagSEC_CONTENT	they\tagSEC_CONTENT	also\tagSEC_CONTENT	integrated\tagSEC_CONTENT	word\tagSEC_CONTENT	position\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	helped\tagSEC_CONTENT	a\tagSEC_CONTENT	lot\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	architecture\tagSEC_CONTENT	.\tagSEC_CONTENT	dos\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	similar\tagSEC_CONTENT	CNN\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	named\tagSEC_CONTENT	CR\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	replacing\tagSEC_CONTENT	the\tagSEC_CONTENT	common\tagSEC_CONTENT	so\tagSEC_CONTENT	f\tagSEC_CONTENT	tmax\tagSEC_CONTENT	cost\tagSEC_CONTENT	function\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	ranking\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	cost\tagSEC_CONTENT	function\tagSEC_CONTENT	.\tagSEC_CONTENT	By\tagSEC_CONTENT	diminishing\tagSEC_CONTENT	the\tagSEC_CONTENT	impact\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	Other\tagSEC_CONTENT	class\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	have\tagSEC_CONTENT	achieved\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	84.1\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	Along\tagSEC_CONTENT	the\tagSEC_CONTENT	line\tagSEC_CONTENT	of\tagSEC_CONTENT	CNNs\tagSEC_CONTENT	,\tagSEC_CONTENT	Xu\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	2015a\tagSEC_CONTENT	)\tagSEC_CONTENT	designed\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	negative\tagSEC_CONTENT	sampling\tagSEC_CONTENT	method\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	introduced\tagSEC_CONTENT	additional\tagSEC_CONTENT	samples\tagSEC_CONTENT	from\tagSEC_CONTENT	other\tagSEC_CONTENT	corpora\tagSEC_CONTENT	like\tagSEC_CONTENT	the\tagSEC_CONTENT	NYT\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	Doing\tagSEC_CONTENT	so\tagSEC_CONTENT	greatly\tagSEC_CONTENT	improved\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	high\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	85.6\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	designed\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	the\tagSEC_CONTENT	subtrees\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	achieve\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	83.6\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	Without\tagSEC_START	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	,\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	Feature\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	Compositional\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	Model\tagSEC_CONTENT	(\tagSEC_CONTENT	FCM\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	combined\tagSEC_CONTENT	unlexicalized\tagSEC_CONTENT	linguistic\tagSEC_CONTENT	contexts\tagSEC_CONTENT	and\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	achieved\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	83.0\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	make\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	three\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	information\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	:\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	NER\tagSEC_CONTENT	features\tagSEC_CONTENT	and\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	hypernyms\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	model\tagSEC_CONTENT	yields\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	86.3\tagSEC_CONTENT	%\tagSEC_CONTENT	,\tagSEC_CONTENT	outperforming\tagSEC_CONTENT	existing\tagSEC_CONTENT	competing\tagSEC_CONTENT	approaches\tagSEC_CONTENT	.\tagSEC_CONTENT	Without\tagSEC_CONTENT	using\tagSEC_CONTENT	any\tagSEC_CONTENT	human\tagSEC_CONTENT	-\tagSEC_CONTENT	designed\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	still\tagSEC_CONTENT	achieve\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	85.4\tagSEC_CONTENT	%\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	theart\tagSEC_CONTENT	methods\tagSEC_CONTENT	is\tagSEC_CONTENT	84.1\tagSEC_CONTENT	%\tagSEC_CONTENT	(\tagSEC_CONTENT	dos\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	 \tagSEC_CONTENT	For\tagSEC_CONTENT	a\tagSEC_CONTENT	fair\tagSEC_CONTENT	comparison\tagSEC_CONTENT	,\tagSEC_CONTENT	hyperparameters\tagSEC_CONTENT	are\tagSEC_CONTENT	set\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	validation\tagSEC_CONTENT	dataset\tagSEC_CONTENT	as\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	.\tagSEC_CONTENT	CNN\tagSEC_CONTENT	with\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	positions\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	81.8\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	with\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	only\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	76.6\tagSEC_CONTENT	%\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	proves\tagSEC_CONTENT	that\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	in\tagSEC_CONTENT	SDPs\tagSEC_CONTENT	play\tagSEC_CONTENT	an\tagSEC_CONTENT	important\tagSEC_CONTENT	role\tagSEC_CONTENT	in\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	Two\tagSEC_CONTENT	-\tagSEC_CONTENT	channel\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	concatenates\tagSEC_CONTENT	the\tagSEC_CONTENT	pooling\tagSEC_CONTENT	layers\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	,\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	81.5\tagSEC_CONTENT	%\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	still\tagSEC_CONTENT	lower\tagSEC_CONTENT	than\tagSEC_CONTENT	CNN\tagSEC_CONTENT	.\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	captures\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	dependency\tagSEC_CONTENT	units\tagSEC_CONTENT	by\tagSEC_CONTENT	combining\tagSEC_CONTENT	the\tagSEC_CONTENT	advantages\tagSEC_CONTENT	of\tagSEC_CONTENT	CNN\tagSEC_CONTENT	and\tagSEC_CONTENT	RNN\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	82.4\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	Analysis\tagSECTITLE_END	Model\tagSECTITLE_END	Input\tagSEC_START	,\tagSEC_CONTENT	if\tagSEC_CONTENT	we\tagSEC_CONTENT	inverted\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	of\tagSEC_CONTENT	all\tagSEC_CONTENT	relations\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	observe\tagSEC_CONTENT	a\tagSEC_CONTENT	performance\tagSEC_CONTENT	degradation\tagSEC_CONTENT	of\tagSEC_CONTENT	1.2\tagSEC_CONTENT	%\tagSEC_CONTENT	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	mentioned\tagSEC_CONTENT	in\tagSEC_CONTENT	section\tagSEC_CONTENT	3.1\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	task\tagdataset	8\tagSEC_CONTENT	dataset\tagSEC_CONTENT	contains\tagSEC_CONTENT	an\tagSEC_CONTENT	undirected\tagSEC_CONTENT	class\tagSEC_CONTENT	Other\tagSEC_CONTENT	in\tagSEC_CONTENT	addition\tagSEC_CONTENT	to\tagSEC_CONTENT	9\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations(18\tagSEC_CONTENT	classes\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	natural\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	inversed\tagSEC_CONTENT	Other\tagSEC_CONTENT	relation\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Other\tagSEC_CONTENT	class\tagSEC_CONTENT	itself\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	class\tagSEC_CONTENT	Other\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	indicate\tagSEC_CONTENT	that\tagSEC_CONTENT	relation\tagtask	between\tagSEC_CONTENT	two\tagSEC_CONTENT	nominals\tagSEC_CONTENT	dose\tagSEC_CONTENT	not\tagSEC_CONTENT	belong\tagSEC_CONTENT	to\tagSEC_CONTENT	any\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	9\tagSEC_CONTENT	directed\tagSEC_CONTENT	classes\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	class\tagSEC_CONTENT	Other\tagSEC_CONTENT	is\tagSEC_CONTENT	very\tagSEC_CONTENT	noisy\tagSEC_CONTENT	since\tagSEC_CONTENT	it\tagSEC_CONTENT	groups\tagSEC_CONTENT	many\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	with\tagSEC_CONTENT	different\tagSEC_CONTENT	directions\tagSEC_CONTENT	.\tagSEC_END	On\tagSEC_START	the\tagSEC_CONTENT	basis\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	analysis\tagSEC_CONTENT	above\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	only\tagSEC_CONTENT	inverse\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	of\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	significant\tagSEC_CONTENT	improvement\tagSEC_CONTENT	is\tagSEC_CONTENT	observed\tagSEC_CONTENT	and\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	84.9\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	proves\tagSEC_CONTENT	bidirectional\tagtask	representations\tagtask	provide\tagSEC_CONTENT	more\tagSEC_CONTENT	useful\tagSEC_CONTENT	information\tagSEC_CONTENT	to\tagSEC_CONTENT	classify\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	still\tagSEC_CONTENT	benefits\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	coarse\tagSEC_CONTENT	-\tagSEC_CONTENT	grained\tagSEC_CONTENT	classification\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	help\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	learn\tagSEC_CONTENT	inherent\tagtask	correlation\tagtask	between\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations\tagSEC_CONTENT	with\tagSEC_CONTENT	opposite\tagSEC_CONTENT	directions\tagSEC_CONTENT	.\tagSEC_CONTENT	Compared\tagSEC_CONTENT	with\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	classifying\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	Sand\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	S\tagSEC_CONTENT	into\tagSEC_CONTENT	19\tagSEC_CONTENT	classes\tagSEC_CONTENT	separately\tagSEC_CONTENT	,\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	also\tagSEC_CONTENT	conducts\tagSEC_CONTENT	a\tagSEC_CONTENT	10\tagSEC_CONTENT	classes\tagSEC_CONTENT	(\tagSEC_CONTENT	9\tagSEC_CONTENT	directed\tagSEC_CONTENT	relations\tagSEC_CONTENT	and\tagSEC_CONTENT	Other\tagSEC_CONTENT	)\tagSEC_CONTENT	classification\tagSEC_CONTENT	and\tagSEC_CONTENT	improves\tagSEC_CONTENT	0.5\tagSEC_CONTENT	%\tagSEC_CONTENT	in\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	.\tagSEC_CONTENT	Beyond\tagSEC_CONTENT	the\tagtask	relation\tagtask	classification\tagtask	task\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	believe\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	method\tagSEC_CONTENT	is\tagSEC_CONTENT	general\tagSEC_CONTENT	technique\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	restricted\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	specific\tagSEC_CONTENT	dataset\tagSEC_CONTENT	and\tagSEC_CONTENT	has\tagSEC_CONTENT	the\tagSEC_CONTENT	potential\tagSEC_CONTENT	to\tagSEC_CONTENT	benefit\tagSEC_CONTENT	other\tagSEC_CONTENT	NLP\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Relation\tagSEC_START	classification\tagtask	is\tagSEC_CONTENT	an\tagSEC_CONTENT	important\tagSEC_CONTENT	topic\tagSEC_CONTENT	in\tagSEC_CONTENT	NLP\tagSEC_CONTENT	.\tagSEC_CONTENT	Traditional\tagSEC_CONTENT	Methods\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	mainly\tagSEC_CONTENT	fall\tagSEC_CONTENT	into\tagSEC_CONTENT	three\tagSEC_CONTENT	classes\tagSEC_CONTENT	:\tagSEC_CONTENT	feature\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	,\tagSEC_CONTENT	kernel\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	and\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	feature\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	approaches\tagSEC_CONTENT	,\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	features\tagSEC_CONTENT	are\tagSEC_CONTENT	extracted\tagSEC_CONTENT	and\tagSEC_CONTENT	fed\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_CONTENT	Generally\tagSEC_CONTENT	,\tagSEC_CONTENT	three\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	features\tagSEC_CONTENT	are\tagSEC_CONTENT	often\tagSEC_CONTENT	used\tagSEC_CONTENT	.\tagSEC_CONTENT	Lexical\tagSEC_CONTENT	features\tagSEC_CONTENT	concentrate\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	entities\tagSEC_CONTENT	of\tagSEC_CONTENT	interest\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	POS\tagSEC_CONTENT	.\tagSEC_CONTENT	Syntactic\tagSEC_CONTENT	features\tagSEC_CONTENT	include\tagSEC_CONTENT	chunking\tagSEC_CONTENT	,\tagSEC_CONTENT	parse\tagSEC_CONTENT	trees\tagSEC_CONTENT	,\tagSEC_CONTENT	etc\tagSEC_CONTENT	.\tagSEC_CONTENT	Semantic\tagSEC_CONTENT	features\tagSEC_CONTENT	are\tagSEC_CONTENT	exemplified\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	concept\tagSEC_CONTENT	hierarchy\tagSEC_CONTENT	,\tagSEC_CONTENT	entity\tagSEC_CONTENT	class\tagSEC_CONTENT	.\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	maximum\tagSEC_CONTENT	entropy\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	feature\tagSEC_CONTENT	combination\tagSEC_CONTENT	.\tagSEC_CONTENT	collected\tagSEC_CONTENT	various\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	lexical\tagSEC_CONTENT	,\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	semantic\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	kernel\tagSEC_CONTENT	based\tagSEC_CONTENT	methods\tagSEC_CONTENT	,\tagSEC_CONTENT	similarity\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	data\tagSEC_CONTENT	samples\tagSEC_CONTENT	is\tagSEC_CONTENT	measured\tagSEC_CONTENT	without\tagSEC_CONTENT	explicit\tagSEC_CONTENT	feature\tagSEC_CONTENT	representation\tagSEC_CONTENT	.\tagSEC_CONTENT	designed\tagSEC_CONTENT	a\tagSEC_CONTENT	kernel\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	by\tagSEC_CONTENT	observing\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagtask	relation\tagtask	strongly\tagSEC_CONTENT	relies\tagSEC_CONTENT	on\tagSEC_CONTENT	SDPs\tagSEC_CONTENT	.\tagSEC_CONTENT	provided\tagSEC_CONTENT	a\tagSEC_CONTENT	systematic\tagSEC_CONTENT	analysis\tagSEC_CONTENT	of\tagSEC_CONTENT	several\tagSEC_CONTENT	kernels\tagSEC_CONTENT	and\tagSEC_CONTENT	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	relation\tagtask	extraction\tagtask	can\tagSEC_CONTENT	benefit\tagSEC_CONTENT	from\tagSEC_CONTENT	combining\tagSEC_CONTENT	convolution\tagSEC_CONTENT	kernel\tagSEC_CONTENT	and\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_CONTENT	combined\tagSEC_CONTENT	structural\tagSEC_CONTENT	information\tagSEC_CONTENT	and\tagSEC_CONTENT	semantic\tagtask	information\tagtask	in\tagSEC_CONTENT	a\tagSEC_CONTENT	tree\tagSEC_CONTENT	kernel\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	potential\tagSEC_CONTENT	difficulty\tagSEC_CONTENT	of\tagSEC_CONTENT	kernel\tagSEC_CONTENT	methods\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	all\tagtask	data\tagtask	information\tagtask	is\tagSEC_CONTENT	completely\tagSEC_CONTENT	summarized\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	kernel\tagSEC_CONTENT	function\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	thus\tagSEC_CONTENT	designing\tagSEC_CONTENT	an\tagSEC_CONTENT	effective\tagSEC_CONTENT	kernel\tagSEC_CONTENT	becomes\tagSEC_CONTENT	crucial\tagSEC_CONTENT	.\tagSEC_END	Recently\tagSEC_START	,\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	are\tagSEC_CONTENT	playing\tagSEC_CONTENT	an\tagSEC_CONTENT	important\tagSEC_CONTENT	role\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	introduced\tagSEC_CONTENT	a\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	model\tagSEC_CONTENT	that\tagSEC_CONTENT	assigns\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	-\tagSEC_CONTENT	vector\tagSEC_CONTENT	representation\tagSEC_CONTENT	to\tagSEC_CONTENT	every\tagSEC_CONTENT	node\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	parse\tagSEC_CONTENT	tree\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	compositional\tagSEC_CONTENT	vector\tagSEC_CONTENT	representations\tagSEC_CONTENT	for\tagSEC_CONTENT	sentences\tagSEC_CONTENT	of\tagSEC_CONTENT	arbitrary\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	type\tagSEC_CONTENT	and\tagSEC_CONTENT	length\tagSEC_CONTENT	.\tagSEC_END	Convolutional\tagSEC_START	neural\tagSEC_CONTENT	works\tagSEC_CONTENT	are\tagSEC_CONTENT	widely\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	an\tagSEC_CONTENT	approach\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	where\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	are\tagSEC_CONTENT	learned\tagSEC_CONTENT	through\tagSEC_CONTENT	a\tagSEC_CONTENT	CNN\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	has\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	and\tagSEC_CONTENT	position\tagSEC_CONTENT	features\tagSEC_CONTENT	as\tagSEC_CONTENT	its\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	parallel\tagSEC_CONTENT	,\tagSEC_CONTENT	lexical\tagSEC_CONTENT	features\tagSEC_CONTENT	were\tagSEC_CONTENT	extracted\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	given\tagSEC_CONTENT	nouns\tagSEC_CONTENT	.\tagSEC_CONTENT	dos\tagSEC_CONTENT	Santos\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	2015\tagSEC_CONTENT	)\tagSEC_CONTENT	tackled\tagSEC_CONTENT	the\tagtask	relation\tagtask	classification\tagtask	task\tagtask	using\tagSEC_CONTENT	a\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	and\tagSEC_CONTENT	proposed\tagSEC_CONTENT	anew\tagSEC_CONTENT	pairwise\tagSEC_CONTENT	ranking\tagSEC_CONTENT	loss\tagSEC_CONTENT	function\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	achieved\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	result\tagSEC_CONTENT	in\tagSEC_CONTENT	SemEval-2010\tagdataset	Task\tagdataset	8\tagSEC_CONTENT	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	Factor\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	Compositional\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	Model\tagSEC_CONTENT	(\tagSEC_CONTENT	FCM\tagSEC_CONTENT	)\tagSEC_CONTENT	by\tagSEC_CONTENT	deriving\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	and\tagSEC_CONTENT	substructure\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	from\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	dependency\tagSEC_CONTENT	trees\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	achieved\tagSEC_CONTENT	slightly\tagSEC_CONTENT	higher\tagSEC_CONTENT	accuracy\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	dataset\tagSEC_CONTENT	than\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	only\tagSEC_CONTENT	when\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	.\tagSEC_END	Nowadays\tagSEC_START	,\tagSEC_CONTENT	many\tagSEC_CONTENT	works\tagSEC_CONTENT	concentrate\tagSEC_CONTENT	on\tagSEC_CONTENT	extracting\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	learned\tagSEC_CONTENT	robust\tagtask	relation\tagtask	representations\tagtask	from\tagSEC_CONTENT	SDP\tagSEC_CONTENT	through\tagSEC_CONTENT	a\tagSEC_CONTENT	CNN\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	straightforward\tagSEC_CONTENT	negative\tagSEC_CONTENT	sampling\tagSEC_CONTENT	strategy\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	the\tagSEC_CONTENT	assignment\tagSEC_CONTENT	of\tagSEC_CONTENT	subjects\tagSEC_CONTENT	and\tagSEC_CONTENT	objects\tagSEC_CONTENT	.\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	recursive\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	designed\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	the\tagSEC_CONTENT	subtrees\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	CNN\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	features\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	.\tagSEC_CONTENT	picked\tagSEC_CONTENT	up\tagSEC_CONTENT	heterogeneous\tagSEC_CONTENT	information\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	left\tagSEC_CONTENT	and\tagSEC_CONTENT	right\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	path\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	respectively\tagSEC_CONTENT	,\tagSEC_CONTENT	leveraging\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	with\tagSEC_CONTENT	long\tagSEC_CONTENT	short\tagSEC_CONTENT	term\tagSEC_CONTENT	memory\tagSEC_CONTENT	units\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	propose\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	pickup\tagSEC_CONTENT	bidirectional\tagtask	information\tagtask	with\tagSEC_CONTENT	a\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	and\tagSEC_CONTENT	CNN\tagSEC_CONTENT	.\tagSEC_END	763\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	proposed\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	The\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	RCNNs\tagSEC_CONTENT	,\tagSEC_CONTENT	learns\tagSEC_CONTENT	features\tagSEC_CONTENT	along\tagSEC_CONTENT	SDP\tagSEC_CONTENT	and\tagSEC_CONTENT	inversely\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	Information\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	a\tagSEC_CONTENT	two\tagSEC_CONTENT	-\tagSEC_CONTENT	channel\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	units\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	features\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	units\tagSEC_CONTENT	in\tagSEC_CONTENT	SDP\tagSEC_CONTENT	are\tagSEC_CONTENT	extracted\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	convolution\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	demonstrate\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	by\tagSEC_CONTENT	evaluating\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	SemEval-2010\tagdataset	relation\tagdataset	classification\tagdataset	task\tagdataset	.\tagSEC_CONTENT	RCNN\tagSEC_CONTENT	achieves\tagSEC_CONTENT	a\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	at\tagSEC_CONTENT	learning\tagSEC_CONTENT	features\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	,\tagSEC_CONTENT	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	some\tagSEC_CONTENT	common\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	significant\tagSEC_CONTENT	improvement\tagSEC_CONTENT	is\tagSEC_CONTENT	observed\tagSEC_CONTENT	when\tagSEC_CONTENT	BRCNN\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	,\tagSEC_CONTENT	outperforming\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_END	
1703.00572	title\tagSECTITLE_END	Structural\tagSEC_START	Embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	Syntactic\tagSEC_CONTENT	Trees\tagSEC_CONTENT	for\tagSEC_CONTENT	Machine\tagSEC_CONTENT	Comprehension\tagSEC_END	abstract\tagSECTITLE_END	Deep\tagSEC_START	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	for\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	typically\tagSEC_CONTENT	utilizes\tagSEC_CONTENT	only\tagSEC_CONTENT	word\tagSEC_CONTENT	or\tagSEC_CONTENT	character\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	without\tagSEC_CONTENT	explicitly\tagSEC_CONTENT	taking\tagSEC_CONTENT	advantage\tagSEC_CONTENT	of\tagSEC_CONTENT	structured\tagSEC_CONTENT	linguistic\tagSEC_CONTENT	information\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	constituency\tagSEC_CONTENT	trees\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	trees\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	trees\tagSEC_CONTENT	(\tagSEC_CONTENT	SEST\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	framework\tagSEC_CONTENT	to\tagSEC_CONTENT	utilize\tagSEC_CONTENT	structured\tagSEC_CONTENT	information\tagSEC_CONTENT	and\tagSEC_CONTENT	encode\tagSEC_CONTENT	them\tagmetric	into\tagSEC_CONTENT	vector\tagSEC_CONTENT	representations\tagSEC_CONTENT	that\tagSEC_CONTENT	can\tagSEC_CONTENT	boost\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	neu\tagSEC_CONTENT	-\tagSEC_CONTENT	ral\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	accurately\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	boundaries\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentences\tagSEC_CONTENT	and\tagSEC_CONTENT	extract\tagSEC_CONTENT	answers\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	syntactically\tagSEC_CONTENT	coherent\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	Reading\tagSEC_START	comprehension\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	SQuAD\tagdataset	(\tagSEC_CONTENT	)\tagSEC_CONTENT	or\tagSEC_CONTENT	NewsQA\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	requires\tagSEC_CONTENT	identifying\tagSEC_CONTENT	a\tagSEC_CONTENT	span\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	given\tagSEC_CONTENT	context\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	extension\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	traditional\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	aiming\tagSEC_CONTENT	at\tagSEC_CONTENT	responding\tagSEC_CONTENT	questions\tagSEC_CONTENT	posed\tagSEC_CONTENT	by\tagSEC_CONTENT	human\tagSEC_CONTENT	with\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	Many\tagSEC_CONTENT	works\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	proposed\tagSEC_CONTENT	to\tagSEC_CONTENT	leverage\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	for\tagSEC_CONTENT	such\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	most\tagSEC_CONTENT	of\tagSEC_CONTENT	which\tagSEC_CONTENT	involve\tagSEC_CONTENT	learning\tagSEC_CONTENT	the\tagSEC_CONTENT	query\tagSEC_CONTENT	-\tagSEC_CONTENT	aware\tagSEC_CONTENT	context\tagSEC_CONTENT	representations\tagSEC_CONTENT	(;\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	based\tagSEC_CONTENT	methods\tagSEC_CONTENT	demonstrated\tagSEC_CONTENT	great\tagSEC_CONTENT	potentials\tagSEC_CONTENT	for\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	,\tagSEC_CONTENT	none\tagSEC_CONTENT	them\tagSEC_CONTENT	take\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentences\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	con-\tagSEC_CONTENT	*\tagSEC_CONTENT	Authors\tagSEC_CONTENT	contributed\tagSEC_CONTENT	equally\tagSEC_CONTENT	to\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	.\tagSEC_CONTENT	stituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	into\tagSEC_CONTENT	consideration\tagSEC_CONTENT	.\tagSEC_CONTENT	Such\tagSEC_CONTENT	techniques\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	proven\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	useful\tagSEC_CONTENT	in\tagSEC_CONTENT	many\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	understanding\tagSEC_CONTENT	tasks\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	past\tagSEC_CONTENT	and\tagSEC_CONTENT	illustrated\tagSEC_CONTENT	noticeable\tagSEC_CONTENT	improvements\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	work\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	adopt\tagSEC_CONTENT	similar\tagSEC_CONTENT	ideas\tagSEC_CONTENT	but\tagSEC_CONTENT	apply\tagSEC_CONTENT	them\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	neural\tagSEC_CONTENT	attention\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	defines\tagSEC_CONTENT	internal\tagSEC_CONTENT	nodes\tagSEC_CONTENT	and\tagSEC_CONTENT	terminal\tagSEC_CONTENT	nodes\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	phrase\tagSEC_CONTENT	structure\tagSEC_CONTENT	grammars\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	actual\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	illustrates\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	architect\tagSEC_CONTENT	or\tagSEC_CONTENT	engineer\tagSEC_CONTENT	acts\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	coordinator\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	architect\tagSEC_CONTENT	or\tagSEC_CONTENT	engineer\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	coordinator\tagSEC_CONTENT	"\tagSEC_CONTENT	are\tagSEC_CONTENT	labeled\tagSEC_CONTENT	as\tagSEC_CONTENT	noun\tagSEC_CONTENT	phrases\tagSEC_CONTENT	(\tagSEC_CONTENT	"\tagSEC_CONTENT	NP\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	critical\tagSEC_CONTENT	for\tagSEC_CONTENT	answering\tagSEC_CONTENT	the\tagtask	question\tagtask	below\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	asks\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	name\tagSEC_CONTENT	of\tagSEC_CONTENT	certain\tagSEC_CONTENT	occupation\tagSEC_CONTENT	that\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	best\tagSEC_CONTENT	answered\tagSEC_CONTENT	using\tagSEC_CONTENT	an\tagSEC_CONTENT	noun\tagSEC_CONTENT	phrase\tagSEC_CONTENT	.\tagSEC_CONTENT	Utilizing\tagSEC_CONTENT	the\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	constituency\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	reduce\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	space\tagSEC_CONTENT	and\tagSEC_CONTENT	help\tagSEC_CONTENT	the\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	answer\tagSEC_CONTENT	.\tagSEC_END	Whose\tagSEC_START	role\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	design\tagSEC_CONTENT	the\tagSEC_CONTENT	works\tagSEC_CONTENT	,\tagSEC_CONTENT	prepare\tagSEC_CONTENT	the\tagSEC_CONTENT	specifications\tagSEC_CONTENT	and\tagSEC_CONTENT	produce\tagSEC_CONTENT	construction\tagtask	drawings\tagtask	,\tagSEC_CONTENT	administer\tagSEC_CONTENT	the\tagSEC_CONTENT	contract\tagSEC_CONTENT	,\tagSEC_CONTENT	tender\tagSEC_CONTENT	the\tagSEC_CONTENT	works\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	manage\tagSEC_CONTENT	the\tagSEC_CONTENT	works\tagSEC_CONTENT	from\tagSEC_CONTENT	inception\tagSEC_CONTENT	to\tagSEC_CONTENT	completion\tagSEC_CONTENT	?\tagSEC_END	On\tagSEC_START	the\tagSEC_CONTENT	other\tagSEC_CONTENT	hand\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	constructed\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	structure\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	displays\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	for\tagSEC_CONTENT	sentence\tagSEC_END	The\tagSEC_START	Annual\tagSEC_CONTENT	Conference\tagSEC_CONTENT	,\tagSEC_CONTENT	roughly\tagSEC_CONTENT	the\tagSEC_CONTENT	equivalent\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	diocese\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Anglican\tagSEC_CONTENT	Communion\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	Roman\tagSEC_CONTENT	Catholic\tagSEC_CONTENT	Church\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	synod\tagSEC_CONTENT	in\tagSEC_CONTENT	some\tagSEC_CONTENT	Lutheran\tagSEC_CONTENT	denominations\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	Evangelical\tagSEC_CONTENT	Lutheran\tagSEC_CONTENT	Church\tagSEC_CONTENT	in\tagSEC_CONTENT	America\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	unit\tagSEC_CONTENT	of\tagSEC_CONTENT	organization\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	UMC\tagSEC_CONTENT	.\tagSEC_CONTENT	"\tagSEC_CONTENT	The\tagSEC_CONTENT	Annual\tagSEC_CONTENT	Conference\tagSEC_CONTENT	"\tagSEC_CONTENT	being\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	of\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	unit\tagSEC_CONTENT	of\tagSEC_CONTENT	organization\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	UMC\tagSEC_CONTENT	"\tagSEC_CONTENT	provides\tagSEC_CONTENT	a\tagSEC_CONTENT	critical\tagSEC_CONTENT	clue\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	skip\tagSEC_CONTENT	over\tagSEC_CONTENT	a\tagSEC_CONTENT	large\tagSEC_CONTENT	chunk\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	when\tagSEC_CONTENT	answering\tagSEC_CONTENT	the\tagtask	question\tagtask	"\tagSEC_CONTENT	What\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	unit\tagSEC_CONTENT	of\tagSEC_CONTENT	organization\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	UMC\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	we\tagSEC_CONTENT	show\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	analysis\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	adding\tagSEC_CONTENT	dependency\tagSEC_CONTENT	information\tagSEC_CONTENT	dramatically\tagSEC_CONTENT	helps\tagSEC_CONTENT	identify\tagSEC_CONTENT	dependency\tagSEC_CONTENT	structures\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	otherwise\tagSEC_CONTENT	difficult\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	Structural\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	Syntactic\tagSEC_CONTENT	Trees\tagSEC_CONTENT	(\tagSEC_CONTENT	SEST\tagSEC_CONTENT	)\tagSEC_CONTENT	that\tagSEC_CONTENT	encode\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	structured\tagSEC_CONTENT	by\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	into\tagSEC_CONTENT	neural\tagSEC_CONTENT	attention\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagtask	question\tagtask	answering\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	dataset\tagSEC_CONTENT	illustrates\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	helps\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	choose\tagSEC_CONTENT	the\tagSEC_CONTENT	answers\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	both\tagSEC_CONTENT	succinct\tagSEC_CONTENT	and\tagSEC_CONTENT	grammatically\tagSEC_CONTENT	coherent\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	boosted\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	qualitative\tagSEC_CONTENT	studies\tagSEC_CONTENT	and\tagSEC_CONTENT	numerical\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	focus\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	show\tagSEC_CONTENT	adding\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	can\tagSEC_CONTENT	improve\tagSEC_CONTENT	baseline\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	directly\tagSEC_CONTENT	compare\tagSEC_CONTENT	to\tagSEC_CONTENT	published\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	the\tagSEC_CONTENT	methods\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	paper\tagSEC_CONTENT	are\tagSEC_CONTENT	demonstrated\tagSEC_CONTENT	using\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	trees\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	note\tagSEC_CONTENT	that\tagSEC_CONTENT	similar\tagSEC_CONTENT	approaches\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	other\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	tree\tagSEC_CONTENT	structured\tagSEC_CONTENT	information\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	graphs\tagSEC_CONTENT	and\tagSEC_CONTENT	ontology\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	Methodology\tagSECTITLE_END	The\tagSEC_START	general\tagSEC_CONTENT	framework\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	illustrated\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	question\tagtask	while\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	is\tagSEC_CONTENT	two\tagSEC_CONTENT	indices\tagSEC_CONTENT	begin\tagSEC_CONTENT	and\tagSEC_CONTENT	end\tagSEC_CONTENT	which\tagSEC_CONTENT	indicate\tagSEC_CONTENT	the\tagSEC_CONTENT	begin\tagSEC_CONTENT	and\tagSEC_CONTENT	end\tagSEC_CONTENT	indices\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	input\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	contains\tagSEC_CONTENT	two\tagSEC_CONTENT	parts\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	/\tagSEC_CONTENT	character\tagSEC_CONTENT	model\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	shaded\tagSEC_CONTENT	portion\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	represents\tagSEC_CONTENT	the\tagSEC_CONTENT	encoded\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	of\tagSEC_CONTENT	both\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	question\tagtask	that\tagSEC_CONTENT	are\tagSEC_CONTENT	fed\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	gain\tagSEC_CONTENT	an\tagSEC_CONTENT	insight\tagSEC_CONTENT	of\tagSEC_CONTENT	how\tagSEC_CONTENT	the\tagSEC_CONTENT	encoding\tagSEC_CONTENT	works\tagSEC_CONTENT	,\tagSEC_CONTENT	consider\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	which\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	four\tagSEC_CONTENT	nodes\tagSEC_CONTENT	(\tagSEC_CONTENT	o1\tagSEC_CONTENT	,\tagSEC_CONTENT	o2\tagSEC_CONTENT	,\tagSEC_CONTENT	o3\tagSEC_CONTENT	,\tagSEC_CONTENT	o4\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	specific\tagSEC_CONTENT	word\tagSEC_CONTENT	is\tagSEC_CONTENT	represented\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	nodes\tagSEC_CONTENT	from\tagSEC_CONTENT	its\tagSEC_CONTENT	leave\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	root\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	cover\tagSEC_CONTENT	how\tagSEC_CONTENT	this\tagSEC_CONTENT	process\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3.1.1\tagSEC_CONTENT	and\tagSEC_CONTENT	3.1.2\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	input\tagSEC_CONTENT	that\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	fed\tagSEC_CONTENT	into\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	information\tagSEC_CONTENT	for\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	characters\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	There\tagSEC_CONTENT	are\tagSEC_CONTENT	many\tagSEC_CONTENT	ways\tagSEC_CONTENT	to\tagSEC_CONTENT	convert\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	highdimensional\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	choose\tagSEC_CONTENT	GloVe\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	a\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	and\tagSEC_CONTENT	fixed\tagSEC_CONTENT	vector\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	Instead\tagSEC_CONTENT	of\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	embedding\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	Convolutional\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Networks\tagSEC_CONTENT	(\tagSEC_CONTENT	CNN\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	character\tagSEC_CONTENT	level\tagSEC_CONTENT	embedding\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	values\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	changed\tagSEC_CONTENT	during\tagSEC_CONTENT	training\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	integrate\tagSEC_CONTENT	both\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	feed\tagSEC_CONTENT	the\tagSEC_CONTENT	concatenation\tagSEC_CONTENT	of\tagSEC_CONTENT	them\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	inputs\tagSEC_CONTENT	are\tagSEC_CONTENT	processed\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	to\tagSEC_CONTENT	form\tagSEC_CONTENT	more\tagSEC_CONTENT	abstract\tagSEC_CONTENT	representations\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	we\tagSEC_CONTENT	choose\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	layer\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	Long\tagSEC_CONTENT	Short\tagSEC_CONTENT	Term\tagSEC_CONTENT	Memory\tagSEC_CONTENT	(\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	more\tagSEC_CONTENT	abstract\tagSEC_CONTENT	representations\tagSEC_CONTENT	for\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	contexts\tagSEC_CONTENT	and\tagSEC_CONTENT	questions\tagSEC_CONTENT	.\tagSEC_END	After\tagSEC_START	that\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	employ\tagSEC_CONTENT	an\tagSEC_CONTENT	attention\tagSEC_CONTENT	layer\tagSEC_CONTENT	to\tagSEC_CONTENT	fuse\tagSEC_CONTENT	information\tagSEC_CONTENT	from\tagSEC_CONTENT	both\tagSEC_CONTENT	the\tagSEC_CONTENT	contexts\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagtask	questions\tagtask	.\tagSEC_CONTENT	Various\tagSEC_CONTENT	matching\tagSEC_CONTENT	mechanisms\tagSEC_CONTENT	using\tagSEC_CONTENT	attentions\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	extensively\tagSEC_CONTENT	studied\tagSEC_CONTENT	for\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	tasks\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	Attention\tagSEC_CONTENT	flow\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	 \tagSEC_CONTENT	We\tagSEC_CONTENT	then\tagSEC_CONTENT	feed\tagSEC_CONTENT	the\tagSEC_CONTENT	concatenated\tagSEC_CONTENT	vectors\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	stacked\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	with\tagSEC_CONTENT	two\tagSEC_CONTENT	layers\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	context\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	note\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	trees\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	easily\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	any\tagSEC_CONTENT	attention\tagSEC_CONTENT	approaches\tagSEC_CONTENT	mentioned\tagSEC_CONTENT	above\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	task\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	phrase\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	two\tagSEC_CONTENT	softmax\tagSEC_CONTENT	functions\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	layer\tagSEC_CONTENT	to\tagSEC_CONTENT	predict\tagSEC_CONTENT	the\tagSEC_CONTENT	begin\tagSEC_CONTENT	and\tagSEC_CONTENT	end\tagSEC_CONTENT	indices\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	phrase\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_END	Structural\tagSECTITLE_START	Embedding\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Syntactic\tagSECTITLE_CONTENT	Tree\tagSECTITLE_END	We\tagSEC_START	detail\tagSEC_CONTENT	the\tagSEC_CONTENT	procedures\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagSEC_CONTENT	alternative\tagSEC_CONTENT	implementation\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	methods\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	Structural\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	Constituency\tagSEC_CONTENT	Trees\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	SECT\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	Structural\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	Dependency\tagSEC_CONTENT	Trees\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	assume\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	has\tagSEC_CONTENT	already\tagSEC_CONTENT	been\tagSEC_CONTENT	generated\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	step\tagSEC_CONTENT	using\tagSEC_CONTENT	tools\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	Stanford\tagSEC_CONTENT	CoreNLP\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Syntactic\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	We\tagSEC_START	first\tagSEC_CONTENT	extract\tagSEC_CONTENT	a\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	collection\tagSEC_CONTENT	C(p\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	p\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	nodes\tagSEC_CONTENT	{\tagSEC_CONTENT	o\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	d−1\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	d\tagSEC_CONTENT	}\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	parse\tagSEC_CONTENT	tree\tagSEC_CONTENT	T\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	node\tagSEC_CONTENT	oi\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	grammatical\tagSEC_CONTENT	category\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	part\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	speech\tagSEC_CONTENT	tagging\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	dependency\tagSEC_CONTENT	link\tagSEC_CONTENT	label\tagSEC_CONTENT	,\tagSEC_CONTENT	depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	construct\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	thing\tagSEC_CONTENT	we\tagSEC_CONTENT	need\tagSEC_CONTENT	to\tagSEC_CONTENT	do\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	define\tagSEC_CONTENT	a\tagSEC_CONTENT	specific\tagSEC_CONTENT	processing\tagSEC_CONTENT	order\tagSEC_CONTENT	A\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	collection\tagSEC_CONTENT	C(p\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	way\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	extract\tagSEC_CONTENT	a\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	S(p\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	p.\tagSEC_END	Structural\tagSECTITLE_START	Embedding\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Constituency\tagSECTITLE_CONTENT	Trees\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	SECT\tagSECTITLE_CONTENT	)\tagSECTITLE_END	The\tagSEC_START	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	parse\tagSEC_CONTENT	tree\tagSEC_CONTENT	constructed\tagSEC_CONTENT	by\tagSEC_CONTENT	phrase\tagSEC_CONTENT	structure\tagSEC_CONTENT	grammars\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	defines\tagSEC_CONTENT	the\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	hierarchically\tagSEC_CONTENT	construct\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	from\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	bottomup\tagSEC_CONTENT	manner\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	constituency\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	Words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	contexts\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagtask	questions\tagtask	are\tagSEC_CONTENT	represented\tagSEC_CONTENT	by\tagSEC_CONTENT	leaf\tagSEC_CONTENT	nodes\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	terminal\tagSEC_CONTENT	nodes\tagSEC_CONTENT	are\tagSEC_CONTENT	labeled\tagSEC_CONTENT	by\tagSEC_CONTENT	categories\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	grammar\tagSEC_CONTENT	.\tagSEC_CONTENT	Non\tagSEC_CONTENT	-\tagSEC_CONTENT	terminal\tagSEC_CONTENT	nodes\tagSEC_CONTENT	summarize\tagSEC_CONTENT	the\tagSEC_CONTENT	grammatical\tagSEC_CONTENT	function\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	tree\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	an\tagSEC_CONTENT	example\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	with\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	architect\tagSEC_CONTENT	or\tagSEC_CONTENT	engineer\tagSEC_CONTENT	"\tagSEC_CONTENT	being\tagSEC_CONTENT	annotated\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	noun\tagSEC_CONTENT	phrase\tagSEC_CONTENT	(\tagSEC_CONTENT	NP\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	path\tagSEC_CONTENT	originating\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	leaf\tagSEC_CONTENT	node\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	root\tagSEC_CONTENT	node\tagSEC_CONTENT	captures\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	way\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	higher\tagSEC_CONTENT	the\tagSEC_CONTENT	node\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	longer\tagSEC_CONTENT	span\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	the\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	tree\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	node\tagSEC_CONTENT	covers\tagSEC_CONTENT	.\tagSEC_CONTENT	Hence\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	extract\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	S(p\tagSEC_CONTENT	)\tagSEC_CONTENT	fora\tagSEC_CONTENT	leaf\tagSEC_CONTENT	node\tagSEC_CONTENT	p\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	reasonable\tagSEC_CONTENT	to\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	processing\tagSEC_CONTENT	order\tagSEC_CONTENT	A(p\tagSEC_CONTENT	)\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	leaf\tagSEC_CONTENT	pall\tagSEC_CONTENT	the\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	its\tagSEC_CONTENT	root\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	phrase\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	project\tagSEC_CONTENT	coordinator\tagSEC_CONTENT	"\tagSEC_CONTENT	in\tagSEC_CONTENT	is\tagSEC_CONTENT	detected\tagSEC_CONTENT	as\tagSEC_CONTENT	(\tagSEC_CONTENT	NP\tagSEC_CONTENT	,\tagSEC_CONTENT	PP\tagSEC_CONTENT	,\tagSEC_CONTENT	VP\tagSEC_CONTENT	,\tagSEC_CONTENT	S\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	practice\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	usually\tagSEC_CONTENT	take\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	hidden\tagSEC_CONTENT	units\tagSEC_CONTENT	of\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	encoding\tagSEC_CONTENT	mechanisms\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	Bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	the\tagSEC_CONTENT	sequence\tagSEC_CONTENT	state\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	is\tagSEC_CONTENT	indicated\tagSEC_CONTENT	in\tagSEC_CONTENT	(\tagSEC_CONTENT	a\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	set\tagSEC_CONTENT	a\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	to\tagSEC_CONTENT	limit\tagSEC_CONTENT	the\tagSEC_CONTENT	amount\tagSEC_CONTENT	of\tagSEC_CONTENT	information\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	if\tagSEC_CONTENT	we\tagSEC_CONTENT	choose\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	as\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	becomes\tagSEC_CONTENT	(\tagSEC_CONTENT	NP\tagSEC_CONTENT	,\tagSEC_CONTENT	PP\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	process\tagSEC_CONTENT	is\tagSEC_CONTENT	introduced\tagSEC_CONTENT	for\tagSEC_CONTENT	both\tagSEC_CONTENT	performance\tagSEC_CONTENT	and\tagSEC_CONTENT	memory\tagSEC_CONTENT	utilization\tagSEC_CONTENT	consideration\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	discussed\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4.5\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	addition\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	terminal\tagSEC_CONTENT	node\tagSEC_CONTENT	at\tagSEC_CONTENT	a\tagSEC_CONTENT	particular\tagSEC_CONTENT	position\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	defines\tagSEC_CONTENT	the\tagSEC_CONTENT	begin\tagSEC_CONTENT	and\tagSEC_CONTENT	end\tagSEC_CONTENT	indices\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	phrase\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	By\tagSEC_CONTENT	measuring\tagSEC_CONTENT	the\tagSEC_CONTENT	similarity\tagSEC_CONTENT	between\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	se-\tagSEC_CONTENT	Figure\tagSEC_CONTENT	3\tagSEC_CONTENT	:\tagSEC_CONTENT	Model\tagSEC_CONTENT	Framework\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	and\tagSEC_CONTENT	testing\tagSEC_CONTENT	is\tagSEC_CONTENT	built\tagSEC_CONTENT	by\tagSEC_CONTENT	components\tagSEC_CONTENT	with\tagSEC_CONTENT	solid\tagSEC_CONTENT	lines\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	includes\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	attention\tagtask	layer\tagtask	,\tagSEC_CONTENT	and\tagSEC_CONTENT	output\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	shaded\tagSEC_CONTENT	area\tagSEC_CONTENT	highlights\tagSEC_CONTENT	the\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	framework\tagSEC_CONTENT	that\tagSEC_CONTENT	involves\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	Components\tagSEC_CONTENT	with\tagSEC_CONTENT	dashed\tagSEC_CONTENT	lines\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	example\tagSEC_CONTENT	to\tagSEC_CONTENT	illustrate\tagSEC_CONTENT	how\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	is\tagSEC_CONTENT	decoded\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	is\tagSEC_CONTENT	decomposed\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	with\tagSEC_CONTENT	four\tagSEC_CONTENT	nodes\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	fora\tagSEC_CONTENT	specific\tagSEC_CONTENT	word\tagSEC_CONTENT	is\tagSEC_CONTENT	recorded\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	path\tagSEC_CONTENT	from\tagSEC_CONTENT	its\tagSEC_CONTENT	position\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	root\tagSEC_CONTENT	,\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	(\tagSEC_CONTENT	o\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	case\tagSEC_CONTENT	.\tagSEC_CONTENT	quences\tagSEC_CONTENT	S(p\tagSEC_CONTENT	)\tagSEC_CONTENT	extracted\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	p\tagSEC_CONTENT	of\tagSEC_CONTENT	both\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	are\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	locate\tagSEC_CONTENT	the\tagSEC_CONTENT	boundaries\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	span\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	done\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	layer\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_END	Structural\tagSECTITLE_START	Embedding\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_END	Trees\tagSEC_START	(\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	)\tagSEC_CONTENT	The\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	constructed\tagSEC_CONTENT	by\tagSEC_CONTENT	dependency\tagSEC_CONTENT	grammars\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	defines\tagSEC_CONTENT	the\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	connect\tagSEC_CONTENT	words\tagSEC_CONTENT	by\tagSEC_CONTENT	directed\tagSEC_CONTENT	links\tagSEC_CONTENT	that\tagSEC_CONTENT	represent\tagSEC_CONTENT	dependencies\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	dependency\tagSEC_CONTENT	link\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	both\tagSEC_CONTENT	long\tagSEC_CONTENT	and\tagSEC_CONTENT	short\tagSEC_CONTENT	distance\tagSEC_CONTENT	dependencies\tagSEC_CONTENT	of\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	Relations\tagSEC_CONTENT	on\tagSEC_CONTENT	links\tagSEC_CONTENT	vary\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	functions\tagSEC_CONTENT	and\tagSEC_CONTENT	are\tagSEC_CONTENT	labeled\tagSEC_CONTENT	with\tagSEC_CONTENT	different\tagSEC_CONTENT	categories\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	plotted\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	link\tagSEC_CONTENT	from\tagSEC_CONTENT	"\tagSEC_CONTENT	unit\tagSEC_CONTENT	"\tagSEC_CONTENT	to\tagSEC_CONTENT	"\tagSEC_CONTENT	Conference\tagSEC_CONTENT	"\tagSEC_CONTENT	indicates\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	node\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	nominal\tagSEC_CONTENT	subject\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	NSUBJ\tagSEC_CONTENT	)\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	source\tagSEC_CONTENT	node\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	syntactic\tagSEC_CONTENT	collection\tagSEC_CONTENT	C(p\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	is\tagSEC_CONTENT	defined\tagSEC_CONTENT	as\tagSEC_CONTENT	p\tagSEC_CONTENT	's\tagSEC_CONTENT	children\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	represented\tagSEC_CONTENT	by\tagSEC_CONTENT	its\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	concatenated\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	vector\tagSEC_CONTENT	that\tagSEC_CONTENT	uniquely\tagSEC_CONTENT	identifies\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	label\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	processing\tagSEC_CONTENT	order\tagSEC_CONTENT	A(p\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	defined\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	the\tagSEC_CONTENT	dependent\tagSEC_CONTENT	's\tagSEC_CONTENT	original\tagSEC_CONTENT	order\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_END	Take\tagSEC_START	the\tagSEC_CONTENT	word\tagSEC_CONTENT	"\tagSEC_CONTENT	unit\tagSEC_CONTENT	"\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	encode\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	tree\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	indicated\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	tree\tagSEC_CONTENT	,\tagSEC_CONTENT	since\tagSEC_CONTENT	children\tagSEC_CONTENT	are\tagSEC_CONTENT	directly\tagSEC_CONTENT	linked\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	root\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	position\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	sequence\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	encoding\tagSEC_CONTENT	of\tagSEC_CONTENT	C\tagSEC_CONTENT	-\tagSEC_CONTENT	Tree\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	take\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	hidden\tagSEC_CONTENT	states\tagSEC_CONTENT	as\tagSEC_CONTENT	its\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_END	Similar\tagSEC_START	to\tagSEC_CONTENT	SECT\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	window\tagSEC_CONTENT	of\tagSEC_CONTENT	size\tagSEC_CONTENT	l\tagSEC_CONTENT	to\tagSEC_CONTENT	limit\tagSEC_CONTENT	the\tagSEC_CONTENT	amount\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	learning\tagSEC_CONTENT	models\tagSEC_CONTENT	by\tagSEC_CONTENT	choosing\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	l\tagSEC_CONTENT	-\tagSEC_CONTENT	nearest\tagSEC_CONTENT	dependents\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	again\tagSEC_CONTENT	reported\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4.5\tagSEC_CONTENT	.\tagSEC_END	Syntactic\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	Encoding\tagSECTITLE_END	Similar\tagSEC_START	to\tagSEC_CONTENT	previous\tagSEC_CONTENT	work\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	a\tagSEC_CONTENT	variable\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	fixedlength\tagSEC_CONTENT	vector\tagSEC_CONTENT	representation\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	encoder\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	Recurrent\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	RNN\tagSEC_CONTENT	)\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	Convolutional\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	CNN\tagSEC_CONTENT	)\tagSEC_CONTENT	that\tagSEC_CONTENT	learns\tagSEC_CONTENT	a\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	node\tagSEC_CONTENT	such\tagSEC_CONTENT	that\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	nodes\tagSEC_CONTENT	under\tagSEC_CONTENT	similar\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	trees\tagSEC_CONTENT	are\tagSEC_CONTENT	close\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	embedding\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	can\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	as\tagSEC_CONTENT	our\tagSEC_CONTENT	RNN\tagSEC_CONTENT	encoder\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	v\tagSEC_CONTENT	pt\tagSEC_CONTENT	is\tagSEC_CONTENT	updated\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	x\tagSEC_CONTENT	pt\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	t\tagSEC_CONTENT	th\tagSEC_CONTENT	node\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	p\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	vector\tagSEC_CONTENT	that\tagSEC_CONTENT	uniquely\tagSEC_CONTENT	identifies\tagSEC_CONTENT	each\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	node\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	obtain\tagSEC_CONTENT	the\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	given\tagSEC_CONTENT	word\tagSEC_CONTENT	p\tagSEC_CONTENT	,\tagSEC_CONTENT	v\tagSEC_CONTENT	p\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	=\tagSEC_CONTENT	v\tagSEC_CONTENT	p\tagSEC_CONTENT	T\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	.\tagSEC_END	Alternatively\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	also\tagSEC_CONTENT	use\tagSEC_CONTENT	CNN\tagSEC_CONTENT	to\tagSEC_CONTENT	obtain\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	nodes\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	denote\tagSEC_CONTENT	l\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	filter\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	encoder\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	define\tagSEC_CONTENT	x\tagSEC_CONTENT	p\tagSEC_CONTENT	i\tagSEC_CONTENT	:\tagSEC_CONTENT	i+l\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	concatenation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	vectors\tagSEC_CONTENT	from\tagSEC_CONTENT	x\tagSEC_CONTENT	pi\tagSEC_CONTENT	to\tagSEC_CONTENT	x\tagSEC_CONTENT	p\tagSEC_CONTENT	i+l−1\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	filter\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	i\tagSEC_CONTENT	th\tagSEC_CONTENT	element\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	j\tagSEC_CONTENT	th\tagSEC_CONTENT	feature\tagSEC_CONTENT	map\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	obtained\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	we\tagSEC_CONTENT	obtain\tagSEC_CONTENT	the\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	given\tagSEC_CONTENT	word\tagSEC_CONTENT	p\tagSEC_CONTENT	by\tagSEC_CONTENT	v\tagSEC_CONTENT	p\tagSEC_CONTENT	CNN\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	3\tagSEC_CONTENT	.\tagSEC_END	where\tagSEC_START	w\tagSEC_CONTENT	j\tagSEC_CONTENT	and\tagSEC_CONTENT	b\tagSEC_CONTENT	j\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	weight\tagSEC_CONTENT	and\tagSEC_CONTENT	bias\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	j\tagSEC_CONTENT	th\tagSEC_CONTENT	filter\tagSEC_CONTENT	respectively\tagSEC_CONTENT	,\tagSEC_CONTENT	f\tagmetric	is\tagSEC_CONTENT	a\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	activation\tagSEC_CONTENT	function\tagSEC_CONTENT	and\tagSEC_CONTENT	max\tagSEC_CONTENT	row\tagSEC_CONTENT	(\tagSEC_CONTENT	·\tagSEC_CONTENT	)\tagSEC_CONTENT	takes\tagSEC_CONTENT	the\tagSEC_CONTENT	maximum\tagSEC_CONTENT	value\tagSEC_CONTENT	along\tagSEC_CONTENT	rows\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	.\tagSEC_CONTENT	 \tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	Ew\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	for\tagSEC_CONTENT	"\tagSEC_CONTENT	coordinator\tagSEC_CONTENT	"\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	100\tagSEC_CONTENT	dimensions\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	and\tagSEC_CONTENT	each\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	encoded\tagSEC_CONTENT	vector\tagSEC_CONTENT	u\tagSEC_CONTENT	and\tagSEC_CONTENT	v\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	30\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	encode\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	"\tagSEC_CONTENT	unit\tagSEC_CONTENT	"\tagSEC_CONTENT	in\tagSEC_CONTENT	with\tagSEC_CONTENT	its\tagSEC_CONTENT	dependent\tagSEC_CONTENT	nodes\tagSEC_CONTENT	including\tagSEC_CONTENT	"\tagSEC_CONTENT	Conference\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	is\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	basic\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	organization\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	ordered\tagSEC_CONTENT	by\tagSEC_CONTENT	their\tagSEC_CONTENT	positions\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	word\tagSEC_CONTENT	is\tagSEC_CONTENT	represented\tagSEC_CONTENT	with\tagSEC_CONTENT	its\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	to\tagSEC_CONTENT	SECT\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	representation\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	concatenation\tagSEC_CONTENT	[\tagSEC_CONTENT	Ew\tagSEC_CONTENT	;\tagSEC_CONTENT	u\tagSEC_CONTENT	0\tagSEC_CONTENT	;\tagSEC_CONTENT	v\tagSEC_CONTENT	6\tagSEC_CONTENT	]\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	sent\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	layer\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_END	We\tagSEC_START	conducted\tagSEC_CONTENT	systematic\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	dataset\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	compared\tagSEC_CONTENT	our\tagSEC_CONTENT	methods\tagSEC_CONTENT	against\tagSEC_CONTENT	Bi\tagSEC_CONTENT	-\tagSEC_CONTENT	Directional\tagSEC_CONTENT	Attention\tagSEC_CONTENT	Flow\tagSEC_CONTENT	(\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	SEST\tagSEC_CONTENT	models\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	.\tagSEC_END	Preprocessing\tagSECTITLE_END	A\tagSEC_START	couple\tagSEC_CONTENT	of\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	steps\tagSEC_CONTENT	is\tagSEC_CONTENT	performed\tagSEC_CONTENT	to\tagSEC_CONTENT	ensure\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	models\tagSEC_CONTENT	get\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	segmented\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	questions\tagtask	into\tagSEC_CONTENT	sentences\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	NLTK\tagSEC_CONTENT	's\tagSEC_CONTENT	Punkt\tagSEC_CONTENT	sentence\tagSEC_CONTENT	segmenter\tagSEC_CONTENT	.\tagSEC_CONTENT	Words\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sentences\tagSEC_CONTENT	were\tagSEC_CONTENT	then\tagSEC_CONTENT	converted\tagSEC_CONTENT	into\tagSEC_CONTENT	symbols\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	PTB\tagSEC_CONTENT	Tokenizer\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	Syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	including\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	and\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	trees\tagSEC_CONTENT	were\tagSEC_CONTENT	acquired\tagSEC_CONTENT	by\tagSEC_CONTENT	Stanford\tagSEC_CONTENT	CoreNLP\tagSEC_CONTENT	utilities\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	parser\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	collected\tagSEC_CONTENT	constituent\tagSEC_CONTENT	relations\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	relations\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	tree\tagSEC_CONTENT	annotation\tagSEC_CONTENT	and\tagSEC_CONTENT	enhanced\tagSEC_CONTENT	dependencies\tagSEC_CONTENT	annotation\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	generate\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	removed\tagSEC_CONTENT	sequences\tagSEC_CONTENT	whose\tagSEC_CONTENT	first\tagSEC_CONTENT	node\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	punctuation\tagSEC_CONTENT	(\tagSEC_CONTENT	"\tagSEC_CONTENT	$\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	:\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	#\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	"\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	"\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	")\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	use\tagSEC_CONTENT	dependency\tagSEC_CONTENT	labels\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	removed\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	subcategories\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	nmod\tagSEC_CONTENT	:\tagSEC_CONTENT	poss\tagSEC_CONTENT	"\tagSEC_CONTENT	⇒\tagSEC_CONTENT	"\tagSEC_CONTENT	nmod\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Experiment\tagSECTITLE_START	Setting\tagSECTITLE_END	We\tagSEC_START	run\tagSEC_CONTENT	our\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	machine\tagSEC_CONTENT	that\tagSEC_CONTENT	contains\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	GTX\tagSEC_CONTENT	1080\tagSEC_CONTENT	GPU\tagSEC_CONTENT	with\tagSEC_CONTENT	8\tagSEC_CONTENT	GB\tagSEC_CONTENT	VRAM\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	being\tagSEC_CONTENT	compared\tagSEC_CONTENT	have\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	settings\tagSEC_CONTENT	on\tagSEC_CONTENT	character\tagSEC_CONTENT	embedding\tagSEC_CONTENT	and\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	introduced\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	variable\tagSEC_CONTENT	character\tagSEC_CONTENT	embedding\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	to\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	character\tagSEC_CONTENT	embedding\tagSEC_CONTENT	is\tagSEC_CONTENT	implemented\tagSEC_CONTENT	using\tagSEC_CONTENT	CNN\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	layer\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	100\tagSEC_CONTENT	units\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	channel\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	5\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	has\tagSEC_CONTENT	an\tagSEC_CONTENT	input\tagSEC_CONTENT	depth\tagSEC_CONTENT	of\tagSEC_CONTENT	8\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	max\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	SQuAD\tagdataset	is\tagSEC_CONTENT	16\tagSEC_CONTENT	which\tagSEC_CONTENT	means\tagSEC_CONTENT	there\tagSEC_CONTENT	area\tagSEC_CONTENT	maximum\tagSEC_CONTENT	16\tagSEC_CONTENT	words\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	fixed\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	dimension\tagSEC_CONTENT	of\tagSEC_CONTENT	100\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	GloVe\tagSEC_CONTENT	data\tagSEC_CONTENT	set\tagSEC_CONTENT	(\tagSEC_CONTENT	Pennington\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	2014a\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	settings\tagSEC_CONTENT	for\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	embedding\tagSEC_CONTENT	are\tagSEC_CONTENT	slightly\tagSEC_CONTENT	different\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	model\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	deal\tagSEC_CONTENT	with\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	POS\tagSEC_CONTENT	model\tagSEC_CONTENT	contains\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	with\tagSEC_CONTENT	39\tagSEC_CONTENT	different\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	that\tagSEC_CONTENT	serve\tagSEC_CONTENT	as\tagSEC_CONTENT	both\tagSEC_CONTENT	input\tagSEC_CONTENT	and\tagSEC_CONTENT	output\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	SECT\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	the\tagSEC_CONTENT	input\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	8\tagSEC_CONTENT	with\tagSEC_CONTENT	30\tagSEC_CONTENT	units\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	output\tagSEC_CONTENT	.\tagSEC_CONTENT	Both\tagSEC_CONTENT	of\tagSEC_CONTENT	them\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	maximum\tagSEC_CONTENT	length\tagSEC_CONTENT	size\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	10\tagSEC_CONTENT	and\tagSEC_CONTENT	20\tagSEC_CONTENT	respectively\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	values\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	further\tagSEC_CONTENT	discussed\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4.5\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	also\tagSEC_CONTENT	have\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	ways\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	as\tagSEC_CONTENT	indicated\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	:\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	and\tagSEC_CONTENT	CNN\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	apply\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	sets\tagSEC_CONTENT	of\tagSEC_CONTENT	parameters\tagSEC_CONTENT	when\tagSEC_CONTENT	we\tagSEC_CONTENT	experiment\tagSEC_CONTENT	them\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	report\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	development\tagSEC_CONTENT	set\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	blind\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_END	Predictive\tagSECTITLE_START	Performance\tagSECTITLE_END	We\tagSEC_START	first\tagSEC_CONTENT	compared\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	single\tagSEC_CONTENT	models\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	approach\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	proposed\tagSEC_CONTENT	SEST\tagSEC_CONTENT	approaches\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	SE\tagSEC_CONTENT	-\tagSEC_CONTENT	POS\tagSEC_CONTENT	,\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	,\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	,\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	development\tagSEC_CONTENT	dataset\tagSEC_CONTENT	of\tagSEC_CONTENT	SQuAD\tagdataset	.\tagSEC_CONTENT	For\tagSEC_CONTENT	each\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	conducted\tagSEC_CONTENT	5\tagSEC_CONTENT	different\tagSEC_CONTENT	single\tagSEC_CONTENT	experiments\tagSEC_CONTENT	and\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	them\tagSEC_CONTENT	using\tagSEC_CONTENT	two\tagSEC_CONTENT	metrics\tagSEC_CONTENT	:\tagSEC_CONTENT	"\tagSEC_CONTENT	Exact\tagSEC_CONTENT	match\tagSEC_CONTENT	"\tagSEC_CONTENT	(\tagSEC_CONTENT	EM\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	calculates\tagSEC_CONTENT	the\tagSEC_CONTENT	ratio\tagSEC_CONTENT	of\tagSEC_CONTENT	questions\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	answered\tagSEC_CONTENT	correctly\tagSEC_CONTENT	by\tagSEC_CONTENT	strict\tagSEC_CONTENT	string\tagSEC_CONTENT	comparison\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	calculates\tagSEC_CONTENT	the\tagSEC_CONTENT	harmonic\tagSEC_CONTENT	mean\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	precision\tagSEC_CONTENT	and\tagSEC_CONTENT	recall\tagSEC_CONTENT	between\tagSEC_CONTENT	predicted\tagSEC_CONTENT	answers\tagSEC_CONTENT	and\tagSEC_CONTENT	ground\tagSEC_CONTENT	true\tagSEC_CONTENT	answers\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	character\tagSEC_CONTENT	level\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	reported\tagSEC_CONTENT	the\tagSEC_CONTENT	maximum\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	mean\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	standard\tagSEC_CONTENT	deviation\tagSEC_CONTENT	of\tagSEC_CONTENT	EM\tagSEC_CONTENT	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	scores\tagSEC_CONTENT	across\tagSEC_CONTENT	all\tagSEC_CONTENT	single\tagSEC_CONTENT	runs\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	approach\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	highlighted\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	model\tagSEC_CONTENT	using\tagSEC_CONTENT	bold\tagSEC_CONTENT	font\tagSEC_CONTENT	.\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	best\tagSEC_CONTENT	method\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	confirms\tagSEC_CONTENT	the\tagSEC_CONTENT	predictive\tagSEC_CONTENT	powers\tagSEC_CONTENT	of\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	could\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	and\tagSEC_CONTENT	other\tagSEC_CONTENT	proposed\tagSEC_CONTENT	methods\tagSEC_CONTENT	in\tagSEC_CONTENT	terms\tagSEC_CONTENT	of\tagSEC_CONTENT	both\tagSEC_CONTENT	EM\tagSEC_CONTENT	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	observation\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	propose\tagSEC_CONTENT	models\tagSEC_CONTENT	achieve\tagSEC_CONTENT	higher\tagSEC_CONTENT	relative\tagSEC_CONTENT	improvements\tagSEC_CONTENT	in\tagSEC_CONTENT	EM\tagSEC_CONTENT	scores\tagSEC_CONTENT	than\tagSEC_CONTENT	F1\tagSEC_CONTENT	scores\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	methods\tagSEC_CONTENT	,\tagSEC_CONTENT	providing\tagSEC_CONTENT	the\tagSEC_CONTENT	evidence\tagSEC_CONTENT	that\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	can\tagSEC_CONTENT	accurately\tagSEC_CONTENT	locate\tagSEC_CONTENT	the\tagSEC_CONTENT	boundaries\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	.\tagSEC_CONTENT	Moreover\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	both\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	have\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	than\tagSEC_CONTENT	their\tagSEC_CONTENT	CNN\tagSEC_CONTENT	counterparts\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	suggests\tagSEC_CONTENT	that\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	can\tagSEC_CONTENT	more\tagSEC_CONTENT	effectively\tagSEC_CONTENT	preserve\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	a\tagSEC_CONTENT	result\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	conducted\tagSEC_CONTENT	further\tagSEC_CONTENT	analysis\tagSEC_CONTENT	of\tagSEC_CONTENT	only\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	models\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	subsequent\tagSEC_CONTENT	subsections\tagSEC_CONTENT	and\tagSEC_CONTENT	drop\tagSEC_CONTENT	the\tagSEC_CONTENT	suffix\tagSEC_CONTENT	"\tagSEC_CONTENT	-LSTM\tagSEC_CONTENT	"\tagSEC_CONTENT	for\tagSEC_CONTENT	abbreviation\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	built\tagSEC_CONTENT	an\tagSEC_CONTENT	ensemble\tagSEC_CONTENT	model\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	5\tagSEC_CONTENT	single\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	method\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	methods\tagSEC_CONTENT	SEPOS\tagSEC_CONTENT	,\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	ensemble\tagSEC_CONTENT	model\tagSEC_CONTENT	choose\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	highest\tagSEC_CONTENT	sum\tagSEC_CONTENT	of\tagSEC_CONTENT	confidence\tagSEC_CONTENT	scores\tagSEC_CONTENT	among\tagSEC_CONTENT	the\tagSEC_CONTENT	5\tagSEC_CONTENT	single\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	question\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	compared\tagSEC_CONTENT	these\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	the\tagSEC_CONTENT	development\tagSEC_CONTENT	set\tagSEC_CONTENT	and\tagSEC_CONTENT	official\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	and\tagSEC_CONTENT	reported\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	have\tagSEC_CONTENT	higher\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	development\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	coincides\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	data\tagSEC_CONTENT	set\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Contribution\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Syntactic\tagSECTITLE_CONTENT	Sequence\tagSECTITLE_END	To\tagSEC_START	take\tagSEC_CONTENT	a\tagSEC_CONTENT	closer\tagSEC_CONTENT	look\tagSEC_CONTENT	at\tagSEC_CONTENT	how\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequences\tagSEC_CONTENT	affect\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	removed\tagSEC_CONTENT	the\tagSEC_CONTENT	character\tagSEC_CONTENT	/\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	from\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	seen\tagSEC_CONTENT	in\tagSEC_CONTENT	and\tagSEC_CONTENT	conducted\tagSEC_CONTENT	experiments\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	input\tagSEC_CONTENT	alone\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	particular\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	are\tagSEC_CONTENT	interested\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	aspects\tagSEC_CONTENT	related\tagSEC_CONTENT	to\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequences\tagSEC_CONTENT	:\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	predict\tagSEC_CONTENT	answers\tagSEC_CONTENT	of\tagSEC_CONTENT	questions\tagtask	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequences\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	complete\tagSEC_CONTENT	random\tagSEC_CONTENT	sequences\tagSEC_CONTENT	.\tagSEC_CONTENT	Second\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	amount\tagSEC_CONTENT	of\tagSEC_CONTENT	impacts\tagSEC_CONTENT	brought\tagSEC_CONTENT	by\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	ordering\tagSEC_CONTENT	introduced\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	3.1.1\tagSEC_CONTENT	and\tagSEC_CONTENT	Section\tagSEC_CONTENT	3.1.2\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	random\tagSEC_CONTENT	ordering\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	compared\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	using\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	along\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	original\tagSEC_CONTENT	order\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	Only\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	Only\tagSEC_CONTENT	)\tagSEC_CONTENT	against\tagSEC_CONTENT	their\tagSEC_CONTENT	counterparts\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	nodes\tagSEC_CONTENT	but\tagSEC_CONTENT	with\tagSEC_CONTENT	randomly\tagSEC_CONTENT	shuffled\tagSEC_CONTENT	order\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	Random\tagSEC_CONTENT	-\tagSEC_CONTENT	Order\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	-\tagSEC_CONTENT	RandomOrder\tagSEC_CONTENT	)\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	baselines\tagSEC_CONTENT	with\tagSEC_CONTENT	randomly\tagSEC_CONTENT	generated\tagSEC_CONTENT	tree\tagSEC_CONTENT	nodes\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	SECT\tagSEC_CONTENT	-\tagSEC_CONTENT	Random\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDTRandom\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	we\tagSEC_CONTENT	choose\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	10\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	predictive\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	terms\tagmetric	of\tagSEC_CONTENT	EM\tagmetric	and\tagSEC_CONTENT	F1\tagSEC_CONTENT	metrics\tagSEC_CONTENT	are\tagSEC_CONTENT	reported\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_CONTENT	From\tagSEC_CONTENT	the\tagSEC_CONTENT	table\tagSEC_CONTENT	we\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	both\tagSEC_CONTENT	the\tagSEC_CONTENT	ordering\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	contents\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	tree\tagSEC_CONTENT	are\tagSEC_CONTENT	important\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	work\tagSEC_CONTENT	properly\tagSEC_CONTENT	:\tagSEC_CONTENT	constituency\tagSEC_CONTENT	and\tagSEC_CONTENT	dependency\tagSEC_CONTENT	trees\tagSEC_CONTENT	achieved\tagSEC_CONTENT	over\tagSEC_CONTENT	20\tagSEC_CONTENT	%\tagSEC_CONTENT	boost\tagSEC_CONTENT	on\tagSEC_CONTENT	performance\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	randomly\tagSEC_CONTENT	generated\tagSEC_CONTENT	ones\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	ordering\tagSEC_CONTENT	also\tagSEC_CONTENT	out\tagSEC_CONTENT	-\tagSEC_CONTENT	performed\tagSEC_CONTENT	the\tagSEC_CONTENT	random\tagSEC_CONTENT	ordering\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	also\tagSEC_CONTENT	worth\tagSEC_CONTENT	mentioning\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	ordering\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	trees\tagSEC_CONTENT	seems\tagSEC_CONTENT	to\tagSEC_CONTENT	have\tagSEC_CONTENT	less\tagSEC_CONTENT	impact\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	that\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	trees\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	because\tagSEC_CONTENT	sequences\tagSEC_CONTENT	extracted\tagSEC_CONTENT	from\tagSEC_CONTENT	constituency\tagSEC_CONTENT	trees\tagSEC_CONTENT	contain\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	ordering\tagSEC_CONTENT	will\tagSEC_CONTENT	affect\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	significantly\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	sequences\tagSEC_CONTENT	extracted\tagSEC_CONTENT	from\tagSEC_CONTENT	dependency\tagSEC_CONTENT	trees\tagSEC_CONTENT	are\tagSEC_CONTENT	all\tagSEC_CONTENT	children\tagSEC_CONTENT	nodes\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	often\tagSEC_CONTENT	interchangeable\tagSEC_CONTENT	and\tagSEC_CONTENT	do\tagSEC_CONTENT	n't\tagSEC_CONTENT	seem\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	affected\tagSEC_CONTENT	by\tagSEC_CONTENT	ordering\tagSEC_CONTENT	much\tagSEC_CONTENT	.\tagSEC_END	Window\tagSECTITLE_START	Size\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	As\tagSEC_START	we\tagSEC_CONTENT	have\tagSEC_CONTENT	mentioned\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	earlier\tagSEC_CONTENT	sections\tagSEC_CONTENT	,\tagSEC_CONTENT	limiting\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	important\tagSEC_CONTENT	technique\tagSEC_CONTENT	to\tagSEC_CONTENT	prevent\tagSEC_CONTENT	excessive\tagSEC_CONTENT	usage\tagSEC_CONTENT	on\tagSEC_CONTENT	VRAM\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	practice\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	limiting\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	also\tagSEC_CONTENT	benefits\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	we\tagSEC_CONTENT	compared\tagSEC_CONTENT	the\tagSEC_CONTENT	predictive\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	SECT\tagSEC_CONTENT	:\tagSEC_CONTENT	Performance\tagSEC_CONTENT	comparisons\tagSEC_CONTENT	of\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	only\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	against\tagSEC_CONTENT	their\tagSEC_CONTENT	counterparts\tagSEC_CONTENT	with\tagSEC_CONTENT	randomly\tagSEC_CONTENT	shuffled\tagSEC_CONTENT	node\tagSEC_CONTENT	sequences\tagSEC_CONTENT	and\tagSEC_CONTENT	randomly\tagSEC_CONTENT	generated\tagSEC_CONTENT	tree\tagSEC_CONTENT	nodes\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	Dev\tagSEC_CONTENT	set\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	models\tagSEC_CONTENT	by\tagSEC_CONTENT	varying\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	their\tagSEC_CONTENT	window\tagSEC_CONTENT	sizes\tagSEC_CONTENT	from\tagSEC_CONTENT	1\tagSEC_CONTENT	to\tagSEC_CONTENT	maximum\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	development\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	general\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	illustrate\tagSEC_CONTENT	that\tagSEC_CONTENT	performances\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	increase\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	length\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	for\tagSEC_CONTENT	SECT\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	its\tagSEC_CONTENT	mean\tagSEC_CONTENT	performance\tagSEC_CONTENT	reached\tagSEC_CONTENT	the\tagSEC_CONTENT	peak\tagSEC_CONTENT	while\tagSEC_CONTENT	standard\tagSEC_CONTENT	deviations\tagSEC_CONTENT	narrowed\tagSEC_CONTENT	when\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	reaches\tagSEC_CONTENT	10\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	observed\tagSEC_CONTENT	that\tagSEC_CONTENT	larger\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	generate\tagSEC_CONTENT	predictive\tagSEC_CONTENT	results\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	as\tagSEC_CONTENT	good\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	one\tagSEC_CONTENT	with\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	10\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	suggests\tagSEC_CONTENT	that\tagSEC_CONTENT	there\tagSEC_CONTENT	exists\tagSEC_CONTENT	an\tagSEC_CONTENT	optimal\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	constituency\tagSEC_CONTENT	tree\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	possible\tagSEC_CONTENT	ex-\tagSEC_CONTENT	 \tagSEC_CONTENT	planation\tagSEC_CONTENT	is\tagSEC_CONTENT	increasing\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	increase\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	nodes\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	extracted\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	subtrees\tagSEC_CONTENT	might\tagSEC_CONTENT	be\tagSEC_CONTENT	similar\tagSEC_CONTENT	between\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	question\tagtask	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	very\tagSEC_CONTENT	unlikely\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	complete\tagSEC_CONTENT	trees\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	.\tagSEC_CONTENT	Because\tagSEC_CONTENT	of\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	allowing\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	sequence\tagSEC_CONTENT	to\tagSEC_CONTENT	extend\tagSEC_CONTENT	beyond\tagSEC_CONTENT	the\tagSEC_CONTENT	certain\tagSEC_CONTENT	heights\tagSEC_CONTENT	will\tagSEC_CONTENT	introduce\tagSEC_CONTENT	unnecessary\tagSEC_CONTENT	noise\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	learned\tagSEC_CONTENT	representation\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	will\tagSEC_CONTENT	compromise\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	conclusion\tagSEC_CONTENT	holds\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	has\tagSEC_CONTENT	an\tagSEC_CONTENT	improved\tagSEC_CONTENT	performance\tagSEC_CONTENT	and\tagSEC_CONTENT	decreased\tagSEC_CONTENT	variance\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	10\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	did\tagSEC_CONTENT	not\tagSEC_CONTENT	perform\tagSEC_CONTENT	experiments\tagSEC_CONTENT	with\tagSEC_CONTENT	window\tagSEC_CONTENT	size\tagSEC_CONTENT	beyond\tagSEC_CONTENT	10\tagSEC_CONTENT	for\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	since\tagSEC_CONTENT	it\tagSEC_CONTENT	will\tagSEC_CONTENT	consume\tagSEC_CONTENT	VRAM\tagSEC_CONTENT	that\tagSEC_CONTENT	exceeds\tagSEC_CONTENT	the\tagSEC_CONTENT	capacity\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	computing\tagSEC_CONTENT	device\tagSEC_CONTENT	.\tagSEC_END	Overlapping\tagSECTITLE_START	Analysis\tagSECTITLE_END	To\tagSEC_START	further\tagSEC_CONTENT	understand\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	benefits\tagSEC_CONTENT	of\tagSEC_CONTENT	incorporating\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagtask	question\tagtask	answering\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	take\tagSEC_CONTENT	a\tagSEC_CONTENT	look\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	questions\tagSEC_CONTENT	on\tagSEC_CONTENT	which\tagSEC_CONTENT	models\tagSEC_CONTENT	disagree\tagSEC_CONTENT	.\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	Venn\tagSEC_CONTENT	Diagram\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	questions\tagSEC_CONTENT	that\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	corrected\tagSEC_CONTENT	identified\tagSEC_CONTENT	by\tagSEC_CONTENT	SECT\tagSEC_CONTENT	,\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	we\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	vast\tagSEC_CONTENT	Question\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	SECT\tagSEC_CONTENT	Whose\tagSEC_CONTENT	role\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	design\tagSEC_CONTENT	the\tagSEC_CONTENT	works\tagSEC_CONTENT	,\tagSEC_CONTENT	prepare\tagSEC_CONTENT	the\tagSEC_CONTENT	specifications\tagSEC_CONTENT	and\tagSEC_CONTENT	produce\tagSEC_CONTENT	construction\tagSEC_CONTENT	drawings\tagSEC_CONTENT	,\tagSEC_CONTENT	administer\tagSEC_CONTENT	the\tagSEC_CONTENT	contract\tagSEC_CONTENT	,\tagSEC_CONTENT	tender\tagSEC_CONTENT	the\tagSEC_CONTENT	works\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	manage\tagSEC_CONTENT	the\tagSEC_CONTENT	works\tagSEC_CONTENT	from\tagSEC_CONTENT	inception\tagSEC_CONTENT	to\tagSEC_CONTENT	completion\tagSEC_CONTENT	?\tagSEC_CONTENT	 \tagSEC_CONTENT	These\tagSEC_CONTENT	advances\tagSEC_CONTENT	led\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	development\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	layered\tagSEC_CONTENT	model\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	Earth\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	crust\tagSEC_CONTENT	and\tagSEC_CONTENT	lithosphere\tagSEC_CONTENT	on\tagSEC_CONTENT	top\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	mantle\tagSEC_CONTENT	below\tagSEC_CONTENT	(\tagSEC_CONTENT	separated\tagSEC_CONTENT	within\tagSEC_CONTENT	itself\tagSEC_CONTENT	by\tagSEC_CONTENT	seismic\tagSEC_CONTENT	discontinuities\tagSEC_CONTENT	at\tagSEC_CONTENT	410\tagSEC_CONTENT	and\tagSEC_CONTENT	660\tagSEC_CONTENT	kilometers\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	outer\tagSEC_CONTENT	core\tagSEC_CONTENT	and\tagSEC_CONTENT	inner\tagSEC_CONTENT	core\tagSEC_CONTENT	below\tagSEC_CONTENT	that\tagSEC_CONTENT	.\tagSEC_CONTENT	seismic\tagSEC_CONTENT	discontinuities\tagSEC_CONTENT	at\tagSEC_CONTENT	410\tagSEC_CONTENT	and\tagSEC_CONTENT	660\tagSEC_CONTENT	kilometers\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	outer\tagSEC_CONTENT	core\tagSEC_CONTENT	and\tagSEC_CONTENT	inner\tagSEC_CONTENT	core\tagSEC_CONTENT	the\tagSEC_CONTENT	outer\tagSEC_CONTENT	core\tagSEC_CONTENT	and\tagSEC_CONTENT	inner\tagSEC_CONTENT	core\tagSEC_CONTENT	What\tagSEC_CONTENT	percentage\tagSEC_CONTENT	of\tagSEC_CONTENT	farmland\tagSEC_CONTENT	grows\tagSEC_CONTENT	wheat\tagSEC_CONTENT	?\tagSEC_END	More\tagSEC_START	than\tagSEC_CONTENT	50\tagSEC_CONTENT	%\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	area\tagSEC_CONTENT	is\tagSEC_CONTENT	sown\tagSEC_CONTENT	for\tagSEC_CONTENT	wheat\tagSEC_CONTENT	,\tagSEC_CONTENT	33\tagSEC_CONTENT	%\tagSEC_CONTENT	for\tagSEC_CONTENT	barley\tagSEC_CONTENT	and\tagSEC_CONTENT	7\tagSEC_CONTENT	%\tagSEC_CONTENT	for\tagSEC_CONTENT	oats\tagSEC_CONTENT	.\tagSEC_END	33\tagSECTITLE_START	%\tagSECTITLE_CONTENT	50\tagSECTITLE_CONTENT	%\tagSECTITLE_END	What\tagSEC_START	is\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	unit\tagSEC_CONTENT	of\tagSEC_CONTENT	organization\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	UMC\tagSEC_CONTENT	?\tagSEC_END	The\tagSEC_START	Annual\tagSEC_CONTENT	Conference\tagSEC_CONTENT	,\tagSEC_CONTENT	roughly\tagSEC_CONTENT	the\tagSEC_CONTENT	equivalent\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	diocese\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	Anglican\tagSEC_CONTENT	Communion\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	Roman\tagSEC_CONTENT	Catholic\tagSEC_CONTENT	Church\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	synod\tagSEC_CONTENT	in\tagSEC_CONTENT	some\tagSEC_CONTENT	Lutheran\tagSEC_CONTENT	denominations\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	Evangelical\tagSEC_CONTENT	Lutheran\tagSEC_CONTENT	Church\tagSEC_CONTENT	in\tagSEC_CONTENT	America\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	unit\tagSEC_CONTENT	of\tagSEC_CONTENT	organization\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	UMC\tagSEC_CONTENT	.\tagSEC_END	Evangelical\tagSECTITLE_END	Lutheran\tagSEC_START	Church\tagSEC_CONTENT	in\tagSEC_CONTENT	America\tagSEC_END	The\tagSEC_START	Annual\tagSEC_CONTENT	Conference\tagSEC_CONTENT	 \tagSEC_CONTENT	To\tagSEC_CONTENT	understand\tagSEC_CONTENT	the\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagtask	questions\tagtask	that\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	models\tagSEC_CONTENT	can\tagSEC_CONTENT	do\tagSEC_CONTENT	better\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	extracted\tagSEC_CONTENT	three\tagSEC_CONTENT	questions\tagSEC_CONTENT	that\tagSEC_CONTENT	were\tagSEC_CONTENT	correctly\tagSEC_CONTENT	answered\tagSEC_CONTENT	by\tagSEC_CONTENT	SECT\tagSEC_CONTENT	and\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	but\tagSEC_CONTENT	not\tagSEC_CONTENT	the\tagSEC_CONTENT	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	,\tagSEC_CONTENT	all\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	three\tagSEC_CONTENT	questions\tagSEC_CONTENT	are\tagSEC_CONTENT	"\tagSEC_CONTENT	Wh\tagSEC_CONTENT	-\tagSEC_CONTENT	questions\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	expect\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	noun\tagSEC_CONTENT	phrase\tagSEC_CONTENT	(\tagSEC_CONTENT	NP\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Without\tagSEC_CONTENT	knowing\tagSEC_CONTENT	the\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	answered\tagSEC_CONTENT	questions\tagSEC_CONTENT	with\tagSEC_CONTENT	unnecessary\tagSEC_CONTENT	structures\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	verb\tagSEC_CONTENT	phrases\tagSEC_CONTENT	(\tagSEC_CONTENT	vp\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	acts\tagSEC_CONTENT	as\tagSEC_CONTENT	·\tagSEC_CONTENT	·\tagSEC_CONTENT	·\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	represented\tagSEC_CONTENT	·\tagSEC_CONTENT	·\tagSEC_CONTENT	·\tagSEC_CONTENT	")\tagSEC_CONTENT	or\tagSEC_CONTENT	prepositional\tagSEC_CONTENT	phrases\tagSEC_CONTENT	(\tagSEC_CONTENT	pp\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	in\tagSEC_CONTENT	·\tagSEC_CONTENT	·\tagSEC_CONTENT	·\tagSEC_CONTENT	")\tagSEC_CONTENT	in\tagSEC_CONTENT	addition\tagSEC_CONTENT	to\tagSEC_CONTENT	NPs\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	architect\tagSEC_CONTENT	engineer\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	uncertainty\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	powerful\tagSEC_CONTENT	high\tagSEC_CONTENT	frequency\tagSEC_CONTENT	currents\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	that\tagSEC_CONTENT	normal\tagSEC_CONTENT	human\tagSEC_CONTENT	would\tagSEC_CONTENT	answer\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	that\tagSEC_CONTENT	reason\tagSEC_CONTENT	,\tagSEC_CONTENT	answers\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	failed\tagSEC_CONTENT	the\tagSEC_CONTENT	exact\tagSEC_CONTENT	match\tagSEC_CONTENT	although\tagSEC_CONTENT	its\tagSEC_CONTENT	answers\tagSEC_CONTENT	are\tagSEC_CONTENT	semantically\tagSEC_CONTENT	equivalent\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	ones\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	SECT\tagSEC_CONTENT	.\tagSEC_CONTENT	Having\tagSEC_CONTENT	incorporated\tagSEC_CONTENT	constituency\tagSEC_CONTENT	information\tagSEC_CONTENT	provided\tagSEC_CONTENT	an\tagSEC_CONTENT	huge\tagSEC_CONTENT	advantage\tagSEC_CONTENT	in\tagSEC_CONTENT	inferring\tagSEC_CONTENT	the\tagSEC_CONTENT	answers\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	most\tagSEC_CONTENT	natural\tagSEC_CONTENT	fora\tagSEC_CONTENT	human\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	advantages\tagSEC_CONTENT	of\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	illustrated\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagtask	questions\tagtask	in\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	again\tagSEC_CONTENT	we\tagSEC_CONTENT	listed\tagSEC_CONTENT	the\tagSEC_CONTENT	ones\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	correctly\tagSEC_CONTENT	identified\tagSEC_CONTENT	by\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	but\tagSEC_CONTENT	not\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	for\tagSEC_CONTENT	first\tagSEC_CONTENT	question\tagSEC_CONTENT	broke\tagSEC_CONTENT	the\tagSEC_CONTENT	parenthesis\tagSEC_CONTENT	incorrectly\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	that\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	easily\tagSEC_CONTENT	solved\tagSEC_CONTENT	by\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	dependency\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	failed\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	structures\tagSEC_CONTENT	between\tagSEC_CONTENT	"\tagSEC_CONTENT	50\tagSEC_CONTENT	%\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	keyword\tagSEC_CONTENT	being\tagSEC_CONTENT	asked\tagSEC_CONTENT	"\tagSEC_CONTENT	wheat\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	resulted\tagSEC_CONTENT	in\tagSEC_CONTENT	an\tagSEC_CONTENT	incorrect\tagSEC_CONTENT	answer\tagSEC_CONTENT	that\tagSEC_CONTENT	has\tagSEC_CONTENT	nothing\tagSEC_CONTENT	to\tagSEC_CONTENT	do\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	.\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	,\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	hand\tagSEC_CONTENT	,\tagSEC_CONTENT	answered\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	correctly\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	third\tagSEC_CONTENT	question\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	key\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	correctly\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	of\tagSEC_CONTENT	question\tagSEC_CONTENT	phrase\tagSEC_CONTENT	"\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	basic\tagSEC_CONTENT	unit\tagSEC_CONTENT	of\tagSEC_CONTENT	organization\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Using\tagSEC_CONTENT	the\tagSEC_CONTENT	dependency\tagSEC_CONTENT	tree\tagSEC_CONTENT	as\tagSEC_CONTENT	illustrated\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	is\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	phrase\tagSEC_CONTENT	correctly\tagSEC_CONTENT	,\tagSEC_CONTENT	namely\tagSEC_CONTENT	"\tagSEC_CONTENT	The\tagSEC_CONTENT	Annual\tagSEC_CONTENT	Conference\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	failed\tagSEC_CONTENT	to\tagSEC_CONTENT	anwer\tagSEC_CONTENT	the\tagSEC_CONTENT	question\tagSEC_CONTENT	correctly\tagSEC_CONTENT	and\tagSEC_CONTENT	selected\tagSEC_CONTENT	a\tagSEC_CONTENT	noun\tagSEC_CONTENT	phrase\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Reading\tagSEC_START	Comprehension\tagSEC_CONTENT	.\tagSEC_CONTENT	Reading\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	challenging\tagSEC_CONTENT	task\tagSEC_CONTENT	in\tagSEC_CONTENT	NLP\tagSEC_CONTENT	research\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	the\tagSEC_CONTENT	release\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	SQuAD\tagSEC_CONTENT	data\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	many\tagSEC_CONTENT	works\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	done\tagSEC_CONTENT	to\tagSEC_CONTENT	construct\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	massive\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	data\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	Rajpurkar\tagSEC_CONTENT	et\tagSEC_CONTENT	.\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	are\tagSEC_CONTENT	among\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	authors\tagSEC_CONTENT	to\tagSEC_CONTENT	explore\tagSEC_CONTENT	the\tagdataset	SQuAD\tagdataset	.\tagSEC_CONTENT	They\tagSEC_CONTENT	used\tagSEC_CONTENT	logistic\tagSEC_CONTENT	regression\tagSEC_CONTENT	with\tagSEC_CONTENT	pos\tagSEC_CONTENT	tagging\tagSEC_CONTENT	information\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	provided\tagSEC_CONTENT	a\tagSEC_CONTENT	strong\tagSEC_CONTENT	baseline\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	subsequent\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	steep\tagSEC_CONTENT	improvement\tagSEC_CONTENT	was\tagSEC_CONTENT	given\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	RaSoR\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	which\tagSEC_CONTENT	utilized\tagSEC_CONTENT	recurrent\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	to\tagSEC_CONTENT	consider\tagSEC_CONTENT	all\tagSEC_CONTENT	possible\tagSEC_CONTENT	subphrases\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	them\tagSEC_CONTENT	one\tagSEC_CONTENT	by\tagSEC_CONTENT	one\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	avoid\tagSEC_CONTENT	comparing\tagSEC_CONTENT	all\tagSEC_CONTENT	possible\tagSEC_CONTENT	candidates\tagSEC_CONTENT	and\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	Match\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	(\tagSEC_CONTENT	was\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	pointer\tagSEC_CONTENT	network\tagSEC_CONTENT	(\tagSEC_CONTENT	to\tagSEC_CONTENT	extract\tagSEC_CONTENT	the\tagSEC_CONTENT	answer\tagSEC_CONTENT	span\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	same\tagSEC_CONTENT	idea\tagSEC_CONTENT	was\tagSEC_CONTENT	taken\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	by\tagSEC_CONTENT	introducing\tagSEC_CONTENT	a\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	.\tagSEC_CONTENT	Despite\tagSEC_CONTENT	the\tagSEC_CONTENT	above\tagSEC_CONTENT	-\tagSEC_CONTENT	mentioned\tagSEC_CONTENT	strong\tagSEC_CONTENT	models\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	none\tagSEC_CONTENT	of\tagSEC_CONTENT	them\tagSEC_CONTENT	considers\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	into\tagSEC_CONTENT	their\tagSEC_CONTENT	prediction\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_END	Representations\tagSEC_START	of\tagSEC_CONTENT	Texts\tagSEC_CONTENT	and\tagSEC_CONTENT	Words\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	issues\tagSEC_CONTENT	in\tagSEC_CONTENT	reading\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	latent\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	texts\tagSEC_CONTENT	and\tagSEC_CONTENT	words\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Many\tagSEC_START	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	libraries\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	word2vec\tagSEC_CONTENT	(\tagSEC_CONTENT	and\tagSEC_CONTENT	)\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	widely\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	map\tagSEC_CONTENT	words\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	high\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	embedding\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	approach\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	models\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	Character\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	and\tagSEC_CONTENT	Tree\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	thing\tagSEC_CONTENT	that\tagSEC_CONTENT	worth\tagSEC_CONTENT	mentioning\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	although\tagSEC_CONTENT	Tree\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	does\tagSEC_CONTENT	utilize\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	targets\tagSEC_CONTENT	at\tagSEC_CONTENT	the\tagSEC_CONTENT	phrases\tagSEC_CONTENT	or\tagSEC_CONTENT	sentences\tagSEC_CONTENT	level\tagSEC_CONTENT	embedding\tagSEC_CONTENT	other\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	level\tagSEC_CONTENT	embedding\tagSEC_CONTENT	we\tagSEC_CONTENT	have\tagSEC_CONTENT	discussed\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	.\tagSEC_CONTENT	Many\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	models\tagSEC_CONTENT	include\tagSEC_CONTENT	both\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	and\tagSEC_CONTENT	variable\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	that\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	changed\tagSEC_CONTENT	through\tagSEC_CONTENT	a\tagSEC_CONTENT	training\tagSEC_CONTENT	stage\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Conclusion\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	proposed\tagSEC_CONTENT	methods\tagSEC_CONTENT	to\tagSEC_CONTENT	embed\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	the\tagSEC_CONTENT	accuracy\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	formally\tagSEC_CONTENT	defined\tagSEC_CONTENT	our\tagSEC_CONTENT	SEST\tagSEC_CONTENT	framework\tagSEC_CONTENT	and\tagSEC_CONTENT	proposed\tagSEC_CONTENT	two\tagSEC_CONTENT	instances\tagSEC_CONTENT	to\tagSEC_CONTENT	it\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	constituency\tagSEC_CONTENT	trees\tagSEC_CONTENT	(\tagSEC_CONTENT	SECT\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	structural\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	dependency\tagSEC_CONTENT	trees\tagSEC_CONTENT	(\tagSEC_CONTENT	SEDT\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	SQuAD\tagdataset	data\tagdataset	set\tagdataset	showed\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	proposed\tagSEC_CONTENT	approaches\tagSEC_CONTENT	outperform\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	proving\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	proposed\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	play\tagSEC_CONTENT	a\tagSEC_CONTENT	significant\tagSEC_CONTENT	part\tagSEC_CONTENT	in\tagSEC_CONTENT	correctly\tagSEC_CONTENT	identifying\tagSEC_CONTENT	answers\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	particular\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	perform\tagSEC_CONTENT	especially\tagSEC_CONTENT	well\tagSEC_CONTENT	on\tagSEC_CONTENT	exact\tagSEC_CONTENT	match\tagSEC_CONTENT	metrics\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	requires\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	to\tagSEC_CONTENT	accurately\tagSEC_CONTENT	locate\tagSEC_CONTENT	the\tagSEC_CONTENT	boundaries\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	answers\tagSEC_CONTENT	.\tagSEC_CONTENT	Similar\tagSEC_CONTENT	approaches\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	other\tagSEC_CONTENT	tree\tagSEC_CONTENT	structures\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	graphs\tagSEC_CONTENT	and\tagSEC_CONTENT	ontology\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	This\tagSEC_START	work\tagSEC_CONTENT	opened\tagSEC_CONTENT	several\tagSEC_CONTENT	potential\tagSEC_CONTENT	new\tagSEC_CONTENT	lines\tagSEC_CONTENT	of\tagSEC_CONTENT	research\tagSEC_CONTENT	:\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	experiments\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	paper\tagSEC_CONTENT	we\tagSEC_CONTENT	utilized\tagSEC_CONTENT	the\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	retrieve\tagSEC_CONTENT	answers\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	no\tagSEC_CONTENT	structures\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	BiDAF\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	specifically\tagSEC_CONTENT	optimize\tagSEC_CONTENT	for\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	designed\tagSEC_CONTENT	for\tagSEC_CONTENT	to\tagSEC_CONTENT	utilize\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	information\tagSEC_CONTENT	should\tagSEC_CONTENT	be\tagSEC_CONTENT	studied\tagSEC_CONTENT	.\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	Another\tagSEC_CONTENT	direction\tagSEC_CONTENT	of\tagSEC_CONTENT	research\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	incorporate\tagSEC_CONTENT	SEST\tagSEC_CONTENT	with\tagSEC_CONTENT	deeper\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	VD\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	learning\tagSEC_CONTENT	capacity\tagSEC_CONTENT	for\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_END	3\tagSEC_START	)\tagSEC_CONTENT	Tree\tagSEC_CONTENT	structured\tagSEC_CONTENT	information\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	graphs\tagSEC_CONTENT	and\tagSEC_CONTENT	ontology\tagSEC_CONTENT	structure\tagSEC_CONTENT	should\tagSEC_CONTENT	be\tagSEC_CONTENT	studied\tagSEC_CONTENT	and\tagSEC_CONTENT	improve\tagSEC_CONTENT	question\tagtask	answering\tagtask	tasks\tagtask	using\tagSEC_CONTENT	similar\tagSEC_CONTENT	techniques\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	ones\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	paper\tagSEC_CONTENT	.\tagSEC_END	
P16-2034	title\tagSECTITLE_END	Attention\tagSEC_START	-\tagSEC_CONTENT	Based\tagSEC_CONTENT	Bidirectional\tagSEC_CONTENT	Long\tagSEC_CONTENT	Short\tagSEC_CONTENT	-\tagSEC_CONTENT	Term\tagSEC_CONTENT	Memory\tagSEC_CONTENT	Networks\tagSEC_CONTENT	for\tagSEC_CONTENT	Relation\tagtask	Classification\tagSEC_END	abstract\tagSECTITLE_END	Relation\tagSEC_START	classification\tagtask	is\tagSEC_CONTENT	an\tagSEC_CONTENT	important\tagSEC_CONTENT	semantic\tagSEC_CONTENT	processing\tagSEC_CONTENT	task\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	field\tagSEC_CONTENT	of\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	processing\tagSEC_CONTENT	(\tagSEC_CONTENT	NLP\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	State\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	systems\tagSEC_CONTENT	still\tagSEC_CONTENT	rely\tagSEC_CONTENT	on\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	or\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	like\tagSEC_CONTENT	dependency\tagSEC_CONTENT	parser\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	entity\tagSEC_CONTENT	recognizers\tagSEC_CONTENT	(\tagSEC_CONTENT	NER\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	challenge\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	important\tagSEC_CONTENT	information\tagSEC_CONTENT	can\tagSEC_CONTENT	appear\tagSEC_CONTENT	at\tagSEC_CONTENT	any\tagSEC_CONTENT	position\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	tackle\tagSEC_CONTENT	these\tagSEC_CONTENT	problems\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	Attention\tagSEC_CONTENT	-\tagSEC_CONTENT	Based\tagSEC_CONTENT	Bidirectional\tagSEC_CONTENT	Long\tagSEC_CONTENT	Short\tagSEC_CONTENT	-\tagSEC_CONTENT	Term\tagSEC_CONTENT	Memory\tagSEC_CONTENT	Networks(Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	semantic\tagSEC_CONTENT	information\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	relation\tagdataset	classification\tagdataset	task\tagdataset	show\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	most\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	existing\tagSEC_CONTENT	methods\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	only\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	Relation\tagSEC_START	classification\tagtask	is\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	finding\tagSEC_CONTENT	semantic\tagtask	relations\tagtask	between\tagSEC_CONTENT	pairs\tagSEC_CONTENT	of\tagSEC_CONTENT	nominals\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	useful\tagSEC_CONTENT	for\tagSEC_CONTENT	many\tagSEC_CONTENT	NLP\tagSEC_CONTENT	applications\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	information\tagtask	extraction\tagtask	(\tagSEC_CONTENT	,\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	instance\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	sentence\tagSEC_CONTENT	contains\tagSEC_CONTENT	an\tagSEC_CONTENT	example\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	Entity\tagSEC_CONTENT	-\tagSEC_CONTENT	Destination\tagSEC_CONTENT	relation\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	nominals\tagSEC_CONTENT	Flowers\tagSEC_CONTENT	and\tagSEC_CONTENT	chapel\tagSEC_CONTENT	.\tagSEC_CONTENT	⟨e\tagSEC_CONTENT	1\tagSEC_CONTENT	⟩\tagSEC_CONTENT	Flowers\tagSEC_CONTENT	⟨/e\tagSEC_CONTENT	1\tagSEC_CONTENT	⟩\tagSEC_CONTENT	are\tagSEC_CONTENT	carried\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	⟨e\tagSEC_CONTENT	2\tagSEC_CONTENT	⟩\tagSEC_CONTENT	chapel\tagSEC_CONTENT	⟨/e\tagSEC_CONTENT	2\tagSEC_CONTENT	⟩.\tagSEC_CONTENT	⟨e\tagSEC_CONTENT	1\tagSEC_CONTENT	⟩\tagSEC_CONTENT	,\tagSEC_CONTENT	⟨/e\tagSEC_CONTENT	1\tagSEC_CONTENT	⟩\tagSEC_CONTENT	,\tagSEC_CONTENT	⟨e\tagSEC_CONTENT	2\tagSEC_CONTENT	⟩\tagSEC_CONTENT	,\tagSEC_CONTENT	⟨/e\tagSEC_CONTENT	2\tagSEC_CONTENT	⟩\tagSEC_CONTENT	are\tagSEC_CONTENT	four\tagSEC_CONTENT	position\tagSEC_CONTENT	indicators\tagSEC_CONTENT	which\tagSEC_CONTENT	specify\tagSEC_CONTENT	the\tagSEC_CONTENT	starting\tagSEC_CONTENT	and\tagSEC_CONTENT	ending\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	nominals\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_END	Traditional\tagSEC_START	relation\tagSEC_CONTENT	classification\tagSEC_CONTENT	methods\tagSEC_CONTENT	that\tagSEC_CONTENT	employ\tagSEC_CONTENT	handcrafted\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	usually\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	pattern\tagSEC_CONTENT	matching\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	have\tagSEC_CONTENT	achieved\tagSEC_CONTENT	high\tagSEC_CONTENT	performance\tagSEC_CONTENT	(\tagSEC_CONTENT	Bunescu\tagSEC_CONTENT	*\tagSEC_CONTENT	Correspondence\tagSEC_CONTENT	author\tagSEC_CONTENT	:\tagSEC_CONTENT	zhenyu.qi@ia.ac.cn\tagSEC_CONTENT	and\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	downside\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	methods\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	many\tagSEC_CONTENT	traditional\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	are\tagSEC_CONTENT	utilized\tagSEC_CONTENT	to\tagSEC_CONTENT	extract\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	speech\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path\tagSEC_CONTENT	and\tagSEC_CONTENT	named\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	consequently\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	increase\tagSEC_CONTENT	of\tagSEC_CONTENT	computational\tagSEC_CONTENT	cost\tagSEC_CONTENT	and\tagSEC_CONTENT	additional\tagSEC_CONTENT	propagation\tagSEC_CONTENT	errors\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	downside\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	designing\tagSEC_CONTENT	features\tagSEC_CONTENT	manually\tagSEC_CONTENT	is\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	consuming\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	performing\tagSEC_CONTENT	poor\tagSEC_CONTENT	on\tagSEC_CONTENT	generalization\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	low\tagSEC_CONTENT	coverage\tagSEC_CONTENT	of\tagSEC_CONTENT	different\tagSEC_CONTENT	training\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_END	Recently\tagSEC_START	,\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	methods\tagSEC_CONTENT	provide\tagSEC_CONTENT	an\tagSEC_CONTENT	effective\tagSEC_CONTENT	way\tagSEC_CONTENT	of\tagSEC_CONTENT	reducing\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	handcrafted\tagSEC_CONTENT	features\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	these\tagSEC_CONTENT	approaches\tagSEC_CONTENT	still\tagSEC_CONTENT	use\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	or\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	like\tagSEC_CONTENT	dependency\tagSEC_CONTENT	parsers\tagSEC_CONTENT	and\tagSEC_CONTENT	NER\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_END	This\tagSEC_START	paper\tagSEC_CONTENT	proposes\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	utilizes\tagSEC_CONTENT	neural\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	with\tagSEC_CONTENT	Bidirectional\tagSEC_CONTENT	Long\tagSEC_CONTENT	Short\tagSEC_CONTENT	-\tagSEC_CONTENT	Term\tagSEC_CONTENT	Memory\tagSEC_CONTENT	Networks(BLSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	semantic\tagSEC_CONTENT	information\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	does\tagSEC_CONTENT	n't\tagSEC_CONTENT	utilize\tagSEC_CONTENT	any\tagSEC_CONTENT	features\tagSEC_CONTENT	derived\tagSEC_CONTENT	from\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	or\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	contribution\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	is\tagSEC_CONTENT	using\tagSEC_CONTENT	BLST\tagSEC_CONTENT	-\tagSEC_CONTENT	M\tagSEC_CONTENT	with\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	can\tagSEC_CONTENT	automatically\tagSEC_CONTENT	focus\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	words\tagSEC_CONTENT	that\tagSEC_CONTENT	have\tagSEC_CONTENT	decisive\tagSEC_CONTENT	effect\tagSEC_CONTENT	on\tagSEC_CONTENT	classification\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	the\tagSEC_CONTENT	most\tagSEC_CONTENT	important\tagSEC_CONTENT	semantic\tagSEC_CONTENT	information\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	,\tagSEC_CONTENT	without\tagSEC_CONTENT	using\tagSEC_CONTENT	extra\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	and\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	conduct\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	Task\tagdataset	8\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	achieve\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1-score\tagSEC_CONTENT	of\tagSEC_CONTENT	84.0\tagSEC_CONTENT	%\tagSEC_CONTENT	,\tagSEC_CONTENT	higher\tagSEC_CONTENT	than\tagSEC_CONTENT	most\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	existing\tagSEC_CONTENT	methods\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	literature\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	remainder\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	paper\tagSEC_CONTENT	is\tagSEC_CONTENT	structured\tagSEC_CONTENT	as\tagSEC_CONTENT	follows\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	Section\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	review\tagSEC_CONTENT	related\tagSEC_CONTENT	work\tagSEC_CONTENT	about\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	presents\tagSEC_CONTENT	our\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	Section\tagSEC_CONTENT	4\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	describe\tagSEC_CONTENT	details\tagSEC_CONTENT	about\tagSEC_CONTENT	the\tagSEC_CONTENT	setup\tagSEC_CONTENT	of\tagSEC_CONTENT	experimental\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	have\tagSEC_CONTENT	our\tagSEC_CONTENT	conclusion\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	5\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Over\tagSEC_START	the\tagSEC_CONTENT	years\tagSEC_CONTENT	,\tagSEC_CONTENT	various\tagSEC_CONTENT	methods\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	proposed\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	Most\tagSEC_CONTENT	of\tagSEC_CONTENT	them\tagSEC_CONTENT	are\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	pattern\tagSEC_CONTENT	matching\tagSEC_CONTENT	and\tagSEC_CONTENT	apply\tagSEC_CONTENT	extra\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	to\tagSEC_CONTENT	derive\tagSEC_CONTENT	lexical\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	related\tagSEC_CONTENT	work\tagSEC_CONTENT	is\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	utilizes\tagSEC_CONTENT	many\tagSEC_CONTENT	features\tagSEC_CONTENT	derived\tagSEC_CONTENT	from\tagSEC_CONTENT	external\tagSEC_CONTENT	corpora\tagSEC_CONTENT	fora\tagSEC_CONTENT	Support\tagSEC_CONTENT	Vector\tagSEC_CONTENT	Machine(SVM\tagSEC_CONTENT	)\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_END	Recently\tagSEC_START	,\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	can\tagSEC_CONTENT	learn\tagSEC_CONTENT	underlying\tagSEC_CONTENT	features\tagSEC_CONTENT	automatically\tagSEC_CONTENT	and\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	used\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	literature\tagSEC_CONTENT	.\tagSEC_CONTENT	Most\tagSEC_CONTENT	representative\tagSEC_CONTENT	progress\tagSEC_CONTENT	was\tagSEC_CONTENT	made\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	who\tagSEC_CONTENT	utilized\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks(CNN\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	While\tagSEC_CONTENT	CNN\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	suitable\tagSEC_CONTENT	for\tagSEC_CONTENT	learning\tagSEC_CONTENT	long\tagSEC_CONTENT	-\tagSEC_CONTENT	distance\tagSEC_CONTENT	semantic\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	builds\tagSEC_CONTENT	on\tagSEC_CONTENT	Recurrent\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network(RNN\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	One\tagSEC_START	related\tagSEC_CONTENT	work\tagSEC_CONTENT	was\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	employed\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	RN\tagSEC_CONTENT	-\tagSEC_CONTENT	N\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	patterns\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	from\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_CONTENT	Although\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	RNN\tagSEC_CONTENT	has\tagSEC_CONTENT	access\tagSEC_CONTENT	to\tagSEC_CONTENT	both\tagSEC_CONTENT	past\tagSEC_CONTENT	and\tagSEC_CONTENT	future\tagSEC_CONTENT	context\tagSEC_CONTENT	information\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	range\tagSEC_CONTENT	of\tagSEC_CONTENT	context\tagSEC_CONTENT	is\tagSEC_CONTENT	limited\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	vanishing\tagSEC_CONTENT	gradient\tagSEC_CONTENT	problem\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	overcome\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	Long\tagSEC_CONTENT	short\tagSEC_CONTENT	-\tagSEC_CONTENT	Term\tagSEC_CONTENT	memory(LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	units\tagSEC_CONTENT	are\tagSEC_CONTENT	introduced\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_END	Another\tagSEC_START	related\tagSEC_CONTENT	work\tagSEC_CONTENT	is\tagSEC_CONTENT	SDP\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	leverages\tagSEC_CONTENT	the\tagSEC_CONTENT	shortest\tagSEC_CONTENT	dependency\tagSEC_CONTENT	path(SDP\tagSEC_CONTENT	)\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	nominals\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	it\tagSEC_CONTENT	picks\tagSEC_CONTENT	up\tagSEC_CONTENT	heterogeneous\tagSEC_CONTENT	information\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	with\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	units\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	regards\tagSEC_CONTENT	the\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	.\tagSEC_END	Finally\tagSEC_START	,\tagSEC_CONTENT	our\tagSEC_CONTENT	work\tagSEC_CONTENT	is\tagSEC_CONTENT	related\tagSEC_CONTENT	to\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	NLP\tagSEC_CONTENT	tools\tagSEC_CONTENT	and\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	position\tagSEC_CONTENT	,\tagSEC_CONTENT	POS\tagSEC_CONTENT	,\tagSEC_CONTENT	NER\tagSEC_CONTENT	,\tagSEC_CONTENT	dependency\tagSEC_CONTENT	parse\tagSEC_CONTENT	and\tagSEC_CONTENT	hypernym\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	together\tagSEC_CONTENT	with\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	units\tagSEC_CONTENT	,\tagSEC_CONTENT	achieved\tagSEC_CONTENT	a\tagSEC_CONTENT	comparable\tagSEC_CONTENT	result\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	ofthe\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	comparing\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	complicated\tagSEC_CONTENT	features\tagSEC_CONTENT	that\tagSEC_CONTENT	employed\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	regards\tagSEC_CONTENT	the\tagSEC_CONTENT	four\tagSEC_CONTENT	position\tagSEC_CONTENT	indicators\tagSEC_CONTENT	⟨e1⟩\tagSEC_CONTENT	,\tagSEC_CONTENT	⟨/e1⟩\tagSEC_CONTENT	,\tagSEC_CONTENT	⟨e2⟩\tagSEC_CONTENT	,\tagSEC_CONTENT	⟨/e2⟩\tagSEC_CONTENT	as\tagSEC_CONTENT	single\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	transforms\tagSEC_CONTENT	all\tagSEC_CONTENT	words\tagSEC_CONTENT	to\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	,\tagSEC_CONTENT	forming\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	but\tagSEC_CONTENT	competing\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_END	Model\tagSECTITLE_END	In\tagSEC_START	this\tagtask	section\tagtask	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	contains\tagSEC_CONTENT	five\tagSEC_CONTENT	components\tagSEC_CONTENT	:\tagSEC_END	(\tagSEC_START	1\tagSEC_CONTENT	)\tagSEC_CONTENT	Input\tagSEC_CONTENT	layer\tagSEC_CONTENT	:\tagSEC_CONTENT	input\tagSEC_CONTENT	sentence\tagSEC_CONTENT	to\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	;\tagSEC_CONTENT	(\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	Embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	:\tagSEC_CONTENT	map\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	low\tagSEC_CONTENT	dimension\tagSEC_CONTENT	vector\tagSEC_CONTENT	;\tagSEC_CONTENT	(\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	:\tagSEC_CONTENT	utilize\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	high\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	step\tagSEC_CONTENT	;\tagSEC_CONTENT	(\tagSEC_CONTENT	4\tagSEC_CONTENT	)\tagSEC_CONTENT	Attention\tagSEC_CONTENT	layer\tagSEC_CONTENT	:\tagSEC_CONTENT	produce\tagSEC_CONTENT	a\tagSEC_CONTENT	weight\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	merge\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	from\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	feature\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	multiplying\tagSEC_CONTENT	the\tagSEC_CONTENT	weight\tagSEC_CONTENT	vector\tagSEC_CONTENT	;\tagSEC_END	(\tagSEC_START	5\tagSEC_CONTENT	)\tagSEC_CONTENT	Output\tagSEC_CONTENT	layer\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	feature\tagSEC_CONTENT	vector\tagSEC_CONTENT	is\tagSEC_CONTENT	finally\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_END	These\tagSEC_START	components\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	presented\tagSEC_CONTENT	in\tagSEC_CONTENT	detail\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagtask	section\tagtask	.\tagSEC_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	Given\tagSEC_START	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	T\tagSEC_CONTENT	words\tagSEC_CONTENT	S\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	x\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	x\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	x\tagSEC_CONTENT	T\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	every\tagSEC_CONTENT	word\tagSEC_CONTENT	xi\tagSEC_CONTENT	is\tagSEC_CONTENT	converted\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	real\tagSEC_CONTENT	-\tagSEC_CONTENT	valued\tagSEC_CONTENT	vector\tagSEC_CONTENT	e\tagSEC_CONTENT	i\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	S\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	first\tagSEC_CONTENT	lookup\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	matrix\tagSEC_CONTENT	W\tagSEC_CONTENT	wrd\tagSEC_CONTENT	∈\tagSEC_CONTENT	Rd\tagSEC_CONTENT	w\tagSEC_CONTENT	|V\tagSEC_CONTENT	|\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	V\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	sized\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	d\tagSEC_CONTENT	w\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	matrix\tagSEC_CONTENT	W\tagSEC_CONTENT	wrd\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	parameter\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	learned\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	d\tagSEC_CONTENT	w\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	hyper\tagSEC_CONTENT	-\tagSEC_CONTENT	parameter\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	chosen\tagSEC_CONTENT	by\tagSEC_CONTENT	user\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	transform\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	xi\tagSEC_CONTENT	into\tagSEC_CONTENT	its\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	e\tagSEC_CONTENT	i\tagSEC_CONTENT	by\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	matrix\tagSEC_CONTENT	-\tagSEC_CONTENT	vector\tagSEC_CONTENT	product\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	vi\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	vector\tagSEC_CONTENT	of\tagSEC_CONTENT	size\tagSEC_CONTENT	|V\tagSEC_CONTENT	|\tagSEC_CONTENT	which\tagSEC_CONTENT	has\tagSEC_CONTENT	value\tagSEC_CONTENT	1\tagSEC_CONTENT	at\tagSEC_CONTENT	index\tagSEC_CONTENT	e\tagSEC_CONTENT	i\tagSEC_CONTENT	and\tagSEC_CONTENT	0\tagSEC_CONTENT	in\tagSEC_CONTENT	all\tagSEC_CONTENT	other\tagSEC_CONTENT	positions\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	is\tagSEC_CONTENT	feed\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	next\tagSEC_CONTENT	layer\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	real\tagSEC_CONTENT	-\tagSEC_CONTENT	valued\tagSEC_CONTENT	vectors\tagSEC_CONTENT	emb\tagSEC_CONTENT	s\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	e\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	T\tagSEC_CONTENT	}\tagSEC_CONTENT	.\tagSEC_END	Bidirectional\tagSECTITLE_START	Network\tagSECTITLE_END	LSTM\tagSEC_START	units\tagSEC_CONTENT	are\tagSEC_CONTENT	firstly\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	to\tagSEC_CONTENT	overcome\tagSEC_CONTENT	gradient\tagSEC_CONTENT	vanishing\tagSEC_CONTENT	problem\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	main\tagSEC_CONTENT	idea\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	introduce\tagSEC_CONTENT	an\tagSEC_CONTENT	adaptive\tagSEC_CONTENT	gating\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	decides\tagSEC_CONTENT	the\tagSEC_CONTENT	degree\tagSEC_CONTENT	to\tagSEC_CONTENT	which\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	units\tagSEC_CONTENT	keep\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	state\tagSEC_CONTENT	and\tagSEC_CONTENT	memorize\tagSEC_CONTENT	the\tagSEC_CONTENT	extracted\tagSEC_CONTENT	features\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	data\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	lots\tagSEC_CONTENT	of\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	variants\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	proposed\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	adopt\tagSEC_CONTENT	a\tagSEC_CONTENT	variant\tagSEC_CONTENT	introduced\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	adds\tagSEC_CONTENT	weighted\tagSEC_CONTENT	peephole\tagSEC_CONTENT	connections\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	Constant\tagSEC_CONTENT	Error\tagSEC_CONTENT	Carousel\tagSEC_CONTENT	(\tagSEC_CONTENT	CEC\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	gates\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	memory\tagSEC_CONTENT	block\tagSEC_CONTENT	.\tagSEC_CONTENT	By\tagSEC_CONTENT	directly\tagSEC_CONTENT	employing\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	cell\tagSEC_CONTENT	state\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	the\tagSEC_CONTENT	gate\tagSEC_CONTENT	degrees\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	peephole\tagSEC_CONTENT	connections\tagSEC_CONTENT	allow\tagSEC_CONTENT	all\tagSEC_CONTENT	gates\tagSEC_CONTENT	to\tagSEC_CONTENT	inspect\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	cell\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	  \tagSEC_CONTENT	,\tagSEC_CONTENT	all\tagSEC_CONTENT	of\tagSEC_CONTENT	those\tagSEC_CONTENT	gates\tagSEC_CONTENT	are\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	some\tagSEC_CONTENT	degrees\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	current\tagSEC_CONTENT	input\tagSEC_CONTENT	xi\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	h\tagSEC_CONTENT	i−1\tagSEC_CONTENT	that\tagSEC_CONTENT	previous\tagSEC_CONTENT	step\tagSEC_CONTENT	generated\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	current\tagSEC_CONTENT	state\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	cell\tagSEC_CONTENT	c\tagSEC_CONTENT	i−1\tagSEC_CONTENT	(\tagSEC_CONTENT	peephole\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	decisions\tagSEC_CONTENT	whether\tagSEC_CONTENT	to\tagSEC_CONTENT	take\tagSEC_CONTENT	the\tagSEC_CONTENT	inputs\tagSEC_CONTENT	,\tagSEC_CONTENT	forget\tagSEC_CONTENT	the\tagSEC_CONTENT	memory\tagSEC_CONTENT	stored\tagSEC_CONTENT	before\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	output\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	generated\tagSEC_CONTENT	later\tagSEC_CONTENT	.\tagSEC_CONTENT	Just\tagSEC_CONTENT	as\tagSEC_CONTENT	these\tagSEC_CONTENT	following\tagSEC_CONTENT	equations\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	:\tagSEC_END	Hence\tagSEC_START	,\tagSEC_CONTENT	current\tagSEC_CONTENT	cell\tagSEC_CONTENT	state\tagSEC_CONTENT	ct\tagSEC_CONTENT	will\tagSEC_CONTENT	be\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	calculating\tagSEC_CONTENT	the\tagSEC_CONTENT	weighted\tagSEC_CONTENT	sum\tagSEC_CONTENT	using\tagSEC_CONTENT	both\tagSEC_CONTENT	previous\tagSEC_CONTENT	cell\tagSEC_CONTENT	state\tagSEC_CONTENT	and\tagSEC_CONTENT	current\tagSEC_CONTENT	information\tagSEC_CONTENT	generated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	cell\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	many\tagSEC_CONTENT	sequence\tagSEC_CONTENT	modelling\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	beneficial\tagSEC_CONTENT	to\tagSEC_CONTENT	have\tagSEC_CONTENT	access\tagSEC_CONTENT	to\tagSEC_CONTENT	future\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	past\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	standard\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	networks\tagSEC_CONTENT	process\tagSEC_CONTENT	sequences\tagSEC_CONTENT	in\tagSEC_CONTENT	temporal\tagSEC_CONTENT	order\tagSEC_CONTENT	,\tagSEC_CONTENT	they\tagSEC_CONTENT	ignore\tagSEC_CONTENT	future\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	Bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	networks\tagSEC_CONTENT	extend\tagSEC_CONTENT	the\tagSEC_CONTENT	unidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	networks\tagSEC_CONTENT	by\tagSEC_CONTENT	introducing\tagSEC_CONTENT	a\tagSEC_CONTENT	second\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	to\tagSEC_CONTENT	hidden\tagSEC_CONTENT	connections\tagSEC_CONTENT	flow\tagSEC_CONTENT	in\tagSEC_CONTENT	opposite\tagSEC_CONTENT	temporal\tagSEC_CONTENT	order\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	therefore\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	exploit\tagSEC_CONTENT	information\tagSEC_CONTENT	both\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	past\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	future\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	also\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	network\tagSEC_CONTENT	contains\tagSEC_CONTENT	two\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	networks\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	left\tagSEC_CONTENT	and\tagSEC_CONTENT	right\tagSEC_CONTENT	sequence\tagSEC_CONTENT	context\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	forward\tagSEC_CONTENT	and\tagSEC_CONTENT	backward\tagSEC_CONTENT	pass\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	i\tagSEC_CONTENT	th\tagSEC_CONTENT	word\tagSEC_CONTENT	is\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	equation\tagSEC_CONTENT	:\tagSEC_END	Here\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	element\tagSEC_CONTENT	-\tagSEC_CONTENT	wise\tagSEC_CONTENT	sum\tagSEC_CONTENT	to\tagSEC_CONTENT	combine\tagSEC_CONTENT	the\tagSEC_CONTENT	forward\tagSEC_CONTENT	and\tagSEC_CONTENT	backward\tagSEC_CONTENT	pass\tagSEC_CONTENT	outputs\tagSEC_CONTENT	.\tagSEC_END	Attention\tagSECTITLE_END	Attentive\tagSEC_START	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	have\tagSEC_CONTENT	recently\tagSEC_CONTENT	demonstrated\tagSEC_CONTENT	success\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	wide\tagSEC_CONTENT	range\tagSEC_CONTENT	of\tagSEC_CONTENT	tasks\tagSEC_CONTENT	ranging\tagSEC_CONTENT	from\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	,\tagSEC_CONTENT	machine\tagtask	translations\tagtask	,\tagSEC_CONTENT	speech\tagSEC_CONTENT	recognition\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	image\tagSEC_CONTENT	captioning\tagSEC_CONTENT	(\tagSEC_CONTENT	Hermann\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	2015\tagSEC_CONTENT	;\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagtask	section\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	the\tagSEC_CONTENT	attention\tagSEC_CONTENT	mechanism\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	tasks\tagtask	.\tagSEC_CONTENT	Let\tagSEC_CONTENT	H\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	output\tagSEC_CONTENT	vectors[h\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	h\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	h\tagSEC_CONTENT	T\tagSEC_CONTENT	]\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	produced\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	T\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	length\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	representation\tagSEC_CONTENT	r\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	is\tagSEC_CONTENT	formed\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	weighted\tagSEC_CONTENT	sum\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	output\tagSEC_CONTENT	vectors\tagSEC_CONTENT	:\tagSEC_END	Model\tagSECTITLE_END	Feature\tagSEC_START	Set\tagSEC_CONTENT	F1\tagSEC_CONTENT	SVM\tagSEC_CONTENT	POS\tagSEC_CONTENT	,\tagSEC_CONTENT	prefixes\tagSEC_CONTENT	,\tagSEC_CONTENT	morphological\tagSEC_CONTENT	,\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	,\tagSEC_CONTENT	dependency\tagSEC_CONTENT	parse\tagSEC_CONTENT	,\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	Levin\tagSEC_CONTENT	classed\tagSEC_CONTENT	,\tagSEC_CONTENT	ProBank\tagSEC_CONTENT	,\tagSEC_CONTENT	FramNet\tagSEC_CONTENT	,\tagSEC_CONTENT	NomLex\tagSEC_CONTENT	-\tagSEC_CONTENT	Plus\tagSEC_CONTENT	,\tagSEC_CONTENT	82.2\tagSEC_CONTENT	Google\tagSEC_CONTENT	n\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	,\tagSEC_CONTENT	paraphrases\tagSEC_CONTENT	,\tagSEC_CONTENT	TextRunner\tagSEC_CONTENT	CNN\tagSEC_CONTENT	WV\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	dim=50\tagSEC_CONTENT	)\tagSEC_CONTENT	69.7\tagSEC_CONTENT	(\tagSEC_CONTENT	+\tagSEC_CONTENT	PF\tagSEC_CONTENT	+\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	82.7\tagSEC_CONTENT	RNN\tagSEC_CONTENT	WV\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	dim=50\tagSEC_CONTENT	)\tagSEC_CONTENT	+\tagSEC_CONTENT	PI\tagSEC_CONTENT	80.0\tagSEC_CONTENT	(\tagSEC_CONTENT	WV\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	dim=300\tagSEC_CONTENT	)\tagSEC_CONTENT	+\tagSEC_CONTENT	PI\tagSEC_CONTENT	82.5\tagSEC_CONTENT	SDP\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	WV\tagSEC_CONTENT	(\tagSEC_CONTENT	pretrained\tagSEC_CONTENT	by\tagSEC_CONTENT	word2vec\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	dim=200\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	parse\tagSEC_CONTENT	82.4\tagSEC_CONTENT	+\tagSEC_CONTENT	POS\tagSEC_CONTENT	+\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	+\tagSEC_CONTENT	grammar\tagSEC_CONTENT	relation\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	83.7\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	WV\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	dim=100\tagSEC_CONTENT	)\tagSEC_CONTENT	82.7\tagSEC_CONTENT	(\tagSEC_CONTENT	 \tagSEC_CONTENT	where\tagSEC_CONTENT	H\tagSEC_CONTENT	∈\tagSEC_CONTENT	Rd\tagSEC_CONTENT	w\tagSEC_CONTENT	×T\tagSEC_CONTENT	,\tagSEC_CONTENT	d\tagSEC_CONTENT	w\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	dimension\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	,\tagSEC_CONTENT	w\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	trained\tagSEC_CONTENT	parameter\tagSEC_CONTENT	vector\tagSEC_CONTENT	and\tagSEC_CONTENT	w\tagSEC_CONTENT	T\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	transpose\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	dimension\tagSEC_CONTENT	of\tagSEC_CONTENT	w\tagSEC_CONTENT	,\tagSEC_CONTENT	α\tagSEC_CONTENT	,\tagSEC_CONTENT	r\tagSEC_CONTENT	is\tagSEC_CONTENT	d\tagSEC_CONTENT	w\tagSEC_CONTENT	,\tagSEC_CONTENT	T\tagSEC_CONTENT	,\tagSEC_CONTENT	d\tagSEC_CONTENT	w\tagSEC_CONTENT	separately\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	obtain\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	pair\tagSEC_CONTENT	representation\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	classification\tagSEC_CONTENT	from\tagSEC_CONTENT	:\tagSEC_END	Classifying\tagSECTITLE_END	In\tagSEC_START	this\tagtask	setting\tagtask	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	a\tagSEC_CONTENT	softmax\tagSEC_CONTENT	classifier\tagSEC_CONTENT	to\tagSEC_CONTENT	predict\tagSEC_CONTENT	labeî\tagSEC_CONTENT	y\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	discrete\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	classes\tagSEC_CONTENT	Y\tagSEC_CONTENT	fora\tagSEC_CONTENT	sentence\tagSEC_CONTENT	S.\tagSEC_CONTENT	The\tagSEC_CONTENT	classifier\tagSEC_CONTENT	takes\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	state\tagSEC_CONTENT	h\tagSEC_CONTENT	*\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	:\tagSEC_END	The\tagSEC_START	cost\tagSEC_CONTENT	function\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	true\tagSEC_CONTENT	class\tagSEC_CONTENT	labelsˆylabelsˆ\tagSEC_CONTENT	labelsˆy\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	t\tagSEC_CONTENT	∈\tagSEC_CONTENT	ℜ\tagSEC_CONTENT	m\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	one\tagSEC_CONTENT	-\tagSEC_CONTENT	hot\tagSEC_CONTENT	represented\tagSEC_CONTENT	ground\tagSEC_CONTENT	truth\tagSEC_CONTENT	and\tagSEC_CONTENT	y\tagSEC_CONTENT	∈\tagSEC_CONTENT	ℜ\tagSEC_CONTENT	m\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	estimated\tagSEC_CONTENT	probability\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	class\tagSEC_CONTENT	by\tagSEC_CONTENT	softmax\tagSEC_CONTENT	(\tagSEC_CONTENT	m\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	target\tagSEC_CONTENT	classes\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	λ\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	L2\tagSEC_CONTENT	regularization\tagSEC_CONTENT	hyperparameter\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	combine\tagSEC_CONTENT	dropout\tagSEC_CONTENT	with\tagSEC_CONTENT	L2\tagSEC_CONTENT	regularization\tagSEC_CONTENT	to\tagSEC_CONTENT	alleviate\tagSEC_CONTENT	overfitting\tagSEC_CONTENT	.\tagSEC_END	Regularization\tagSECTITLE_END	Dropout\tagSEC_START	,\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	(\tagSEC_CONTENT	Hinton\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	2012\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	prevents\tagSEC_CONTENT	co\tagSEC_CONTENT	-\tagSEC_CONTENT	adaptation\tagSEC_CONTENT	of\tagSEC_CONTENT	hidden\tagSEC_CONTENT	units\tagSEC_CONTENT	by\tagSEC_CONTENT	randomly\tagSEC_CONTENT	omitting\tagSEC_CONTENT	feature\tagSEC_CONTENT	detectors\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	network\tagSEC_CONTENT	during\tagSEC_CONTENT	forward\tagSEC_CONTENT	propagation\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	employ\tagSEC_CONTENT	dropout\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	penultimate\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	additionally\tagSEC_CONTENT	constrain\tagSEC_CONTENT	L2-norms\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	weight\tagSEC_CONTENT	vectors\tagSEC_CONTENT	by\tagSEC_CONTENT	rescaling\tagSEC_CONTENT	w\tagSEC_CONTENT	to\tagSEC_CONTENT	have\tagSEC_CONTENT	∥w∥\tagSEC_CONTENT	=\tagSEC_CONTENT	s\tagSEC_CONTENT	,\tagSEC_CONTENT	whenever\tagSEC_CONTENT	∥w∥\tagSEC_CONTENT	>\tagSEC_CONTENT	s\tagSEC_CONTENT	after\tagSEC_CONTENT	a\tagSEC_CONTENT	gradient\tagSEC_CONTENT	descent\tagSEC_CONTENT	step\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	equation\tagSEC_CONTENT	15\tagSEC_CONTENT	.\tagSEC_CONTENT	Training\tagtask	details\tagtask	are\tagSEC_CONTENT	further\tagSEC_CONTENT	introduced\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4.1\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Experimental\tagSECTITLE_CONTENT	Setup\tagSECTITLE_END	Experiments\tagSEC_START	are\tagSEC_CONTENT	conducted\tagSEC_CONTENT	on\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	dataset\tagSEC_CONTENT	contains\tagSEC_CONTENT	9\tagtask	relationships\tagtask	(\tagSEC_CONTENT	with\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	an\tagSEC_CONTENT	undirected\tagSEC_CONTENT	Other\tagSEC_CONTENT	class\tagSEC_CONTENT	.\tagSEC_CONTENT	There\tagSEC_CONTENT	are\tagSEC_CONTENT	10,717\tagSEC_CONTENT	annotated\tagSEC_CONTENT	examples\tagSEC_CONTENT	,\tagSEC_CONTENT	including\tagSEC_CONTENT	8,000\tagSEC_CONTENT	sentences\tagSEC_CONTENT	for\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	2,717\tagSEC_CONTENT	for\tagSEC_CONTENT	testing\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	adopt\tagSEC_CONTENT	the\tagSEC_CONTENT	official\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	metric\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	systems\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	macro\tagSEC_CONTENT	-\tagSEC_CONTENT	averaged\tagSEC_CONTENT	F1-score\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	nine\tagSEC_CONTENT	actual\tagSEC_CONTENT	relations\tagSEC_CONTENT	(\tagSEC_CONTENT	excluding\tagSEC_CONTENT	the\tagSEC_CONTENT	Other\tagSEC_CONTENT	relation\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	takes\tagSEC_CONTENT	the\tagSEC_CONTENT	directionality\tagSEC_CONTENT	into\tagSEC_CONTENT	consideration\tagtask	.\tagSEC_END	In\tagSEC_START	order\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	work\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	to\tagSEC_CONTENT	initialize\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	work\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	100-dimensional\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	pretrained\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_END	Since\tagSEC_START	there\tagSEC_CONTENT	is\tagSEC_CONTENT	no\tagSEC_CONTENT	official\tagSEC_CONTENT	development\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	randomly\tagSEC_CONTENT	select\tagSEC_CONTENT	800\tagSEC_CONTENT	sentence\tagSEC_CONTENT	for\tagSEC_CONTENT	validation\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	hyper\tagSEC_CONTENT	-\tagSEC_CONTENT	parameters\tagSEC_CONTENT	for\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	were\tagSEC_CONTENT	tuned\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	development\tagSEC_CONTENT	set\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	was\tagSEC_CONTENT	trained\tagSEC_CONTENT	using\tagSEC_CONTENT	AdaDelta\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	of\tagSEC_CONTENT	1.0\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	minibatch\tagSEC_CONTENT	size\tagSEC_CONTENT	10\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	model\tagSEC_CONTENT	parameters\tagSEC_CONTENT	were\tagSEC_CONTENT	regularized\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	perminibatch\tagSEC_CONTENT	L2\tagSEC_CONTENT	regularization\tagSEC_CONTENT	strength\tagSEC_CONTENT	of\tagSEC_CONTENT	10\tagSEC_CONTENT	−5\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	effect\tagSEC_CONTENT	of\tagSEC_CONTENT	dropout\tagSEC_CONTENT	embedding\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	dropout\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	and\tagSEC_CONTENT	dropout\tagSEC_CONTENT	the\tagSEC_CONTENT	penultimate\tagSEC_CONTENT	layer\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	when\tagSEC_CONTENT	the\tagSEC_CONTENT	dropout\tagSEC_CONTENT	rate\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	as\tagSEC_CONTENT	0.3\tagSEC_CONTENT	,\tagSEC_CONTENT	0.3\tagSEC_CONTENT	,\tagSEC_CONTENT	0.5\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	Other\tagSEC_CONTENT	parameters\tagSEC_CONTENT	in\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	are\tagSEC_CONTENT	initialized\tagSEC_CONTENT	randomly\tagSEC_CONTENT	.\tagSEC_CONTENT	compares\tagSEC_CONTENT	our\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	with\tagSEC_CONTENT	other\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	methods\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	SVM\tagSEC_START	:\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	performed\tagSEC_CONTENT	system\tagSEC_CONTENT	in\tagSEC_CONTENT	SemEval-2010\tagSEC_CONTENT	.\tagSEC_CONTENT	leveraged\tagSEC_CONTENT	a\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	handcrafted\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	use\tagSEC_CONTENT	SVM\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	classifier\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	achieved\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	82.2\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	CNN\tagSEC_START	:\tagSEC_CONTENT	treated\tagSEC_CONTENT	a\tagSEC_CONTENT	sentences\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sequential\tagSEC_CONTENT	data\tagSEC_CONTENT	and\tagSEC_CONTENT	exploited\tagSEC_CONTENT	the\tagSEC_CONTENT	convolutional\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	;\tagSEC_CONTENT	they\tagSEC_CONTENT	also\tagSEC_CONTENT	used\tagSEC_CONTENT	a\tagSEC_CONTENT	special\tagSEC_CONTENT	position\tagSEC_CONTENT	vector\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	and\tagSEC_CONTENT	lexical\tagSEC_CONTENT	features\tagSEC_CONTENT	were\tagSEC_CONTENT	concatenated\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	vector\tagSEC_CONTENT	and\tagSEC_CONTENT	fed\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	softmax\tagSEC_CONTENT	classifier\tagSEC_CONTENT	for\tagSEC_CONTENT	prediction\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	82.7\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_END	RNN\tagSEC_START	:\tagSEC_CONTENT	Zhang\tagSEC_CONTENT	and\tagSEC_CONTENT	Wang\tagSEC_CONTENT	(\tagSEC_CONTENT	2015\tagSEC_CONTENT	)\tagSEC_CONTENT	employed\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	RNN\tagSEC_CONTENT	networks\tagSEC_CONTENT	with\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	dimension\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	They\tagSEC_CONTENT	achieved\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	82.8\tagSEC_CONTENT	%\tagSEC_CONTENT	using\tagSEC_CONTENT	300-dimensional\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	80.0\tagSEC_CONTENT	%\tagSEC_CONTENT	using\tagSEC_CONTENT	50-dimensional\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	50-dimensional\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	achieves\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	82.5\tagSEC_CONTENT	%\tagSEC_CONTENT	,\tagSEC_CONTENT	about\tagSEC_CONTENT	2.5\tagSEC_CONTENT	percent\tagSEC_CONTENT	more\tagSEC_CONTENT	than\tagSEC_CONTENT	theirs\tagSEC_CONTENT	.\tagSEC_CONTENT	SDP\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	:\tagSEC_CONTENT	utilized\tagSEC_CONTENT	four\tagSEC_CONTENT	different\tagSEC_CONTENT	channels\tagSEC_CONTENT	to\tagSEC_CONTENT	pickup\tagSEC_CONTENT	heterogeneous\tagSEC_CONTENT	along\tagSEC_CONTENT	the\tagSEC_CONTENT	SDP\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	they\tagSEC_CONTENT	achieved\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	83.7\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	Comparing\tagSEC_CONTENT	with\tagSEC_CONTENT	their\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	regarding\tagSEC_CONTENT	the\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sequence\tagSEC_CONTENT	is\tagSEC_CONTENT	simpler\tagSEC_CONTENT	.\tagSEC_END	BLSTM\tagSEC_START	:\tagSEC_CONTENT	 \tagSEC_CONTENT	employed\tagSEC_CONTENT	many\tagSEC_CONTENT	features\tagSEC_CONTENT	derived\tagSEC_CONTENT	from\tagSEC_CONTENT	NLP\tagSEC_CONTENT	tools\tagSEC_CONTENT	and\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	with\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	networks\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	they\tagSEC_CONTENT	achieved\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	SemEval-2010\tagdataset	Task\tagdataset	8\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	achieves\tagSEC_CONTENT	a\tagSEC_CONTENT	very\tagSEC_CONTENT	similar\tagSEC_CONTENT	result\tagSEC_CONTENT	(\tagSEC_CONTENT	84.0\tagSEC_CONTENT	%\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	simple\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	proposed\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	yields\tagSEC_CONTENT	an\tagSEC_CONTENT	F\tagSEC_CONTENT	1\tagSEC_CONTENT	-score\tagSEC_CONTENT	of\tagSEC_CONTENT	84.0\tagSEC_CONTENT	%\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	most\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	existing\tagSEC_CONTENT	competing\tagSEC_CONTENT	approaches\tagSEC_CONTENT	,\tagSEC_CONTENT	without\tagSEC_CONTENT	using\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	WordNet\tagSEC_CONTENT	or\tagSEC_CONTENT	NLP\tagSEC_CONTENT	systems\tagSEC_CONTENT	like\tagSEC_CONTENT	dependency\tagSEC_CONTENT	parser\tagSEC_CONTENT	and\tagSEC_CONTENT	NER\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	features\tagSEC_CONTENT	.\tagSEC_END	Conclusion\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	novel\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	named\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	relation\tagtask	classification\tagtask	.\tagSEC_CONTENT	This\tagSEC_CONTENT	model\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	rely\tagSEC_CONTENT	on\tagSEC_CONTENT	NLP\tagSEC_CONTENT	tools\tagSEC_CONTENT	or\tagSEC_CONTENT	lexical\tagSEC_CONTENT	resources\tagSEC_CONTENT	to\tagSEC_CONTENT	get\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	uses\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	with\tagSEC_CONTENT	position\tagSEC_CONTENT	indicators\tagSEC_CONTENT	as\tagSEC_CONTENT	input\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	Att\tagSEC_CONTENT	-\tagSEC_CONTENT	BLSTM\tagSEC_CONTENT	is\tagSEC_CONTENT	demonstrated\tagSEC_CONTENT	by\tagSEC_CONTENT	evaluating\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	SemEval-2010\tagdataset	relation\tagdataset	classification\tagdataset	task\tagdataset	.\tagSEC_END	
1702.03814	title\tagSECTITLE_END	Bilateral\tagSEC_START	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	Perspective\tagSEC_CONTENT	Matching\tagSEC_CONTENT	for\tagSEC_CONTENT	Natural\tagSEC_CONTENT	Language\tagSEC_CONTENT	Sentences\tagSEC_END	abstract\tagSECTITLE_END	Natural\tagSEC_START	language\tagSEC_CONTENT	sentence\tagSEC_CONTENT	matching\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	fundamental\tagSEC_CONTENT	technology\tagSEC_CONTENT	fora\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	Previous\tagSEC_CONTENT	approaches\tagSEC_CONTENT	either\tagSEC_CONTENT	match\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	direction\tagSEC_CONTENT	or\tagSEC_CONTENT	only\tagSEC_CONTENT	apply\tagSEC_CONTENT	single\tagSEC_CONTENT	granular\tagSEC_CONTENT	(\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	byword\tagSEC_CONTENT	or\tagSEC_CONTENT	sentence\tagSEC_CONTENT	-\tagSEC_CONTENT	by\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	)\tagSEC_CONTENT	matching\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	bilateral\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	(\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Given\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	first\tagSEC_CONTENT	encodes\tagSEC_CONTENT	them\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	BiL\tagSEC_CONTENT	-\tagSEC_CONTENT	STM\tagSEC_CONTENT	encoder\tagSEC_CONTENT	.\tagSEC_CONTENT	Next\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	match\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	encoded\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	P\tagSEC_CONTENT	against\tagSEC_CONTENT	Q\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	against\tagSEC_CONTENT	P.\tagSEC_CONTENT	In\tagSEC_CONTENT	each\tagSEC_CONTENT	matching\tagSEC_CONTENT	direction\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	sentence\tagSEC_CONTENT	is\tagSEC_CONTENT	matched\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	sentence\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	another\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	utilized\tagSEC_CONTENT	to\tagSEC_CONTENT	aggregate\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	results\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	decision\tagSEC_CONTENT	is\tagSEC_CONTENT	made\tagSEC_CONTENT	through\tagSEC_CONTENT	a\tagSEC_CONTENT	fully\tagSEC_CONTENT	connected\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	tasks\tagSEC_CONTENT	:\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	,\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	and\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	standard\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	datasets\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	achieves\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	Introduction\tagSECTITLE_END	Natural\tagSEC_START	language\tagSEC_CONTENT	sentence\tagSEC_CONTENT	matching\tagSEC_CONTENT	(\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	of\tagSEC_CONTENT	comparing\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	and\tagSEC_CONTENT	identifying\tagSEC_CONTENT	the\tagSEC_CONTENT	relationship\tagSEC_CONTENT	between\tagSEC_CONTENT	them\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	fundamental\tagSEC_CONTENT	technology\tagSEC_CONTENT	fora\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	determine\tagSEC_CONTENT	whether\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	are\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	or\tagSEC_CONTENT	not\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	a\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	is\tagSEC_CONTENT	utilized\tagSEC_CONTENT	to\tagSEC_CONTENT	judge\tagSEC_CONTENT	whether\tagSEC_CONTENT	a\tagSEC_CONTENT	hypothesis\tagSEC_CONTENT	sentence\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	inferred\tagSEC_CONTENT	from\tagSEC_CONTENT	a\tagSEC_CONTENT	premise\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	and\tagSEC_CONTENT	information\tagSEC_CONTENT	retrieval\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	is\tagSEC_CONTENT	employed\tagSEC_CONTENT	to\tagSEC_CONTENT	assess\tagSEC_CONTENT	the\tagSEC_CONTENT	relevance\tagSEC_CONTENT	between\tagSEC_CONTENT	query\tagdataset	-\tagdataset	answer\tagdataset	pairs\tagdataset	and\tagSEC_CONTENT	rank\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	candidate\tagSEC_CONTENT	answers\tagSEC_CONTENT	[\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	machine\tagSEC_CONTENT	comprehension\tagSEC_CONTENT	tasks\tagSEC_CONTENT	,\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	matching\tagSEC_CONTENT	a\tagSEC_CONTENT	passage\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagdataset	question\tagdataset	and\tagSEC_CONTENT	pointing\tagSEC_CONTENT	out\tagSEC_CONTENT	the\tagSEC_CONTENT	correct\tagSEC_CONTENT	answer\tagSEC_CONTENT	span\tagSEC_CONTENT	.\tagSEC_END	With\tagSEC_START	the\tagSEC_CONTENT	renaissance\tagSEC_CONTENT	of\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	two\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	frameworks\tagSEC_CONTENT	were\tagSEC_CONTENT	proposed\tagSEC_CONTENT	for\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	first\tagSEC_CONTENT	framework\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	"\tagSEC_CONTENT	architecture\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	framework\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	encoder\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	CNN\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	RNN\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	applied\tagSEC_CONTENT	to\tagSEC_CONTENT	two\tagSEC_CONTENT	input\tagSEC_CONTENT	sentences\tagSEC_CONTENT	individually\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	that\tagSEC_CONTENT	both\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	are\tagSEC_CONTENT	encoded\tagSEC_CONTENT	into\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	embedding\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	matching\tagSEC_CONTENT	decision\tagSEC_CONTENT	is\tagSEC_CONTENT	made\tagSEC_CONTENT	solely\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	advantage\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	framework\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	sharing\tagSEC_CONTENT	parameters\tagSEC_CONTENT	makes\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	smaller\tagSEC_CONTENT	and\tagSEC_CONTENT	easier\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	visualization\tagSEC_CONTENT	,\tagSEC_CONTENT	sentence\tagSEC_CONTENT	clustering\tagSEC_CONTENT	and\tagSEC_CONTENT	many\tagSEC_CONTENT	other\tagSEC_CONTENT	purposes\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	disadvantage\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	there\tagSEC_CONTENT	is\tagSEC_CONTENT	no\tagSEC_CONTENT	explicit\tagSEC_CONTENT	interaction\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	during\tagSEC_CONTENT	the\tagSEC_CONTENT	encoding\tagSEC_CONTENT	procedure\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	may\tagSEC_CONTENT	lose\tagSEC_CONTENT	some\tagSEC_CONTENT	important\tagSEC_CONTENT	information\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	deal\tagSEC_CONTENT	with\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	second\tagSEC_CONTENT	framework\tagSEC_CONTENT	"\tagSEC_CONTENT	matchingaggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	proposed\tagSEC_CONTENT	.\tagSEC_CONTENT	Under\tagSEC_CONTENT	this\tagSEC_CONTENT	framework\tagSEC_CONTENT	,\tagSEC_CONTENT	smaller\tagSEC_CONTENT	units\tagSEC_CONTENT	(\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	words\tagSEC_CONTENT	or\tagSEC_CONTENT	contextual\tagSEC_CONTENT	vectors\tagSEC_CONTENT	)\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	are\tagSEC_CONTENT	firstly\tagSEC_CONTENT	matched\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	then\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	results\tagSEC_CONTENT	are\tagSEC_CONTENT	aggregated\tagSEC_CONTENT	(\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	CNN\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	vector\tagSEC_CONTENT	to\tagSEC_CONTENT	make\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	decision\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	new\tagSEC_CONTENT	framework\tagSEC_CONTENT	captures\tagSEC_CONTENT	more\tagSEC_CONTENT	interactive\tagSEC_CONTENT	features\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	therefore\tagSEC_CONTENT	it\tagSEC_CONTENT	acquires\tagSEC_CONTENT	significant\tagSEC_CONTENT	improvements\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	"\tagSEC_CONTENT	matchingaggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	approaches\tagSEC_CONTENT	still\tagSEC_CONTENT	have\tagSEC_CONTENT	some\tagSEC_CONTENT	limitations\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	some\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	approaches\tagSEC_CONTENT	only\tagSEC_CONTENT	explored\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	-\tagSEC_CONTENT	by\tagSEC_CONTENT	-\tagSEC_CONTENT	word\tagSEC_CONTENT	matching\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	ignored\tagSEC_CONTENT	other\tagSEC_CONTENT	granular\tagSEC_CONTENT	matchings\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	phrase\tagSEC_CONTENT	-\tagSEC_CONTENT	by\tagSEC_CONTENT	-\tagSEC_CONTENT	sentence\tagSEC_CONTENT	)\tagSEC_CONTENT	;\tagSEC_CONTENT	Second\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	is\tagSEC_CONTENT	only\tagSEC_CONTENT	performed\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	direction\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	matching\tagSEC_CONTENT	P\tagSEC_CONTENT	against\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	neglected\tagSEC_CONTENT	the\tagSEC_CONTENT	reverse\tagSEC_CONTENT	direction\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	,\tagSEC_CONTENT	matching\tagSEC_CONTENT	Q\tagSEC_CONTENT	against\tagSEC_CONTENT	P\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	tackle\tagSEC_CONTENT	these\tagSEC_CONTENT	limitations\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	bilateral\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	(\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	essentially\tagSEC_CONTENT	belongs\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	matchingaggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	framework\tagSEC_CONTENT	.\tagSEC_CONTENT	Given\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	first\tagSEC_CONTENT	encodes\tagSEC_CONTENT	them\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	bidirectional\tagSEC_CONTENT	Long\tagSEC_CONTENT	ShortTerm\tagSEC_CONTENT	Memory\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Next\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	match\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	encoded\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	and\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q.\tagSEC_CONTENT	In\tagSEC_CONTENT	each\tagSEC_CONTENT	matching\tagSEC_CONTENT	direction\tagSEC_CONTENT	,\tagSEC_CONTENT	let\tagSEC_CONTENT	's\tagSEC_CONTENT	say\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	Q\tagSEC_CONTENT	is\tagSEC_CONTENT	matched\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	P\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	another\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	utilized\tagSEC_CONTENT	to\tagSEC_CONTENT	aggregate\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	results\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	decision\tagSEC_CONTENT	is\tagSEC_CONTENT	made\tagSEC_CONTENT	through\tagSEC_CONTENT	a\tagSEC_CONTENT	fully\tagSEC_CONTENT	connected\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	tasks\tagSEC_CONTENT	:\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	,\tagSEC_CONTENT	natural\tagSEC_CONTENT	lan\tagSEC_CONTENT	-\tagSEC_CONTENT	guage\tagSEC_CONTENT	inference\tagSEC_CONTENT	and\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	standard\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	datasets\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	achieves\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	following\tagSEC_CONTENT	parts\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	start\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	brief\tagSEC_CONTENT	definition\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	task\tagSEC_CONTENT	(\tagSEC_CONTENT	Section\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	followed\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	details\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	Section\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	we\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	standard\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	datasets\tagSEC_CONTENT	(\tagSEC_CONTENT	Section\tagSEC_CONTENT	4\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	talk\tagSEC_CONTENT	about\tagSEC_CONTENT	related\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	conclude\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	6\tagSEC_CONTENT	.\tagSEC_END	Task\tagSECTITLE_START	Definition\tagSECTITLE_END	Formally\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	represent\tagSEC_CONTENT	each\tagSEC_CONTENT	example\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	task\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	triple\tagSEC_CONTENT	(\tagSEC_CONTENT	P\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	y\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	P\tagSEC_CONTENT	=\tagSEC_CONTENT	(\tagSEC_CONTENT	p\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	...\tagSEC_CONTENT	,\tagSEC_CONTENT	p\tagSEC_CONTENT	j\tagSEC_CONTENT	,\tagSEC_CONTENT	...\tagSEC_CONTENT	,\tagSEC_CONTENT	p\tagSEC_CONTENT	M\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	length\tagSEC_CONTENT	M\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	=\tagSEC_CONTENT	(\tagSEC_CONTENT	q\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	...\tagSEC_CONTENT	,\tagSEC_CONTENT	q\tagSEC_CONTENT	i\tagSEC_CONTENT	,\tagSEC_CONTENT	...\tagSEC_CONTENT	,\tagSEC_CONTENT	q\tagSEC_CONTENT	N\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	sentence\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	length\tagSEC_CONTENT	N\tagSEC_CONTENT	,\tagSEC_CONTENT	y\tagSEC_CONTENT	∈\tagSEC_CONTENT	Y\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	label\tagSEC_CONTENT	representing\tagSEC_CONTENT	the\tagSEC_CONTENT	relationship\tagSEC_CONTENT	between\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Y\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	taskspecific\tagSEC_CONTENT	labels\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	task\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	represented\tagSEC_CONTENT	as\tagSEC_CONTENT	estimating\tagSEC_CONTENT	a\tagSEC_CONTENT	conditional\tagSEC_CONTENT	probability\tagSEC_CONTENT	Pr\tagSEC_CONTENT	(\tagSEC_CONTENT	y|P\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	predicting\tagSEC_CONTENT	the\tagSEC_CONTENT	relationship\tagSEC_CONTENT	for\tagSEC_CONTENT	testing\tagSEC_CONTENT	examples\tagSEC_CONTENT	by\tagSEC_CONTENT	y\tagSEC_CONTENT	*\tagSEC_CONTENT	=\tagSEC_CONTENT	arg\tagSEC_CONTENT	max\tagSEC_CONTENT	y∈Y\tagSEC_CONTENT	Pr(y|P\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Concretely\tagSEC_CONTENT	,\tagSEC_CONTENT	fora\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	,\tagSEC_CONTENT	Y\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	0\tagSEC_CONTENT	,\tagSEC_CONTENT	1\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	y\tagSEC_CONTENT	=\tagSEC_CONTENT	1\tagSEC_CONTENT	means\tagSEC_CONTENT	that\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	are\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	other\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	y\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	otherwise\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	a\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	P\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	premise\tagSEC_CONTENT	sentence\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	hypothesis\tagSEC_CONTENT	sentence\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Y\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	entailment\tagSEC_CONTENT	,\tagSEC_CONTENT	contradiction\tagSEC_CONTENT	,\tagSEC_CONTENT	neutral\tagSEC_CONTENT	}\tagSEC_CONTENT	where\tagSEC_CONTENT	entailment\tagSEC_CONTENT	indicates\tagSEC_CONTENT	Q\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	inferred\tagSEC_CONTENT	from\tagSEC_CONTENT	P\tagSEC_CONTENT	,\tagSEC_CONTENT	contradiction\tagSEC_CONTENT	indicates\tagSEC_CONTENT	Q\tagSEC_CONTENT	can\tagSEC_CONTENT	not\tagSEC_CONTENT	be\tagSEC_CONTENT	true\tagSEC_CONTENT	condition\tagSEC_CONTENT	on\tagSEC_CONTENT	P\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	neutral\tagSEC_CONTENT	means\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	are\tagSEC_CONTENT	irrelevant\tagSEC_CONTENT	to\tagSEC_CONTENT	each\tagSEC_CONTENT	other\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	an\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	P\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagdataset	question\tagdataset	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	candidate\tagSEC_CONTENT	answer\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Y\tagSEC_CONTENT	=\tagSEC_CONTENT	{\tagSEC_CONTENT	0\tagSEC_CONTENT	,\tagSEC_CONTENT	1\tagSEC_CONTENT	}\tagSEC_CONTENT	where\tagSEC_CONTENT	y\tagSEC_CONTENT	=\tagSEC_CONTENT	1\tagSEC_CONTENT	means\tagSEC_CONTENT	Q\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	correct\tagSEC_CONTENT	answer\tagSEC_CONTENT	for\tagSEC_CONTENT	P\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	y\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	otherwise\tagSEC_CONTENT	.\tagSEC_END	Method\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	first\tagSEC_CONTENT	give\tagSEC_CONTENT	a\tagSEC_CONTENT	high\tagSEC_CONTENT	-\tagSEC_CONTENT	level\tagSEC_CONTENT	overview\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	in\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	3.1\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	then\tagSEC_CONTENT	give\tagSEC_CONTENT	more\tagSEC_CONTENT	details\tagSEC_CONTENT	about\tagSEC_CONTENT	our\tagSEC_CONTENT	novel\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	operation\tagSEC_CONTENT	in\tagSEC_CONTENT	Subsection\tagSEC_CONTENT	3.2\tagSEC_CONTENT	.\tagSEC_END	Model\tagSECTITLE_START	Overview\tagSECTITLE_END	We\tagSEC_START	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	bilateral\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	(\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	estimate\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	distribution\tagSEC_CONTENT	Pr(y|P\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	belongs\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	matching\tagSEC_CONTENT	-\tagSEC_CONTENT	aggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	framework\tagSEC_CONTENT	.\tagSEC_CONTENT	Contrarily\tagSEC_CONTENT	to\tagSEC_CONTENT	previous\tagSEC_CONTENT	"\tagSEC_CONTENT	matching\tagSEC_CONTENT	-\tagSEC_CONTENT	aggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	approaches\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	matches\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	(\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	and\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	each\tagSEC_CONTENT	individual\tagSEC_CONTENT	direction\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	matches\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	architecture\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	Given\tagSEC_CONTENT	a\tagSEC_CONTENT	pair\tagSEC_CONTENT	of\tagSEC_CONTENT	sentences\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	model\tagSEC_CONTENT	estimates\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	distribution\tagSEC_CONTENT	Pr(y|P\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	through\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	five\tagSEC_CONTENT	layers\tagSEC_CONTENT	.\tagSEC_END	Word\tagSEC_START	Representation\tagdataset	Layer\tagdataset	.\tagSEC_CONTENT	The\tagSEC_CONTENT	goal\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	in\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	d\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	construct\tagSEC_CONTENT	the\tagSEC_CONTENT	d\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	vector\tagSEC_CONTENT	with\tagSEC_CONTENT	two\tagSEC_CONTENT	components\tagSEC_CONTENT	:\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	character\tagSEC_CONTENT	-\tagSEC_CONTENT	composed\tagSEC_CONTENT	embedding\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	word\tagSEC_CONTENT	embedding\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	vector\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	individual\tagSEC_CONTENT	word\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	with\tagSEC_CONTENT	GloVe\tagSEC_CONTENT	or\tagSEC_CONTENT	word2vec\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	charactercomposed\tagSEC_CONTENT	embedding\tagSEC_CONTENT	is\tagSEC_CONTENT	calculated\tagSEC_CONTENT	by\tagSEC_CONTENT	feeding\tagSEC_CONTENT	each\tagmetric	character\tagmetric	(\tagSEC_CONTENT	represented\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	character\tagSEC_CONTENT	embedding\tagSEC_CONTENT	)\tagSEC_CONTENT	within\tagSEC_CONTENT	a\tagSEC_CONTENT	word\tagSEC_END	Word\tagSECTITLE_START	Representation\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Matching\tagSEC_START	Layer\tagSEC_END	Context\tagSECTITLE_START	Representation\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Aggregation\tagSECTITLE_START	Layer\tagSECTITLE_END	softmax\tagSECTITLE_END	Prediction\tagSECTITLE_START	Layer\tagSECTITLE_END	Pr\tagSEC_START	(\tagSEC_CONTENT	y|í\tagSEC_CONTENT	µí±\tagSEC_CONTENT	,\tagSEC_CONTENT	í\tagSEC_CONTENT	µí±\tagSEC_CONTENT	)\tagSEC_CONTENT	 \tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	Long\tagSEC_CONTENT	Short\tagSEC_CONTENT	-\tagSEC_CONTENT	Term\tagSEC_CONTENT	Memory\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	character\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	are\tagSEC_CONTENT	randomly\tagSEC_CONTENT	initialized\tagSEC_CONTENT	and\tagSEC_CONTENT	learned\tagSEC_CONTENT	jointly\tagSEC_CONTENT	with\tagSEC_CONTENT	other\tagSEC_CONTENT	network\tagSEC_CONTENT	parameters\tagSEC_CONTENT	from\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	layer\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	sequences\tagSEC_CONTENT	of\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	P\tagSEC_CONTENT	:\tagSEC_END	Context\tagSEC_START	Representation\tagSEC_CONTENT	Layer\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	purpose\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	incorporate\tagSEC_CONTENT	contextual\tagtask	information\tagtask	into\tagSEC_CONTENT	the\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q.\tagSEC_CONTENT	We\tagSEC_CONTENT	utilize\tagSEC_CONTENT	a\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	directional\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	(\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	P\tagSEC_CONTENT	.\tagSEC_END	Meanwhile\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	apply\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	to\tagSEC_CONTENT	encode\tagSEC_CONTENT	Q\tagSEC_CONTENT	:\tagSEC_END	Matching\tagSEC_START	Layer\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	core\tagSEC_CONTENT	layer\tagSEC_CONTENT	within\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	goal\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	each\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embedding\tagSEC_CONTENT	(\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	)\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	sentence\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	(\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	)\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	shown\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	will\tagSEC_CONTENT	match\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	:\tagSEC_CONTENT	match\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	P\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	Q\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	match\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	Q\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	P\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	match\tagSEC_CONTENT	one\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sentence\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	sentence\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	design\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	operation\tagSEC_CONTENT	⊗.\tagSEC_CONTENT	We\tagSEC_CONTENT	will\tagSEC_CONTENT	give\tagSEC_CONTENT	more\tagSEC_CONTENT	details\tagSEC_CONTENT	about\tagSEC_CONTENT	this\tagSEC_CONTENT	operation\tagSEC_CONTENT	in\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	3.2\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	output\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	layer\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	sequences\tagSEC_CONTENT	of\tagSEC_CONTENT	matching\tagSEC_CONTENT	vectors\tagSEC_CONTENT	(\tagSEC_CONTENT	right\tagSEC_CONTENT	above\tagSEC_CONTENT	the\tagSEC_CONTENT	operation\tagSEC_CONTENT	⊗\tagSEC_CONTENT	in\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	each\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	result\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_END	Aggregation\tagSEC_START	Layer\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	employed\tagSEC_CONTENT	to\tagSEC_CONTENT	aggregate\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sequences\tagSEC_CONTENT	of\tagSEC_CONTENT	matching\tagSEC_CONTENT	vectors\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	utilize\tagSEC_CONTENT	another\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	apply\tagSEC_CONTENT	it\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sequences\tagSEC_CONTENT	of\tagSEC_CONTENT	matching\tagSEC_CONTENT	vectors\tagSEC_CONTENT	individually\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	construct\tagSEC_CONTENT	the\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	by\tagSEC_CONTENT	concatenating\tagSEC_CONTENT	(\tagSEC_CONTENT	the\tagSEC_CONTENT	four\tagSEC_CONTENT	green\tagSEC_CONTENT	)\tagSEC_CONTENT	vectors\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_END	Prediction\tagSEC_START	Layer\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	purpose\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	distribution\tagSEC_CONTENT	Pr(y|P\tagSEC_CONTENT	,\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	this\tagSEC_CONTENT	end\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	employ\tagSEC_CONTENT	a\tagSEC_CONTENT	two\tagSEC_CONTENT	layer\tagSEC_CONTENT	feed\tagSEC_CONTENT	-\tagSEC_CONTENT	forward\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	to\tagSEC_CONTENT	consume\tagSEC_CONTENT	the\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	length\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	apply\tagSEC_CONTENT	the\tagSEC_CONTENT	sof\tagSEC_CONTENT	tmax\tagSEC_CONTENT	function\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	nodes\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	output\tagSEC_CONTENT	layer\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	each\tagSEC_CONTENT	specific\tagSEC_CONTENT	task\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	perspective\tagSECTITLE_CONTENT	Matching\tagSECTITLE_CONTENT	Operation\tagSECTITLE_END	We\tagSEC_START	define\tagSEC_CONTENT	the\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	operation\tagSEC_CONTENT	⊗\tagSEC_CONTENT	in\tagSEC_CONTENT	following\tagSEC_CONTENT	two\tagSEC_CONTENT	steps\tagSEC_CONTENT	:\tagSEC_END	First\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	cosine\tagSEC_CONTENT	matching\tagSEC_CONTENT	function\tagSEC_CONTENT	f\tagSEC_CONTENT	m\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	two\tagSEC_CONTENT	vectors\tagSEC_END	where\tagSEC_START	v\tagSEC_CONTENT	1\tagSEC_CONTENT	and\tagSEC_CONTENT	v\tagSEC_CONTENT	2\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	d\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	vectors\tagSEC_CONTENT	,\tagSEC_CONTENT	W\tagSEC_CONTENT	∈\tagSEC_CONTENT	l×d\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	trainable\tagSEC_CONTENT	parameter\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	shape\tagSEC_CONTENT	l\tagSEC_CONTENT	×\tagSEC_CONTENT	d\tagSEC_CONTENT	,\tagSEC_CONTENT	l\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	returned\tagSEC_CONTENT	value\tagSEC_CONTENT	m\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	l\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_END	Each\tagSEC_START	element\tagSEC_CONTENT	m\tagSEC_CONTENT	k\tagSEC_CONTENT	∈\tagSEC_CONTENT	m\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	matching\tagSEC_CONTENT	value\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	k\tagSEC_CONTENT	-\tagSEC_CONTENT	th\tagSEC_CONTENT	perspective\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	calculated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagtask	cosine\tagtask	similarity\tagtask	between\tagSEC_CONTENT	two\tagSEC_CONTENT	weighted\tagSEC_CONTENT	vectors\tagSEC_END	where\tagSEC_START	•\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	element\tagSEC_CONTENT	-\tagSEC_CONTENT	wise\tagSEC_CONTENT	multiplication\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	W\tagSEC_CONTENT	k\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	k\tagSEC_CONTENT	-\tagSEC_CONTENT	th\tagSEC_CONTENT	row\tagSEC_CONTENT	of\tagSEC_CONTENT	W\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	controls\tagSEC_CONTENT	the\tagSEC_CONTENT	k\tagSEC_CONTENT	-\tagSEC_CONTENT	th\tagSEC_CONTENT	perspective\tagSEC_CONTENT	and\tagSEC_CONTENT	assigns\tagSEC_CONTENT	different\tagSEC_CONTENT	weights\tagSEC_CONTENT	to\tagSEC_CONTENT	different\tagSEC_CONTENT	dimensions\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	ddimensional\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_END	Second\tagSEC_START	,\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	f\tagSEC_CONTENT	m\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	four\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategies\tagSEC_CONTENT	to\tagSEC_CONTENT	compare\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	sentence\tagSEC_CONTENT	against\tagSEC_CONTENT	all\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	steps\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	sentence\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	avoid\tagSEC_CONTENT	repetition\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	only\tagSEC_CONTENT	define\tagSEC_CONTENT	these\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategies\tagSEC_CONTENT	for\tagSEC_CONTENT	one\tagSEC_CONTENT	matching\tagSEC_CONTENT	direction\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q.\tagSEC_CONTENT	The\tagSEC_CONTENT	readers\tagSEC_CONTENT	can\tagSEC_CONTENT	infer\tagSEC_CONTENT	equations\tagdataset	for\tagSEC_CONTENT	the\tagSEC_CONTENT	reverse\tagSEC_CONTENT	direction\tagSEC_CONTENT	easily\tagSEC_CONTENT	.\tagSEC_END	(\tagSEC_START	1\tagSEC_CONTENT	)\tagSEC_CONTENT	Full\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	a\tagSEC_CONTENT	)\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	diagram\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategy\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	strategy\tagSEC_CONTENT	,\tagSEC_CONTENT	each\tagSEC_CONTENT	forward\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	backward\tagSEC_CONTENT	)\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embedding\tagSEC_END	is\tagSEC_START	compared\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	last\tagSEC_CONTENT	time\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	forward\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	backward\tagSEC_CONTENT	)\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	sentence\tagSEC_END	(\tagSEC_START	2\tagSEC_CONTENT	)\tagSEC_CONTENT	Maxpooling\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	.\tagSEC_END	where\tagSEC_START	max\tagSEC_END	is\tagSEC_START	element\tagSEC_CONTENT	-\tagSEC_CONTENT	wise\tagSEC_CONTENT	maximum\tagSEC_CONTENT	.\tagSEC_END	Then\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	take\tagSEC_END	,\tagSEC_START	and\tagSEC_CONTENT	calculate\tagSEC_CONTENT	an\tagSEC_CONTENT	attentive\tagSEC_CONTENT	vector\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	entire\tagSEC_CONTENT	sentence\tagSEC_CONTENT	Q\tagSEC_CONTENT	by\tagSEC_CONTENT	weighted\tagSEC_CONTENT	summing\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	Q\tagSEC_CONTENT	:\tagSEC_END	Finally\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	match\tagSEC_CONTENT	each\tagSEC_CONTENT	forward\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	backward\tagSEC_CONTENT	)\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embedding\tagSEC_CONTENT	of\tagSEC_CONTENT	−\tagSEC_CONTENT	→\tagSEC_CONTENT	hp\tagSEC_CONTENT	i\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	←\tagSEC_CONTENT	−\tagSEC_CONTENT	hp\tagSEC_CONTENT	i\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	its\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	attentive\tagSEC_CONTENT	vector\tagSEC_CONTENT	:\tagSEC_END	(\tagSEC_START	4\tagSEC_CONTENT	)\tagSEC_CONTENT	Max\tagSEC_CONTENT	-\tagSEC_CONTENT	Attentive\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	diagram\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategy\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	strategy\tagSEC_CONTENT	is\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	Attentive\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	strategy\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	instead\tagSEC_CONTENT	of\tagSEC_CONTENT	taking\tagSEC_CONTENT	the\tagSEC_CONTENT	weighed\tagSEC_CONTENT	sum\tagSEC_CONTENT	of\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	attentive\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	pick\tagSEC_CONTENT	the\tagSEC_CONTENT	contextual\tagSEC_CONTENT	embedding\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagtask	highest\tagtask	cosine\tagtask	similarity\tagtask	as\tagSEC_CONTENT	the\tagSEC_CONTENT	attentive\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	match\tagSEC_CONTENT	each\tagtask	contextual\tagtask	embedding\tagtask	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	P\tagSEC_CONTENT	with\tagSEC_CONTENT	its\tagSEC_CONTENT	new\tagSEC_CONTENT	attentive\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	apply\tagSEC_CONTENT	all\tagSEC_CONTENT	these\tagSEC_CONTENT	four\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategies\tagSEC_CONTENT	to\tagSEC_CONTENT	each\tagSEC_CONTENT	timestep\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	P\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	concatenate\tagSEC_CONTENT	the\tagSEC_CONTENT	generated\tagSEC_CONTENT	eight\tagSEC_CONTENT	vectors\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	vector\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	step\tagSEC_CONTENT	of\tagSEC_CONTENT	P\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	perform\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	process\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	reverse\tagSEC_CONTENT	matching\tagSEC_CONTENT	direction\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	tasks\tagSEC_CONTENT	:\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	,\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	and\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	will\tagSEC_CONTENT	first\tagSEC_CONTENT	introduce\tagSEC_CONTENT	the\tagSEC_CONTENT	general\tagSEC_CONTENT	setting\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	models\tagSEC_CONTENT	in\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	4.1\tagSEC_CONTENT	.\tagSEC_CONTENT	Then\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	the\tagSEC_CONTENT	properties\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	through\tagSEC_CONTENT	some\tagSEC_CONTENT	ablation\tagSEC_CONTENT	studies\tagSEC_CONTENT	in\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	4.2\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	compare\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	some\tagSEC_CONTENT	standard\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	datasets\tagSEC_CONTENT	in\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	4.3\tagSEC_CONTENT	,\tagSEC_CONTENT	4.4\tagSEC_CONTENT	and\tagSEC_CONTENT	4.5\tagSEC_CONTENT	.\tagSEC_END	Experiment\tagSECTITLE_START	Settings\tagSECTITLE_END	We\tagSEC_START	initialize\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	representation\tagSEC_CONTENT	layer\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	300-dimensional\tagSEC_CONTENT	GloVe\tagSEC_CONTENT	word\tagSEC_CONTENT	vectors\tagSEC_CONTENT	pretrained\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	840B\tagSEC_CONTENT	Common\tagSEC_CONTENT	Crawl\tagSEC_CONTENT	corpus\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	out\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	vocabulary\tagSEC_CONTENT	(\tagSEC_CONTENT	OOV\tagSEC_CONTENT	)\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	initialize\tagSEC_CONTENT	the\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	randomly\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	the\tagSEC_CONTENT	charactercomposed\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	initialize\tagSEC_CONTENT	each\tagmetric	character\tagmetric	as\tagSEC_CONTENT	a\tagSEC_CONTENT	20-dimensional\tagSEC_CONTENT	vector\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	compose\tagSEC_CONTENT	each\tagSEC_CONTENT	word\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	50-dimensional\tagSEC_CONTENT	vector\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	set\tagSEC_CONTENT	the\tagSEC_CONTENT	hidden\tagSEC_CONTENT	size\tagSEC_CONTENT	as\tagSEC_CONTENT	100\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	BiLSTM\tagSEC_CONTENT	layers\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	apply\tagSEC_CONTENT	dropout\tagSEC_CONTENT	to\tagSEC_CONTENT	every\tagSEC_CONTENT	layers\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	set\tagSEC_CONTENT	the\tagSEC_CONTENT	dropout\tagSEC_CONTENT	ratio\tagSEC_CONTENT	as\tagSEC_CONTENT	0.1\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	train\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	minimize\tagSEC_CONTENT	the\tagSEC_CONTENT	cross\tagSEC_CONTENT	entropy\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	ADAM\tagSEC_CONTENT	optimizer\tagSEC_CONTENT	to\tagSEC_CONTENT	update\tagSEC_CONTENT	parameters\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	set\tagSEC_CONTENT	the\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	as\tagSEC_CONTENT	0.001\tagSEC_CONTENT	.\tagSEC_CONTENT	During\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	update\tagSEC_CONTENT	the\tagSEC_CONTENT	pre\tagSEC_CONTENT	-\tagSEC_CONTENT	trained\tagSEC_CONTENT	word\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	experiments\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	pick\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	which\tagSEC_CONTENT	works\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	dev\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	then\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	it\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_END	Model\tagSECTITLE_START	Properties\tagSECTITLE_END	To\tagSEC_START	demonstrate\tagSEC_CONTENT	the\tagSEC_CONTENT	properties\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	choose\tagSEC_CONTENT	the\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	experiment\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	Quora\tagSEC_CONTENT	Question\tagSEC_CONTENT	Pairs\tagSEC_CONTENT	"\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	dataset\tagSEC_CONTENT	consists\tagSEC_CONTENT	of\tagSEC_CONTENT	over\tagdataset	400,000\tagdataset	question\tagdataset	pairs\tagdataset	,\tagSEC_CONTENT	and\tagSEC_CONTENT	each\tagdataset	question\tagdataset	pair\tagdataset	is\tagSEC_CONTENT	annotated\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	binary\tagSEC_CONTENT	value\tagSEC_CONTENT	indicating\tagSEC_CONTENT	whether\tagSEC_CONTENT	the\tagdataset	two\tagdataset	questions\tagdataset	are\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	other\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	randomly\tagSEC_CONTENT	select\tagSEC_CONTENT	5,000\tagSEC_CONTENT	paraphrases\tagSEC_CONTENT	and\tagSEC_CONTENT	5,000\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	paraphrases\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	dev\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	sample\tagSEC_CONTENT	another\tagSEC_CONTENT	5,000\tagSEC_CONTENT	paraphrases\tagSEC_CONTENT	and\tagSEC_CONTENT	5,000\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	paraphrases\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	keep\tagSEC_CONTENT	the\tagSEC_CONTENT	remaining\tagSEC_CONTENT	instances\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	set\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	study\tagSEC_CONTENT	the\tagSEC_CONTENT	influence\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	cosine\tagSEC_CONTENT	matching\tagSEC_CONTENT	function\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq.(3\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	vary\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	l\tagSEC_CONTENT	among\tagSEC_CONTENT	{\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	10\tagSEC_CONTENT	,\tagSEC_CONTENT	15\tagSEC_CONTENT	,\tagSEC_CONTENT	20\tagSEC_CONTENT	}\tagSEC_CONTENT	3\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	keep\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	options\tagSEC_CONTENT	unchanged\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	build\tagSEC_CONTENT	a\tagSEC_CONTENT	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	by\tagSEC_CONTENT	replacing\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagtask	vanilla\tagtask	cosine\tagtask	similarity\tagtask	function\tagtask	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	curve\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	dev\tagSEC_CONTENT	set\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	l\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	baseline\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	even\tagSEC_CONTENT	if\tagSEC_CONTENT	we\tagSEC_CONTENT	only\tagSEC_CONTENT	utilize\tagSEC_CONTENT	one\tagSEC_CONTENT	perspective\tagSEC_CONTENT	(\tagSEC_CONTENT	l\tagSEC_CONTENT	=\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	gets\tagSEC_CONTENT	a\tagSEC_CONTENT	significant\tagSEC_CONTENT	improvement\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	increasing\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	improves\tagSEC_CONTENT	significantly\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	cosine\tagSEC_CONTENT	matching\tagSEC_CONTENT	function\tagSEC_CONTENT	is\tagSEC_CONTENT	really\tagSEC_CONTENT	effective\tagSEC_CONTENT	for\tagSEC_CONTENT	matching\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_END	Second\tagSEC_START	,\tagSEC_CONTENT	to\tagSEC_CONTENT	check\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	bilateral\tagSEC_CONTENT	matching\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	build\tagSEC_CONTENT	two\tagSEC_CONTENT	ablation\tagSEC_CONTENT	models\tagSEC_CONTENT	to\tagSEC_CONTENT	matching\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	only\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	direction\tagSEC_CONTENT	:\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	which\tagSEC_CONTENT	only\tagSEC_CONTENT	matches\tagSEC_CONTENT	P\tagSEC_CONTENT	against\tagSEC_CONTENT	Q\tagSEC_CONTENT	;\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	which\tagSEC_CONTENT	only\tagSEC_CONTENT	matches\tagSEC_CONTENT	Q\tagSEC_CONTENT	against\tagSEC_CONTENT	P\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	dev\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	Comparing\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	ablation\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	Full\tagSEC_CONTENT	Model\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	observe\tagSEC_CONTENT	that\tagSEC_CONTENT	single\tagSEC_CONTENT	direction\tagSEC_CONTENT	matching\tagSEC_CONTENT	hurts\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	for\tagSEC_CONTENT	about\tagSEC_CONTENT	1\tagSEC_CONTENT	percent\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	matching\tagSEC_CONTENT	sentences\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	is\tagSEC_CONTENT	really\tagSEC_CONTENT	necessary\tagSEC_CONTENT	for\tagSEC_CONTENT	acquiring\tagSEC_CONTENT	better\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_END	Third\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	different\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategies\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	this\tagSEC_CONTENT	end\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	construct\tagSEC_CONTENT	four\tagSEC_CONTENT	ablation\tagSEC_CONTENT	models\tagSEC_CONTENT	(\tagSEC_CONTENT	w/o\tagSEC_CONTENT	Full\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	,\tagSEC_CONTENT	w/o\tagSEC_CONTENT	Maxpooling\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	,\tagSEC_CONTENT	w/o\tagSEC_CONTENT	Attentive\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	,\tagSEC_CONTENT	w/o\tagSEC_CONTENT	Max\tagSEC_CONTENT	-\tagSEC_CONTENT	Attentive\tagSEC_CONTENT	-\tagSEC_CONTENT	Matching\tagSEC_CONTENT	)\tagSEC_CONTENT	by\tagSEC_CONTENT	eliminating\tagSEC_CONTENT	a\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategy\tagSEC_CONTENT	at\tagSEC_CONTENT	each\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	dev\tagSEC_CONTENT	set\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	eliminating\tagSEC_CONTENT	any\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	matching\tagSEC_CONTENT	strategies\tagSEC_CONTENT	would\tagSEC_CONTENT	hurt\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	significantly\tagSEC_CONTENT	.\tagSEC_END	Models\tagSECTITLE_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Paraphrase\tagSECTITLE_CONTENT	Identification\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	compare\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	theart\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	still\tagSEC_CONTENT	experiment\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	Quora\tagdataset	Question\tagdataset	Pairs\tagdataset	"\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	dataset\tagSEC_CONTENT	partition\tagSEC_CONTENT	as\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	4.2\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	brand\tagSEC_CONTENT	-\tagSEC_CONTENT	new\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	no\tagSEC_CONTENT	previous\tagSEC_CONTENT	results\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	published\tagSEC_CONTENT	yet\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	implemented\tagSEC_CONTENT	three\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	baseline\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_END	First\tagSEC_START	,\tagSEC_CONTENT	under\tagSEC_CONTENT	the\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	framework\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	implement\tagSEC_CONTENT	two\tagSEC_CONTENT	baseline\tagSEC_CONTENT	models\tagSEC_CONTENT	:\tagSEC_CONTENT	"\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Both\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	models\tagSEC_CONTENT	encode\tagSEC_CONTENT	two\tagSEC_CONTENT	input\tagSEC_CONTENT	sentences\tagSEC_CONTENT	into\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	encoder\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	make\tagSEC_CONTENT	a\tagSEC_CONTENT	decision\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagtask	cosine\tagtask	similarity\tagtask	between\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	But\tagSEC_CONTENT	they\tagSEC_CONTENT	implement\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	encoder\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	CNN\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	design\tagSEC_CONTENT	the\tagSEC_CONTENT	CNN\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	model\tagSEC_CONTENT	according\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	architectures\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_END	Second\tagSEC_START	,\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	baseline\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	implement\tagSEC_CONTENT	two\tagSEC_CONTENT	more\tagSEC_CONTENT	baseline\tagSEC_CONTENT	models\tagSEC_CONTENT	"\tagSEC_CONTENT	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	Perspective\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	Perspective\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	these\tagSEC_CONTENT	two\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	change\tagSEC_CONTENT	the\tagSEC_CONTENT	cosine\tagSEC_CONTENT	similarity\tagSEC_CONTENT	calculation\tagSEC_CONTENT	layer\tagSEC_CONTENT	with\tagSEC_CONTENT	our\tagSEC_CONTENT	multiperspective\tagSEC_CONTENT	cosine\tagSEC_CONTENT	matching\tagSEC_CONTENT	function\tagSEC_CONTENT	in\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	apply\tagSEC_CONTENT	a\tagSEC_CONTENT	fully\tagSEC_CONTENT	-\tagSEC_CONTENT	connected\tagSEC_CONTENT	layer\tagSEC_CONTENT	(\tagSEC_CONTENT	with\tagSEC_CONTENT	sigmoid\tagSEC_CONTENT	function\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	)\tagSEC_CONTENT	to\tagSEC_CONTENT	make\tagSEC_CONTENT	the\tagSEC_CONTENT	prediction\tagSEC_CONTENT	.\tagSEC_END	Third\tagSEC_START	,\tagSEC_CONTENT	we\tagSEC_CONTENT	re\tagSEC_CONTENT	-\tagSEC_CONTENT	implement\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	L.D.C.\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	model\tagSEC_CONTENT	under\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	matchingaggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	framework\tagSEC_CONTENT	and\tagSEC_CONTENT	acquires\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	several\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	performances\tagSEC_CONTENT	of\tagSEC_CONTENT	all\tagSEC_CONTENT	baseline\tagSEC_CONTENT	models\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	"\tagSEC_CONTENT	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	Perspective\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	"\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	Multi\tagSEC_CONTENT	-\tagSEC_CONTENT	Perspective\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	works\tagSEC_CONTENT	much\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	"\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	-\tagSEC_CONTENT	CNN\tagSEC_CONTENT	"\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	-\tagSEC_CONTENT	LSTM\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	further\tagSEC_CONTENT	indicates\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	cosine\tagSEC_CONTENT	matching\tagSEC_CONTENT	funcModels\tagSEC_CONTENT	Accuracy\tagSEC_CONTENT	77.6\tagSEC_CONTENT	81.4\tagSEC_CONTENT	82.1\tagSEC_CONTENT	83.5\tagSEC_CONTENT	[\tagSEC_CONTENT	 \tagSEC_CONTENT	85.0\tagSEC_CONTENT	[\tagSEC_CONTENT	 \tagSEC_CONTENT	85.1\tagSEC_CONTENT	86.1\tagSEC_CONTENT	86.3\tagSEC_CONTENT	86.8\tagSEC_CONTENT	87.3\tagSEC_CONTENT	87.5\tagSEC_CONTENT	87.7\tagSEC_CONTENT	88.3\tagSEC_END	Only\tagSEC_START	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	85.6\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	86.3\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	86.9\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	(\tagSEC_CONTENT	Ensemble\tagSEC_CONTENT	)\tagSEC_END	88.8\tagSEC_START	tion\tagSEC_CONTENT	(\tagSEC_CONTENT	Eq\tagSEC_CONTENT	.\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	very\tagSEC_CONTENT	effective\tagSEC_CONTENT	for\tagSEC_CONTENT	matching\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	L.D.C.\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	by\tagSEC_CONTENT	more\tagSEC_CONTENT	than\tagSEC_CONTENT	two\tagSEC_CONTENT	percent\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	very\tagSEC_CONTENT	effective\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Natural\tagSECTITLE_CONTENT	Language\tagSECTITLE_CONTENT	Inference\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	task\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	SNLI\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	test\tagSEC_CONTENT	four\tagSEC_CONTENT	variations\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	single\tagSEC_CONTENT	direction\tagSEC_CONTENT	matching\tagSEC_CONTENT	models\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	4.2\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	is\tagSEC_CONTENT	our\tagSEC_CONTENT	full\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	(\tagSEC_CONTENT	Ensemble\tagSEC_CONTENT	)\tagSEC_CONTENT	"\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	ensemble\tagSEC_CONTENT	version\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	design\tagSEC_CONTENT	the\tagSEC_CONTENT	ensemble\tagSEC_CONTENT	model\tagSEC_CONTENT	by\tagSEC_CONTENT	simply\tagSEC_CONTENT	averaging\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	distributions\tagSEC_CONTENT	of\tagSEC_CONTENT	four\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	each\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	has\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	architecture\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	is\tagSEC_CONTENT	initialized\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	different\tagSEC_CONTENT	seed\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	performances\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	models\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	First\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	works\tagSEC_CONTENT	significantly\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	tells\tagSEC_CONTENT	us\tagSEC_CONTENT	that\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	,\tagSEC_CONTENT	matching\tagSEC_CONTENT	the\tagSEC_CONTENT	hypothesis\tagSEC_CONTENT	against\tagSEC_CONTENT	the\tagSEC_CONTENT	premise\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	effective\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	way\tagSEC_CONTENT	around\tagSEC_CONTENT	.\tagSEC_CONTENT	Second\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	works\tagSEC_CONTENT	much\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	"\tagSEC_CONTENT	Only\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	reveals\tagSEC_CONTENT	that\tagSEC_CONTENT	matching\tagSEC_CONTENT	premise\tagSEC_CONTENT	against\tagSEC_CONTENT	the\tagSEC_CONTENT	hypothesis\tagSEC_CONTENT	can\tagSEC_CONTENT	also\tagSEC_CONTENT	bring\tagSEC_CONTENT	some\tagSEC_CONTENT	benefits\tagSEC_CONTENT	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	comparing\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	observe\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	single\tagSEC_CONTENT	model\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	is\tagSEC_CONTENT	on\tagSEC_CONTENT	par\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	single\tagSEC_CONTENT	models\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	'\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	(\tagSEC_CONTENT	Ensemble\tagSEC_CONTENT	)\tagSEC_CONTENT	"\tagSEC_CONTENT	works\tagSEC_CONTENT	much\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	"\tagSEC_CONTENT	 \tagSEC_CONTENT	(\tagSEC_CONTENT	Ensemble\tagSEC_CONTENT	)\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	models\tagSEC_CONTENT	achieve\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	in\tagSEC_CONTENT	both\tagSEC_CONTENT	single\tagSEC_CONTENT	and\tagSEC_CONTENT	ensemble\tagSEC_CONTENT	scenarios\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_END	Models\tagSECTITLE_END	TREC\tagSECTITLE_START	-\tagSECTITLE_CONTENT	QA\tagSECTITLE_END	WikiQA\tagSEC_START	MAP\tagSEC_CONTENT	MRR\tagSEC_CONTENT	MAP\tagSEC_CONTENT	MRR\tagSEC_CONTENT	 \tagSEC_CONTENT	0.695\tagSEC_CONTENT	0.763\tagSEC_CONTENT	0.652\tagSEC_CONTENT	0.665\tagSEC_CONTENT	0.728\tagSEC_CONTENT	0.832\tagSEC_CONTENT	--Wang\tagSEC_CONTENT	and\tagSEC_CONTENT	Itty\tagSEC_CONTENT	.\tagSEC_CONTENT	0.746\tagSEC_CONTENT	0.820\tagSEC_CONTENT	--\tagSEC_CONTENT	[\tagSEC_CONTENT	0.753\tagSEC_CONTENT	0.851\tagSEC_CONTENT	0.689\tagSEC_CONTENT	0.696\tagSEC_CONTENT	--0.692\tagSEC_CONTENT	0.711\tagSEC_CONTENT	--0.689\tagSEC_CONTENT	0.707\tagSEC_CONTENT	[\tagSEC_CONTENT	0.771\tagSEC_CONTENT	0.845\tagSEC_CONTENT	0.706\tagSEC_CONTENT	0.723\tagSEC_CONTENT	0.777\tagSEC_CONTENT	0.836\tagSEC_CONTENT	0.709\tagSEC_CONTENT	0.723\tagSEC_CONTENT	0.801\tagSEC_CONTENT	0.877\tagSEC_CONTENT	0.701\tagSEC_CONTENT	0.718\tagSEC_CONTENT	[\tagSEC_CONTENT	 \tagSEC_CONTENT	--0.734\tagSEC_CONTENT	0.742\tagSEC_CONTENT	--0.743\tagSEC_CONTENT	0.755\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	0.802\tagSEC_CONTENT	0.875\tagSEC_CONTENT	0.718\tagSEC_CONTENT	0.731\tagSEC_CONTENT	:\tagSEC_CONTENT	Performance\tagSEC_CONTENT	for\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	on\tagSEC_CONTENT	TREC\tagSEC_CONTENT	-\tagSEC_CONTENT	QA\tagSEC_CONTENT	and\tagSEC_CONTENT	WikiQA\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Answer\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	section\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	study\tagSEC_CONTENT	the\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	for\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	task\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	rank\tagSEC_CONTENT	a\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	candidate\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentences\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	their\tagtask	similarities\tagtask	to\tagSEC_CONTENT	the\tagdataset	question\tagdataset	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	is\tagSEC_CONTENT	measured\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	mean\tagSEC_CONTENT	average\tagSEC_CONTENT	precision\tagSEC_CONTENT	(\tagSEC_CONTENT	MAP\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	mean\tagSEC_CONTENT	reciprocal\tagSEC_CONTENT	rank\tagSEC_CONTENT	(\tagSEC_CONTENT	MRR\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	experiment\tagSEC_CONTENT	on\tagSEC_CONTENT	two\tagSEC_CONTENT	datasets\tagSEC_CONTENT	:\tagSEC_CONTENT	TREC\tagSEC_CONTENT	-\tagSEC_CONTENT	QA\tagSEC_CONTENT	[\tagSEC_CONTENT	and\tagSEC_CONTENT	WikiQA\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	models\tagSEC_CONTENT	and\tagSEC_CONTENT	our\tagSEC_CONTENT	"\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	"\tagSEC_CONTENT	model\tagSEC_CONTENT	are\tagSEC_CONTENT	listed\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	performances\tagSEC_CONTENT	are\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	standard\tagSEC_CONTENT	trec\tagSEC_CONTENT	eval-8.0\tagSEC_CONTENT	script\tagSEC_CONTENT	5\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	can\tagSEC_CONTENT	see\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	from\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	on\tagSEC_CONTENT	par\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	also\tagSEC_CONTENT	effective\tagSEC_CONTENT	for\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Natural\tagSEC_START	language\tagSEC_CONTENT	sentence\tagSEC_CONTENT	matching\tagSEC_CONTENT	(\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	)\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	studied\tagSEC_CONTENT	for\tagSEC_CONTENT	many\tagSEC_CONTENT	years\tagSEC_CONTENT	.\tagSEC_CONTENT	Early\tagSEC_CONTENT	approaches\tagSEC_CONTENT	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	designing\tagSEC_CONTENT	hand\tagSEC_CONTENT	-\tagSEC_CONTENT	craft\tagSEC_CONTENT	features\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	n\tagSEC_CONTENT	-\tagSEC_CONTENT	gram\tagSEC_CONTENT	overlapping\tagSEC_CONTENT	,\tagSEC_CONTENT	word\tagSEC_CONTENT	reordering\tagSEC_CONTENT	and\tagSEC_CONTENT	syntactic\tagSEC_CONTENT	alignments\tagSEC_CONTENT	phenomena\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	kind\tagSEC_CONTENT	of\tagSEC_CONTENT	method\tagSEC_CONTENT	can\tagSEC_CONTENT	work\tagSEC_CONTENT	well\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	specific\tagSEC_CONTENT	task\tagSEC_CONTENT	or\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	it\tagSEC_CONTENT	's\tagSEC_CONTENT	hard\tagSEC_CONTENT	to\tagSEC_CONTENT	generalize\tagSEC_CONTENT	well\tagSEC_CONTENT	to\tagSEC_CONTENT	other\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_CONTENT	With\tagSEC_CONTENT	the\tagSEC_CONTENT	availability\tagSEC_CONTENT	of\tagSEC_CONTENT	large\tagSEC_CONTENT	-\tagSEC_CONTENT	scale\tagSEC_CONTENT	annotated\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	many\tagSEC_CONTENT	deep\tagSEC_CONTENT	learning\tagSEC_CONTENT	models\tagSEC_CONTENT	were\tagSEC_CONTENT	proposed\tagSEC_CONTENT	for\tagSEC_CONTENT	NLSM\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	first\tagSEC_CONTENT	kind\tagSEC_CONTENT	of\tagSEC_CONTENT	framework\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	the\tagSEC_CONTENT	Siamese\tagSEC_CONTENT	architecture\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	sentences\tagSEC_CONTENT	are\tagSEC_CONTENT	encoded\tagSEC_CONTENT	into\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	some\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	encoders\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	then\tagSEC_CONTENT	the\tagSEC_CONTENT	relationship\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	was\tagSEC_CONTENT	decided\tagSEC_CONTENT	solely\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentence\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	kind\tagSEC_CONTENT	of\tagSEC_CONTENT	framework\tagSEC_CONTENT	ignores\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	lower\tagSEC_CONTENT	level\tagSEC_CONTENT	interactive\tagSEC_CONTENT	features\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	[\tagSEC_CONTENT	pointed\tagSEC_CONTENT	out\tagSEC_CONTENT	that\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	versions\tagSEC_CONTENT	of\tagSEC_CONTENT	TREC\tagSEC_CONTENT	-\tagSEC_CONTENT	QA\tagSEC_CONTENT	dataset\tagSEC_CONTENT	:\tagSEC_CONTENT	raw\tagSEC_CONTENT	-\tagSEC_CONTENT	version\tagSEC_CONTENT	and\tagSEC_CONTENT	clean\tagSEC_CONTENT	-\tagSEC_CONTENT	version\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	utilized\tagSEC_CONTENT	the\tagSEC_CONTENT	clean\tagSEC_CONTENT	-\tagSEC_CONTENT	version\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	only\tagSEC_CONTENT	compare\tagSEC_CONTENT	with\tagSEC_CONTENT	approaches\tagSEC_CONTENT	reporting\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	5\tagSEC_CONTENT	http://trec.nist.gove/trec\tagSEC_CONTENT	eval/\tagSEC_CONTENT	sentences\tagSEC_CONTENT	are\tagSEC_CONTENT	indispensable\tagSEC_CONTENT	.\tagSEC_CONTENT	Therefore\tagSEC_CONTENT	,\tagSEC_CONTENT	many\tagSEC_CONTENT	neural\tagSEC_CONTENT	network\tagSEC_CONTENT	models\tagSEC_CONTENT	were\tagSEC_CONTENT	proposed\tagSEC_CONTENT	to\tagSEC_CONTENT	match\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	level\tagSEC_CONTENT	of\tagSEC_CONTENT	granularity\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	many\tagSEC_CONTENT	tasks\tagSEC_CONTENT	have\tagSEC_CONTENT	proofed\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	new\tagSEC_CONTENT	framework\tagSEC_CONTENT	works\tagSEC_CONTENT	significantly\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	methods\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	model\tagSEC_CONTENT	also\tagSEC_CONTENT	belongs\tagSEC_CONTENT	to\tagSEC_CONTENT	this\tagSEC_CONTENT	framework\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	have\tagSEC_CONTENT	shown\tagSEC_CONTENT	its\tagSEC_CONTENT	effectiveness\tagSEC_CONTENT	in\tagSEC_CONTENT	Section\tagSEC_CONTENT	4\tagSEC_CONTENT	.\tagSEC_END	Conclusion\tagSECTITLE_END	In\tagSEC_START	this\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	a\tagSEC_CONTENT	bilateral\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	perspective\tagSEC_CONTENT	matching\tagSEC_CONTENT	(\tagSEC_CONTENT	BiMPM\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	under\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	matching\tagSEC_CONTENT	-\tagSEC_CONTENT	aggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	framework\tagSEC_CONTENT	.\tagSEC_CONTENT	Different\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	"\tagSEC_CONTENT	matchingaggregation\tagSEC_CONTENT	"\tagSEC_CONTENT	approaches\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	matches\tagSEC_CONTENT	sentences\tagSEC_CONTENT	P\tagSEC_CONTENT	and\tagSEC_CONTENT	Q\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	directions\tagSEC_CONTENT	(\tagSEC_CONTENT	P\tagSEC_CONTENT	→\tagSEC_CONTENT	Q\tagSEC_CONTENT	and\tagSEC_CONTENT	P\tagSEC_CONTENT	←\tagSEC_CONTENT	Q\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	And\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	each\tagSEC_CONTENT	individual\tagSEC_CONTENT	direction\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	matches\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	sentences\tagSEC_CONTENT	from\tagSEC_CONTENT	multiple\tagSEC_CONTENT	perspectives\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	three\tagSEC_CONTENT	tasks\tagSEC_CONTENT	:\tagSEC_CONTENT	paraphrase\tagSEC_CONTENT	identification\tagSEC_CONTENT	,\tagSEC_CONTENT	natural\tagSEC_CONTENT	language\tagSEC_CONTENT	inference\tagSEC_CONTENT	and\tagSEC_CONTENT	answer\tagSEC_CONTENT	sentence\tagSEC_CONTENT	selection\tagSEC_CONTENT	.\tagSEC_CONTENT	Experimental\tagSEC_CONTENT	results\tagSEC_CONTENT	on\tagSEC_CONTENT	standard\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	datasets\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	achieves\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	performance\tagSEC_CONTENT	on\tagSEC_CONTENT	all\tagSEC_CONTENT	tasks\tagSEC_CONTENT	.\tagSEC_END	
S18-1012	title\tagSECTITLE_END	Chrono\tagSEC_START	at\tagSEC_CONTENT	SemEval-2018\tagSEC_CONTENT	Task\tagSEC_CONTENT	6\tagSEC_CONTENT	:\tagSEC_CONTENT	A\tagSEC_CONTENT	System\tagSEC_CONTENT	for\tagSEC_CONTENT	Normalizing\tagSEC_CONTENT	Temporal\tagSEC_CONTENT	Expressions\tagSEC_END	abstract\tagSECTITLE_END	Temporal\tagSEC_START	information\tagtask	extraction\tagtask	is\tagSEC_CONTENT	a\tagSEC_CONTENT	challenging\tagSEC_CONTENT	task\tagSEC_CONTENT	.\tagSEC_CONTENT	Here\tagSEC_CONTENT	we\tagSEC_CONTENT	describe\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	hybrid\tagSEC_CONTENT	rule\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	and\tagSEC_CONTENT	machine\tagSEC_CONTENT	learning\tagSEC_CONTENT	system\tagSEC_CONTENT	that\tagSEC_CONTENT	identifies\tagSEC_CONTENT	temporal\tagtask	expressions\tagtask	in\tagSEC_CONTENT	text\tagSEC_CONTENT	and\tagSEC_CONTENT	normalizes\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	schema\tagSEC_CONTENT	.\tagSEC_CONTENT	After\tagSEC_CONTENT	minor\tagSEC_CONTENT	parsing\tagSEC_CONTENT	logic\tagSEC_CONTENT	adjustments\tagSEC_CONTENT	,\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	has\tagSEC_CONTENT	emerged\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	performing\tagSEC_CONTENT	system\tagSEC_CONTENT	for\tagSEC_CONTENT	SemEval\tagSEC_CONTENT	2018\tagSEC_CONTENT	Task\tagSEC_CONTENT	6\tagSEC_CONTENT	:\tagSEC_CONTENT	Parsing\tagSEC_CONTENT	Time\tagtask	Normal\tagtask	-\tagtask	izations\tagtask	.\tagSEC_END	Introduction\tagSECTITLE_END	Understanding\tagSEC_START	and\tagSEC_CONTENT	processing\tagSEC_CONTENT	temporal\tagtask	information\tagtask	is\tagSEC_CONTENT	vital\tagSEC_CONTENT	for\tagSEC_CONTENT	navigating\tagSEC_CONTENT	life\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	human\tagSEC_CONTENT	mind\tagSEC_CONTENT	processes\tagSEC_CONTENT	subtle\tagSEC_CONTENT	temporal\tagSEC_CONTENT	expressions\tagSEC_CONTENT	instantly\tagSEC_CONTENT	and\tagSEC_CONTENT	effortlessly\tagSEC_CONTENT	;\tagSEC_CONTENT	however\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	difficult\tagSEC_CONTENT	for\tagSEC_CONTENT	computers\tagSEC_CONTENT	to\tagSEC_CONTENT	do\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	.\tagSEC_CONTENT	Identifying\tagSEC_CONTENT	,\tagSEC_CONTENT	processing\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	utilizing\tagSEC_CONTENT	this\tagtask	information\tagtask	requires\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	and\tagSEC_CONTENT	understanding\tagSEC_CONTENT	of\tagSEC_CONTENT	syntax\tagSEC_CONTENT	,\tagSEC_CONTENT	semantics\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	context\tagSEC_CONTENT	to\tagSEC_CONTENT	link\tagSEC_CONTENT	temporal\tagtask	information\tagtask	to\tagSEC_CONTENT	related\tagSEC_CONTENT	events\tagSEC_CONTENT	and\tagSEC_CONTENT	order\tagSEC_CONTENT	them\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagSEC_CONTENT	time\tagSEC_CONTENT	-\tagSEC_CONTENT	line\tagSEC_CONTENT	.\tagSEC_CONTENT	)\tagSEC_CONTENT	aims\tagSEC_CONTENT	to\tagSEC_CONTENT	normalize\tagSEC_CONTENT	fine\tagSEC_CONTENT	-\tagSEC_CONTENT	grained\tagSEC_CONTENT	temporal\tagSEC_CONTENT	information\tagSEC_CONTENT	and\tagSEC_CONTENT	relationships\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	Semantically\tagSEC_CONTENT	Compositional\tagSEC_CONTENT	Annotations\tagSEC_CONTENT	for\tagSEC_CONTENT	Temporal\tagSEC_CONTENT	Expressions\tagSEC_CONTENT	(\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	)\tagSEC_CONTENT	schema\tagSEC_CONTENT	developed\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	scheme\tagSEC_CONTENT	aims\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	upon\tagSEC_CONTENT	the\tagSEC_CONTENT	current\tagSEC_CONTENT	TIMEX3\tagSEC_CONTENT	/\tagSEC_CONTENT	TimeML\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	standard\tagSEC_CONTENT	by\tagSEC_CONTENT	representing\tagSEC_CONTENT	a\tagSEC_CONTENT	wide\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	temporal\tagtask	expressions\tagtask	,\tagSEC_CONTENT	allowing\tagSEC_CONTENT	for\tagSEC_CONTENT	events\tagSEC_CONTENT	to\tagSEC_CONTENT	act\tagSEC_CONTENT	as\tagSEC_CONTENT	anchors\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	using\tagSEC_CONTENT	mathematical\tagSEC_CONTENT	operations\tagSEC_CONTENT	over\tagSEC_CONTENT	a\tagSEC_CONTENT	timeline\tagSEC_CONTENT	to\tagSEC_CONTENT	define\tagSEC_CONTENT	the\tagSEC_CONTENT	semantics\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagtask	annotation\tagtask	.\tagSEC_CONTENT	To\tagSEC_CONTENT	address\tagSEC_CONTENT	this\tagSEC_CONTENT	challenge\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	developed\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	hybrid\tagSEC_CONTENT	rule\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	and\tagSEC_CONTENT	machine\tagSEC_CONTENT	learning\tagSEC_CONTENT	(\tagSEC_CONTENT	ML\tagSEC_CONTENT	)\tagSEC_CONTENT	Python\tagSEC_CONTENT	package\tagSEC_CONTENT	that\tagSEC_CONTENT	normalizes\tagSEC_CONTENT	temporal\tagtask	expressions\tagtask	into\tagSEC_CONTENT	the\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	schema\tagSEC_CONTENT	.\tagSEC_END	https://github.com/AmyOlex/Chrono\tagSECTITLE_END	The\tagSECTITLE_START	Chrono\tagSECTITLE_CONTENT	System\tagSECTITLE_END	Our\tagSEC_START	approach\tagSEC_CONTENT	to\tagSEC_CONTENT	building\tagSEC_CONTENT	this\tagSEC_CONTENT	hybrid\tagSEC_CONTENT	system\tagSEC_CONTENT	includes\tagSEC_CONTENT	four\tagSEC_CONTENT	processing\tagSEC_CONTENT	phases\tagSEC_CONTENT	:\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	text\tagSEC_CONTENT	preprocessing\tagSEC_CONTENT	,\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	flagging\tagSEC_CONTENT	numeric\tagSEC_CONTENT	and\tagSEC_CONTENT	temporal\tagSEC_CONTENT	tokens\tagSEC_CONTENT	,\tagSEC_CONTENT	3\tagSEC_CONTENT	)\tagSEC_CONTENT	temporal\tagSEC_CONTENT	expression\tagSEC_CONTENT	identification\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	4\tagtask	)\tagtask	SCATE\tagtask	normalization\tagtask	.\tagSEC_END	1\tagSEC_START	)\tagSEC_CONTENT	Text\tagSEC_CONTENT	Pre\tagSEC_CONTENT	-\tagSEC_CONTENT	processing\tagSEC_CONTENT	:\tagSEC_CONTENT	Python\tagSEC_CONTENT	's\tagSEC_CONTENT	Natural\tagSEC_CONTENT	Language\tagSEC_CONTENT	Toolkit\tagSEC_CONTENT	(\tagSEC_CONTENT	NLTK\tagSEC_CONTENT	)\tagSEC_CONTENT	WhitespaceTokenizer\tagSEC_CONTENT	and\tagSEC_CONTENT	part\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	speech\tagSEC_CONTENT	(\tagSEC_CONTENT	POS\tagSEC_CONTENT	)\tagSEC_CONTENT	tagger\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	process\tagSEC_CONTENT	raw\tagSEC_CONTENT	text\tagSEC_CONTENT	files\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	individual\tagSEC_CONTENT	tokens\tagSEC_CONTENT	,\tagSEC_CONTENT	token\tagSEC_CONTENT	spans\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	.\tagSEC_CONTENT	Punctuation\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	handled\tagSEC_CONTENT	at\tagSEC_CONTENT	this\tagSEC_CONTENT	phase\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	important\tagSEC_CONTENT	for\tagSEC_CONTENT	identifying\tagSEC_CONTENT	correct\tagSEC_CONTENT	spans\tagSEC_CONTENT	.\tagSEC_END	2\tagSEC_START	)\tagSEC_CONTENT	Flagging\tagSEC_CONTENT	Numeric\tagSEC_CONTENT	and\tagSEC_CONTENT	Temporal\tagtask	Tokens\tagtask	:\tagSEC_CONTENT	All\tagSEC_CONTENT	numeric\tagSEC_CONTENT	tokens\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	regardless\tagSEC_CONTENT	of\tagSEC_CONTENT	context\tagSEC_CONTENT	.\tagSEC_CONTENT	Subsequent\tagSEC_CONTENT	phases\tagSEC_CONTENT	utilize\tagSEC_CONTENT	contextual\tagtask	information\tagtask	to\tagSEC_CONTENT	determine\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	numeric\tagSEC_CONTENT	token\tagSEC_CONTENT	is\tagSEC_CONTENT	part\tagdataset	of\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	expression\tagSEC_CONTENT	.\tagSEC_CONTENT	Depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	rule\tagSEC_CONTENT	may\tagSEC_CONTENT	remove\tagSEC_CONTENT	all\tagSEC_CONTENT	or\tagSEC_CONTENT	some\tagtask	punctuation\tagtask	,\tagSEC_CONTENT	and/or\tagSEC_CONTENT	convert\tagSEC_CONTENT	tokens\tagSEC_CONTENT	to\tagSEC_CONTENT	lowercase\tagSEC_CONTENT	prior\tagSEC_CONTENT	to\tagSEC_CONTENT	parsing\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	,\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	denote\tagSEC_CONTENT	Removing\tagSEC_CONTENT	all\tagSEC_CONTENT	Punctuation\tagSEC_CONTENT	and\tagSEC_CONTENT	converting\tagSEC_CONTENT	to\tagSEC_CONTENT	LowerCase\tagSEC_CONTENT	,\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_END	Numeric\tagSEC_START	Flagging\tagSEC_CONTENT	:\tagSEC_CONTENT	Tokens\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	as\tagSEC_CONTENT	numeric\tagSEC_CONTENT	if\tagSEC_CONTENT	either\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	the\tagSEC_CONTENT	token\tagSEC_CONTENT	has\tagSEC_CONTENT	a\tagSEC_CONTENT	POS\tagSEC_CONTENT	tag\tagSEC_CONTENT	of\tagSEC_CONTENT	"\tagSEC_CONTENT	CD\tagSEC_CONTENT	"\tagSEC_CONTENT	(\tagSEC_CONTENT	Cardinal\tagSEC_CONTENT	Number\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	converted\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	numeric\tagSEC_CONTENT	expression\tagSEC_CONTENT	.\tagSEC_CONTENT	Textual\tagtask	representations\tagtask	of\tagSEC_CONTENT	numeric\tagSEC_CONTENT	expressions\tagSEC_CONTENT	are\tagSEC_CONTENT	converted\tagSEC_CONTENT	to\tagSEC_CONTENT	numerics\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	Word2Number\tagSEC_CONTENT	2\tagSEC_CONTENT	Python\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	custom\tagSEC_CONTENT	method\tagSEC_CONTENT	recognizes\tagSEC_CONTENT	ordinals\tagSEC_CONTENT	from\tagSEC_CONTENT	"\tagSEC_CONTENT	first\tagSEC_CONTENT	"\tagSEC_CONTENT	to\tagSEC_CONTENT	"\tagSEC_CONTENT	thirty\tagSEC_CONTENT	-\tagSEC_CONTENT	first\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	converts\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	associated\tagSEC_CONTENT	numerics\tagSEC_CONTENT	1\tagSEC_CONTENT	to\tagSEC_CONTENT	31\tagSEC_CONTENT	,\tagSEC_CONTENT	respectively\tagSEC_CONTENT	.\tagSEC_CONTENT	LC\tagtask	normalization\tagtask	is\tagSEC_CONTENT	done\tagSEC_CONTENT	prior\tagSEC_CONTENT	to\tagSEC_CONTENT	parsing\tagSEC_CONTENT	textual\tagSEC_CONTENT	numerics\tagSEC_CONTENT	.\tagSEC_END	Temporal\tagSEC_START	Flagging\tagSEC_CONTENT	:\tagSEC_CONTENT	Temporal\tagtask	tokens\tagtask	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	through\tagSEC_CONTENT	rule\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	parsing\tagSEC_CONTENT	using\tagSEC_CONTENT	lists\tagSEC_CONTENT	of\tagSEC_CONTENT	key\tagSEC_CONTENT	words\tagSEC_CONTENT	and\tagSEC_CONTENT	regular\tagSEC_CONTENT	expressions\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	phase\tagSEC_CONTENT	is\tagSEC_CONTENT	more\tagSEC_CONTENT	liberal\tagSEC_CONTENT	in\tagSEC_CONTENT	its\tagtask	identification\tagtask	of\tagSEC_CONTENT	a\tagtask	temporal\tagtask	token\tagtask	than\tagSEC_CONTENT	the\tagtask	SCATE\tagtask	normalization\tagtask	phase\tagtask	,\tagSEC_CONTENT	so\tagSEC_CONTENT	it\tagSEC_CONTENT	identifies\tagSEC_CONTENT	a\tagSEC_CONTENT	broader\tagSEC_CONTENT	range\tagSEC_CONTENT	of\tagSEC_CONTENT	potential\tagSEC_CONTENT	temporal\tagSEC_CONTENT	tokens\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	refined\tagSEC_CONTENT	in\tagSEC_CONTENT	future\tagSEC_CONTENT	steps\tagSEC_CONTENT	.\tagSEC_CONTENT	Tokens\tagSEC_CONTENT	maybe\tagSEC_CONTENT	numeric\tagSEC_CONTENT	and\tagSEC_CONTENT	temporal\tagSEC_CONTENT	simultaneously\tagSEC_CONTENT	.\tagSEC_CONTENT	Numeric\tagSEC_CONTENT	tokens\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	characters\tagSEC_CONTENT	'\tagSEC_CONTENT	$\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	#\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	'\tagSEC_CONTENT	%\tagSEC_CONTENT	'\tagSEC_CONTENT	are\tagSEC_CONTENT	NOT\tagSEC_CONTENT	marked\tagSEC_CONTENT	as\tagSEC_CONTENT	temporal\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	following\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	tokens\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	as\tagSEC_CONTENT	temporal\tagSEC_CONTENT	:\tagSEC_END	•\tagSEC_START	Formatted\tagSEC_CONTENT	date\tagSEC_CONTENT	patterns\tagSEC_CONTENT	using\tagSEC_CONTENT	'\tagSEC_CONTENT	/\tagSEC_CONTENT	'\tagSEC_CONTENT	or\tagSEC_CONTENT	'\tagSEC_CONTENT	-\tagSEC_CONTENT	'\tagSEC_CONTENT	:\tagSEC_CONTENT	mm\tagSEC_CONTENT	/\tagSEC_CONTENT	dd\tagSEC_CONTENT	/\tagSEC_CONTENT	yyyy\tagSEC_CONTENT	,\tagSEC_CONTENT	mm\tagSEC_CONTENT	/\tagSEC_CONTENT	dd\tagSEC_CONTENT	/\tagSEC_CONTENT	yy\tagSEC_CONTENT	,\tagSEC_CONTENT	yyyy\tagSEC_CONTENT	/\tagSEC_CONTENT	mm\tagSEC_CONTENT	/\tagSEC_CONTENT	dd\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	yy\tagSEC_CONTENT	/\tagSEC_CONTENT	mm\tagSEC_CONTENT	/\tagSEC_CONTENT	dd\tagSEC_CONTENT	•\tagSEC_CONTENT	Formatted\tagSEC_CONTENT	time\tagSEC_CONTENT	patterns\tagSEC_CONTENT	matching\tagSEC_CONTENT	hh\tagSEC_CONTENT	:\tagSEC_CONTENT	mm\tagSEC_CONTENT	:\tagSEC_CONTENT	ss\tagSEC_CONTENT	•\tagSEC_CONTENT	Sequence\tagSEC_CONTENT	of\tagSEC_CONTENT	4\tagSEC_CONTENT	to\tagSEC_CONTENT	8\tagSEC_CONTENT	consecutive\tagSEC_CONTENT	digits\tagSEC_CONTENT	matching\tagSEC_CONTENT	range\tagSEC_CONTENT	criteria\tagSEC_CONTENT	for\tagSEC_CONTENT	24-hour\tagSEC_CONTENT	times\tagSEC_CONTENT	or\tagSEC_CONTENT	fora\tagSEC_CONTENT	year\tagSEC_CONTENT	,\tagSEC_CONTENT	month\tagSEC_CONTENT	,\tagSEC_CONTENT	and/or\tagSEC_CONTENT	day\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	1998\tagSEC_CONTENT	or\tagSEC_CONTENT	08241998\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Spelled\tagSEC_CONTENT	out\tagSEC_CONTENT	month\tagSEC_CONTENT	or\tagSEC_CONTENT	abbreviation\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	Mar.\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	March\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	except\tagSEC_CONTENT	periods\tagSEC_CONTENT	as\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	required\tagSEC_CONTENT	to\tagSEC_CONTENT	retrieve\tagSEC_CONTENT	correct\tagSEC_CONTENT	spans\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Days\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	week\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	Sat\tagSEC_CONTENT	.\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	Saturday\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	parsed\tagSEC_CONTENT	similar\tagSEC_CONTENT	to\tagSEC_CONTENT	months\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Temporal\tagSEC_CONTENT	words\tagSEC_CONTENT	indicating\tagSEC_CONTENT	periods\tagSEC_CONTENT	of\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	yesterday\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	decade\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Mentions\tagSEC_CONTENT	of\tagSEC_CONTENT	AM\tagSEC_CONTENT	and\tagSEC_CONTENT	PM\tagSEC_CONTENT	in\tagSEC_CONTENT	any\tagSEC_CONTENT	format\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	except\tagSEC_CONTENT	periods\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	The\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	week\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	weekend\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	weekends\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Seasons\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	year\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Various\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	day\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	noon\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	morning\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Time\tagSEC_CONTENT	zones\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Other\tagSEC_CONTENT	temporal\tagSEC_CONTENT	words\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	this\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	now\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	nearly\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	others\tagSEC_CONTENT	,\tagSEC_CONTENT	are\tagSEC_CONTENT	flagged\tagSEC_CONTENT	after\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_END	3\tagSEC_START	)\tagSEC_CONTENT	Temporal\tagSEC_CONTENT	Expression\tagSEC_CONTENT	Identification\tagSEC_CONTENT	:\tagSEC_CONTENT	A\tagSEC_CONTENT	temporal\tagSEC_CONTENT	expression\tagSEC_CONTENT	is\tagSEC_CONTENT	represented\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	define\tagSEC_CONTENT	as\tagSEC_CONTENT	two\tagSEC_CONTENT	or\tagSEC_CONTENT	more\tagSEC_CONTENT	consecutive\tagSEC_CONTENT	temporal\tagSEC_CONTENT	/\tagSEC_CONTENT	numeric\tagSEC_CONTENT	tokens\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	line\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	an\tagSEC_CONTENT	isolated\tagSEC_CONTENT	temporal\tagSEC_CONTENT	token\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	some\tagSEC_CONTENT	exceptions\tagSEC_CONTENT	.\tagSEC_CONTENT	If\tagSEC_CONTENT	a\tagSEC_CONTENT	numeric\tagSEC_CONTENT	token\tagSEC_CONTENT	contains\tagSEC_CONTENT	a\tagSEC_CONTENT	'\tagSEC_CONTENT	$\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	#\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	'\tagSEC_CONTENT	%\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagSEC_CONTENT	text\tagSEC_CONTENT	'\tagSEC_CONTENT	million\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	'\tagSEC_CONTENT	billion\tagSEC_CONTENT	'\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	'\tagSEC_CONTENT	trillion\tagSEC_CONTENT	'\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	included\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	as\tagSEC_CONTENT	these\tagSEC_CONTENT	generally\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	temporal\tagSEC_CONTENT	values\tagSEC_CONTENT	.\tagSEC_CONTENT	Additionally\tagSEC_CONTENT	,\tagSEC_CONTENT	isolated\tagSEC_CONTENT	numeric\tagSEC_CONTENT	tokens\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	considered\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	.\tagSEC_END	4\tagSECTITLE_START	)\tagSECTITLE_CONTENT	SCATE\tagSECTITLE_CONTENT	Normalization\tagSECTITLE_CONTENT	:\tagSECTITLE_END	Chrono\tagSEC_START	parses\tagSEC_CONTENT	each\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	into\tagSEC_CONTENT	zero\tagSEC_CONTENT	or\tagSEC_CONTENT	more\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	links\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	disambiguates\tagSEC_CONTENT	the\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	entities\tagSEC_CONTENT	"\tagSEC_CONTENT	Period\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	Calendar\tagSEC_CONTENT	-\tagSEC_CONTENT	Interval\tagSEC_CONTENT	"\tagSEC_CONTENT	via\tagSEC_CONTENT	a\tagSEC_CONTENT	machine\tagSEC_CONTENT	learning\tagSEC_CONTENT	module\tagSEC_CONTENT	.\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	implements\tagSEC_CONTENT	32\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	entities\tagSEC_CONTENT	with\tagSEC_CONTENT	5\tagSEC_CONTENT	parent\tagSEC_CONTENT	types\tagSEC_CONTENT	that\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	described\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	Parsing\tagSEC_CONTENT	strategies\tagSEC_CONTENT	differ\tagSEC_CONTENT	depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagtask	composition\tagtask	of\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	being\tagSEC_CONTENT	parsed\tagSEC_CONTENT	.\tagSEC_CONTENT	Each\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	is\tagSEC_CONTENT	interrogated\tagSEC_CONTENT	by\tagSEC_CONTENT	all\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	parsing\tagSEC_CONTENT	strategies\tagSEC_CONTENT	.\tagSEC_END	Formatted\tagSECTITLE_START	Dates\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Times\tagSECTITLE_CONTENT	:\tagSECTITLE_END	Formatted\tagSEC_START	dates\tagSEC_CONTENT	/\tagSEC_CONTENT	times\tagSEC_CONTENT	are\tagSEC_CONTENT	parsed\tagSEC_CONTENT	using\tagSEC_CONTENT	regular\tagSEC_CONTENT	expressions\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	identify\tagSEC_CONTENT	which\tagSEC_CONTENT	format\tagSEC_CONTENT	the\tagSEC_CONTENT	date\tagSEC_CONTENT	/\tagSEC_CONTENT	time\tagSEC_CONTENT	is\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	looks\tagSEC_CONTENT	fora\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	or\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	first\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	uses\tagSEC_CONTENT	that\tagSEC_CONTENT	position\tagSEC_CONTENT	for\tagSEC_CONTENT	orientation\tagtask	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	the\tagSEC_CONTENT	remaining\tagSEC_CONTENT	elements\tagSEC_CONTENT	.\tagSEC_CONTENT	If\tagSEC_CONTENT	a\tagSEC_CONTENT	formatted\tagSEC_CONTENT	date\tagSEC_CONTENT	/\tagSEC_CONTENT	time\tagSEC_CONTENT	is\tagSEC_CONTENT	identified\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	the\tagSEC_CONTENT	appropriate\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	are\tagSEC_CONTENT	linked\tagSEC_CONTENT	during\tagSEC_CONTENT	element\tagSEC_CONTENT	parsing\tagSEC_CONTENT	.\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	years\tagSEC_CONTENT	take\tagSEC_CONTENT	precedence\tagSEC_CONTENT	over\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	years\tagSEC_CONTENT	.\tagSEC_END	Numeric\tagSEC_START	Dates\tagSEC_CONTENT	and\tagSEC_CONTENT	Times\tagSEC_CONTENT	:\tagSEC_CONTENT	Header\tagSEC_CONTENT	and\tagSEC_CONTENT	metadata\tagSEC_CONTENT	for\tagSEC_CONTENT	Newswire\tagSEC_CONTENT	articles\tagSEC_CONTENT	frequently\tagSEC_CONTENT	have\tagSEC_CONTENT	numeric\tagSEC_CONTENT	dates\tagSEC_CONTENT	listed\tagSEC_CONTENT	with\tagSEC_CONTENT	no\tagSEC_CONTENT	punctuation\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	19980218\tagSEC_CONTENT	"\tagSEC_CONTENT	codes\tagSEC_CONTENT	for\tagSEC_CONTENT	"\tagSEC_CONTENT	Feb\tagSEC_CONTENT	,\tagSEC_CONTENT	18\tagSEC_CONTENT	1998\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	isolated\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	mentions\tagSEC_CONTENT	are\tagSEC_CONTENT	frequent\tagSEC_CONTENT	.\tagSEC_CONTENT	After\tagSEC_CONTENT	formatted\tagSEC_CONTENT	dates\tagSEC_CONTENT	and\tagSEC_CONTENT	times\tagSEC_CONTENT	are\tagSEC_CONTENT	parsed\tagSEC_CONTENT	,\tagSEC_CONTENT	any\tagSEC_CONTENT	phrase\tagSEC_CONTENT	containing\tagSEC_CONTENT	a\tagSEC_CONTENT	numeric\tagSEC_CONTENT	token\tagSEC_CONTENT	is\tagSEC_CONTENT	interrogated\tagSEC_CONTENT	fora\tagSEC_CONTENT	potential\tagSEC_CONTENT	date\tagSEC_CONTENT	or\tagSEC_CONTENT	year\tagSEC_CONTENT	mention\tagSEC_CONTENT	.\tagSEC_CONTENT	If\tagSEC_CONTENT	a\tagSEC_CONTENT	numeric\tagSEC_CONTENT	token\tagSEC_CONTENT	is\tagSEC_CONTENT	4-digits\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	tested\tagSEC_CONTENT	fora\tagSEC_CONTENT	year\tagSEC_CONTENT	between\tagSEC_CONTENT	1500\tagSEC_CONTENT	and\tagSEC_CONTENT	2050\tagSEC_CONTENT	,\tagSEC_CONTENT	6-digit\tagSEC_CONTENT	tokens\tagSEC_CONTENT	are\tagSEC_CONTENT	parsed\tagSEC_CONTENT	for\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	/\tagSEC_CONTENT	month\tagSEC_CONTENT	/\tagSEC_CONTENT	day\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	8-digit\tagSEC_CONTENT	strings\tagSEC_CONTENT	are\tagSEC_CONTENT	parsed\tagSEC_CONTENT	fora\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	and\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	month\tagSEC_CONTENT	/\tagSEC_CONTENT	day\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	elements\tagSEC_CONTENT	must\tagSEC_CONTENT	be\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	proper\tagSEC_CONTENT	range\tagSEC_CONTENT	,\tagSEC_CONTENT	otherwise\tagSEC_CONTENT	the\tagSEC_CONTENT	token\tagSEC_CONTENT	is\tagSEC_CONTENT	skipped\tagSEC_CONTENT	.\tagSEC_CONTENT	Appropriate\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	are\tagSEC_CONTENT	linked\tagSEC_CONTENT	during\tagSEC_CONTENT	element\tagSEC_CONTENT	parsing\tagSEC_CONTENT	.\tagSEC_END	24-hour\tagSEC_START	Time\tagSEC_CONTENT	:\tagSEC_CONTENT	24-hour\tagSEC_CONTENT	times\tagSEC_CONTENT	are\tagSEC_CONTENT	identified\tagSEC_CONTENT	by\tagSEC_CONTENT	either\tagSEC_CONTENT	the\tagSEC_CONTENT	format\tagSEC_CONTENT	hhmmzzz\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	zzz\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	timezone\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	a\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	number\tagSEC_CONTENT	that\tagSEC_CONTENT	has\tagSEC_CONTENT	not\tagSEC_CONTENT	been\tagSEC_CONTENT	classified\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	year\tagSEC_CONTENT	.\tagSEC_CONTENT	Hour\tagSEC_CONTENT	digits\tagSEC_CONTENT	must\tagSEC_CONTENT	be\tagSEC_CONTENT	less\tagSEC_CONTENT	than\tagSEC_CONTENT	24\tagSEC_CONTENT	and\tagSEC_CONTENT	minutes\tagSEC_CONTENT	less\tagSEC_CONTENT	than\tagSEC_CONTENT	60\tagSEC_CONTENT	.\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	are\tagSEC_CONTENT	linked\tagSEC_CONTENT	at\tagSEC_CONTENT	this\tagSEC_CONTENT	time\tagSEC_CONTENT	if\tagSEC_CONTENT	existing\tagSEC_CONTENT	.\tagSEC_CONTENT	Time\tagSEC_CONTENT	zones\tagSEC_CONTENT	are\tagSEC_CONTENT	handled\tagSEC_CONTENT	separately\tagSEC_CONTENT	and\tagSEC_CONTENT	are\tagSEC_CONTENT	linked\tagSEC_CONTENT	back\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	hour\tagSEC_CONTENT	entity\tagSEC_CONTENT	during\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	interval\tagSEC_CONTENT	linking\tagSEC_CONTENT	step\tagSEC_CONTENT	.\tagSEC_END	Temporal\tagSEC_START	Token\tagSEC_CONTENT	Search\tagSEC_CONTENT	:\tagSEC_CONTENT	The\tagSEC_CONTENT	majority\tagSEC_CONTENT	of\tagSEC_CONTENT	textual\tagSEC_CONTENT	temporal\tagSEC_CONTENT	entities\tagSEC_CONTENT	are\tagSEC_CONTENT	identified\tagSEC_CONTENT	by\tagSEC_CONTENT	looking\tagSEC_CONTENT	for\tagSEC_CONTENT	specific\tagSEC_CONTENT	tokens\tagSEC_CONTENT	.\tagSEC_CONTENT	Token\tagSEC_CONTENT	categories\tagSEC_CONTENT	include\tagSEC_CONTENT	days\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	week\tagSEC_CONTENT	,\tagSEC_CONTENT	months\tagSEC_CONTENT	,\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	day\tagSEC_CONTENT	/\tagSEC_CONTENT	week\tagSEC_CONTENT	,\tagSEC_CONTENT	time\tagSEC_CONTENT	zones\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	other\tagSEC_CONTENT	temporal\tagSEC_CONTENT	operators\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	early\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	this\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	before\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	etc\tagSEC_CONTENT	.\tagSEC_CONTENT	Prior\tagSEC_CONTENT	to\tagSEC_CONTENT	looking\tagSEC_CONTENT	for\tagSEC_CONTENT	these\tagSEC_CONTENT	tokens\tagSEC_CONTENT	,\tagSEC_CONTENT	text\tagSEC_CONTENT	is\tagSEC_CONTENT	normalized\tagSEC_CONTENT	by\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_CONTENT	Exceptions\tagSEC_CONTENT	to\tagSEC_CONTENT	RP\tagSEC_CONTENT	include\tagSEC_CONTENT	searching\tagSEC_CONTENT	for\tagSEC_CONTENT	day\tagSEC_CONTENT	/\tagSEC_CONTENT	month\tagSEC_CONTENT	abbreviations\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	Sat\tagSEC_CONTENT	.\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	Aug.\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	these\tagSEC_CONTENT	cases\tagSEC_CONTENT	periods\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	removed\tagSEC_CONTENT	because\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	part\tagdataset	of\tagSEC_CONTENT	the\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	span\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	exception\tagSEC_CONTENT	to\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	is\tagSEC_CONTENT	identifying\tagSEC_CONTENT	mentions\tagtask	of\tagSEC_CONTENT	AM\tagSEC_CONTENT	or\tagSEC_CONTENT	PM\tagSEC_CONTENT	where\tagSEC_CONTENT	periods\tagSEC_CONTENT	are\tagSEC_CONTENT	kept\tagSEC_CONTENT	and\tagSEC_CONTENT	text\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	converted\tagSEC_CONTENT	to\tagSEC_CONTENT	lowercase\tagSEC_CONTENT	in\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	capture\tagSEC_CONTENT	variations\tagSEC_CONTENT	like\tagSEC_CONTENT	"\tagSEC_CONTENT	PM\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	p.m.\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Non\tagSEC_CONTENT	-\tagSEC_CONTENT	temporal\tagSEC_CONTENT	mentions\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	months\tagSEC_CONTENT	or\tagSEC_CONTENT	seasons\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	year\tagSEC_CONTENT	"\tagSEC_CONTENT	may\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	march\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	spring\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	fall\tagSEC_CONTENT	"\tagSEC_CONTENT	are\tagSEC_CONTENT	disambiguated\tagSEC_CONTENT	using\tagSEC_CONTENT	POS\tagSEC_CONTENT	tags\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	tokens\tagSEC_CONTENT	that\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	entity\tagSEC_CONTENT	generally\tagSEC_CONTENT	have\tagSEC_CONTENT	a\tagSEC_CONTENT	POS\tagSEC_CONTENT	tag\tagSEC_CONTENT	of\tagSEC_CONTENT	"\tagSEC_CONTENT	NN\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	NP\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	linked\tagSEC_CONTENT	during\tagSEC_CONTENT	token\tagSEC_CONTENT	searches\tagSEC_CONTENT	.\tagSEC_END	Text\tagSEC_START	Year\tagSEC_CONTENT	:\tagSEC_CONTENT	Another\tagSEC_CONTENT	special\tagSEC_CONTENT	case\tagSEC_CONTENT	of\tagSEC_CONTENT	parsing\tagSEC_CONTENT	temporal\tagtask	tokens\tagtask	are\tagSEC_CONTENT	textual\tagtask	representations\tagtask	of\tagSEC_CONTENT	years\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	nineteen\tagSEC_CONTENT	ninety\tagSEC_CONTENT	-\tagSEC_CONTENT	seven\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	Word2Number\tagSEC_CONTENT	Python\tagSEC_CONTENT	module\tagSEC_CONTENT	was\tagSEC_CONTENT	modified\tagSEC_CONTENT	to\tagSEC_CONTENT	recognize\tagSEC_CONTENT	these\tagSEC_CONTENT	phrases\tagSEC_CONTENT	.\tagSEC_CONTENT	Previously\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	would\tagSEC_CONTENT	add\tagSEC_CONTENT	19\tagSEC_CONTENT	and\tagSEC_CONTENT	97\tagSEC_CONTENT	together\tagSEC_CONTENT	instead\tagSEC_CONTENT	of\tagSEC_CONTENT	returning\tagSEC_CONTENT	1997\tagSEC_CONTENT	.\tagSEC_END	Periods\tagSEC_START	and\tagSEC_CONTENT	Calendar\tagSEC_CONTENT	-\tagSEC_CONTENT	Intervals\tagSEC_CONTENT	:\tagSEC_CONTENT	The\tagtask	same\tagtask	temporal\tagtask	token\tagtask	can\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	either\tagSEC_CONTENT	a\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	"\tagSEC_CONTENT	Period\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	Calendar\tagSEC_CONTENT	-\tagSEC_CONTENT	Interval\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	phrases\tagSEC_CONTENT	"\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	week\tagSEC_CONTENT	"\tagSEC_CONTENT	vs\tagSEC_CONTENT	"\tagSEC_CONTENT	next\tagSEC_CONTENT	week\tagSEC_CONTENT	"\tagSEC_CONTENT	the\tagSEC_CONTENT	token\tagSEC_CONTENT	"\tagSEC_CONTENT	week\tagSEC_CONTENT	"\tagSEC_CONTENT	is\tagSEC_CONTENT	classified\tagSEC_CONTENT	differently\tagSEC_CONTENT	.\tagSEC_CONTENT	Due\tagSEC_CONTENT	to\tagSEC_CONTENT	language\tagSEC_CONTENT	intricacies\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	difficult\tagSEC_CONTENT	to\tagSEC_CONTENT	define\tagSEC_CONTENT	a\tagSEC_CONTENT	rule\tagSEC_CONTENT	-\tagSEC_CONTENT	base\tagSEC_CONTENT	system\tagSEC_CONTENT	to\tagSEC_CONTENT	disambiguate\tagSEC_CONTENT	these\tagSEC_CONTENT	entities\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagtask	classification\tagtask	is\tagSEC_CONTENT	contingent\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	topic\tagSEC_CONTENT	being\tagSEC_CONTENT	discussed\tagSEC_CONTENT	where\tagSEC_CONTENT	phrasing\tagSEC_CONTENT	around\tagSEC_CONTENT	the\tagSEC_CONTENT	entity\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	different\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	instance\tagSEC_CONTENT	.\tagSEC_CONTENT	Thus\tagSEC_CONTENT	,\tagSEC_CONTENT	Period\tagSEC_CONTENT	/\tagSEC_CONTENT	Calendar\tagSEC_CONTENT	-\tagSEC_CONTENT	Interval\tagSEC_CONTENT	tokens\tagSEC_CONTENT	are\tagSEC_CONTENT	initially\tagSEC_CONTENT	identified\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	token\tagSEC_CONTENT	search\tagSEC_CONTENT	using\tagSEC_CONTENT	a\tagSEC_CONTENT	defined\tagSEC_CONTENT	list\tagSEC_CONTENT	of\tagSEC_CONTENT	terms\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	the\tagSEC_CONTENT	identified\tagSEC_CONTENT	term\tagSEC_CONTENT	and\tagSEC_CONTENT	its\tagSEC_CONTENT	span\tagSEC_CONTENT	are\tagSEC_CONTENT	passed\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	ML\tagSEC_CONTENT	algorithm\tagSEC_CONTENT	for\tagSEC_CONTENT	classification\tagSEC_CONTENT	.\tagSEC_END	Machine\tagSEC_START	Learning\tagSEC_CONTENT	Classification\tagSEC_CONTENT	:\tagSEC_CONTENT	Four\tagSEC_CONTENT	ML\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	are\tagSEC_CONTENT	available\tagSEC_CONTENT	in\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	to\tagSEC_CONTENT	differentiate\tagSEC_CONTENT	between\tagSEC_CONTENT	"\tagSEC_CONTENT	Period\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	Calendar\tagSEC_CONTENT	-\tagSEC_CONTENT	Interval\tagSEC_CONTENT	"\tagSEC_CONTENT	entities\tagSEC_CONTENT	using\tagSEC_CONTENT	contextual\tagtask	information\tagtask	.\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	implements\tagSEC_CONTENT	Naive\tagSEC_CONTENT	Bayes\tagSEC_CONTENT	(\tagSEC_CONTENT	NB\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	NN\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	Decision\tagSEC_CONTENT	Tree\tagSEC_CONTENT	(\tagSEC_CONTENT	DT\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Support\tagSEC_CONTENT	Vector\tagSEC_CONTENT	Machine\tagSEC_CONTENT	(\tagSEC_CONTENT	SVM\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Binary\tagSEC_CONTENT	feature\tagSEC_CONTENT	vectors\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	implementations\tagSEC_CONTENT	have\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	features\tagSEC_CONTENT	:\tagSEC_END	•\tagSEC_START	temporal\tagSEC_CONTENT	self\tagSEC_CONTENT	:\tagSEC_CONTENT	If\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	is\tagSEC_CONTENT	flagged\tagSEC_CONTENT	as\tagSEC_CONTENT	temporal\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	feature\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	"\tagSEC_CONTENT	1\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	temporal\tagSEC_CONTENT	context\tagSEC_CONTENT	:\tagSEC_CONTENT	If\tagSEC_CONTENT	there\tagSEC_CONTENT	is\tagSEC_CONTENT	at\tagSEC_CONTENT	least\tagSEC_CONTENT	one\tagSEC_CONTENT	temporal\tagSEC_CONTENT	word\tagSEC_CONTENT	within\tagSEC_CONTENT	a\tagSEC_CONTENT	5-word\tagSEC_CONTENT	window\tagSEC_CONTENT	up\tagSEC_CONTENT	-\tagSEC_CONTENT	or\tagSEC_CONTENT	down\tagSEC_CONTENT	-\tagSEC_CONTENT	stream\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	this\tagSEC_CONTENT	feature\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	"\tagSEC_CONTENT	1\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	numeric\tagSEC_CONTENT	:\tagSEC_CONTENT	If\tagSEC_CONTENT	there\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	numeric\tagSEC_CONTENT	expression\tagSEC_CONTENT	either\tagSEC_CONTENT	directly\tagSEC_CONTENT	before\tagSEC_CONTENT	or\tagSEC_CONTENT	after\tagSEC_CONTENT	(\tagSEC_CONTENT	a\tagSEC_CONTENT	1-word\tagSEC_CONTENT	window\tagSEC_CONTENT	)\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	feature\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	"\tagSEC_CONTENT	1\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	context\tagSEC_CONTENT	:\tagSEC_CONTENT	All\tagSEC_CONTENT	words\tagSEC_CONTENT	within\tagSEC_CONTENT	a\tagSEC_CONTENT	5-word\tagSEC_CONTENT	window\tagSEC_CONTENT	are\tagSEC_CONTENT	identified\tagSEC_CONTENT	as\tagSEC_CONTENT	features\tagSEC_CONTENT	and\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	"\tagSEC_CONTENT	1\tagSEC_CONTENT	"\tagSEC_CONTENT	if\tagSEC_CONTENT	that\tagSEC_CONTENT	word\tagSEC_CONTENT	is\tagSEC_CONTENT	present\tagSEC_CONTENT	.\tagSEC_CONTENT	Prior\tagSEC_CONTENT	to\tagSEC_CONTENT	identifying\tagSEC_CONTENT	these\tagSEC_CONTENT	features\tagSEC_CONTENT	all\tagSEC_CONTENT	words\tagSEC_CONTENT	are\tagSEC_CONTENT	normalized\tagSEC_CONTENT	with\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	5-word\tagSEC_CONTENT	window\tagSEC_CONTENT	includes\tagSEC_CONTENT	crossing\tagSEC_CONTENT	sentence\tagSEC_CONTENT	boundaries\tagSEC_CONTENT	before\tagSEC_CONTENT	and\tagSEC_CONTENT	after\tagSEC_CONTENT	the\tagSEC_CONTENT	target\tagSEC_CONTENT	word\tagSEC_CONTENT	.\tagSEC_END	We\tagSEC_START	use\tagSEC_CONTENT	NLTK\tagSEC_CONTENT	with\tagSEC_CONTENT	default\tagSEC_CONTENT	parameters\tagSEC_CONTENT	to\tagSEC_CONTENT	implement\tagSEC_CONTENT	NB\tagSEC_CONTENT	and\tagSEC_CONTENT	DT\tagSEC_CONTENT	,\tagSEC_CONTENT	NN\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	feed\tagSEC_CONTENT	-\tagSEC_CONTENT	forward\tagSEC_CONTENT	network\tagSEC_CONTENT	with\tagSEC_CONTENT	three\tagSEC_CONTENT	hidden\tagSEC_CONTENT	layers\tagSEC_CONTENT	implemented\tagSEC_CONTENT	using\tagSEC_CONTENT	Python\tagSEC_CONTENT	's\tagSEC_CONTENT	Keras\tagSEC_CONTENT	package\tagSEC_CONTENT	3\tagSEC_CONTENT	with\tagSEC_CONTENT	epochs\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	5\tagSEC_CONTENT	and\tagSEC_CONTENT	batch\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	10\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	SVM\tagSEC_CONTENT	is\tagSEC_CONTENT	implemented\tagSEC_CONTENT	using\tagSEC_CONTENT	SciKitLearn\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	C\tagSEC_CONTENT	set\tagSEC_CONTENT	to\tagSEC_CONTENT	0.05\tagSEC_CONTENT	and\tagSEC_CONTENT	max\tagtask	iterations\tagtask	set\tagSEC_CONTENT	to\tagSEC_CONTENT	3\tagSEC_CONTENT	.\tagSEC_CONTENT	Ordinals\tagSEC_CONTENT	:\tagSEC_CONTENT	Ordinals\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	first\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	3rd\tagSEC_CONTENT	"\tagSEC_CONTENT	are\tagSEC_CONTENT	classified\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	"\tagSEC_CONTENT	NthFromStart\tagSEC_CONTENT	"\tagSEC_CONTENT	entity\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	schema\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	mentions\tagSEC_CONTENT	are\tagSEC_CONTENT	identified\tagSEC_CONTENT	by\tagSEC_CONTENT	normalizing\tagSEC_CONTENT	with\tagSEC_CONTENT	RP\tagSEC_CONTENT	and\tagSEC_CONTENT	LC\tagSEC_CONTENT	before\tagSEC_CONTENT	searching\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagtask	ordinal\tagtask	tokens\tagtask	representing\tagSEC_CONTENT	the\tagSEC_CONTENT	numbers\tagSEC_CONTENT	1\tagSEC_CONTENT	-\tagSEC_CONTENT	31\tagSEC_CONTENT	.\tagSEC_END	Sub\tagSEC_START	-\tagSEC_CONTENT	Interval\tagSEC_CONTENT	Linking\tagSEC_CONTENT	:\tagSEC_CONTENT	After\tagSEC_CONTENT	all\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	entities\tagSEC_CONTENT	are\tagSEC_CONTENT	identified\tagSEC_CONTENT	,\tagSEC_CONTENT	all\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrases\tagSEC_CONTENT	are\tagSEC_CONTENT	re\tagSEC_CONTENT	-\tagSEC_CONTENT	parsed\tagSEC_CONTENT	to\tagSEC_CONTENT	identify\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	within\tagSEC_CONTENT	each\tagSEC_CONTENT	phrase\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	phrase\tagSEC_CONTENT	"\tagSEC_CONTENT	August\tagSEC_CONTENT	1998\tagSEC_CONTENT	"\tagSEC_CONTENT	are\tagSEC_CONTENT	parsed\tagSEC_CONTENT	by\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	methods\tagSEC_CONTENT	leaving\tagSEC_CONTENT	the\tagSEC_CONTENT	subinterval\tagSEC_CONTENT	link\tagSEC_CONTENT	vacant\tagSEC_CONTENT	.\tagSEC_CONTENT	During\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	interval\tagSEC_CONTENT	linking\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	year\tagSEC_CONTENT	"\tagSEC_CONTENT	1998\tagSEC_CONTENT	"\tagSEC_CONTENT	has\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	August\tagSEC_CONTENT	"\tagSEC_CONTENT	entity\tagSEC_CONTENT	added\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	interval\tagSEC_CONTENT	.\tagSEC_CONTENT	Sub\tagSEC_CONTENT	-\tagSEC_CONTENT	interval\tagSEC_CONTENT	linking\tagSEC_CONTENT	reviews\tagSEC_CONTENT	entities\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	smallest\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	largest\tagSEC_CONTENT	,\tagSEC_CONTENT	adding\tagSEC_CONTENT	missing\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	as\tagSEC_CONTENT	needed\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	method\tagSEC_CONTENT	assumes\tagSEC_CONTENT	each\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	contains\tagSEC_CONTENT	zero\tagSEC_CONTENT	or\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	SCATE\tagSEC_CONTENT	entity\tagSEC_CONTENT	.\tagSEC_END	Next\tagSEC_START	/\tagSEC_CONTENT	Last\tagSEC_CONTENT	Parsing\tagSEC_CONTENT	:\tagSEC_CONTENT	Determining\tagSEC_CONTENT	whether\tagSEC_CONTENT	an\tagSEC_CONTENT	entity\tagSEC_CONTENT	is\tagSEC_CONTENT	referring\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	date\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	future\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	Next\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	past\tagSEC_CONTENT	,\tagSEC_CONTENT	"\tagSEC_CONTENT	Last\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	depends\tagSEC_CONTENT	on\tagSEC_CONTENT	context\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	document\tagSEC_CONTENT	time\tagSEC_CONTENT	(\tagSEC_CONTENT	doc\tagSEC_CONTENT	-\tagSEC_CONTENT	time\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Next\tagSEC_CONTENT	/\tagSEC_CONTENT	Last\tagSEC_CONTENT	parsing\tagSEC_CONTENT	is\tagSEC_CONTENT	done\tagSEC_CONTENT	after\tagSEC_CONTENT	all\tagSEC_CONTENT	other\tagSEC_CONTENT	parsing\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	checks\tagSEC_CONTENT	two\tagSEC_CONTENT	cases\tagSEC_CONTENT	:\tagSEC_CONTENT	1\tagSEC_CONTENT	)\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	phrase\tagSEC_CONTENT	contains\tagSEC_CONTENT	a\tagSEC_CONTENT	year\tagSEC_CONTENT	,\tagSEC_CONTENT	no\tagSEC_CONTENT	additional\tagSEC_CONTENT	annotation\tagSEC_CONTENT	is\tagSEC_CONTENT	made\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	2\tagSEC_CONTENT	)\tagSEC_CONTENT	if\tagSEC_CONTENT	specific\tagSEC_CONTENT	modifier\tagSEC_CONTENT	words\tagSEC_CONTENT	are\tagSEC_CONTENT	present\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	next\tagSEC_CONTENT	"\tagSEC_CONTENT	or\tagSEC_CONTENT	"\tagSEC_CONTENT	last\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	immediately\tagSEC_CONTENT	preceding\tagSEC_CONTENT	a\tagSEC_CONTENT	temporal\tagSEC_CONTENT	expression\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	modifier\tagSEC_CONTENT	is\tagSEC_CONTENT	annotated\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	interval\tagSEC_CONTENT	referencing\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	temporal\tagSEC_CONTENT	entity\tagSEC_CONTENT	.\tagSEC_CONTENT	If\tagSEC_CONTENT	neither\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	cases\tagSEC_CONTENT	hold\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	year\tagSEC_CONTENT	is\tagSEC_CONTENT	set\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	doc\tagSEC_CONTENT	-\tagSEC_CONTENT	time\tagSEC_CONTENT	year\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	month\tagSEC_CONTENT	and\tagSEC_CONTENT	day\tagSEC_CONTENT	are\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	full\tagSEC_CONTENT	doc\tagSEC_CONTENT	-\tagSEC_CONTENT	time\tagSEC_CONTENT	to\tagSEC_CONTENT	determine\tagSEC_CONTENT	if\tagSEC_CONTENT	it\tagSEC_CONTENT	occurs\tagSEC_CONTENT	before\tagSEC_CONTENT	or\tagSEC_CONTENT	after\tagSEC_CONTENT	.\tagSEC_CONTENT	Note\tagSEC_CONTENT	the\tagtask	year\tagtask	assumption\tagtask	is\tagSEC_CONTENT	not\tagSEC_CONTENT	always\tagSEC_CONTENT	valid\tagSEC_CONTENT	and\tagSEC_CONTENT	more\tagSEC_CONTENT	complex\tagSEC_CONTENT	,\tagSEC_CONTENT	content\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	parsing\tagSEC_CONTENT	maybe\tagSEC_CONTENT	required\tagSEC_CONTENT	to\tagSEC_CONTENT	achieve\tagSEC_CONTENT	higher\tagtask	precision\tagtask	.\tagSEC_CONTENT	Finally\tagSEC_CONTENT	,\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	day\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	week\tagSEC_CONTENT	(\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	"\tagSEC_CONTENT	Saturday\tagSEC_CONTENT	"\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	mentioned\tagSEC_CONTENT	,\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	finds\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	preceding\tagSEC_CONTENT	verb\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	sentence\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	if\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	past\tagSEC_CONTENT	tense\tagSEC_CONTENT	the\tagSEC_CONTENT	temporal\tagSEC_CONTENT	entity\tagSEC_CONTENT	is\tagSEC_CONTENT	annotated\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	Last\tagSEC_CONTENT	"\tagSEC_CONTENT	,\tagSEC_CONTENT	otherwise\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	annotated\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	Next\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_END	Results\tagSECTITLE_END	Training\tagSEC_START	and\tagSEC_CONTENT	evaluation\tagtask	of\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	utilizes\tagSEC_CONTENT	the\tagSEC_CONTENT	Newswire\tagSEC_CONTENT	corpus\tagSEC_CONTENT	,\tagSEC_CONTENT	consisting\tagSEC_CONTENT	of\tagSEC_CONTENT	81\tagSEC_CONTENT	documents\tagSEC_CONTENT	,\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	organizers\tagSEC_CONTENT	.\tagSEC_CONTENT	Average\tagSEC_CONTENT	preci\tagSEC_CONTENT	-\tagSEC_CONTENT	sion\tagSEC_CONTENT	,\tagSEC_CONTENT	recall\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	F1-measure\tagSEC_CONTENT	of\tagSEC_CONTENT	5-fold\tagSEC_CONTENT	cross\tagSEC_CONTENT	validation\tagSEC_CONTENT	for\tagSEC_CONTENT	Track\tagSEC_CONTENT	1\tagSEC_CONTENT	(\tagSEC_CONTENT	parsing\tagSEC_CONTENT	)\tagSEC_CONTENT	are\tagSEC_CONTENT	reported\tagSEC_CONTENT	in\tagSEC_CONTENT	Table\tagSEC_CONTENT	1\tagSEC_CONTENT	(\tagSEC_CONTENT	annotations\tagSEC_CONTENT	for\tagSEC_CONTENT	"\tagSEC_CONTENT	Event\tagSEC_CONTENT	"\tagSEC_CONTENT	and\tagSEC_CONTENT	"\tagSEC_CONTENT	Modifier\tagSEC_CONTENT	"\tagSEC_CONTENT	are\tagSEC_CONTENT	ignored\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Scores\tagSEC_CONTENT	for\tagSEC_CONTENT	"\tagSEC_CONTENT	100\tagSEC_CONTENT	%\tagSEC_CONTENT	Correct\tagSEC_CONTENT	Entity\tagSEC_CONTENT	"\tagSEC_CONTENT	consider\tagSEC_CONTENT	the\tagtask	entity\tagtask	location\tagtask	and\tagSEC_CONTENT	all\tagSEC_CONTENT	properties\tagSEC_CONTENT	(\tagSEC_CONTENT	like\tagSEC_CONTENT	sub\tagSEC_CONTENT	-\tagSEC_CONTENT	intervals\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	scores\tagSEC_CONTENT	for\tagSEC_CONTENT	"\tagSEC_CONTENT	Correct\tagSEC_CONTENT	Span\tagSEC_CONTENT	"\tagSEC_CONTENT	only\tagSEC_CONTENT	consider\tagSEC_CONTENT	the\tagtask	entity\tagtask	location\tagtask	.\tagSEC_END	On\tagSEC_START	average\tagSEC_CONTENT	,\tagSEC_CONTENT	all\tagSEC_CONTENT	ML\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	perform\tagSEC_CONTENT	similarly\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	"\tagSEC_CONTENT	100\tagSEC_CONTENT	%\tagSEC_CONTENT	Correct\tagSEC_CONTENT	Entity\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	All\tagSEC_CONTENT	versions\tagSEC_CONTENT	also\tagSEC_CONTENT	obtain\tagSEC_CONTENT	a\tagSEC_CONTENT	higher\tagSEC_CONTENT	F1\tagSEC_CONTENT	score\tagSEC_CONTENT	when\tagSEC_CONTENT	only\tagSEC_CONTENT	considering\tagSEC_CONTENT	correct\tagSEC_CONTENT	spans\tagSEC_CONTENT	versus\tagSEC_CONTENT	getting\tagSEC_CONTENT	all\tagSEC_CONTENT	entity\tagSEC_CONTENT	properties\tagSEC_CONTENT	correct\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	indicates\tagSEC_CONTENT	that\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	correctly\tagSEC_CONTENT	identifies\tagSEC_CONTENT	the\tagSEC_CONTENT	majority\tagSEC_CONTENT	of\tagSEC_CONTENT	temporal\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	has\tagSEC_CONTENT	trouble\tagSEC_CONTENT	parsing\tagSEC_CONTENT	some\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	properties\tagSEC_CONTENT	.\tagSEC_END	ChronoNN\tagSEC_START	processed\tagSEC_CONTENT	the\tagSEC_CONTENT	final\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	dataset\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	consisted\tagSEC_CONTENT	of\tagSEC_CONTENT	20\tagSEC_CONTENT	previously\tagSEC_CONTENT	unseen\tagSEC_CONTENT	Newswire\tagSEC_CONTENT	articles\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	received\tagSEC_CONTENT	a\tagmetric	F1\tagmetric	of\tagSEC_CONTENT	.44\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	dataset\tagSEC_CONTENT	contained\tagSEC_CONTENT	five\tagSEC_CONTENT	articles\tagSEC_CONTENT	from\tagSEC_CONTENT	BBC\tagSEC_CONTENT	that\tagSEC_CONTENT	were\tagSEC_CONTENT	not\tagSEC_CONTENT	represented\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	's\tagSEC_CONTENT	low\tagSEC_CONTENT	performance\tagSEC_CONTENT	indicates\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	maybe\tagSEC_CONTENT	over\tagSEC_CONTENT	-\tagSEC_CONTENT	fit\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	the\tagSEC_CONTENT	training\tagSEC_CONTENT	dataset\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	one\tagSEC_CONTENT	downfall\tagSEC_CONTENT	of\tagSEC_CONTENT	rule\tagSEC_CONTENT	-\tagSEC_CONTENT	based\tagSEC_CONTENT	systems\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	new\tagSEC_CONTENT	rules\tagSEC_CONTENT	need\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	developed\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	new\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	temporal\tagtask	representation\tagtask	.\tagSEC_CONTENT	Upon\tagSEC_CONTENT	further\tagSEC_CONTENT	review\tagSEC_CONTENT	we\tagSEC_CONTENT	found\tagSEC_CONTENT	the\tagSEC_CONTENT	submitted\tagSEC_CONTENT	version\tagSEC_CONTENT	of\tagSEC_CONTENT	Chrono\tagSEC_CONTENT	had\tagSEC_CONTENT	three\tagSEC_CONTENT	minor\tagSEC_CONTENT	parsing\tagSEC_CONTENT	flaws\tagSEC_CONTENT	that\tagSEC_CONTENT	resulted\tagSEC_CONTENT	in\tagSEC_CONTENT	unintentional\tagSEC_CONTENT	false\tagSEC_CONTENT	positives\tagSEC_CONTENT	.\tagSEC_END	1\tagSEC_START	)\tagSEC_CONTENT	Formatted\tagSEC_CONTENT	dates\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	"\tagSEC_CONTENT	2013\tagSEC_CONTENT	-\tagSEC_CONTENT	02\tagSEC_CONTENT	-\tagSEC_CONTENT	22\tagSEC_CONTENT	"\tagSEC_CONTENT	were\tagSEC_CONTENT	being\tagSEC_CONTENT	parsed\tagSEC_CONTENT	twice\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	first\tagSEC_CONTENT	parse\tagSEC_CONTENT	specifically\tagSEC_CONTENT	looked\tagSEC_CONTENT	fora\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	and\tagSEC_CONTENT	identified\tagSEC_CONTENT	all\tagSEC_CONTENT	correct\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	parse\tagSEC_CONTENT	looked\tagSEC_CONTENT	fora\tagSEC_CONTENT	formatted\tagSEC_CONTENT	date\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	did\tagSEC_CONTENT	n't\tagSEC_CONTENT	check\tagSEC_CONTENT	to\tagSEC_CONTENT	see\tagSEC_CONTENT	if\tagSEC_CONTENT	a\tagSEC_CONTENT	year\tagSEC_CONTENT	had\tagSEC_CONTENT	already\tagSEC_CONTENT	been\tagSEC_CONTENT	found\tagSEC_CONTENT	,\tagSEC_CONTENT	so\tagSEC_CONTENT	returned\tagSEC_CONTENT	a\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	value\tagSEC_CONTENT	"\tagSEC_CONTENT	22\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	was\tagSEC_CONTENT	easily\tagSEC_CONTENT	fixed\tagSEC_CONTENT	by\tagSEC_CONTENT	having\tagSEC_CONTENT	the\tagSEC_CONTENT	2-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	parser\tagSEC_CONTENT	check\tagSEC_CONTENT	fora\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	flag\tagSEC_CONTENT	before\tagSEC_CONTENT	proceeding\tagSEC_CONTENT	(\tagSEC_CONTENT	month\tagSEC_CONTENT	and\tagSEC_CONTENT	day\tagSEC_CONTENT	flags\tagSEC_CONTENT	were\tagSEC_CONTENT	already\tagSEC_CONTENT	implemented\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	2\tagSEC_START	)\tagSEC_CONTENT	24-hour\tagSEC_CONTENT	time\tagSEC_CONTENT	priority\tagSEC_CONTENT	was\tagSEC_CONTENT	incorrectly\tagSEC_CONTENT	placed\tagSEC_CONTENT	above\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	resulted\tagSEC_CONTENT	in\tagSEC_CONTENT	any\tagSEC_CONTENT	isolated\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	being\tagSEC_CONTENT	parsed\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	24-hour\tagSEC_CONTENT	time\tagSEC_CONTENT	expression\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	a\tagSEC_CONTENT	year\tagSEC_CONTENT	as\tagSEC_CONTENT	originally\tagSEC_CONTENT	intended\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	simple\tagSEC_CONTENT	flip\tagSEC_CONTENT	of\tagSEC_CONTENT	parsing\tagSEC_CONTENT	order\tagSEC_CONTENT	resolved\tagSEC_CONTENT	this\tagSEC_CONTENT	issue\tagSEC_CONTENT	.\tagSEC_END	3\tagSEC_START	)\tagSEC_CONTENT	Numeric\tagSEC_CONTENT	temporal\tagSEC_CONTENT	expressions\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	an\tagSEC_CONTENT	isolated\tagSEC_CONTENT	4-digit\tagSEC_CONTENT	year\tagSEC_CONTENT	,\tagSEC_CONTENT	were\tagSEC_CONTENT	being\tagSEC_CONTENT	parsed\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	whole\tagSEC_CONTENT	phrase\tagSEC_CONTENT	rather\tagSEC_CONTENT	than\tagSEC_CONTENT	breaking\tagSEC_CONTENT	out\tagSEC_CONTENT	each\tagSEC_CONTENT	token\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	phrase\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	year\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	phrase\tagSEC_CONTENT	"\tagSEC_CONTENT	Last\tagSEC_CONTENT	1953\tagSEC_CONTENT	"\tagSEC_CONTENT	was\tagSEC_CONTENT	not\tagSEC_CONTENT	being\tagSEC_CONTENT	identified\tagSEC_CONTENT	because\tagSEC_CONTENT	it\tagSEC_CONTENT	was\tagSEC_CONTENT	not\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	phrase\tagSEC_CONTENT	all\tagSEC_CONTENT	by\tagSEC_CONTENT	itself\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	fix\tagSEC_CONTENT	this\tagSEC_CONTENT	the\tagSEC_CONTENT	parsing\tagSEC_CONTENT	function\tagSEC_CONTENT	was\tagSEC_CONTENT	edited\tagSEC_CONTENT	to\tagSEC_CONTENT	loop\tagSEC_CONTENT	through\tagSEC_CONTENT	each\tagSEC_CONTENT	token\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	phrase\tagSEC_CONTENT	(\tagSEC_CONTENT	a\tagSEC_CONTENT	method\tagSEC_CONTENT	that\tagSEC_CONTENT	was\tagSEC_CONTENT	already\tagSEC_CONTENT	implemented\tagSEC_CONTENT	inmost\tagSEC_CONTENT	other\tagSEC_CONTENT	parsers\tagSEC_CONTENT	and\tagSEC_CONTENT	was\tagSEC_CONTENT	just\tagSEC_CONTENT	over-\tagSEC_CONTENT	looked\tagSEC_CONTENT	here\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	ChronoNN\tagSEC_START	received\tagSEC_CONTENT	a\tagSEC_CONTENT	Post\tagSEC_CONTENT	-\tagSEC_CONTENT	Evaluation\tagSEC_CONTENT	F1\tagSEC_CONTENT	of\tagSEC_CONTENT	.55\tagSEC_CONTENT	for\tagSEC_CONTENT	Track\tagSEC_CONTENT	1\tagSEC_CONTENT	after\tagSEC_CONTENT	implementing\tagSEC_CONTENT	these\tagSEC_CONTENT	fixes\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	sets\tagSEC_CONTENT	ChronoNN\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	top\tagSEC_CONTENT	performing\tagSEC_CONTENT	system\tagSEC_CONTENT	for\tagSEC_CONTENT	SemEval\tagSEC_CONTENT	2018\tagSEC_CONTENT	Task\tagSEC_CONTENT	6\tagSEC_CONTENT	,\tagSEC_CONTENT	Track\tagSEC_CONTENT	1\tagSEC_CONTENT	.\tagSEC_END	
trouillon16	title\tagSECTITLE_END	Complex\tagSEC_START	Embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	Simple\tagtask	Link\tagtask	Prediction\tagSEC_END	abstract\tagSECTITLE_END	In\tagSEC_START	statistical\tagSEC_CONTENT	relational\tagSEC_CONTENT	learning\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagtask	link\tagtask	prediction\tagtask	problem\tagtask	is\tagSEC_CONTENT	key\tagSEC_CONTENT	to\tagSEC_CONTENT	automatically\tagSEC_CONTENT	understand\tagSEC_CONTENT	the\tagSEC_CONTENT	structure\tagSEC_CONTENT	of\tagSEC_CONTENT	large\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	bases\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	in\tagSEC_CONTENT	previous\tagSEC_CONTENT	studies\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	propose\tagSEC_CONTENT	to\tagSEC_CONTENT	solve\tagSEC_CONTENT	this\tagSEC_CONTENT	problem\tagSEC_CONTENT	through\tagSEC_CONTENT	latent\tagSEC_CONTENT	factorization\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	here\tagSEC_CONTENT	we\tagSEC_CONTENT	make\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	complex\tagSEC_CONTENT	valued\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	composition\tagSEC_CONTENT	of\tagSEC_CONTENT	complex\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	can\tagSEC_CONTENT	handle\tagSEC_CONTENT	a\tagSEC_CONTENT	large\tagSEC_CONTENT	variety\tagSEC_CONTENT	of\tagSEC_CONTENT	binary\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	among\tagSEC_CONTENT	them\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	and\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	Compared\tagSEC_CONTENT	to\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	models\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Tensor\tagSEC_CONTENT	Network\tagSEC_CONTENT	and\tagSEC_CONTENT	Holographic\tagSEC_CONTENT	Embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	complex\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	is\tagSEC_CONTENT	arguably\tagSEC_CONTENT	simpler\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	only\tagSEC_CONTENT	uses\tagSEC_CONTENT	the\tagSEC_CONTENT	Hermitian\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	counterpart\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	standard\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	between\tagSEC_CONTENT	real\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	Our\tagSEC_CONTENT	approach\tagSEC_CONTENT	is\tagSEC_CONTENT	scalable\tagSEC_CONTENT	to\tagSEC_CONTENT	large\tagSEC_CONTENT	datasets\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	remains\tagSEC_CONTENT	linear\tagSEC_CONTENT	in\tagSEC_CONTENT	both\tagSEC_CONTENT	space\tagSEC_CONTENT	and\tagSEC_CONTENT	time\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	consistently\tagSEC_CONTENT	outperforming\tagSEC_CONTENT	alternative\tagSEC_CONTENT	approaches\tagSEC_CONTENT	on\tagSEC_CONTENT	standard\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	.\tagSEC_CONTENT	1\tagSEC_END	Introduction\tagSECTITLE_END	Web\tagSEC_START	-\tagSEC_CONTENT	scale\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	bases\tagSEC_CONTENT	(\tagSEC_CONTENT	KBs\tagSEC_CONTENT	)\tagSEC_CONTENT	provide\tagSEC_CONTENT	a\tagSEC_CONTENT	structured\tagSEC_CONTENT	representation\tagSEC_CONTENT	of\tagSEC_CONTENT	world\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	projects\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	DBPedia\tagSEC_CONTENT	(\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagSEC_CONTENT	Google\tagSEC_CONTENT	Knowledge\tagSEC_CONTENT	Vault\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	They\tagSEC_CONTENT	enable\tagSEC_CONTENT	a\tagSEC_CONTENT	wide\tagSEC_CONTENT	range\tagSEC_CONTENT	of\tagSEC_CONTENT	applications\tagtask	such\tagSEC_CONTENT	as\tagSEC_CONTENT	recommender\tagSEC_CONTENT	systems\tagSEC_CONTENT	,\tagSEC_CONTENT	question\tagSEC_CONTENT	answering\tagSEC_CONTENT	or\tagSEC_CONTENT	automated\tagSEC_CONTENT	personal\tagSEC_CONTENT	agents\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	incompleteness\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	KBs\tagSEC_CONTENT	has\tagSEC_CONTENT	stimulated\tagSEC_CONTENT	research\tagSEC_CONTENT	into\tagSEC_CONTENT	predicting\tagSEC_CONTENT	missing\tagSEC_CONTENT	entries\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	task\tagSEC_CONTENT	known\tagSEC_CONTENT	as\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	main\tagSEC_CONTENT	problems\tagSEC_CONTENT	in\tagSEC_CONTENT	Statistical\tagSEC_CONTENT	Relational\tagSEC_CONTENT	Learning\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	KBs\tagSEC_START	express\tagSEC_CONTENT	data\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	directed\tagSEC_CONTENT	graph\tagSEC_CONTENT	with\tagSEC_CONTENT	labeled\tagSEC_CONTENT	edges\tagSEC_CONTENT	(\tagSEC_CONTENT	relations\tagtask	)\tagSEC_CONTENT	between\tagSEC_CONTENT	nodes\tagSEC_CONTENT	(\tagSEC_CONTENT	entities\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Natural\tagSEC_CONTENT	redundancies\tagSEC_CONTENT	among\tagSEC_CONTENT	the\tagSEC_CONTENT	recorded\tagSEC_CONTENT	relations\tagSEC_CONTENT	often\tagSEC_CONTENT	make\tagSEC_CONTENT	it\tagSEC_CONTENT	possible\tagSEC_CONTENT	to\tagSEC_CONTENT	fill\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	missing\tagSEC_CONTENT	entries\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	KB\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	an\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	CountryOfBirth\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	recorded\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	it\tagSEC_CONTENT	can\tagSEC_CONTENT	easily\tagSEC_CONTENT	be\tagSEC_CONTENT	inferred\tagSEC_CONTENT	if\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	CityOfBirth\tagSEC_CONTENT	is\tagSEC_CONTENT	known\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	goal\tagSEC_CONTENT	of\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	automatic\tagSEC_CONTENT	discovery\tagSEC_CONTENT	of\tagSEC_CONTENT	such\tagSEC_CONTENT	regularities\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	many\tagSEC_CONTENT	relations\tagSEC_CONTENT	are\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	deterministic\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	combination\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	facts\tagSEC_CONTENT	IsBornIn(John\tagSEC_CONTENT	,\tagSEC_CONTENT	Athens\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	IsLocatedIn(Athens\tagSEC_CONTENT	,\tagSEC_CONTENT	Greece\tagSEC_CONTENT	)\tagSEC_CONTENT	does\tagSEC_CONTENT	not\tagSEC_CONTENT	always\tagSEC_CONTENT	imply\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	HasNationality(John\tagSEC_CONTENT	,\tagSEC_CONTENT	Greece\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Hence\tagSEC_CONTENT	,\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	required\tagSEC_CONTENT	to\tagSEC_CONTENT	handle\tagSEC_CONTENT	other\tagSEC_CONTENT	facts\tagSEC_CONTENT	involving\tagSEC_CONTENT	these\tagSEC_CONTENT	relations\tagSEC_CONTENT	or\tagSEC_CONTENT	entities\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	probabilistic\tagSEC_CONTENT	fashion\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	do\tagSEC_CONTENT	so\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	increasingly\tagSEC_CONTENT	popular\tagSEC_CONTENT	method\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	state\tagSEC_CONTENT	the\tagtask	link\tagtask	prediction\tagtask	task\tagtask	as\tagSEC_CONTENT	a\tagSEC_CONTENT	3D\tagSEC_CONTENT	binary\tagSEC_CONTENT	tensor\tagSEC_CONTENT	completion\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	each\tagSEC_CONTENT	slice\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	adjacency\tagSEC_CONTENT	matrix\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	relation\tagSEC_CONTENT	type\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	graph\tagSEC_CONTENT	.\tagSEC_CONTENT	Completion\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	low\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	factorization\tagSEC_CONTENT	or\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	popularized\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	Netflix\tagSEC_CONTENT	challenge\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	partially\tagSEC_CONTENT	observed\tagSEC_CONTENT	matrix\tagSEC_CONTENT	or\tagSEC_CONTENT	tensor\tagSEC_CONTENT	is\tagSEC_CONTENT	decomposed\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	product\tagSEC_CONTENT	of\tagSEC_CONTENT	embedding\tagSEC_CONTENT	matrices\tagSEC_CONTENT	with\tagSEC_CONTENT	much\tagSEC_CONTENT	smaller\tagSEC_CONTENT	rank\tagSEC_CONTENT	,\tagSEC_CONTENT	resulting\tagSEC_CONTENT	in\tagSEC_CONTENT	fixed\tagSEC_CONTENT	-\tagSEC_CONTENT	dimensional\tagSEC_CONTENT	vector\tagSEC_CONTENT	representations\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	entity\tagSEC_CONTENT	and\tagSEC_CONTENT	relation\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	database\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	a\tagSEC_CONTENT	given\tagSEC_CONTENT	fact\tagSEC_CONTENT	r(s\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	)\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	subject\tagSEC_CONTENT	sis\tagSEC_CONTENT	linked\tagSEC_CONTENT	to\tagSEC_CONTENT	object\tagSEC_CONTENT	o\tagSEC_CONTENT	through\tagSEC_CONTENT	relation\tagSEC_CONTENT	r\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	score\tagSEC_CONTENT	can\tagSEC_CONTENT	then\tagSEC_CONTENT	be\tagSEC_CONTENT	recovered\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	product\tagSEC_CONTENT	between\tagSEC_CONTENT	the\tagSEC_CONTENT	embedding\tagSEC_CONTENT	vectors\tagSEC_CONTENT	of\tagSEC_CONTENT	s\tagSEC_CONTENT	,\tagSEC_CONTENT	rand\tagSEC_CONTENT	o\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Binary\tagSEC_START	relations\tagtask	in\tagSEC_CONTENT	KBs\tagSEC_CONTENT	exhibit\tagSEC_CONTENT	various\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	patterns\tagSEC_CONTENT	:\tagSEC_CONTENT	hierarchies\tagSEC_CONTENT	and\tagSEC_CONTENT	compositions\tagSEC_CONTENT	like\tagSEC_CONTENT	FatherOf\tagSEC_CONTENT	,\tagSEC_CONTENT	OlderThan\tagSEC_CONTENT	or\tagSEC_CONTENT	IsPartOf\tagSEC_CONTENT	-\tagSEC_CONTENT	with\tagSEC_CONTENT	partial\tagSEC_CONTENT	/\tagSEC_CONTENT	total\tagSEC_CONTENT	,\tagSEC_CONTENT	strict\tagSEC_CONTENT	/\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	strict\tagSEC_CONTENT	orders\tagSEC_CONTENT	-\tagSEC_CONTENT	and\tagSEC_CONTENT	equivalence\tagSEC_CONTENT	relations\tagSEC_CONTENT	like\tagSEC_CONTENT	IsSimilarTo\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	described\tagSEC_CONTENT	in\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	relational\tagSEC_CONTENT	model\tagSEC_CONTENT	should\tagSEC_CONTENT	(\tagSEC_CONTENT	a\tagSEC_CONTENT	)\tagSEC_CONTENT	be\tagSEC_CONTENT	able\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	all\tagSEC_CONTENT	combinations\tagSEC_CONTENT	of\tagSEC_CONTENT	these\tagSEC_CONTENT	properties\tagSEC_CONTENT	,\tagSEC_CONTENT	namely\tagSEC_CONTENT	reflexivity\tagSEC_CONTENT	/\tagSEC_CONTENT	irreflexivity\tagSEC_CONTENT	,\tagSEC_CONTENT	symmetry\tagSEC_CONTENT	/\tagSEC_CONTENT	antisymmetry\tagSEC_CONTENT	and\tagSEC_CONTENT	transitivity\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	(\tagSEC_CONTENT	b\tagSEC_CONTENT	)\tagSEC_CONTENT	be\tagSEC_CONTENT	linear\tagSEC_CONTENT	in\tagSEC_CONTENT	both\tagSEC_CONTENT	time\tagSEC_CONTENT	and\tagSEC_CONTENT	memory\tagSEC_CONTENT	in\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	scale\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	size\tagSEC_CONTENT	of\tagSEC_CONTENT	present\tagSEC_CONTENT	day\tagSEC_CONTENT	KBs\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	keep\tagSEC_CONTENT	up\tagSEC_CONTENT	with\tagSEC_CONTENT	their\tagSEC_CONTENT	growth\tagSEC_CONTENT	.\tagSEC_END	Dot\tagSEC_START	products\tagSEC_CONTENT	of\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	scale\tagSEC_CONTENT	well\tagSEC_CONTENT	and\tagSEC_CONTENT	can\tagSEC_CONTENT	naturally\tagSEC_CONTENT	handle\tagSEC_CONTENT	both\tagSEC_CONTENT	symmetry\tagSEC_CONTENT	and\tagSEC_CONTENT	(\tagSEC_CONTENT	ir-)reflexivity\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	;\tagSEC_CONTENT	using\tagSEC_CONTENT	an\tagSEC_CONTENT	appropriate\tagSEC_CONTENT	loss\tagSEC_CONTENT	function\tagSEC_CONTENT	even\tagSEC_CONTENT	enables\tagSEC_CONTENT	transitivity\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	dealing\tagSEC_CONTENT	with\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	has\tagSEC_CONTENT	so\tagSEC_CONTENT	far\tagSEC_CONTENT	almost\tagSEC_CONTENT	always\tagSEC_CONTENT	implied\tagSEC_CONTENT	an\tagSEC_CONTENT	explosion\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	parameters\tagSEC_CONTENT	)\tagSEC_CONTENT	(\tagSEC_CONTENT	see\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	making\tagSEC_CONTENT	models\tagSEC_CONTENT	prone\tagSEC_CONTENT	to\tagSEC_CONTENT	overfitting\tagSEC_CONTENT	.\tagSEC_CONTENT	Finding\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	ratio\tagSEC_CONTENT	between\tagSEC_CONTENT	expressiveness\tagSEC_CONTENT	and\tagSEC_CONTENT	parameter\tagSEC_CONTENT	space\tagSEC_CONTENT	size\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	keystone\tagSEC_CONTENT	of\tagSEC_CONTENT	embedding\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	this\tagSEC_CONTENT	work\tagSEC_CONTENT	we\tagSEC_CONTENT	argue\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	standard\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	between\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	very\tagSEC_CONTENT	effective\tagSEC_CONTENT	composition\tagSEC_CONTENT	function\tagSEC_CONTENT	,\tagSEC_CONTENT	provided\tagSEC_CONTENT	that\tagSEC_CONTENT	one\tagSEC_CONTENT	uses\tagSEC_CONTENT	the\tagSEC_CONTENT	right\tagSEC_CONTENT	representation\tagSEC_CONTENT	.\tagSEC_CONTENT	Instead\tagSEC_CONTENT	of\tagSEC_CONTENT	using\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	containing\tagSEC_CONTENT	real\tagSEC_CONTENT	numbers\tagSEC_CONTENT	we\tagSEC_CONTENT	discuss\tagSEC_CONTENT	and\tagSEC_CONTENT	demonstrate\tagSEC_CONTENT	the\tagSEC_CONTENT	capabilities\tagSEC_CONTENT	of\tagSEC_CONTENT	complex\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	When\tagSEC_CONTENT	using\tagSEC_CONTENT	complex\tagSEC_CONTENT	vectors\tagSEC_CONTENT	,\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	vectors\tagSEC_CONTENT	with\tagSEC_CONTENT	entries\tagSEC_CONTENT	in\tagSEC_CONTENT	C\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	is\tagSEC_CONTENT	often\tagSEC_CONTENT	called\tagSEC_CONTENT	the\tagSEC_CONTENT	Hermitian\tagSEC_CONTENT	(\tagSEC_CONTENT	or\tagSEC_CONTENT	sesquilinear\tagSEC_CONTENT	)\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	involves\tagSEC_CONTENT	the\tagSEC_CONTENT	conjugate\tagSEC_CONTENT	-\tagSEC_CONTENT	transpose\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	a\tagSEC_CONTENT	consequence\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	anymore\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	facts\tagSEC_CONTENT	about\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	can\tagSEC_CONTENT	receive\tagSEC_CONTENT	different\tagSEC_CONTENT	scores\tagSEC_CONTENT	depending\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	ordering\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	entities\tagSEC_CONTENT	involved\tagSEC_CONTENT	.\tagSEC_CONTENT	Thus\tagSEC_CONTENT	complex\tagSEC_CONTENT	vectors\tagSEC_CONTENT	can\tagSEC_CONTENT	effectively\tagSEC_CONTENT	capture\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	while\tagSEC_CONTENT	retaining\tagSEC_CONTENT	the\tagSEC_CONTENT	efficiency\tagSEC_CONTENT	benefits\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	linearity\tagSEC_CONTENT	in\tagSEC_CONTENT	both\tagSEC_CONTENT	space\tagSEC_CONTENT	and\tagSEC_CONTENT	time\tagSEC_CONTENT	complexity\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	remainder\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	paper\tagSEC_CONTENT	is\tagSEC_CONTENT	organized\tagSEC_CONTENT	as\tagSEC_CONTENT	follows\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	first\tagSEC_CONTENT	justify\tagSEC_CONTENT	the\tagSEC_CONTENT	intuition\tagSEC_CONTENT	of\tagSEC_CONTENT	using\tagSEC_CONTENT	complex\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	square\tagSEC_CONTENT	matrix\tagSEC_CONTENT	casein\tagSEC_CONTENT	which\tagSEC_CONTENT	there\tagSEC_CONTENT	is\tagSEC_CONTENT	only\tagtask	a\tagtask	single\tagtask	relation\tagtask	between\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	formulation\tagSEC_CONTENT	is\tagSEC_CONTENT	then\tagSEC_CONTENT	extended\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	stacked\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	square\tagSEC_CONTENT	matrices\tagSEC_CONTENT	in\tagSEC_CONTENT	a\tagSEC_CONTENT	third\tagSEC_CONTENT	-\tagSEC_CONTENT	order\tagSEC_CONTENT	tensor\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	multiple\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	then\tagSEC_CONTENT	describe\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	large\tagSEC_CONTENT	scale\tagSEC_CONTENT	public\tagSEC_CONTENT	benchmark\tagSEC_CONTENT	KBs\tagSEC_CONTENT	in\tagSEC_CONTENT	which\tagSEC_CONTENT	we\tagSEC_CONTENT	empirically\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	representation\tagSEC_CONTENT	leads\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	to\tagSEC_CONTENT	simpler\tagSEC_CONTENT	and\tagSEC_CONTENT	faster\tagSEC_CONTENT	algorithms\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	also\tagSEC_CONTENT	gives\tagSEC_CONTENT	a\tagSEC_CONTENT	systematic\tagSEC_CONTENT	accuracy\tagSEC_CONTENT	improvement\tagSEC_CONTENT	over\tagSEC_CONTENT	current\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	alternatives\tagSEC_CONTENT	.\tagSEC_END	To\tagSEC_START	give\tagSEC_CONTENT	a\tagSEC_CONTENT	clear\tagSEC_CONTENT	comparison\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	existing\tagSEC_CONTENT	approaches\tagSEC_CONTENT	using\tagSEC_CONTENT	only\tagSEC_CONTENT	real\tagSEC_CONTENT	numbers\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	also\tagSEC_CONTENT	present\tagSEC_CONTENT	an\tagSEC_CONTENT	equivalent\tagSEC_CONTENT	reformulation\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	that\tagSEC_CONTENT	involves\tagSEC_CONTENT	only\tagSEC_CONTENT	real\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	should\tagSEC_CONTENT	help\tagSEC_CONTENT	practitioners\tagSEC_CONTENT	when\tagSEC_CONTENT	implementing\tagSEC_CONTENT	our\tagSEC_CONTENT	method\tagSEC_CONTENT	,\tagSEC_CONTENT	without\tagSEC_CONTENT	requiring\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	complex\tagSEC_CONTENT	numbers\tagSEC_CONTENT	in\tagSEC_CONTENT	their\tagSEC_CONTENT	software\tagSEC_CONTENT	implementation\tagSEC_CONTENT	.\tagSEC_END	Relations\tagSECTITLE_START	as\tagSECTITLE_CONTENT	Real\tagSECTITLE_CONTENT	Part\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Low\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Rank\tagSECTITLE_CONTENT	Normal\tagSECTITLE_CONTENT	Matrices\tagSECTITLE_END	In\tagSEC_START	this\tagtask	section\tagtask	we\tagSEC_CONTENT	discuss\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	complex\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	low\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	matrix\tagSEC_CONTENT	factorization\tagSEC_CONTENT	and\tagSEC_CONTENT	illustrate\tagSEC_CONTENT	this\tagSEC_CONTENT	by\tagSEC_CONTENT	considering\tagSEC_CONTENT	a\tagSEC_CONTENT	simplified\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	task\tagSEC_CONTENT	with\tagSEC_CONTENT	merely\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	relation\tagSEC_CONTENT	type\tagSEC_CONTENT	.\tagSEC_END	Understanding\tagSEC_START	the\tagtask	factorization\tagtask	in\tagSEC_CONTENT	complex\tagSEC_CONTENT	space\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	better\tagSEC_CONTENT	theoretical\tagSEC_CONTENT	understanding\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	class\tagSEC_CONTENT	of\tagSEC_CONTENT	matrices\tagSEC_CONTENT	that\tagSEC_CONTENT	can\tagSEC_CONTENT	actually\tagSEC_CONTENT	be\tagSEC_CONTENT	approximated\tagSEC_CONTENT	by\tagSEC_CONTENT	dot\tagSEC_CONTENT	products\tagSEC_CONTENT	of\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	so\tagSEC_CONTENT	-\tagSEC_CONTENT	called\tagSEC_CONTENT	normal\tagSEC_CONTENT	matrices\tagSEC_CONTENT	for\tagSEC_CONTENT	which\tagSEC_CONTENT	the\tagSEC_CONTENT	left\tagSEC_CONTENT	and\tagSEC_CONTENT	right\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	share\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	unitary\tagSEC_CONTENT	basis\tagSEC_CONTENT	.\tagSEC_END	Modelling\tagSECTITLE_START	Relations\tagSECTITLE_END	Let\tagSEC_START	E\tagSEC_CONTENT	be\tagSEC_CONTENT	a\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	entities\tagSEC_CONTENT	with\tagSEC_CONTENT	|E|\tagSEC_CONTENT	=\tagSEC_CONTENT	n.\tagSEC_CONTENT	A\tagtask	relation\tagtask	between\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	is\tagSEC_CONTENT	represented\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	binary\tagSEC_CONTENT	value\tagSEC_CONTENT	Y\tagSEC_CONTENT	so\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	−1\tagSEC_CONTENT	,\tagSEC_CONTENT	1\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	s\tagSEC_CONTENT	∈\tagSEC_CONTENT	E\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	and\tagSEC_CONTENT	o\tagSEC_CONTENT	∈\tagSEC_CONTENT	E\tagSEC_CONTENT	its\tagSEC_CONTENT	object\tagSEC_CONTENT	.\tagSEC_CONTENT	Its\tagSEC_CONTENT	probability\tagSEC_CONTENT	is\tagSEC_CONTENT	given\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	logistic\tagSEC_CONTENT	inverse\tagSEC_CONTENT	link\tagSEC_CONTENT	function\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	X\tagSEC_CONTENT	∈\tagSEC_CONTENT	R\tagSEC_CONTENT	n×n\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	latent\tagSEC_CONTENT	matrix\tagSEC_CONTENT	of\tagSEC_CONTENT	scores\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Y\tagSEC_CONTENT	the\tagSEC_CONTENT	partially\tagSEC_CONTENT	observed\tagSEC_CONTENT	sign\tagSEC_CONTENT	matrix\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	goal\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	find\tagSEC_CONTENT	a\tagSEC_CONTENT	generic\tagSEC_CONTENT	structure\tagSEC_CONTENT	for\tagSEC_CONTENT	X\tagSEC_CONTENT	that\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	flexible\tagSEC_CONTENT	approximation\tagSEC_CONTENT	of\tagSEC_CONTENT	common\tagtask	relations\tagtask	in\tagSEC_CONTENT	real\tagSEC_CONTENT	world\tagSEC_CONTENT	KBs\tagSEC_CONTENT	.\tagSEC_CONTENT	Standard\tagSEC_CONTENT	matrix\tagSEC_CONTENT	factorization\tagSEC_CONTENT	approximates\tagSEC_CONTENT	X\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	product\tagSEC_CONTENT	UV\tagSEC_CONTENT	T\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	U\tagSEC_CONTENT	and\tagSEC_CONTENT	V\tagSEC_CONTENT	are\tagSEC_CONTENT	two\tagSEC_CONTENT	functionally\tagSEC_CONTENT	independent\tagSEC_CONTENT	n\tagSEC_CONTENT	×\tagSEC_CONTENT	K\tagSEC_CONTENT	matrices\tagSEC_CONTENT	,\tagSEC_CONTENT	K\tagSEC_CONTENT	being\tagSEC_CONTENT	the\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	matrix\tagSEC_CONTENT	.\tagSEC_CONTENT	Within\tagSEC_CONTENT	this\tagSEC_CONTENT	formulation\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	assumed\tagSEC_CONTENT	that\tagSEC_CONTENT	entities\tagSEC_CONTENT	appearing\tagSEC_CONTENT	as\tagSEC_CONTENT	subjects\tagSEC_CONTENT	are\tagSEC_CONTENT	different\tagSEC_CONTENT	from\tagSEC_CONTENT	entities\tagSEC_CONTENT	appearing\tagSEC_CONTENT	as\tagSEC_CONTENT	objects\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	means\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	entity\tagSEC_CONTENT	will\tagSEC_CONTENT	have\tagSEC_CONTENT	two\tagSEC_CONTENT	different\tagSEC_CONTENT	embedding\tagSEC_CONTENT	vectors\tagSEC_CONTENT	,\tagSEC_CONTENT	depending\tagSEC_CONTENT	on\tagSEC_CONTENT	whether\tagSEC_CONTENT	it\tagSEC_CONTENT	appears\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagSEC_CONTENT	object\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	relation\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	extensively\tagSEC_CONTENT	studied\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	closely\tagSEC_CONTENT	related\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	singular\tagSEC_CONTENT	value\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	(\tagSEC_CONTENT	SVD\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	fits\tagSEC_CONTENT	well\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	case\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	matrix\tagSEC_CONTENT	X\tagSEC_CONTENT	is\tagSEC_CONTENT	rectangular\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	many\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	problems\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	entity\tagSEC_CONTENT	can\tagSEC_CONTENT	appear\tagSEC_CONTENT	as\tagSEC_CONTENT	both\tagSEC_CONTENT	subject\tagSEC_CONTENT	and\tagSEC_CONTENT	object\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	then\tagSEC_CONTENT	seems\tagSEC_CONTENT	natural\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	joint\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	entails\tagSEC_CONTENT	sharing\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	left\tagSEC_CONTENT	and\tagSEC_CONTENT	right\tagSEC_CONTENT	factors\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	proposed\tagSEC_CONTENT	by\tagSEC_CONTENT	several\tagSEC_CONTENT	authors\tagSEC_CONTENT	to\tagSEC_CONTENT	solve\tagSEC_CONTENT	the\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	problem\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	order\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	embedding\tagSEC_CONTENT	for\tagSEC_CONTENT	subjects\tagSEC_CONTENT	and\tagSEC_CONTENT	objects\tagSEC_CONTENT	,\tagSEC_CONTENT	researchers\tagSEC_CONTENT	have\tagSEC_CONTENT	generalised\tagSEC_CONTENT	the\tagSEC_CONTENT	notion\tagSEC_CONTENT	of\tagSEC_CONTENT	dot\tagSEC_CONTENT	products\tagSEC_CONTENT	to\tagSEC_CONTENT	scoring\tagSEC_CONTENT	functions\tagSEC_CONTENT	,\tagSEC_CONTENT	also\tagSEC_CONTENT	known\tagSEC_CONTENT	as\tagSEC_CONTENT	composition\tagSEC_CONTENT	functions\tagSEC_CONTENT	,\tagSEC_CONTENT	that\tagSEC_CONTENT	combine\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	in\tagSEC_CONTENT	specific\tagSEC_CONTENT	ways\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	briefly\tagSEC_CONTENT	recall\tagSEC_CONTENT	several\tagSEC_CONTENT	examples\tagSEC_CONTENT	of\tagSEC_CONTENT	scoring\tagSEC_CONTENT	functions\tagSEC_CONTENT	in\tagSEC_CONTENT	Table\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	extension\tagSEC_CONTENT	proposed\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	paper\tagSEC_CONTENT	.\tagSEC_END	Using\tagSEC_START	the\tagSEC_CONTENT	same\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	right\tagSEC_CONTENT	and\tagSEC_CONTENT	left\tagSEC_CONTENT	factors\tagSEC_CONTENT	boils\tagSEC_CONTENT	down\tagSEC_CONTENT	to\tagSEC_CONTENT	Eigenvalue\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	:\tagSEC_END	It\tagSEC_START	is\tagSEC_CONTENT	often\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	approximate\tagSEC_CONTENT	real\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	matrices\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	covariance\tagSEC_CONTENT	matrices\tagSEC_CONTENT	,\tagSEC_CONTENT	kernel\tagtask	functions\tagtask	and\tagSEC_CONTENT	distance\tagSEC_CONTENT	or\tagSEC_CONTENT	similarity\tagSEC_CONTENT	matrices\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	these\tagSEC_CONTENT	cases\tagSEC_CONTENT	all\tagSEC_CONTENT	eigenvalues\tagSEC_CONTENT	and\tagSEC_CONTENT	eigenvectors\tagSEC_CONTENT	live\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	space\tagSEC_CONTENT	and\tagSEC_CONTENT	E\tagSEC_CONTENT	is\tagSEC_CONTENT	orthogonal\tagSEC_CONTENT	:\tagSEC_CONTENT	.\tagSEC_CONTENT	Scoring\tagSEC_CONTENT	functions\tagSEC_CONTENT	of\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	latent\tagSEC_CONTENT	factor\tagSEC_CONTENT	models\tagSEC_CONTENT	fora\tagSEC_CONTENT	given\tagSEC_CONTENT	fact\tagSEC_CONTENT	r(s\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	along\tagSEC_CONTENT	with\tagSEC_CONTENT	their\tagSEC_CONTENT	relation\tagSEC_CONTENT	parameters\tagSEC_CONTENT	,\tagSEC_CONTENT	time\tagSEC_CONTENT	and\tagSEC_CONTENT	space\tagSEC_CONTENT	(\tagSEC_CONTENT	memory\tagSEC_CONTENT	)\tagSEC_CONTENT	complexity\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	es\tagSEC_CONTENT	and\tagSEC_CONTENT	eo\tagSEC_CONTENT	of\tagSEC_CONTENT	subject\tagSEC_CONTENT	sand\tagSEC_CONTENT	object\tagSEC_CONTENT	o\tagSEC_CONTENT	are\tagSEC_CONTENT	in\tagSEC_CONTENT	R\tagSEC_CONTENT	K\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	except\tagSEC_CONTENT	for\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	(\tagSEC_CONTENT	ComplEx\tagSEC_CONTENT	)\tagSEC_CONTENT	where\tagSEC_CONTENT	es\tagSEC_CONTENT	,\tagSEC_CONTENT	eo\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	K\tagSEC_CONTENT	.\tagSEC_CONTENT	Dis\tagSEC_CONTENT	an\tagSEC_CONTENT	additional\tagSEC_CONTENT	latent\tagSEC_CONTENT	dimension\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	NTN\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	F\tagSEC_CONTENT	and\tagSEC_CONTENT	F\tagSEC_CONTENT	−1\tagSEC_CONTENT	denote\tagSEC_CONTENT	respectively\tagSEC_CONTENT	the\tagSEC_CONTENT	Fourier\tagSEC_CONTENT	transform\tagSEC_CONTENT	and\tagSEC_CONTENT	its\tagSEC_CONTENT	inverse\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	element\tagSEC_CONTENT	-\tagSEC_CONTENT	wise\tagSEC_CONTENT	product\tagSEC_CONTENT	between\tagSEC_CONTENT	two\tagSEC_CONTENT	vectors\tagSEC_CONTENT	.\tagSEC_END	ET\tagSEC_START	=\tagSEC_CONTENT	E\tagSEC_CONTENT	−1\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	are\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	however\tagSEC_CONTENT	explicitly\tagSEC_CONTENT	interested\tagSEC_CONTENT	in\tagSEC_CONTENT	problems\tagSEC_CONTENT	where\tagSEC_CONTENT	matrices\tagSEC_CONTENT	-and\tagSEC_CONTENT	thus\tagSEC_CONTENT	the\tagSEC_CONTENT	relations\tagSEC_CONTENT	they\tagSEC_CONTENT	represent\tagSEC_CONTENT	-can\tagSEC_CONTENT	also\tagSEC_CONTENT	be\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	that\tagSEC_CONTENT	case\tagSEC_CONTENT	eigenvalue\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	possible\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	space\tagSEC_CONTENT	;\tagSEC_CONTENT	there\tagSEC_CONTENT	only\tagSEC_CONTENT	exists\tagSEC_CONTENT	a\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	space\tagSEC_CONTENT	where\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	x\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	K\tagSEC_CONTENT	are\tagSEC_CONTENT	composed\tagSEC_CONTENT	of\tagSEC_CONTENT	areal\tagSEC_CONTENT	vector\tagSEC_CONTENT	component\tagSEC_CONTENT	Re(x\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	an\tagSEC_CONTENT	imaginary\tagSEC_CONTENT	vector\tagSEC_CONTENT	component\tagSEC_CONTENT	Im(x\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	With\tagSEC_CONTENT	complex\tagSEC_CONTENT	numbers\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	also\tagSEC_CONTENT	called\tagSEC_CONTENT	the\tagSEC_CONTENT	Hermitian\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	sesquilinear\tagSEC_CONTENT	form\tagSEC_CONTENT	,\tagSEC_CONTENT	is\tagSEC_CONTENT	defined\tagSEC_CONTENT	as\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	u\tagSEC_CONTENT	and\tagSEC_CONTENT	v\tagSEC_CONTENT	are\tagSEC_CONTENT	complex\tagSEC_CONTENT	-\tagSEC_CONTENT	valued\tagSEC_CONTENT	vectors\tagSEC_CONTENT	,\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	u\tagSEC_CONTENT	=\tagSEC_CONTENT	Re(u\tagSEC_CONTENT	)\tagSEC_CONTENT	+\tagSEC_CONTENT	iIm(u\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	Re(u\tagSEC_CONTENT	)\tagSEC_CONTENT	∈\tagSEC_CONTENT	R\tagSEC_CONTENT	K\tagSEC_CONTENT	and\tagSEC_CONTENT	Im(u\tagSEC_CONTENT	)\tagSEC_CONTENT	∈\tagSEC_CONTENT	R\tagSEC_CONTENT	K\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	and\tagSEC_CONTENT	imaginary\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	vector\tagSEC_CONTENT	u\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	K\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	i\tagSEC_CONTENT	denoting\tagSEC_CONTENT	the\tagSEC_CONTENT	square\tagSEC_CONTENT	root\tagSEC_CONTENT	of\tagSEC_CONTENT	−1\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	see\tagSEC_CONTENT	here\tagSEC_CONTENT	that\tagSEC_CONTENT	one\tagSEC_CONTENT	crucial\tagSEC_CONTENT	operation\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	take\tagSEC_CONTENT	the\tagSEC_CONTENT	conjugate\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	vector\tagSEC_CONTENT	:\tagSEC_CONTENT	¯\tagSEC_CONTENT	u\tagSEC_CONTENT	=\tagSEC_CONTENT	Re(u\tagSEC_CONTENT	)\tagSEC_CONTENT	−\tagSEC_CONTENT	iIm(u\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	A\tagSEC_CONTENT	simple\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	justify\tagSEC_CONTENT	the\tagSEC_CONTENT	Hermitian\tagSEC_CONTENT	product\tagSEC_CONTENT	for\tagSEC_CONTENT	composing\tagSEC_CONTENT	complex\tagSEC_CONTENT	vectors\tagSEC_CONTENT	is\tagSEC_CONTENT	that\tagSEC_CONTENT	it\tagSEC_CONTENT	provides\tagSEC_CONTENT	a\tagSEC_CONTENT	valid\tagSEC_CONTENT	topological\tagSEC_CONTENT	norm\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	induced\tagSEC_CONTENT	vectorial\tagSEC_CONTENT	space\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	¯\tagSEC_CONTENT	x\tagSEC_CONTENT	T\tagSEC_CONTENT	x\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	implies\tagSEC_CONTENT	x\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	while\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	the\tagSEC_CONTENT	case\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	bilinear\tagSEC_CONTENT	form\tagSEC_CONTENT	x\tagSEC_CONTENT	T\tagSEC_CONTENT	x\tagSEC_CONTENT	as\tagSEC_CONTENT	there\tagSEC_CONTENT	are\tagSEC_CONTENT	many\tagSEC_CONTENT	complex\tagSEC_CONTENT	vectors\tagSEC_CONTENT	for\tagSEC_CONTENT	which\tagSEC_CONTENT	x\tagSEC_CONTENT	T\tagSEC_CONTENT	x\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	.\tagSEC_END	Even\tagSEC_START	with\tagSEC_CONTENT	complex\tagSEC_CONTENT	eigenvectors\tagSEC_CONTENT	E\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	n×n\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	inversion\tagSEC_CONTENT	of\tagSEC_CONTENT	E\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	eigendecomposition\tagSEC_CONTENT	of\tagSEC_CONTENT	Equation\tagSEC_CONTENT	leads\tagSEC_CONTENT	to\tagSEC_CONTENT	computational\tagSEC_CONTENT	issues\tagSEC_CONTENT	.\tagSEC_CONTENT	Fortunately\tagSEC_CONTENT	,\tagSEC_CONTENT	mathematicians\tagSEC_CONTENT	defined\tagSEC_CONTENT	an\tagSEC_CONTENT	appropriate\tagSEC_CONTENT	class\tagSEC_CONTENT	of\tagSEC_CONTENT	matrices\tagSEC_CONTENT	that\tagSEC_CONTENT	prevents\tagSEC_CONTENT	us\tagSEC_CONTENT	from\tagSEC_CONTENT	inverting\tagSEC_CONTENT	the\tagSEC_CONTENT	eigenvector\tagSEC_CONTENT	matrix\tagSEC_CONTENT	:\tagSEC_CONTENT	we\tagSEC_CONTENT	consider\tagSEC_CONTENT	the\tagSEC_CONTENT	space\tagSEC_CONTENT	of\tagSEC_CONTENT	normal\tagSEC_CONTENT	matrices\tagSEC_CONTENT	,\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	n\tagSEC_CONTENT	×\tagSEC_CONTENT	n\tagSEC_CONTENT	matrices\tagSEC_CONTENT	X\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	that\tagSEC_CONTENT	X\tagSEC_CONTENT	¯\tagSEC_CONTENT	X\tagSEC_CONTENT	T\tagSEC_CONTENT	=\tagSEC_CONTENT	¯\tagSEC_CONTENT	X\tagSEC_CONTENT	TX\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	spectral\tagSEC_CONTENT	theorem\tagSEC_CONTENT	for\tagSEC_CONTENT	normal\tagSEC_CONTENT	matrices\tagSEC_CONTENT	states\tagSEC_CONTENT	that\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	X\tagSEC_CONTENT	is\tagSEC_CONTENT	normal\tagSEC_CONTENT	if\tagSEC_CONTENT	and\tagSEC_CONTENT	only\tagSEC_CONTENT	if\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	unitarily\tagSEC_CONTENT	diagonalizable\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	W\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	n×n\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	diagonal\tagSEC_CONTENT	matrix\tagSEC_CONTENT	of\tagSEC_CONTENT	eigenvalues\tagSEC_CONTENT	(\tagSEC_CONTENT	with\tagSEC_CONTENT	decreasing\tagSEC_CONTENT	modulus\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	E\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	n×n\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	unitary\tagSEC_CONTENT	matrix\tagSEC_CONTENT	of\tagSEC_CONTENT	eigenvectors\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	¯\tagSEC_CONTENT	E\tagSEC_CONTENT	representing\tagSEC_CONTENT	its\tagSEC_CONTENT	complex\tagSEC_CONTENT	conjugate\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	set\tagSEC_CONTENT	of\tagSEC_CONTENT	purely\tagSEC_CONTENT	real\tagSEC_CONTENT	normal\tagSEC_CONTENT	matrices\tagSEC_CONTENT	includes\tagSEC_CONTENT	all\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	and\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	sign\tagSEC_CONTENT	matrices\tagSEC_CONTENT	(\tagSEC_CONTENT	useful\tagSEC_CONTENT	to\tagSEC_CONTENT	model\tagSEC_CONTENT	hierarchical\tagSEC_CONTENT	relations\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	IsOlder\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	all\tagSEC_CONTENT	orthogonal\tagSEC_CONTENT	matrices\tagSEC_CONTENT	(\tagSEC_CONTENT	including\tagSEC_CONTENT	permutation\tagtask	matrices\tagtask	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	many\tagSEC_CONTENT	other\tagSEC_CONTENT	matrices\tagSEC_CONTENT	that\tagSEC_CONTENT	are\tagSEC_CONTENT	useful\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	binary\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	assignment\tagSEC_CONTENT	matrices\tagSEC_CONTENT	which\tagSEC_CONTENT	represent\tagSEC_CONTENT	bipartite\tagSEC_CONTENT	graphs\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	far\tagSEC_CONTENT	from\tagSEC_CONTENT	all\tagSEC_CONTENT	matrices\tagSEC_CONTENT	expressed\tagSEC_CONTENT	as\tagSEC_CONTENT	EW\tagSEC_CONTENT	¯\tagSEC_CONTENT	ET\tagSEC_CONTENT	are\tagSEC_CONTENT	purely\tagSEC_CONTENT	real\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	equation\tagSEC_CONTENT	1\tagSEC_CONTENT	requires\tagSEC_CONTENT	the\tagSEC_CONTENT	scores\tagSEC_CONTENT	X\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	purely\tagSEC_CONTENT	real\tagSEC_CONTENT	.\tagSEC_CONTENT	So\tagSEC_CONTENT	we\tagSEC_CONTENT	simply\tagSEC_CONTENT	keep\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	:\tagSEC_END	In\tagSEC_START	fact\tagSEC_CONTENT	,\tagSEC_CONTENT	performing\tagSEC_CONTENT	this\tagtask	projection\tagtask	on\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	subspace\tagSEC_CONTENT	allows\tagSEC_CONTENT	the\tagSEC_CONTENT	exact\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	of\tagSEC_CONTENT	any\tagSEC_CONTENT	real\tagSEC_CONTENT	square\tagSEC_CONTENT	matrix\tagSEC_CONTENT	X\tagSEC_CONTENT	and\tagSEC_CONTENT	not\tagSEC_CONTENT	only\tagSEC_CONTENT	normal\tagSEC_CONTENT	ones\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	shown\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_END	Compared\tagSEC_START	to\tagSEC_CONTENT	the\tagSEC_CONTENT	singular\tagSEC_CONTENT	value\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	eigenvalue\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	has\tagSEC_CONTENT	two\tagSEC_CONTENT	key\tagSEC_CONTENT	differences\tagSEC_CONTENT	:\tagSEC_END	•\tagSEC_START	The\tagSEC_CONTENT	eigenvalues\tagSEC_CONTENT	are\tagSEC_CONTENT	not\tagSEC_CONTENT	necessarily\tagSEC_CONTENT	positive\tagSEC_CONTENT	or\tagSEC_CONTENT	real\tagSEC_CONTENT	;\tagSEC_END	•\tagSEC_START	The\tagtask	factorization\tagtask	is\tagSEC_CONTENT	useful\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	rows\tagSEC_CONTENT	of\tagSEC_CONTENT	E\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	used\tagSEC_CONTENT	as\tagSEC_CONTENT	vectorial\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	entities\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	to\tagSEC_CONTENT	rows\tagSEC_CONTENT	and\tagSEC_CONTENT	columns\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	matrix\tagSEC_CONTENT	X.\tagSEC_CONTENT	Indeed\tagSEC_CONTENT	,\tagSEC_CONTENT	fora\tagSEC_CONTENT	given\tagSEC_CONTENT	entity\tagSEC_CONTENT	,\tagSEC_CONTENT	its\tagSEC_CONTENT	subject\tagSEC_CONTENT	embedding\tagSEC_CONTENT	vector\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	conjugate\tagSEC_CONTENT	of\tagSEC_CONTENT	its\tagSEC_CONTENT	object\tagSEC_CONTENT	embedding\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_END	Low\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Rank\tagSECTITLE_CONTENT	Decomposition\tagSECTITLE_END	Ina\tagSEC_START	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagtask	relation\tagtask	matrix\tagtask	is\tagSEC_CONTENT	unknown\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	goal\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	recover\tagSEC_CONTENT	it\tagSEC_CONTENT	entirely\tagSEC_CONTENT	from\tagSEC_CONTENT	noisy\tagSEC_CONTENT	observations\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	enable\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	learnable\tagSEC_CONTENT	,\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	to\tagSEC_CONTENT	generalize\tagSEC_CONTENT	to\tagSEC_CONTENT	unobserved\tagSEC_CONTENT	links\tagSEC_CONTENT	,\tagSEC_CONTENT	some\tagSEC_CONTENT	regularity\tagSEC_CONTENT	assumptions\tagSEC_CONTENT	are\tagSEC_CONTENT	needed\tagSEC_CONTENT	.\tagSEC_CONTENT	Since\tagSEC_CONTENT	we\tagSEC_CONTENT	deal\tagSEC_CONTENT	with\tagSEC_CONTENT	binary\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	assume\tagSEC_CONTENT	that\tagSEC_CONTENT	they\tagSEC_CONTENT	have\tagSEC_CONTENT	low\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	a\tagSEC_CONTENT	sign\tagSEC_CONTENT	matrix\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	smallest\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	areal\tagSEC_CONTENT	matrix\tagSEC_CONTENT	that\tagSEC_CONTENT	has\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	pattern\tagSEC_CONTENT	as\tagSEC_CONTENT	Y\tagSEC_CONTENT	:\tagSEC_END	This\tagSEC_START	is\tagSEC_CONTENT	theoretically\tagSEC_CONTENT	justified\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	signrank\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	natural\tagSEC_CONTENT	complexity\tagSEC_CONTENT	measure\tagSEC_CONTENT	of\tagSEC_CONTENT	sign\tagSEC_CONTENT	matrices\tagSEC_CONTENT	(\tagSEC_CONTENT	and\tagSEC_CONTENT	is\tagSEC_CONTENT	linked\tagSEC_CONTENT	to\tagSEC_CONTENT	learnability\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	empirically\tagSEC_CONTENT	confirmed\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	wide\tagSEC_CONTENT	success\tagSEC_CONTENT	of\tagSEC_CONTENT	factorization\tagSEC_CONTENT	models\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	If\tagSEC_START	the\tagSEC_CONTENT	observation\tagSEC_CONTENT	matrix\tagSEC_CONTENT	Y\tagSEC_CONTENT	is\tagSEC_CONTENT	low\tagSEC_CONTENT	-\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	,\tagSEC_CONTENT	then\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	decompose\tagSEC_CONTENT	it\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	rank\tagSEC_CONTENT	at\tagSEC_CONTENT	most\tagSEC_CONTENT	the\tagSEC_CONTENT	double\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	Y\tagSEC_CONTENT	.\tagSEC_CONTENT	That\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	any\tagSEC_CONTENT	Y\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	−1\tagSEC_CONTENT	,\tagSEC_CONTENT	1\tagSEC_CONTENT	}\tagSEC_CONTENT	n×n\tagSEC_CONTENT	,\tagSEC_CONTENT	there\tagSEC_CONTENT	always\tagSEC_CONTENT	exists\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	X\tagSEC_CONTENT	=\tagSEC_CONTENT	Re(EW\tagSEC_CONTENT	¯\tagSEC_CONTENT	ET\tagSEC_CONTENT	)\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	sign\tagSEC_CONTENT	pattern\tagSEC_CONTENT	sign(X\tagSEC_CONTENT	)\tagSEC_CONTENT	=\tagSEC_CONTENT	Y\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	the\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	EW\tagSEC_CONTENT	¯\tagSEC_CONTENT	ET\tagSEC_CONTENT	is\tagSEC_CONTENT	at\tagSEC_CONTENT	most\tagSEC_CONTENT	twice\tagSEC_CONTENT	the\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	Y\tagSEC_CONTENT	(\tagSEC_CONTENT	.\tagSEC_END	Although\tagSEC_START	twice\tagSEC_CONTENT	sounds\tagSEC_CONTENT	bad\tagSEC_CONTENT	,\tagSEC_CONTENT	this\tagSEC_CONTENT	is\tagSEC_CONTENT	actually\tagSEC_CONTENT	a\tagSEC_CONTENT	good\tagSEC_CONTENT	upper\tagSEC_CONTENT	bound\tagSEC_CONTENT	.\tagSEC_CONTENT	Indeed\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	is\tagSEC_CONTENT	often\tagSEC_CONTENT	much\tagSEC_CONTENT	lower\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	Y\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	rank\tagSEC_CONTENT	of\tagSEC_CONTENT	then\tagSEC_CONTENT	×\tagSEC_CONTENT	n\tagSEC_CONTENT	identity\tagSEC_CONTENT	matrix\tagSEC_CONTENT	I\tagSEC_CONTENT	is\tagSEC_CONTENT	n\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	rank\tagSEC_CONTENT	±\tagSEC_CONTENT	(\tagSEC_CONTENT	I\tagSEC_CONTENT	)\tagSEC_CONTENT	=\tagSEC_CONTENT	3\tagSEC_CONTENT	(\tagSEC_CONTENT	Alon\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	,\tagSEC_CONTENT	2015\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	By\tagSEC_CONTENT	permutation\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	columns\tagSEC_CONTENT	2j\tagSEC_CONTENT	and\tagSEC_CONTENT	2j\tagSEC_CONTENT	+\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	I\tagSEC_CONTENT	matrix\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagtask	relation\tagtask	marriedTo\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	relation\tagSEC_CONTENT	known\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	hard\tagSEC_CONTENT	to\tagSEC_CONTENT	factorize\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Yet\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	express\tagSEC_CONTENT	it\tagSEC_CONTENT	in\tagSEC_CONTENT	rank\tagSEC_CONTENT	6\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	any\tagSEC_CONTENT	n.\tagSEC_END	By\tagSEC_START	imposing\tagSEC_CONTENT	a\tagSEC_CONTENT	low\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	K\tagSEC_CONTENT	non\tagSEC_CONTENT	EW\tagSEC_CONTENT	¯\tagSEC_CONTENT	ET\tagSEC_CONTENT	,\tagSEC_CONTENT	only\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	K\tagSEC_CONTENT	values\tagSEC_CONTENT	of\tagSEC_CONTENT	diag(W\tagSEC_CONTENT	)\tagSEC_CONTENT	are\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	zero\tagSEC_CONTENT	.\tagSEC_CONTENT	So\tagSEC_CONTENT	we\tagSEC_CONTENT	can\tagSEC_CONTENT	directly\tagSEC_CONTENT	have\tagSEC_CONTENT	E\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	n×K\tagSEC_CONTENT	and\tagSEC_CONTENT	W\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	K×K\tagSEC_CONTENT	.\tagSEC_CONTENT	Individual\tagSEC_CONTENT	relation\tagSEC_CONTENT	scores\tagSEC_CONTENT	X\tagSEC_CONTENT	so\tagSEC_CONTENT	between\tagSEC_CONTENT	entities\tagSEC_CONTENT	sand\tagSEC_CONTENT	o\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	predicted\tagSEC_CONTENT	through\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	product\tagSEC_CONTENT	of\tagSEC_CONTENT	their\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	o\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	K\tagSEC_CONTENT	:\tagSEC_END	We\tagSEC_START	summarize\tagSEC_CONTENT	the\tagtask	above\tagtask	discussion\tagtask	in\tagSEC_CONTENT	three\tagSEC_CONTENT	points\tagSEC_CONTENT	:\tagSEC_END	1\tagSEC_START	.\tagSEC_CONTENT	Our\tagtask	factorization\tagtask	encompasses\tagSEC_CONTENT	all\tagSEC_CONTENT	possible\tagSEC_CONTENT	binary\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	2\tagSEC_START	.\tagSEC_CONTENT	By\tagSEC_CONTENT	construction\tagtask	,\tagSEC_CONTENT	it\tagSEC_CONTENT	accurately\tagSEC_CONTENT	describes\tagSEC_CONTENT	both\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	and\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	3\tagSEC_START	.\tagSEC_CONTENT	Learnable\tagtask	relations\tagtask	can\tagSEC_CONTENT	be\tagSEC_CONTENT	efficiently\tagSEC_CONTENT	approximated\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	low\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	factorization\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	complex\tagSEC_CONTENT	numbers\tagSEC_CONTENT	to\tagSEC_CONTENT	represent\tagSEC_CONTENT	the\tagSEC_CONTENT	latent\tagSEC_CONTENT	factors\tagSEC_CONTENT	.\tagSEC_END	Application\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Binary\tagSECTITLE_CONTENT	Multi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Relational\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	The\tagSEC_START	previous\tagtask	section\tagtask	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	modeling\tagSEC_CONTENT	a\tagSEC_CONTENT	single\tagSEC_CONTENT	type\tagSEC_CONTENT	of\tagSEC_CONTENT	relation\tagSEC_CONTENT	;\tagSEC_CONTENT	we\tagSEC_CONTENT	now\tagSEC_CONTENT	extend\tagSEC_CONTENT	this\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	multiple\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	do\tagSEC_CONTENT	so\tagSEC_CONTENT	by\tagSEC_CONTENT	allocating\tagSEC_CONTENT	an\tagSEC_CONTENT	embedding\tagSEC_CONTENT	w\tagSEC_CONTENT	r\tagSEC_CONTENT	to\tagSEC_CONTENT	each\tagSEC_CONTENT	relation\tagSEC_CONTENT	r\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	by\tagSEC_CONTENT	sharing\tagSEC_CONTENT	the\tagSEC_CONTENT	entity\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	across\tagSEC_CONTENT	all\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	Let\tagSEC_START	Rand\tagSEC_CONTENT	E\tagSEC_CONTENT	be\tagSEC_CONTENT	the\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagtask	and\tagSEC_CONTENT	entities\tagSEC_CONTENT	present\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	KB\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	want\tagSEC_CONTENT	to\tagSEC_CONTENT	recover\tagSEC_CONTENT	the\tagSEC_CONTENT	matrices\tagSEC_CONTENT	of\tagSEC_CONTENT	scores\tagSEC_CONTENT	X\tagSEC_CONTENT	r\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	relations\tagSEC_CONTENT	r\tagSEC_CONTENT	∈\tagSEC_CONTENT	R.\tagSEC_CONTENT	Given\tagSEC_CONTENT	two\tagSEC_CONTENT	entities\tagSEC_CONTENT	sand\tagSEC_CONTENT	o\tagSEC_CONTENT	∈\tagSEC_CONTENT	E\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	odd\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	probability\tagSEC_CONTENT	that\tagSEC_CONTENT	the\tagSEC_CONTENT	fact\tagSEC_CONTENT	r(s\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	true\tagSEC_CONTENT	is\tagSEC_CONTENT	:\tagSEC_END	where\tagSEC_START	φ\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	scoring\tagSEC_CONTENT	function\tagSEC_CONTENT	that\tagSEC_CONTENT	is\tagSEC_CONTENT	typically\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	a\tagtask	factorization\tagtask	of\tagSEC_CONTENT	the\tagSEC_CONTENT	observed\tagSEC_CONTENT	relations\tagSEC_CONTENT	and\tagSEC_CONTENT	Θ\tagSEC_CONTENT	denotes\tagSEC_CONTENT	the\tagSEC_CONTENT	parameters\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	model\tagSEC_CONTENT	.\tagSEC_CONTENT	While\tagSEC_CONTENT	X\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	whole\tagSEC_CONTENT	is\tagSEC_CONTENT	unknown\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	assume\tagSEC_CONTENT	that\tagSEC_CONTENT	we\tagSEC_CONTENT	observe\tagSEC_CONTENT	a\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	true\tagSEC_CONTENT	and\tagSEC_CONTENT	false\tagSEC_CONTENT	facts\tagSEC_CONTENT	{\tagSEC_CONTENT	Y\tagSEC_CONTENT	rso\tagSEC_CONTENT	}\tagSEC_CONTENT	r(s\tagSEC_CONTENT	,\tagSEC_CONTENT	o)∈Ω\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	−1\tagSEC_CONTENT	,\tagSEC_CONTENT	1\tagSEC_CONTENT	}\tagSEC_CONTENT	|Ω|\tagSEC_CONTENT	,\tagSEC_CONTENT	corresponding\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	partially\tagSEC_CONTENT	observed\tagSEC_CONTENT	adjacency\tagSEC_CONTENT	matrices\tagSEC_CONTENT	of\tagSEC_CONTENT	different\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	where\tagSEC_CONTENT	Ω\tagSEC_CONTENT	⊂\tagSEC_CONTENT	R\tagSEC_CONTENT	⊗\tagSEC_CONTENT	E\tagSEC_CONTENT	⊗\tagSEC_CONTENT	E\tagSEC_CONTENT	is\tagSEC_CONTENT	the\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	observed\tagSEC_CONTENT	triples\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	goal\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	find\tagSEC_CONTENT	the\tagSEC_CONTENT	probabilities\tagSEC_CONTENT	of\tagSEC_CONTENT	entries\tagSEC_CONTENT	Y\tagSEC_CONTENT	r\tagSEC_CONTENT	so\tagSEC_CONTENT	being\tagSEC_CONTENT	true\tagSEC_CONTENT	or\tagSEC_CONTENT	false\tagSEC_CONTENT	fora\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	targeted\tagSEC_CONTENT	unobserved\tagSEC_CONTENT	triples\tagSEC_CONTENT	r\tagSEC_CONTENT	(\tagSEC_CONTENT	s\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	)\tagSEC_CONTENT	/\tagSEC_CONTENT	∈\tagSEC_CONTENT	Ω.\tagSEC_END	Depending\tagSEC_START	on\tagSEC_CONTENT	the\tagSEC_CONTENT	scoring\tagSEC_CONTENT	function\tagSEC_CONTENT	φ(s\tagSEC_CONTENT	,\tagSEC_CONTENT	r\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	;\tagSEC_CONTENT	Θ\tagSEC_CONTENT	)\tagSEC_CONTENT	used\tagSEC_CONTENT	to\tagSEC_CONTENT	predict\tagSEC_CONTENT	the\tagSEC_CONTENT	entries\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	tensor\tagSEC_CONTENT	X\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	obtain\tagSEC_CONTENT	different\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Examples\tagSEC_CONTENT	of\tagSEC_CONTENT	scoring\tagSEC_CONTENT	functions\tagSEC_CONTENT	are\tagSEC_CONTENT	given\tagSEC_CONTENT	in\tagSEC_CONTENT	.\tagSEC_END	Our\tagSEC_START	model\tagSEC_CONTENT	scoring\tagSEC_CONTENT	function\tagSEC_CONTENT	is\tagSEC_CONTENT	:\tagSEC_END	=\tagSEC_START	Re\tagSEC_CONTENT	(\tagSEC_END	where\tagSEC_START	w\tagSEC_CONTENT	r\tagSEC_CONTENT	∈\tagSEC_CONTENT	C\tagSEC_CONTENT	K\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	complex\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	equations\tagSEC_CONTENT	provide\tagSEC_CONTENT	two\tagSEC_CONTENT	interesting\tagSEC_CONTENT	views\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	:\tagSEC_END	•\tagSEC_START	Changing\tagSEC_CONTENT	the\tagSEC_CONTENT	representation\tagSEC_CONTENT	:\tagSEC_CONTENT	Equation\tagSEC_CONTENT	(\tagSEC_CONTENT	10\tagSEC_CONTENT	)\tagSEC_CONTENT	would\tagSEC_CONTENT	correspond\tagSEC_CONTENT	to\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	with\tagSEC_CONTENT	real\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	handles\tagSEC_CONTENT	asymmetry\tagSEC_CONTENT	thanks\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	conjugate\tagSEC_CONTENT	of\tagSEC_CONTENT	one\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	2\tagSEC_CONTENT	.\tagSEC_END	•\tagSEC_START	Changing\tagSEC_CONTENT	the\tagSEC_CONTENT	scoring\tagSEC_CONTENT	function\tagSEC_CONTENT	:\tagSEC_CONTENT	Equation\tagSEC_CONTENT	(\tagSEC_CONTENT	11\tagSEC_CONTENT	)\tagSEC_CONTENT	only\tagSEC_CONTENT	involves\tagSEC_CONTENT	real\tagtask	vectors\tagtask	corresponding\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	and\tagSEC_CONTENT	imaginary\tagSEC_CONTENT	parts\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	and\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	One\tagSEC_START	can\tagSEC_CONTENT	easily\tagSEC_CONTENT	check\tagSEC_CONTENT	that\tagSEC_CONTENT	this\tagSEC_CONTENT	function\tagSEC_CONTENT	is\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	when\tagSEC_CONTENT	w\tagSEC_CONTENT	r\tagSEC_CONTENT	is\tagSEC_CONTENT	purely\tagSEC_CONTENT	imaginary\tagSEC_CONTENT	(\tagSEC_CONTENT	i.e.\tagSEC_CONTENT	its\tagSEC_CONTENT	real\tagSEC_CONTENT	part\tagSEC_CONTENT	is\tagSEC_CONTENT	zero\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	when\tagSEC_CONTENT	w\tagSEC_CONTENT	r\tagSEC_CONTENT	is\tagSEC_CONTENT	real\tagSEC_CONTENT	.\tagSEC_CONTENT	Interestingly\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	separating\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	and\tagSEC_CONTENT	imaginary\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagtask	relation\tagtask	embedding\tagSEC_CONTENT	w\tagSEC_CONTENT	r\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	obtain\tagSEC_CONTENT	a\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	matrix\tagSEC_CONTENT	X\tagSEC_CONTENT	r\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	sum\tagSEC_CONTENT	of\tagSEC_CONTENT	asymmetric\tagSEC_CONTENT	matrix\tagSEC_CONTENT	Re(E\tagSEC_CONTENT	diag(Re(w\tagSEC_CONTENT	r\tagSEC_CONTENT	)\tagSEC_CONTENT	)\tagSEC_CONTENT	¯\tagSEC_CONTENT	ET\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	a\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	matrix\tagSEC_CONTENT	Im(E\tagSEC_CONTENT	diag(−Im(w\tagSEC_CONTENT	r\tagSEC_CONTENT	)\tagSEC_CONTENT	)\tagSEC_CONTENT	¯\tagSEC_CONTENT	ET\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Relation\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	naturally\tagSEC_CONTENT	act\tagSEC_CONTENT	as\tagSEC_CONTENT	weights\tagSEC_CONTENT	on\tagSEC_CONTENT	each\tagSEC_CONTENT	latent\tagSEC_CONTENT	dimension\tagSEC_CONTENT	:\tagSEC_CONTENT	Re(w\tagSEC_CONTENT	r\tagSEC_CONTENT	)\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	,\tagSEC_CONTENT	real\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	e\tagSEC_CONTENT	o\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	Im(w\tagSEC_CONTENT	)\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	,\tagSEC_CONTENT	imaginary\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	e\tagSEC_CONTENT	o\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	.\tagSEC_CONTENT	Indeed\tagSEC_CONTENT	,\tagSEC_CONTENT	one\tagSEC_CONTENT	has\tagSEC_CONTENT	e\tagSEC_CONTENT	o\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	=\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	o\tagSEC_CONTENT	,\tagSEC_CONTENT	meaning\tagSEC_CONTENT	that\tagSEC_CONTENT	Re(e\tagSEC_CONTENT	o\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	Im(e\tagSEC_CONTENT	o\tagSEC_CONTENT	,\tagSEC_CONTENT	e\tagSEC_CONTENT	s\tagSEC_CONTENT	)\tagSEC_CONTENT	is\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	enables\tagSEC_CONTENT	us\tagSEC_CONTENT	to\tagSEC_CONTENT	accurately\tagSEC_CONTENT	describe\tagSEC_CONTENT	both\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	and\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	between\tagSEC_CONTENT	pairs\tagSEC_CONTENT	of\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	still\tagSEC_CONTENT	using\tagSEC_CONTENT	joint\tagSEC_CONTENT	representations\tagSEC_CONTENT	of\tagSEC_CONTENT	entities\tagSEC_CONTENT	,\tagSEC_CONTENT	whether\tagSEC_CONTENT	they\tagSEC_CONTENT	appear\tagSEC_CONTENT	as\tagSEC_CONTENT	subject\tagSEC_CONTENT	or\tagSEC_CONTENT	object\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_END	Geometrically\tagSEC_START	,\tagSEC_CONTENT	each\tagtask	relation\tagtask	embedding\tagSEC_CONTENT	w\tagSEC_CONTENT	r\tagSEC_CONTENT	is\tagSEC_CONTENT	an\tagSEC_CONTENT	anisotropic\tagSEC_CONTENT	scaling\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	basis\tagSEC_CONTENT	defined\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	entity\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	E\tagSEC_CONTENT	,\tagSEC_CONTENT	followed\tagSEC_CONTENT	by\tagSEC_CONTENT	a\tagSEC_CONTENT	projection\tagSEC_CONTENT	onto\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	subspace\tagSEC_CONTENT	.\tagSEC_END	Experiments\tagSECTITLE_END	In\tagSEC_START	order\tagSEC_CONTENT	to\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	our\tagSEC_CONTENT	proposal\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	conducted\tagSEC_CONTENT	experiments\tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	synthetic\tagSEC_CONTENT	and\tagSEC_CONTENT	real\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	synthetic\tagSEC_CONTENT	dataset\tagSEC_CONTENT	is\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	relations\tagtask	that\tagSEC_CONTENT	are\tagSEC_CONTENT	either\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	or\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	datasets\tagSEC_CONTENT	comprise\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagSEC_CONTENT	found\tagSEC_CONTENT	in\tagSEC_CONTENT	different\tagSEC_CONTENT	,\tagSEC_CONTENT	standard\tagSEC_CONTENT	KBs\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	refer\tagSEC_CONTENT	to\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	as\tagSEC_CONTENT	ComplEx\tagSEC_CONTENT	,\tagSEC_CONTENT	for\tagSEC_CONTENT	Complex\tagSEC_CONTENT	Embeddings\tagSEC_CONTENT	.\tagSEC_END	Synthetic\tagSECTITLE_START	Task\tagSECTITLE_END	To\tagSEC_START	assess\tagSEC_CONTENT	the\tagSEC_CONTENT	ability\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	proposal\tagSEC_CONTENT	to\tagSEC_CONTENT	accurately\tagSEC_CONTENT	model\tagSEC_CONTENT	symmetry\tagSEC_CONTENT	and\tagSEC_CONTENT	antisymmetry\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	randomly\tagSEC_CONTENT	generated\tagSEC_CONTENT	a\tagSEC_CONTENT	KB\tagSEC_CONTENT	of\tagSEC_CONTENT	two\tagtask	relations\tagtask	and\tagSEC_CONTENT	30\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	One\tagSEC_CONTENT	relation\tagSEC_CONTENT	is\tagSEC_CONTENT	entirely\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	is\tagSEC_CONTENT	completely\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	dataset\tagSEC_CONTENT	corresponds\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	2\tagSEC_CONTENT	×\tagSEC_CONTENT	30\tagSEC_CONTENT	×\tagSEC_CONTENT	30\tagSEC_CONTENT	tensor\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	apart\tagSEC_CONTENT	of\tagSEC_CONTENT	this\tagSEC_CONTENT	randomly\tagSEC_CONTENT	generated\tagSEC_CONTENT	tensor\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	asymmetric\tagSEC_CONTENT	slice\tagSEC_CONTENT	and\tagSEC_CONTENT	an\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	slice\tagSEC_CONTENT	,\tagSEC_CONTENT	decomposed\tagSEC_CONTENT	into\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	validation\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	sets\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	diagonal\tagSEC_CONTENT	is\tagSEC_CONTENT	unobserved\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	not\tagSEC_CONTENT	relevant\tagSEC_CONTENT	in\tagSEC_CONTENT	this\tagSEC_CONTENT	experiment\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	train\tagSEC_CONTENT	set\tagSEC_CONTENT	contains\tagSEC_CONTENT	1392\tagSEC_CONTENT	observed\tagSEC_CONTENT	triples\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	sets\tagSEC_CONTENT	contain\tagSEC_CONTENT	174\tagSEC_CONTENT	triples\tagSEC_CONTENT	each\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	cross\tagSEC_CONTENT	-\tagSEC_CONTENT	validated\tagSEC_CONTENT	Average\tagSEC_CONTENT	Precision\tagSEC_CONTENT	(\tagSEC_CONTENT	area\tagSEC_CONTENT	under\tagSEC_CONTENT	Precision\tagSEC_CONTENT	-\tagSEC_CONTENT	Recall\tagSEC_CONTENT	curve\tagSEC_CONTENT	)\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	factorization\tagSEC_CONTENT	models\tagSEC_CONTENT	of\tagSEC_CONTENT	ranks\tagSEC_CONTENT	ranging\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	50\tagSEC_CONTENT	.\tagSEC_CONTENT	Models\tagSEC_CONTENT	were\tagSEC_CONTENT	trained\tagSEC_CONTENT	using\tagSEC_CONTENT	Stochastic\tagSEC_CONTENT	Gradient\tagSEC_CONTENT	Descent\tagSEC_CONTENT	with\tagSEC_CONTENT	mini\tagSEC_CONTENT	-\tagSEC_CONTENT	batches\tagSEC_CONTENT	and\tagSEC_CONTENT	AdaGrad\tagSEC_CONTENT	for\tagSEC_CONTENT	tuning\tagSEC_CONTENT	the\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	by\tagSEC_CONTENT	minimizing\tagSEC_CONTENT	the\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	logistic\tagSEC_CONTENT	model\tagSEC_CONTENT	with\tagSEC_CONTENT	L\tagtask	2\tagtask	regularization\tagtask	on\tagSEC_CONTENT	the\tagSEC_CONTENT	parameters\tagSEC_CONTENT	Θ\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	considered\tagSEC_CONTENT	model\tagSEC_CONTENT	:\tagSEC_CONTENT	 \tagSEC_CONTENT	on\tagSEC_CONTENT	both\tagSEC_CONTENT	relations\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	has\tagSEC_CONTENT	to\tagSEC_CONTENT	push\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	and\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	patterns\tagSEC_CONTENT	through\tagSEC_CONTENT	the\tagSEC_CONTENT	entity\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	Surprisingly\tagSEC_CONTENT	,\tagSEC_CONTENT	only\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	succeeds\tagSEC_CONTENT	on\tagSEC_CONTENT	such\tagSEC_CONTENT	simple\tagSEC_CONTENT	data\tagSEC_CONTENT	.\tagSEC_END	Datasets\tagSECTITLE_START	:\tagSECTITLE_CONTENT	FB15\tagSECTITLE_CONTENT	K\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	WN18\tagSECTITLE_END	Dataset\tagSEC_START	 \tagSEC_CONTENT	We\tagSEC_CONTENT	next\tagSEC_CONTENT	evaluate\tagSEC_CONTENT	the\tagSEC_CONTENT	performance\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagdataset	FB15\tagdataset	K\tagdataset	and\tagSEC_CONTENT	WN18\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_CONTENT	FB15\tagSEC_CONTENT	K\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	subset\tagSEC_CONTENT	of\tagSEC_CONTENT	Freebase\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	curated\tagSEC_CONTENT	KB\tagSEC_CONTENT	of\tagSEC_CONTENT	general\tagSEC_CONTENT	facts\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	WN18\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	subset\tagSEC_CONTENT	of\tagSEC_CONTENT	Wordnet\tagSEC_CONTENT	,\tagSEC_CONTENT	a\tagSEC_CONTENT	database\tagSEC_CONTENT	featuring\tagSEC_CONTENT	lexical\tagSEC_CONTENT	relations\tagSEC_CONTENT	between\tagSEC_CONTENT	words\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	use\tagSEC_CONTENT	original\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	validation\tagSEC_CONTENT	and\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	splits\tagSEC_CONTENT	as\tagSEC_CONTENT	provided\tagSEC_CONTENT	by\tagSEC_CONTENT	.\tagSEC_CONTENT	summarizes\tagSEC_CONTENT	the\tagSEC_CONTENT	metadata\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	two\tagSEC_CONTENT	datasets\tagSEC_CONTENT	.\tagSEC_END	Both\tagSEC_START	datasets\tagSEC_CONTENT	contain\tagSEC_CONTENT	only\tagSEC_CONTENT	positive\tagSEC_CONTENT	triples\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	in\tagSEC_CONTENT	Bordes\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	2013b\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	generated\tagSEC_CONTENT	negatives\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	local\tagSEC_CONTENT	closed\tagSEC_CONTENT	world\tagSEC_CONTENT	assumption\tagSEC_CONTENT	.\tagSEC_CONTENT	That\tagSEC_CONTENT	is\tagSEC_CONTENT	,\tagSEC_CONTENT	fora\tagSEC_CONTENT	triple\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	randomly\tagSEC_CONTENT	change\tagSEC_CONTENT	either\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	or\tagSEC_CONTENT	the\tagSEC_CONTENT	object\tagSEC_CONTENT	at\tagSEC_CONTENT	random\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	form\tagSEC_CONTENT	a\tagSEC_CONTENT	negative\tagSEC_CONTENT	example\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	negative\tagSEC_CONTENT	sampling\tagSEC_CONTENT	is\tagSEC_CONTENT	performed\tagSEC_CONTENT	at\tagSEC_CONTENT	runtime\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	batch\tagSEC_CONTENT	of\tagSEC_CONTENT	training\tagSEC_CONTENT	positive\tagSEC_CONTENT	examples\tagSEC_CONTENT	.\tagSEC_END	For\tagSEC_START	evaluation\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	measure\tagSEC_CONTENT	the\tagSEC_CONTENT	quality\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	of\tagSEC_CONTENT	each\tagSEC_CONTENT	test\tagSEC_CONTENT	triple\tagSEC_CONTENT	among\tagSEC_CONTENT	all\tagSEC_CONTENT	possible\tagSEC_CONTENT	subject\tagSEC_CONTENT	and\tagSEC_CONTENT	object\tagSEC_CONTENT	substitutions\tagSEC_CONTENT	:\tagSEC_CONTENT	r(s\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	)\tagSEC_CONTENT	and\tagSEC_CONTENT	r(s\tagSEC_CONTENT	,\tagSEC_CONTENT	o\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	∀s\tagSEC_CONTENT	,\tagSEC_CONTENT	∀o\tagSEC_CONTENT	∈\tagSEC_CONTENT	E.\tagSEC_CONTENT	Mean\tagSEC_CONTENT	Reciprocal\tagSEC_CONTENT	Rank\tagSEC_CONTENT	(\tagmetric	MRR\tagmetric	)\tagSEC_CONTENT	and\tagSEC_CONTENT	Hits\tagSEC_CONTENT	at\tagSEC_CONTENT	mare\tagSEC_CONTENT	the\tagSEC_CONTENT	standard\tagSEC_CONTENT	evaluation\tagSEC_CONTENT	measures\tagSEC_CONTENT	for\tagSEC_CONTENT	these\tagSEC_CONTENT	datasets\tagSEC_CONTENT	and\tagSEC_CONTENT	come\tagSEC_CONTENT	in\tagSEC_CONTENT	two\tagSEC_CONTENT	flavours\tagSEC_CONTENT	:\tagSEC_CONTENT	raw\tagSEC_CONTENT	and\tagSEC_CONTENT	filtered\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	filtered\tagSEC_CONTENT	metrics\tagSEC_CONTENT	are\tagSEC_CONTENT	computed\tagSEC_CONTENT	after\tagSEC_CONTENT	removing\tagSEC_CONTENT	all\tagSEC_CONTENT	the\tagSEC_CONTENT	other\tagSEC_CONTENT	positive\tagSEC_CONTENT	observed\tagSEC_CONTENT	triples\tagSEC_CONTENT	that\tagSEC_CONTENT	appear\tagSEC_CONTENT	in\tagSEC_CONTENT	either\tagSEC_CONTENT	training\tagSEC_CONTENT	,\tagSEC_CONTENT	validation\tagSEC_CONTENT	or\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	the\tagSEC_CONTENT	raw\tagSEC_CONTENT	metrics\tagSEC_CONTENT	do\tagSEC_CONTENT	not\tagSEC_CONTENT	remove\tagSEC_CONTENT	these\tagSEC_CONTENT	.\tagSEC_END	Since\tagSEC_START	ranking\tagSEC_CONTENT	measures\tagSEC_CONTENT	are\tagSEC_CONTENT	used\tagSEC_CONTENT	,\tagSEC_CONTENT	previous\tagSEC_CONTENT	studies\tagSEC_CONTENT	generally\tagSEC_CONTENT	preferred\tagSEC_CONTENT	a\tagSEC_CONTENT	pairwise\tagSEC_CONTENT	ranking\tagSEC_CONTENT	loss\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	task\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	chose\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	the\tagSEC_CONTENT	negative\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	logistic\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	it\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	continuous\tagSEC_CONTENT	surrogate\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	sign\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	has\tagSEC_CONTENT	been\tagSEC_CONTENT	shown\tagSEC_CONTENT	to\tagSEC_CONTENT	learn\tagSEC_CONTENT	compact\tagSEC_CONTENT	representations\tagSEC_CONTENT	for\tagSEC_CONTENT	several\tagtask	important\tagtask	relations\tagtask	,\tagSEC_CONTENT	especially\tagSEC_CONTENT	for\tagSEC_CONTENT	transitive\tagSEC_CONTENT	relations\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	preliminary\tagSEC_CONTENT	work\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	tried\tagSEC_CONTENT	both\tagSEC_CONTENT	losses\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	indeed\tagSEC_CONTENT	the\tagSEC_CONTENT	loglikelihood\tagSEC_CONTENT	yielded\tagSEC_CONTENT	better\tagSEC_CONTENT	results\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	ranking\tagSEC_CONTENT	loss\tagSEC_CONTENT	(\tagSEC_CONTENT	except\tagSEC_CONTENT	with\tagSEC_CONTENT	TransE\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	especially\tagSEC_CONTENT	on\tagSEC_CONTENT	FB15K.\tagSEC_END	We\tagSEC_START	report\tagSEC_CONTENT	both\tagSEC_CONTENT	filtered\tagSEC_CONTENT	and\tagSEC_CONTENT	raw\tagSEC_CONTENT	MRR\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	filtered\tagSEC_CONTENT	Hits\tagSEC_CONTENT	at\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	3\tagSEC_CONTENT	and\tagSEC_CONTENT	10\tagSEC_CONTENT	in\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	Furthermore\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	chose\tagSEC_CONTENT	TransE\tagSEC_CONTENT	,\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	and\tagSEC_CONTENT	HolE\tagSEC_CONTENT	as\tagSEC_CONTENT	baselines\tagSEC_CONTENT	since\tagSEC_CONTENT	they\tagSEC_CONTENT	are\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	performing\tagSEC_CONTENT	models\tagSEC_CONTENT	on\tagSEC_CONTENT	those\tagSEC_CONTENT	datasets\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	knowledge\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	compare\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	CP\tagSEC_CONTENT	model\tagSEC_CONTENT	to\tagSEC_CONTENT	emphasize\tagSEC_CONTENT	empirically\tagSEC_CONTENT	the\tagSEC_CONTENT	importance\tagSEC_CONTENT	of\tagSEC_CONTENT	learning\tagSEC_CONTENT	unique\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	for\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	experimental\tagSEC_CONTENT	fairness\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	reimplemented\tagSEC_CONTENT	these\tagSEC_CONTENT	methods\tagSEC_CONTENT	within\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	framework\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	ComplEx\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	using\tagSEC_CONTENT	theano\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	time\tagSEC_CONTENT	constraints\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	complexity\tagSEC_CONTENT	of\tagSEC_CONTENT	an\tagSEC_CONTENT	efficient\tagSEC_CONTENT	implementation\tagSEC_CONTENT	of\tagSEC_CONTENT	HolE\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	record\tagSEC_CONTENT	the\tagSEC_CONTENT	original\tagSEC_CONTENT	results\tagSEC_CONTENT	for\tagSEC_CONTENT	HolE\tagSEC_CONTENT	as\tagSEC_CONTENT	reported\tagSEC_CONTENT	in\tagSEC_CONTENT	Nickel\tagSEC_CONTENT	et\tagSEC_CONTENT	al\tagSEC_CONTENT	.\tagSEC_CONTENT	(\tagSEC_CONTENT	2016b\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Results\tagSECTITLE_END	WN18\tagSEC_START	describes\tagSEC_CONTENT	lexical\tagSEC_CONTENT	and\tagSEC_CONTENT	semantic\tagSEC_CONTENT	hierarchies\tagSEC_CONTENT	between\tagSEC_CONTENT	concepts\tagSEC_CONTENT	and\tagSEC_CONTENT	contains\tagSEC_CONTENT	many\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	hypernymy\tagSEC_CONTENT	,\tagSEC_CONTENT	hyponymy\tagSEC_CONTENT	,\tagSEC_CONTENT	or\tagSEC_CONTENT	being\tagSEC_CONTENT	"\tagSEC_CONTENT	part\tagSEC_CONTENT	of\tagSEC_CONTENT	"\tagSEC_CONTENT	.\tagSEC_CONTENT	Indeed\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	and\tagSEC_CONTENT	TransE\tagSEC_CONTENT	models\tagSEC_CONTENT	are\tagSEC_CONTENT	outperformed\tagSEC_CONTENT	hereby\tagSEC_CONTENT	ComplEx\tagSEC_CONTENT	and\tagSEC_CONTENT	HolE\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	are\tagSEC_CONTENT	on\tagSEC_CONTENT	par\tagSEC_CONTENT	with\tagSEC_CONTENT	respective\tagSEC_CONTENT	filtered\tagSEC_CONTENT	MRR\tagSEC_CONTENT	scores\tagSEC_CONTENT	of\tagSEC_CONTENT	0.941\tagSEC_CONTENT	and\tagSEC_CONTENT	0.938\tagSEC_CONTENT	.\tagSEC_CONTENT	shows\tagSEC_CONTENT	the\tagSEC_CONTENT	filtered\tagSEC_CONTENT	test\tagSEC_CONTENT	set\tagSEC_CONTENT	MRR\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	models\tagSEC_CONTENT	considered\tagSEC_CONTENT	and\tagSEC_CONTENT	each\tagSEC_CONTENT	relation\tagSEC_CONTENT	of\tagSEC_CONTENT	WN18\tagSEC_CONTENT	,\tagSEC_CONTENT	confirming\tagSEC_CONTENT	the\tagSEC_CONTENT	advantage\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	on\tagSEC_CONTENT	antisymmetric\tagSEC_CONTENT	relations\tagSEC_CONTENT	while\tagSEC_CONTENT	losing\tagSEC_CONTENT	nothing\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	others\tagSEC_CONTENT	.\tagSEC_CONTENT	2D\tagSEC_CONTENT	projections\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	provided\tagSEC_CONTENT	in\tagSEC_CONTENT	Appendix\tagSEC_CONTENT	B\tagSEC_CONTENT	visually\tagSEC_CONTENT	corroborate\tagSEC_CONTENT	the\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_END	On\tagSEC_START	FB15\tagdataset	K\tagdataset	,\tagSEC_CONTENT	the\tagSEC_CONTENT	gap\tagSEC_CONTENT	is\tagSEC_CONTENT	much\tagSEC_CONTENT	more\tagSEC_CONTENT	pronounced\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	ComplEx\tagSEC_CONTENT	model\tagSEC_CONTENT	largely\tagSEC_CONTENT	outperforms\tagSEC_CONTENT	HolE\tagSEC_CONTENT	,\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	filtered\tagSEC_CONTENT	MRR\tagSEC_CONTENT	of\tagSEC_CONTENT	0.692\tagSEC_CONTENT	and\tagSEC_CONTENT	59.9\tagSEC_CONTENT	%\tagSEC_CONTENT	of\tagSEC_CONTENT	Hits\tagSEC_CONTENT	at\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	0.524\tagSEC_CONTENT	and\tagSEC_CONTENT	40.2\tagSEC_CONTENT	%\tagSEC_CONTENT	for\tagSEC_CONTENT	HolE.\tagSEC_CONTENT	We\tagSEC_CONTENT	attribute\tagSEC_CONTENT	this\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	simplicity\tagSEC_CONTENT	of\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	different\tagSEC_CONTENT	loss\tagSEC_CONTENT	function\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	is\tagSEC_CONTENT	supported\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	relatively\tagSEC_CONTENT	small\tagSEC_CONTENT	gap\tagSEC_CONTENT	in\tagSEC_CONTENT	MRR\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	(\tagSEC_CONTENT	0.654\tagSEC_CONTENT	)\tagSEC_CONTENT	;\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	can\tagSEC_CONTENT	in\tagSEC_CONTENT	fact\tagSEC_CONTENT	be\tagSEC_CONTENT	interpreted\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	complex\tagSEC_CONTENT	number\tagSEC_CONTENT	version\tagSEC_CONTENT	of\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	,\tagSEC_CONTENT	TransE\tagSEC_CONTENT	   \tagSEC_CONTENT	and\tagSEC_CONTENT	CP\tagSEC_CONTENT	are\tagSEC_CONTENT	largely\tagSEC_CONTENT	left\tagSEC_CONTENT	behind\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	illustrates\tagSEC_CONTENT	the\tagSEC_CONTENT	power\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	simple\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	first\tagSEC_CONTENT	case\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	the\tagSEC_CONTENT	importance\tagSEC_CONTENT	of\tagSEC_CONTENT	learning\tagSEC_CONTENT	unique\tagSEC_CONTENT	entity\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	second\tagSEC_CONTENT	.\tagSEC_CONTENT	CP\tagSEC_CONTENT	performs\tagSEC_CONTENT	poorly\tagSEC_CONTENT	on\tagSEC_CONTENT	WN18\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	small\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	which\tagSEC_CONTENT	magnifies\tagSEC_CONTENT	this\tagSEC_CONTENT	subject\tagSEC_CONTENT	/\tagSEC_CONTENT	object\tagSEC_CONTENT	difference\tagSEC_CONTENT	.\tagSEC_END	Reported\tagSEC_START	results\tagSEC_CONTENT	are\tagSEC_CONTENT	given\tagSEC_CONTENT	for\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	set\tagSEC_CONTENT	of\tagSEC_CONTENT	hyper\tagSEC_CONTENT	-\tagSEC_CONTENT	parameters\tagSEC_CONTENT	evaluated\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	for\tagSEC_CONTENT	each\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	after\tagSEC_CONTENT	grid\tagSEC_CONTENT	search\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	following\tagSEC_CONTENT	values\tagSEC_CONTENT	:\tagSEC_CONTENT	K\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	10\tagSEC_CONTENT	,\tagSEC_CONTENT	20\tagSEC_CONTENT	,\tagSEC_CONTENT	50\tagSEC_CONTENT	,\tagSEC_CONTENT	100\tagSEC_CONTENT	,\tagSEC_CONTENT	150\tagSEC_CONTENT	,\tagSEC_CONTENT	200\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	λ\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	0.1\tagSEC_CONTENT	,\tagSEC_CONTENT	0.03\tagSEC_CONTENT	,\tagSEC_CONTENT	0.01\tagSEC_CONTENT	,\tagSEC_CONTENT	0.003\tagSEC_CONTENT	,\tagSEC_CONTENT	0.001\tagSEC_CONTENT	,\tagSEC_CONTENT	0.0003\tagSEC_CONTENT	,\tagSEC_CONTENT	0.0\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	α\tagSEC_CONTENT	0\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	1.0\tagSEC_CONTENT	,\tagSEC_CONTENT	0.5\tagSEC_CONTENT	,\tagSEC_CONTENT	0.2\tagSEC_CONTENT	,\tagSEC_CONTENT	0.1\tagSEC_CONTENT	,\tagSEC_CONTENT	0.05\tagSEC_CONTENT	,\tagSEC_CONTENT	0.02\tagSEC_CONTENT	,\tagSEC_CONTENT	0.01\tagSEC_CONTENT	}\tagSEC_CONTENT	,\tagSEC_CONTENT	η\tagSEC_CONTENT	∈\tagSEC_CONTENT	{\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	10\tagSEC_CONTENT	}\tagSEC_CONTENT	with\tagSEC_CONTENT	λ\tagSEC_CONTENT	the\tagtask	L\tagtask	2\tagtask	regularization\tagtask	parameter\tagtask	,\tagSEC_CONTENT	α\tagSEC_CONTENT	0\tagSEC_CONTENT	the\tagSEC_CONTENT	initial\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	(\tagSEC_CONTENT	then\tagSEC_CONTENT	tuned\tagSEC_CONTENT	at\tagSEC_CONTENT	runtime\tagSEC_CONTENT	with\tagSEC_CONTENT	AdaGrad\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	η\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	negatives\tagSEC_CONTENT	generated\tagSEC_CONTENT	per\tagSEC_CONTENT	positive\tagSEC_CONTENT	training\tagSEC_CONTENT	triple\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	also\tagSEC_CONTENT	tried\tagSEC_CONTENT	varying\tagSEC_CONTENT	the\tagSEC_CONTENT	batch\tagSEC_CONTENT	size\tagSEC_CONTENT	but\tagSEC_CONTENT	this\tagSEC_CONTENT	had\tagSEC_CONTENT	no\tagSEC_CONTENT	impact\tagSEC_CONTENT	and\tagSEC_CONTENT	we\tagSEC_CONTENT	settled\tagSEC_CONTENT	with\tagSEC_CONTENT	100\tagSEC_CONTENT	batches\tagSEC_CONTENT	per\tagSEC_CONTENT	epoch\tagSEC_CONTENT	.\tagSEC_CONTENT	Best\tagSEC_CONTENT	ranks\tagSEC_CONTENT	were\tagSEC_CONTENT	generally\tagSEC_CONTENT	150\tagSEC_CONTENT	or\tagSEC_CONTENT	200\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	both\tagSEC_CONTENT	cases\tagSEC_CONTENT	scores\tagSEC_CONTENT	were\tagSEC_CONTENT	always\tagSEC_CONTENT	very\tagSEC_CONTENT	close\tagSEC_CONTENT	for\tagSEC_CONTENT	all\tagSEC_CONTENT	models\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	negative\tagSEC_CONTENT	samples\tagSEC_CONTENT	per\tagSEC_CONTENT	positive\tagSEC_CONTENT	sample\tagSEC_CONTENT	also\tagSEC_CONTENT	had\tagSEC_CONTENT	a\tagSEC_CONTENT	large\tagSEC_CONTENT	influence\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	filtered\tagSEC_CONTENT	MRR\tagSEC_CONTENT	on\tagSEC_CONTENT	FB15\tagSEC_CONTENT	K\tagSEC_CONTENT	(\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	+0.08\tagSEC_CONTENT	improvement\tagSEC_CONTENT	from\tagSEC_CONTENT	1\tagSEC_CONTENT	to\tagSEC_CONTENT	10\tagSEC_CONTENT	negatives\tagSEC_CONTENT	)\tagSEC_CONTENT	,\tagSEC_CONTENT	but\tagSEC_CONTENT	not\tagSEC_CONTENT	much\tagSEC_CONTENT	on\tagSEC_CONTENT	WN18\tagSEC_CONTENT	.\tagSEC_CONTENT	On\tagSEC_CONTENT	both\tagSEC_CONTENT	datasets\tagSEC_CONTENT	regularization\tagSEC_CONTENT	was\tagSEC_CONTENT	important\tagSEC_CONTENT	(\tagSEC_CONTENT	up\tagSEC_CONTENT	to\tagSEC_CONTENT	+0.05\tagSEC_CONTENT	on\tagSEC_CONTENT	filtered\tagSEC_CONTENT	MRR\tagSEC_CONTENT	between\tagSEC_CONTENT	λ\tagSEC_CONTENT	=\tagSEC_CONTENT	0\tagSEC_CONTENT	and\tagSEC_CONTENT	optimal\tagSEC_CONTENT	one\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	found\tagSEC_CONTENT	the\tagSEC_CONTENT	initial\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	to\tagSEC_CONTENT	be\tagSEC_CONTENT	very\tagSEC_CONTENT	important\tagSEC_CONTENT	on\tagSEC_CONTENT	FB15\tagSEC_CONTENT	K\tagSEC_CONTENT	,\tagSEC_CONTENT	while\tagSEC_CONTENT	not\tagSEC_CONTENT	so\tagSEC_CONTENT	much\tagSEC_CONTENT	on\tagSEC_CONTENT	WN18\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	think\tagSEC_CONTENT	this\tagSEC_CONTENT	may\tagSEC_CONTENT	also\tagSEC_CONTENT	explain\tagSEC_CONTENT	the\tagSEC_CONTENT	large\tagSEC_CONTENT	gap\tagSEC_CONTENT	of\tagSEC_CONTENT	improvement\tagSEC_CONTENT	our\tagSEC_CONTENT	model\tagSEC_CONTENT	provides\tagSEC_CONTENT	on\tagSEC_CONTENT	this\tagSEC_CONTENT	dataset\tagSEC_CONTENT	compared\tagSEC_CONTENT	to\tagSEC_CONTENT	previously\tagSEC_CONTENT	published\tagSEC_CONTENT	results\tagSEC_CONTENT	-as\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	results\tagSEC_CONTENT	are\tagSEC_CONTENT	also\tagSEC_CONTENT	better\tagSEC_CONTENT	than\tagSEC_CONTENT	those\tagSEC_CONTENT	previously\tagSEC_CONTENT	reported\tagSEC_CONTENT	-along\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	log\tagSEC_CONTENT	-\tagSEC_CONTENT	likelihood\tagSEC_CONTENT	objective\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	seems\tagSEC_CONTENT	that\tagSEC_CONTENT	in\tagSEC_CONTENT	general\tagSEC_CONTENT	AdaGrad\tagSEC_CONTENT	is\tagSEC_CONTENT	relatively\tagSEC_CONTENT	insensitive\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	initial\tagSEC_CONTENT	learning\tagSEC_CONTENT	rate\tagSEC_CONTENT	,\tagSEC_CONTENT	perhaps\tagSEC_CONTENT	causing\tagSEC_CONTENT	some\tagSEC_CONTENT	overconfidence\tagSEC_CONTENT	in\tagSEC_CONTENT	its\tagSEC_CONTENT	ability\tagSEC_CONTENT	to\tagSEC_CONTENT	tune\tagSEC_CONTENT	the\tagSEC_CONTENT	step\tagSEC_CONTENT	size\tagSEC_CONTENT	online\tagSEC_CONTENT	and\tagSEC_CONTENT	consequently\tagSEC_CONTENT	leading\tagSEC_CONTENT	to\tagSEC_CONTENT	less\tagSEC_CONTENT	efforts\tagSEC_CONTENT	when\tagSEC_CONTENT	selecting\tagSEC_CONTENT	the\tagSEC_CONTENT	initial\tagSEC_CONTENT	step\tagSEC_CONTENT	size\tagSEC_CONTENT	.\tagSEC_END	Training\tagSEC_START	was\tagSEC_CONTENT	stopped\tagSEC_CONTENT	using\tagSEC_CONTENT	early\tagSEC_CONTENT	stopping\tagSEC_CONTENT	on\tagSEC_CONTENT	the\tagSEC_CONTENT	validation\tagSEC_CONTENT	set\tagSEC_CONTENT	filtered\tagSEC_CONTENT	MRR\tagSEC_CONTENT	,\tagSEC_CONTENT	computed\tagSEC_CONTENT	every\tagSEC_CONTENT	50\tagSEC_CONTENT	epochs\tagSEC_CONTENT	with\tagSEC_CONTENT	a\tagSEC_CONTENT	maximum\tagSEC_CONTENT	of\tagSEC_CONTENT	1000\tagSEC_CONTENT	epochs\tagSEC_CONTENT	.\tagSEC_END	Influence\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Negative\tagSECTITLE_CONTENT	Samples\tagSECTITLE_END	We\tagSEC_START	further\tagSEC_CONTENT	investigated\tagSEC_CONTENT	the\tagSEC_CONTENT	influence\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	negatives\tagSEC_CONTENT	generated\tagSEC_CONTENT	per\tagSEC_CONTENT	positive\tagSEC_CONTENT	training\tagSEC_CONTENT	sample\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	experiment\tagSEC_CONTENT	,\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	computational\tagSEC_CONTENT	limitations\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	negatives\tagSEC_CONTENT	per\tagSEC_CONTENT	training\tagSEC_CONTENT	sample\tagSEC_CONTENT	,\tagSEC_CONTENT	η\tagSEC_CONTENT	,\tagSEC_CONTENT	was\tagSEC_CONTENT	validated\tagSEC_CONTENT	among\tagSEC_CONTENT	the\tagSEC_CONTENT	possible\tagSEC_CONTENT	numbers\tagSEC_CONTENT	{\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	10\tagSEC_CONTENT	}\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	want\tagSEC_CONTENT	to\tagSEC_CONTENT	explore\tagSEC_CONTENT	here\tagSEC_CONTENT	whether\tagSEC_CONTENT	increasing\tagSEC_CONTENT	these\tagSEC_CONTENT	numbers\tagSEC_CONTENT	could\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	better\tagSEC_CONTENT	results\tagSEC_CONTENT	.\tagSEC_CONTENT	To\tagSEC_CONTENT	do\tagSEC_CONTENT	so\tagSEC_CONTENT	,\tagSEC_CONTENT	we\tagSEC_CONTENT	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	FB15\tagdataset	K\tagdataset	,\tagSEC_CONTENT	with\tagSEC_CONTENT	the\tagSEC_CONTENT	best\tagSEC_CONTENT	validated\tagSEC_CONTENT	λ\tagSEC_CONTENT	,\tagSEC_CONTENT	K\tagSEC_CONTENT	,\tagSEC_CONTENT	α\tagSEC_CONTENT	0\tagSEC_CONTENT	,\tagSEC_CONTENT	obtained\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	previous\tagSEC_CONTENT	experiment\tagSEC_CONTENT	.\tagSEC_CONTENT	We\tagSEC_CONTENT	then\tagSEC_CONTENT	let\tagSEC_CONTENT	η\tagSEC_CONTENT	vary\tagSEC_CONTENT	in\tagSEC_CONTENT	{\tagSEC_CONTENT	1\tagSEC_CONTENT	,\tagSEC_CONTENT	2\tagSEC_CONTENT	,\tagSEC_CONTENT	5\tagSEC_CONTENT	,\tagSEC_CONTENT	10\tagSEC_CONTENT	,\tagSEC_CONTENT	20\tagSEC_CONTENT	,\tagSEC_CONTENT	50\tagSEC_CONTENT	,\tagSEC_CONTENT	100\tagSEC_CONTENT	,\tagSEC_CONTENT	200\tagSEC_CONTENT	}\tagSEC_CONTENT	.\tagSEC_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSEC_START	the\tagSEC_CONTENT	early\tagSEC_CONTENT	age\tagSEC_CONTENT	of\tagSEC_CONTENT	spectral\tagSEC_CONTENT	theory\tagSEC_CONTENT	in\tagSEC_CONTENT	linear\tagSEC_CONTENT	algebra\tagSEC_CONTENT	,\tagSEC_CONTENT	complex\tagSEC_CONTENT	numbers\tagSEC_CONTENT	were\tagSEC_CONTENT	not\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	matrix\tagtask	factorization\tagtask	and\tagSEC_CONTENT	mathematicians\tagSEC_CONTENT	mostly\tagSEC_CONTENT	focused\tagSEC_CONTENT	on\tagSEC_CONTENT	bi\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	forms\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	eigen\tagSEC_CONTENT	-\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	domain\tagSEC_CONTENT	as\tagSEC_CONTENT	taught\tagSEC_CONTENT	today\tagSEC_CONTENT	in\tagSEC_CONTENT	linear\tagSEC_CONTENT	algebra\tagSEC_CONTENT	courses\tagSEC_CONTENT	came\tagSEC_CONTENT	40\tagSEC_CONTENT	years\tagSEC_CONTENT	later\tagSEC_CONTENT	.\tagSEC_CONTENT	Similarly\tagSEC_CONTENT	,\tagSEC_CONTENT	most\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	existing\tagSEC_CONTENT	approaches\tagSEC_CONTENT	for\tagSEC_CONTENT	tensor\tagSEC_CONTENT	factorization\tagSEC_CONTENT	were\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	decompositions\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	domain\tagSEC_CONTENT	,\tagSEC_CONTENT	such\tagSEC_CONTENT	as\tagSEC_CONTENT	the\tagSEC_CONTENT	Canonical\tagSEC_CONTENT	Polyadic\tagSEC_CONTENT	(\tagSEC_CONTENT	CP\tagSEC_CONTENT	)\tagSEC_CONTENT	decomposition\tagSEC_CONTENT	.\tagSEC_CONTENT	These\tagSEC_CONTENT	methods\tagSEC_CONTENT	are\tagSEC_CONTENT	very\tagSEC_CONTENT	effective\tagSEC_CONTENT	in\tagSEC_CONTENT	many\tagSEC_CONTENT	applications\tagSEC_CONTENT	that\tagSEC_CONTENT	use\tagSEC_CONTENT	different\tagSEC_CONTENT	modes\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	tensor\tagSEC_CONTENT	for\tagSEC_CONTENT	different\tagSEC_CONTENT	types\tagSEC_CONTENT	of\tagSEC_CONTENT	entities\tagSEC_CONTENT	.\tagSEC_CONTENT	But\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	link\tagSEC_CONTENT	prediction\tagSEC_CONTENT	problem\tagSEC_CONTENT	,\tagSEC_CONTENT	antisymmetry\tagSEC_CONTENT	of\tagSEC_CONTENT	relations\tagSEC_CONTENT	was\tagSEC_CONTENT	quickly\tagSEC_CONTENT	seen\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	problem\tagSEC_CONTENT	and\tagSEC_CONTENT	asymmetric\tagSEC_CONTENT	extensions\tagSEC_CONTENT	of\tagSEC_CONTENT	tensors\tagSEC_CONTENT	were\tagSEC_CONTENT	studied\tagSEC_CONTENT	,\tagSEC_CONTENT	mostly\tagSEC_CONTENT	by\tagSEC_CONTENT	either\tagSEC_CONTENT	considering\tagSEC_CONTENT	independent\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	or\tagSEC_CONTENT	considering\tagSEC_CONTENT	relations\tagSEC_CONTENT	as\tagSEC_CONTENT	matrices\tagSEC_CONTENT	instead\tagSEC_CONTENT	of\tagSEC_CONTENT	vectors\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	RESCAL\tagSEC_CONTENT	model\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	Direct\tagSEC_CONTENT	extensions\tagSEC_CONTENT	were\tagSEC_CONTENT	based\tagSEC_CONTENT	on\tagSEC_CONTENT	uni-,bi\tagSEC_CONTENT	-\tagSEC_CONTENT	and\tagSEC_CONTENT	trigram\tagSEC_CONTENT	latent\tagSEC_CONTENT	factors\tagSEC_CONTENT	for\tagSEC_CONTENT	triple\tagSEC_CONTENT	data\tagSEC_CONTENT	,\tagSEC_CONTENT	as\tagSEC_CONTENT	well\tagSEC_CONTENT	as\tagSEC_CONTENT	a\tagSEC_CONTENT	low\tagSEC_CONTENT	-\tagSEC_CONTENT	rank\tagSEC_CONTENT	relation\tagSEC_CONTENT	matrix\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Pairwise\tagSEC_START	interaction\tagSEC_CONTENT	models\tagSEC_CONTENT	were\tagSEC_CONTENT	also\tagSEC_CONTENT	considered\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	prediction\tagtask	performances\tagtask	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	Universal\tagSEC_CONTENT	Schema\tagSEC_CONTENT	approach\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	factorizes\tagSEC_CONTENT	a\tagSEC_CONTENT	2D\tagSEC_CONTENT	unfolding\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	tensor\tagSEC_CONTENT	(\tagSEC_CONTENT	a\tagSEC_CONTENT	matrix\tagSEC_CONTENT	of\tagSEC_CONTENT	entity\tagSEC_CONTENT	pairs\tagSEC_CONTENT	vs.\tagSEC_CONTENT	relations\tagSEC_CONTENT	)\tagSEC_CONTENT	while\tagSEC_CONTENT	extend\tagSEC_CONTENT	this\tagSEC_CONTENT	also\tagSEC_CONTENT	to\tagSEC_CONTENT	other\tagSEC_CONTENT	pairs\tagSEC_CONTENT	.\tagSEC_END	In\tagSEC_START	the\tagSEC_CONTENT	Neural\tagSEC_CONTENT	Tensor\tagSEC_CONTENT	Network\tagSEC_CONTENT	(\tagSEC_CONTENT	NTN\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	,\tagSEC_CONTENT	combine\tagSEC_CONTENT	linear\tagSEC_CONTENT	transformations\tagSEC_CONTENT	and\tagSEC_CONTENT	multiple\tagSEC_CONTENT	bilinear\tagSEC_CONTENT	forms\tagSEC_CONTENT	of\tagSEC_CONTENT	subject\tagSEC_CONTENT	and\tagSEC_CONTENT	object\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	to\tagSEC_CONTENT	jointly\tagSEC_CONTENT	feed\tagSEC_CONTENT	them\tagSEC_CONTENT	into\tagSEC_CONTENT	a\tagSEC_CONTENT	nonlinear\tagSEC_CONTENT	neural\tagSEC_CONTENT	layer\tagSEC_CONTENT	.\tagSEC_CONTENT	Its\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	linearity\tagSEC_CONTENT	and\tagSEC_CONTENT	multiple\tagSEC_CONTENT	ways\tagSEC_CONTENT	of\tagSEC_CONTENT	including\tagSEC_CONTENT	interactions\tagtask	between\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	gives\tagSEC_CONTENT	it\tagSEC_CONTENT	an\tagSEC_CONTENT	advantage\tagSEC_CONTENT	in\tagSEC_CONTENT	expressiveness\tagSEC_CONTENT	over\tagSEC_CONTENT	models\tagSEC_CONTENT	with\tagSEC_CONTENT	simpler\tagSEC_CONTENT	scoring\tagSEC_CONTENT	function\tagSEC_CONTENT	like\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	or\tagSEC_CONTENT	RESCAL\tagSEC_CONTENT	.\tagSEC_CONTENT	As\tagSEC_CONTENT	a\tagSEC_CONTENT	downside\tagSEC_CONTENT	,\tagSEC_CONTENT	its\tagSEC_CONTENT	very\tagSEC_CONTENT	large\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	parameters\tagSEC_CONTENT	can\tagSEC_CONTENT	make\tagSEC_CONTENT	the\tagSEC_CONTENT	NTN\tagSEC_CONTENT	model\tagSEC_CONTENT	harder\tagSEC_CONTENT	to\tagSEC_CONTENT	train\tagSEC_CONTENT	and\tagSEC_CONTENT	overfit\tagSEC_CONTENT	more\tagSEC_CONTENT	easily\tagSEC_CONTENT	.\tagSEC_END	The\tagSEC_START	original\tagSEC_CONTENT	multi\tagSEC_CONTENT	-\tagSEC_CONTENT	linear\tagSEC_CONTENT	DistMult\tagSEC_CONTENT	model\tagSEC_CONTENT	is\tagSEC_CONTENT	symmetric\tagSEC_CONTENT	in\tagSEC_CONTENT	subject\tagSEC_CONTENT	and\tagSEC_CONTENT	object\tagSEC_CONTENT	for\tagSEC_CONTENT	every\tagSEC_CONTENT	relation\tagSEC_CONTENT	and\tagSEC_CONTENT	achieves\tagSEC_CONTENT	good\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	presumably\tagSEC_CONTENT	due\tagSEC_CONTENT	to\tagSEC_CONTENT	its\tagSEC_CONTENT	simplicity\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	TransE\tagSEC_CONTENT	model\tagSEC_CONTENT	from\tagSEC_CONTENT	also\tagSEC_CONTENT	embeds\tagSEC_CONTENT	entities\tagSEC_CONTENT	and\tagSEC_CONTENT	relations\tagtask	in\tagSEC_CONTENT	the\tagSEC_CONTENT	same\tagSEC_CONTENT	space\tagSEC_CONTENT	and\tagSEC_CONTENT	imposes\tagSEC_CONTENT	a\tagSEC_CONTENT	geometrical\tagSEC_CONTENT	structural\tagSEC_CONTENT	bias\tagSEC_CONTENT	into\tagSEC_CONTENT	the\tagSEC_CONTENT	model\tagSEC_CONTENT	:\tagSEC_CONTENT	the\tagSEC_CONTENT	subject\tagSEC_CONTENT	entity\tagSEC_CONTENT	vector\tagSEC_CONTENT	should\tagSEC_CONTENT	be\tagSEC_CONTENT	close\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	object\tagSEC_CONTENT	entity\tagSEC_CONTENT	vector\tagSEC_CONTENT	once\tagSEC_CONTENT	translated\tagSEC_CONTENT	by\tagSEC_CONTENT	the\tagSEC_CONTENT	relation\tagSEC_CONTENT	vector\tagSEC_CONTENT	.\tagSEC_END	A\tagSEC_START	recent\tagSEC_CONTENT	novel\tagSEC_CONTENT	way\tagSEC_CONTENT	to\tagSEC_CONTENT	handle\tagSEC_CONTENT	antisymmetry\tagSEC_CONTENT	is\tagSEC_CONTENT	via\tagSEC_CONTENT	the\tagSEC_CONTENT	Holographic\tagSEC_CONTENT	Embeddings\tagSEC_CONTENT	(\tagSEC_CONTENT	HolE\tagSEC_CONTENT	)\tagSEC_CONTENT	model\tagSEC_CONTENT	by\tagSEC_CONTENT	(\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_CONTENT	In\tagSEC_CONTENT	HolE\tagSEC_CONTENT	the\tagSEC_CONTENT	circular\tagSEC_CONTENT	correlation\tagSEC_CONTENT	is\tagSEC_CONTENT	used\tagSEC_CONTENT	for\tagSEC_CONTENT	combining\tagSEC_CONTENT	entity\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	,\tagSEC_CONTENT	measuring\tagSEC_CONTENT	the\tagSEC_CONTENT	covariance\tagSEC_CONTENT	between\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	at\tagSEC_CONTENT	different\tagSEC_CONTENT	dimension\tagSEC_CONTENT	shifts\tagSEC_CONTENT	.\tagSEC_CONTENT	This\tagSEC_CONTENT	generally\tagSEC_CONTENT	suggests\tagSEC_CONTENT	that\tagSEC_CONTENT	other\tagSEC_CONTENT	composition\tagSEC_CONTENT	functions\tagSEC_CONTENT	than\tagSEC_CONTENT	the\tagSEC_CONTENT	classical\tagSEC_CONTENT	tensor\tagSEC_CONTENT	product\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	helpful\tagSEC_CONTENT	as\tagSEC_CONTENT	they\tagSEC_CONTENT	allow\tagSEC_CONTENT	fora\tagtask	richer\tagtask	interaction\tagtask	of\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	.\tagSEC_CONTENT	However\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	asymmetry\tagSEC_CONTENT	in\tagSEC_CONTENT	the\tagSEC_CONTENT	composition\tagSEC_CONTENT	function\tagSEC_CONTENT	in\tagSEC_CONTENT	HolE\tagSEC_CONTENT	stems\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	asymmetry\tagSEC_CONTENT	of\tagSEC_CONTENT	circular\tagSEC_CONTENT	correlation\tagSEC_CONTENT	,\tagSEC_CONTENT	an\tagSEC_CONTENT	O(nlog(n\tagSEC_CONTENT	)\tagSEC_CONTENT	)\tagSEC_CONTENT	operation\tagSEC_CONTENT	,\tagSEC_CONTENT	whereas\tagSEC_CONTENT	ours\tagSEC_CONTENT	is\tagSEC_CONTENT	inherited\tagSEC_CONTENT	from\tagSEC_CONTENT	the\tagSEC_CONTENT	complex\tagSEC_CONTENT	inner\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	in\tagSEC_CONTENT	O(n\tagSEC_CONTENT	)\tagSEC_CONTENT	.\tagSEC_END	Conclusion\tagSECTITLE_END	We\tagSEC_START	described\tagSEC_CONTENT	a\tagSEC_CONTENT	simple\tagSEC_CONTENT	approach\tagSEC_CONTENT	to\tagSEC_CONTENT	matrix\tagSEC_CONTENT	and\tagSEC_CONTENT	tensor\tagSEC_CONTENT	factorization\tagSEC_CONTENT	for\tagSEC_CONTENT	link\tagtask	prediction\tagtask	data\tagtask	that\tagSEC_CONTENT	uses\tagSEC_CONTENT	vectors\tagSEC_CONTENT	with\tagSEC_CONTENT	complex\tagSEC_CONTENT	values\tagSEC_CONTENT	and\tagSEC_CONTENT	retains\tagSEC_CONTENT	the\tagSEC_CONTENT	mathematical\tagSEC_CONTENT	definition\tagSEC_CONTENT	of\tagSEC_CONTENT	the\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	.\tagSEC_CONTENT	The\tagSEC_CONTENT	class\tagSEC_CONTENT	of\tagSEC_CONTENT	normal\tagSEC_CONTENT	matrices\tagSEC_CONTENT	is\tagSEC_CONTENT	a\tagSEC_CONTENT	natural\tagSEC_CONTENT	fit\tagSEC_CONTENT	for\tagSEC_CONTENT	binary\tagSEC_CONTENT	relations\tagSEC_CONTENT	,\tagSEC_CONTENT	and\tagSEC_CONTENT	using\tagSEC_CONTENT	the\tagSEC_CONTENT	real\tagSEC_CONTENT	part\tagSEC_CONTENT	allows\tagSEC_CONTENT	for\tagSEC_CONTENT	efficient\tagSEC_CONTENT	approximation\tagSEC_CONTENT	of\tagSEC_CONTENT	any\tagSEC_CONTENT	learnable\tagSEC_CONTENT	relation\tagSEC_CONTENT	.\tagSEC_CONTENT	Results\tagSEC_CONTENT	on\tagSEC_CONTENT	standard\tagSEC_CONTENT	benchmarks\tagSEC_CONTENT	show\tagSEC_CONTENT	that\tagSEC_CONTENT	no\tagSEC_CONTENT	more\tagSEC_CONTENT	modifications\tagSEC_CONTENT	are\tagSEC_CONTENT	needed\tagSEC_CONTENT	to\tagSEC_CONTENT	improve\tagSEC_CONTENT	over\tagSEC_CONTENT	the\tagSEC_CONTENT	state\tagSEC_CONTENT	-\tagSEC_CONTENT	of\tagSEC_CONTENT	-\tagSEC_CONTENT	the\tagSEC_CONTENT	-\tagSEC_CONTENT	art\tagSEC_CONTENT	.\tagSEC_END	There\tagSEC_START	are\tagSEC_CONTENT	several\tagtask	directions\tagtask	in\tagSEC_CONTENT	which\tagSEC_CONTENT	this\tagSEC_CONTENT	work\tagSEC_CONTENT	can\tagSEC_CONTENT	be\tagSEC_CONTENT	extended\tagSEC_CONTENT	.\tagSEC_CONTENT	An\tagSEC_CONTENT	obvious\tagSEC_CONTENT	one\tagSEC_CONTENT	is\tagSEC_CONTENT	to\tagSEC_CONTENT	merge\tagSEC_CONTENT	our\tagSEC_CONTENT	approach\tagSEC_CONTENT	with\tagSEC_CONTENT	known\tagSEC_CONTENT	extensions\tagSEC_CONTENT	to\tagSEC_CONTENT	tensor\tagSEC_CONTENT	factorization\tagSEC_CONTENT	in\tagSEC_CONTENT	order\tagSEC_CONTENT	to\tagSEC_CONTENT	further\tagSEC_CONTENT	improve\tagSEC_CONTENT	predictive\tagSEC_CONTENT	performance\tagSEC_CONTENT	.\tagSEC_CONTENT	For\tagSEC_CONTENT	example\tagSEC_CONTENT	,\tagSEC_CONTENT	the\tagSEC_CONTENT	use\tagSEC_CONTENT	of\tagSEC_CONTENT	pairwise\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	together\tagSEC_CONTENT	with\tagSEC_CONTENT	complex\tagSEC_CONTENT	numbers\tagSEC_CONTENT	might\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	improved\tagSEC_CONTENT	results\tagSEC_CONTENT	in\tagSEC_CONTENT	many\tagSEC_CONTENT	situations\tagSEC_CONTENT	that\tagSEC_CONTENT	involve\tagSEC_CONTENT	non\tagSEC_CONTENT	-\tagSEC_CONTENT	compositionality\tagSEC_CONTENT	.\tagSEC_CONTENT	Another\tagSEC_CONTENT	direction\tagSEC_CONTENT	would\tagSEC_CONTENT	be\tagSEC_CONTENT	to\tagSEC_CONTENT	develop\tagSEC_CONTENT	a\tagSEC_CONTENT	more\tagSEC_CONTENT	intelligent\tagSEC_CONTENT	negative\tagSEC_CONTENT	sampling\tagSEC_CONTENT	procedure\tagSEC_CONTENT	,\tagSEC_CONTENT	to\tagSEC_CONTENT	generate\tagSEC_CONTENT	more\tagSEC_CONTENT	informative\tagSEC_CONTENT	negatives\tagSEC_CONTENT	with\tagSEC_CONTENT	respect\tagSEC_CONTENT	to\tagSEC_CONTENT	the\tagSEC_CONTENT	positive\tagSEC_CONTENT	sample\tagSEC_CONTENT	from\tagSEC_CONTENT	which\tagSEC_CONTENT	they\tagSEC_CONTENT	have\tagSEC_CONTENT	been\tagSEC_CONTENT	sampled\tagSEC_CONTENT	.\tagSEC_CONTENT	It\tagSEC_CONTENT	would\tagSEC_CONTENT	reduce\tagSEC_CONTENT	the\tagSEC_CONTENT	number\tagSEC_CONTENT	of\tagSEC_CONTENT	negatives\tagSEC_CONTENT	required\tagSEC_CONTENT	to\tagSEC_CONTENT	reach\tagSEC_CONTENT	good\tagSEC_CONTENT	performance\tagSEC_CONTENT	,\tagSEC_CONTENT	thus\tagSEC_CONTENT	accelerating\tagSEC_CONTENT	training\tagSEC_CONTENT	time\tagSEC_CONTENT	.\tagSEC_END	Also\tagSEC_START	,\tagSEC_CONTENT	if\tagSEC_CONTENT	we\tagSEC_CONTENT	were\tagSEC_CONTENT	to\tagSEC_CONTENT	use\tagSEC_CONTENT	complex\tagSEC_CONTENT	embeddings\tagSEC_CONTENT	every\tagSEC_CONTENT	time\tagSEC_CONTENT	a\tagSEC_CONTENT	model\tagSEC_CONTENT	includes\tagSEC_CONTENT	a\tagSEC_CONTENT	dot\tagSEC_CONTENT	product\tagSEC_CONTENT	,\tagSEC_CONTENT	e.g.\tagSEC_CONTENT	in\tagSEC_CONTENT	deep\tagSEC_CONTENT	neural\tagSEC_CONTENT	networks\tagSEC_CONTENT	,\tagSEC_CONTENT	would\tagSEC_CONTENT	it\tagSEC_CONTENT	lead\tagSEC_CONTENT	to\tagSEC_CONTENT	a\tagSEC_CONTENT	similar\tagSEC_CONTENT	systematic\tagSEC_CONTENT	improvement\tagSEC_CONTENT	?\tagSEC_END	
