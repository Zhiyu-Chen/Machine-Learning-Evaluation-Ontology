title	SECTITLE_END
Semi	SEC_START
-	SEC_CONTENT
Supervised	SEC_CONTENT
Sequence	SEC_CONTENT
Modeling	SEC_CONTENT
with	SEC_CONTENT
Cross	task
-	task
View	task
Training	SEC_END
abstract	SECTITLE_END
Unsupervised	SEC_START
representation	SEC_CONTENT
learning	SEC_CONTENT
algorithms	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word2vec	SEC_CONTENT
and	SEC_CONTENT
ELMo	SEC_CONTENT
improve	SEC_CONTENT
the	metric
accuracy	metric
of	SEC_CONTENT
many	SEC_CONTENT
supervised	SEC_CONTENT
NLP	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
mainly	SEC_CONTENT
because	SEC_CONTENT
they	SEC_CONTENT
can	SEC_CONTENT
take	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
large	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
text	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
supervised	SEC_CONTENT
models	SEC_CONTENT
only	SEC_CONTENT
learn	SEC_CONTENT
from	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
during	SEC_CONTENT
the	task
main	task
training	task
phase	task
.	SEC_CONTENT
We	SEC_CONTENT
therefore	SEC_CONTENT
propose	SEC_CONTENT
Cross	task
-	task
View	task
Training	task
(	SEC_CONTENT
CVT	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
algorithm	SEC_CONTENT
that	SEC_CONTENT
improves	SEC_CONTENT
the	task
representations	task
of	SEC_CONTENT
a	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
mix	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
and	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
standard	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
CVT	SEC_CONTENT
teaches	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
that	SEC_CONTENT
see	SEC_CONTENT
restricted	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
only	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
match	SEC_CONTENT
the	SEC_CONTENT
predictions	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
seeing	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
modules	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
share	SEC_CONTENT
intermediate	task
representations	task
,	SEC_CONTENT
this	SEC_CONTENT
in	SEC_CONTENT
turn	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
CVT	SEC_CONTENT
is	SEC_CONTENT
particularly	SEC_CONTENT
effective	SEC_CONTENT
when	SEC_CONTENT
combined	SEC_CONTENT
with	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
evaluate	SEC_CONTENT
CVT	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
sequence	SEC_CONTENT
tagging	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
achieving	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
1	SEC_END
Introduction	SECTITLE_END
Deep	SEC_START
learning	SEC_CONTENT
models	SEC_CONTENT
work	SEC_CONTENT
best	SEC_CONTENT
when	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
large	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
acquiring	SEC_CONTENT
labels	metric
is	SEC_CONTENT
costly	SEC_CONTENT
,	SEC_CONTENT
motivating	SEC_CONTENT
the	SEC_CONTENT
need	SEC_CONTENT
for	SEC_CONTENT
effective	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
techniques	SEC_CONTENT
that	SEC_CONTENT
leverage	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
widely	SEC_CONTENT
successful	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
strategy	SEC_CONTENT
for	SEC_CONTENT
neural	SEC_CONTENT
NLP	SEC_CONTENT
is	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
word	SEC_CONTENT
vectors	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
recent	SEC_CONTENT
work	SEC_CONTENT
trains	SEC_CONTENT
a	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
to	SEC_CONTENT
do	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
incorporates	SEC_CONTENT
its	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
sensitive	SEC_CONTENT
representations	SEC_CONTENT
into	SEC_CONTENT
supervised	SEC_CONTENT
models	SEC_CONTENT
Code	SEC_CONTENT
is	SEC_CONTENT
available	SEC_CONTENT
at	SEC_CONTENT
https://github.com/	SEC_CONTENT
tensorflow	SEC_CONTENT
/	SEC_CONTENT
models	SEC_CONTENT
/	SEC_CONTENT
tree	SEC_CONTENT
/	SEC_CONTENT
master	SEC_CONTENT
/	SEC_CONTENT
research/	SEC_CONTENT
cvt_text	SEC_CONTENT
2018	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Such	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
methods	SEC_CONTENT
perform	SEC_CONTENT
unsupervised	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
corpus	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
followed	SEC_CONTENT
by	SEC_CONTENT
supervised	task
training	task
.	SEC_END
A	SEC_START
key	SEC_CONTENT
disadvantage	SEC_CONTENT
of	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
phase	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
take	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
-the	SEC_CONTENT
model	SEC_CONTENT
attempts	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
generally	SEC_CONTENT
effective	SEC_CONTENT
representations	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
ones	metric
that	SEC_CONTENT
are	SEC_CONTENT
targeted	SEC_CONTENT
towards	SEC_CONTENT
a	SEC_CONTENT
particular	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Older	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
algorithms	SEC_CONTENT
like	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
suffer	SEC_CONTENT
from	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
because	SEC_CONTENT
they	SEC_CONTENT
continually	SEC_CONTENT
learn	SEC_CONTENT
about	SEC_CONTENT
a	SEC_CONTENT
task	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
mix	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
and	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Selftraining	SEC_CONTENT
has	SEC_CONTENT
historically	SEC_CONTENT
been	SEC_CONTENT
effective	SEC_CONTENT
for	SEC_CONTENT
NLP	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
is	SEC_CONTENT
less	SEC_CONTENT
commonly	SEC_CONTENT
used	SEC_CONTENT
with	SEC_CONTENT
neural	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
paper	SEC_CONTENT
presents	SEC_CONTENT
Cross	task
-	task
View	task
Training	task
(	SEC_CONTENT
CVT	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
anew	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
algorithm	SEC_CONTENT
that	SEC_CONTENT
works	SEC_CONTENT
well	SEC_CONTENT
for	SEC_CONTENT
neural	SEC_CONTENT
sequence	SEC_CONTENT
models	SEC_CONTENT
.	SEC_END
In	SEC_START
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
learns	SEC_CONTENT
as	SEC_CONTENT
normal	SEC_CONTENT
on	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
acts	SEC_CONTENT
as	SEC_CONTENT
both	SEC_CONTENT
a	SEC_CONTENT
teacher	SEC_CONTENT
that	SEC_CONTENT
makes	SEC_CONTENT
predictions	SEC_CONTENT
about	SEC_CONTENT
the	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
student	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
those	SEC_CONTENT
predictions	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
this	SEC_CONTENT
process	SEC_CONTENT
has	SEC_CONTENT
shown	SEC_CONTENT
value	SEC_CONTENT
for	SEC_CONTENT
some	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
somewhat	SEC_CONTENT
tautological	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
already	SEC_CONTENT
produces	SEC_CONTENT
the	SEC_CONTENT
predictions	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
being	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
.	SEC_CONTENT
Recent	SEC_CONTENT
research	SEC_CONTENT
on	SEC_CONTENT
computer	SEC_CONTENT
vision	SEC_CONTENT
addresses	SEC_CONTENT
this	SEC_CONTENT
by	SEC_CONTENT
adding	SEC_CONTENT
noise	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
's	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
robust	SEC_CONTENT
to	SEC_CONTENT
input	SEC_CONTENT
perturbations	dataset
(	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
applying	SEC_CONTENT
noise	SEC_CONTENT
is	SEC_CONTENT
difficult	SEC_CONTENT
for	SEC_CONTENT
discrete	SEC_CONTENT
inputs	SEC_CONTENT
like	SEC_CONTENT
text	SEC_CONTENT
.	SEC_END
As	SEC_START
a	task
solution	task
,	SEC_CONTENT
we	SEC_CONTENT
take	SEC_CONTENT
inspiration	task
from	SEC_CONTENT
multiview	SEC_CONTENT
learning	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
consistent	task
predictions	task
across	SEC_CONTENT
different	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
of	SEC_CONTENT
only	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
student	SEC_CONTENT
,	SEC_CONTENT
CVT	SEC_CONTENT
adds	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
-neural	SEC_CONTENT
networks	SEC_CONTENT
that	SEC_CONTENT
transform	SEC_CONTENT
vector	SEC_CONTENT
representations	SEC_CONTENT
into	SEC_CONTENT
predictions	SEC_CONTENT
-to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
also	SEC_CONTENT
trains	SEC_CONTENT
them	SEC_CONTENT
as	SEC_CONTENT
students	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
student	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
intermediate	SEC_CONTENT
rep	SEC_CONTENT
-	SEC_CONTENT
resentations	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
restricted	SEC_CONTENT
view	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
example	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
tagging	SEC_CONTENT
is	SEC_CONTENT
attached	SEC_CONTENT
to	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
forward	SEC_CONTENT
"	SEC_CONTENT
LSTM	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
first	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
makes	SEC_CONTENT
predictions	SEC_CONTENT
without	SEC_CONTENT
seeing	SEC_CONTENT
any	SEC_CONTENT
tokens	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
one	SEC_CONTENT
.	SEC_END
CVT	SEC_START
works	SEC_CONTENT
by	SEC_CONTENT
improving	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
can	SEC_CONTENT
learn	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
predictions	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
better	SEC_CONTENT
,	SEC_CONTENT
unrestricted	SEC_CONTENT
view	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
modules	SEC_CONTENT
learn	SEC_CONTENT
to	SEC_CONTENT
make	SEC_CONTENT
accurate	SEC_CONTENT
predictions	SEC_CONTENT
despite	SEC_CONTENT
their	SEC_CONTENT
restricted	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
quality	SEC_CONTENT
of	SEC_CONTENT
the	task
representations	task
they	SEC_CONTENT
are	SEC_CONTENT
built	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
in	SEC_CONTENT
turn	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
shared	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
short	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
method	SEC_CONTENT
combines	SEC_CONTENT
the	SEC_CONTENT
idea	SEC_CONTENT
of	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
classic	task
self	task
-	task
training	task
.	SEC_END
CVT	SEC_START
can	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
tasks	SEC_CONTENT
and	SEC_CONTENT
neural	SEC_CONTENT
architectures	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
sequence	SEC_CONTENT
modeling	SEC_CONTENT
tasks	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
attached	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
propose	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
that	SEC_CONTENT
work	SEC_CONTENT
well	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
taggers	SEC_CONTENT
,	SEC_CONTENT
graph	task
-	task
based	task
dependency	task
parsers	task
,	SEC_CONTENT
and	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
evaluate	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
on	SEC_CONTENT
English	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
combinatory	SEC_CONTENT
categorial	SEC_CONTENT
grammar	SEC_CONTENT
supertagging	SEC_CONTENT
,	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
,	SEC_CONTENT
partof	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
tagging	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
text	SEC_CONTENT
chunking	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
English	SEC_CONTENT
to	SEC_CONTENT
Vietnamese	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
.	SEC_CONTENT
CVT	SEC_CONTENT
improves	SEC_CONTENT
over	SEC_CONTENT
previously	SEC_CONTENT
published	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
these	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
CVT	SEC_CONTENT
can	SEC_CONTENT
easily	SEC_CONTENT
and	SEC_CONTENT
effectively	SEC_CONTENT
be	SEC_CONTENT
combined	SEC_CONTENT
with	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
:	SEC_CONTENT
we	SEC_CONTENT
just	SEC_CONTENT
add	SEC_CONTENT
additional	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
different	SEC_CONTENT
tasks	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_CONTENT
Training	SEC_CONTENT
a	SEC_CONTENT
unified	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
jointly	SEC_CONTENT
perform	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
except	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
improves	SEC_CONTENT
results	SEC_CONTENT
(	SEC_CONTENT
outperforming	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
ELMo	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
while	SEC_CONTENT
decreasing	SEC_CONTENT
the	SEC_CONTENT
total	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
.	SEC_END
Cross	SECTITLE_START
-	SECTITLE_CONTENT
View	SECTITLE_CONTENT
Training	SECTITLE_END
We	SEC_START
first	SEC_CONTENT
present	SEC_CONTENT
Cross	task
-	task
View	task
Training	task
and	SEC_CONTENT
describe	SEC_CONTENT
how	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
combined	SEC_CONTENT
effectively	SEC_CONTENT
with	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
See	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
overview	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
method	SEC_CONTENT
.	SEC_END
Method	SECTITLE_END
to	SEC_START
denote	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
classes	metric
pro-	SEC_CONTENT
:	SEC_CONTENT
An	SEC_CONTENT
overview	SEC_CONTENT
of	SEC_CONTENT
Cross	task
-	task
View	task
Training	task
.	SEC_CONTENT
The	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
standard	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
agree	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
particular	SEC_CONTENT
example	SEC_CONTENT
shows	SEC_CONTENT
CVT	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_CONTENT
From	SEC_CONTENT
the	SEC_CONTENT
labeled	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
learn	SEC_CONTENT
that	SEC_CONTENT
"	SEC_CONTENT
Washington	SEC_CONTENT
"	SEC_CONTENT
usually	SEC_CONTENT
refers	SEC_CONTENT
to	SEC_CONTENT
a	task
location	task
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
reach	SEC_CONTENT
the	task
same	task
prediction	task
without	SEC_CONTENT
seeing	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
doing	SEC_CONTENT
so	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
contextual	SEC_CONTENT
representations	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
learning	SEC_CONTENT
that	SEC_CONTENT
"	SEC_CONTENT
traveled	SEC_CONTENT
to	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
followed	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
location	SEC_CONTENT
.	SEC_CONTENT
duced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
parameters	SEC_CONTENT
θ	SEC_CONTENT
on	SEC_CONTENT
input	SEC_CONTENT
xi	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
CVT	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
alternates	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
minibatch	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
minibatch	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
CVT	SEC_CONTENT
uses	SEC_CONTENT
standard	SEC_CONTENT
cross	SEC_CONTENT
-	SEC_CONTENT
entropy	SEC_CONTENT
loss	SEC_CONTENT
:	SEC_END
CVT	SEC_START
adds	SEC_CONTENT
k	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
when	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
followed	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
one	SEC_CONTENT
takes	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
an	SEC_CONTENT
intermediate	SEC_CONTENT
representation	SEC_CONTENT
h	SEC_CONTENT
j	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
LSTMs	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
outputs	SEC_CONTENT
a	task
distribution	task
over	SEC_CONTENT
labels	SEC_CONTENT
p	SEC_CONTENT
j	SEC_CONTENT
θ	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
h	SEC_CONTENT
j	SEC_CONTENT
is	SEC_CONTENT
chosen	SEC_CONTENT
such	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
only	SEC_CONTENT
uses	SEC_CONTENT
apart	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
xi	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
particular	SEC_CONTENT
choice	SEC_CONTENT
can	SEC_CONTENT
depend	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
propose	SEC_CONTENT
variants	SEC_CONTENT
for	SEC_CONTENT
several	SEC_CONTENT
tasks	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
only	SEC_CONTENT
used	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
-	SEC_CONTENT
time	SEC_CONTENT
prediction	SEC_CONTENT
come	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
that	SEC_CONTENT
produces	SEC_CONTENT
p	SEC_CONTENT
θ	SEC_CONTENT
.	SEC_END
On	SEC_START
an	SEC_CONTENT
unlabeled	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
first	SEC_CONTENT
produces	SEC_CONTENT
soft	SEC_CONTENT
targets	SEC_CONTENT
p	SEC_CONTENT
θ	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
performing	SEC_CONTENT
inference	SEC_CONTENT
.	SEC_CONTENT
CVT	SEC_CONTENT
trains	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
to	SEC_CONTENT
match	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
by	SEC_CONTENT
minimizing	SEC_END
where	SEC_START
Dis	SEC_CONTENT
a	SEC_CONTENT
distance	SEC_CONTENT
function	SEC_CONTENT
between	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
(	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
KL	SEC_CONTENT
divergence	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
hold	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
module	SEC_CONTENT
's	SEC_CONTENT
prediction	SEC_CONTENT
p	SEC_CONTENT
θ	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
fixed	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
back	SEC_CONTENT
-	SEC_CONTENT
propagate	SEC_CONTENT
through	SEC_CONTENT
it	SEC_CONTENT
)	SEC_CONTENT
so	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
modules	SEC_CONTENT
learn	SEC_CONTENT
to	SEC_CONTENT
imitate	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
one	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
not	SEC_CONTENT
vice	SEC_CONTENT
versa	SEC_CONTENT
.	SEC_CONTENT
CVT	SEC_CONTENT
works	SEC_CONTENT
by	SEC_CONTENT
enhancing	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
modules	SEC_CONTENT
train	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
representations	SEC_CONTENT
they	SEC_CONTENT
take	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
improve	SEC_CONTENT
so	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
useful	SEC_CONTENT
for	SEC_CONTENT
making	SEC_CONTENT
predictions	SEC_CONTENT
even	SEC_CONTENT
when	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
inputs	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
available	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
in	SEC_CONTENT
turn	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
built	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
shared	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
combine	SEC_CONTENT
the	SEC_CONTENT
supervised	SEC_CONTENT
and	SEC_CONTENT
CVT	SEC_CONTENT
losses	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
total	SEC_CONTENT
loss	SEC_CONTENT
,	SEC_CONTENT
L	SEC_CONTENT
=	SEC_CONTENT
L	SEC_CONTENT
sup	SEC_CONTENT
+	SEC_CONTENT
L	SEC_CONTENT
CVT	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
minimize	SEC_CONTENT
it	SEC_CONTENT
with	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
alternate	SEC_CONTENT
minimizing	SEC_CONTENT
L	SEC_CONTENT
sup	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
minibatch	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
and	SEC_CONTENT
minimizing	SEC_CONTENT
L	SEC_CONTENT
CVT	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
minibatch	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_END
For	SEC_START
most	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
,	SEC_CONTENT
adding	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
additional	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
is	SEC_CONTENT
computationally	SEC_CONTENT
cheap	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
the	task
portion	task
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
building	SEC_CONTENT
up	SEC_CONTENT
representations	SEC_CONTENT
(	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
RNN	SEC_CONTENT
or	SEC_CONTENT
CNN	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
our	SEC_CONTENT
method	SEC_CONTENT
contributes	SEC_CONTENT
little	SEC_CONTENT
overhead	SEC_CONTENT
to	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
over	SEC_CONTENT
other	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
approaches	SEC_CONTENT
for	SEC_CONTENT
most	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
CVT	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
change	SEC_CONTENT
inference	SEC_CONTENT
time	SEC_CONTENT
or	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
fullytrained	SEC_CONTENT
model	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
only	SEC_CONTENT
used	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
Combining	SECTITLE_START
CVT	SECTITLE_CONTENT
with	SECTITLE_CONTENT
Multi	SECTITLE_CONTENT
-	SECTITLE_CONTENT
Task	SECTITLE_CONTENT
Learning	SECTITLE_END
CVT	SEC_START
can	SEC_CONTENT
easily	SEC_CONTENT
be	SEC_CONTENT
combined	SEC_CONTENT
with	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
by	SEC_CONTENT
adding	SEC_CONTENT
additional	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
tasks	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
supervised	task
learning	task
,	SEC_CONTENT
we	SEC_CONTENT
randomly	SEC_CONTENT
select	SEC_CONTENT
a	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
update	SEC_CONTENT
L	SEC_CONTENT
sup	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
minibatch	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
for	SEC_CONTENT
that	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
optimize	SEC_CONTENT
L	SEC_CONTENT
CVT	SEC_CONTENT
jointly	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
at	SEC_CONTENT
once	SEC_CONTENT
,	SEC_CONTENT
first	SEC_CONTENT
running	SEC_CONTENT
inference	SEC_CONTENT
with	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
learning	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
predictions	SEC_CONTENT
with	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
before	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
alternates	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
minibatches	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
and	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
Examples	SEC_CONTENT
labeled	SEC_CONTENT
across	SEC_CONTENT
many	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
useful	SEC_CONTENT
for	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
systems	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
from	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
most	SEC_CONTENT
datasets	SEC_CONTENT
are	SEC_CONTENT
only	SEC_CONTENT
labeled	SEC_CONTENT
with	SEC_CONTENT
one	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
benefit	SEC_CONTENT
of	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
CVT	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
creates	SEC_CONTENT
(	SEC_CONTENT
artificial	SEC_CONTENT
)	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
tasks	SEC_CONTENT
-	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
from	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
significantly	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
data	SEC_CONTENT
efficiency	SEC_CONTENT
and	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
running	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
is	SEC_CONTENT
computationally	SEC_CONTENT
cheap	SEC_CONTENT
,	SEC_CONTENT
computing	SEC_CONTENT
L	SEC_CONTENT
CVT	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
much	SEC_CONTENT
slower	SEC_CONTENT
for	SEC_CONTENT
many	SEC_CONTENT
tasks	SEC_CONTENT
than	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
fora	SEC_CONTENT
single	SEC_CONTENT
one	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
tasks	SEC_CONTENT
-	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
substantially	SEC_CONTENT
speedup	SEC_CONTENT
model	SEC_CONTENT
convergence	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
six	SEC_CONTENT
tasks	SEC_CONTENT
takes	SEC_CONTENT
about	SEC_CONTENT
three	SEC_CONTENT
times	SEC_CONTENT
as	SEC_CONTENT
long	SEC_CONTENT
to	SEC_CONTENT
converge	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
one	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
50	SEC_CONTENT
%	SEC_CONTENT
decrease	SEC_CONTENT
in	SEC_CONTENT
total	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
.	SEC_END
Cross	SECTITLE_START
-	SECTITLE_CONTENT
View	SECTITLE_CONTENT
Training	SECTITLE_CONTENT
Models	SECTITLE_END
CVT	SEC_START
relies	SEC_CONTENT
on	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
that	SEC_CONTENT
have	SEC_CONTENT
restricted	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	task
section	task
,	SEC_CONTENT
we	SEC_CONTENT
describe	SEC_CONTENT
specific	SEC_CONTENT
constructions	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
effective	SEC_CONTENT
for	SEC_CONTENT
sequence	task
tagging	task
,	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
tosequence	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_END
Bi	SECTITLE_START
-	SECTITLE_CONTENT
LSTM	SECTITLE_CONTENT
Sentence	SECTITLE_CONTENT
Encoder	SECTITLE_END
All	SEC_START
of	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
BiLSTM	SEC_CONTENT
(	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
takes	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
words	SEC_END
First	SEC_START
,	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
is	SEC_CONTENT
represented	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
Convolutional	SEC_CONTENT
Neural	SEC_CONTENT
Network	SEC_CONTENT
,	SEC_CONTENT
resulting	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
vectors	SEC_END
The	SEC_START
encoder	SEC_CONTENT
applies	SEC_CONTENT
a	SEC_CONTENT
twolayer	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
these	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
layer	SEC_CONTENT
runs	SEC_CONTENT
a	SEC_CONTENT
Long	SEC_CONTENT
Short	SEC_CONTENT
-	SEC_CONTENT
Term	SEC_CONTENT
Memory	SEC_CONTENT
unit	SEC_CONTENT
(	SEC_CONTENT
Hochreiter	SEC_CONTENT
and	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
direction	SEC_CONTENT
(	SEC_CONTENT
taking	SEC_CONTENT
v	SEC_CONTENT
t	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
step	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
backward	SEC_CONTENT
direction	SEC_CONTENT
(	SEC_CONTENT
taking	SEC_CONTENT
v	SEC_CONTENT
T	SEC_CONTENT
−t+1	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
step	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
vector	SEC_CONTENT
sequences	SEC_END
The	SEC_START
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
is	SEC_CONTENT
the	task
concatenation	task
of	SEC_CONTENT
these	SEC_CONTENT
vectors	SEC_CONTENT
:	SEC_END
The	SEC_START
second	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
layer	SEC_CONTENT
works	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
,	SEC_CONTENT
producing	SEC_CONTENT
outputs	SEC_CONTENT
h	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
except	SEC_CONTENT
it	SEC_CONTENT
takes	SEC_CONTENT
h	SEC_CONTENT
1	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
v.	SEC_END
CVT	SECTITLE_START
for	SECTITLE_CONTENT
Sequence	SECTITLE_CONTENT
Tagging	SECTITLE_END
In	SEC_START
sequence	task
tagging	task
,	SEC_CONTENT
each	SEC_CONTENT
token	SEC_CONTENT
x	SEC_CONTENT
ti	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
corresponding	SEC_CONTENT
label	SEC_CONTENT
y	SEC_CONTENT
ti	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
tagging	SEC_CONTENT
produces	SEC_CONTENT
a	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
classes	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
t	SEC_CONTENT
th	SEC_CONTENT
label	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
onehidden	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
encoder	SEC_CONTENT
outputs	SEC_CONTENT
:	SEC_END
The	SEC_START
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
take	SEC_END
,	SEC_START
the	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
LSTMs	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
2	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
add	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
four	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
:	SEC_END
The	SEC_START
"	SEC_CONTENT
forward	SEC_CONTENT
"	SEC_CONTENT
module	SEC_CONTENT
makes	SEC_CONTENT
each	task
prediction	task
without	SEC_CONTENT
seeing	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
token	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
"	SEC_CONTENT
future	SEC_CONTENT
"	SEC_CONTENT
module	SEC_CONTENT
makes	SEC_CONTENT
each	task
prediction	task
without	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
or	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
token	SEC_CONTENT
itself	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
it	SEC_CONTENT
works	SEC_CONTENT
like	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
predicting	SEC_CONTENT
which	SEC_CONTENT
token	SEC_CONTENT
comes	SEC_CONTENT
next	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
predicts	SEC_CONTENT
which	SEC_CONTENT
class	SEC_CONTENT
of	SEC_CONTENT
token	SEC_CONTENT
comes	SEC_CONTENT
next	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
"	SEC_CONTENT
backward	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
past	SEC_CONTENT
"	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
analogous	SEC_CONTENT
.	SEC_END
CVT	SECTITLE_START
for	SECTITLE_CONTENT
Dependency	SECTITLE_CONTENT
Parsing	SECTITLE_END
Ina	SEC_START
dependency	task
parse	task
,	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
are	SEC_CONTENT
treated	SEC_CONTENT
as	SEC_CONTENT
nodes	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
graph	SEC_CONTENT
.	SEC_CONTENT
Typed	SEC_CONTENT
directed	SEC_CONTENT
edges	SEC_CONTENT
connect	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
forming	SEC_CONTENT
a	SEC_CONTENT
tree	SEC_CONTENT
structure	SEC_CONTENT
describing	SEC_CONTENT
the	SEC_CONTENT
syntactic	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
x	SEC_CONTENT
ti	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_END
.	SEC_START
,	SEC_CONTENT
x	SEC_CONTENT
Ti	SEC_CONTENT
receives	SEC_CONTENT
exactly	SEC_CONTENT
one	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
going	SEC_CONTENT
edge	SEC_CONTENT
(	SEC_CONTENT
u	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
r	SEC_CONTENT
)	SEC_CONTENT
going	SEC_CONTENT
from	SEC_CONTENT
word	SEC_CONTENT
x	SEC_CONTENT
u	SEC_CONTENT
i	SEC_CONTENT
(	SEC_CONTENT
called	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
head	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
it	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
dependent	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
type	SEC_CONTENT
r	SEC_CONTENT
(	task
the	task
"	task
relation	task
"	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
a	task
graph	task
-	task
based	task
dependency	task
parser	task
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
from	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
treats	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
classification	SEC_CONTENT
task	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
which	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
going	SEC_CONTENT
edge	SEC_CONTENT
y	SEC_CONTENT
ti	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
u	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
r	SEC_CONTENT
)	SEC_CONTENT
connects	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
x	SEC_CONTENT
ti	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
representations	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
candidate	SEC_CONTENT
head	SEC_CONTENT
and	SEC_CONTENT
dependent	SEC_CONTENT
are	SEC_CONTENT
Modules	SEC_CONTENT
taking	SEC_CONTENT
inputs	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
layer	SEC_CONTENT
would	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
restricted	SEC_CONTENT
views	SEC_CONTENT
because	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
sentence	SEC_CONTENT
gets	SEC_CONTENT
propagated	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
passed	SEC_CONTENT
through	SEC_CONTENT
separate	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
bilinear	SEC_CONTENT
classifier	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
these	SEC_CONTENT
representations	SEC_CONTENT
produces	SEC_CONTENT
a	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
candidate	SEC_CONTENT
edge	SEC_CONTENT
.	SEC_CONTENT
Lastly	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
scores	SEC_CONTENT
are	SEC_CONTENT
passed	SEC_CONTENT
through	SEC_CONTENT
a	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
probabilities	SEC_CONTENT
.	SEC_CONTENT
Mathematically	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
edge	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
as	SEC_CONTENT
:	SEC_END
where	SEC_START
sis	SEC_CONTENT
the	SEC_CONTENT
scoring	SEC_CONTENT
function	SEC_CONTENT
:	SEC_END
The	SEC_START
bilinear	SEC_CONTENT
classifier	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
W	SEC_CONTENT
r	SEC_CONTENT
specific	SEC_CONTENT
to	SEC_CONTENT
the	task
candidate	task
relation	task
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
W	SEC_CONTENT
shared	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
relations	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
unlike	SEC_CONTENT
inmost	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
dependency	SEC_CONTENT
parser	SEC_CONTENT
only	SEC_CONTENT
takes	SEC_CONTENT
words	SEC_CONTENT
as	SEC_CONTENT
inputs	SEC_CONTENT
,	SEC_CONTENT
not	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
tags	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
add	SEC_CONTENT
four	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
cross	SEC_CONTENT
-	SEC_CONTENT
view	SEC_CONTENT
training	SEC_CONTENT
:	SEC_END
Each	SEC_START
one	SEC_CONTENT
has	SEC_CONTENT
some	SEC_CONTENT
missing	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
not	SEC_CONTENT
seeing	SEC_CONTENT
either	SEC_CONTENT
the	SEC_CONTENT
preceding	SEC_CONTENT
or	SEC_CONTENT
following	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
candidate	SEC_CONTENT
head	SEC_CONTENT
and	SEC_CONTENT
candidate	SEC_CONTENT
dependent	SEC_CONTENT
.	SEC_END
CVT	SECTITLE_START
for	SECTITLE_CONTENT
Sequence	SECTITLE_CONTENT
-	SECTITLE_CONTENT
to	SECTITLE_CONTENT
-	SECTITLE_CONTENT
Sequence	SECTITLE_CONTENT
Learning	SECTITLE_END
We	SEC_START
use	SEC_CONTENT
an	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
attention	task
.	SEC_CONTENT
Each	SEC_CONTENT
example	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
(	SEC_CONTENT
source	SEC_CONTENT
)	SEC_CONTENT
sequence	SEC_CONTENT
xi	SEC_CONTENT
=	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
Ti	SEC_CONTENT
and	SEC_CONTENT
output	SEC_CONTENT
(	SEC_CONTENT
target	SEC_CONTENT
)	SEC_CONTENT
sequence	SEC_CONTENT
y	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
y	SEC_CONTENT
1	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
K	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
encoder	SEC_CONTENT
's	SEC_CONTENT
representations	SEC_CONTENT
are	SEC_CONTENT
passed	SEC_CONTENT
into	SEC_CONTENT
an	SEC_CONTENT
LSTM	SEC_CONTENT
decoder	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
bilinear	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
t	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
computes	SEC_CONTENT
an	SEC_CONTENT
attention	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
source	SEC_CONTENT
sequence	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
as	SEC_CONTENT
α	SEC_CONTENT
j	SEC_CONTENT
∝	SEC_CONTENT
eh	SEC_CONTENT
j	SEC_CONTENT
Wα	SEC_CONTENT
¯	SEC_CONTENT
ht	SEC_CONTENT
where	SEC_CONTENT
¯	SEC_CONTENT
ht	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
's	SEC_CONTENT
current	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
source	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
weighted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
distribution	SEC_CONTENT
form	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
:	SEC_CONTENT
ct	SEC_CONTENT
=	SEC_CONTENT
j	SEC_CONTENT
α	SEC_CONTENT
j	SEC_CONTENT
h	SEC_CONTENT
j	SEC_CONTENT
.	SEC_CONTENT
Next	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
and	SEC_CONTENT
current	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
are	SEC_CONTENT
combined	SEC_CONTENT
into	SEC_CONTENT
an	SEC_CONTENT
attention	SEC_CONTENT
vector	SEC_CONTENT
at	SEC_CONTENT
=	SEC_CONTENT
tanh(W	SEC_CONTENT
a	SEC_CONTENT
[	SEC_CONTENT
c	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
ht	SEC_CONTENT
]	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Lastly	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
predicts	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
token	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
sequence	SEC_CONTENT
:	SEC_CONTENT
p(y	SEC_CONTENT
ti	SEC_CONTENT
|y	SEC_CONTENT
<	SEC_CONTENT
t	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
xi	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
softmax(W	SEC_CONTENT
s	SEC_CONTENT
at	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
add	SEC_CONTENT
two	SEC_CONTENT
auxiliary	SEC_CONTENT
decoders	SEC_CONTENT
when	SEC_CONTENT
applying	SEC_CONTENT
CVT	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
auxiliary	SEC_CONTENT
decoders	SEC_CONTENT
share	SEC_CONTENT
embedding	SEC_CONTENT
and	SEC_CONTENT
LSTM	SEC_CONTENT
parameters	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
decoder	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
have	SEC_CONTENT
different	SEC_CONTENT
parameters	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
mechanisms	SEC_CONTENT
and	SEC_CONTENT
softmax	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
one	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
restrict	SEC_CONTENT
its	SEC_CONTENT
view	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
by	SEC_CONTENT
applying	SEC_CONTENT
attention	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
randomly	SEC_CONTENT
zeroing	SEC_CONTENT
out	SEC_CONTENT
a	SEC_CONTENT
fraction	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
attention	SEC_CONTENT
weights	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
one	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
sequence	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
one	SEC_CONTENT
:	SEC_CONTENT
p	SEC_CONTENT
future	SEC_END
Since	SEC_START
there	SEC_CONTENT
is	SEC_CONTENT
no	SEC_CONTENT
target	SEC_CONTENT
sequence	SEC_CONTENT
for	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
apply	SEC_CONTENT
teacher	SEC_CONTENT
forcing	SEC_CONTENT
to	SEC_CONTENT
get	SEC_CONTENT
an	SEC_CONTENT
output	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
decoder	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
produce	SEC_CONTENT
hard	SEC_CONTENT
targets	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
modules	SEC_CONTENT
by	SEC_CONTENT
running	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
decoder	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
idea	SEC_CONTENT
has	SEC_CONTENT
previously	SEC_CONTENT
been	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
knowledge	SEC_CONTENT
distillation	SEC_CONTENT
by	SEC_CONTENT
and	SEC_CONTENT
makes	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
backtranslation	task
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
We	SEC_START
compare	SEC_CONTENT
Cross	task
-	task
View	task
Training	task
against	SEC_CONTENT
several	SEC_CONTENT
strong	SEC_CONTENT
baselines	SEC_CONTENT
on	SEC_CONTENT
seven	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_END
Combinatory	SEC_START
Categorial	SEC_CONTENT
Grammar	SEC_CONTENT
(	dataset
CCG	dataset
)	SEC_CONTENT
Supertagging	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
data	SEC_CONTENT
from	SEC_CONTENT
CCGBank	dataset
.	SEC_END
Text	SEC_START
Chunking	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2000	SEC_CONTENT
data	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Named	SEC_START
Entity	task
Recognition	task
(	SEC_CONTENT
NER	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2003	SEC_CONTENT
data	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Fine	SEC_START
-	SEC_CONTENT
Grained	SEC_CONTENT
NER	SEC_CONTENT
(	SEC_CONTENT
FGN	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	dataset
OntoNotes	dataset
(	SEC_CONTENT
)	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
Part	SEC_START
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
Speech	SEC_CONTENT
(	SEC_CONTENT
POS	metric
)	SEC_CONTENT
Tagging	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
Wall	SEC_CONTENT
Street	SEC_CONTENT
Journal	SEC_CONTENT
portion	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
.	SEC_END
Dependency	SEC_START
Parsing	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
converted	SEC_CONTENT
to	SEC_CONTENT
Stanford	SEC_CONTENT
Dependencies	SEC_CONTENT
version	SEC_CONTENT
3.3.0	SEC_CONTENT
.	SEC_END
Machine	SEC_START
Translation	SEC_CONTENT
:	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	task
EnglishVietnamese	task
translation	task
dataset	SEC_CONTENT
from	SEC_CONTENT
IWSLT	SEC_CONTENT
2015	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
(	SEC_CONTENT
tokenized	SEC_CONTENT
)	SEC_CONTENT
BLEU	metric
scores	metric
on	SEC_CONTENT
the	SEC_CONTENT
tst2013	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
We	SEC_START
use	SEC_CONTENT
the	SEC_CONTENT
1	SEC_CONTENT
Billion	SEC_CONTENT
Word	SEC_CONTENT
Language	SEC_CONTENT
Model	SEC_CONTENT
Benchmark	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
pool	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
sentences	SEC_CONTENT
for	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_END
Model	SECTITLE_START
Details	SECTITLE_CONTENT
and	SECTITLE_CONTENT
Baselines	SECTITLE_END
We	SEC_START
apply	SEC_CONTENT
dropout	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
not	SEC_CONTENT
when	SEC_CONTENT
running	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
soft	SEC_CONTENT
targets	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
listed	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
it	SEC_CONTENT
slightly	SEC_CONTENT
improves	SEC_CONTENT
results	SEC_CONTENT
to	SEC_CONTENT
add	SEC_CONTENT
another	SEC_CONTENT
one	SEC_CONTENT
that	SEC_CONTENT
sees	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
input	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
subset	SEC_CONTENT
(	SEC_CONTENT
but	SEC_CONTENT
unlike	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
,	SEC_CONTENT
does	SEC_CONTENT
have	SEC_CONTENT
dropout	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
representations	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Unless	SEC_CONTENT
indicated	SEC_CONTENT
otherwise	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
have	SEC_CONTENT
LSTMs	SEC_CONTENT
with	SEC_CONTENT
1024-sized	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
and	SEC_CONTENT
512-sized	SEC_CONTENT
projection	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
See	SEC_CONTENT
the	SEC_CONTENT
appendix	SEC_CONTENT
for	SEC_CONTENT
full	SEC_CONTENT
training	SEC_CONTENT
details	SEC_CONTENT
and	SEC_CONTENT
hyperparameters	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compare	SEC_CONTENT
CVT	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
other	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
algorithms	SEC_CONTENT
:	SEC_END
Word	SEC_START
Dropout	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
method	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
acting	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
teacher	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
run	SEC_CONTENT
as	SEC_CONTENT
normal	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
when	SEC_CONTENT
acting	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
student	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
randomly	SEC_CONTENT
replace	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
REMOVED	SEC_CONTENT
token	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
CVT	SEC_CONTENT
in	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
exposes	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
restricted	SEC_CONTENT
view	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
less	SEC_CONTENT
data	SEC_CONTENT
efficient	SEC_CONTENT
.	SEC_CONTENT
By	SEC_CONTENT
carefully	SEC_CONTENT
designing	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
to	SEC_CONTENT
match	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
one	SEC_CONTENT
across	SEC_CONTENT
many	SEC_CONTENT
different	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
a	SEC_CONTENT
once	SEC_CONTENT
,	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
just	SEC_CONTENT
one	SEC_CONTENT
view	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
.	SEC_END
Virtual	SEC_START
Adversarial	SEC_CONTENT
Training	SEC_CONTENT
(	SEC_CONTENT
VAT	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
VAT	SEC_CONTENT
(	SEC_CONTENT
Miyato	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
works	SEC_CONTENT
like	SEC_CONTENT
word	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
adds	SEC_CONTENT
noise	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
dropping	SEC_CONTENT
out	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Notably	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
noise	SEC_CONTENT
is	SEC_CONTENT
chosen	SEC_CONTENT
adversarially	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
most	SEC_CONTENT
changes	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
prediction	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
method	SEC_CONTENT
was	SEC_CONTENT
applied	SEC_CONTENT
successfully	SEC_CONTENT
to	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
text	SEC_CONTENT
classification	SEC_CONTENT
by	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
separately	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
implementaiton	SEC_CONTENT
follows	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
combining	SEC_CONTENT
ELMo	SEC_CONTENT
with	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
allow	SEC_CONTENT
each	SEC_CONTENT
task	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
weights	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
embeddings	SEC_CONTENT
going	SEC_CONTENT
into	SEC_CONTENT
each	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
found	SEC_CONTENT
applying	SEC_CONTENT
dropout	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
embeddings	SEC_CONTENT
was	SEC_CONTENT
crucial	SEC_CONTENT
for	SEC_CONTENT
achieving	SEC_CONTENT
good	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
Results	SEC_START
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
CVT	SEC_CONTENT
on	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
outperforms	SEC_CONTENT
or	SEC_CONTENT
is	SEC_CONTENT
comparable	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
previously	SEC_CONTENT
published	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
an	SEC_CONTENT
example	SEC_CONTENT
win	SEC_CONTENT
for	SEC_CONTENT
CVT	SEC_CONTENT
over	SEC_CONTENT
supervised	task
learning	task
.	SEC_CONTENT
.	SEC_CONTENT
Of	SEC_CONTENT
the	SEC_CONTENT
prior	SEC_CONTENT
results	SEC_CONTENT
listed	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
only	SEC_CONTENT
TagLM	SEC_CONTENT
and	SEC_CONTENT
ELMo	SEC_CONTENT
are	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
methods	SEC_CONTENT
first	SEC_CONTENT
train	SEC_CONTENT
an	SEC_CONTENT
enormous	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
incorporate	SEC_CONTENT
the	task
representations	task
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
supervised	SEC_CONTENT
classifier	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
base	SEC_CONTENT
models	SEC_CONTENT
use	SEC_CONTENT
1024	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
in	SEC_CONTENT
their	SEC_CONTENT
LSTMs	SEC_CONTENT
(	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
4096	SEC_CONTENT
in	SEC_CONTENT
ELMo	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
require	SEC_CONTENT
fewer	SEC_CONTENT
training	SEC_CONTENT
steps	SEC_CONTENT
(	SEC_CONTENT
around	SEC_CONTENT
one	SEC_CONTENT
pass	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
billion	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
benchmark	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
many	SEC_CONTENT
passes	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
require	SEC_CONTENT
a	SEC_CONTENT
pipelined	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
they	SEC_CONTENT
perform	SEC_CONTENT
An	SEC_CONTENT
NER	SEC_CONTENT
example	SEC_CONTENT
that	SEC_CONTENT
CVT	SEC_CONTENT
classifies	SEC_CONTENT
correctly	SEC_CONTENT
but	SEC_CONTENT
supervised	task
learning	task
does	SEC_CONTENT
not	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
Warner	SEC_CONTENT
"	SEC_CONTENT
only	SEC_CONTENT
occurs	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
last	SEC_CONTENT
name	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
train	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
the	SEC_CONTENT
supervised	SEC_CONTENT
model	SEC_CONTENT
classifies	SEC_CONTENT
"	SEC_CONTENT
Warner	SEC_CONTENT
Bros	SEC_CONTENT
"	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
person	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
CVT	SEC_CONTENT
model	SEC_CONTENT
also	SEC_CONTENT
mistakenly	SEC_CONTENT
classifies	SEC_CONTENT
"	SEC_CONTENT
Warner	SEC_CONTENT
Bros	SEC_CONTENT
"	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
person	SEC_CONTENT
to	SEC_CONTENT
start	SEC_CONTENT
with	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
sees	SEC_CONTENT
more	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
(	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
"	SEC_CONTENT
Warner	SEC_CONTENT
"	SEC_CONTENT
occurs	SEC_CONTENT
thousands	SEC_CONTENT
of	SEC_CONTENT
times	SEC_CONTENT
)	SEC_CONTENT
it	SEC_CONTENT
learns	SEC_CONTENT
that	SEC_CONTENT
"	SEC_CONTENT
Warner	SEC_CONTENT
Bros	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
an	task
organization	task
.	SEC_END
on	SEC_START
par	SEC_CONTENT
with	SEC_CONTENT
ELMo	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
faster	SEC_CONTENT
and	SEC_CONTENT
simpler	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
.	SEC_CONTENT
Increasing	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
CVT+Multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
model	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
4096	SEC_CONTENT
units	SEC_CONTENT
in	SEC_CONTENT
its	SEC_CONTENT
LSTMs	SEC_CONTENT
like	SEC_CONTENT
ELMo	SEC_CONTENT
improves	SEC_CONTENT
results	SEC_CONTENT
further	SEC_CONTENT
so	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
significantly	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
ELMo+Multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
ones	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
suspect	SEC_CONTENT
there	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
further	SEC_CONTENT
gains	SEC_CONTENT
from	SEC_CONTENT
combining	SEC_CONTENT
our	SEC_CONTENT
method	SEC_CONTENT
with	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
leave	SEC_CONTENT
for	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
.	SEC_END
CVT	SEC_START
+	SEC_CONTENT
Multi	SEC_CONTENT
-	SEC_CONTENT
Task	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
sharedencoder	SEC_CONTENT
CVT	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
except	SEC_CONTENT
machine	task
translation	task
(	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
quite	SEC_CONTENT
different	SEC_CONTENT
and	SEC_CONTENT
requires	SEC_CONTENT
more	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
ones	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
improves	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
except	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
grained	SEC_CONTENT
NER	SEC_CONTENT
,	SEC_CONTENT
sometimes	SEC_CONTENT
by	SEC_CONTENT
large	SEC_CONTENT
margins	SEC_CONTENT
.	SEC_CONTENT
Prior	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
many	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
NLP	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
uses	SEC_CONTENT
complicated	SEC_CONTENT
architectures	SEC_CONTENT
and	SEC_CONTENT
training	SEC_CONTENT
algorithms	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
result	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
simple	SEC_CONTENT
parameter	SEC_CONTENT
sharing	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
enough	SEC_CONTENT
for	SEC_CONTENT
effective	SEC_CONTENT
many	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
big	SEC_CONTENT
and	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Interestingly	SEC_CONTENT
,	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
works	SEC_CONTENT
better	SEC_CONTENT
in	SEC_CONTENT
conjunction	SEC_CONTENT
with	SEC_CONTENT
CVT	SEC_CONTENT
than	SEC_CONTENT
with	SEC_CONTENT
ELMo	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
models	SEC_CONTENT
quickly	SEC_CONTENT
fit	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
primarily	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
vectors	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
perhaps	SEC_CONTENT
hinders	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
from	SEC_CONTENT
learning	SEC_CONTENT
effective	SEC_CONTENT
representations	SEC_CONTENT
that	SEC_CONTENT
transfer	SEC_CONTENT
across	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
believe	SEC_CONTENT
CVT	SEC_CONTENT
alleviates	SEC_CONTENT
the	SEC_CONTENT
danger	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
"	SEC_CONTENT
forgetting	SEC_CONTENT
"	SEC_CONTENT
one	SEC_CONTENT
task	SEC_CONTENT
while	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
ones	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
well	SEC_CONTENT
-	SEC_CONTENT
known	SEC_CONTENT
problem	SEC_CONTENT
in	SEC_CONTENT
many	task
-	task
task	task
learning	task
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
CVT	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
makes	SEC_CONTENT
predictions	SEC_CONTENT
about	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
creating	SEC_CONTENT
(	SEC_CONTENT
artificial	SEC_CONTENT
)	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
tasks	SEC_CONTENT
-	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
see	SEC_CONTENT
one	SEC_CONTENT
task	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
plus	SEC_CONTENT
self	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
Learning	SEC_CONTENT
without	SEC_CONTENT
Forgetting	SEC_CONTENT
algorithm	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
trains	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
keep	SEC_CONTENT
its	task
predictions	task
on	SEC_CONTENT
an	SEC_CONTENT
old	SEC_CONTENT
task	SEC_CONTENT
unchanged	SEC_CONTENT
when	SEC_CONTENT
learning	SEC_CONTENT
anew	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
test	SEC_CONTENT
the	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
tasks	SEC_CONTENT
-	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
trained	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
CVT	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
only	SEC_CONTENT
computes	SEC_CONTENT
L	SEC_CONTENT
CVT	SEC_CONTENT
on	SEC_CONTENT
one	SEC_CONTENT
task	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
(	SEC_CONTENT
chosen	SEC_CONTENT
randomly	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
unlabeled	SEC_CONTENT
minibatch	SEC_CONTENT
)	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
in	SEC_CONTENT
parallel	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
at	SEC_CONTENT
-	SEC_CONTENT
a	SEC_CONTENT
-	SEC_CONTENT
time	SEC_CONTENT
model	SEC_CONTENT
performs	SEC_CONTENT
substantially	SEC_CONTENT
worse	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
:	SEC_CONTENT
Dev	SEC_CONTENT
set	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
CVT	SEC_CONTENT
with	SEC_CONTENT
and	SEC_CONTENT
without	SEC_CONTENT
producing	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
tasks	SEC_CONTENT
-	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_END
Model	SECTITLE_END
Model	SEC_START
Generalization	task
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
evaluate	SEC_CONTENT
how	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
generalize	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
from	SEC_CONTENT
the	task
train	task
set	task
,	SEC_CONTENT
we	SEC_CONTENT
plot	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
vs.	SEC_CONTENT
train	metric
accuracy	metric
for	SEC_CONTENT
our	SEC_CONTENT
different	SEC_CONTENT
methods	SEC_CONTENT
as	SEC_CONTENT
they	SEC_CONTENT
learn	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
CVT	SEC_CONTENT
and	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
improve	SEC_CONTENT
model	task
generalization	task
:	SEC_CONTENT
for	SEC_CONTENT
the	metric
same	metric
train	metric
accuracy	metric
,	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
get	SEC_CONTENT
better	metric
dev	metric
accuracy	metric
than	SEC_CONTENT
purely	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
Interestingly	SEC_CONTENT
,	SEC_CONTENT
CVT	SEC_CONTENT
continues	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
in	SEC_CONTENT
dev	metric
set	metric
accuracy	metric
while	SEC_CONTENT
close	SEC_CONTENT
to	SEC_CONTENT
100	SEC_CONTENT
%	SEC_CONTENT
train	SEC_CONTENT
ac-	SEC_CONTENT
 	SEC_CONTENT
curacy	metric
for	SEC_CONTENT
CCG	dataset
,	SEC_CONTENT
Chunking	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
NER	SEC_CONTENT
,	SEC_CONTENT
perhaps	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
still	SEC_CONTENT
learning	SEC_CONTENT
from	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
even	SEC_CONTENT
when	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
completely	SEC_CONTENT
fit	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
train	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
show	SEC_CONTENT
results	SEC_CONTENT
fora	SEC_CONTENT
smaller	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
+	SEC_CONTENT
CVT	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
it	SEC_CONTENT
generalizes	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
larger	SEC_CONTENT
one	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
halts	SEC_CONTENT
making	SEC_CONTENT
progress	metric
on	SEC_CONTENT
the	task
train	task
set	SEC_CONTENT
earlier	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
suggests	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
important	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
sufficiently	SEC_CONTENT
large	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
for	SEC_CONTENT
multitask	SEC_CONTENT
learning	SEC_CONTENT
:	SEC_CONTENT
otherwise	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
the	SEC_CONTENT
capacity	SEC_CONTENT
to	SEC_CONTENT
fit	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Auxiliary	SEC_START
Prediction	SEC_CONTENT
Module	SEC_CONTENT
Ablation	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
briefly	SEC_CONTENT
explore	SEC_CONTENT
which	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
more	SEC_CONTENT
important	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
tagging	SEC_CONTENT
tasks	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
both	SEC_CONTENT
kinds	SEC_CONTENT
of	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
improve	SEC_CONTENT
performance	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
future	SEC_CONTENT
and	SEC_CONTENT
past	SEC_CONTENT
modules	SEC_CONTENT
improve	SEC_CONTENT
results	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
ones	SEC_CONTENT
,	SEC_CONTENT
perhaps	SEC_CONTENT
because	SEC_CONTENT
they	SEC_CONTENT
see	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
restricted	SEC_CONTENT
and	SEC_CONTENT
challenging	SEC_CONTENT
view	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
  	SEC_CONTENT
over	SEC_CONTENT
purely	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
grows	SEC_CONTENT
larger	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
decreases	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
,	SEC_CONTENT
left	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Using	SEC_CONTENT
only	SEC_CONTENT
25	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
already	SEC_CONTENT
performs	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
or	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
fully	SEC_CONTENT
supervised	SEC_CONTENT
model	SEC_CONTENT
using	SEC_CONTENT
100	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
demonstrating	SEC_CONTENT
that	SEC_CONTENT
CVT	SEC_CONTENT
is	SEC_CONTENT
particularly	SEC_CONTENT
useful	SEC_CONTENT
on	SEC_CONTENT
small	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_END
Training	SEC_START
Larger	SEC_CONTENT
Models	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
sequence	SEC_CONTENT
taggers	SEC_CONTENT
and	SEC_CONTENT
dependency	task
parsers	task
in	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
use	SEC_CONTENT
small	SEC_CONTENT
LSTMs	SEC_CONTENT
(	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
sizes	SEC_CONTENT
of	SEC_CONTENT
around	SEC_CONTENT
300	SEC_CONTENT
)	SEC_CONTENT
because	SEC_CONTENT
larger	SEC_CONTENT
models	SEC_CONTENT
yield	SEC_CONTENT
little	SEC_CONTENT
to	SEC_CONTENT
no	SEC_CONTENT
gains	SEC_CONTENT
in	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
found	SEC_CONTENT
our	SEC_CONTENT
own	SEC_CONTENT
supervised	SEC_CONTENT
approaches	SEC_CONTENT
also	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
benefit	SEC_CONTENT
greatly	SEC_CONTENT
from	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
using	SEC_CONTENT
CVT	SEC_CONTENT
accuracy	SEC_CONTENT
scales	SEC_CONTENT
better	SEC_CONTENT
with	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
,	SEC_CONTENT
right	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
finding	SEC_CONTENT
suggests	SEC_CONTENT
the	SEC_CONTENT
appropriate	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
methods	SEC_CONTENT
may	SEC_CONTENT
enable	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
of	SEC_CONTENT
larger	SEC_CONTENT
,	SEC_CONTENT
more	SEC_CONTENT
sophisticated	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
with	SEC_CONTENT
limited	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Generalizable	SEC_START
Representations	SEC_CONTENT
.	SEC_CONTENT
Lastly	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
explore	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
CVT+multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
freezing	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
only	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
sixth	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
tests	SEC_CONTENT
whether	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
's	SEC_CONTENT
representations	SEC_CONTENT
generalize	SEC_CONTENT
to	SEC_CONTENT
anew	SEC_CONTENT
task	SEC_CONTENT
not	SEC_CONTENT
seen	SEC_CONTENT
during	SEC_CONTENT
its	task
training	task
.	SEC_CONTENT
Only	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
fast	SEC_CONTENT
because	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
(	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
by	SEC_CONTENT
far	SEC_CONTENT
the	SEC_CONTENT
slowest	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
run	SEC_CONTENT
over	SEC_CONTENT
each	SEC_CONTENT
example	SEC_CONTENT
only	SEC_CONTENT
once	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
back	SEC_CONTENT
-	SEC_CONTENT
propagate	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_CONTENT
Results	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
:	SEC_CONTENT
Comparison	SEC_CONTENT
of	SEC_CONTENT
single	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
CVT	SEC_CONTENT
-	SEC_CONTENT
MT	SEC_CONTENT
frozen	SEC_CONTENT
"	SEC_CONTENT
means	SEC_CONTENT
we	SEC_CONTENT
pretrain	SEC_CONTENT
a	SEC_CONTENT
CVT	SEC_CONTENT
+	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
train	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
sixth	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
ELMo	SEC_CONTENT
frozen	SEC_CONTENT
"	SEC_CONTENT
means	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
(	SEC_CONTENT
but	SEC_CONTENT
no	SEC_CONTENT
LSTMs	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
ELMo	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_END
even	SEC_START
a	SEC_CONTENT
vanilla	SEC_CONTENT
supervised	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
showing	SEC_CONTENT
the	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
building	SEC_CONTENT
up	SEC_CONTENT
effective	SEC_CONTENT
representations	SEC_CONTENT
for	SEC_CONTENT
language	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
the	task
representations	task
could	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
like	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
vectors	SEC_CONTENT
(	SEC_CONTENT
to	SEC_CONTENT
quickly	SEC_CONTENT
train	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
new	SEC_CONTENT
tasks	SEC_CONTENT
without	SEC_CONTENT
slow	SEC_CONTENT
representation	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
Unsupervised	SEC_START
Representation	SEC_CONTENT
Learning	SEC_CONTENT
.	SEC_CONTENT
Early	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
deep	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
pretrain	SEC_CONTENT
neural	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
successful	SEC_CONTENT
for	SEC_CONTENT
applications	SEC_CONTENT
in	SEC_CONTENT
computer	SEC_CONTENT
vision	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
NLP	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
noteworthy	SEC_CONTENT
for	SEC_CONTENT
NLP	SEC_CONTENT
are	SEC_CONTENT
algorithms	SEC_CONTENT
for	SEC_CONTENT
learning	SEC_CONTENT
effective	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
pretraining	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
other	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
machine	task
translation	task
has	SEC_CONTENT
also	SEC_CONTENT
been	SEC_CONTENT
studied	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Other	SEC_CONTENT
approaches	SEC_CONTENT
train	SEC_CONTENT
"	SEC_CONTENT
thought	SEC_CONTENT
vectors	SEC_CONTENT
"	SEC_CONTENT
representing	SEC_CONTENT
sentences	SEC_CONTENT
through	SEC_CONTENT
unsupervised	SEC_CONTENT
(	SEC_CONTENT
or	SEC_CONTENT
supervised	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_END
Self	SEC_START
-	SEC_CONTENT
Training	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
earliest	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
is	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
successfully	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
sense	SEC_CONTENT
disambiguation	SEC_CONTENT
and	SEC_CONTENT
parsing	task
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
each	SEC_CONTENT
round	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
classifier	SEC_CONTENT
,	SEC_CONTENT
acting	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
teacher	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
labels	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
adds	SEC_CONTENT
it	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
acting	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
student	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
retrained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
new	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
Many	SEC_CONTENT
recent	SEC_CONTENT
approaches	SEC_CONTENT
(	SEC_CONTENT
including	SEC_CONTENT
the	SEC_CONTENT
consistentency	SEC_CONTENT
regularization	SEC_CONTENT
methods	SEC_CONTENT
discussed	SEC_CONTENT
below	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
own	SEC_CONTENT
method	SEC_CONTENT
)	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
with	SEC_CONTENT
soft	SEC_CONTENT
targets	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
's	SEC_CONTENT
output	SEC_CONTENT
distribution	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
hard	SEC_CONTENT
label	SEC_CONTENT
,	SEC_CONTENT
making	SEC_CONTENT
the	SEC_CONTENT
procedure	SEC_CONTENT
more	SEC_CONTENT
akin	SEC_CONTENT
to	SEC_CONTENT
knowledge	SEC_CONTENT
distillation	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
multiple	SEC_CONTENT
models	SEC_CONTENT
or	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
Consistency	SEC_START
Regularization	task
.	SEC_CONTENT
Recent	SEC_CONTENT
works	SEC_CONTENT
add	SEC_CONTENT
noise	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
drawn	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
distribution	SEC_CONTENT
)	SEC_CONTENT
or	SEC_CONTENT
apply	SEC_CONTENT
stochastic	SEC_CONTENT
transformations	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
horizontally	SEC_CONTENT
flipping	SEC_CONTENT
an	SEC_CONTENT
image	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
's	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
trains	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
give	SEC_CONTENT
consistent	SEC_CONTENT
predictions	SEC_CONTENT
to	SEC_CONTENT
nearby	SEC_CONTENT
data	SEC_CONTENT
points	SEC_CONTENT
,	SEC_CONTENT
encouraging	SEC_CONTENT
distributional	SEC_CONTENT
smoothness	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Consistency	SEC_CONTENT
regularization	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
very	SEC_CONTENT
successful	SEC_CONTENT
for	SEC_CONTENT
computer	SEC_CONTENT
vision	SEC_CONTENT
applications	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
stochastic	SEC_CONTENT
input	SEC_CONTENT
alterations	SEC_CONTENT
are	SEC_CONTENT
more	SEC_CONTENT
difficult	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
to	SEC_CONTENT
discrete	SEC_CONTENT
data	SEC_CONTENT
like	SEC_CONTENT
text	SEC_CONTENT
,	SEC_CONTENT
making	SEC_CONTENT
consistency	SEC_CONTENT
regularization	SEC_CONTENT
less	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
solution	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
add	SEC_CONTENT
noise	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
Miyato	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2017a	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
against	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
CVT	SEC_CONTENT
is	SEC_CONTENT
easily	SEC_CONTENT
applicable	SEC_CONTENT
to	SEC_CONTENT
text	SEC_CONTENT
because	SEC_CONTENT
it	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
require	SEC_CONTENT
changing	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
's	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_END
Multi	SEC_START
-	SEC_CONTENT
View	SEC_CONTENT
Learning	SEC_CONTENT
.	SEC_CONTENT
Multi	SEC_CONTENT
-	SEC_CONTENT
view	SEC_CONTENT
learning	SEC_CONTENT
on	SEC_CONTENT
data	SEC_CONTENT
where	SEC_CONTENT
features	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
separated	SEC_CONTENT
into	SEC_CONTENT
distinct	SEC_CONTENT
subsets	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
well	SEC_CONTENT
studied	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
relevant	SEC_CONTENT
are	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
regularization	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
trains	SEC_CONTENT
two	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
disjoint	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
one	SEC_CONTENT
acts	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
teacher	SEC_CONTENT
"	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	task
to	SEC_CONTENT
these	SEC_CONTENT
methods	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
trains	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
unified	SEC_CONTENT
model	SEC_CONTENT
where	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
see	SEC_CONTENT
different	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
not	SEC_CONTENT
necessarily	SEC_CONTENT
independent	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_END
Self	SEC_START
Supervision	SEC_CONTENT
.	SEC_CONTENT
Self	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
methods	SEC_CONTENT
train	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
on	SEC_CONTENT
tasks	SEC_CONTENT
where	SEC_CONTENT
performance	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
measured	SEC_CONTENT
without	SEC_CONTENT
human	SEC_CONTENT
-	SEC_CONTENT
provided	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
Recent	SEC_CONTENT
work	SEC_CONTENT
has	SEC_CONTENT
jointly	SEC_CONTENT
trained	SEC_CONTENT
image	SEC_CONTENT
classifiers	SEC_CONTENT
with	SEC_CONTENT
tasks	SEC_CONTENT
like	SEC_CONTENT
relative	SEC_CONTENT
position	SEC_CONTENT
and	SEC_CONTENT
colorization	SEC_CONTENT
,	SEC_CONTENT
sequence	SEC_CONTENT
taggers	SEC_CONTENT
with	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
agents	SEC_CONTENT
with	SEC_CONTENT
predicting	SEC_CONTENT
changes	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
environment	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
these	SEC_CONTENT
approaches	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
are	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
labeling	SEC_CONTENT
,	SEC_CONTENT
not	SEC_CONTENT
labels	SEC_CONTENT
deterministically	SEC_CONTENT
constructed	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_END
Multi	SEC_START
-	SEC_CONTENT
Task	SEC_CONTENT
Learning	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
extensive	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
NLP	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
work	SEC_CONTENT
has	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
closely	SEC_CONTENT
related	SEC_CONTENT
tasks	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Manytask	SEC_CONTENT
systems	SEC_CONTENT
are	SEC_CONTENT
less	SEC_CONTENT
commonly	SEC_CONTENT
developed	SEC_CONTENT
.	SEC_CONTENT
Collobert	SEC_CONTENT
and	SEC_CONTENT
Weston	SEC_CONTENT
(	SEC_CONTENT
2008	SEC_CONTENT
)	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
many	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
system	SEC_CONTENT
sharing	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
Hashimoto	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
many	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
model	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
arranged	SEC_CONTENT
hierarchically	SEC_CONTENT
according	SEC_CONTENT
to	SEC_CONTENT
their	SEC_CONTENT
linguistic	SEC_CONTENT
level	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Subramanian	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
-	SEC_CONTENT
encoder	SEC_CONTENT
many	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
purpose	SEC_CONTENT
of	SEC_CONTENT
learning	SEC_CONTENT
better	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
for	SEC_CONTENT
use	metric
in	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
not	SEC_CONTENT
for	SEC_CONTENT
improving	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
propose	SEC_CONTENT
Cross	task
-	task
View	task
Training	task
,	SEC_CONTENT
anew	SEC_CONTENT
method	SEC_CONTENT
for	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
approach	SEC_CONTENT
allows	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
effectively	SEC_CONTENT
leverage	SEC_CONTENT
their	SEC_CONTENT
own	SEC_CONTENT
predictions	SEC_CONTENT
on	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
training	SEC_CONTENT
them	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
effective	SEC_CONTENT
representations	SEC_CONTENT
that	SEC_CONTENT
yield	SEC_CONTENT
accurate	SEC_CONTENT
predictions	SEC_CONTENT
even	SEC_CONTENT
when	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
available	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
achieve	SEC_CONTENT
excellent	SEC_CONTENT
results	SEC_CONTENT
across	SEC_CONTENT
seven	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
especially	SEC_CONTENT
when	SEC_CONTENT
CVT	SEC_CONTENT
is	SEC_CONTENT
combined	SEC_CONTENT
with	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_END
B	SECTITLE_START
Model	SECTITLE_CONTENT
Details	SECTITLE_END
Our	SEC_START
models	SEC_CONTENT
use	SEC_CONTENT
two	SEC_CONTENT
layer	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
BiLSTM	SEC_CONTENT
encoders	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
.	SEC_CONTENT
See	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
paper	SEC_CONTENT
for	SEC_CONTENT
details	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
provide	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
minor	SEC_CONTENT
details	SEC_CONTENT
not	SEC_CONTENT
covered	SEC_CONTENT
there	SEC_CONTENT
below	SEC_CONTENT
.	SEC_END
Sequence	SEC_START
Tagging	task
.	SEC_CONTENT
For	SEC_CONTENT
Chunking	SEC_CONTENT
and	SEC_CONTENT
Named	SEC_CONTENT
Entity	SEC_CONTENT
Recognition	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
BIOES	SEC_CONTENT
tagging	SEC_CONTENT
scheme	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
apply	SEC_CONTENT
label	SEC_CONTENT
smoothing	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
0.1	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
labels	SEC_CONTENT
when	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Dependency	SEC_START
Parsing	task
.	SEC_CONTENT
We	SEC_CONTENT
omit	SEC_CONTENT
punctuation	SEC_CONTENT
from	SEC_CONTENT
evaluation	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
standard	SEC_CONTENT
practice	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
PTB	SEC_CONTENT
-	SEC_CONTENT
SD	SEC_CONTENT
3.3.0	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
ROOT	SEC_CONTENT
is	SEC_CONTENT
represented	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
vector	SEC_CONTENT
h	SEC_CONTENT
ROOT	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
otherwise	SEC_CONTENT
dependencies	SEC_CONTENT
coming	SEC_CONTENT
from	SEC_CONTENT
ROOT	SEC_CONTENT
are	SEC_CONTENT
scored	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
way	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
dependencies	SEC_CONTENT
.	SEC_END
Machine	SEC_START
Translation	task
.	SEC_CONTENT
We	SEC_CONTENT
apply	SEC_CONTENT
dropout	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
LSTM	SEC_CONTENT
layer	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
implementation	SEC_CONTENT
is	SEC_CONTENT
heavily	SEC_CONTENT
based	SEC_CONTENT
off	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Google	SEC_CONTENT
NMT	SEC_CONTENT
Tutorial	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
attribute	SEC_CONTENT
our	SEC_CONTENT
significantly	SEC_CONTENT
better	SEC_CONTENT
results	SEC_CONTENT
to	SEC_CONTENT
using	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
CNN	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
larger	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
stronger	SEC_CONTENT
regularization	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
better	SEC_CONTENT
hyperparameter	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
Target	SEC_CONTENT
words	SEC_CONTENT
occurring	SEC_CONTENT
5	SEC_CONTENT
or	SEC_CONTENT
fewer	SEC_CONTENT
times	SEC_CONTENT
in	SEC_CONTENT
the	task
train	task
set	task
are	SEC_CONTENT
replaced	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
UNK	SEC_CONTENT
token	SEC_CONTENT
(	SEC_CONTENT
but	SEC_CONTENT
not	SEC_CONTENT
during	SEC_CONTENT
evaluation	task
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
abeam	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
10	SEC_CONTENT
when	SEC_CONTENT
performing	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
found	SEC_CONTENT
it	SEC_CONTENT
slightly	SEC_CONTENT
beneficial	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
label	SEC_CONTENT
smoothing	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
0.1	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
's	SEC_CONTENT
predictions	SEC_CONTENT
(	SEC_CONTENT
unlike	SEC_CONTENT
our	SEC_CONTENT
other	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
only	SEC_CONTENT
provides	SEC_CONTENT
hard	SEC_CONTENT
targets	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
students	SEC_CONTENT
for	SEC_CONTENT
translation	task
)	SEC_CONTENT
.	SEC_END
Multi	SEC_START
-	SEC_CONTENT
Task	SEC_CONTENT
Learning	SEC_CONTENT
.	SEC_CONTENT
Several	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
datasets	SEC_CONTENT
are	SEC_CONTENT
constructed	SEC_CONTENT
from	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
treat	SEC_CONTENT
them	SEC_CONTENT
as	SEC_CONTENT
separate	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
providing	SEC_CONTENT
examples	SEC_CONTENT
labeled	SEC_CONTENT
across	SEC_CONTENT
multiple	SEC_CONTENT
tasks	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
during	SEC_CONTENT
supervised	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
tasks	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
all	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
train	SEC_CONTENT
/	SEC_CONTENT
dev	SEC_CONTENT
/	SEC_CONTENT
test	SEC_CONTENT
splits	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
ensure	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
split	SEC_CONTENT
of	SEC_CONTENT
one	SEC_CONTENT
task	SEC_CONTENT
never	SEC_CONTENT
overlaps	SEC_CONTENT
the	SEC_CONTENT
evaluation	SEC_CONTENT
split	SEC_CONTENT
of	SEC_CONTENT
another	SEC_CONTENT
by	SEC_CONTENT
discarding	SEC_CONTENT
the	SEC_CONTENT
overlapping	SEC_CONTENT
examples	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
train	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_END
Other	SEC_START
Details	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
apply	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
an	SEC_CONTENT
exponential	SEC_CONTENT
-	SEC_CONTENT
moving	SEC_CONTENT
-	SEC_CONTENT
average	SEC_CONTENT
(	SEC_CONTENT
EMA	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
weights	SEC_CONTENT
from	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
model	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
this	SEC_CONTENT
to	SEC_CONTENT
slightly	SEC_CONTENT
improve	SEC_CONTENT
accuracy	metric
and	SEC_CONTENT
significantly	SEC_CONTENT
reduce	SEC_CONTENT
the	metric
variance	metric
inaccuracy	metric
between	SEC_CONTENT
models	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
random	SEC_CONTENT
initializations	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
SGD	SEC_CONTENT
with	SEC_CONTENT
momentum	SEC_CONTENT
.	SEC_CONTENT
Word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
initialized	SEC_CONTENT
with	SEC_CONTENT
GloVe	SEC_CONTENT
vectors	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
finetuned	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
full	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
model	SEC_CONTENT
hyperparameters	SEC_CONTENT
are	SEC_CONTENT
listed	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Baselines	SEC_START
.	SEC_CONTENT
Baselines	SEC_CONTENT
were	SEC_CONTENT
run	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
architecture	SEC_CONTENT
and	SEC_CONTENT
hyperparameters	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
CVT	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
word	SEC_CONTENT
dropout	SEC_CONTENT
"	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
randomly	SEC_CONTENT
replace	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
REMOVED	SEC_CONTENT
token	SEC_CONTENT
with	SEC_CONTENT
probability	SEC_CONTENT
0.1	SEC_CONTENT
(	SEC_CONTENT
this	SEC_CONTENT
value	SEC_CONTENT
worked	SEC_CONTENT
well	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
sets	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
Virtual	SEC_CONTENT
Adversarial	SEC_CONTENT
Training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
the	task
perturbation	task
to	SEC_CONTENT
be	SEC_CONTENT
1.5	SEC_CONTENT
for	SEC_CONTENT
CCG	dataset
,	SEC_CONTENT
1.0	SEC_CONTENT
for	SEC_CONTENT
Dependency	task
Parsing	task
,	SEC_CONTENT
and	SEC_CONTENT
0.5	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
tasks	SEC_CONTENT
(	SEC_CONTENT
these	SEC_CONTENT
values	SEC_CONTENT
worked	SEC_CONTENT
best	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
sets	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Otherwise	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
implementation	SEC_CONTENT
is	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
Miyato	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2017a	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
based	SEC_CONTENT
our	SEC_CONTENT
implementation	SEC_CONTENT
off	SEC_CONTENT
of	SEC_CONTENT
their	SEC_CONTENT
code	SEC_CONTENT
4	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
were	SEC_CONTENT
unable	SEC_CONTENT
to	SEC_CONTENT
successfully	SEC_CONTENT
apply	SEC_CONTENT
VAT	SEC_CONTENT
to	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
perhaps	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
is	SEC_CONTENT
provided	SEC_CONTENT
hard	SEC_CONTENT
targets	SEC_CONTENT
for	SEC_CONTENT
that	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
ELMo	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
applied	SEC_CONTENT
dropout	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
embeddings	SEC_CONTENT
before	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
incorporated	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
rest	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
ELMo	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
prediction	SEC_CONTENT
module	SEC_CONTENT
has	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
softmax	SEC_CONTENT
-	SEC_CONTENT
normalized	SEC_CONTENT
weights	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
task	SEC_CONTENT
j	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
emeddings	SEC_CONTENT
going	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
prediction	SEC_CONTENT
modules	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
tasks	SEC_CONTENT
share	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
s	SEC_CONTENT
j	SEC_CONTENT
weights	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
ELMo	SEC_CONTENT
embeddings	SEC_CONTENT
going	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_END
C	SECTITLE_START
CVT	SECTITLE_CONTENT
for	SECTITLE_CONTENT
Image	SECTITLE_CONTENT
Recognition	SECTITLE_END
Although	SEC_START
the	SEC_CONTENT
focus	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
on	SEC_CONTENT
NLP	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
applied	SEC_CONTENT
CVT	SEC_CONTENT
to	SEC_CONTENT
image	SEC_CONTENT
recognition	task
and	SEC_CONTENT
found	SEC_CONTENT
it	SEC_CONTENT
performs	SEC_CONTENT
competitively	SEC_CONTENT
with	SEC_CONTENT
existing	SEC_CONTENT
methods	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
image	SEC_CONTENT
recognition	SEC_CONTENT
approaches	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
against	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
being	SEC_CONTENT
continuous	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
they	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
difficult	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
to	SEC_CONTENT
text	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
specifically	SEC_CONTENT
,	SEC_CONTENT
consistency	SEC_CONTENT
regularization	SEC_CONTENT
methods	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
adding	SEC_CONTENT
continuous	SEC_CONTENT
noise	SEC_CONTENT
and	SEC_CONTENT
applying	SEC_CONTENT
imagespecific	SEC_CONTENT
transformations	SEC_CONTENT
like	SEC_CONTENT
cropping	SEC_CONTENT
to	SEC_CONTENT
inputs	SEC_CONTENT
,	SEC_CONTENT
GANs	SEC_CONTENT
(	SEC_CONTENT
are	SEC_CONTENT
very	SEC_CONTENT
difficult	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
on	SEC_CONTENT
text	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
discrete	SEC_CONTENT
nature	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
mixup	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
requires	SEC_CONTENT
away	SEC_CONTENT
of	SEC_CONTENT
smoothly	SEC_CONTENT
interpolating	SEC_CONTENT
between	SEC_CONTENT
different	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_END
Approach	SEC_START
.	SEC_CONTENT
Our	task
image	task
recognition	task
models	task
are	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
Convolutional	SEC_CONTENT
Neural	SEC_CONTENT
Networks	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
produce	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
H(x	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
n×n×d	SEC_CONTENT
from	SEC_CONTENT
an	SEC_CONTENT
image	SEC_CONTENT
xi	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
two	SEC_CONTENT
dimensions	SEC_CONTENT
of	SEC_CONTENT
H	SEC_CONTENT
index	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
spatial	SEC_CONTENT
coordinates	SEC_CONTENT
of	SEC_CONTENT
feature	SEC_CONTENT
vectors	SEC_CONTENT
and	SEC_CONTENT
dis	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
shallower	SEC_CONTENT
CNNs	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
particular	SEC_CONTENT
feature	SEC_CONTENT
vector	SEC_CONTENT
corresponds	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
region	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
image	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
H	SEC_CONTENT
0,0	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
d	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
upper	SEC_CONTENT
left	SEC_CONTENT
corner	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
deeper	SEC_CONTENT
CNNs	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
particular	SEC_CONTENT
feature	SEC_CONTENT
vector	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
image	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
still	SEC_CONTENT
only	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
region	SEC_CONTENT
"	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
representations	SEC_CONTENT
from	SEC_CONTENT
an	SEC_CONTENT
earlier	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
CNNs	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
are	SEC_CONTENT
all	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
category	SEC_CONTENT
.	SEC_END
The	SEC_START
primary	SEC_CONTENT
prediction	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
CNNs	SEC_CONTENT
take	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
the	SEC_CONTENT
mean	SEC_CONTENT
of	SEC_CONTENT
H	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
two	SEC_CONTENT
dimensions	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
d	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
vector	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
fed	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
:	SEC_END
We	SEC_START
add	SEC_CONTENT
n	SEC_CONTENT
2	SEC_CONTENT
auxiliary	SEC_CONTENT
prediction	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
CNN	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
jth	SEC_CONTENT
layer	SEC_CONTENT
takes	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
feature	SEC_CONTENT
vector	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
:	SEC_END
Data	SEC_START
.	SEC_CONTENT
We	SEC_CONTENT
evaluated	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CIFAR-10	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
datasets	SEC_CONTENT
semisupervised	SEC_CONTENT
by	SEC_CONTENT
only	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
provided	SEC_CONTENT
labels	SEC_CONTENT
fora	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
examples	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
rest	SEC_CONTENT
are	SEC_CONTENT
treated	SEC_CONTENT
as	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
add	SEC_CONTENT
36	SEC_CONTENT
auxiliary	SEC_CONTENT
softmax	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
6	SEC_CONTENT
×	SEC_CONTENT
6	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
feature	SEC_CONTENT
vectors	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
CNN	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
auxiliary	SEC_CONTENT
layer	SEC_CONTENT
sees	SEC_CONTENT
a	SEC_CONTENT
patch	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
image	SEC_CONTENT
ranging	SEC_CONTENT
in	SEC_CONTENT
size	SEC_CONTENT
from	SEC_CONTENT
21	SEC_CONTENT
×	SEC_CONTENT
21	SEC_CONTENT
pixels	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
corner	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
29	SEC_CONTENT
×	SEC_CONTENT
29	SEC_CONTENT
pixels	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
center	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
32	SEC_CONTENT
×	SEC_CONTENT
32	SEC_CONTENT
pixel	SEC_CONTENT
images	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
some	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
combine	SEC_CONTENT
CVT	SEC_CONTENT
with	SEC_CONTENT
standard	task
consistency	task
regularization	task
by	SEC_CONTENT
adding	SEC_CONTENT
a	SEC_CONTENT
perturbation	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
random	SEC_CONTENT
vector	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
's	SEC_CONTENT
inputs	SEC_CONTENT
when	SEC_CONTENT
computing	SEC_CONTENT
L	SEC_CONTENT
CVT	SEC_CONTENT
.	SEC_END
Results	SEC_START
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Unsurprisingly	SEC_CONTENT
,	SEC_CONTENT
adding	SEC_CONTENT
continuous	dataset
noise	dataset
to	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
works	SEC_CONTENT
much	SEC_CONTENT
better	SEC_CONTENT
with	SEC_CONTENT
images	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
are	SEC_CONTENT
naturally	SEC_CONTENT
continuous	SEC_CONTENT
,	SEC_CONTENT
than	SEC_CONTENT
with	SEC_CONTENT
language	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
we	SEC_CONTENT
see	SEC_CONTENT
much	SEC_CONTENT
better	SEC_CONTENT
results	SEC_CONTENT
from	SEC_CONTENT
VAT	SEC_CONTENT
on	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
CIFAR-10	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
on	SEC_CONTENT
our	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
still	SEC_CONTENT
find	SEC_CONTENT
incorporating	SEC_CONTENT
CVT	SEC_CONTENT
improves	SEC_CONTENT
over	SEC_CONTENT
models	SEC_CONTENT
without	SEC_CONTENT
CVT	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
CVT	SEC_CONTENT
+	SEC_CONTENT
VAT	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
competitive	SEC_CONTENT
with	SEC_CONTENT
current	SEC_CONTENT
start	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
found	SEC_CONTENT
the	SEC_CONTENT
gains	SEC_CONTENT
from	SEC_CONTENT
CVT	SEC_CONTENT
are	SEC_CONTENT
larger	SEC_CONTENT
when	SEC_CONTENT
no	task
data	task
augmentation	task
is	SEC_CONTENT
applied	SEC_CONTENT
,	SEC_CONTENT
perhaps	SEC_CONTENT
because	SEC_CONTENT
random	task
translations	task
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
expose	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
different	SEC_CONTENT
"	SEC_CONTENT
views	SEC_CONTENT
"	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
similar	SEC_CONTENT
manner	SEC_CONTENT
as	SEC_CONTENT
with	SEC_CONTENT
CVT	SEC_CONTENT
.	SEC_END
D	SECTITLE_START
Negative	SECTITLE_CONTENT
Results	SECTITLE_END
We	SEC_START
briefly	SEC_CONTENT
describe	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
ideas	SEC_CONTENT
we	SEC_CONTENT
implemented	SEC_CONTENT
that	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
seem	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
in	SEC_CONTENT
initial	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
these	SEC_CONTENT
findings	SEC_CONTENT
are	SEC_CONTENT
from	SEC_CONTENT
early	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
off	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
pursue	SEC_CONTENT
them	SEC_CONTENT
further	SEC_CONTENT
after	SEC_CONTENT
our	SEC_CONTENT
first	SEC_CONTENT
attempts	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
pan	SEC_CONTENT
out	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
possible	SEC_CONTENT
that	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
approaches	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
proper	SEC_CONTENT
adjustments	SEC_CONTENT
and	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_END
•	SEC_START
Hard	SEC_CONTENT
vs	SEC_CONTENT
soft	SEC_CONTENT
targets	SEC_CONTENT
:	SEC_CONTENT
Classic	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
algorithms	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
hot	SEC_CONTENT
"	SEC_CONTENT
hard	SEC_CONTENT
"	SEC_CONTENT
targets	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
's	SEC_CONTENT
highest	SEC_CONTENT
probability	SEC_CONTENT
prediction	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
decreased	SEC_CONTENT
performance	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
using	SEC_CONTENT
soft	SEC_CONTENT
targets	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
finding	SEC_CONTENT
is	SEC_CONTENT
consistent	SEC_CONTENT
with	SEC_CONTENT
research	SEC_CONTENT
on	SEC_CONTENT
knowledge	SEC_CONTENT
distillation	SEC_CONTENT
(	SEC_CONTENT
where	SEC_CONTENT
soft	SEC_CONTENT
targets	SEC_CONTENT
also	SEC_CONTENT
work	SEC_CONTENT
notably	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
hard	SEC_CONTENT
targets	SEC_CONTENT
.	SEC_END
•	SEC_START
Confidence	task
thresholding	task
:	SEC_CONTENT
Classic	SEC_CONTENT
selftraining	SEC_CONTENT
often	SEC_CONTENT
only	SEC_CONTENT
trains	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
examples	SEC_CONTENT
on	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
has	SEC_CONTENT
confident	SEC_CONTENT
predictions	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
distribution	SEC_CONTENT
has	SEC_CONTENT
low	SEC_CONTENT
entropy	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
tried	SEC_CONTENT
both	SEC_CONTENT
"	SEC_CONTENT
hard	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
ignores	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
confidence	SEC_CONTENT
examples	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
soft	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
where	SEC_CONTENT
examples	SEC_CONTENT
are	SEC_CONTENT
weighted	SEC_CONTENT
according	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
teacher	SEC_CONTENT
's	SEC_CONTENT
confidence	SEC_CONTENT
)	SEC_CONTENT
versions	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
they	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
seem	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
•	SEC_START
Mean	SEC_CONTENT
Teacher	SEC_CONTENT
:	SEC_CONTENT
The	SEC_CONTENT
Mean	SEC_CONTENT
Teacher	SEC_CONTENT
method	SEC_CONTENT
)	SEC_CONTENT
tracks	SEC_CONTENT
an	SEC_CONTENT
exponential	SEC_CONTENT
moving	SEC_CONTENT
average	SEC_CONTENT
(	SEC_CONTENT
EMA	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
model	SEC_CONTENT
weights	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
targets	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
students	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
idea	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
these	SEC_CONTENT
targets	SEC_CONTENT
maybe	SEC_CONTENT
better	SEC_CONTENT
quality	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
selfensembling	SEC_CONTENT
effect	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
have	SEC_CONTENT
little	SEC_CONTENT
to	SEC_CONTENT
no	SEC_CONTENT
benefit	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
using	SEC_CONTENT
EMA	SEC_CONTENT
model	SEC_CONTENT
weights	SEC_CONTENT
attest	SEC_CONTENT
time	SEC_CONTENT
did	SEC_CONTENT
improve	SEC_CONTENT
results	SEC_CONTENT
slightly	SEC_CONTENT
.	SEC_END
•	SEC_START
Purely	SEC_CONTENT
supervised	SEC_CONTENT
CVT	SEC_CONTENT
:	SEC_CONTENT
Lastly	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
explored	SEC_CONTENT
adding	SEC_CONTENT
cross	SEC_CONTENT
-	SEC_CONTENT
view	SEC_CONTENT
losses	SEC_CONTENT
to	SEC_CONTENT
purely	SEC_CONTENT
supervised	SEC_CONTENT
classifiers	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
hoped	SEC_CONTENT
that	SEC_CONTENT
adding	SEC_CONTENT
auxiliary	SEC_CONTENT
softmax	SEC_CONTENT
layers	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
views	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
would	SEC_CONTENT
act	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
regularizer	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
little	SEC_CONTENT
to	SEC_CONTENT
no	SEC_CONTENT
benefit	SEC_CONTENT
from	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
negative	SEC_CONTENT
result	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
gains	SEC_CONTENT
from	SEC_CONTENT
CVT	SEC_CONTENT
are	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
improved	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
learning	SEC_CONTENT
mechanism	SEC_CONTENT
,	SEC_CONTENT
not	SEC_CONTENT
the	SEC_CONTENT
additional	SEC_CONTENT
prediction	SEC_CONTENT
layers	SEC_CONTENT
regularizing	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
91.62	SEC_CONTENT
±	SEC_CONTENT
0.33	SEC_CONTENT
86.28	SEC_CONTENT
±	SEC_CONTENT
0.26	SEC_CONTENT
ID	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
(	SEC_CONTENT
90.65	SEC_CONTENT
±	SEC_CONTENT
0.15	SEC_CONTENT
86.84	SEC_CONTENT
±	SEC_CONTENT
0.19	SEC_CONTENT
Tri	SEC_CONTENT
-	SEC_CONTENT
Trained	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
94.7	SEC_CONTENT
Shortcut	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
95.08	SEC_CONTENT
97.53	SEC_CONTENT
JMT	SEC_CONTENT
*	SEC_CONTENT
(	SEC_CONTENT
95.77	SEC_CONTENT
97.55	SEC_CONTENT
94.67	SEC_CONTENT
92.90	SEC_CONTENT
LM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
CRF	SEC_CONTENT
(	SEC_CONTENT
95.96	SEC_CONTENT
±	SEC_CONTENT
0.08	SEC_CONTENT
91.71	SEC_CONTENT
±	SEC_CONTENT
0.10	SEC_CONTENT
97.53	SEC_CONTENT
±	SEC_CONTENT
0.03	SEC_CONTENT
TagLM	SEC_CONTENT
†	SEC_CONTENT
(	SEC_CONTENT
96.37	SEC_CONTENT
±	SEC_CONTENT
0.05	SEC_CONTENT
91.93	SEC_CONTENT
±	SEC_CONTENT
0.19	SEC_CONTENT
ELMo	SEC_CONTENT
†	SEC_CONTENT
(	SEC_CONTENT
92	SEC_CONTENT
:	SEC_CONTENT
Results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
means	SEC_CONTENT
and	SEC_CONTENT
standard	SEC_CONTENT
deviations	SEC_CONTENT
of	SEC_CONTENT
5	SEC_CONTENT
runs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
+	SEC_CONTENT
Larger	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
four	SEC_CONTENT
times	SEC_CONTENT
as	SEC_CONTENT
many	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
others	SEC_CONTENT
,	SEC_CONTENT
making	SEC_CONTENT
it	SEC_CONTENT
similar	SEC_CONTENT
in	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
when	SEC_CONTENT
ELMo	SEC_CONTENT
is	SEC_CONTENT
included	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
dependency	task
parsing	task
,	SEC_CONTENT
we	SEC_CONTENT
omit	SEC_CONTENT
results	SEC_CONTENT
from	SEC_CONTENT
Choe	SEC_CONTENT
and	SEC_CONTENT
Charniak	SEC_CONTENT
(	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Liu	SEC_CONTENT
and	SEC_CONTENT
Zhang	SEC_CONTENT
(	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
because	SEC_CONTENT
these	SEC_CONTENT
train	SEC_CONTENT
constituency	SEC_CONTENT
parsers	SEC_CONTENT
and	SEC_CONTENT
convert	SEC_CONTENT
the	SEC_CONTENT
system	SEC_CONTENT
outputs	SEC_CONTENT
to	SEC_CONTENT
dependency	SEC_CONTENT
parses	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
produce	SEC_CONTENT
higher	SEC_CONTENT
scores	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
have	SEC_CONTENT
access	SEC_CONTENT
to	SEC_CONTENT
more	SEC_CONTENT
information	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
apply	SEC_CONTENT
to	SEC_CONTENT
datasets	SEC_CONTENT
without	SEC_CONTENT
constituency	SEC_CONTENT
annotations	SEC_CONTENT
.	SEC_CONTENT
*	SEC_CONTENT
denotes	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
and	SEC_CONTENT
†	SEC_CONTENT
denotes	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
14.41	SEC_CONTENT
±	SEC_CONTENT
0.30	SEC_CONTENT
-VAT	SEC_CONTENT
(	SEC_CONTENT
13.15	SEC_CONTENT
10.55	SEC_CONTENT
VAdD	SEC_CONTENT
(	SEC_CONTENT
-11.68	SEC_CONTENT
±	SEC_CONTENT
0.19	SEC_CONTENT
VAdD	SEC_CONTENT
+	SEC_CONTENT
VAT	SEC_CONTENT
(	SEC_CONTENT
-10.07	SEC_CONTENT
±	SEC_CONTENT
0.11	SEC_CONTENT
SNGT	SEC_CONTENT
+	SEC_CONTENT
Π	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
13.62	SEC_CONTENT
±	SEC_CONTENT
0.17	SEC_CONTENT
11.00	SEC_CONTENT
±	SEC_CONTENT
0.36	SEC_CONTENT
SNGT	SEC_CONTENT
+	SEC_CONTENT
VAT	SEC_CONTENT
(	SEC_CONTENT
12.49	SEC_CONTENT
±	SEC_CONTENT
0.36	SEC_CONTENT
9.89	SEC_CONTENT
±	SEC_CONTENT
0.34	SEC_CONTENT
Consistency	SEC_CONTENT
+	SEC_CONTENT
WGAN	SEC_CONTENT
(	SEC_CONTENT
-9.98	SEC_CONTENT
±	SEC_CONTENT
0.21	SEC_CONTENT
Manifold	SEC_CONTENT
Mixup	SEC_CONTENT
(	SEC_CONTENT
-10.26	SEC_CONTENT
±	SEC_CONTENT
0.32	SEC_CONTENT
Supervised	SEC_CONTENT
23.61	SEC_CONTENT
±	SEC_CONTENT
0.60	SEC_CONTENT
19.61	SEC_CONTENT
±	SEC_CONTENT
0.56	SEC_CONTENT
VAT	SEC_CONTENT
(	SEC_CONTENT
ours	SEC_CONTENT
)	SEC_CONTENT
13.29	SEC_CONTENT
±	SEC_CONTENT
0.33	SEC_CONTENT
10.90	SEC_CONTENT
±	SEC_CONTENT
0.31	SEC_CONTENT
CVT	SEC_CONTENT
,	SEC_CONTENT
no	SEC_CONTENT
input	SEC_CONTENT
perturbation	SEC_CONTENT
14.63	SEC_CONTENT
±	SEC_CONTENT
0.20	SEC_CONTENT
12.44	SEC_CONTENT
±	SEC_CONTENT
0.27	SEC_CONTENT
CVT	SEC_CONTENT
,	SEC_CONTENT
random	SEC_CONTENT
input	SEC_CONTENT
perturbation	SEC_CONTENT
13.80	SEC_CONTENT
±	SEC_CONTENT
0.30	SEC_CONTENT
11.10	SEC_CONTENT
±	SEC_CONTENT
0.26	SEC_CONTENT
CVT	SEC_CONTENT
,	SEC_CONTENT
adversarial	SEC_CONTENT
input	SEC_CONTENT
perturbation	SEC_CONTENT
12.01	SEC_CONTENT
±	SEC_CONTENT
0.11	SEC_CONTENT
10.11	SEC_CONTENT
±	SEC_CONTENT
0.15	SEC_CONTENT
:	SEC_CONTENT
Error	SEC_CONTENT
rates	SEC_CONTENT
on	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
CIFAR-10	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
means	SEC_CONTENT
and	SEC_CONTENT
standard	SEC_CONTENT
deviations	SEC_CONTENT
from	SEC_CONTENT
5	SEC_CONTENT
runs	SEC_CONTENT
.	SEC_CONTENT
CIFAR-10	SEC_CONTENT
+	SEC_CONTENT
refers	SEC_CONTENT
to	SEC_CONTENT
results	SEC_CONTENT
where	SEC_CONTENT
data	SEC_CONTENT
augmentation	SEC_CONTENT
(	SEC_CONTENT
random	SEC_CONTENT
translations	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
image	SEC_CONTENT
)	SEC_CONTENT
was	SEC_CONTENT
applied	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
or	SEC_CONTENT
adversarially	SEC_CONTENT
chosen	SEC_CONTENT
perturbation	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
student	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
inputs	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
done	SEC_CONTENT
inmost	SEC_CONTENT
consistency	SEC_CONTENT
regularization	SEC_CONTENT
methods	SEC_CONTENT
.	SEC_END
Method	SECTITLE_END
Parameter	SECTITLE_END
