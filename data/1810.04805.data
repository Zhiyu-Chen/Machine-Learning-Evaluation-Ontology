title	SECTITLE_END
BERT	SEC_START
:	SEC_CONTENT
Pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
Deep	SEC_CONTENT
Bidirectional	SEC_CONTENT
Transformers	SEC_CONTENT
for	SEC_CONTENT
Language	SEC_CONTENT
Understanding	SEC_END
abstract	SECTITLE_END
We	SEC_START
introduce	SEC_CONTENT
anew	SEC_CONTENT
language	SEC_CONTENT
representation	SEC_CONTENT
model	SEC_CONTENT
called	SEC_CONTENT
BERT	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
stands	SEC_CONTENT
for	SEC_CONTENT
Bidirectional	SEC_CONTENT
Encoder	SEC_CONTENT
Representations	SEC_CONTENT
from	SEC_CONTENT
Transformers	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
recent	SEC_CONTENT
language	SEC_CONTENT
representation	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
Peters	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2018	SEC_CONTENT
;	SEC_CONTENT
Radford	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2018	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
BERT	SEC_CONTENT
is	SEC_CONTENT
designed	SEC_CONTENT
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
representations	SEC_CONTENT
by	SEC_CONTENT
jointly	SEC_CONTENT
conditioning	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
left	SEC_CONTENT
and	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
a	SEC_CONTENT
result	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
BERT	SEC_CONTENT
representations	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuned	SEC_CONTENT
with	SEC_CONTENT
just	SEC_CONTENT
one	SEC_CONTENT
additional	SEC_CONTENT
output	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
create	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
models	SEC_CONTENT
fora	SEC_CONTENT
wide	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
question	task
answering	task
and	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
,	SEC_CONTENT
without	SEC_CONTENT
substantial	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
architecture	SEC_CONTENT
modifications	SEC_CONTENT
.	SEC_CONTENT
BERT	SEC_CONTENT
is	SEC_CONTENT
conceptually	SEC_CONTENT
simple	SEC_CONTENT
and	SEC_CONTENT
empirically	SEC_CONTENT
powerful	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
obtains	SEC_CONTENT
new	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
eleven	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
pushing	SEC_CONTENT
the	SEC_CONTENT
GLUE	SEC_CONTENT
benchmark	SEC_CONTENT
to	SEC_CONTENT
80.4	SEC_CONTENT
%	SEC_CONTENT
(	SEC_CONTENT
7.6	SEC_CONTENT
%	SEC_CONTENT
absolute	SEC_CONTENT
improvement	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
MultiNLI	SEC_CONTENT
accuracy	SEC_CONTENT
to	SEC_CONTENT
86.7	SEC_CONTENT
%	SEC_CONTENT
(	SEC_CONTENT
5.6	SEC_CONTENT
%	SEC_CONTENT
absolute	SEC_CONTENT
improvement	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
SQuAD	SEC_CONTENT
v1.1	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
Test	SEC_CONTENT
F1	SEC_CONTENT
to	SEC_CONTENT
93.2	SEC_CONTENT
(	SEC_CONTENT
1.5	SEC_CONTENT
absolute	SEC_CONTENT
improvement	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
outperforming	SEC_CONTENT
human	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
2.0	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Language	SEC_START
model	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
has	SEC_CONTENT
shown	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
for	SEC_CONTENT
improving	SEC_CONTENT
many	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
tasks	SEC_CONTENT
include	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
paraphrasing	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
relationships	SEC_CONTENT
between	SEC_CONTENT
sentences	SEC_CONTENT
by	SEC_CONTENT
analyzing	SEC_CONTENT
them	metric
holistically	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
token	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
and	SEC_CONTENT
SQuAD	dataset
question	dataset
answering	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
required	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
grained	SEC_CONTENT
output	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
.	SEC_END
There	SEC_START
are	SEC_CONTENT
two	SEC_CONTENT
existing	SEC_CONTENT
strategies	SEC_CONTENT
for	SEC_CONTENT
applying	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
language	SEC_CONTENT
representations	SEC_CONTENT
to	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
and	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
ELMo	metric
(	SEC_CONTENT
,	SEC_CONTENT
uses	SEC_CONTENT
tasks	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
architectures	SEC_CONTENT
that	SEC_CONTENT
include	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
representations	SEC_CONTENT
as	SEC_CONTENT
additional	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
Generative	SEC_CONTENT
Pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
Transformer	SEC_CONTENT
(	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
introduces	SEC_CONTENT
minimal	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
parameters	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
by	SEC_CONTENT
simply	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
the	SEC_CONTENT
pretrained	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
both	SEC_CONTENT
approaches	SEC_CONTENT
share	SEC_CONTENT
the	task
same	task
objective	task
function	task
during	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
they	SEC_CONTENT
use	SEC_CONTENT
unidirectional	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
general	SEC_CONTENT
language	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_END
We	SEC_START
argue	SEC_CONTENT
that	SEC_CONTENT
current	SEC_CONTENT
techniques	SEC_CONTENT
severely	SEC_CONTENT
restrict	SEC_CONTENT
the	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
especially	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
major	SEC_CONTENT
limitation	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
standard	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
unidirectional	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
limits	SEC_CONTENT
the	SEC_CONTENT
choice	SEC_CONTENT
of	SEC_CONTENT
architectures	SEC_CONTENT
that	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
during	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
authors	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
leftto	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
every	SEC_CONTENT
token	SEC_CONTENT
can	SEC_CONTENT
only	SEC_CONTENT
attended	SEC_CONTENT
to	SEC_CONTENT
previous	SEC_CONTENT
tokens	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Transformer	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Such	SEC_CONTENT
restrictions	SEC_CONTENT
are	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
optimal	SEC_CONTENT
for	SEC_CONTENT
sentencelevel	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
devastating	SEC_CONTENT
when	SEC_CONTENT
applying	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
based	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
token	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
SQuAD	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
crucial	SEC_CONTENT
to	SEC_CONTENT
incorporate	SEC_CONTENT
context	metric
from	SEC_CONTENT
both	SEC_CONTENT
directions	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
based	SEC_CONTENT
approaches	SEC_CONTENT
by	SEC_CONTENT
proposing	SEC_CONTENT
BERT	SEC_CONTENT
:	SEC_CONTENT
Bidirectional	SEC_CONTENT
Encoder	SEC_CONTENT
Representations	SEC_CONTENT
from	SEC_CONTENT
Transformers	SEC_CONTENT
.	SEC_CONTENT
BERT	SEC_CONTENT
addresses	SEC_CONTENT
the	SEC_CONTENT
previously	SEC_CONTENT
mentioned	SEC_CONTENT
unidirectional	SEC_CONTENT
constraints	SEC_CONTENT
by	SEC_CONTENT
proposing	SEC_CONTENT
anew	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
objective	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
masked	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
MLM	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
inspired	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
Cloze	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
masked	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
randomly	SEC_CONTENT
masks	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
tokens	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
vocabulary	SEC_CONTENT
i	SEC_CONTENT
d	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
masked	SEC_CONTENT
word	SEC_CONTENT
based	SEC_CONTENT
only	SEC_CONTENT
on	SEC_CONTENT
its	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
MLM	SEC_CONTENT
objective	SEC_CONTENT
allows	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
to	SEC_CONTENT
fuse	SEC_CONTENT
the	SEC_CONTENT
left	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
Transformer	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
masked	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
introduce	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
next	SEC_CONTENT
sentence	SEC_CONTENT
prediction	SEC_CONTENT
"	SEC_CONTENT
task	SEC_CONTENT
that	SEC_CONTENT
jointly	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trains	SEC_CONTENT
text	SEC_CONTENT
-	SEC_CONTENT
pair	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_END
The	SEC_START
contributions	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
paper	SEC_CONTENT
are	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
•	SEC_START
We	SEC_CONTENT
demonstrate	SEC_CONTENT
the	SEC_CONTENT
importance	SEC_CONTENT
of	SEC_CONTENT
bidirectional	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
language	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
uses	SEC_CONTENT
unidirectional	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
pretraining	SEC_CONTENT
,	SEC_CONTENT
BERT	SEC_CONTENT
uses	SEC_CONTENT
masked	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
enable	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
in	SEC_CONTENT
contrast	SEC_CONTENT
to	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
shallow	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
independently	SEC_CONTENT
trained	SEC_CONTENT
leftto	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
and	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
left	SEC_CONTENT
LMs	SEC_CONTENT
.	SEC_END
•	SEC_START
We	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
representations	SEC_CONTENT
eliminate	SEC_CONTENT
the	SEC_CONTENT
needs	SEC_CONTENT
of	SEC_CONTENT
many	SEC_CONTENT
heavilyengineered	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
architectures	SEC_CONTENT
.	SEC_CONTENT
BERT	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
based	SEC_CONTENT
representation	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
achieves	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
suite	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
and	SEC_CONTENT
token	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
outperforming	SEC_CONTENT
many	SEC_CONTENT
systems	SEC_CONTENT
with	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
architectures	SEC_CONTENT
.	SEC_END
•	SEC_START
BERT	SEC_CONTENT
advances	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
for	SEC_CONTENT
eleven	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
report	SEC_CONTENT
extensive	SEC_CONTENT
ablations	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
,	SEC_CONTENT
demonstrating	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
bidirectional	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
single	SEC_CONTENT
most	SEC_CONTENT
important	SEC_CONTENT
new	SEC_CONTENT
contribution	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
code	SEC_CONTENT
and	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
available	SEC_CONTENT
at	SEC_CONTENT
goo.gl/language/bert	SEC_CONTENT
.	SEC_CONTENT
1	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
There	SEC_START
is	SEC_CONTENT
along	SEC_CONTENT
history	SEC_CONTENT
of	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
general	SEC_CONTENT
language	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
briefly	SEC_CONTENT
review	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
popular	SEC_CONTENT
approaches	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
.	SEC_END
Feature	SECTITLE_START
-	SECTITLE_CONTENT
based	SECTITLE_CONTENT
Approaches	SECTITLE_END
Learning	SEC_START
widely	SEC_CONTENT
applicable	SEC_CONTENT
representations	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
an	SEC_CONTENT
active	SEC_CONTENT
area	SEC_CONTENT
of	SEC_CONTENT
research	SEC_CONTENT
for	SEC_CONTENT
decades	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
neural	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
Will	SEC_CONTENT
be	SEC_CONTENT
released	SEC_CONTENT
before	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
of	SEC_CONTENT
October	SEC_CONTENT
2018	SEC_CONTENT
.	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
neural	SEC_CONTENT
)	SEC_CONTENT
methods	SEC_CONTENT
.	SEC_CONTENT
Pretrained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
considered	SEC_CONTENT
to	SEC_CONTENT
bean	SEC_CONTENT
integral	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
modern	SEC_CONTENT
NLP	SEC_CONTENT
systems	SEC_CONTENT
,	SEC_CONTENT
offering	SEC_CONTENT
significant	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
embeddings	SEC_CONTENT
learned	SEC_CONTENT
from	SEC_CONTENT
scratch	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
approaches	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
generalized	SEC_CONTENT
to	SEC_CONTENT
coarser	SEC_CONTENT
granularities	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
sentence	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
or	SEC_CONTENT
paragraph	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
with	SEC_CONTENT
traditional	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
learned	SEC_CONTENT
representations	SEC_CONTENT
are	SEC_CONTENT
also	SEC_CONTENT
typically	SEC_CONTENT
used	SEC_CONTENT
as	SEC_CONTENT
features	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
downstream	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
)	SEC_CONTENT
generalizes	SEC_CONTENT
traditional	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
research	SEC_CONTENT
along	SEC_CONTENT
a	SEC_CONTENT
different	SEC_CONTENT
dimension	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
propose	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
contextsensitive	SEC_CONTENT
features	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
integrating	SEC_CONTENT
contextual	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
with	SEC_CONTENT
existing	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
architectures	SEC_CONTENT
,	SEC_CONTENT
ELMo	metric
advances	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
for	SEC_CONTENT
several	SEC_CONTENT
major	SEC_CONTENT
NLP	SEC_CONTENT
benchmarks	SEC_CONTENT
(	SEC_CONTENT
including	SEC_CONTENT
question	task
answering	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
SQuAD	SEC_CONTENT
,	SEC_CONTENT
sentiment	SEC_CONTENT
analysis	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Fine	SECTITLE_START
-	SECTITLE_CONTENT
tuning	SECTITLE_CONTENT
Approaches	SECTITLE_END
A	SEC_START
recent	SEC_CONTENT
trend	SEC_CONTENT
in	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
from	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
LMs	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
some	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
LM	SEC_CONTENT
objective	SEC_CONTENT
before	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
that	SEC_CONTENT
same	SEC_CONTENT
model	SEC_CONTENT
fora	SEC_CONTENT
supervised	SEC_CONTENT
downstream	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
approaches	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
few	SEC_CONTENT
parameters	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
learned	SEC_CONTENT
from	SEC_CONTENT
scratch	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
least	SEC_CONTENT
partly	SEC_CONTENT
due	SEC_CONTENT
this	SEC_CONTENT
advantage	SEC_CONTENT
,	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
achieved	SEC_CONTENT
previously	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
many	SEC_CONTENT
sentencelevel	SEC_CONTENT
tasks	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
GLUE	SEC_CONTENT
benchmark	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Transfer	SECTITLE_START
Learning	SECTITLE_CONTENT
from	SECTITLE_CONTENT
Supervised	SECTITLE_CONTENT
Data	SECTITLE_END
While	SEC_START
the	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
unsupervised	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
nearly	SEC_CONTENT
unlimited	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
data	SEC_CONTENT
available	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
has	SEC_CONTENT
also	SEC_CONTENT
been	SEC_CONTENT
work	SEC_CONTENT
showing	SEC_CONTENT
effective	SEC_CONTENT
transfer	SEC_CONTENT
from	SEC_CONTENT
supervised	SEC_CONTENT
tasks	SEC_CONTENT
with	SEC_CONTENT
large	SEC_CONTENT
datasets	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
.	SEC_CONTENT
Outside	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
,	SEC_CONTENT
computer	SEC_CONTENT
vision	SEC_CONTENT
research	SEC_CONTENT
has	SEC_CONTENT
also	SEC_CONTENT
demonstrated	SEC_CONTENT
the	SEC_CONTENT
importance	SEC_CONTENT
of	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
from	SEC_CONTENT
large	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
an	SEC_CONTENT
effective	SEC_CONTENT
recipe	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_END
BERT	SECTITLE_END
We	SEC_START
introduce	SEC_CONTENT
BERT	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
detailed	SEC_CONTENT
implementation	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
first	SEC_CONTENT
cover	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
representation	SEC_CONTENT
for	SEC_CONTENT
BERT	SEC_CONTENT
.	SEC_END
We	SEC_START
then	SEC_CONTENT
introduce	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
core	SEC_CONTENT
innovation	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3.3	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
procedures	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
procedures	SEC_CONTENT
are	SEC_CONTENT
detailed	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3.4	SEC_CONTENT
and	SEC_CONTENT
3.5	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
differences	SEC_CONTENT
between	SEC_CONTENT
BERT	SEC_CONTENT
and	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
are	SEC_CONTENT
discussed	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3.6	SEC_CONTENT
.	SEC_END
Model	SECTITLE_START
Architecture	SECTITLE_END
BERT	SEC_START
's	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
bidirectional	SEC_CONTENT
Transformer	SEC_CONTENT
encoder	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
implementation	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
and	SEC_CONTENT
released	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
tensor2tensor	SEC_CONTENT
library	SEC_CONTENT
.	SEC_CONTENT
Because	SEC_CONTENT
the	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
Transformers	SEC_CONTENT
has	SEC_CONTENT
become	SEC_CONTENT
ubiquitous	SEC_CONTENT
recently	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
implementation	SEC_CONTENT
is	SEC_CONTENT
effectively	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
omit	SEC_CONTENT
an	SEC_CONTENT
exhaustive	SEC_CONTENT
background	SEC_CONTENT
description	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
and	SEC_CONTENT
refer	SEC_CONTENT
readers	SEC_CONTENT
to	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
excellent	SEC_CONTENT
guides	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
"	SEC_CONTENT
The	SEC_CONTENT
Annotated	SEC_CONTENT
Transformer	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
layers	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
Transformer	SEC_CONTENT
blocks	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
L	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
size	SEC_CONTENT
as	SEC_CONTENT
H	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
heads	SEC_CONTENT
as	SEC_CONTENT
A.	SEC_CONTENT
In	SEC_CONTENT
all	SEC_CONTENT
cases	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
/	SEC_CONTENT
filter	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
4H	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
3072	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
768	SEC_CONTENT
and	SEC_CONTENT
4096	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
1024	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
primarily	SEC_CONTENT
report	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
two	task
model	task
sizes	task
:	SEC_END
•	SEC_START
BERT	SEC_CONTENT
BASE	SEC_CONTENT
was	SEC_CONTENT
chosen	SEC_CONTENT
to	SEC_CONTENT
have	SEC_CONTENT
an	SEC_CONTENT
identical	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
as	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
for	SEC_CONTENT
comparison	task
purposes	task
.	SEC_CONTENT
Critically	SEC_CONTENT
,	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
BERT	SEC_CONTENT
Transformer	SEC_CONTENT
uses	SEC_CONTENT
bidirectional	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
GPT	SEC_CONTENT
Transformer	SEC_CONTENT
uses	SEC_CONTENT
constrained	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
where	SEC_CONTENT
every	SEC_CONTENT
token	SEC_CONTENT
can	SEC_CONTENT
only	SEC_CONTENT
attend	SEC_CONTENT
to	SEC_CONTENT
context	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
left	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
the	SEC_CONTENT
bidirectional	SEC_CONTENT
Transformer	SEC_CONTENT
is	SEC_CONTENT
often	SEC_CONTENT
referred	SEC_CONTENT
to	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
Transformer	SEC_CONTENT
encoder	SEC_CONTENT
"	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
only	SEC_CONTENT
version	SEC_CONTENT
is	SEC_CONTENT
referred	SEC_CONTENT
to	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
Transformer	SEC_CONTENT
decoder	SEC_CONTENT
"	SEC_CONTENT
since	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
text	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
comparisons	SEC_CONTENT
between	SEC_CONTENT
BERT	SEC_CONTENT
,	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
and	SEC_CONTENT
ELMo	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
visually	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Input	SECTITLE_START
Representation	SECTITLE_END
Our	SEC_START
input	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
unambiguously	SEC_CONTENT
represent	SEC_CONTENT
both	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
text	SEC_CONTENT
sentence	SEC_CONTENT
or	SEC_CONTENT
a	SEC_CONTENT
pair	SEC_CONTENT
of	SEC_CONTENT
text	SEC_CONTENT
sentences	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
one	task
token	task
sequence	task
.	SEC_CONTENT
For	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
token	SEC_CONTENT
,	SEC_CONTENT
its	SEC_CONTENT
input	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
constructed	SEC_CONTENT
by	SEC_CONTENT
summing	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
token	SEC_CONTENT
,	SEC_CONTENT
segment	SEC_CONTENT
and	SEC_CONTENT
position	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
visual	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
input	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
The	SEC_START
specifics	SEC_CONTENT
are	SEC_CONTENT
:	SEC_END
•	SEC_START
We	SEC_CONTENT
use	SEC_CONTENT
WordPiece	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
30,000	SEC_CONTENT
token	SEC_CONTENT
vocabulary	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
denote	SEC_CONTENT
split	SEC_CONTENT
word	SEC_CONTENT
pieces	SEC_CONTENT
with	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
.	SEC_END
•	SEC_START
We	SEC_CONTENT
use	SEC_CONTENT
learned	SEC_CONTENT
positional	SEC_CONTENT
embeddings	SEC_CONTENT
with	SEC_CONTENT
supported	SEC_CONTENT
sequence	SEC_CONTENT
lengths	SEC_CONTENT
up	SEC_CONTENT
to	SEC_CONTENT
512	SEC_CONTENT
tokens	SEC_CONTENT
.	SEC_END
[	SEC_START
CLS	SEC_CONTENT
]	SEC_END
he	SEC_START
likes	SEC_CONTENT
play	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
ing	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
cute	SEC_CONTENT
Input	SEC_CONTENT
E	SEC_CONTENT
E	SEC_END
Position	SECTITLE_START
Embeddings	SECTITLE_END
Figure	SEC_START
2	SEC_CONTENT
:	SEC_CONTENT
BERT	SEC_CONTENT
input	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
segmentation	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
the	task
position	task
embeddings	task
.	SEC_END
•	SEC_START
The	SEC_CONTENT
first	SEC_CONTENT
token	SEC_CONTENT
of	SEC_CONTENT
every	SEC_CONTENT
sequence	SEC_CONTENT
is	SEC_CONTENT
always	SEC_CONTENT
the	SEC_CONTENT
special	SEC_CONTENT
classification	SEC_CONTENT
embedding	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
Transformer	SEC_CONTENT
)	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
token	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
aggregate	SEC_CONTENT
sequence	SEC_CONTENT
representation	SEC_CONTENT
for	SEC_CONTENT
classification	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
nonclassification	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
vector	SEC_CONTENT
is	SEC_CONTENT
ignored	SEC_CONTENT
.	SEC_END
•	SEC_START
Sentence	SEC_CONTENT
pairs	SEC_CONTENT
are	SEC_CONTENT
packed	SEC_CONTENT
together	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
differentiate	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
two	SEC_CONTENT
ways	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
separate	SEC_CONTENT
them	metric
with	SEC_CONTENT
a	SEC_CONTENT
special	SEC_CONTENT
token	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
a	SEC_CONTENT
learned	SEC_CONTENT
sentence	SEC_CONTENT
A	SEC_CONTENT
embedding	SEC_CONTENT
to	SEC_CONTENT
every	SEC_CONTENT
token	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
B	SEC_CONTENT
embedding	SEC_CONTENT
to	SEC_CONTENT
every	SEC_CONTENT
token	SEC_CONTENT
of	SEC_CONTENT
the	task
second	task
sentence	task
.	SEC_END
•	SEC_START
For	SEC_CONTENT
single	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
inputs	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
A	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_END
Pre	SECTITLE_START
-	SECTITLE_CONTENT
training	SECTITLE_CONTENT
Tasks	SECTITLE_END
Unlike	SEC_START
Peters	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
and	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
use	SEC_CONTENT
traditional	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
or	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
left	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
BERT	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
BERT	SEC_CONTENT
using	SEC_CONTENT
two	SEC_CONTENT
novel	SEC_CONTENT
unsupervised	SEC_CONTENT
prediction	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
.	SEC_END
Task	SECTITLE_START
#	SECTITLE_CONTENT
1	SECTITLE_CONTENT
:	SECTITLE_CONTENT
Masked	SECTITLE_CONTENT
LM	SECTITLE_END
Intuitively	SEC_START
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
reasonable	SEC_CONTENT
to	SEC_CONTENT
believe	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
strictly	SEC_CONTENT
more	SEC_CONTENT
powerful	SEC_CONTENT
than	SEC_CONTENT
either	SEC_CONTENT
a	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
model	SEC_CONTENT
or	SEC_CONTENT
the	SEC_CONTENT
shallow	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
and	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
toleft	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Unfortunately	SEC_CONTENT
,	SEC_CONTENT
standard	SEC_CONTENT
conditional	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
can	SEC_CONTENT
only	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
or	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
left	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
bidirectional	task
conditioning	task
would	SEC_CONTENT
allow	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
to	SEC_CONTENT
indirectly	SEC_CONTENT
"	SEC_CONTENT
see	SEC_CONTENT
itself	SEC_CONTENT
"	SEC_CONTENT
in	SEC_CONTENT
a	metric
multi	metric
-	metric
layered	metric
context	metric
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
representation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
take	SEC_CONTENT
a	SEC_CONTENT
straightforward	SEC_CONTENT
approach	SEC_CONTENT
of	SEC_CONTENT
masking	SEC_CONTENT
some	SEC_CONTENT
percentage	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
tokens	SEC_CONTENT
at	SEC_CONTENT
random	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
predicting	SEC_CONTENT
only	SEC_CONTENT
those	SEC_CONTENT
masked	SEC_CONTENT
tokens	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
procedure	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
"	SEC_CONTENT
masked	SEC_CONTENT
LM	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
MLM	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
often	SEC_CONTENT
referred	SEC_CONTENT
to	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
Cloze	SEC_CONTENT
task	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
vectors	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
mask	SEC_CONTENT
tokens	SEC_CONTENT
are	SEC_CONTENT
fed	SEC_CONTENT
into	SEC_CONTENT
an	SEC_CONTENT
output	SEC_CONTENT
softmax	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
LM	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
mask	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
WordPiece	SEC_CONTENT
tokens	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
sequence	SEC_CONTENT
at	SEC_CONTENT
random	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
to	SEC_CONTENT
denoising	SEC_CONTENT
auto	SEC_CONTENT
-	SEC_CONTENT
encoders	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
masked	SEC_CONTENT
words	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
reconstructing	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
input	SEC_CONTENT
.	SEC_END
Although	SEC_START
this	SEC_CONTENT
does	SEC_CONTENT
allow	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
a	SEC_CONTENT
bidirectional	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
two	SEC_CONTENT
downsides	SEC_CONTENT
to	SEC_CONTENT
such	SEC_CONTENT
an	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
creating	SEC_CONTENT
a	SEC_CONTENT
mismatch	SEC_CONTENT
between	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
finetuning	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
is	SEC_CONTENT
never	SEC_CONTENT
seen	SEC_CONTENT
during	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
mitigate	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
always	SEC_CONTENT
replace	SEC_CONTENT
"	SEC_CONTENT
masked	SEC_CONTENT
"	SEC_CONTENT
words	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
actual	SEC_CONTENT
token	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
generator	SEC_CONTENT
chooses	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
tokens	SEC_CONTENT
at	SEC_CONTENT
random	SEC_CONTENT
,	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
hairy	SEC_CONTENT
it	SEC_CONTENT
chooses	SEC_CONTENT
hairy	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
then	SEC_CONTENT
performs	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
procedure	SEC_CONTENT
:	SEC_END
•	SEC_START
Rather	SEC_CONTENT
than	SEC_CONTENT
always	SEC_CONTENT
replacing	SEC_CONTENT
the	SEC_CONTENT
chosen	SEC_CONTENT
words	SEC_CONTENT
with	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
generator	SEC_CONTENT
will	SEC_CONTENT
do	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
:	SEC_END
•	SEC_START
80	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
:	SEC_CONTENT
Replace	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
,	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
hairy	SEC_CONTENT
→	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
•	SEC_CONTENT
10	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
:	SEC_CONTENT
Replace	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
hairy	SEC_CONTENT
→	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
apple	SEC_END
•	SEC_START
10	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
:	SEC_CONTENT
Keep	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
unchanged	SEC_CONTENT
,	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
hairy	SEC_CONTENT
→	SEC_CONTENT
my	SEC_CONTENT
dog	SEC_CONTENT
is	SEC_CONTENT
hairy	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
purpose	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
bias	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
towards	SEC_CONTENT
the	SEC_CONTENT
actual	SEC_CONTENT
observed	SEC_CONTENT
word	SEC_CONTENT
.	SEC_END
The	SEC_START
Transformer	SEC_CONTENT
encoder	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
know	SEC_CONTENT
which	SEC_CONTENT
words	SEC_CONTENT
it	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
asked	SEC_CONTENT
to	SEC_CONTENT
predictor	SEC_CONTENT
which	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
replaced	SEC_CONTENT
by	SEC_CONTENT
random	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
forced	SEC_CONTENT
to	SEC_CONTENT
keep	SEC_CONTENT
a	SEC_CONTENT
distributional	SEC_CONTENT
contextual	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
every	SEC_CONTENT
input	SEC_CONTENT
token	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
random	SEC_CONTENT
replacement	SEC_CONTENT
only	SEC_CONTENT
occurs	SEC_CONTENT
for	SEC_CONTENT
1.5	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
tokens	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
10	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
seem	SEC_CONTENT
to	SEC_CONTENT
harm	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
capability	SEC_CONTENT
.	SEC_END
The	SEC_START
second	SEC_CONTENT
downside	SEC_CONTENT
of	SEC_CONTENT
using	SEC_CONTENT
an	SEC_CONTENT
MLM	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
only	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
tokens	SEC_CONTENT
are	SEC_CONTENT
predicted	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
batch	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
more	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
steps	SEC_CONTENT
maybe	SEC_CONTENT
required	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
converge	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
Section	SEC_CONTENT
5.3	SEC_CONTENT
we	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
MLM	SEC_CONTENT
does	SEC_CONTENT
converge	SEC_CONTENT
marginally	SEC_CONTENT
slower	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
which	SEC_CONTENT
predicts	SEC_CONTENT
every	SEC_CONTENT
token	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
the	SEC_CONTENT
empirical	SEC_CONTENT
improvements	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
MLM	SEC_CONTENT
model	SEC_CONTENT
far	SEC_CONTENT
outweigh	SEC_CONTENT
the	SEC_CONTENT
increased	SEC_CONTENT
training	SEC_CONTENT
cost	SEC_CONTENT
.	SEC_END
Task	SECTITLE_START
#	SECTITLE_CONTENT
2	SECTITLE_CONTENT
:	SECTITLE_CONTENT
Next	SECTITLE_CONTENT
Sentence	SECTITLE_CONTENT
Prediction	SECTITLE_END
Many	SEC_START
important	SEC_CONTENT
downstream	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
Question	task
Answering	task
(	SEC_CONTENT
QA	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
Natural	SEC_CONTENT
Language	SEC_CONTENT
Inference	SEC_CONTENT
(	SEC_CONTENT
NLI	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
understanding	SEC_CONTENT
the	SEC_CONTENT
relationship	SEC_CONTENT
between	SEC_CONTENT
two	SEC_CONTENT
text	SEC_CONTENT
sentences	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
directly	SEC_CONTENT
captured	SEC_CONTENT
by	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
understands	SEC_CONTENT
sentence	SEC_CONTENT
relationships	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
binarized	SEC_CONTENT
next	SEC_CONTENT
sentence	SEC_CONTENT
prediction	SEC_CONTENT
task	SEC_CONTENT
that	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trivially	SEC_CONTENT
generated	SEC_CONTENT
from	SEC_CONTENT
any	SEC_CONTENT
monolingual	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
choosing	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
A	SEC_CONTENT
and	SEC_CONTENT
B	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
pretraining	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
50	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
B	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
actual	SEC_CONTENT
next	SEC_CONTENT
sentence	SEC_CONTENT
that	SEC_CONTENT
follows	SEC_CONTENT
A	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
50	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
sentence	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_END
We	SEC_START
choose	SEC_CONTENT
the	SEC_CONTENT
NotNext	SEC_CONTENT
sentences	SEC_CONTENT
completely	SEC_CONTENT
at	SEC_CONTENT
random	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
97%-98	metric
%	metric
accuracy	metric
at	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Despite	SEC_CONTENT
its	SEC_CONTENT
simplicity	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
demonstrate	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
5.1	SEC_CONTENT
that	SEC_CONTENT
pretraining	SEC_CONTENT
towards	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
beneficial	SEC_CONTENT
to	SEC_CONTENT
both	SEC_CONTENT
QA	SEC_CONTENT
and	SEC_CONTENT
NLI	SEC_CONTENT
.	SEC_END
Pre	SECTITLE_START
-	SECTITLE_CONTENT
training	SECTITLE_CONTENT
Procedure	SECTITLE_END
The	SEC_START
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
largely	SEC_CONTENT
follows	SEC_CONTENT
the	SEC_CONTENT
existing	SEC_CONTENT
literature	SEC_CONTENT
on	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
For	SEC_START
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
BooksCorpus	SEC_CONTENT
(	SEC_CONTENT
800	SEC_CONTENT
M	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
English	SEC_CONTENT
Wikipedia	SEC_CONTENT
(	SEC_CONTENT
2,500	SEC_CONTENT
M	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
Wikipedia	SEC_CONTENT
we	SEC_CONTENT
extract	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
text	SEC_CONTENT
passages	SEC_CONTENT
and	SEC_CONTENT
ignore	SEC_CONTENT
lists	SEC_CONTENT
,	SEC_CONTENT
tables	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
headers	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
critical	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
document	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
corpus	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
shuffled	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
corpus	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
Billion	SEC_CONTENT
Word	SEC_CONTENT
Benchmark	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
long	SEC_CONTENT
contiguous	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_END
To	SEC_START
generate	SEC_CONTENT
each	SEC_CONTENT
training	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
sample	SEC_CONTENT
two	SEC_CONTENT
spans	SEC_CONTENT
of	SEC_CONTENT
text	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
as	SEC_CONTENT
"	SEC_CONTENT
sentences	SEC_CONTENT
"	SEC_CONTENT
even	SEC_CONTENT
though	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
typically	SEC_CONTENT
much	SEC_CONTENT
longer	SEC_CONTENT
than	SEC_CONTENT
single	SEC_CONTENT
sentences	SEC_CONTENT
(	SEC_CONTENT
but	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
shorter	SEC_CONTENT
also	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
sentence	SEC_CONTENT
receives	SEC_CONTENT
the	SEC_CONTENT
A	SEC_CONTENT
embedding	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
receives	SEC_CONTENT
the	SEC_CONTENT
B	SEC_CONTENT
embedding	SEC_CONTENT
.	SEC_CONTENT
50	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
B	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
actual	SEC_CONTENT
next	SEC_CONTENT
sentence	SEC_CONTENT
that	SEC_CONTENT
follows	SEC_CONTENT
A	SEC_CONTENT
and	SEC_CONTENT
50	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
done	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
next	SEC_CONTENT
sentence	SEC_CONTENT
prediction	SEC_CONTENT
"	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
are	SEC_CONTENT
sampled	SEC_CONTENT
such	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
combined	SEC_CONTENT
length	SEC_CONTENT
is	SEC_CONTENT
≤	SEC_CONTENT
512	SEC_CONTENT
tokens	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
LM	SEC_CONTENT
masking	SEC_CONTENT
is	SEC_CONTENT
applied	SEC_CONTENT
after	SEC_CONTENT
WordPiece	SEC_CONTENT
tokenization	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
uniform	SEC_CONTENT
masking	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
no	task
special	task
consideration	task
given	SEC_CONTENT
to	SEC_CONTENT
partial	SEC_CONTENT
word	SEC_CONTENT
pieces	SEC_CONTENT
.	SEC_END
We	SEC_START
train	SEC_CONTENT
with	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
256	SEC_CONTENT
sequences	SEC_CONTENT
(	SEC_CONTENT
256	SEC_CONTENT
sequences	SEC_CONTENT
*	SEC_CONTENT
512	SEC_CONTENT
tokens	SEC_CONTENT
=	SEC_CONTENT
128,000	SEC_CONTENT
tokens	SEC_CONTENT
/	SEC_CONTENT
batch	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
1,000,000	SEC_CONTENT
steps	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
approximately	SEC_CONTENT
40	SEC_CONTENT
epochs	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
3.3	SEC_CONTENT
billion	SEC_CONTENT
word	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
Adam	SEC_CONTENT
with	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
1e-4	SEC_CONTENT
,	SEC_CONTENT
β	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
0.9	SEC_CONTENT
,	SEC_CONTENT
β	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
0.999	SEC_CONTENT
,	SEC_CONTENT
L2	SEC_CONTENT
weight	SEC_CONTENT
decay	SEC_CONTENT
of	SEC_CONTENT
0.01	SEC_CONTENT
,	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
warmup	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
10,000	SEC_CONTENT
steps	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
linear	SEC_CONTENT
decay	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
dropout	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
0.1	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
gelu	SEC_CONTENT
activation	SEC_CONTENT
)	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
relu	SEC_CONTENT
,	SEC_CONTENT
following	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
training	SEC_CONTENT
loss	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
mean	SEC_CONTENT
masked	SEC_CONTENT
LM	SEC_CONTENT
likelihood	SEC_CONTENT
and	SEC_CONTENT
mean	SEC_CONTENT
next	task
sentence	task
prediction	task
likelihood	task
.	SEC_END
Training	SEC_START
of	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
was	SEC_CONTENT
performed	SEC_CONTENT
on	SEC_CONTENT
4	SEC_CONTENT
Cloud	SEC_CONTENT
TPUs	SEC_CONTENT
in	SEC_CONTENT
Pod	SEC_CONTENT
configuration	SEC_CONTENT
(	SEC_CONTENT
16	SEC_CONTENT
TPU	SEC_CONTENT
chips	SEC_CONTENT
total	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Training	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
was	SEC_CONTENT
performed	SEC_CONTENT
on	SEC_CONTENT
16	SEC_CONTENT
Cloud	SEC_CONTENT
TPUs	SEC_CONTENT
(	SEC_CONTENT
64	SEC_CONTENT
TPU	SEC_CONTENT
chips	SEC_CONTENT
total	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
pretraining	SEC_CONTENT
took	SEC_CONTENT
4	SEC_CONTENT
days	SEC_CONTENT
to	SEC_CONTENT
complete	SEC_CONTENT
.	SEC_END
Fine	SECTITLE_START
-	SECTITLE_CONTENT
tuning	SECTITLE_CONTENT
Procedure	SECTITLE_END
For	SEC_START
sequence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
classification	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
BERT	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
is	SEC_CONTENT
straightforward	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
pooled	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
take	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Transformer	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
token	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
by	SEC_CONTENT
construction	SEC_CONTENT
corresponds	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
the	SEC_CONTENT
special	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
denote	SEC_CONTENT
this	SEC_CONTENT
vector	SEC_CONTENT
as	SEC_CONTENT
C	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
only	SEC_CONTENT
new	SEC_CONTENT
parameters	SEC_CONTENT
added	SEC_CONTENT
during	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
are	SEC_CONTENT
fora	SEC_CONTENT
classification	SEC_CONTENT
layer	SEC_CONTENT
W	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
K×H	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
K	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
classifier	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
label	SEC_CONTENT
probabilities	SEC_CONTENT
P	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
K	SEC_CONTENT
are	SEC_CONTENT
computed	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
softmax	SEC_CONTENT
,	SEC_CONTENT
P	SEC_CONTENT
=	SEC_CONTENT
softmax(CW	SEC_CONTENT
T	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
and	SEC_CONTENT
Ware	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuned	SEC_CONTENT
jointly	SEC_CONTENT
to	SEC_CONTENT
maximize	SEC_CONTENT
the	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
label	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
spanlevel	SEC_CONTENT
and	SEC_CONTENT
token	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
prediction	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
procedure	SEC_CONTENT
must	SEC_CONTENT
be	SEC_CONTENT
modified	SEC_CONTENT
slightly	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
taskspecific	SEC_CONTENT
manner	SEC_CONTENT
.	SEC_CONTENT
Details	SEC_CONTENT
are	SEC_CONTENT
given	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
subsection	SEC_CONTENT
of	SEC_CONTENT
Section	SEC_CONTENT
4	SEC_CONTENT
.	SEC_END
For	SEC_START
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
model	SEC_CONTENT
hyperparameters	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
exception	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
,	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
dropout	SEC_CONTENT
probability	SEC_CONTENT
was	SEC_CONTENT
always	SEC_CONTENT
kept	SEC_CONTENT
at	SEC_CONTENT
0.1	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
optimal	SEC_CONTENT
hyperparameter	SEC_CONTENT
values	SEC_CONTENT
are	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
values	SEC_CONTENT
to	SEC_CONTENT
work	SEC_CONTENT
well	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_END
•	SEC_START
Batch	SEC_CONTENT
size	SEC_CONTENT
:	SEC_CONTENT
16	SEC_CONTENT
,	SEC_CONTENT
32	SEC_CONTENT
•	SEC_CONTENT
Learning	SEC_CONTENT
rate	SEC_CONTENT
(	SEC_CONTENT
Adam	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
5e-5	SEC_CONTENT
,	SEC_CONTENT
3e-5	SEC_CONTENT
,	SEC_CONTENT
2e-5	SEC_CONTENT
•	SEC_CONTENT
Number	SEC_CONTENT
of	SEC_CONTENT
epochs	SEC_CONTENT
:	SEC_CONTENT
3	SEC_CONTENT
,	SEC_CONTENT
4	SEC_END
We	SEC_START
also	SEC_CONTENT
observed	SEC_CONTENT
that	SEC_CONTENT
large	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
100k+	SEC_CONTENT
labeled	SEC_CONTENT
training	SEC_CONTENT
examples	SEC_CONTENT
)	SEC_CONTENT
were	SEC_CONTENT
far	SEC_CONTENT
less	SEC_CONTENT
sensitive	SEC_CONTENT
to	SEC_CONTENT
hyperparameter	SEC_CONTENT
choice	SEC_CONTENT
than	SEC_CONTENT
small	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
Fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
is	SEC_CONTENT
typically	SEC_CONTENT
very	SEC_CONTENT
fast	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
reasonable	SEC_CONTENT
to	SEC_CONTENT
simply	SEC_CONTENT
run	SEC_CONTENT
an	SEC_CONTENT
exhaustive	SEC_CONTENT
search	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
parameters	SEC_CONTENT
and	SEC_CONTENT
choose	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
performs	SEC_CONTENT
best	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Comparison	SECTITLE_START
of	SECTITLE_CONTENT
BERT	SECTITLE_CONTENT
and	SECTITLE_CONTENT
OpenAI	SECTITLE_CONTENT
GPT	SECTITLE_END
The	SEC_START
most	SEC_CONTENT
comparable	SEC_CONTENT
existing	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
method	SEC_CONTENT
to	SEC_CONTENT
BERT	SEC_CONTENT
is	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
trains	SEC_CONTENT
a	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
toright	SEC_CONTENT
Transformer	SEC_CONTENT
LM	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
text	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
many	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
design	SEC_CONTENT
decisions	SEC_CONTENT
in	SEC_CONTENT
BERT	SEC_CONTENT
were	SEC_CONTENT
intentionally	SEC_CONTENT
chosen	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
as	SEC_CONTENT
close	SEC_CONTENT
to	SEC_CONTENT
GPT	SEC_CONTENT
as	SEC_CONTENT
possible	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
methods	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
minimally	SEC_CONTENT
compared	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
core	SEC_CONTENT
argument	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
novel	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
tasks	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3.3	SEC_CONTENT
account	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
majority	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
empirical	SEC_CONTENT
improvements	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
several	SEC_CONTENT
other	SEC_CONTENT
differences	SEC_CONTENT
between	SEC_CONTENT
how	SEC_CONTENT
BERT	SEC_CONTENT
and	SEC_CONTENT
GPT	SEC_CONTENT
were	SEC_CONTENT
trained	SEC_CONTENT
:	SEC_END
•	SEC_START
GPT	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
BooksCorpus	SEC_CONTENT
(	SEC_CONTENT
800	SEC_CONTENT
M	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
BERT	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
BooksCorpus	SEC_CONTENT
(	SEC_CONTENT
800	SEC_CONTENT
M	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
Wikipedia	SEC_CONTENT
(	SEC_CONTENT
2,500	SEC_CONTENT
M	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
•	SEC_START
GPT	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
separator	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
classifier	SEC_CONTENT
token	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
only	SEC_CONTENT
introduced	SEC_CONTENT
at	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
time	SEC_CONTENT
;	SEC_CONTENT
BERT	SEC_CONTENT
learns	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
sentence	SEC_CONTENT
A	SEC_CONTENT
/	SEC_CONTENT
B	SEC_CONTENT
embeddings	SEC_CONTENT
during	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
•	SEC_START
GPT	SEC_CONTENT
was	SEC_CONTENT
trained	SEC_CONTENT
for	SEC_CONTENT
1	SEC_CONTENT
M	SEC_CONTENT
steps	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
32,000	SEC_CONTENT
words	SEC_CONTENT
;	SEC_CONTENT
BERT	SEC_CONTENT
was	SEC_CONTENT
trained	SEC_CONTENT
for	SEC_CONTENT
1	SEC_CONTENT
M	SEC_CONTENT
steps	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
128,000	SEC_CONTENT
words	SEC_CONTENT
.	SEC_END
•	SEC_START
GPT	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
5e-5	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
experiments	SEC_CONTENT
;	SEC_CONTENT
BERT	SEC_CONTENT
chooses	SEC_CONTENT
a	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
which	SEC_CONTENT
performs	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
To	SEC_START
isolate	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
differences	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
perform	SEC_CONTENT
ablation	SEC_CONTENT
experiments	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
5.1	SEC_CONTENT
which	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
majority	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
improvements	SEC_CONTENT
are	SEC_CONTENT
in	SEC_CONTENT
fact	SEC_CONTENT
coming	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
new	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
BERT	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
11	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
GLUE	SECTITLE_START
Datasets	SECTITLE_END
The	SEC_START
General	SEC_CONTENT
Language	SEC_CONTENT
Understanding	SEC_CONTENT
Evaluation	SEC_CONTENT
(	SEC_CONTENT
GLUE	SEC_CONTENT
)	SEC_CONTENT
benchmark	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
diverse	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
GLUE	SEC_CONTENT
datasets	SEC_CONTENT
have	SEC_CONTENT
already	SEC_CONTENT
existed	SEC_CONTENT
fora	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
years	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
the	SEC_CONTENT
purpose	SEC_CONTENT
of	SEC_CONTENT
GLUE	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
distribute	SEC_CONTENT
these	SEC_CONTENT
datasets	SEC_CONTENT
with	SEC_CONTENT
canonical	SEC_CONTENT
Train	SEC_CONTENT
,	SEC_CONTENT
Dev	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Test	SEC_CONTENT
splits	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
setup	SEC_CONTENT
an	SEC_CONTENT
evaluation	SEC_CONTENT
server	SEC_CONTENT
to	SEC_CONTENT
mitigate	SEC_CONTENT
issues	SEC_CONTENT
with	SEC_CONTENT
evaluation	SEC_CONTENT
inconsistencies	SEC_CONTENT
and	SEC_CONTENT
Test	task
set	task
overfitting	task
.	SEC_CONTENT
GLUE	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
distribute	SEC_CONTENT
labels	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
Test	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
users	SEC_CONTENT
must	SEC_CONTENT
upload	SEC_CONTENT
their	SEC_CONTENT
predictions	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
GLUE	SEC_CONTENT
server	SEC_CONTENT
for	SEC_CONTENT
evaluation	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
limits	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
submissions	SEC_CONTENT
.	SEC_END
The	SEC_START
GLUE	SEC_CONTENT
benchmark	SEC_CONTENT
includes	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
datasets	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
descriptions	SEC_CONTENT
of	SEC_CONTENT
which	SEC_CONTENT
were	SEC_CONTENT
originally	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
:	SEC_END
MNLI	SEC_START
Multi	SEC_CONTENT
-	SEC_CONTENT
Genre	SEC_CONTENT
Natural	SEC_CONTENT
Language	SEC_CONTENT
Inference	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
-	SEC_CONTENT
scale	SEC_CONTENT
,	SEC_CONTENT
crowdsourced	SEC_CONTENT
entailment	SEC_CONTENT
classification	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
pair	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
whether	SEC_CONTENT
the	task
second	task
sentence	task
is	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
,	SEC_CONTENT
contradiction	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
neutral	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
one	SEC_CONTENT
.	SEC_END
QQP	SEC_START
Quora	task
Question	task
Pairs	task
is	SEC_CONTENT
a	SEC_CONTENT
binary	SEC_CONTENT
classification	SEC_CONTENT
task	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
determine	SEC_CONTENT
if	SEC_CONTENT
two	SEC_CONTENT
questions	SEC_CONTENT
asked	SEC_CONTENT
on	SEC_CONTENT
Quora	SEC_CONTENT
are	SEC_CONTENT
semantically	SEC_CONTENT
equivalent	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
...	SEC_START
...	SEC_START
...	SEC_START
...	SEC_START
...	SEC_START
...	SEC_END
T	SEC_START
...	SEC_END
...	SEC_START
...	SEC_END
[	SEC_START
CLS	SEC_CONTENT
]	SEC_END
Tok	SEC_START
1	SEC_CONTENT
[	SEC_CONTENT
CLS	SEC_CONTENT
]	SEC_END
Tok	SEC_START
1	SEC_CONTENT
...	SEC_CONTENT
CoLA	SEC_CONTENT
The	SEC_CONTENT
Corpus	SEC_CONTENT
of	SEC_CONTENT
Linguistic	SEC_CONTENT
Acceptability	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
binary	SEC_CONTENT
single	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
classification	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
whether	SEC_CONTENT
an	SEC_CONTENT
English	SEC_CONTENT
sentence	SEC_CONTENT
is	SEC_CONTENT
linguistically	SEC_CONTENT
"	SEC_CONTENT
acceptable	SEC_CONTENT
"	SEC_CONTENT
or	SEC_CONTENT
not	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
STS	SEC_START
-	SEC_CONTENT
B	SEC_CONTENT
The	SEC_CONTENT
Semantic	SEC_CONTENT
Textual	SEC_CONTENT
Similarity	SEC_CONTENT
Benchmark	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
drawn	SEC_CONTENT
from	SEC_CONTENT
news	SEC_CONTENT
headlines	SEC_CONTENT
and	SEC_CONTENT
other	SEC_CONTENT
sources	SEC_CONTENT
(	SEC_CONTENT
Cer	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
were	SEC_CONTENT
annotated	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
score	SEC_CONTENT
from	SEC_CONTENT
1	SEC_CONTENT
to	SEC_CONTENT
5	SEC_CONTENT
denoting	SEC_CONTENT
how	SEC_CONTENT
similar	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
sentences	SEC_CONTENT
are	SEC_CONTENT
in	SEC_CONTENT
terms	metric
of	SEC_CONTENT
semantic	task
meaning	task
.	SEC_END
MRPC	SEC_START
Microsoft	SEC_CONTENT
Research	SEC_CONTENT
Paraphrase	SEC_CONTENT
Corpus	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
automatically	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
online	SEC_CONTENT
news	SEC_CONTENT
sources	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
human	SEC_CONTENT
annotations	SEC_CONTENT
for	SEC_CONTENT
whether	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
pair	SEC_CONTENT
are	SEC_CONTENT
semantically	SEC_CONTENT
equivalent	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
WNLI	SEC_CONTENT
Winograd	SEC_CONTENT
NLI	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
dataset	SEC_CONTENT
deriving	SEC_CONTENT
from	SEC_CONTENT
(	SEC_CONTENT
Levesque	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
GLUE	SEC_CONTENT
webpage	SEC_CONTENT
notes	SEC_CONTENT
that	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
issues	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
construction	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
7	SEC_CONTENT
and	SEC_CONTENT
every	SEC_CONTENT
trained	SEC_CONTENT
system	SEC_CONTENT
that	SEC_CONTENT
's	SEC_CONTENT
been	SEC_CONTENT
submitted	SEC_CONTENT
to	SEC_CONTENT
GLUE	SEC_CONTENT
has	SEC_CONTENT
has	SEC_CONTENT
performed	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
65.1	SEC_CONTENT
baseline	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
predicting	SEC_CONTENT
the	SEC_CONTENT
majority	SEC_CONTENT
class	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
therefore	SEC_CONTENT
exclude	SEC_CONTENT
this	SEC_CONTENT
set	SEC_CONTENT
out	SEC_CONTENT
of	SEC_CONTENT
fairness	SEC_CONTENT
to	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
our	SEC_CONTENT
GLUE	SEC_CONTENT
submission	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
always	SEC_CONTENT
predicted	SEC_CONTENT
the	SEC_CONTENT
majority	SEC_CONTENT
class	SEC_CONTENT
.	SEC_END
System	SECTITLE_END
MNLI-(m	SECTITLE_START
/	SECTITLE_CONTENT
mm	SECTITLE_CONTENT
)	SECTITLE_CONTENT
QQP	SECTITLE_CONTENT
QNLI	SECTITLE_CONTENT
SST-2	SECTITLE_CONTENT
CoLA	SECTITLE_CONTENT
STS	SECTITLE_CONTENT
-	SECTITLE_CONTENT
B	SECTITLE_CONTENT
MRPC	SECTITLE_CONTENT
RTE	SECTITLE_CONTENT
Average	SECTITLE_END
GLUE	SECTITLE_START
Results	SECTITLE_END
To	SEC_START
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_CONTENT
on	SEC_CONTENT
GLUE	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
represent	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
or	SEC_CONTENT
sequence	SEC_CONTENT
pair	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
vector	SEC_CONTENT
C	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
input	SEC_CONTENT
token	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
aggregate	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
demonstrated	SEC_CONTENT
visually	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
b	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
only	SEC_CONTENT
new	SEC_CONTENT
parameters	SEC_CONTENT
introduced	SEC_CONTENT
during	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
classification	SEC_CONTENT
layer	SEC_CONTENT
W	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
K×H	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
K	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compute	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
classification	SEC_CONTENT
loss	SEC_CONTENT
with	SEC_CONTENT
C	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
log(softmax(CW	SEC_CONTENT
T	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
We	SEC_START
use	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
32	SEC_CONTENT
and	SEC_CONTENT
3	SEC_CONTENT
epochs	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
GLUE	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
each	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
ran	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tunings	SEC_CONTENT
with	SEC_CONTENT
learning	SEC_CONTENT
rates	SEC_CONTENT
of	SEC_CONTENT
5e-5	SEC_CONTENT
,	SEC_CONTENT
4e-5	SEC_CONTENT
,	SEC_CONTENT
3e-5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
2e-5	SEC_CONTENT
and	SEC_CONTENT
selected	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
that	SEC_CONTENT
performed	SEC_CONTENT
best	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Dev	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
was	SEC_CONTENT
sometimes	SEC_CONTENT
unstable	SEC_CONTENT
on	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
report	SEC_CONTENT
single	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
.	SEC_CONTENT
Multitask	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
approach	SEC_CONTENT
could	SEC_CONTENT
potentially	SEC_CONTENT
push	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
even	SEC_CONTENT
further	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
observe	SEC_CONTENT
substantial	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
RTE	SEC_CONTENT
from	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
MNLI	SEC_CONTENT
.	SEC_END
7	SEC_START
https://gluebenchmark.com/faq	SEC_CONTENT
small	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
some	SEC_CONTENT
runs	SEC_CONTENT
would	SEC_CONTENT
produce	SEC_CONTENT
degenerate	SEC_CONTENT
results	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
we	SEC_CONTENT
ran	SEC_CONTENT
several	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
and	SEC_CONTENT
selected	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
performed	SEC_CONTENT
best	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Dev	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
checkpoint	SEC_CONTENT
but	SEC_CONTENT
perform	SEC_CONTENT
different	SEC_CONTENT
finetuning	SEC_CONTENT
data	SEC_CONTENT
shuffling	SEC_CONTENT
and	SEC_CONTENT
classifier	SEC_CONTENT
layer	SEC_CONTENT
initialization	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
GLUE	SEC_CONTENT
data	SEC_CONTENT
set	SEC_CONTENT
distribution	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
include	SEC_CONTENT
the	SEC_CONTENT
Test	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
made	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
GLUE	SEC_CONTENT
evaluation	SEC_CONTENT
server	SEC_CONTENT
submission	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
and	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
.	SEC_END
Results	SEC_START
are	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
and	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
outperform	SEC_CONTENT
all	SEC_CONTENT
existing	SEC_CONTENT
systems	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
substantial	SEC_CONTENT
margin	SEC_CONTENT
,	SEC_CONTENT
obtaining	SEC_CONTENT
4.4	SEC_CONTENT
%	SEC_CONTENT
and	SEC_CONTENT
6.7	SEC_CONTENT
%	SEC_CONTENT
respective	SEC_CONTENT
average	SEC_CONTENT
accuracy	SEC_CONTENT
improvement	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
and	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
are	SEC_CONTENT
nearly	SEC_CONTENT
identical	SEC_CONTENT
in	SEC_CONTENT
terms	metric
of	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
outside	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
masking	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
largest	SEC_CONTENT
and	SEC_CONTENT
most	SEC_CONTENT
widely	SEC_CONTENT
reported	SEC_CONTENT
GLUE	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
MNLI	SEC_CONTENT
,	SEC_CONTENT
BERT	SEC_CONTENT
obtains	SEC_CONTENT
a	SEC_CONTENT
4.7	SEC_CONTENT
%	SEC_CONTENT
absolute	SEC_CONTENT
accuracy	SEC_CONTENT
improvement	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
official	SEC_CONTENT
GLUE	SEC_CONTENT
leaderboard	SEC_CONTENT
,	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
obtains	SEC_CONTENT
a	SEC_CONTENT
score	SEC_CONTENT
of	SEC_CONTENT
80.4	SEC_CONTENT
,	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
leaderboard	SEC_CONTENT
system	SEC_CONTENT
,	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
obtains	SEC_CONTENT
72.8	SEC_CONTENT
as	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
date	SEC_CONTENT
of	SEC_CONTENT
writing	SEC_CONTENT
.	SEC_END
It	SEC_START
is	SEC_CONTENT
interesting	SEC_CONTENT
to	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
significantly	SEC_CONTENT
outperforms	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
those	SEC_CONTENT
with	SEC_CONTENT
very	SEC_CONTENT
little	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
is	SEC_CONTENT
explored	SEC_CONTENT
more	SEC_CONTENT
thoroughly	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
5.2	SEC_CONTENT
.	SEC_END
SQuAD	SECTITLE_START
v1.1	SECTITLE_END
The	SEC_START
Standford	task
Question	task
Answering	task
Dataset	task
(	task
SQuAD	task
)	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
100k	SEC_CONTENT
crowdsourced	SEC_CONTENT
question	SEC_CONTENT
/	SEC_CONTENT
answer	SEC_CONTENT
pairs	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
question	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
paragraph	SEC_CONTENT
from	SEC_CONTENT
Wikipedia	SEC_CONTENT
containing	SEC_CONTENT
the	SEC_CONTENT
answer	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
answer	SEC_CONTENT
text	SEC_CONTENT
span	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
paragraph	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
:	SEC_END
•	SEC_START
Input	SEC_CONTENT
Question	SEC_CONTENT
:	SEC_END
Where	SEC_START
do	SEC_CONTENT
water	SEC_CONTENT
droplets	SEC_CONTENT
collide	SEC_CONTENT
with	SEC_CONTENT
ice	SEC_CONTENT
crystals	SEC_CONTENT
to	SEC_CONTENT
form	SEC_CONTENT
precipitation	SEC_CONTENT
?	SEC_END
•	SEC_START
Input	SEC_CONTENT
Paragraph	SEC_CONTENT
:	SEC_END
...	SEC_START
Precipitation	SEC_CONTENT
forms	SEC_CONTENT
as	SEC_CONTENT
smaller	SEC_CONTENT
droplets	SEC_CONTENT
coalesce	SEC_CONTENT
via	SEC_CONTENT
collision	SEC_CONTENT
with	SEC_CONTENT
other	SEC_CONTENT
rain	SEC_CONTENT
drops	SEC_CONTENT
or	SEC_CONTENT
ice	SEC_CONTENT
crystals	SEC_CONTENT
within	SEC_CONTENT
a	SEC_CONTENT
cloud	SEC_CONTENT
.	SEC_CONTENT
...	SEC_END
•	SECTITLE_START
Output	SECTITLE_CONTENT
Answer	SECTITLE_CONTENT
:	SECTITLE_END
within	SEC_START
a	SEC_CONTENT
cloud	SEC_CONTENT
This	SEC_CONTENT
type	SEC_CONTENT
of	SEC_CONTENT
span	SEC_CONTENT
prediction	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
quite	SEC_CONTENT
different	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
classification	SEC_CONTENT
tasks	SEC_CONTENT
of	SEC_CONTENT
GLUE	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
adapt	SEC_CONTENT
BERT	SEC_CONTENT
to	SEC_CONTENT
run	SEC_CONTENT
on	SEC_CONTENT
SQuAD	dataset
in	SEC_CONTENT
a	SEC_CONTENT
straightforward	SEC_CONTENT
manner	SEC_CONTENT
.	SEC_CONTENT
Just	SEC_CONTENT
as	SEC_CONTENT
with	SEC_CONTENT
GLUE	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
represent	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
question	SEC_CONTENT
and	SEC_CONTENT
paragraph	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
packed	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
question	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
A	SEC_CONTENT
embedding	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
paragraph	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
B	SEC_CONTENT
embedding	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
only	SEC_CONTENT
new	SEC_CONTENT
parameters	SEC_CONTENT
learned	SEC_CONTENT
during	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
area	SEC_CONTENT
start	SEC_CONTENT
vector	SEC_CONTENT
S	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
and	SEC_CONTENT
an	SEC_CONTENT
end	SEC_CONTENT
vector	SEC_CONTENT
E	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
vector	SEC_CONTENT
from	SEC_CONTENT
BERT	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
i	SEC_CONTENT
th	SEC_CONTENT
input	SEC_CONTENT
token	SEC_CONTENT
be	SEC_CONTENT
denoted	SEC_CONTENT
as	SEC_CONTENT
Ti	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
.	SEC_CONTENT
See	SEC_CONTENT
(	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
fora	SEC_CONTENT
visualization	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
i	SEC_CONTENT
being	SEC_CONTENT
the	SEC_CONTENT
start	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
answer	SEC_CONTENT
span	SEC_CONTENT
is	SEC_CONTENT
computed	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
dot	SEC_CONTENT
product	SEC_CONTENT
between	SEC_CONTENT
Ti	SEC_CONTENT
and	SEC_CONTENT
S	SEC_CONTENT
followed	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
softmax	SEC_CONTENT
overall	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
paragraph	SEC_CONTENT
:	SEC_END
The	SEC_START
same	SEC_CONTENT
formula	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
of	SEC_CONTENT
the	task
answer	task
span	task
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
maximum	SEC_CONTENT
scoring	SEC_CONTENT
span	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
training	SEC_CONTENT
objective	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
loglikelihood	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
start	SEC_CONTENT
and	SEC_CONTENT
end	SEC_CONTENT
positions	SEC_CONTENT
.	SEC_END
We	SEC_START
train	SEC_CONTENT
for	SEC_CONTENT
3	SEC_CONTENT
epochs	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
5e-5	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
32	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
inference	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	task
end	task
prediction	task
is	SEC_CONTENT
not	SEC_CONTENT
conditioned	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
start	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
the	SEC_CONTENT
constraint	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
must	SEC_CONTENT
come	SEC_CONTENT
after	SEC_CONTENT
the	SEC_CONTENT
start	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
no	SEC_CONTENT
other	SEC_CONTENT
heuristics	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
tokenized	SEC_CONTENT
labeled	SEC_CONTENT
span	SEC_CONTENT
is	SEC_CONTENT
aligned	SEC_CONTENT
back	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
untokenized	SEC_CONTENT
input	SEC_CONTENT
for	SEC_CONTENT
evaluation	SEC_CONTENT
.	SEC_END
Results	SEC_START
are	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
SQuAD	dataset
uses	SEC_CONTENT
a	SEC_CONTENT
highly	SEC_CONTENT
rigorous	SEC_CONTENT
testing	SEC_CONTENT
procedure	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
submitter	SEC_CONTENT
must	SEC_CONTENT
manually	SEC_CONTENT
contact	SEC_CONTENT
the	SEC_CONTENT
SQuAD	SEC_CONTENT
organizers	SEC_CONTENT
to	SEC_CONTENT
run	SEC_CONTENT
their	SEC_CONTENT
system	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
hidden	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
submitted	SEC_CONTENT
our	SEC_CONTENT
best	SEC_CONTENT
system	SEC_CONTENT
for	SEC_CONTENT
testing	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
result	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
table	SEC_CONTENT
is	SEC_CONTENT
our	SEC_CONTENT
first	SEC_CONTENT
and	SEC_CONTENT
only	SEC_CONTENT
Test	SEC_CONTENT
submission	SEC_CONTENT
to	SEC_CONTENT
SQuAD	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
results	SEC_END
System	SECTITLE_END
Dev	SEC_START
Test	SEC_CONTENT
EM	SEC_CONTENT
F1	SEC_CONTENT
EM	SEC_CONTENT
F1	SEC_CONTENT
Leaderboard	SEC_CONTENT
(	SEC_CONTENT
Oct	SEC_CONTENT
8th	SEC_CONTENT
,	SEC_CONTENT
2018	SEC_CONTENT
)	SEC_CONTENT
Human	SEC_CONTENT
--82.3	SEC_CONTENT
91.2	SEC_CONTENT
#	SEC_CONTENT
1	SEC_CONTENT
Ensemble	SEC_CONTENT
-nlnet	SEC_CONTENT
--86.0	SEC_CONTENT
91.7	SEC_CONTENT
#	SEC_CONTENT
2	SEC_CONTENT
Ensemble	SEC_CONTENT
-QANet	SEC_CONTENT
--84.5	SEC_CONTENT
90.5	SEC_CONTENT
#	SEC_CONTENT
1	SEC_CONTENT
Single	SEC_CONTENT
-nlnet	SEC_CONTENT
--83.5	SEC_CONTENT
90.1	SEC_CONTENT
#	SEC_CONTENT
2	SEC_CONTENT
Single	SEC_CONTENT
-QANet	SEC_CONTENT
--82.5	SEC_CONTENT
89	SEC_CONTENT
.	SEC_CONTENT
 	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
SQuAD	SEC_CONTENT
leaderboard	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
up	SEC_CONTENT
-	SEC_CONTENT
todate	SEC_CONTENT
public	SEC_CONTENT
system	SEC_CONTENT
descriptions	SEC_CONTENT
available	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
are	SEC_CONTENT
allowed	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
any	SEC_CONTENT
public	SEC_CONTENT
data	SEC_CONTENT
when	SEC_CONTENT
training	SEC_CONTENT
their	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
therefore	SEC_CONTENT
use	SEC_CONTENT
very	SEC_CONTENT
modest	SEC_CONTENT
data	SEC_CONTENT
augmentation	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
submitted	SEC_CONTENT
system	SEC_CONTENT
by	SEC_CONTENT
jointly	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
SQuAD	dataset
and	SEC_CONTENT
TriviaQA	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
best	SEC_CONTENT
performing	SEC_CONTENT
system	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
leaderboard	SEC_CONTENT
system	SEC_CONTENT
by	SEC_CONTENT
+1.5	SEC_CONTENT
F1	SEC_CONTENT
in	SEC_CONTENT
ensembling	SEC_CONTENT
and	SEC_CONTENT
+1.3	SEC_CONTENT
F1	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
system	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
single	SEC_CONTENT
BERT	SEC_CONTENT
model	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
ensemble	SEC_CONTENT
system	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
If	SEC_CONTENT
we	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_CONTENT
on	SEC_CONTENT
only	SEC_CONTENT
SQuAD	SEC_CONTENT
(	SEC_CONTENT
without	SEC_CONTENT
TriviaQA	SEC_CONTENT
)	SEC_CONTENT
we	SEC_CONTENT
lose	SEC_CONTENT
0.1	SEC_CONTENT
-	SEC_CONTENT
0.4	SEC_CONTENT
F1	SEC_CONTENT
and	SEC_CONTENT
still	SEC_CONTENT
outperform	SEC_CONTENT
all	SEC_CONTENT
existing	SEC_CONTENT
systems	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
wide	SEC_CONTENT
margin	SEC_CONTENT
.	SEC_END
Named	SECTITLE_START
Entity	SECTITLE_CONTENT
Recognition	SECTITLE_END
To	SEC_START
evaluate	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
token	SEC_CONTENT
tagging	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_CONTENT
BERT	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL	SEC_CONTENT
2003	SEC_CONTENT
Named	SEC_CONTENT
Entity	task
Recognition	task
(	SEC_CONTENT
NER	SEC_CONTENT
)	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
dataset	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
200k	SEC_CONTENT
training	SEC_CONTENT
words	SEC_CONTENT
which	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
annotated	SEC_CONTENT
as	SEC_CONTENT
Person	SEC_CONTENT
,	SEC_CONTENT
Organization	SEC_CONTENT
,	SEC_CONTENT
Location	SEC_CONTENT
,	SEC_CONTENT
Miscellaneous	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
Other	SEC_CONTENT
(	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
For	SEC_START
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
feed	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
representation	SEC_CONTENT
Ti	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
for	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
token	SEC_CONTENT
i	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
classification	SEC_CONTENT
layer	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
NER	SEC_CONTENT
label	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
predictions	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
conditioned	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
surrounding	SEC_CONTENT
predictions	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
autoregressive	SEC_CONTENT
and	SEC_CONTENT
no	SEC_CONTENT
CRF	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
make	SEC_CONTENT
this	SEC_CONTENT
compatible	SEC_CONTENT
with	SEC_CONTENT
WordPiece	SEC_CONTENT
tokenization	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
feed	SEC_CONTENT
each	SEC_CONTENT
CoNLL	SEC_CONTENT
-	SEC_CONTENT
tokenized	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
into	SEC_CONTENT
our	SEC_CONTENT
WordPiece	SEC_CONTENT
tokenizer	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
 	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
token	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
classifier	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
:	SEC_END
Jim	SEC_START
Hen	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
son	SEC_CONTENT
was	SEC_CONTENT
a	SEC_CONTENT
puppet	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
eer	SEC_END
Where	SEC_START
no	SEC_CONTENT
prediction	SEC_CONTENT
is	SEC_CONTENT
made	SEC_CONTENT
for	SEC_CONTENT
X.	SEC_CONTENT
Since	SEC_CONTENT
the	SEC_CONTENT
WordPiece	SEC_CONTENT
tokenization	SEC_CONTENT
boundaries	SEC_CONTENT
area	SEC_CONTENT
known	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
done	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
visual	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
given	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
cased	SEC_CONTENT
WordPiece	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
NER	SEC_CONTENT
,	SEC_CONTENT
whereas	SEC_CONTENT
an	SEC_CONTENT
uncased	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
other	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Results	SEC_CONTENT
are	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
existing	SEC_CONTENT
SOTA	SEC_CONTENT
,	SEC_CONTENT
Cross	SEC_CONTENT
-	SEC_CONTENT
View	SEC_CONTENT
Training	SEC_CONTENT
with	SEC_CONTENT
multi	task
-	task
task	task
learning	task
,	SEC_CONTENT
by	SEC_CONTENT
+0.2	SEC_CONTENT
on	SEC_CONTENT
CoNLL-2003	SEC_CONTENT
NER	SEC_CONTENT
Test	SEC_CONTENT
.	SEC_END
SWAG	SECTITLE_END
The	SEC_START
Situations	SEC_CONTENT
With	SEC_CONTENT
Adversarial	SEC_CONTENT
Generations	SEC_CONTENT
(	SEC_CONTENT
SWAG	dataset
)	SEC_CONTENT
dataset	SEC_CONTENT
contains	SEC_CONTENT
113k	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
pair	SEC_CONTENT
completion	SEC_CONTENT
examples	SEC_CONTENT
that	SEC_CONTENT
evaluate	SEC_CONTENT
grounded	SEC_CONTENT
commonsense	SEC_CONTENT
inference	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
Given	SEC_START
a	SEC_CONTENT
sentence	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
video	SEC_CONTENT
captioning	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
decide	SEC_CONTENT
among	SEC_CONTENT
four	SEC_CONTENT
choices	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
plausible	SEC_CONTENT
continuation	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
:	SEC_END
A	SEC_START
girl	SEC_CONTENT
is	SEC_CONTENT
going	SEC_CONTENT
across	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
monkey	SEC_CONTENT
bars	SEC_CONTENT
.	SEC_CONTENT
She	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
jumps	SEC_CONTENT
up	SEC_CONTENT
across	SEC_CONTENT
the	SEC_CONTENT
monkey	SEC_CONTENT
bars	SEC_CONTENT
.	SEC_END
(	SEC_START
ii	SEC_CONTENT
)	SEC_CONTENT
struggles	SEC_CONTENT
onto	SEC_CONTENT
the	SEC_CONTENT
bars	SEC_CONTENT
to	SEC_CONTENT
grab	SEC_CONTENT
her	SEC_CONTENT
head	SEC_CONTENT
.	SEC_END
(	SEC_START
iii	SEC_CONTENT
)	SEC_CONTENT
gets	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
and	SEC_CONTENT
stands	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
wooden	SEC_CONTENT
plank	SEC_CONTENT
.	SEC_END
(	SEC_START
iv	SEC_CONTENT
)	SEC_CONTENT
jumps	SEC_CONTENT
up	SEC_CONTENT
and	SEC_CONTENT
does	SEC_CONTENT
aback	SEC_CONTENT
flip	SEC_CONTENT
.	SEC_END
Adapting	SEC_START
BERT	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
SWAG	SEC_CONTENT
dataset	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
adaptation	SEC_CONTENT
for	SEC_CONTENT
GLUE	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
each	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
construct	SEC_CONTENT
four	SEC_CONTENT
input	SEC_CONTENT
sequences	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
each	SEC_CONTENT
contain	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
the	SEC_CONTENT
given	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
sentence	SEC_CONTENT
A	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
a	task
possible	task
continuation	task
(	SEC_CONTENT
sentence	SEC_CONTENT
B	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
only	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
parameters	SEC_CONTENT
we	SEC_CONTENT
introduce	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
V	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
,	SEC_CONTENT
whose	SEC_CONTENT
dot	SEC_CONTENT
product	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
aggregate	SEC_CONTENT
representation	SEC_CONTENT
Ci	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
H	SEC_CONTENT
denotes	SEC_CONTENT
a	SEC_CONTENT
 	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
choice	SEC_CONTENT
i.	SEC_CONTENT
The	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
four	SEC_CONTENT
choices	SEC_CONTENT
:	SEC_END
We	SEC_START
fine	SEC_CONTENT
-	SEC_CONTENT
tune	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
3	SEC_CONTENT
epochs	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
2e-5	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
16	SEC_CONTENT
.	SEC_CONTENT
Results	SEC_CONTENT
are	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
authors	SEC_CONTENT
'	SEC_CONTENT
baseline	SEC_CONTENT
ESIM+ELMo	SEC_CONTENT
system	SEC_CONTENT
by	SEC_CONTENT
+27.1	SEC_CONTENT
%	SEC_CONTENT
.	SEC_END
Ablation	SECTITLE_START
Studies	SECTITLE_END
Although	SEC_START
we	SEC_CONTENT
have	SEC_CONTENT
demonstrated	SEC_CONTENT
extremely	SEC_CONTENT
strong	SEC_CONTENT
empirical	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
presented	SEC_CONTENT
so	SEC_CONTENT
far	SEC_CONTENT
have	SEC_CONTENT
not	SEC_CONTENT
isolated	SEC_CONTENT
the	task
specific	task
contributions	task
from	SEC_CONTENT
each	SEC_CONTENT
aspect	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
BERT	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
perform	SEC_CONTENT
ablation	SEC_CONTENT
experiments	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
facets	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
better	SEC_CONTENT
understand	SEC_CONTENT
their	SEC_CONTENT
relative	SEC_CONTENT
importance	SEC_CONTENT
.	SEC_END
Effect	SECTITLE_START
of	SECTITLE_CONTENT
Pre	SECTITLE_CONTENT
-	SECTITLE_CONTENT
training	SECTITLE_CONTENT
Tasks	SECTITLE_END
One	SEC_START
of	SEC_CONTENT
our	SEC_CONTENT
core	SEC_CONTENT
claims	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
deep	SEC_CONTENT
bidirectionality	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
enabled	SEC_CONTENT
by	SEC_CONTENT
masked	SEC_CONTENT
LM	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
single	SEC_CONTENT
most	SEC_CONTENT
important	SEC_CONTENT
improvement	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
give	SEC_CONTENT
evidence	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
claim	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
evaluate	SEC_CONTENT
two	SEC_CONTENT
new	SEC_CONTENT
models	SEC_CONTENT
which	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
exact	SEC_CONTENT
same	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
scheme	SEC_CONTENT
and	SEC_CONTENT
Transformer	SEC_CONTENT
hyperparameters	SEC_CONTENT
as	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
:	SEC_END
1	SEC_START
.	SEC_CONTENT
No	SEC_CONTENT
NSP	SEC_CONTENT
:	SEC_CONTENT
A	SEC_CONTENT
model	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
masked	SEC_CONTENT
LM	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
MLM	SEC_CONTENT
)	SEC_CONTENT
but	SEC_CONTENT
without	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
next	SEC_CONTENT
sentence	SEC_CONTENT
prediction	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
NSP	SEC_CONTENT
)	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
2	SEC_START
.	SEC_CONTENT
LTR	SEC_CONTENT
&	SEC_CONTENT
No	SEC_CONTENT
NSP	SEC_CONTENT
:	SEC_CONTENT
A	SEC_CONTENT
model	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
Left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
Right	SEC_CONTENT
(	SEC_CONTENT
LTR	SEC_CONTENT
)	SEC_CONTENT
LM	SEC_CONTENT
,	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
an	SEC_CONTENT
MLM	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
predict	SEC_CONTENT
every	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
and	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
apply	SEC_CONTENT
any	SEC_CONTENT
masking	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
only	SEC_CONTENT
constraint	SEC_CONTENT
was	SEC_CONTENT
also	SEC_CONTENT
applied	SEC_CONTENT
at	SEC_CONTENT
finetuning	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
always	SEC_CONTENT
worse	SEC_CONTENT
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
with	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
only	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
and	SEC_CONTENT
finetune	SEC_CONTENT
with	SEC_CONTENT
bidirectional	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
without	SEC_CONTENT
the	SEC_CONTENT
NSP	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
directly	SEC_CONTENT
comparable	SEC_CONTENT
to	SEC_CONTENT
OpenAI	SEC_CONTENT
GPT	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
using	SEC_CONTENT
our	SEC_CONTENT
larger	SEC_CONTENT
training	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
input	SEC_CONTENT
representation	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
scheme	SEC_CONTENT
.	SEC_END
Results	SEC_START
are	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
first	SEC_CONTENT
examine	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
brought	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
NSP	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
removing	SEC_CONTENT
NSP	SEC_CONTENT
hurts	SEC_CONTENT
performance	SEC_CONTENT
significantly	SEC_CONTENT
on	SEC_CONTENT
QNLI	SEC_CONTENT
,	SEC_CONTENT
MNLI	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
SQuAD	dataset
.	SEC_CONTENT
These	SEC_CONTENT
results	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
method	SEC_CONTENT
is	SEC_CONTENT
critical	SEC_CONTENT
in	SEC_CONTENT
obtaining	SEC_CONTENT
the	SEC_CONTENT
strong	SEC_CONTENT
empirical	SEC_CONTENT
results	SEC_CONTENT
presented	SEC_CONTENT
previously	SEC_CONTENT
.	SEC_END
Next	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
evaluate	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
bidirectional	SEC_CONTENT
representations	SEC_CONTENT
by	SEC_CONTENT
comparing	SEC_CONTENT
"	SEC_CONTENT
No	SEC_CONTENT
NSP	SEC_CONTENT
"	SEC_CONTENT
to	SEC_CONTENT
"	SEC_CONTENT
LTR	SEC_CONTENT
&	SEC_CONTENT
No	SEC_CONTENT
NSP	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
LTR	SEC_CONTENT
model	SEC_CONTENT
performs	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
MLM	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
extremely	SEC_CONTENT
large	SEC_CONTENT
drops	SEC_CONTENT
on	SEC_CONTENT
MRPC	SEC_CONTENT
and	SEC_CONTENT
SQuAD	dataset
.	SEC_CONTENT
For	SEC_CONTENT
SQuAD	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
intuitively	SEC_CONTENT
clear	SEC_CONTENT
that	SEC_CONTENT
an	SEC_CONTENT
LTR	SEC_CONTENT
model	SEC_CONTENT
will	SEC_CONTENT
perform	SEC_CONTENT
very	SEC_CONTENT
poorly	SEC_CONTENT
at	SEC_CONTENT
span	SEC_CONTENT
and	SEC_CONTENT
token	SEC_CONTENT
prediction	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
have	SEC_CONTENT
no	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
side	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
MRPC	SEC_CONTENT
is	SEC_CONTENT
unclear	SEC_CONTENT
whether	SEC_CONTENT
the	SEC_CONTENT
poor	SEC_CONTENT
performance	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
small	SEC_CONTENT
data	SEC_CONTENT
size	SEC_CONTENT
or	SEC_CONTENT
the	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
this	SEC_CONTENT
poor	SEC_CONTENT
performance	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
consistent	SEC_CONTENT
across	SEC_CONTENT
a	SEC_CONTENT
full	SEC_CONTENT
hyperparameter	SEC_CONTENT
sweep	SEC_CONTENT
with	SEC_CONTENT
many	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
.	SEC_END
In	SEC_START
order	SEC_CONTENT
make	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
faith	SEC_CONTENT
attempt	SEC_CONTENT
at	SEC_CONTENT
strengthening	SEC_CONTENT
the	SEC_CONTENT
LTR	SEC_CONTENT
system	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
tried	SEC_CONTENT
adding	SEC_CONTENT
a	SEC_CONTENT
randomly	SEC_CONTENT
initialized	SEC_CONTENT
BiLSTM	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
it	SEC_CONTENT
for	SEC_CONTENT
finetuning	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
does	SEC_CONTENT
significantly	SEC_CONTENT
improve	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
SQuAD	dataset
,	SEC_CONTENT
but	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
still	SEC_CONTENT
far	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
 	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
bidirectional	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
also	SEC_CONTENT
hurts	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
four	SEC_CONTENT
GLUE	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
recognize	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
would	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
separate	SEC_CONTENT
LTR	SEC_CONTENT
and	SEC_CONTENT
RTL	SEC_CONTENT
models	SEC_CONTENT
and	SEC_CONTENT
represent	SEC_CONTENT
each	SEC_CONTENT
token	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
ELMo	SEC_CONTENT
does	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
:	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
twice	SEC_CONTENT
as	SEC_CONTENT
expensive	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
bidirectional	SEC_CONTENT
model	SEC_CONTENT
;	SEC_CONTENT
(	SEC_CONTENT
b	SEC_CONTENT
)	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
intuitive	SEC_CONTENT
for	SEC_CONTENT
tasks	SEC_CONTENT
like	SEC_CONTENT
QA	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
RTL	SEC_CONTENT
model	SEC_CONTENT
would	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
condition	SEC_CONTENT
the	SEC_CONTENT
answer	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
question	SEC_CONTENT
;	SEC_CONTENT
(	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
this	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
strictly	SEC_CONTENT
less	SEC_CONTENT
powerful	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
model	SEC_CONTENT
could	SEC_CONTENT
choose	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
either	SEC_CONTENT
left	SEC_CONTENT
or	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
.	SEC_END
Effect	SECTITLE_START
of	SECTITLE_CONTENT
Model	SECTITLE_CONTENT
Size	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
explore	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
on	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
task	SEC_CONTENT
accuracy	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
a	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
differing	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
attention	SEC_CONTENT
heads	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
otherwise	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
hyperparameters	SEC_CONTENT
and	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
previously	SEC_CONTENT
.	SEC_END
Results	SEC_START
on	SEC_CONTENT
selected	SEC_CONTENT
GLUE	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
table	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
Dev	SEC_CONTENT
Set	SEC_CONTENT
accuracy	SEC_CONTENT
from	SEC_CONTENT
5	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
of	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
larger	SEC_CONTENT
models	SEC_CONTENT
lead	SEC_CONTENT
to	SEC_CONTENT
a	metric
strict	metric
accuracy	metric
improvement	metric
across	SEC_CONTENT
all	SEC_CONTENT
four	SEC_CONTENT
datasets	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
for	SEC_CONTENT
MRPC	SEC_CONTENT
which	SEC_CONTENT
only	SEC_CONTENT
has	SEC_CONTENT
3,600	SEC_CONTENT
labeled	SEC_CONTENT
training	SEC_CONTENT
examples	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
substantially	SEC_CONTENT
different	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
perhaps	SEC_CONTENT
surprising	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
such	SEC_CONTENT
significant	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
models	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
already	SEC_CONTENT
quite	SEC_CONTENT
large	SEC_CONTENT
relative	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
existing	SEC_CONTENT
literature	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
largest	SEC_CONTENT
Transformer	SEC_CONTENT
explored	SEC_CONTENT
in	SEC_CONTENT
is	SEC_CONTENT
(	SEC_CONTENT
L=6	SEC_CONTENT
,	SEC_CONTENT
H=1024	SEC_CONTENT
,	SEC_CONTENT
A=16	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
100	SEC_CONTENT
M	SEC_CONTENT
parameters	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
largest	SEC_CONTENT
Transformer	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
found	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
is	SEC_CONTENT
(	SEC_CONTENT
L=64	SEC_CONTENT
,	SEC_CONTENT
H=512	SEC_CONTENT
,	SEC_CONTENT
A=2	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
235	SEC_CONTENT
M	SEC_CONTENT
parameters	SEC_CONTENT
(	SEC_CONTENT
Al-	SEC_CONTENT
:	SEC_CONTENT
Ablation	SEC_CONTENT
over	SEC_CONTENT
BERT	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
.	SEC_CONTENT
#	SEC_CONTENT
L	SEC_CONTENT
=	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
layers	SEC_CONTENT
;	SEC_CONTENT
#	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
hidden	SEC_CONTENT
size	SEC_CONTENT
;	SEC_CONTENT
#	SEC_CONTENT
A	SEC_CONTENT
=	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
attention	SEC_CONTENT
heads	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
LM	SEC_CONTENT
(	SEC_CONTENT
ppl	SEC_CONTENT
)	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
masked	SEC_CONTENT
LM	SEC_CONTENT
perplexity	SEC_CONTENT
of	SEC_CONTENT
held	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
contains	SEC_START
110	SEC_CONTENT
M	SEC_CONTENT
parameters	SEC_CONTENT
and	SEC_CONTENT
BERT	SEC_CONTENT
LARGE	SEC_CONTENT
contains	SEC_CONTENT
340	SEC_CONTENT
M	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
known	SEC_CONTENT
for	SEC_CONTENT
many	SEC_CONTENT
years	SEC_CONTENT
that	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
size	SEC_CONTENT
will	SEC_CONTENT
lead	SEC_CONTENT
to	SEC_CONTENT
continual	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
large	SEC_CONTENT
-	SEC_CONTENT
scale	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
demonstrated	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
LM	SEC_CONTENT
perplexity	SEC_CONTENT
of	SEC_CONTENT
held	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
believe	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
work	SEC_CONTENT
to	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
scaling	SEC_CONTENT
to	SEC_CONTENT
extreme	SEC_CONTENT
model	SEC_CONTENT
sizes	SEC_CONTENT
also	SEC_CONTENT
leads	SEC_CONTENT
to	SEC_CONTENT
large	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
very	SEC_CONTENT
small	SEC_CONTENT
scale	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
provided	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
sufficiently	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
.	SEC_CONTENT
presents	SEC_CONTENT
MNLI	SEC_CONTENT
Dev	SEC_CONTENT
accuracy	SEC_CONTENT
after	SEC_CONTENT
finetuning	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
checkpoint	SEC_CONTENT
that	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
fork	SEC_CONTENT
steps	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
answer	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
questions	SEC_CONTENT
:	SEC_END
Effect	SECTITLE_START
of	SECTITLE_CONTENT
Number	SECTITLE_CONTENT
of	SECTITLE_CONTENT
Training	SECTITLE_CONTENT
Steps	SECTITLE_END
1	SEC_START
.	SEC_CONTENT
Question	task
:	SEC_CONTENT
Does	SEC_CONTENT
BERT	SEC_CONTENT
really	SEC_CONTENT
need	SEC_CONTENT
such	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
128,000	SEC_CONTENT
words	SEC_CONTENT
/	SEC_CONTENT
batch	SEC_CONTENT
*	SEC_CONTENT
1,000,000	SEC_CONTENT
steps	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
high	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
accuracy	SEC_CONTENT
?	SEC_CONTENT
Answer	SEC_CONTENT
:	SEC_CONTENT
Yes	SEC_CONTENT
,	SEC_CONTENT
BERT	SEC_CONTENT
BASE	SEC_CONTENT
achieves	SEC_CONTENT
almost	SEC_CONTENT
1.0	SEC_CONTENT
%	SEC_CONTENT
additional	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
MNLI	SEC_CONTENT
when	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
1	SEC_CONTENT
M	SEC_CONTENT
steps	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
500k	SEC_CONTENT
steps	SEC_CONTENT
.	SEC_END
2	SEC_START
.	SEC_CONTENT
Question	task
:	SEC_CONTENT
Does	SEC_CONTENT
MLM	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
converge	SEC_CONTENT
slower	SEC_CONTENT
than	SEC_CONTENT
LTR	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
only	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
are	SEC_CONTENT
predicted	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
batch	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
every	SEC_CONTENT
word	SEC_CONTENT
?	SEC_END
Answer	SEC_START
:	SEC_CONTENT
The	SEC_CONTENT
MLM	SEC_CONTENT
model	SEC_CONTENT
does	SEC_CONTENT
converge	SEC_CONTENT
slightly	SEC_CONTENT
slower	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
LTR	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
terms	metric
of	SEC_CONTENT
absolute	SEC_CONTENT
accuracy	SEC_CONTENT
the	SEC_CONTENT
MLM	SEC_CONTENT
model	SEC_CONTENT
begins	SEC_CONTENT
to	SEC_CONTENT
outperform	SEC_CONTENT
the	SEC_CONTENT
LTR	SEC_CONTENT
model	SEC_CONTENT
almost	SEC_CONTENT
immediately	SEC_CONTENT
.	SEC_END
Feature	SECTITLE_START
-	SECTITLE_CONTENT
based	SECTITLE_CONTENT
Approach	SECTITLE_CONTENT
with	SECTITLE_CONTENT
BERT	SECTITLE_END
All	SEC_START
of	SEC_CONTENT
the	SEC_CONTENT
BERT	SEC_CONTENT
results	SEC_CONTENT
presented	SEC_CONTENT
so	SEC_CONTENT
far	SEC_CONTENT
have	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
classification	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
all	SEC_CONTENT
parameters	SEC_CONTENT
are	SEC_CONTENT
jointly	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuned	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
downstream	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
fixed	SEC_CONTENT
features	SEC_CONTENT
are	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
pretrained	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
has	SEC_CONTENT
certain	SEC_CONTENT
advantages	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
not	SEC_CONTENT
all	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
easily	SEC_CONTENT
be	SEC_CONTENT
represented	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
Transformer	SEC_CONTENT
encoder	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
therefore	SEC_CONTENT
require	SEC_CONTENT
a	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
model	SEC_CONTENT
architecture	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
added	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
major	SEC_CONTENT
computational	SEC_CONTENT
benefits	SEC_CONTENT
to	SEC_CONTENT
being	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
compute	SEC_CONTENT
an	task
expensive	task
representation	task
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
once	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
run	SEC_CONTENT
many	SEC_CONTENT
experiments	SEC_CONTENT
with	SEC_CONTENT
less	SEC_CONTENT
expensive	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
we	SEC_CONTENT
evaluate	SEC_CONTENT
how	SEC_CONTENT
well	SEC_CONTENT
BERT	SEC_CONTENT
performs	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approach	SEC_CONTENT
by	SEC_CONTENT
generating	SEC_CONTENT
ELMo	metric
-	SEC_CONTENT
like	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
contextual	SEC_CONTENT
representations	SEC_CONTENT
on	SEC_CONTENT
the	dataset
CoNLL-2003	dataset
NER	dataset
task	dataset
.	SEC_CONTENT
To	SEC_CONTENT
do	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	task
same	task
input	task
representation	task
as	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
4.3	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
activations	SEC_CONTENT
from	SEC_CONTENT
one	SEC_CONTENT
or	SEC_CONTENT
more	SEC_CONTENT
layers	SEC_CONTENT
without	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
any	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
BERT	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
contextual	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
randomly	SEC_CONTENT
initialized	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
768-dimensional	SEC_CONTENT
BiL	SEC_CONTENT
-	SEC_CONTENT
STM	SEC_CONTENT
before	SEC_CONTENT
the	SEC_CONTENT
classification	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_END
Results	SEC_START
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
best	SEC_CONTENT
performing	SEC_CONTENT
method	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
concatenate	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
representations	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
four	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
pretrained	SEC_CONTENT
Transformer	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
0.3	SEC_CONTENT
F1	SEC_CONTENT
behind	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
demonstrates	SEC_CONTENT
that	SEC_CONTENT
BERT	SEC_CONTENT
is	SEC_CONTENT
effective	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
and	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_END
Layers	SECTITLE_END
Dev	SEC_START
:	SEC_CONTENT
Ablation	SEC_CONTENT
using	SEC_CONTENT
BERT	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approach	SEC_CONTENT
on	SEC_CONTENT
CoNLL-2003	dataset
NER	dataset
.	SEC_CONTENT
The	SEC_CONTENT
activations	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
specified	SEC_CONTENT
layers	SEC_CONTENT
are	SEC_CONTENT
combined	SEC_CONTENT
and	SEC_CONTENT
fed	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
BiLSTM	SEC_CONTENT
,	SEC_CONTENT
without	SEC_CONTENT
backpropagation	SEC_CONTENT
to	SEC_CONTENT
BERT	SEC_CONTENT
.	SEC_END
Recent	SEC_START
empirical	SEC_CONTENT
improvements	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
transfer	SEC_CONTENT
learning	SEC_CONTENT
with	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
have	SEC_CONTENT
demonstrated	SEC_CONTENT
that	SEC_CONTENT
rich	SEC_CONTENT
,	SEC_CONTENT
unsupervised	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
integral	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
many	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
results	SEC_CONTENT
enable	SEC_CONTENT
even	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
resource	SEC_CONTENT
tasks	SEC_CONTENT
to	SEC_CONTENT
benefit	SEC_CONTENT
from	SEC_CONTENT
very	SEC_CONTENT
deep	SEC_CONTENT
unidirectional	SEC_CONTENT
architectures	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
major	SEC_CONTENT
contribution	SEC_CONTENT
is	SEC_CONTENT
further	SEC_CONTENT
generalizing	SEC_CONTENT
these	SEC_CONTENT
findings	SEC_CONTENT
to	SEC_CONTENT
deep	SEC_CONTENT
bidirectional	SEC_CONTENT
architectures	SEC_CONTENT
,	SEC_CONTENT
allowing	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
successfully	SEC_CONTENT
tackle	SEC_CONTENT
abroad	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
the	SEC_CONTENT
empirical	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
strong	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
some	task
cases	task
surpassing	SEC_CONTENT
human	SEC_CONTENT
performance	SEC_CONTENT
,	SEC_CONTENT
important	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
linguistic	SEC_CONTENT
phenomena	SEC_CONTENT
that	SEC_CONTENT
mayor	SEC_CONTENT
may	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
captured	SEC_CONTENT
by	SEC_CONTENT
BERT	SEC_CONTENT
.	SEC_END
