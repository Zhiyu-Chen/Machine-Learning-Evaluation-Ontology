title	SECTITLE_END
Direct	SEC_START
Output	SEC_CONTENT
Connection	SEC_CONTENT
fora	SEC_CONTENT
High	SEC_CONTENT
-	SEC_CONTENT
Rank	SEC_CONTENT
Language	SEC_CONTENT
Model	SEC_END
abstract	SECTITLE_END
This	SEC_START
paper	SEC_CONTENT
proposes	SEC_CONTENT
a	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
RNN	task
)	task
language	task
model	task
that	SEC_CONTENT
combines	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
computed	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
final	SEC_CONTENT
RNN	SEC_CONTENT
layer	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
from	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
proposed	SEC_CONTENT
method	SEC_CONTENT
raises	SEC_CONTENT
the	SEC_CONTENT
expressive	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
matrix	SEC_CONTENT
factorization	SEC_CONTENT
interpretation	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
introduced	SEC_CONTENT
by	SEC_CONTENT
Yang	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
2018	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
proposed	SEC_CONTENT
method	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
score	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
and	SEC_CONTENT
WikiText-2	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
benchmark	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
indicate	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
method	SEC_CONTENT
contributes	SEC_CONTENT
to	SEC_CONTENT
two	SEC_CONTENT
application	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
code	SEC_CONTENT
is	SEC_CONTENT
publicly	SEC_CONTENT
available	SEC_CONTENT
at	SEC_CONTENT
:	SEC_CONTENT
https://github.com/nttcslab-nlp/doc	SEC_CONTENT
lm	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Neural	SEC_START
network	task
language	task
models	task
have	SEC_CONTENT
played	SEC_CONTENT
a	SEC_CONTENT
central	SEC_CONTENT
role	SEC_CONTENT
in	SEC_CONTENT
recent	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
(	SEC_CONTENT
NLP	SEC_CONTENT
)	SEC_CONTENT
advances	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
neural	SEC_CONTENT
encoderdecoder	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
were	SEC_CONTENT
successfully	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
various	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
generation	SEC_CONTENT
tasks	SEC_CONTENT
including	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
summarization	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
dialogue	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
interpreted	SEC_CONTENT
as	SEC_CONTENT
conditional	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
also	SEC_CONTENT
positively	SEC_CONTENT
influence	SEC_CONTENT
syntactic	SEC_CONTENT
parsing	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
methods	SEC_CONTENT
as	SEC_CONTENT
Skipgram	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
vLBL	SEC_CONTENT
)	SEC_CONTENT
originated	SEC_CONTENT
from	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
designed	SEC_CONTENT
to	SEC_CONTENT
handle	SEC_CONTENT
much	SEC_CONTENT
larger	SEC_CONTENT
vocabulary	SEC_CONTENT
and	SEC_CONTENT
data	SEC_CONTENT
sizes	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
as	SEC_CONTENT
contextualized	SEC_CONTENT
word	SEC_CONTENT
representations	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
benchmark	SEC_CONTENT
task	SEC_CONTENT
for	SEC_CONTENT
investigating	SEC_CONTENT
the	SEC_CONTENT
general	SEC_CONTENT
frameworks	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
methods	SEC_CONTENT
in	SEC_CONTENT
NLP	SEC_CONTENT
field	SEC_CONTENT
.	SEC_END
In	SEC_START
language	task
modeling	task
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
joint	SEC_CONTENT
probability	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
product	SEC_CONTENT
of	SEC_CONTENT
conditional	SEC_CONTENT
probabilities	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
T	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
sequence	SEC_CONTENT
with	SEC_CONTENT
length	SEC_CONTENT
T	SEC_CONTENT
:	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
T	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
obtain	SEC_CONTENT
the	SEC_CONTENT
joint	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
sequence	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
T	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_CONTENT
p(w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
T	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
p(w	SEC_CONTENT
1	SEC_CONTENT
)	SEC_END
T	SEC_START
−1	SEC_CONTENT
t=1	SEC_CONTENT
p(w	SEC_CONTENT
t+1	SEC_CONTENT
|w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
(	SEC_START
1	SEC_CONTENT
)	SEC_CONTENT
p(w	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
assumed	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
1	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
literature	SEC_CONTENT
,	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
,	SEC_CONTENT
p(w	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
thus	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
ignore	SEC_CONTENT
its	SEC_CONTENT
calculation	SEC_CONTENT
.	SEC_CONTENT
See	SEC_CONTENT
the	SEC_CONTENT
implementation	SEC_CONTENT
of	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
example	SEC_CONTENT
.	SEC_CONTENT
RNN	task
language	task
models	task
obtain	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
p(w	SEC_CONTENT
t+1	SEC_CONTENT
|w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
encode	SEC_CONTENT
sequence	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
t	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
vector	SEC_CONTENT
and	SEC_CONTENT
apply	SEC_CONTENT
a	SEC_CONTENT
transformation	SEC_CONTENT
matrix	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
Previous	SEC_CONTENT
researches	SEC_CONTENT
demonstrated	SEC_CONTENT
that	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
achieve	SEC_CONTENT
high	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
several	SEC_CONTENT
regularizations	SEC_CONTENT
and	SEC_CONTENT
selecting	SEC_CONTENT
appropriate	SEC_CONTENT
hyperparameters	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
proved	SEC_CONTENT
that	SEC_CONTENT
existing	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
have	SEC_CONTENT
low	SEC_CONTENT
expressive	SEC_CONTENT
power	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
Softmax	SEC_CONTENT
bottleneck	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
means	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
matrix	SEC_CONTENT
of	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
is	SEC_CONTENT
low	SEC_CONTENT
rank	SEC_CONTENT
when	SEC_CONTENT
we	SEC_CONTENT
interpret	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
factorization	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
solve	SEC_CONTENT
the	SEC_CONTENT
Softmax	SEC_CONTENT
bottleneck	SEC_CONTENT
,	SEC_CONTENT
proposed	SEC_CONTENT
Mixture	SEC_CONTENT
of	SEC_CONTENT
Softmaxes	SEC_CONTENT
(	SEC_CONTENT
MoS	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
increases	SEC_CONTENT
the	SEC_CONTENT
rank	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
matrix	SEC_CONTENT
by	SEC_CONTENT
combining	SEC_CONTENT
multiple	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
computed	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
encoded	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
vector	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
study	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
Direct	SEC_CONTENT
Output	SEC_CONTENT
Connection	SEC_CONTENT
(	SEC_CONTENT
DOC	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
generalization	SEC_CONTENT
of	SEC_CONTENT
MoS.	SEC_CONTENT
For	SEC_CONTENT
stacked	SEC_CONTENT
RNNs	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
computes	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
including	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
raising	SEC_CONTENT
the	dataset
rank	dataset
,	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
method	SEC_CONTENT
helps	SEC_CONTENT
weaken	SEC_CONTENT
the	SEC_CONTENT
vanishing	SEC_CONTENT
gradient	SEC_CONTENT
problem	SEC_CONTENT
in	SEC_CONTENT
backpropagation	SEC_CONTENT
because	SEC_CONTENT
DOC	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
shortcut	SEC_CONTENT
connection	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
.	SEC_END
We	SEC_START
conduct	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
standard	SEC_CONTENT
benchmark	SEC_CONTENT
datasets	SEC_CONTENT
for	SEC_CONTENT
language	task
modeling	task
:	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
and	SEC_CONTENT
WikiText-2	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
experiments	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
outperforms	SEC_CONTENT
MoS	SEC_CONTENT
and	SEC_CONTENT
achieves	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
theart	SEC_CONTENT
perplexities	SEC_CONTENT
on	SEC_CONTENT
each	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
on	SEC_CONTENT
two	SEC_CONTENT
applications	SEC_CONTENT
:	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
indicate	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
can	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
baseline	SEC_CONTENT
for	SEC_CONTENT
such	SEC_CONTENT
applications	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
an	SEC_CONTENT
experiment	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
constituency	SEC_CONTENT
parsing	SEC_CONTENT
task	SEC_CONTENT
to	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
.	SEC_END
RNN	SECTITLE_START
Language	SECTITLE_CONTENT
Model	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
briefly	SEC_CONTENT
overview	SEC_CONTENT
RNN	task
language	task
models	task
.	SEC_CONTENT
Let	SEC_CONTENT
V	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
size	SEC_CONTENT
and	SEC_CONTENT
let	SEC_CONTENT
Pt	SEC_CONTENT
∈	SEC_CONTENT
RV	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
at	SEC_CONTENT
timestep	SEC_CONTENT
t.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
let	SEC_CONTENT
D	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
dimension	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
RNN	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
let	SEC_CONTENT
D	SEC_CONTENT
e	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
dimensions	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
the	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
predict	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
P	SEC_CONTENT
t+1	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equation	SEC_CONTENT
:	SEC_END
where	SEC_START
W	SEC_CONTENT
∈	SEC_CONTENT
RV	SEC_CONTENT
×D	SEC_CONTENT
h	SEC_CONTENT
N	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
E	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
De×V	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
matrix	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
V	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
hot	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
wt	SEC_CONTENT
at	SEC_CONTENT
timestep	metric
t	metric
,	SEC_CONTENT
and	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
t	SEC_CONTENT
∈	SEC_CONTENT
RD	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
RNN	SEC_CONTENT
at	SEC_CONTENT
timestep	SEC_CONTENT
t.	SEC_CONTENT
We	SEC_CONTENT
define	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
tat	SEC_CONTENT
timestep	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
0	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
zero	SEC_CONTENT
vector	SEC_CONTENT
:	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
0	SEC_CONTENT
=	SEC_CONTENT
0	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
f	SEC_CONTENT
(	SEC_CONTENT
·	SEC_CONTENT
)	SEC_CONTENT
represent	SEC_CONTENT
an	SEC_CONTENT
abstract	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
RNN	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
might	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
Elman	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
Long	SEC_CONTENT
Short	SEC_CONTENT
-	SEC_CONTENT
Term	SEC_CONTENT
Memory	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
indicated	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
interpreted	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
factorization	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
briefly	SEC_CONTENT
introduce	SEC_CONTENT
their	SEC_CONTENT
description	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
word	SEC_CONTENT
sequence	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
t	SEC_CONTENT
be	SEC_CONTENT
context	SEC_CONTENT
ct	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
regard	SEC_CONTENT
a	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
finite	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
pairs	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
:	SEC_END
Language	SECTITLE_START
Modeling	SECTITLE_CONTENT
as	SECTITLE_CONTENT
Matrix	SECTITLE_CONTENT
Factorization	SECTITLE_END
where	SEC_START
U	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
contexts	SEC_CONTENT
and	SEC_CONTENT
X	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
V	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
representing	SEC_CONTENT
a	SEC_CONTENT
onehot	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
Here	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
matrix	SEC_CONTENT
A	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
U	SEC_CONTENT
×V	SEC_CONTENT
that	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
log	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
and	SEC_CONTENT
matrix	SEC_CONTENT
H	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
U	SEC_CONTENT
×D	SEC_CONTENT
h	SEC_CONTENT
N	SEC_CONTENT
that	SEC_CONTENT
contains	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
RNN	SEC_CONTENT
layer	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
context	SEC_CONTENT
ct	SEC_CONTENT
:	SEC_END
Then	SEC_START
we	SEC_CONTENT
obtain	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
matrices	SEC_CONTENT
F	SEC_CONTENT
(	SEC_CONTENT
A	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
A	SEC_CONTENT
+	SEC_CONTENT
ΛS	SEC_CONTENT
}	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
S	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
U	SEC_CONTENT
×V	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
ones	SEC_CONTENT
matrix	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Λ	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
U	SEC_CONTENT
×U	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
diagonal	SEC_CONTENT
matrix	SEC_CONTENT
.	SEC_CONTENT
F	SEC_CONTENT
(	SEC_CONTENT
A	SEC_CONTENT
)	SEC_CONTENT
contains	SEC_CONTENT
matrices	SEC_CONTENT
that	SEC_CONTENT
shifted	SEC_CONTENT
each	SEC_CONTENT
row	SEC_CONTENT
of	SEC_CONTENT
A	SEC_CONTENT
by	SEC_CONTENT
an	SEC_CONTENT
arbitrary	SEC_CONTENT
real	SEC_CONTENT
number	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
take	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
from	SEC_CONTENT
F	SEC_CONTENT
(	SEC_CONTENT
A	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
function	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
rows	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
obtain	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
that	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
true	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
some	SEC_CONTENT
A	SEC_CONTENT
∈	SEC_CONTENT
F	SEC_CONTENT
(	SEC_CONTENT
A	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
training	SEC_CONTENT
RNN	task
language	task
models	task
is	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
satisfying	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equation	SEC_CONTENT
:	SEC_CONTENT
 	SEC_CONTENT
In	SEC_CONTENT
summary	SEC_CONTENT
,	SEC_CONTENT
indicated	SEC_CONTENT
that	SEC_CONTENT
D	SEC_CONTENT
h	SEC_CONTENT
N	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
smaller	SEC_CONTENT
than	SEC_CONTENT
rank(A	SEC_CONTENT
)	SEC_CONTENT
because	SEC_CONTENT
its	SEC_CONTENT
scale	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
10	SEC_CONTENT
2	SEC_CONTENT
and	SEC_CONTENT
vocabulary	SEC_CONTENT
size	SEC_CONTENT
V	SEC_CONTENT
is	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
10	SEC_CONTENT
4	SEC_CONTENT
.	SEC_END
Proposed	SECTITLE_START
Method	SECTITLE_CONTENT
:	SECTITLE_CONTENT
Direct	SECTITLE_CONTENT
Output	SECTITLE_CONTENT
Connection	SECTITLE_END
To	SEC_START
construct	SEC_CONTENT
a	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
rank	SEC_CONTENT
matrix	SEC_CONTENT
,	SEC_CONTENT
proposed	SEC_CONTENT
Mixture	SEC_CONTENT
of	SEC_CONTENT
Softmaxes	SEC_CONTENT
(	SEC_CONTENT
MoS	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
MoS	SEC_CONTENT
computes	SEC_CONTENT
multiple	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
final	SEC_CONTENT
RNN	SEC_CONTENT
layer	SEC_CONTENT
h	SEC_CONTENT
N	SEC_CONTENT
and	SEC_CONTENT
regards	SEC_CONTENT
the	SEC_CONTENT
weighted	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
distribution	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
study	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
Direct	SEC_CONTENT
Output	SEC_CONTENT
Connection	SEC_CONTENT
(	SEC_CONTENT
DOC	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
generalization	SEC_CONTENT
method	SEC_CONTENT
of	SEC_CONTENT
MoS.	SEC_CONTENT
DOC	SEC_CONTENT
computes	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
directly	SEC_CONTENT
connects	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
an	SEC_CONTENT
overview	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
,	SEC_CONTENT
that	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
(	SEC_CONTENT
including	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
computes	SEC_CONTENT
three	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
vary	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
and	SEC_CONTENT
select	SEC_CONTENT
some	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
search	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
appropriate	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_END
Formally	SEC_START
,	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
Equation	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
computes	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
at	SEC_CONTENT
timestep	metric
t	metric
+	SEC_CONTENT
1	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equation	SEC_CONTENT
:	SEC_END
s.t	SEC_START
.	SEC_END
where	SEC_START
π	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
∈	SEC_CONTENT
Rd	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
computed	SEC_CONTENT
from	SEC_CONTENT
each	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
and˜Wand˜	SEC_CONTENT
and˜W	SEC_CONTENT
∈	SEC_CONTENT
RV	SEC_CONTENT
×d	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
P	SEC_CONTENT
t+1	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
weighted	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
J	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
define	SEC_CONTENT
the	SEC_CONTENT
U	SEC_CONTENT
×	SEC_CONTENT
U	SEC_CONTENT
diagonal	SEC_CONTENT
matrix	SEC_CONTENT
whose	SEC_CONTENT
elements	SEC_CONTENT
are	SEC_CONTENT
weight	SEC_CONTENT
π	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
context	SEC_CONTENT
c	SEC_CONTENT
as	SEC_CONTENT
Φ.	SEC_CONTENT
Then	SEC_CONTENT
we	SEC_CONTENT
obtain	SEC_CONTENT
matrix˜Amatrix˜	SEC_CONTENT
matrix˜A	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
U	SEC_CONTENT
×V	SEC_CONTENT
:	SEC_END
where	SEC_START
K	SEC_CONTENT
j	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
U	SEC_CONTENT
×d	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
whose	SEC_CONTENT
rows	SEC_CONTENT
are	SEC_CONTENT
vector	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
.	SEC_CONTENT
˜	SEC_CONTENT
A	SEC_CONTENT
can	SEC_CONTENT
bean	SEC_CONTENT
arbitrary	SEC_CONTENT
high	SEC_CONTENT
rank	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
righthand	SEC_CONTENT
side	SEC_CONTENT
of	SEC_CONTENT
Equation	SEC_CONTENT
9	SEC_CONTENT
computes	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
matrix	SEC_CONTENT
multiplication	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
a	SEC_CONTENT
nonlinear	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
an	task
RNN	task
language	task
model	task
with	SEC_CONTENT
DOC	SEC_CONTENT
can	SEC_CONTENT
output	SEC_CONTENT
a	SEC_CONTENT
distribution	SEC_CONTENT
matrix	SEC_CONTENT
whose	SEC_CONTENT
rank	SEC_CONTENT
is	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
˜	SEC_CONTENT
A	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
better	SEC_CONTENT
approximation	SEC_CONTENT
of	SEC_CONTENT
A	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Next	SEC_START
we	SEC_CONTENT
describe	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
acquire	SEC_CONTENT
weight	SEC_CONTENT
π	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
and	SEC_CONTENT
vector	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
π	SEC_CONTENT
ct	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
J	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
whose	SEC_CONTENT
elements	SEC_CONTENT
are	SEC_CONTENT
weight	SEC_CONTENT
π	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
π	SEC_CONTENT
ct	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
RNN	SEC_CONTENT
layer	SEC_CONTENT
:	SEC_END
where	SEC_START
W	SEC_CONTENT
π	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
J×D	SEC_CONTENT
h	SEC_CONTENT
N	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
next	SEC_CONTENT
compute	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
RNN	SEC_CONTENT
layer	SEC_CONTENT
:	SEC_END
where	SEC_START
W	SEC_CONTENT
j	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×D	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
let	SEC_CONTENT
in	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
from	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
t	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
we	SEC_CONTENT
define	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
in	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
n	SEC_CONTENT
as	SEC_CONTENT
J	SEC_CONTENT
;	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
,	SEC_CONTENT
N	SEC_CONTENT
n=0	SEC_CONTENT
in	SEC_CONTENT
=	SEC_CONTENT
J.	SEC_CONTENT
In	SEC_CONTENT
short	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
computes	SEC_CONTENT
J	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
embedding	SEC_CONTENT
(	SEC_CONTENT
h	SEC_CONTENT
0	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
i	SEC_CONTENT
N	SEC_CONTENT
=	SEC_CONTENT
J	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
becomes	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
MoS.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
increasing	SEC_CONTENT
the	dataset
rank	dataset
,	SEC_CONTENT
we	SEC_CONTENT
expect	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
weakens	SEC_CONTENT
the	SEC_CONTENT
vanishing	SEC_CONTENT
gradient	SEC_CONTENT
problem	SEC_CONTENT
during	SEC_CONTENT
backpropagation	SEC_CONTENT
because	SEC_CONTENT
a	SEC_CONTENT
middle	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
directly	SEC_CONTENT
connected	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
classifiers	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
For	SEC_START
a	SEC_CONTENT
network	SEC_CONTENT
that	SEC_CONTENT
computes	SEC_CONTENT
the	SEC_CONTENT
weights	SEC_CONTENT
for	SEC_CONTENT
several	SEC_CONTENT
vectors	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
Equation	SEC_CONTENT
10	SEC_CONTENT
,	SEC_CONTENT
indicated	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
often	SEC_CONTENT
converges	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
state	SEC_CONTENT
where	SEC_CONTENT
it	SEC_CONTENT
always	SEC_CONTENT
produces	SEC_CONTENT
large	task
weights	task
for	SEC_CONTENT
few	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
observed	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
tends	SEC_CONTENT
to	SEC_CONTENT
assign	SEC_CONTENT
large	SEC_CONTENT
weights	SEC_CONTENT
to	SEC_CONTENT
shallow	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
prevent	SEC_CONTENT
this	SEC_CONTENT
phenomenon	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
coefficient	SEC_CONTENT
of	SEC_CONTENT
variation	SEC_CONTENT
of	SEC_CONTENT
Equation	SEC_CONTENT
10	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
regularization	SEC_CONTENT
term	SEC_CONTENT
following	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
try	SEC_CONTENT
to	SEC_CONTENT
adjust	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
weights	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
with	SEC_CONTENT
identical	SEC_CONTENT
values	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
.	SEC_CONTENT
Formally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equation	SEC_CONTENT
fora	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
w	SEC_CONTENT
b	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
b+1	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
˜	SEC_CONTENT
b	SEC_CONTENT
:	SEC_END
where	SEC_START
functions	SEC_CONTENT
std	SEC_CONTENT
(	SEC_CONTENT
·	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
avg	SEC_CONTENT
(	SEC_CONTENT
·	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
functions	SEC_CONTENT
that	SEC_CONTENT
respectively	SEC_CONTENT
return	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
's	SEC_CONTENT
standard	SEC_CONTENT
deviation	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
average	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
multiplied	SEC_CONTENT
by	SEC_CONTENT
weight	SEC_CONTENT
coefficient	SEC_CONTENT
β	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
function	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_START
on	SECTITLE_CONTENT
Language	SECTITLE_CONTENT
Modeling	SECTITLE_END
We	SEC_START
investigate	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
on	SEC_CONTENT
the	task
language	task
modeling	task
task	task
.	SEC_CONTENT
In	SEC_CONTENT
detail	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
prediction	SEC_CONTENT
experiments	SEC_CONTENT
and	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
MoS	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
only	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
evaluate	SEC_CONTENT
various	SEC_CONTENT
combinations	SEC_CONTENT
of	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
explore	SEC_CONTENT
which	SEC_CONTENT
combination	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
score	SEC_CONTENT
.	SEC_END
Datasets	SECTITLE_END
We	SEC_START
used	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
(	SEC_CONTENT
PTB	SEC_CONTENT
)	SEC_CONTENT
(	SEC_END
Hyperparameters	SECTITLE_END
Our	SEC_START
implementation	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
averaged	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
Weight	SEC_CONTENT
-	SEC_CONTENT
Dropped	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
  	SEC_CONTENT
dropout	SEC_CONTENT
rate	SEC_CONTENT
for	SEC_CONTENT
vector	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
monotone	SEC_CONTENT
interval	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
dropout	SEC_CONTENT
rate	SEC_CONTENT
for	SEC_CONTENT
vector	SEC_CONTENT
k	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
ct	SEC_CONTENT
greatly	SEC_CONTENT
influences	SEC_CONTENT
β	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
13	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
varied	SEC_CONTENT
it	SEC_CONTENT
from	SEC_CONTENT
0.3	SEC_CONTENT
to	SEC_CONTENT
0.6	SEC_CONTENT
with	SEC_CONTENT
0.1	SEC_CONTENT
intervals	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
selected	SEC_CONTENT
0.6	SEC_CONTENT
because	SEC_CONTENT
this	SEC_CONTENT
value	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
score	SEC_CONTENT
on	SEC_CONTENT
the	metric
PTB	metric
validation	metric
dataset	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
nonmonotone	SEC_CONTENT
interval	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopted	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
value	SEC_CONTENT
as	SEC_CONTENT
.	SEC_CONTENT
summarizes	SEC_CONTENT
the	SEC_CONTENT
hyperparameters	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
   	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
t	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
combination	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
varied	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
by	SEC_CONTENT
fixing	SEC_CONTENT
their	SEC_CONTENT
total	SEC_CONTENT
to	SEC_CONTENT
20	SEC_CONTENT
:	SEC_CONTENT
J	SEC_CONTENT
=	SEC_CONTENT
20	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
row	SEC_CONTENT
of	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
of	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
MoS	SEC_CONTENT
reported	SEC_CONTENT
in	SEC_CONTENT
for	SEC_CONTENT
comparison	SEC_CONTENT
.	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
using	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
outperformed	SEC_CONTENT
one	SEC_CONTENT
using	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
20	SEC_CONTENT
)	SEC_CONTENT
degraded	SEC_CONTENT
the	SEC_CONTENT
score	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
15	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
row	SEC_CONTENT
of	SEC_CONTENT
Table	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
a	SEC_CONTENT
superior	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
should	SEC_CONTENT
not	SEC_CONTENT
increase	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
should	SEC_CONTENT
instead	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
with	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
DOC	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
15	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
5	SEC_CONTENT
setting	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
performance	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
settings	SEC_CONTENT
with	SEC_CONTENT
shallow	SEC_CONTENT
layers	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
little	SEC_CONTENT
effect	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
result	SEC_CONTENT
implies	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
need	SEC_CONTENT
some	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
output	SEC_CONTENT
accurate	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
previous	SEC_CONTENT
studies	SEC_CONTENT
adopted	SEC_CONTENT
two	SEC_CONTENT
LSTM	SEC_CONTENT
layers	SEC_CONTENT
for	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
need	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
two	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
quality	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
For	SEC_START
the	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
15	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
5	SEC_CONTENT
setting	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
explored	SEC_CONTENT
:	SEC_CONTENT
Perplexities	metric
of	SEC_CONTENT
our	SEC_CONTENT
implementations	SEC_CONTENT
and	SEC_CONTENT
reruns	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
PTB	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
monotone	SEC_CONTENT
interval	SEC_CONTENT
to	SEC_CONTENT
60	SEC_CONTENT
.	SEC_CONTENT
†	SEC_CONTENT
represents	SEC_CONTENT
results	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
original	SEC_CONTENT
implementations	SEC_CONTENT
with	SEC_CONTENT
identical	SEC_CONTENT
hyperparameters	SEC_CONTENT
except	SEC_CONTENT
for	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
monotone	SEC_CONTENT
interval	SEC_CONTENT
.	SEC_CONTENT
‡	SEC_CONTENT
indicates	SEC_CONTENT
the	SEC_CONTENT
result	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
our	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
implementation	SEC_CONTENT
with	SEC_CONTENT
identical	SEC_CONTENT
dropout	SEC_CONTENT
rates	SEC_CONTENT
as	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
(	SEC_CONTENT
fin	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
repeated	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
until	SEC_CONTENT
convergence	SEC_CONTENT
.	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
in	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
0.01	SEC_CONTENT
,	SEC_CONTENT
0.001	SEC_CONTENT
,	SEC_CONTENT
0.0001	SEC_CONTENT
}	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
=	SEC_CONTENT
0.001	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
perplexity	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
consistent	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
coefficient	SEC_CONTENT
of	SEC_CONTENT
variation	SEC_CONTENT
of	SEC_CONTENT
Equation	SEC_CONTENT
10	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
√	SEC_CONTENT
β	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
PTB	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
table	SEC_CONTENT
demonstrates	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
coefficient	SEC_CONTENT
of	SEC_CONTENT
variation	SEC_CONTENT
decreases	SEC_CONTENT
with	SEC_CONTENT
growth	SEC_CONTENT
in	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
assigns	SEC_CONTENT
balanced	SEC_CONTENT
weights	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
results	SEC_CONTENT
indicate	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
always	SEC_CONTENT
necessary	SEC_CONTENT
to	SEC_CONTENT
equally	SEC_CONTENT
use	SEC_CONTENT
each	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
acquire	SEC_CONTENT
a	SEC_CONTENT
better	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
some	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
.	SEC_CONTENT
Hereafter	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
setting	SEC_CONTENT
that	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
score	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
15	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
5	SEC_CONTENT
,	SEC_CONTENT
λ	SEC_CONTENT
β	SEC_CONTENT
=	SEC_CONTENT
0.001	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
ranks	SEC_CONTENT
of	SEC_CONTENT
matrices	SEC_CONTENT
containing	SEC_CONTENT
log	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
from	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
describes˜Adescribes˜	SEC_CONTENT
describes˜A	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
9	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
by	SEC_CONTENT
this	SEC_CONTENT
table	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
is	SEC_CONTENT
restricted	SEC_CONTENT
to	SEC_CONTENT
D	SEC_CONTENT
3	SEC_CONTENT
7	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
outputted	SEC_CONTENT
matrices	SEC_CONTENT
whose	SEC_CONTENT
ranks	SEC_CONTENT
equal	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
size	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
fact	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
(	SEC_CONTENT
including	SEC_CONTENT
MoS	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
output	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
matrix	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
distributions	SEC_CONTENT
in	SEC_CONTENT
view	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
rank	SEC_CONTENT
.	SEC_CONTENT
illustrates	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
curves	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
on	SEC_CONTENT
PTB	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
figure	SEC_CONTENT
contains	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
scores	SEC_CONTENT
of	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
training	SEC_CONTENT
epoch	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
by	SEC_CONTENT
setting	SEC_CONTENT
the	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
monotone	SEC_CONTENT
interval	SEC_CONTENT
to	SEC_CONTENT
60	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
with	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
hyperparameters	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
ones	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
,	SEC_CONTENT
except	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
monotone	SEC_CONTENT
interval	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
optimization	SEC_CONTENT
method	SEC_CONTENT
converts	SEC_CONTENT
the	SEC_CONTENT
ordinary	SEC_CONTENT
stochastic	SEC_CONTENT
20	SEC_CONTENT
M	SEC_CONTENT
81.9	SEC_CONTENT
±	SEC_CONTENT
0.2	SEC_CONTENT
79.7	SEC_CONTENT
±	SEC_CONTENT
0.1	SEC_CONTENT
Variational	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
large	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
  	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
(	SEC_CONTENT
SGD	SEC_CONTENT
)	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
averaged	SEC_CONTENT
SGD	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
point	SEC_CONTENT
where	SEC_CONTENT
convergence	SEC_CONTENT
almost	SEC_CONTENT
occurs	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
turning	SEC_CONTENT
point	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
epoch	SEC_CONTENT
when	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
drastically	SEC_CONTENT
decreases	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
similarly	SEC_CONTENT
reduces	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
beginning	SEC_CONTENT
.	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
were	SEC_CONTENT
slow	SEC_CONTENT
to	SEC_CONTENT
decrease	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
from	SEC_CONTENT
50	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
constantly	SEC_CONTENT
decreased	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
and	SEC_CONTENT
achieved	SEC_CONTENT
a	SEC_CONTENT
lower	SEC_CONTENT
value	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
methods	SEC_CONTENT
with	SEC_CONTENT
ordinary	SEC_CONTENT
SGD	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conclude	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
positively	SEC_CONTENT
affects	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTMMoS	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
configurations	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
trained	SEC_CONTENT
our	SEC_CONTENT
implementation	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
dropout	SEC_CONTENT
rates	SEC_CONTENT
as	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
fora	SEC_CONTENT
fair	SEC_CONTENT
comparison	SEC_CONTENT
.	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
outperformed	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
implementation	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
outperformed	SEC_CONTENT
MoS.	SEC_END
Since	SEC_START
the	SEC_CONTENT
averaged	SEC_CONTENT
SGD	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
averaged	SEC_CONTENT
parameters	SEC_CONTENT
from	SEC_CONTENT
each	SEC_CONTENT
update	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
the	metric
parameters	metric
of	SEC_CONTENT
the	SEC_CONTENT
early	SEC_CONTENT
steps	SEC_CONTENT
are	SEC_CONTENT
harmful	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
converges	SEC_CONTENT
,	SEC_CONTENT
recent	SEC_CONTENT
studies	SEC_CONTENT
and	SEC_CONTENT
ours	SEC_CONTENT
eliminate	SEC_CONTENT
the	SEC_CONTENT
history	SEC_CONTENT
of	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
retrains	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
referred	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
retraining	SEC_CONTENT
process	SEC_CONTENT
as	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
most	SEC_CONTENT
previous	SEC_CONTENT
studies	SEC_CONTENT
only	SEC_CONTENT
conducted	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
once	SEC_CONTENT
,	SEC_CONTENT
argued	SEC_CONTENT
that	SEC_CONTENT
two	SEC_CONTENT
finetunings	SEC_CONTENT
provided	SEC_CONTENT
additional	SEC_CONTENT
improvement	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
repeated	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
until	SEC_CONTENT
we	SEC_CONTENT
achieved	SEC_CONTENT
no	SEC_CONTENT
more	SEC_CONTENT
improvements	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
as	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
(	SEC_CONTENT
fin	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
repeated	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tunings	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
by	SEC_CONTENT
about	SEC_CONTENT
0.5	SEC_CONTENT
.	SEC_CONTENT
respectively	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
perplexities	SEC_CONTENT
of	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
and	SEC_CONTENT
previous	SEC_CONTENT
studies	SEC_CONTENT
on	SEC_CONTENT
PTB	SEC_CONTENT
and	SEC_CONTENT
WikiText-2	SEC_CONTENT
8	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
tables	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
perplexity	SEC_CONTENT
.	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
by	SEC_CONTENT
almost	SEC_CONTENT
2.0	SEC_CONTENT
on	SEC_CONTENT
PTB	SEC_CONTENT
and	SEC_CONTENT
3.5	SEC_CONTENT
on	SEC_CONTENT
WikiText-2	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
scores	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
ensemble	SEC_CONTENT
technique	SEC_CONTENT
provided	SEC_CONTENT
further	SEC_CONTENT
improvement	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
previous	SEC_CONTENT
studies	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
by	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
4	SEC_CONTENT
points	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
ensemble	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
repeated	SEC_CONTENT
finetuning	SEC_CONTENT
models	SEC_CONTENT
achieved	SEC_CONTENT
47.17	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
PTB	SEC_CONTENT
test	SEC_CONTENT
and	SEC_CONTENT
53.09	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
WikiText-2	SEC_CONTENT
test	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_START
on	SECTITLE_CONTENT
Application	SECTITLE_CONTENT
Tasks	SECTITLE_END
As	SEC_START
described	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
interpreted	SEC_CONTENT
as	SEC_CONTENT
a	task
conditional	task
language	task
model	task
.	SEC_CONTENT
To	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
on	SEC_CONTENT
an	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
incorporate	SEC_CONTENT
DOC	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
and	SEC_CONTENT
examine	SEC_CONTENT
its	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
Dataset	SECTITLE_END
We	SEC_START
conducted	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
two	SEC_CONTENT
kinds	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
(	SEC_CONTENT
EnglishGerman	SEC_CONTENT
and	SEC_CONTENT
English	SEC_CONTENT
-	SEC_CONTENT
French	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
IWSLT	SEC_CONTENT
2016	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
respectively	SEC_CONTENT
contains	SEC_CONTENT
about	SEC_CONTENT
189	SEC_CONTENT
K	SEC_CONTENT
and	SEC_CONTENT
208	SEC_CONTENT
K	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
of	SEC_CONTENT
EnglishGerman	SEC_CONTENT
and	SEC_CONTENT
English	SEC_CONTENT
-	SEC_CONTENT
French	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
experimented	SEC_CONTENT
in	SEC_CONTENT
four	SEC_CONTENT
settings	SEC_CONTENT
:	SEC_CONTENT
from	SEC_CONTENT
English	SEC_CONTENT
to	SEC_CONTENT
German	SEC_CONTENT
(	SEC_CONTENT
En	SEC_CONTENT
-	SEC_CONTENT
De	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
its	SEC_CONTENT
reverse	SEC_CONTENT
(	SEC_CONTENT
De	SEC_CONTENT
-	SEC_CONTENT
En	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
from	SEC_CONTENT
English	SEC_CONTENT
to	SEC_CONTENT
French	SEC_CONTENT
(	SEC_CONTENT
En	SEC_CONTENT
-	SEC_CONTENT
Fr	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
reverse	SEC_CONTENT
(	SEC_CONTENT
Fr	SEC_CONTENT
-	SEC_CONTENT
En	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Headline	SEC_START
generation	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
task	SEC_CONTENT
that	SEC_CONTENT
creates	SEC_CONTENT
a	SEC_CONTENT
short	SEC_CONTENT
summarization	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
constructed	SEC_CONTENT
a	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
dataset	SEC_CONTENT
by	SEC_CONTENT
extracting	SEC_CONTENT
pairs	SEC_CONTENT
of	SEC_CONTENT
first	SEC_CONTENT
sentences	SEC_CONTENT
of	SEC_CONTENT
news	SEC_CONTENT
articles	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
headlines	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
annotated	SEC_CONTENT
English	SEC_CONTENT
Gigaword	SEC_CONTENT
corpus	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
also	SEC_CONTENT
divided	SEC_CONTENT
the	SEC_CONTENT
extracted	SEC_CONTENT
sentenceheadline	SEC_CONTENT
pairs	SEC_CONTENT
into	SEC_CONTENT
three	SEC_CONTENT
parts	SEC_CONTENT
:	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
validation	metric
,	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
contains	SEC_CONTENT
about	SEC_CONTENT
3.8	SEC_CONTENT
M	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
headline	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
our	SEC_CONTENT
evaluation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
constructed	SEC_CONTENT
by	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
constructed	SEC_CONTENT
by	SEC_CONTENT
contains	SEC_CONTENT
some	SEC_CONTENT
invalid	SEC_CONTENT
instances	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
reported	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Encoder	SECTITLE_START
-	SECTITLE_CONTENT
Decoder	SECTITLE_CONTENT
Model	SECTITLE_END
For	SEC_START
the	task
base	task
model	task
,	SEC_CONTENT
we	SEC_CONTENT
adopted	SEC_CONTENT
an	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
encoder	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
2-layer	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
2-layer	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
attention	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
interpreted	SEC_CONTENT
the	SEC_CONTENT
layer	SEC_CONTENT
after	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
3rd	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
as	SEC_CONTENT
EncDec	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
hyperparameters	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
followed	SEC_CONTENT
the	SEC_CONTENT
setting	SEC_CONTENT
of	SEC_CONTENT
except	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
sizes	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
and	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
500	SEC_CONTENT
for	SEC_CONTENT
machine	SEC_CONTENT
  	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
400	SEC_CONTENT
for	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
constructed	SEC_CONTENT
a	SEC_CONTENT
vocabulary	SEC_CONTENT
set	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
Byte	SEC_CONTENT
-	SEC_CONTENT
PairEncoding	SEC_CONTENT
10	SEC_CONTENT
(	SEC_CONTENT
BPE	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
BPE	SEC_CONTENT
merge	SEC_CONTENT
operations	SEC_CONTENT
at	SEC_CONTENT
16	SEC_CONTENT
K	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
K	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_END
In	SEC_START
this	metric
experiment	metric
,	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
DOC	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
base	SEC_CONTENT
EncDec	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
prepared	SEC_CONTENT
two	SEC_CONTENT
DOC	SEC_CONTENT
settings	SEC_CONTENT
:	SEC_CONTENT
using	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
setting	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
MoS	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
using	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
and	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
2nd	SEC_CONTENT
and	SEC_CONTENT
3rd	SEC_CONTENT
layers	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
latter	SEC_CONTENT
setting	SEC_CONTENT
because	SEC_CONTENT
this	SEC_CONTENT
case	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
task	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
5.3	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
and	SEC_CONTENT
i	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
this	SEC_CONTENT
experiment	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
modified	SEC_CONTENT
a	SEC_CONTENT
publicly	SEC_CONTENT
available	SEC_CONTENT
encode	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
implementation	SEC_CONTENT
11	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
BLEU	SEC_CONTENT
scores	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
an	SEC_CONTENT
initial	SEC_CONTENT
value	SEC_CONTENT
often	SEC_CONTENT
drastically	SEC_CONTENT
varies	SEC_CONTENT
the	SEC_CONTENT
result	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
reported	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
three	SEC_CONTENT
models	SEC_CONTENT
trained	SEC_CONTENT
from	SEC_CONTENT
different	SEC_CONTENT
initial	SEC_CONTENT
values	SEC_CONTENT
and	SEC_CONTENT
random	SEC_CONTENT
seeds	SEC_CONTENT
.	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
EncDec+DOC	SEC_CONTENT
outperformed	SEC_CONTENT
EncDec	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
ROUGE	SEC_CONTENT
F1	SEC_CONTENT
scores	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
implementations	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
upper	SEC_CONTENT
part	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
lower	SEC_CONTENT
part	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
published	SEC_CONTENT
scores	SEC_CONTENT
reported	SEC_CONTENT
in	SEC_CONTENT
previous	SEC_CONTENT
studies	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
upper	SEC_CONTENT
part	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
reported	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
three	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
EncDec+DOC	SEC_CONTENT
outperformed	SEC_CONTENT
EncDec	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
scores	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
EncDec	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
method	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
ROUGE-2	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
F1	SEC_CONTENT
scores	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
other	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
is	SEC_CONTENT
already	SEC_CONTENT
very	SEC_CONTENT
strong	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
believe	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
adopted	SEC_CONTENT
a	SEC_CONTENT
larger	SEC_CONTENT
embedding	SEC_CONTENT
size	SEC_CONTENT
than	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
noteworthy	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
EncDec	SEC_CONTENT
even	SEC_CONTENT
though	SEC_CONTENT
EncDec	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
strong	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
These	SEC_START
results	SEC_CONTENT
indicate	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
positively	SEC_CONTENT
influences	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Using	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layer	SEC_CONTENT
also	SEC_CONTENT
yields	SEC_CONTENT
further	SEC_CONTENT
improvement	SEC_CONTENT
because	SEC_CONTENT
EncDec+DOC	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
i	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
outperformed	SEC_CONTENT
EncDec+DOC	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
3	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_START
on	SECTITLE_CONTENT
Constituency	SECTITLE_CONTENT
Parsing	SECTITLE_END
Choe	SEC_START
and	SEC_CONTENT
Charniak	SEC_CONTENT
(	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
achieved	SEC_CONTENT
high	SEC_CONTENT
F1	SEC_CONTENT
scores	SEC_CONTENT
on	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
constituency	dataset
parsing	SEC_CONTENT
task	SEC_CONTENT
by	SEC_CONTENT
transforming	SEC_CONTENT
candidate	SEC_CONTENT
trees	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
symbol	SEC_CONTENT
sequence	SEC_CONTENT
(	SEC_CONTENT
S	SEC_CONTENT
-	SEC_CONTENT
expression	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
reranking	SEC_CONTENT
them	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
evaluate	SEC_CONTENT
our	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
following	SEC_CONTENT
their	SEC_CONTENT
configurations	SEC_CONTENT
.	SEC_END
Dataset	SECTITLE_END
We	SEC_START
used	SEC_CONTENT
the	SEC_CONTENT
Wall	SEC_CONTENT
Street	SEC_CONTENT
Journal	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
dataset	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
section	SEC_CONTENT
2	SEC_CONTENT
-	SEC_CONTENT
21	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
22	SEC_CONTENT
for	SEC_CONTENT
validation	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
23	SEC_CONTENT
for	SEC_CONTENT
testing	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
applied	SEC_CONTENT
the	SEC_CONTENT
preprocessing	SEC_CONTENT
codes	SEC_CONTENT
of	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
dataset	SEC_CONTENT
and	SEC_CONTENT
converted	SEC_CONTENT
a	SEC_CONTENT
token	SEC_CONTENT
that	SEC_CONTENT
appears	SEC_CONTENT
fewer	SEC_CONTENT
than	SEC_CONTENT
ten	SEC_CONTENT
times	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
dataset	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
special	SEC_CONTENT
token	SEC_CONTENT
unk	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
reranking	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
prepared	SEC_CONTENT
500	SEC_CONTENT
candidates	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
Charniak	SEC_CONTENT
parser	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Models	SECTITLE_END
We	SEC_START
compare	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
with	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTMMoS	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
each	task
model	task
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
hyperparameters	SEC_CONTENT
from	SEC_CONTENT
our	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
experiments	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
selected	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
perplexity	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
during	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
bracketing	SEC_CONTENT
F1	SEC_CONTENT
scores	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
PTB	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
table	SEC_CONTENT
is	SEC_CONTENT
divided	SEC_CONTENT
into	SEC_CONTENT
three	SEC_CONTENT
parts	SEC_CONTENT
by	SEC_CONTENT
horizontal	SEC_CONTENT
lines	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
upper	SEC_CONTENT
part	SEC_CONTENT
describes	SEC_CONTENT
the	SEC_CONTENT
scores	SEC_CONTENT
by	SEC_CONTENT
single	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
based	SEC_CONTENT
rerankers	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
part	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
by	SEC_CONTENT
ensembling	SEC_CONTENT
five	SEC_CONTENT
rerankers	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
lower	SEC_CONTENT
part	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
scores	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
set-	SEC_END
Results	SECTITLE_END
Model	SECTITLE_END
Base	SEC_START
Rerank	SEC_CONTENT
Reranking	SEC_CONTENT
with	SEC_CONTENT
single	task
model	task
89.7	SEC_CONTENT
92.6	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
89.7	SEC_CONTENT
93.2	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
89.7	SEC_CONTENT
93.2	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
89.7	SEC_CONTENT
93.3	SEC_CONTENT
Reranking	SEC_CONTENT
with	SEC_CONTENT
model	SEC_CONTENT
ensemble	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
×	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
ensemble	SEC_CONTENT
)	SEC_CONTENT
89.7	SEC_CONTENT
93.4	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS	SEC_CONTENT
×	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
ensemble	SEC_CONTENT
)	SEC_CONTENT
89.7	SEC_END
93.4	SEC_START
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
×	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
ensemble	SEC_CONTENT
)	SEC_CONTENT
89.7	SEC_CONTENT
93.5	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
×	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
ensemble	SEC_CONTENT
)	SEC_CONTENT
91.2	SEC_CONTENT
94.29	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
×	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
ensemble	SEC_CONTENT
)	SEC_CONTENT
93.12	SEC_CONTENT
94.47	SEC_END
State	SEC_START
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
91.7	SEC_CONTENT
93.3	SEC_CONTENT
Fried	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
92.72	SEC_CONTENT
94.25	SEC_CONTENT
92.74	SEC_CONTENT
94.32	SEC_CONTENT
95.13	SEC_CONTENT
-	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
outperformed	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
MoS.	SEC_CONTENT
These	SEC_CONTENT
results	SEC_CONTENT
correspond	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
the	task
language	task
modeling	task
task	task
(	SEC_CONTENT
Section	SEC_CONTENT
5.3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
middle	SEC_CONTENT
part	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
also	SEC_CONTENT
outperformed	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTMMoS	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
ensemble	SEC_CONTENT
setting	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
exchanging	SEC_CONTENT
the	SEC_CONTENT
base	SEC_CONTENT
parser	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
stronger	SEC_CONTENT
one	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
achieved	SEC_CONTENT
94.29	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
by	SEC_CONTENT
reranking	SEC_CONTENT
the	SEC_CONTENT
candidates	SEC_CONTENT
from	SEC_CONTENT
retrained	SEC_CONTENT
Recurrent	SEC_CONTENT
Neural	SEC_CONTENT
Network	SEC_CONTENT
Grammars	SEC_CONTENT
(	SEC_CONTENT
RNNG	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
that	SEC_CONTENT
achieved	SEC_CONTENT
91.2	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
configuration	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
lowest	SEC_CONTENT
row	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
part	SEC_CONTENT
indicates	SEC_CONTENT
the	SEC_CONTENT
result	SEC_CONTENT
by	SEC_CONTENT
reranking	SEC_CONTENT
the	SEC_CONTENT
candidates	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
retrained	SEC_CONTENT
neural	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
based	SEC_CONTENT
parser	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
base	SEC_CONTENT
parser	SEC_CONTENT
has	SEC_CONTENT
two	SEC_CONTENT
different	SEC_CONTENT
parts	SEC_CONTENT
from	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
RNNs	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
RNN	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
tied	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
matrix	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
retrained	SEC_CONTENT
parser	SEC_CONTENT
achieved	SEC_CONTENT
93.12	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
achieved	SEC_CONTENT
94.47	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
by	SEC_CONTENT
reranking	SEC_CONTENT
its	SEC_CONTENT
candidates	SEC_CONTENT
with	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
DOC	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
expect	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
achieve	SEC_CONTENT
even	SEC_CONTENT
better	SEC_CONTENT
score	SEC_CONTENT
by	SEC_CONTENT
replacing	SEC_CONTENT
the	SEC_CONTENT
base	SEC_CONTENT
parser	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
one	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
are	SEC_CONTENT
pioneers	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
address	SEC_CONTENT
the	SEC_CONTENT
curse	SEC_CONTENT
of	SEC_CONTENT
dimensionality	SEC_CONTENT
in	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
proposed	SEC_CONTENT
a	SEC_CONTENT
method	SEC_CONTENT
using	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
demonstrated	SEC_CONTENT
that	SEC_CONTENT
their	SEC_CONTENT
approach	SEC_CONTENT
outperformed	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
FFNN	SEC_CONTENT
can	SEC_CONTENT
only	SEC_CONTENT
handle	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
contexts	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
of	SEC_CONTENT
FFNN	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
to	SEC_CONTENT
address	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
given	SEC_CONTENT
sequence	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Their	SEC_CONTENT
method	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
Kneser	SEC_CONTENT
-	SEC_CONTENT
Ney	SEC_CONTENT
smoothed	SEC_CONTENT
5-gram	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
Researchers	SEC_START
continue	SEC_CONTENT
to	SEC_CONTENT
try	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
RNN	task
language	task
models	task
.	SEC_CONTENT
used	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
RNN	SEC_CONTENT
for	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
and	SEC_CONTENT
significantly	SEC_CONTENT
improved	SEC_CONTENT
an	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
by	SEC_CONTENT
applying	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
connections	SEC_CONTENT
except	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
recurrent	SEC_CONTENT
connections	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
regularize	SEC_CONTENT
the	SEC_CONTENT
recurrent	SEC_CONTENT
connections	SEC_CONTENT
,	SEC_CONTENT
proposed	SEC_CONTENT
variational	SEC_CONTENT
inference	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
Their	SEC_CONTENT
method	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
dropout	SEC_CONTENT
mask	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
timestep	SEC_CONTENT
.	SEC_CONTENT
proposed	SEC_CONTENT
fraternal	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
minimizes	SEC_CONTENT
the	SEC_CONTENT
differences	SEC_CONTENT
between	SEC_CONTENT
outputs	SEC_CONTENT
from	SEC_CONTENT
different	SEC_CONTENT
dropout	SEC_CONTENT
masks	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
invariant	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
dropout	SEC_CONTENT
mask	SEC_CONTENT
.	SEC_CONTENT
proposed	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
tying	SEC_CONTENT
method	SEC_CONTENT
(	SEC_CONTENT
WT	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
unifies	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
E	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
4	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
(	SEC_CONTENT
W	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
quantitative	SEC_CONTENT
evaluation	SEC_CONTENT
,	SEC_CONTENT
provided	SEC_CONTENT
a	SEC_CONTENT
theoretical	SEC_CONTENT
justification	SEC_CONTENT
for	SEC_CONTENT
WT	SEC_CONTENT
and	SEC_CONTENT
proposed	SEC_CONTENT
the	SEC_CONTENT
augmented	SEC_CONTENT
loss	SEC_CONTENT
technique	SEC_CONTENT
(	SEC_CONTENT
AL	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
computes	SEC_CONTENT
an	SEC_CONTENT
objective	SEC_CONTENT
probability	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
these	SEC_CONTENT
regularization	SEC_CONTENT
techniques	SEC_CONTENT
,	SEC_CONTENT
used	SEC_CONTENT
DropConnect	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
averaged	SEC_CONTENT
SGD	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
LSTM	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Their	SEC_CONTENT
AWD	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
achieved	SEC_CONTENT
lower	SEC_CONTENT
perplexity	SEC_CONTENT
than	SEC_CONTENT
on	SEC_CONTENT
PTB	SEC_CONTENT
and	SEC_CONTENT
WikiText-2	SEC_CONTENT
.	SEC_END
Previous	SEC_START
studies	SEC_CONTENT
also	SEC_CONTENT
explored	SEC_CONTENT
superior	SEC_CONTENT
architecture	SEC_CONTENT
for	SEC_CONTENT
language	task
modeling	task
.	SEC_CONTENT
proposed	SEC_CONTENT
recurrent	SEC_CONTENT
highway	SEC_CONTENT
networks	SEC_CONTENT
that	SEC_CONTENT
use	SEC_CONTENT
highway	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
deepen	SEC_CONTENT
recurrent	SEC_CONTENT
connections	SEC_CONTENT
.	SEC_CONTENT
adopted	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
to	SEC_CONTENT
construct	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
RNN	SEC_CONTENT
structure	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
mentioned	SEC_CONTENT
,	SEC_CONTENT
established	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
LSTM	SEC_CONTENT
is	SEC_CONTENT
superior	SEC_CONTENT
to	SEC_CONTENT
these	SEC_CONTENT
architectures	SEC_CONTENT
.	SEC_CONTENT
Apart	SEC_CONTENT
from	SEC_CONTENT
RNN	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
 	SEC_CONTENT
proposed	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
-	SEC_CONTENT
tooutput	SEC_CONTENT
gate	SEC_CONTENT
(	SEC_CONTENT
IOG	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
boosts	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
trained	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
.	SEC_END
As	SEC_START
described	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
,	SEC_CONTENT
interpreted	SEC_CONTENT
training	task
language	task
modeling	task
as	SEC_CONTENT
matrix	SEC_CONTENT
factorization	SEC_CONTENT
and	SEC_CONTENT
improved	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
computing	SEC_CONTENT
multiple	SEC_CONTENT
probability	SEC_CONTENT
distributions	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
study	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
generalized	SEC_CONTENT
their	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
middle	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
RNNs	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
method	SEC_CONTENT
,	SEC_CONTENT
DOC	SEC_CONTENT
,	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
score	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
benchmark	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_END
Some	SEC_START
studies	SEC_CONTENT
provided	SEC_CONTENT
methods	SEC_CONTENT
that	SEC_CONTENT
boost	SEC_CONTENT
performance	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
statistics	SEC_CONTENT
obtained	SEC_CONTENT
from	SEC_CONTENT
test	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
extended	SEC_CONTENT
a	task
cache	task
model	task
for	SEC_CONTENT
RNN	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
proposed	SEC_CONTENT
dynamic	SEC_CONTENT
evaluation	SEC_CONTENT
that	SEC_CONTENT
updates	SEC_CONTENT
parameters	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
recent	SEC_CONTENT
sequence	SEC_CONTENT
during	SEC_CONTENT
testing	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
these	SEC_CONTENT
methods	SEC_CONTENT
might	SEC_CONTENT
also	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
DOC	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
omitted	SEC_CONTENT
such	SEC_CONTENT
investigation	SEC_CONTENT
to	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
comparisons	SEC_CONTENT
among	SEC_CONTENT
methods	SEC_CONTENT
trained	SEC_CONTENT
only	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
proposed	SEC_CONTENT
Direct	SEC_CONTENT
Output	SEC_CONTENT
Connection	SEC_CONTENT
(	SEC_CONTENT
DOC	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
generalization	SEC_CONTENT
method	SEC_CONTENT
of	SEC_CONTENT
MoS	SEC_CONTENT
introduced	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
DOC	SEC_CONTENT
raises	SEC_CONTENT
the	SEC_CONTENT
expressive	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
RNN	task
language	task
models	task
and	SEC_CONTENT
improves	SEC_CONTENT
quality	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
DOC	SEC_CONTENT
outperformed	SEC_CONTENT
MoS	SEC_CONTENT
and	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
perplexities	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
benchmark	SEC_CONTENT
datasets	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
:	SEC_CONTENT
PTB	SEC_CONTENT
and	SEC_CONTENT
WikiText-2	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
investigated	SEC_CONTENT
its	SEC_CONTENT
effectiveness	SEC_CONTENT
on	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
headline	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
results	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
DOC	SEC_CONTENT
also	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
EncDec	SEC_CONTENT
and	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
middle	SEC_CONTENT
layer	SEC_CONTENT
positively	SEC_CONTENT
affected	SEC_CONTENT
such	SEC_CONTENT
application	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
