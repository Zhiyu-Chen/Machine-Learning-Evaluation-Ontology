title	SECTITLE_END
A	SEC_START
Log	SEC_CONTENT
-	SEC_CONTENT
Linear	SEC_CONTENT
Model	SEC_CONTENT
for	SEC_CONTENT
Unsupervised	task
Text	task
Normalization	SEC_END
abstract	SECTITLE_END
We	SEC_START
present	SEC_CONTENT
a	SEC_CONTENT
unified	SEC_CONTENT
unsupervised	SEC_CONTENT
statistical	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
text	task
normalization	task
.	SEC_CONTENT
The	SEC_CONTENT
relationship	SEC_CONTENT
between	SEC_CONTENT
standard	SEC_CONTENT
and	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
standard	SEC_CONTENT
tokens	SEC_CONTENT
is	SEC_CONTENT
characterized	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
permitting	SEC_CONTENT
arbitrary	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
weights	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
features	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
maximum	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
framework	SEC_CONTENT
,	SEC_CONTENT
employing	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
training	SEC_CONTENT
algorithm	SEC_CONTENT
to	SEC_CONTENT
overcome	SEC_CONTENT
the	SEC_CONTENT
large	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
impractical	SEC_CONTENT
for	SEC_CONTENT
traditional	SEC_CONTENT
dynamic	SEC_CONTENT
programming	SEC_CONTENT
solutions	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
implemented	SEC_CONTENT
in	SEC_CONTENT
a	task
normalization	task
system	task
called	SEC_CONTENT
UNLOL	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
known	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
two	task
normalization	task
datasets	task
,	SEC_CONTENT
outper	SEC_CONTENT
-	SEC_CONTENT
forming	SEC_CONTENT
more	SEC_CONTENT
complex	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
UNLOL	SEC_CONTENT
to	SEC_CONTENT
automatically	SEC_CONTENT
normalize	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
corpus	SEC_CONTENT
of	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
text	SEC_CONTENT
,	SEC_CONTENT
revealing	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
coherent	SEC_CONTENT
orthographic	SEC_CONTENT
styles	SEC_CONTENT
that	SEC_CONTENT
underlie	SEC_CONTENT
online	SEC_CONTENT
language	SEC_CONTENT
variation	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Social	SEC_START
media	SEC_CONTENT
language	SEC_CONTENT
can	SEC_CONTENT
differ	SEC_CONTENT
substantially	SEC_CONTENT
from	SEC_CONTENT
other	SEC_CONTENT
written	SEC_CONTENT
text	SEC_CONTENT
.	SEC_CONTENT
Many	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
attempts	SEC_CONTENT
to	SEC_CONTENT
characterize	SEC_CONTENT
and	SEC_CONTENT
overcome	SEC_CONTENT
this	task
variation	task
have	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
normalization	task
:	SEC_CONTENT
transforming	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
language	SEC_CONTENT
into	SEC_CONTENT
text	SEC_CONTENT
that	SEC_CONTENT
better	SEC_CONTENT
matches	SEC_CONTENT
standard	SEC_CONTENT
datasets	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Because	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
little	SEC_CONTENT
available	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
because	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
language	SEC_CONTENT
changes	SEC_CONTENT
rapidly	SEC_CONTENT
,	SEC_CONTENT
fully	SEC_CONTENT
supervised	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
not	SEC_CONTENT
considered	SEC_CONTENT
appropriate	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
extremely	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
output	SEC_CONTENT
space	SEC_CONTENT
-arbitrary	SEC_CONTENT
sequences	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
across	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
-it	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
very	SEC_CONTENT
challenging	SEC_CONTENT
problem	SEC_CONTENT
for	SEC_CONTENT
unsupervised	SEC_CONTENT
learning	SEC_CONTENT
.	SEC_CONTENT
Perhaps	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
for	SEC_CONTENT
these	SEC_CONTENT
reasons	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
successful	SEC_CONTENT
systems	SEC_CONTENT
are	SEC_CONTENT
pipeline	SEC_CONTENT
architectures	SEC_CONTENT
that	SEC_CONTENT
cobble	SEC_CONTENT
together	SEC_CONTENT
a	SEC_CONTENT
diverse	SEC_CONTENT
array	SEC_CONTENT
of	SEC_CONTENT
techniques	SEC_CONTENT
and	SEC_CONTENT
resources	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
statistical	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
,	SEC_CONTENT
string	SEC_CONTENT
edit	SEC_CONTENT
distances	SEC_CONTENT
,	SEC_CONTENT
off	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
shelf	SEC_CONTENT
spellcheckers	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
curated	SEC_CONTENT
slang	SEC_CONTENT
dictionaries	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
We	SEC_START
propose	SEC_CONTENT
a	SEC_CONTENT
different	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
performing	SEC_CONTENT
normalization	task
in	SEC_CONTENT
a	SEC_CONTENT
maximum	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
are	SEC_CONTENT
two	SEC_CONTENT
main	SEC_CONTENT
sources	SEC_CONTENT
of	SEC_CONTENT
information	task
to	SEC_CONTENT
be	SEC_CONTENT
exploited	SEC_CONTENT
:	SEC_CONTENT
local	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
surface	metric
similarity	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
observed	SEC_CONTENT
strings	SEC_CONTENT
and	SEC_CONTENT
normalization	SEC_CONTENT
candidates	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
treat	SEC_CONTENT
the	SEC_CONTENT
local	SEC_CONTENT
context	SEC_CONTENT
using	SEC_CONTENT
standard	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
techniques	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
treat	SEC_CONTENT
string	SEC_CONTENT
similarity	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
includes	SEC_CONTENT
features	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
surface	SEC_CONTENT
similarity	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_END
Because	SEC_START
labeled	SEC_CONTENT
examples	SEC_CONTENT
of	SEC_CONTENT
normalized	SEC_CONTENT
text	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
available	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
supervised	SEC_CONTENT
fashion	SEC_CONTENT
.	SEC_CONTENT
Nor	SEC_CONTENT
can	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
dynamic	SEC_CONTENT
programming	SEC_CONTENT
techniques	SEC_CONTENT
for	SEC_CONTENT
unsupervised	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
locally	task
-	task
normalized	task
conditional	task
models	task
,	SEC_CONTENT
as	SEC_CONTENT
their	SEC_CONTENT
complexity	SEC_CONTENT
is	SEC_CONTENT
quadratic	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
;	SEC_CONTENT
in	SEC_CONTENT
normalization	task
,	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
itself	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
10	SEC_CONTENT
4	SEC_CONTENT
elements	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
anew	SEC_CONTENT
training	SEC_CONTENT
approach	SEC_CONTENT
using	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
techniques	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
an	SEC_CONTENT
approximate	SEC_CONTENT
gradient	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
weights	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
training	SEC_CONTENT
method	SEC_CONTENT
maybe	SEC_CONTENT
applicable	SEC_CONTENT
in	SEC_CONTENT
other	SEC_CONTENT
unsupervised	SEC_CONTENT
learning	SEC_CONTENT
problems	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
.	SEC_END
This	SEC_START
model	SEC_CONTENT
is	SEC_CONTENT
implemented	SEC_CONTENT
in	SEC_CONTENT
a	task
normalization	task
system	task
called	SEC_CONTENT
UNLOL	SEC_CONTENT
(	task
unsupervised	task
normalization	task
in	SEC_CONTENT
a	SEC_CONTENT
LOg	SEC_CONTENT
-	SEC_CONTENT
Linear	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
lightweight	SEC_CONTENT
proba	SEC_CONTENT
-	SEC_CONTENT
bilistic	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
relying	SEC_CONTENT
only	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
domain	SEC_CONTENT
;	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
adapted	SEC_CONTENT
to	SEC_CONTENT
new	SEC_CONTENT
corpora	SEC_CONTENT
text	SEC_CONTENT
or	SEC_CONTENT
new	SEC_CONTENT
domains	SEC_CONTENT
easily	SEC_CONTENT
and	SEC_CONTENT
quickly	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
evaluations	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
UNLOL	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
standard	task
normalization	task
datasets	task
.	SEC_END
In	SEC_START
addition	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
demonstrate	SEC_CONTENT
the	SEC_CONTENT
linguistic	SEC_CONTENT
insights	SEC_CONTENT
that	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
obtained	SEC_CONTENT
from	SEC_CONTENT
normalization	task
,	SEC_CONTENT
using	SEC_CONTENT
UNLOL	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
classes	SEC_CONTENT
of	SEC_CONTENT
orthographic	SEC_CONTENT
transformations	SEC_CONTENT
that	SEC_CONTENT
form	SEC_CONTENT
coherent	SEC_CONTENT
linguistic	SEC_CONTENT
styles	SEC_CONTENT
.	SEC_END
Background	SECTITLE_END
The	SEC_START
text	task
normalization	task
task	task
was	SEC_CONTENT
introduced	SEC_CONTENT
by	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
attained	SEC_CONTENT
popularity	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
SMS	SEC_CONTENT
messages	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
has	SEC_CONTENT
become	SEC_CONTENT
still	SEC_CONTENT
more	SEC_CONTENT
salient	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
era	SEC_CONTENT
of	SEC_CONTENT
widespread	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
,	SEC_CONTENT
particularly	SEC_CONTENT
Twitter	SEC_CONTENT
.	SEC_CONTENT
Han	SEC_CONTENT
and	SEC_CONTENT
Baldwin	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
formally	SEC_CONTENT
define	SEC_CONTENT
a	task
normalization	task
task	task
for	SEC_CONTENT
Twitter	SEC_CONTENT
,	SEC_CONTENT
focusing	SEC_CONTENT
on	SEC_CONTENT
normalizations	task
between	SEC_CONTENT
single	SEC_CONTENT
tokens	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
excluding	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
tokens	SEC_CONTENT
like	SEC_CONTENT
lol	SEC_CONTENT
(	SEC_CONTENT
laugh	SEC_CONTENT
out	SEC_CONTENT
loud	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	task
normalization	task
task	task
has	SEC_CONTENT
been	SEC_CONTENT
criticized	SEC_CONTENT
by	SEC_CONTENT
,	SEC_CONTENT
who	SEC_CONTENT
argues	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
strips	SEC_CONTENT
away	SEC_CONTENT
important	SEC_CONTENT
social	SEC_CONTENT
meanings	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
recent	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
normalization	task
has	SEC_CONTENT
been	SEC_CONTENT
shown	SEC_CONTENT
to	SEC_CONTENT
yield	SEC_CONTENT
improvements	SEC_CONTENT
for	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
tagging	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
parsing	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
show	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
7	SEC_CONTENT
,	SEC_CONTENT
accurate	task
automated	task
normalization	task
can	SEC_CONTENT
also	SEC_CONTENT
improve	SEC_CONTENT
our	SEC_CONTENT
understanding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
language	SEC_CONTENT
.	SEC_END
Supervised	SEC_START
methods	SEC_CONTENT
Early	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
normalization	task
focused	SEC_CONTENT
on	SEC_CONTENT
labeled	SEC_CONTENT
SMS	SEC_CONTENT
datasets	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
approaches	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
noisy	SEC_CONTENT
-	SEC_CONTENT
channel	SEC_CONTENT
modeling	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
hybrid	SEC_CONTENT
combinations	SEC_CONTENT
of	SEC_CONTENT
spelling	SEC_CONTENT
correction	SEC_CONTENT
and	SEC_CONTENT
speech	SEC_CONTENT
recognition	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
work	SEC_CONTENT
sought	SEC_CONTENT
to	SEC_CONTENT
balance	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
favoring	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
fit	SEC_CONTENT
in	SEC_CONTENT
context	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
transformation	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
favoring	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
observed	SEC_CONTENT
text	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
approach	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
noisy	SEC_CONTENT
channel	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
unlike	SEC_CONTENT
this	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
no	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
required	SEC_CONTENT
.	SEC_END
Unsupervised	SEC_START
methods	SEC_CONTENT
manually	SEC_CONTENT
identify	SEC_CONTENT
several	SEC_CONTENT
word	SEC_CONTENT
formation	SEC_CONTENT
types	SEC_CONTENT
within	SEC_CONTENT
a	SEC_CONTENT
noisy	SEC_CONTENT
channel	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
parametrize	SEC_CONTENT
each	task
formation	task
type	task
with	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
scalar	SEC_CONTENT
values	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
all	task
legal	task
transformations	task
of	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
type	SEC_CONTENT
are	SEC_CONTENT
equally	SEC_CONTENT
likely	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
scalar	SEC_CONTENT
parameters	SEC_CONTENT
are	SEC_CONTENT
then	SEC_CONTENT
estimated	SEC_CONTENT
using	SEC_CONTENT
expectation	task
maximization	task
.	SEC_CONTENT
This	SEC_CONTENT
work	SEC_CONTENT
stands	SEC_CONTENT
apart	SEC_CONTENT
from	SEC_CONTENT
most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
unsupervised	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
pipelines	SEC_CONTENT
.	SEC_CONTENT
use	SEC_CONTENT
string	SEC_CONTENT
edit	SEC_CONTENT
distance	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
closely	SEC_CONTENT
-	SEC_CONTENT
related	SEC_CONTENT
candidate	SEC_CONTENT
orthographic	SEC_CONTENT
forms	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
decode	SEC_CONTENT
the	SEC_CONTENT
message	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
refine	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
by	SEC_CONTENT
mining	SEC_CONTENT
an	SEC_CONTENT
"	SEC_CONTENT
exception	SEC_CONTENT
dictionary	SEC_CONTENT
"	SEC_CONTENT
of	SEC_CONTENT
stronglyassociated	SEC_CONTENT
word	SEC_CONTENT
pairs	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
you	SEC_CONTENT
/	SEC_CONTENT
u	SEC_CONTENT
.	SEC_CONTENT
Like	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
string	SEC_CONTENT
edit	SEC_CONTENT
distance	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
like	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
capture	SEC_CONTENT
strongly	SEC_CONTENT
related	SEC_CONTENT
word	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
applying	SEC_CONTENT
these	SEC_CONTENT
properties	SEC_CONTENT
as	SEC_CONTENT
filtering	SEC_CONTENT
steps	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
pipeline	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
them	SEC_CONTENT
as	SEC_CONTENT
features	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
unified	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Recent	SEC_CONTENT
approaches	SEC_CONTENT
have	SEC_CONTENT
sought	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
accuracy	metric
by	SEC_CONTENT
bringing	SEC_CONTENT
more	SEC_CONTENT
external	SEC_CONTENT
resources	SEC_CONTENT
and	SEC_CONTENT
complex	SEC_CONTENT
architectures	SEC_CONTENT
to	SEC_CONTENT
bear	SEC_CONTENT
.	SEC_CONTENT
begin	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
string	SEC_CONTENT
similarity	SEC_CONTENT
metrics	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
apply	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
contextuallysimilar	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
extract	SEC_CONTENT
noisy	SEC_CONTENT
training	SEC_CONTENT
pairs	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
search	SEC_CONTENT
snippets	SEC_CONTENT
that	SEC_CONTENT
result	SEC_CONTENT
from	SEC_CONTENT
carefully	SEC_CONTENT
designed	SEC_CONTENT
queries	SEC_CONTENT
to	SEC_CONTENT
Google	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
conditional	SEC_CONTENT
random	SEC_CONTENT
field	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
estimate	SEC_CONTENT
a	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
translation	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
later	SEC_CONTENT
extend	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
by	SEC_CONTENT
adding	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
of	SEC_CONTENT
visual	SEC_CONTENT
priming	SEC_CONTENT
,	SEC_CONTENT
an	SEC_CONTENT
off	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
shelf	SEC_CONTENT
spell	SEC_CONTENT
-	SEC_CONTENT
checker	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
local	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
walk	SEC_CONTENT
framework	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
contextual	SEC_CONTENT
similarity	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
they	SEC_CONTENT
then	SEC_CONTENT
interpolate	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
edit	SEC_CONTENT
distance	SEC_CONTENT
metric	SEC_CONTENT
.	SEC_CONTENT
Rather	SEC_CONTENT
than	SEC_CONTENT
seeking	SEC_CONTENT
additional	SEC_CONTENT
external	SEC_CONTENT
resources	SEC_CONTENT
or	SEC_CONTENT
designing	SEC_CONTENT
more	SEC_CONTENT
complex	SEC_CONTENT
metrics	SEC_CONTENT
of	SEC_CONTENT
context	SEC_CONTENT
and	SEC_CONTENT
similarity	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
unified	SEC_CONTENT
statistical	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
learns	SEC_CONTENT
feature	SEC_CONTENT
weights	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
maximum	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_END
Approach	SECTITLE_END
Our	SEC_START
approach	SEC_CONTENT
is	SEC_CONTENT
motivated	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
criteria	SEC_CONTENT
:	SEC_END
•	SEC_START
Unsupervised	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
want	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
without	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
present	SEC_CONTENT
,	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
for	SEC_CONTENT
Twitter	task
normalization	task
is	SEC_CONTENT
available	SEC_CONTENT
only	SEC_CONTENT
in	SEC_CONTENT
small	SEC_CONTENT
quantities	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
language	SEC_CONTENT
is	SEC_CONTENT
undergoing	SEC_CONTENT
rapid	SEC_CONTENT
change	SEC_CONTENT
,	SEC_CONTENT
labeled	SEC_CONTENT
datasets	SEC_CONTENT
may	SEC_CONTENT
become	SEC_CONTENT
stale	SEC_CONTENT
and	SEC_CONTENT
increasingly	SEC_CONTENT
ill	SEC_CONTENT
-	SEC_CONTENT
suited	SEC_CONTENT
to	SEC_CONTENT
new	SEC_CONTENT
spellings	SEC_CONTENT
and	SEC_CONTENT
words	SEC_CONTENT
.	SEC_END
•	SEC_START
Low	SEC_CONTENT
-	SEC_CONTENT
resource	SEC_CONTENT
.	SEC_END
Other	SEC_START
unsupervised	SEC_CONTENT
approaches	SEC_CONTENT
take	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
resources	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
slang	SEC_CONTENT
dictionaries	SEC_CONTENT
and	SEC_CONTENT
spell	SEC_CONTENT
checkers	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Resources	SEC_CONTENT
that	SEC_CONTENT
characterize	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
internet	SEC_CONTENT
language	SEC_CONTENT
risk	SEC_CONTENT
becoming	SEC_CONTENT
outdated	SEC_CONTENT
;	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
we	SEC_CONTENT
investigate	SEC_CONTENT
whether	SEC_CONTENT
high	task
-	task
quality	task
normalization	task
is	SEC_CONTENT
possible	SEC_CONTENT
without	SEC_CONTENT
any	SEC_CONTENT
such	SEC_CONTENT
resources	SEC_CONTENT
.	SEC_END
•	SEC_START
Featurized	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
relationship	SEC_CONTENT
between	SEC_CONTENT
any	SEC_CONTENT
pair	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
characterized	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
different	SEC_CONTENT
ways	SEC_CONTENT
,	SEC_CONTENT
ranging	SEC_CONTENT
from	SEC_CONTENT
simple	SEC_CONTENT
characterlevel	SEC_CONTENT
rules	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
going	SEC_CONTENT
/	SEC_CONTENT
goin	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
larger	SEC_CONTENT
substitutions	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
someone	SEC_CONTENT
/	SEC_CONTENT
sum1	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
even	SEC_CONTENT
to	SEC_CONTENT
patterns	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
lexically	SEC_CONTENT
restricted	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
you	SEC_CONTENT
/	SEC_CONTENT
u	SEC_CONTENT
,	SEC_CONTENT
to/2	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
these	SEC_CONTENT
reasons	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
seek	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
permits	SEC_CONTENT
many	SEC_CONTENT
overlapping	SEC_CONTENT
features	SEC_CONTENT
to	SEC_CONTENT
describe	SEC_CONTENT
candidate	SEC_CONTENT
word	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
features	SEC_CONTENT
may	SEC_CONTENT
include	SEC_CONTENT
simple	SEC_CONTENT
string	SEC_CONTENT
edit	SEC_CONTENT
distance	SEC_CONTENT
metrics	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
lexical	task
features	task
that	SEC_CONTENT
memorize	SEC_CONTENT
specific	SEC_CONTENT
pairs	SEC_CONTENT
of	SEC_CONTENT
standard	SEC_CONTENT
and	SEC_CONTENT
nonstandard	SEC_CONTENT
words	SEC_CONTENT
.	SEC_END
•	SEC_START
Context	SEC_CONTENT
-	SEC_CONTENT
driven	SEC_CONTENT
.	SEC_CONTENT
Learning	SEC_CONTENT
potentially	SEC_CONTENT
arbitrary	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
transformations	SEC_CONTENT
without	SEC_CONTENT
supervision	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
impossible	SEC_CONTENT
without	SEC_CONTENT
the	SEC_CONTENT
strong	SEC_CONTENT
additional	SEC_CONTENT
cue	SEC_CONTENT
of	SEC_CONTENT
local	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
phrase	SEC_END
give	SEC_START
me	SEC_CONTENT
suttin	SEC_CONTENT
to	SEC_CONTENT
believe	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
a	SEC_CONTENT
reader	SEC_CONTENT
who	SEC_CONTENT
has	SEC_CONTENT
never	SEC_CONTENT
before	SEC_CONTENT
seen	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
suttin	SEC_CONTENT
may	SEC_CONTENT
recognize	SEC_CONTENT
it	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
phonetic	SEC_CONTENT
transcription	SEC_CONTENT
of	SEC_CONTENT
something	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
relatively	SEC_CONTENT
high	SEC_CONTENT
string	SEC_CONTENT
edit	SEC_CONTENT
distance	SEC_CONTENT
is	SEC_CONTENT
overcome	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
strong	SEC_CONTENT
contextual	SEC_CONTENT
preference	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
something	SEC_CONTENT
over	SEC_CONTENT
orthographically	SEC_CONTENT
closer	SEC_CONTENT
alternatives	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
button	SEC_CONTENT
or	SEC_CONTENT
suiting	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
apply	SEC_CONTENT
an	SEC_CONTENT
arbitrary	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
leveraging	SEC_CONTENT
large	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
catering	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
desired	SEC_CONTENT
linguistic	SEC_CONTENT
characteristics	SEC_CONTENT
of	SEC_CONTENT
the	task
normalized	task
content	task
.	SEC_END
•	SEC_START
Holistic	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
several	SEC_CONTENT
prior	SEC_CONTENT
approachessuch	SEC_CONTENT
as	SEC_CONTENT
normalization	task
dictionaries	task
-operate	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
token	SEC_CONTENT
level	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
reasons	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
scope	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
message	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
necessity	SEC_CONTENT
for	SEC_CONTENT
such	SEC_CONTENT
holistic	SEC_CONTENT
,	SEC_CONTENT
joint	SEC_CONTENT
inference	SEC_CONTENT
and	SEC_CONTENT
learning	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
by	SEC_CONTENT
changing	SEC_CONTENT
the	SEC_CONTENT
example	SEC_CONTENT
above	SEC_CONTENT
to	SEC_CONTENT
:	SEC_END
gimme	SEC_START
suttin	SEC_CONTENT
2	SEC_CONTENT
beleive	SEC_CONTENT
innnn	SEC_CONTENT
.	SEC_END
None	SEC_START
of	SEC_CONTENT
these	SEC_CONTENT
tokens	SEC_CONTENT
are	SEC_CONTENT
standard	SEC_CONTENT
(	SEC_CONTENT
except	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
appears	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
nonstandard	SEC_CONTENT
sense	SEC_CONTENT
here	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
without	SEC_CONTENT
joint	SEC_CONTENT
inference	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
would	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
context	SEC_CONTENT
to	SEC_CONTENT
help	SEC_CONTENT
normalize	SEC_CONTENT
suttin	SEC_CONTENT
.	SEC_END
Only	SEC_START
by	SEC_CONTENT
jointly	SEC_CONTENT
reasoning	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
message	SEC_CONTENT
can	SEC_CONTENT
we	SEC_CONTENT
obtain	SEC_CONTENT
the	task
correct	task
normalization	task
.	SEC_END
These	SEC_START
desiderata	SEC_CONTENT
point	SEC_CONTENT
towards	SEC_CONTENT
a	SEC_CONTENT
featurized	SEC_CONTENT
sequence	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
must	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
without	SEC_CONTENT
labeled	SEC_CONTENT
examples	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
training	SEC_CONTENT
sequence	SEC_CONTENT
models	SEC_CONTENT
without	SEC_CONTENT
supervision	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
an	task
additional	task
complication	task
not	SEC_CONTENT
faced	SEC_CONTENT
by	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
tagging	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
potential	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
of	SEC_CONTENT
standard	SEC_CONTENT
words	SEC_CONTENT
is	SEC_CONTENT
large	SEC_CONTENT
,	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
order	SEC_CONTENT
of	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
10	SEC_CONTENT
4	SEC_CONTENT
.	SEC_CONTENT
Naive	task
application	task
of	SEC_CONTENT
Viterbi	SEC_CONTENT
decoding	SEC_CONTENT
-which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
component	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
Contrastive	SEC_CONTENT
Estimation	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
locally	SEC_CONTENT
-	SEC_CONTENT
normalized	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
model	SEC_CONTENT
of	SEC_CONTENT
-will	SEC_CONTENT
be	SEC_CONTENT
stymied	SEC_CONTENT
by	SEC_CONTENT
Viterbi	SEC_CONTENT
's	SEC_CONTENT
quadratic	SEC_CONTENT
complexity	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
dimension	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
various	SEC_CONTENT
pruning	SEC_CONTENT
heuristics	SEC_CONTENT
maybe	SEC_CONTENT
applied	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
instead	SEC_CONTENT
look	SEC_CONTENT
to	SEC_CONTENT
Sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
(	SEC_CONTENT
SMC	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
randomized	SEC_CONTENT
algorithm	SEC_CONTENT
which	SEC_CONTENT
approximates	SEC_CONTENT
the	SEC_CONTENT
necessary	SEC_CONTENT
feature	SEC_CONTENT
expectations	SEC_CONTENT
through	SEC_CONTENT
weighted	SEC_CONTENT
samples	SEC_CONTENT
.	SEC_END
Model	SECTITLE_END
Given	SEC_START
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
source	SEC_CONTENT
-	SEC_CONTENT
language	SEC_CONTENT
sentences	SEC_CONTENT
S	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
s	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
}	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
Tweets	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
transduce	SEC_CONTENT
them	SEC_CONTENT
into	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
language	SEC_CONTENT
sentences	SEC_CONTENT
T	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
}	SEC_CONTENT
(	SEC_CONTENT
standard	SEC_CONTENT
English	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
are	SEC_CONTENT
given	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
estimated	SEC_CONTENT
from	SEC_CONTENT
some	SEC_CONTENT
large	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
language	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
vocabularies	SEC_CONTENT
of	SEC_CONTENT
source	SEC_CONTENT
language	SEC_CONTENT
and	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
as	SEC_CONTENT
ν	SEC_CONTENT
Sand	SEC_CONTENT
ν	SEC_CONTENT
T	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_END
We	SEC_START
define	SEC_CONTENT
a	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
scores	SEC_CONTENT
source	SEC_CONTENT
and	SEC_CONTENT
target	SEC_CONTENT
strings	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
the	dataset
form	SEC_END
The	SEC_START
desired	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t|s	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
combining	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t|s	SEC_CONTENT
)	SEC_CONTENT
∝	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s|t	SEC_CONTENT
;	SEC_CONTENT
θ)P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
no	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
available	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
θ	SEC_CONTENT
must	SEC_CONTENT
be	SEC_CONTENT
estimated	SEC_CONTENT
by	SEC_CONTENT
maximizing	SEC_CONTENT
the	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
-	SEC_CONTENT
language	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
define	SEC_CONTENT
the	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
θ	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
)	SEC_CONTENT
fora	SEC_CONTENT
source	SEC_CONTENT
-	SEC_CONTENT
language	SEC_CONTENT
sentence	SEC_CONTENT
s	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
We	SEC_START
would	SEC_CONTENT
like	SEC_CONTENT
to	SEC_CONTENT
maximize	SEC_CONTENT
this	SEC_CONTENT
objective	SEC_CONTENT
by	SEC_CONTENT
making	SEC_CONTENT
gradient	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
updates	SEC_CONTENT
.	SEC_END
We	SEC_START
are	SEC_CONTENT
left	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
difference	SEC_CONTENT
in	SEC_CONTENT
expected	SEC_CONTENT
feature	SEC_CONTENT
counts	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
is	SEC_CONTENT
typical	SEC_CONTENT
in	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
unlike	SEC_CONTENT
the	SEC_CONTENT
supervised	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
here	SEC_CONTENT
both	SEC_CONTENT
terms	SEC_CONTENT
are	SEC_CONTENT
expectations	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
outer	SEC_CONTENT
expectation	SEC_CONTENT
is	SEC_CONTENT
overall	SEC_CONTENT
target	SEC_CONTENT
sequences	SEC_CONTENT
(	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
observed	SEC_CONTENT
source	SEC_CONTENT
sequence	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
nested	SEC_CONTENT
expectation	SEC_CONTENT
is	SEC_CONTENT
overall	SEC_CONTENT
source	SEC_CONTENT
sequences	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
the	SEC_CONTENT
space	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
target	SEC_CONTENT
sequences	SEC_CONTENT
t	SEC_CONTENT
grows	SEC_CONTENT
exponentially	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
length	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
will	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
practical	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
this	SEC_CONTENT
expectation	SEC_CONTENT
directly	SEC_CONTENT
.	SEC_END
Dynamic	SEC_START
programming	SEC_CONTENT
is	SEC_CONTENT
the	task
typical	task
solution	task
for	SEC_CONTENT
computing	SEC_CONTENT
feature	SEC_CONTENT
expectations	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
sequence	SEC_CONTENT
models	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
function	SEC_CONTENT
decomposes	SEC_CONTENT
locally	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
are	SEC_CONTENT
two	SEC_CONTENT
reasons	SEC_CONTENT
this	SEC_CONTENT
will	SEC_CONTENT
notwork	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
case	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
forwardbackward	SEC_CONTENT
algorithm	SEC_CONTENT
would	SEC_CONTENT
enable	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
E	SEC_CONTENT
t|s	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
would	SEC_CONTENT
not	SEC_CONTENT
give	SEC_CONTENT
us	SEC_CONTENT
the	SEC_CONTENT
nested	SEC_CONTENT
expectation	SEC_CONTENT
E	SEC_CONTENT
t|s	SEC_CONTENT
;	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
classic	SEC_CONTENT
challenge	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
globally	SEC_CONTENT
-	SEC_CONTENT
normalized	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
models	SEC_CONTENT
without	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
both	SEC_CONTENT
forward	SEC_CONTENT
-	SEC_CONTENT
backward	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
Viterbi	SEC_CONTENT
algorithm	SEC_CONTENT
have	SEC_CONTENT
time	SEC_CONTENT
complexity	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
quadratic	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
dimension	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
,	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
10	SEC_CONTENT
4	SEC_CONTENT
or	SEC_CONTENT
10	SEC_CONTENT
5	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
show	SEC_CONTENT
,	SEC_CONTENT
Sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
(	SEC_CONTENT
SMC	SEC_CONTENT
)	SEC_CONTENT
algorithms	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
advantages	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
setting	SEC_CONTENT
:	SEC_CONTENT
they	SEC_CONTENT
permit	SEC_CONTENT
the	SEC_CONTENT
efficient	SEC_CONTENT
computation	SEC_CONTENT
of	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
outer	SEC_CONTENT
and	SEC_CONTENT
inner	SEC_CONTENT
expectations	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
trivially	SEC_CONTENT
parallelizable	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
samples	SEC_CONTENT
provides	SEC_CONTENT
an	SEC_CONTENT
intuitive	SEC_CONTENT
tuning	SEC_CONTENT
tradeoff	SEC_CONTENT
between	SEC_CONTENT
accuracy	metric
and	SEC_CONTENT
speed	SEC_CONTENT
.	SEC_END
Sequential	SECTITLE_START
Monte	SECTITLE_CONTENT
Carlo	SECTITLE_CONTENT
approximation	SECTITLE_END
Sequential	SEC_START
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
algorithms	SEC_CONTENT
area	SEC_CONTENT
class	SEC_CONTENT
of	SEC_CONTENT
sampling	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
algorithms	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
latent	SEC_CONTENT
variables	SEC_CONTENT
are	SEC_CONTENT
sampled	SEC_CONTENT
sequentially	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
are	SEC_CONTENT
particularly	SEC_CONTENT
well	SEC_CONTENT
-	SEC_CONTENT
suited	SEC_CONTENT
to	SEC_CONTENT
sequence	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
though	SEC_CONTENT
they	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
more	SEC_CONTENT
broadly	SEC_CONTENT
.	SEC_CONTENT
SMC	SEC_CONTENT
algorithms	SEC_CONTENT
maintain	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
weighted	SEC_CONTENT
hypotheses	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
weights	SEC_CONTENT
correspond	SEC_CONTENT
to	SEC_CONTENT
probabilities	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
hypotheses	SEC_CONTENT
correspond	SEC_CONTENT
to	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
word	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
,	SEC_END
where	SEC_START
ω	SEC_CONTENT
kn	SEC_CONTENT
is	SEC_CONTENT
the	task
normalized	task
weight	task
of	SEC_CONTENT
sample	SEC_CONTENT
k	SEC_CONTENT
at	SEC_CONTENT
word	SEC_CONTENT
n	SEC_CONTENT
(	SEC_CONTENT
˜	SEC_CONTENT
ω	SEC_CONTENT
kn	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
unnormalized	SEC_CONTENT
weight	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
δ	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
delta	SEC_CONTENT
function	SEC_CONTENT
centered	SEC_CONTENT
at	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
each	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
hypothesis	SEC_CONTENT
k	SEC_CONTENT
,	SEC_CONTENT
anew	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
is	SEC_CONTENT
sampled	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
is	SEC_CONTENT
then	SEC_CONTENT
updated	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
maintain	SEC_CONTENT
feature	SEC_CONTENT
counts	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
hypothesis	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
by	SEC_CONTENT
taking	SEC_CONTENT
a	SEC_CONTENT
weighted	SEC_CONTENT
average	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
weights	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
detail	SEC_CONTENT
later	SEC_CONTENT
.	SEC_END
We	SEC_START
make	SEC_CONTENT
a	SEC_CONTENT
Markov	SEC_CONTENT
assumption	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
emission	SEC_CONTENT
probability	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s|t	SEC_CONTENT
)	SEC_CONTENT
decomposes	SEC_CONTENT
across	SEC_CONTENT
the	SEC_CONTENT
elements	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s|t	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
N	SEC_CONTENT
n	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
means	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
functions	SEC_CONTENT
f	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
must	SEC_CONTENT
decompose	SEC_CONTENT
on	SEC_CONTENT
each	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
tn	SEC_CONTENT
pair	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
then	SEC_CONTENT
rewrite	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
as	SEC_END
In	SEC_START
addition	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
assume	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
written	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
N	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
n	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
t	SEC_CONTENT
n−k+1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
these	SEC_CONTENT
assumptions	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
view	SEC_CONTENT
normalization	task
as	SEC_CONTENT
a	SEC_CONTENT
finite	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
space	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
defines	SEC_CONTENT
the	SEC_CONTENT
prior	SEC_CONTENT
distribution	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
process	SEC_CONTENT
and	SEC_CONTENT
Equation	SEC_CONTENT
3	SEC_CONTENT
defines	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
the	SEC_CONTENT
posterior	SEC_CONTENT
probability	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t|s	SEC_CONTENT
)	SEC_CONTENT
using	SEC_CONTENT
sequential	SEC_CONTENT
importance	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
member	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
SMC	SEC_CONTENT
family	SEC_CONTENT
.	SEC_END
The	SEC_START
crucial	SEC_CONTENT
idea	SEC_CONTENT
in	SEC_CONTENT
sequential	SEC_CONTENT
importance	SEC_CONTENT
sampling	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
update	SEC_CONTENT
the	SEC_CONTENT
hypotheses	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
weights	SEC_CONTENT
ω	SEC_CONTENT
kn	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
they	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
posterior	SEC_CONTENT
distribution	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n+1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n+1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Assuming	SEC_START
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
has	SEC_CONTENT
the	dataset
form	dataset
Q(t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
importance	SEC_CONTENT
weights	SEC_CONTENT
are	SEC_CONTENT
given	SEC_CONTENT
by	SEC_CONTENT
ω	SEC_CONTENT
kn	SEC_CONTENT
∝	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
Q(t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_END
In	SEC_START
order	SEC_CONTENT
to	SEC_CONTENT
update	SEC_CONTENT
the	SEC_CONTENT
hypotheses	SEC_CONTENT
recursively	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
rewrite	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
:	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
∝P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
assuming	SEC_CONTENT
a	SEC_CONTENT
bigram	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
further	SEC_CONTENT
assume	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
Q	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
factored	SEC_CONTENT
as	SEC_CONTENT
:	SEC_CONTENT
Q(t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
Q(t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
Q(t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
Q(t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
Q(t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Then	SEC_START
the	SEC_CONTENT
unnormalized	SEC_CONTENT
importance	SEC_CONTENT
weights	SEC_CONTENT
simplify	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
recurrence	SEC_CONTENT
:	SEC_END
P	SEC_START
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
kn	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
kn	SEC_CONTENT
|t	SEC_CONTENT
k	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
Q(t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
Q(t	SEC_CONTENT
k	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_END
Therefore	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
posterior	SEC_CONTENT
distribution	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
n	SEC_CONTENT
|s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
≈	SEC_CONTENT
K	SEC_CONTENT
k=1	SEC_CONTENT
ω	SEC_CONTENT
kn	SEC_CONTENT
δ	SEC_CONTENT
t	SEC_CONTENT
kn	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
outer	SEC_CONTENT
expectation	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
We	SEC_START
compute	SEC_CONTENT
the	SEC_CONTENT
nested	SEC_CONTENT
expectation	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
nonsequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
approximation	SEC_CONTENT
,	SEC_CONTENT
assuming	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
draw	SEC_CONTENT
s	SEC_CONTENT
,	SEC_CONTENT
k	SEC_CONTENT
∼	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s|t	SEC_CONTENT
kn	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
This	SEC_START
gives	SEC_CONTENT
the	SEC_CONTENT
overall	SEC_CONTENT
gradient	SEC_CONTENT
computation	SEC_CONTENT
:	SEC_END
where	SEC_START
we	SEC_CONTENT
sample	SEC_CONTENT
t	SEC_CONTENT
kn	SEC_CONTENT
and	SEC_CONTENT
update	SEC_CONTENT
ω	SEC_CONTENT
kn	SEC_CONTENT
while	SEC_CONTENT
moving	SEC_CONTENT
from	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
sample	SEC_CONTENT
s	SEC_CONTENT
,	SEC_CONTENT
k	SEC_CONTENT
n	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
n.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
although	SEC_CONTENT
the	SEC_CONTENT
sequential	SEC_CONTENT
importance	SEC_CONTENT
sampler	SEC_CONTENT
moves	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
like	SEC_CONTENT
a	SEC_CONTENT
filter	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
weights	SEC_CONTENT
ω	SEC_CONTENT
N	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
resulting	SEC_CONTENT
expectation	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
distribution	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
N	SEC_CONTENT
|t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
N	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
no	SEC_CONTENT
backwards	SEC_CONTENT
"	SEC_CONTENT
smoothing	SEC_CONTENT
"	SEC_CONTENT
pass	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
needed	SEC_CONTENT
to	SEC_CONTENT
eliminate	SEC_CONTENT
bias	SEC_CONTENT
.	SEC_CONTENT
Other	task
applications	task
of	SEC_CONTENT
sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
make	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
resampling	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
degeneration	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
weights	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
this	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
unnecessary	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
short	SEC_CONTENT
length	SEC_CONTENT
of	SEC_CONTENT
Twitter	SEC_CONTENT
messages	SEC_CONTENT
.	SEC_END
Proposal	SECTITLE_START
distribution	SECTITLE_END
The	SEC_START
major	SEC_CONTENT
computational	SEC_CONTENT
challenge	SEC_CONTENT
for	SEC_CONTENT
dynamic	SEC_CONTENT
programming	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
normalization	task
is	SEC_CONTENT
the	SEC_CONTENT
large	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
,	SEC_CONTENT
equal	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
vocabulary	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
may	SEC_CONTENT
appear	SEC_CONTENT
that	SEC_CONTENT
all	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
gained	SEC_CONTENT
by	SEC_CONTENT
applying	SEC_CONTENT
sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
convert	SEC_CONTENT
a	SEC_CONTENT
computational	SEC_CONTENT
problem	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
statistical	SEC_CONTENT
one	SEC_CONTENT
:	SEC_CONTENT
a	SEC_CONTENT
naive	SEC_CONTENT
sampling	SEC_CONTENT
approach	SEC_CONTENT
will	SEC_CONTENT
have	SEC_CONTENT
little	SEC_CONTENT
hope	SEC_CONTENT
of	SEC_CONTENT
finding	SEC_CONTENT
the	SEC_CONTENT
small	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
probability	SEC_CONTENT
region	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
highdimensional	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
sequential	SEC_CONTENT
importance	SEC_CONTENT
sampling	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
address	SEC_CONTENT
this	SEC_CONTENT
issue	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
from	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
sample	SEC_CONTENT
the	SEC_CONTENT
candidate	SEC_CONTENT
words	SEC_CONTENT
tn	SEC_CONTENT
.	SEC_CONTENT
Careful	SEC_CONTENT
design	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
can	SEC_CONTENT
guide	SEC_CONTENT
sampling	SEC_CONTENT
towards	SEC_CONTENT
the	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
probability	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
asymptotic	SEC_CONTENT
limit	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
infinite	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
samples	SEC_CONTENT
,	SEC_CONTENT
any	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
pathological	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
will	SEC_CONTENT
ultimately	SEC_CONTENT
arrive	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
desired	SEC_CONTENT
estimate	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
can	SEC_CONTENT
greatly	SEC_CONTENT
reduce	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
samples	SEC_CONTENT
needed	SEC_CONTENT
.	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
optimal	SEC_CONTENT
proposal	SEC_CONTENT
-which	SEC_CONTENT
minimizes	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
importance	SEC_CONTENT
weights	SEC_CONTENT
conditional	SEC_CONTENT
on	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n−1	SEC_CONTENT
and	SEC_CONTENT
s	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
nhas	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
form	SEC_CONTENT
:	SEC_END
Sampling	SEC_START
from	SEC_CONTENT
this	SEC_CONTENT
proposal	SEC_CONTENT
requires	SEC_CONTENT
computing	SEC_CONTENT
the	task
normalized	task
distribution	task
P	task
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
kn	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
similarly	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
update	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
weights	SEC_CONTENT
(	SEC_CONTENT
Equation	SEC_CONTENT
8)	SEC_CONTENT
requires	SEC_CONTENT
the	task
calculation	task
of	SEC_CONTENT
Q	SEC_CONTENT
in	SEC_CONTENT
its	task
normalized	task
form	task
.	SEC_CONTENT
In	SEC_CONTENT
each	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
total	SEC_CONTENT
cost	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
product	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
sizes	SEC_CONTENT
,	SEC_CONTENT
O(#|ν	SEC_CONTENT
T	SEC_CONTENT
|#|ν	SEC_CONTENT
S	SEC_CONTENT
|	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
tractable	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
vocabularies	SEC_CONTENT
become	SEC_CONTENT
large	SEC_CONTENT
.	SEC_END
In	SEC_START
low	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
settings	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
convenient	SEC_CONTENT
solution	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
equal	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
transition	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
Q(t	SEC_CONTENT
kn	SEC_CONTENT
|s	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
kn	SEC_CONTENT
|t	SEC_CONTENT
k	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
n−k+1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
choice	SEC_CONTENT
is	SEC_CONTENT
called	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
bootstrap	SEC_CONTENT
filter	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
the	SEC_CONTENT
advantage	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
weights	SEC_CONTENT
ω	SEC_CONTENT
(	SEC_CONTENT
k	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
exactly	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
product	SEC_CONTENT
of	SEC_CONTENT
emission	SEC_CONTENT
likelihoods	SEC_CONTENT
n	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
kn	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
complexity	SEC_CONTENT
of	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
weights	SEC_CONTENT
is	SEC_CONTENT
thus	SEC_CONTENT
O(#|ν	SEC_CONTENT
S	SEC_CONTENT
|	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
this	SEC_CONTENT
proposal	SEC_CONTENT
ignores	SEC_CONTENT
the	SEC_CONTENT
emission	SEC_CONTENT
likelihood	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
bootstrap	SEC_CONTENT
filter	SEC_CONTENT
has	SEC_CONTENT
very	SEC_CONTENT
little	SEC_CONTENT
hope	SEC_CONTENT
of	SEC_CONTENT
finding	SEC_CONTENT
a	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
probability	SEC_CONTENT
sample	SEC_CONTENT
in	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
entropy	SEC_CONTENT
contexts	SEC_CONTENT
.	SEC_END
We	SEC_START
strike	SEC_CONTENT
a	SEC_CONTENT
middle	SEC_CONTENT
ground	SEC_CONTENT
between	SEC_CONTENT
efficiency	SEC_CONTENT
and	SEC_CONTENT
accuracy	metric
,	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
closely	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
overall	SEC_CONTENT
likelihood	SEC_CONTENT
,	SEC_CONTENT
yet	SEC_CONTENT
is	SEC_CONTENT
tractable	SEC_CONTENT
to	SEC_CONTENT
sample	SEC_CONTENT
and	SEC_CONTENT
compute	SEC_CONTENT
:	SEC_END
Here	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
simply	SEC_CONTENT
replace	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
distribution	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
11	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
its	task
unnormalized	task
version	task
.	SEC_END
To	SEC_START
update	SEC_CONTENT
the	SEC_CONTENT
unnormalized	SEC_CONTENT
hypothesis	SEC_CONTENT
weights˜ω	SEC_CONTENT
weights˜	SEC_CONTENT
weights˜ω	SEC_CONTENT
kn	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
have˜ω	SEC_END
The	SEC_START
numerator	SEC_CONTENT
requires	SEC_CONTENT
summing	SEC_CONTENT
overall	SEC_CONTENT
elements	SEC_CONTENT
in	SEC_CONTENT
ν	SEC_CONTENT
T	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
denominator	SEC_CONTENT
Z(t	SEC_CONTENT
kn	SEC_CONTENT
)	SEC_CONTENT
requires	SEC_CONTENT
summing	SEC_CONTENT
overall	SEC_CONTENT
elements	SEC_CONTENT
in	SEC_CONTENT
ν	SEC_CONTENT
S	SEC_CONTENT
,	SEC_CONTENT
fora	SEC_CONTENT
total	SEC_CONTENT
cost	SEC_CONTENT
of	SEC_CONTENT
O(#|ν	SEC_CONTENT
T	SEC_CONTENT
|	SEC_CONTENT
+	SEC_CONTENT
#	SEC_CONTENT
|ν	SEC_CONTENT
S	SEC_CONTENT
|	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Decoding	SECTITLE_END
Given	SEC_START
an	SEC_CONTENT
input	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
s	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
decoding	SEC_CONTENT
problem	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
sentence	SEC_CONTENT
t	SEC_CONTENT
that	SEC_CONTENT
maximizes	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t|s	SEC_CONTENT
)	SEC_CONTENT
∝	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s|t)P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
N	SEC_CONTENT
n	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n−1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Feature	SEC_START
name	SEC_CONTENT
Description	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
pair	SEC_CONTENT
A	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
binary	SEC_CONTENT
features	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
source	SEC_CONTENT
/	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
pair	SEC_CONTENT
s	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
string	SEC_CONTENT
similarity	SEC_CONTENT
A	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
binary	SEC_CONTENT
features	SEC_CONTENT
indicating	SEC_CONTENT
whether	SEC_CONTENT
sis	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
N	SEC_CONTENT
string	SEC_CONTENT
similar	SEC_CONTENT
nonstandard	SEC_CONTENT
words	SEC_CONTENT
oft	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
N	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
5	SEC_CONTENT
,	SEC_CONTENT
10	SEC_CONTENT
,	SEC_CONTENT
25	SEC_CONTENT
,	SEC_CONTENT
50	SEC_CONTENT
,	SEC_CONTENT
100	SEC_CONTENT
,	SEC_CONTENT
250	SEC_CONTENT
,	SEC_CONTENT
500	SEC_CONTENT
,	SEC_CONTENT
1000	SEC_CONTENT
}	SEC_CONTENT
:	SEC_CONTENT
The	SEC_CONTENT
feature	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
model	SEC_END
As	SEC_START
with	SEC_CONTENT
learning	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
usual	SEC_CONTENT
dynamic	SEC_CONTENT
programming	SEC_CONTENT
algorithm	SEC_CONTENT
(	SEC_CONTENT
Viterbi	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
quadratic	SEC_CONTENT
cost	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
vocabulary	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
must	SEC_CONTENT
be	SEC_CONTENT
multiplied	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
cost	SEC_CONTENT
of	SEC_CONTENT
computing	SEC_CONTENT
the	task
normalized	task
probability	task
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
resulting	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
prohibitive	SEC_CONTENT
time	SEC_CONTENT
complexity	SEC_CONTENT
of	SEC_CONTENT
O(#|ν	SEC_CONTENT
S	SEC_CONTENT
|#|ν	SEC_CONTENT
T	SEC_CONTENT
|	SEC_CONTENT
2	SEC_CONTENT
N	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
We	SEC_START
consider	SEC_CONTENT
two	SEC_CONTENT
approximate	SEC_CONTENT
decoding	SEC_CONTENT
algorithms	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
simply	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
linear	SEC_CONTENT
complexity	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
vocabularies	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
identical	SEC_CONTENT
to	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t|s	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
extra	SEC_CONTENT
factor	SEC_CONTENT
of	SEC_CONTENT
Z(t	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
numerator	SEC_CONTENT
.	SEC_CONTENT
Alternatively	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
for	SEC_CONTENT
selecting	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
candidates	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
Viterbi	SEC_CONTENT
algorithm	SEC_CONTENT
only	SEC_CONTENT
within	SEC_CONTENT
these	SEC_CONTENT
candidates	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
total	SEC_CONTENT
cost	SEC_CONTENT
is	SEC_CONTENT
O(#|ν	SEC_CONTENT
S	SEC_CONTENT
|T	SEC_CONTENT
2	SEC_CONTENT
N	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
T	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
candidates	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
;	SEC_CONTENT
this	SEC_CONTENT
will	SEC_CONTENT
asymptotically	SEC_CONTENT
approach	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
t|s	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
T	SEC_CONTENT
→	SEC_CONTENT
#	SEC_CONTENT
|ν	SEC_CONTENT
T	SEC_CONTENT
|	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
evaluations	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
more	SEC_CONTENT
expensive	SEC_CONTENT
proposal+Viterbi	SEC_CONTENT
decoding	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
accuracy	metric
with	SEC_CONTENT
the	SEC_CONTENT
more	SEC_CONTENT
efficient	SEC_CONTENT
proposal	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
decoding	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
similar	SEC_CONTENT
.	SEC_END
Features	SECTITLE_END
Our	SEC_START
system	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
types	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
Table	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
word	SEC_CONTENT
pair	SEC_CONTENT
features	SEC_CONTENT
are	SEC_CONTENT
designed	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
lexical	task
conventions	task
,	SEC_CONTENT
e.g.	SEC_CONTENT
you	SEC_CONTENT
/	SEC_CONTENT
u	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
only	SEC_CONTENT
consider	SEC_CONTENT
word	SEC_CONTENT
pair	SEC_CONTENT
features	SEC_CONTENT
that	SEC_CONTENT
fired	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
string	SEC_CONTENT
similarity	SEC_CONTENT
features	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
similarity	SEC_CONTENT
function	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
has	SEC_CONTENT
proven	SEC_CONTENT
effective	SEC_CONTENT
for	SEC_CONTENT
normalization	task
in	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
bin	SEC_CONTENT
this	SEC_CONTENT
similarity	SEC_CONTENT
to	SEC_CONTENT
create	SEC_CONTENT
binary	SEC_CONTENT
features	SEC_CONTENT
indicating	SEC_CONTENT
whether	SEC_CONTENT
a	SEC_CONTENT
string	SEC_CONTENT
sis	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
-	SEC_CONTENT
N	SEC_CONTENT
most	SEC_CONTENT
similar	SEC_CONTENT
strings	SEC_CONTENT
tot	SEC_CONTENT
;	SEC_CONTENT
this	SEC_CONTENT
binning	SEC_CONTENT
yields	SEC_CONTENT
substantial	SEC_CONTENT
speed	SEC_CONTENT
improvements	SEC_CONTENT
without	SEC_CONTENT
negatively	SEC_CONTENT
impacting	SEC_CONTENT
accuracy	metric
.	SEC_END
Implementation	SECTITLE_START
and	SECTITLE_CONTENT
data	SECTITLE_END
The	SEC_START
model	SEC_CONTENT
and	SEC_CONTENT
inference	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
section	SEC_CONTENT
are	SEC_CONTENT
implemented	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
software	SEC_CONTENT
system	SEC_CONTENT
for	SEC_CONTENT
normalizing	task
text	task
on	SEC_CONTENT
twitter	SEC_CONTENT
,	SEC_CONTENT
called	SEC_CONTENT
UNLOL	SEC_CONTENT
:	SEC_CONTENT
unsupervised	task
normalization	task
in	SEC_CONTENT
a	SEC_CONTENT
LOgLinear	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
final	SEC_CONTENT
system	SEC_CONTENT
can	SEC_CONTENT
process	SEC_CONTENT
roughly	SEC_CONTENT
10,000	SEC_CONTENT
Tweets	SEC_CONTENT
per	SEC_CONTENT
hour	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
now	SEC_CONTENT
describe	SEC_CONTENT
some	SEC_CONTENT
implementation	SEC_CONTENT
details	SEC_CONTENT
.	SEC_END
Normalization	SECTITLE_START
candidates	SECTITLE_END
Most	SEC_START
tokens	SEC_CONTENT
in	SEC_CONTENT
tweets	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
require	SEC_CONTENT
normalization	task
.	SEC_CONTENT
The	SEC_CONTENT
question	SEC_CONTENT
of	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
which	SEC_CONTENT
words	SEC_CONTENT
are	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
normalized	SEC_CONTENT
is	SEC_CONTENT
still	SEC_CONTENT
an	SEC_CONTENT
open	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
Han	SEC_CONTENT
and	SEC_CONTENT
Baldwin	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
build	SEC_CONTENT
a	SEC_CONTENT
dictionary	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
permissible	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
domain	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
make	SEC_CONTENT
no	SEC_CONTENT
attempt	SEC_CONTENT
to	SEC_CONTENT
normalize	SEC_CONTENT
source	SEC_CONTENT
strings	SEC_CONTENT
that	SEC_CONTENT
match	SEC_CONTENT
these	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
with	SEC_CONTENT
other	SEC_CONTENT
comparable	SEC_CONTENT
approaches	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
therefore	SEC_CONTENT
unable	SEC_CONTENT
to	SEC_CONTENT
normalize	SEC_CONTENT
strings	SEC_CONTENT
like	SEC_CONTENT
ill	SEC_CONTENT
into	SEC_CONTENT
I	SEC_CONTENT
'll	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
"	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
vocabulary	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
IV	SEC_CONTENT
)	SEC_CONTENT
words	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
GNU	SEC_CONTENT
aspell	SEC_CONTENT
dictionary	SEC_CONTENT
(	SEC_CONTENT
v0.60.6	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
containing	SEC_CONTENT
97,070	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
From	SEC_CONTENT
this	SEC_CONTENT
dictionary	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
follow	SEC_CONTENT
and	SEC_CONTENT
remove	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
count	SEC_CONTENT
of	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
20	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
Edinburgh	SEC_CONTENT
Twitter	SEC_CONTENT
corpus	SEC_CONTENT
)	SEC_CONTENT
-resulting	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
total	SEC_CONTENT
of	SEC_CONTENT
52,449	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
single	SEC_CONTENT
characters	SEC_CONTENT
except	SEC_CONTENT
a	SEC_CONTENT
and	SEC_CONTENT
i	SEC_CONTENT
are	SEC_CONTENT
excluded	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
rt	SEC_CONTENT
is	SEC_CONTENT
treated	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
vocabulary	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
all	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
vocabulary	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
define	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
|t	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
δ(s	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
tn	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
taking	SEC_CONTENT
the	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
zero	SEC_CONTENT
when	SEC_CONTENT
s	SEC_CONTENT
n	SEC_CONTENT
=	SEC_CONTENT
tn	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
effectively	SEC_CONTENT
prevents	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
from	SEC_CONTENT
attempting	SEC_CONTENT
to	SEC_CONTENT
normalize	SEC_CONTENT
these	SEC_CONTENT
words	SEC_CONTENT
.	SEC_END
In	SEC_START
addition	SEC_CONTENT
to	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
vocabulary	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
many	SEC_CONTENT
other	SEC_CONTENT
strings	SEC_CONTENT
that	SEC_CONTENT
should	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
normalized	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
names	SEC_CONTENT
and	SEC_CONTENT
multiword	SEC_CONTENT
shortenings	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
going	SEC_CONTENT
to	SEC_CONTENT
/	SEC_CONTENT
gonna	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
follow	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
and	SEC_CONTENT
assume	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
normalization	task
candidates	task
is	SEC_CONTENT
known	SEC_CONTENT
in	SEC_CONTENT
advance	SEC_CONTENT
during	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
has	SEC_CONTENT
no	task
such	task
information	task
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
we	SEC_CONTENT
attempt	SEC_CONTENT
to	SEC_CONTENT
normalize	SEC_CONTENT
all	SEC_CONTENT
tokens	SEC_CONTENT
that	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
lexicon	SEC_CONTENT
of	SEC_CONTENT
IV	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
composed	SEC_CONTENT
of	SEC_CONTENT
letters	SEC_CONTENT
,	SEC_CONTENT
numbers	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
apostrophe	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
set	SEC_CONTENT
includes	SEC_CONTENT
contractions	SEC_CONTENT
like	SEC_CONTENT
"	SEC_CONTENT
gon	SEC_CONTENT
na	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
got	SEC_CONTENT
ta	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
would	SEC_CONTENT
not	SEC_CONTENT
appear	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
are	SEC_CONTENT
nonetheless	SEC_CONTENT
normalized	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
each	SEC_CONTENT
OOV	SEC_CONTENT
token	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
a	task
pre	task
-	task
normalization	task
step	task
by	SEC_CONTENT
reducing	SEC_CONTENT
any	SEC_CONTENT
repetitions	SEC_CONTENT
of	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
two	SEC_CONTENT
letters	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
nonstandard	SEC_CONTENT
words	SEC_CONTENT
to	SEC_CONTENT
exactly	SEC_CONTENT
two	SEC_CONTENT
letters	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
cooool	SEC_CONTENT
→	SEC_CONTENT
cool	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Language	SECTITLE_START
modeling	SECTITLE_END
The	SEC_START
Kneser	SEC_CONTENT
-	SEC_CONTENT
Ney	SEC_CONTENT
smoothed	SEC_CONTENT
trigram	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
estimated	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
SRILM	SEC_CONTENT
toolkit	SEC_CONTENT
Stolcke	SEC_CONTENT
(	SEC_CONTENT
2002	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
Tweets	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Edinburgh	SEC_CONTENT
Twitter	SEC_CONTENT
corpus	SEC_CONTENT
that	SEC_CONTENT
contain	SEC_CONTENT
no	SEC_CONTENT
OOV	SEC_CONTENT
words	SEC_CONTENT
besides	SEC_CONTENT
hashtags	SEC_CONTENT
and	SEC_CONTENT
username	SEC_CONTENT
mentions	SEC_CONTENT
(	SEC_CONTENT
following	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
this	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
occasionally	SEC_CONTENT
find	SEC_CONTENT
training	SEC_CONTENT
contexts	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
trigram	SEC_CONTENT
tn	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
n−1	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
n−2	SEC_CONTENT
is	SEC_CONTENT
unobserved	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
data	SEC_CONTENT
;	SEC_CONTENT
features	SEC_CONTENT
resulting	SEC_CONTENT
from	SEC_CONTENT
such	SEC_CONTENT
trigrams	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
considered	SEC_CONTENT
when	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
gradients	SEC_CONTENT
.	SEC_END
Parameters	SECTITLE_END
The	SEC_START
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
approximations	SEC_CONTENT
require	SEC_CONTENT
two	SEC_CONTENT
parameters	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
samples	SEC_CONTENT
for	SEC_CONTENT
sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
(	SEC_CONTENT
K	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
samples	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
sequential	SEC_CONTENT
sampler	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
nested	SEC_CONTENT
expectation	SEC_CONTENT
(	SEC_CONTENT
L	SEC_CONTENT
,	SEC_CONTENT
from	SEC_CONTENT
Equation	SEC_CONTENT
10	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
theory	SEC_CONTENT
of	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
approximation	SEC_CONTENT
states	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
quality	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
approximation	SEC_CONTENT
should	SEC_CONTENT
only	SEC_CONTENT
improve	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
samples	SEC_CONTENT
increases	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
obtained	SEC_CONTENT
good	SEC_CONTENT
results	SEC_CONTENT
with	SEC_CONTENT
K	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
and	SEC_CONTENT
L	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
found	SEC_CONTENT
relatively	SEC_CONTENT
little	SEC_CONTENT
improvement	SEC_CONTENT
by	SEC_CONTENT
increasing	SEC_CONTENT
these	SEC_CONTENT
values	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hypotheses	SEC_CONTENT
considered	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
T	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
;	SEC_CONTENT
again	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
should	SEC_CONTENT
only	SEC_CONTENT
improve	SEC_CONTENT
with	SEC_CONTENT
T	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
we	SEC_CONTENT
more	SEC_CONTENT
closely	SEC_CONTENT
approximate	SEC_CONTENT
full	SEC_CONTENT
Viterbi	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
Datasets	SEC_START
We	SEC_CONTENT
use	SEC_CONTENT
two	SEC_CONTENT
existing	SEC_CONTENT
labeled	SEC_CONTENT
Twitter	SEC_CONTENT
datasets	SEC_CONTENT
to	SEC_CONTENT
evaluate	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
dataset	SEC_CONTENT
-which	SEC_CONTENT
we	SEC_CONTENT
call	SEC_CONTENT
LWWL11	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
names	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
authors	SEC_CONTENT
Liu	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
-contains	SEC_CONTENT
3,802	SEC_CONTENT
individual	SEC_CONTENT
"	SEC_CONTENT
nonstandard	SEC_CONTENT
"	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
vocabulary	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
their	task
normalized	task
forms	task
.	SEC_CONTENT
The	SEC_CONTENT
rest	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
message	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
is	SEC_CONTENT
appear	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
available	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
provide	SEC_CONTENT
linguistic	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
its	SEC_CONTENT
decoding	SEC_CONTENT
must	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
unigram	SEC_CONTENT
target	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
dataset	SEC_CONTENT
-which	SEC_CONTENT
is	SEC_CONTENT
called	SEC_CONTENT
LexNorm1.1	SEC_CONTENT
by	SEC_CONTENT
its	SEC_CONTENT
authors	SEC_CONTENT
Han	SEC_CONTENT
and	SEC_CONTENT
Baldwin	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
-contains	SEC_CONTENT
549	SEC_CONTENT
complete	SEC_CONTENT
tweets	SEC_CONTENT
with	SEC_CONTENT
1,184	SEC_CONTENT
nonstandard	SEC_CONTENT
tokens	SEC_CONTENT
(	SEC_CONTENT
558	SEC_CONTENT
unique	SEC_CONTENT
word	SEC_CONTENT
types	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Method	SECTITLE_END
Dataset	SECTITLE_END
Precision	SEC_START
Recall	SEC_CONTENT
F	SEC_CONTENT
-	SEC_CONTENT
measure	SEC_CONTENT
(	SEC_CONTENT
 	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
decode	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
trigram	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Close	SEC_START
analysis	SEC_CONTENT
of	SEC_CONTENT
LexNorm1.1	dataset
revealed	SEC_CONTENT
some	SEC_CONTENT
inconsistencies	SEC_CONTENT
in	SEC_CONTENT
annotation	task
(	SEC_CONTENT
for	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
y'	SEC_CONTENT
all	SEC_CONTENT
and	SEC_CONTENT
2	SEC_CONTENT
are	SEC_CONTENT
sometimes	SEC_CONTENT
normalized	SEC_CONTENT
to	SEC_CONTENT
you	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
are	SEC_CONTENT
left	SEC_CONTENT
unnormalized	SEC_CONTENT
in	SEC_CONTENT
other	SEC_CONTENT
cases	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
several	task
annotations	task
disagree	SEC_CONTENT
with	SEC_CONTENT
existing	SEC_CONTENT
resources	SEC_CONTENT
on	SEC_CONTENT
internet	SEC_CONTENT
language	SEC_CONTENT
and	SEC_CONTENT
dialectal	SEC_CONTENT
English	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
smh	SEC_CONTENT
is	SEC_CONTENT
normalized	SEC_CONTENT
to	SEC_CONTENT
somehow	SEC_CONTENT
in	SEC_CONTENT
LexNorm1.1	dataset
,	SEC_CONTENT
but	SEC_CONTENT
internetslang.com	SEC_CONTENT
and	SEC_CONTENT
urbandictionary.com	SEC_CONTENT
assert	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
stands	SEC_CONTENT
for	SEC_CONTENT
shake	SEC_CONTENT
my	SEC_CONTENT
head	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
evident	SEC_CONTENT
from	SEC_CONTENT
examples	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
smh	SEC_CONTENT
at	SEC_CONTENT
this	SEC_CONTENT
girl	SEC_CONTENT
.	SEC_CONTENT
Similarly	SEC_CONTENT
,	SEC_CONTENT
finna	SEC_CONTENT
is	SEC_CONTENT
normalized	SEC_CONTENT
to	SEC_CONTENT
finally	SEC_CONTENT
in	SEC_CONTENT
LexNorm1.1	dataset
,	SEC_CONTENT
but	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
on	SEC_CONTENT
African	SEC_CONTENT
American	SEC_CONTENT
English	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
corresponds	SEC_CONTENT
to	SEC_CONTENT
fixing	SEC_CONTENT
to	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
'm	SEC_CONTENT
finna	SEC_CONTENT
go	SEC_CONTENT
home	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
address	SEC_CONTENT
these	SEC_CONTENT
issues	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
produced	SEC_CONTENT
anew	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
call	SEC_CONTENT
LexNorm1.2	SEC_CONTENT
(	SEC_CONTENT
after	SEC_CONTENT
consulting	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
creators	SEC_CONTENT
of	SEC_CONTENT
LexNorm1.1	dataset
)	SEC_CONTENT
.	SEC_CONTENT
LexNorm1.2	dataset
differs	SEC_CONTENT
from	SEC_CONTENT
version	SEC_CONTENT
1.1	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
annotations	SEC_CONTENT
for	SEC_CONTENT
172	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
2140	SEC_CONTENT
OOV	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
evaluate	SEC_CONTENT
on	SEC_CONTENT
LexNorm1.1	dataset
to	SEC_CONTENT
compare	SEC_CONTENT
with	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
present	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
LexNorm1.2	dataset
in	SEC_CONTENT
the	SEC_CONTENT
hope	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
will	SEC_CONTENT
become	SEC_CONTENT
standard	SEC_CONTENT
in	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
normalization	task
in	SEC_CONTENT
English	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
dataset	SEC_CONTENT
is	SEC_CONTENT
available	SEC_CONTENT
at	SEC_CONTENT
http://www.cc.gatech.edu/	SEC_CONTENT
~jeisenst	SEC_CONTENT
/	SEC_CONTENT
lexnorm.v1.2.tgz	SEC_CONTENT
.	SEC_END
To	SEC_START
obtain	SEC_CONTENT
unlabeled	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
randomly	SEC_CONTENT
sample	SEC_CONTENT
50	SEC_CONTENT
tweets	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Edinburgh	SEC_CONTENT
Twitter	SEC_CONTENT
corpus	SEC_CONTENT
Petrovi´c	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
OOV	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
Some	SEC_CONTENT
OOV	SEC_CONTENT
words	SEC_CONTENT
appear	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
50	SEC_CONTENT
times	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
we	SEC_CONTENT
obtained	SEC_CONTENT
more	SEC_CONTENT
training	SEC_CONTENT
tweets	SEC_CONTENT
for	SEC_CONTENT
them	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
Twitter	SEC_CONTENT
search	SEC_CONTENT
API	SEC_CONTENT
.	SEC_END
Metrics	SEC_START
Prior	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
these	SEC_CONTENT
datasets	SEC_CONTENT
has	SEC_CONTENT
assumed	SEC_CONTENT
perfect	SEC_CONTENT
detection	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
requiring	SEC_CONTENT
normalization	task
,	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
finding	SEC_CONTENT
the	task
correct	task
normalization	task
for	SEC_CONTENT
these	SEC_CONTENT
.	SEC_CONTENT
Recall	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
proportion	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
requiring	SEC_CONTENT
normalization	task
which	SEC_CONTENT
are	SEC_CONTENT
normalized	SEC_CONTENT
correctly	SEC_CONTENT
;	SEC_CONTENT
precision	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
proportion	SEC_CONTENT
of	SEC_CONTENT
normalizations	task
which	SEC_CONTENT
are	SEC_CONTENT
correct	SEC_CONTENT
.	SEC_END
Results	SEC_START
We	SEC_CONTENT
run	SEC_CONTENT
our	SEC_CONTENT
training	SEC_CONTENT
algorithm	SEC_CONTENT
for	SEC_CONTENT
two	SEC_CONTENT
iterations	SEC_CONTENT
(	SEC_CONTENT
pass	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
twice	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
system	SEC_CONTENT
,	SEC_CONTENT
UNLOL	SEC_CONTENT
,	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
published	SEC_CONTENT
F	SEC_CONTENT
-	SEC_CONTENT
measure	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_CONTENT
Performance	SEC_CONTENT
on	SEC_CONTENT
LexNorm1.2	dataset
is	SEC_CONTENT
very	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
LexNorm1.1	dataset
,	SEC_CONTENT
despite	SEC_CONTENT
the	SEC_CONTENT
fact	SEC_CONTENT
that	SEC_CONTENT
roughly	SEC_CONTENT
8	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
examples	SEC_CONTENT
were	SEC_CONTENT
relabeled	SEC_CONTENT
.	SEC_END
In	SEC_START
the	task
normalization	task
task	task
that	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
tokens	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
normalized	SEC_CONTENT
are	SEC_CONTENT
specified	SEC_CONTENT
in	SEC_CONTENT
advance	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
task	SEC_CONTENT
specification	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
against	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
test	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
system	SEC_CONTENT
attempts	SEC_CONTENT
normalizes	SEC_CONTENT
all	SEC_CONTENT
such	SEC_CONTENT
tokens	SEC_CONTENT
;	SEC_CONTENT
every	SEC_CONTENT
error	SEC_CONTENT
is	SEC_CONTENT
thus	SEC_CONTENT
both	SEC_CONTENT
a	SEC_CONTENT
false	SEC_CONTENT
positive	SEC_CONTENT
and	SEC_CONTENT
false	SEC_CONTENT
negative	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
precision	SEC_CONTENT
equals	SEC_CONTENT
to	SEC_CONTENT
recall	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
;	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
true	SEC_CONTENT
for	SEC_CONTENT
Han	SEC_CONTENT
and	SEC_CONTENT
Baldwin	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
.	SEC_END
It	SEC_START
is	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
trade	SEC_CONTENT
recall	SEC_CONTENT
for	SEC_CONTENT
precision	SEC_CONTENT
by	SEC_CONTENT
refusing	SEC_CONTENT
to	SEC_CONTENT
normalize	SEC_CONTENT
words	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
system	SEC_CONTENT
's	SEC_CONTENT
confidence	SEC_CONTENT
falls	SEC_CONTENT
below	SEC_CONTENT
a	SEC_CONTENT
threshold	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
good	SEC_CONTENT
setting	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
threshold	SEC_CONTENT
can	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
F	SEC_CONTENT
-	SEC_CONTENT
measure	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
report	SEC_CONTENT
these	SEC_CONTENT
results	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
no	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
parameter	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_END
Regularization	SEC_START
One	SEC_CONTENT
potential	SEC_CONTENT
concern	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
zero	SEC_CONTENT
feature	SEC_CONTENT
weights	SEC_CONTENT
will	SEC_CONTENT
continually	SEC_CONTENT
increase	SEC_CONTENT
until	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
cost	SEC_CONTENT
becomes	SEC_CONTENT
overwhelming	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
run	SEC_CONTENT
up	SEC_CONTENT
against	SEC_CONTENT
mem-	SEC_CONTENT
Figure	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
Effect	SEC_CONTENT
of	SEC_CONTENT
L1	task
regularization	task
on	SEC_CONTENT
the	SEC_CONTENT
F	SEC_CONTENT
-	SEC_CONTENT
measure	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
with	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
zero	SEC_CONTENT
weights	SEC_CONTENT
ory	SEC_CONTENT
limitations	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
experiments	SEC_CONTENT
producing	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
issue	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
addressed	SEC_CONTENT
through	SEC_CONTENT
the	task
application	task
of	SEC_CONTENT
L1	task
regularization	task
,	SEC_CONTENT
which	SEC_CONTENT
produces	SEC_CONTENT
sparse	SEC_CONTENT
weight	SEC_CONTENT
vectors	SEC_CONTENT
by	SEC_CONTENT
adding	SEC_CONTENT
a	SEC_CONTENT
penalty	SEC_CONTENT
of	SEC_CONTENT
λ||θ||	SEC_CONTENT
1	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
perform	SEC_CONTENT
online	task
optimization	task
of	SEC_CONTENT
the	SEC_CONTENT
L1-regularized	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
by	SEC_CONTENT
applying	SEC_CONTENT
the	SEC_CONTENT
truncated	SEC_CONTENT
gradient	SEC_CONTENT
method	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
an	SEC_CONTENT
exponential	SEC_CONTENT
decreasing	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
η	SEC_CONTENT
k	SEC_CONTENT
=	SEC_CONTENT
η	SEC_CONTENT
0	SEC_CONTENT
α	SEC_CONTENT
k	SEC_CONTENT
/	SEC_CONTENT
N	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
k	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
iteration	SEC_CONTENT
counter	SEC_CONTENT
and	SEC_CONTENT
N	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
η	SEC_CONTENT
0	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
and	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
.	SEC_CONTENT
Experiments	SEC_CONTENT
were	SEC_CONTENT
run	SEC_CONTENT
until	SEC_CONTENT
300,000	SEC_CONTENT
training	SEC_CONTENT
instances	SEC_CONTENT
were	SEC_CONTENT
observed	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
final	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
1/32	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
regularization	task
can	SEC_CONTENT
dramatically	SEC_CONTENT
decrease	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
active	SEC_CONTENT
features	SEC_CONTENT
without	SEC_CONTENT
harming	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
Analysis	SECTITLE_END
We	SEC_START
apply	SEC_CONTENT
our	task
normalization	task
system	task
to	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
orthographic	SEC_CONTENT
processes	SEC_CONTENT
underlying	SEC_CONTENT
language	SEC_CONTENT
variation	SEC_CONTENT
in	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
.	SEC_CONTENT
Using	SEC_CONTENT
a	SEC_CONTENT
dataset	SEC_CONTENT
of	SEC_CONTENT
400,000	SEC_CONTENT
English	SEC_CONTENT
language	SEC_CONTENT
tweets	SEC_CONTENT
,	SEC_CONTENT
sampled	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
month	SEC_CONTENT
of	SEC_CONTENT
August	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
year	SEC_CONTENT
from	SEC_CONTENT
2009	SEC_CONTENT
to	SEC_CONTENT
2012	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
UNLOL	SEC_CONTENT
to	SEC_CONTENT
automatically	SEC_CONTENT
normalize	SEC_CONTENT
each	SEC_CONTENT
token	SEC_CONTENT
.	SEC_END
We	SEC_START
then	SEC_CONTENT
treat	SEC_CONTENT
these	task
normalizations	task
as	SEC_CONTENT
labeled	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
examine	SEC_CONTENT
the	SEC_CONTENT
Levenshtein	SEC_CONTENT
alignment	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
and	SEC_CONTENT
target	SEC_CONTENT
tokens	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
alignment	SEC_CONTENT
gives	SEC_CONTENT
approximate	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
transduction	SEC_CONTENT
rules	SEC_CONTENT
to	SEC_CONTENT
explain	SEC_CONTENT
each	SEC_CONTENT
OOV	SEC_CONTENT
token	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
then	SEC_CONTENT
examine	SEC_CONTENT
which	SEC_CONTENT
rules	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
by	SEC_CONTENT
each	SEC_CONTENT
author	SEC_CONTENT
,	SEC_CONTENT
constructing	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
of	SEC_CONTENT
authors	SEC_CONTENT
and	SEC_CONTENT
rules	SEC_CONTENT
.	SEC_CONTENT
Factorization	task
of	SEC_CONTENT
the	SEC_CONTENT
author	SEC_CONTENT
-	SEC_CONTENT
rule	SEC_CONTENT
matrix	SEC_CONTENT
reveals	SEC_CONTENT
sets	SEC_CONTENT
of	SEC_CONTENT
rules	SEC_CONTENT
that	SEC_CONTENT
tend	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
together	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
might	SEC_CONTENT
call	SEC_CONTENT
these	SEC_CONTENT
rulesets	SEC_CONTENT
"	SEC_CONTENT
orthographic	SEC_CONTENT
styles	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
We	SEC_CONTENT
apply	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
negative	SEC_CONTENT
matrix	SEC_CONTENT
factorization	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
characterizes	SEC_CONTENT
each	SEC_CONTENT
author	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
k	SEC_CONTENT
style	SEC_CONTENT
loadings	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
simultaneously	SEC_CONTENT
constructs	SEC_CONTENT
k	SEC_CONTENT
style	SEC_CONTENT
dictionaries	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
each	SEC_CONTENT
put	SEC_CONTENT
weight	SEC_CONTENT
on	SEC_CONTENT
different	SEC_CONTENT
orthographic	SEC_CONTENT
rules	SEC_CONTENT
.	SEC_CONTENT
Because	SEC_CONTENT
the	SEC_CONTENT
loadings	SEC_CONTENT
are	SEC_CONTENT
constrained	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
negative	SEC_CONTENT
,	SEC_CONTENT
the	task
factorization	task
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
sparsely	SEC_CONTENT
assigning	SEC_CONTENT
varying	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
style	SEC_CONTENT
to	SEC_CONTENT
each	SEC_CONTENT
author	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
choose	SEC_CONTENT
the	task
factorization	task
that	SEC_CONTENT
minimizes	SEC_CONTENT
the	SEC_CONTENT
Frobenius	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
reconstruction	SEC_CONTENT
error	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
NIMFA	SEC_CONTENT
software	SEC_CONTENT
package	SEC_CONTENT
(	SEC_CONTENT
http://nimfa.biolab.si/	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
The	SEC_START
resulting	SEC_CONTENT
styles	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
fork	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
;	SEC_CONTENT
other	SEC_CONTENT
values	SEC_CONTENT
of	SEC_CONTENT
k	SEC_CONTENT
give	SEC_CONTENT
similar	SEC_CONTENT
overall	SEC_CONTENT
results	SEC_CONTENT
with	SEC_CONTENT
more	SEC_CONTENT
or	SEC_CONTENT
less	SEC_CONTENT
detail	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
styles	SEC_CONTENT
incorporate	SEC_CONTENT
a	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
linguistic	SEC_CONTENT
phenomena	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
:	SEC_CONTENT
expressive	SEC_CONTENT
lengthening	SEC_CONTENT
(	SEC_CONTENT
styles	SEC_CONTENT
7	SEC_CONTENT
-	SEC_CONTENT
9	SEC_CONTENT
;	SEC_CONTENT
see	SEC_CONTENT
Brody	SEC_CONTENT
and	SEC_CONTENT
Diakopoulos	SEC_CONTENT
,	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
g	SEC_CONTENT
-	SEC_CONTENT
and	SEC_CONTENT
t	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
(	SEC_CONTENT
style	SEC_CONTENT
5	SEC_CONTENT
,	SEC_CONTENT
see	SEC_CONTENT
Eisenstein	SEC_CONTENT
2013a	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
th	SEC_CONTENT
-	SEC_CONTENT
stopping	SEC_CONTENT
(	SEC_CONTENT
style	SEC_CONTENT
6	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
dropping	SEC_CONTENT
of	SEC_CONTENT
several	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
final	SEC_CONTENT
vowels	SEC_CONTENT
(	SEC_CONTENT
styles	SEC_CONTENT
1	SEC_CONTENT
-	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Some	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
styles	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
t	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
and	SEC_CONTENT
th	SEC_CONTENT
-	SEC_CONTENT
stopping	SEC_CONTENT
,	SEC_CONTENT
have	SEC_CONTENT
direct	SEC_CONTENT
analogues	SEC_CONTENT
in	SEC_CONTENT
spoken	SEC_CONTENT
language	SEC_CONTENT
varieties	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
others	SEC_CONTENT
,	SEC_CONTENT
like	SEC_CONTENT
expressive	SEC_CONTENT
lengthening	SEC_CONTENT
,	SEC_CONTENT
seem	SEC_CONTENT
more	SEC_CONTENT
unique	SEC_CONTENT
to	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
relationships	SEC_CONTENT
between	SEC_CONTENT
these	SEC_CONTENT
orthographic	SEC_CONTENT
styles	SEC_CONTENT
and	SEC_CONTENT
social	SEC_CONTENT
variables	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
geography	SEC_CONTENT
and	SEC_CONTENT
demograph	SEC_CONTENT
-	SEC_CONTENT
style	SEC_CONTENT
rules	SEC_CONTENT
examples	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
you	SEC_CONTENT
;	SEC_CONTENT
o	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
y/	SEC_CONTENT
_	SEC_CONTENT
ou/_u	SEC_CONTENT
*	SEC_CONTENT
y/	SEC_CONTENT
*	SEC_CONTENT
_	SEC_CONTENT
o/	SEC_CONTENT
_	SEC_CONTENT
u	SEC_CONTENT
,	SEC_CONTENT
yu	SEC_CONTENT
,	SEC_CONTENT
2day	SEC_CONTENT
,	SEC_CONTENT
knw	SEC_CONTENT
,	SEC_CONTENT
gud	SEC_CONTENT
,	SEC_CONTENT
yur	SEC_CONTENT
,	SEC_CONTENT
wud	SEC_CONTENT
,	SEC_CONTENT
yuh	SEC_CONTENT
,	SEC_CONTENT
u've	SEC_CONTENT
,	SEC_CONTENT
toda	SEC_CONTENT
,	SEC_CONTENT
everthing	SEC_CONTENT
,	SEC_CONTENT
everwhere	SEC_CONTENT
,	SEC_CONTENT
ourself	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
e	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
,	SEC_CONTENT
u	SEC_CONTENT
/	SEC_CONTENT
o	SEC_CONTENT
be	SEC_CONTENT
/	SEC_CONTENT
b	SEC_CONTENT
_	SEC_CONTENT
e/	SEC_CONTENT
_	SEC_CONTENT
o	SEC_CONTENT
/	SEC_CONTENT
u	SEC_CONTENT
e*/	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
b	SEC_CONTENT
,	SEC_CONTENT
r	SEC_CONTENT
,	SEC_CONTENT
luv	SEC_CONTENT
,	SEC_CONTENT
cum	SEC_CONTENT
,	SEC_CONTENT
hav	SEC_CONTENT
,	SEC_CONTENT
mayb	SEC_CONTENT
,	SEC_CONTENT
bn	SEC_CONTENT
,	SEC_CONTENT
remembr	SEC_CONTENT
,	SEC_CONTENT
btween	SEC_CONTENT
,	SEC_CONTENT
gunna	SEC_CONTENT
,	SEC_CONTENT
gud	SEC_CONTENT
3	SEC_CONTENT
.	SEC_CONTENT
a	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
a/	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
a/	SEC_CONTENT
*	SEC_CONTENT
_	SEC_CONTENT
re	SEC_CONTENT
/	SEC_CONTENT
r	SEC_CONTENT
_	SEC_CONTENT
ar/_r	SEC_CONTENT
r	SEC_CONTENT
,	SEC_CONTENT
tht	SEC_CONTENT
,	SEC_CONTENT
wht	SEC_CONTENT
,	SEC_CONTENT
yrs	SEC_CONTENT
,	SEC_CONTENT
bck	SEC_CONTENT
,	SEC_CONTENT
strt	SEC_CONTENT
,	SEC_CONTENT
gurantee	SEC_CONTENT
,	SEC_CONTENT
elementry	SEC_CONTENT
,	SEC_CONTENT
wr	SEC_CONTENT
,	SEC_CONTENT
rlly	SEC_CONTENT
,	SEC_CONTENT
wher	SEC_CONTENT
,	SEC_CONTENT
rdy	SEC_CONTENT
,	SEC_CONTENT
preciate	SEC_CONTENT
,	SEC_CONTENT
neway	SEC_CONTENT
4	SEC_CONTENT
.	SEC_CONTENT
g	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
g*/	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
ng	SEC_CONTENT
/	SEC_CONTENT
n	SEC_CONTENT
_	SEC_CONTENT
g/	SEC_CONTENT
_	SEC_CONTENT
goin	SEC_CONTENT
,	SEC_CONTENT
talkin	SEC_CONTENT
,	SEC_CONTENT
watchin	SEC_CONTENT
,	SEC_CONTENT
feelin	SEC_CONTENT
,	SEC_CONTENT
makin	SEC_CONTENT
5	SEC_CONTENT
.	SEC_CONTENT
t	SEC_CONTENT
-	SEC_CONTENT
dropping	SEC_CONTENT
t*/	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
st	SEC_CONTENT
/	SEC_CONTENT
s	SEC_CONTENT
_	SEC_CONTENT
t/	SEC_CONTENT
_	SEC_CONTENT
jus	SEC_CONTENT
,	SEC_CONTENT
bc	SEC_CONTENT
,	SEC_CONTENT
shh	SEC_CONTENT
,	SEC_CONTENT
wha	SEC_CONTENT
,	SEC_CONTENT
gota	SEC_CONTENT
,	SEC_CONTENT
wea	SEC_CONTENT
,	SEC_CONTENT
mus	SEC_CONTENT
,	SEC_CONTENT
firts	SEC_CONTENT
,	SEC_CONTENT
jes	SEC_CONTENT
,	SEC_CONTENT
subsistutes	SEC_CONTENT
6	SEC_CONTENT
.	SEC_CONTENT
th	SEC_CONTENT
-	SEC_CONTENT
stopping	SEC_CONTENT
h/	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
t/	SEC_CONTENT
*	SEC_CONTENT
d	SEC_CONTENT
th	SEC_CONTENT
/	SEC_CONTENT
d	SEC_CONTENT
_	SEC_CONTENT
t	SEC_CONTENT
/	SEC_CONTENT
d	SEC_CONTENT
dat	SEC_CONTENT
,	SEC_CONTENT
de	SEC_CONTENT
,	SEC_CONTENT
skool	SEC_CONTENT
,	SEC_CONTENT
fone	SEC_CONTENT
,	SEC_CONTENT
dese	SEC_CONTENT
,	SEC_CONTENT
dha	SEC_CONTENT
,	SEC_CONTENT
shid	SEC_CONTENT
,	SEC_CONTENT
dhat	SEC_CONTENT
,	SEC_CONTENT
dat	SEC_CONTENT
's	SEC_CONTENT
7	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
kd)-lengthening	SEC_CONTENT
i_/id	SEC_CONTENT
_	SEC_CONTENT
/k	SEC_CONTENT
_	SEC_CONTENT
/d	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
/k	SEC_CONTENT
*	SEC_CONTENT
idk	SEC_CONTENT
,	SEC_CONTENT
fuckk	SEC_CONTENT
,	SEC_CONTENT
okk	SEC_CONTENT
,	SEC_CONTENT
backk	SEC_CONTENT
,	SEC_CONTENT
workk	SEC_CONTENT
,	SEC_CONTENT
badd	SEC_CONTENT
,	SEC_CONTENT
andd	SEC_CONTENT
,	SEC_CONTENT
goodd	SEC_CONTENT
,	SEC_CONTENT
bedd	SEC_CONTENT
,	SEC_CONTENT
elidgible	SEC_CONTENT
,	SEC_CONTENT
pidgeon	SEC_CONTENT
8	SEC_CONTENT
.	SEC_CONTENT
o	SEC_CONTENT
-	SEC_CONTENT
lengthening	SEC_CONTENT
o_/oo	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
/o	SEC_CONTENT
*	SEC_CONTENT
_	SEC_CONTENT
/o	SEC_CONTENT
soo	SEC_CONTENT
,	SEC_CONTENT
noo	SEC_CONTENT
,	SEC_CONTENT
doo	SEC_CONTENT
,	SEC_CONTENT
oohh	SEC_CONTENT
,	SEC_CONTENT
loove	SEC_CONTENT
,	SEC_CONTENT
thoo	SEC_CONTENT
,	SEC_CONTENT
helloo	SEC_CONTENT
9	SEC_CONTENT
.	SEC_CONTENT
e	SEC_CONTENT
-	SEC_CONTENT
lengthening	SEC_CONTENT
_	SEC_CONTENT
/i	SEC_CONTENT
e_/ee	SEC_CONTENT
_	SEC_CONTENT
/e	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
/e	SEC_CONTENT
*	SEC_CONTENT
mee	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
ve	SEC_CONTENT
,	SEC_CONTENT
retweet	SEC_CONTENT
,	SEC_CONTENT
bestie	SEC_CONTENT
,	SEC_CONTENT
lovee	SEC_CONTENT
,	SEC_CONTENT
nicee	SEC_CONTENT
,	SEC_CONTENT
heey	SEC_CONTENT
,	SEC_CONTENT
likee	SEC_CONTENT
,	SEC_CONTENT
iphone	SEC_CONTENT
,	SEC_CONTENT
homie	SEC_CONTENT
,	SEC_CONTENT
ii	SEC_CONTENT
,	SEC_CONTENT
damnit	SEC_CONTENT
10	SEC_CONTENT
.	SEC_CONTENT
a	SEC_CONTENT
-	SEC_CONTENT
adding	SEC_CONTENT
_	SEC_CONTENT
/a	SEC_CONTENT
_	SEC_CONTENT
_	SEC_CONTENT
/ma	SEC_CONTENT
_	SEC_CONTENT
/m	SEC_CONTENT
_	SEC_CONTENT
*	SEC_CONTENT
/a	SEC_CONTENT
*	SEC_CONTENT
i	SEC_CONTENT
m	SEC_CONTENT
a	SEC_CONTENT
,	SEC_CONTENT
outta	SEC_CONTENT
,	SEC_CONTENT
needa	SEC_CONTENT
,	SEC_CONTENT
shoulda	SEC_CONTENT
,	SEC_CONTENT
woulda	SEC_CONTENT
,	SEC_CONTENT
mm	SEC_CONTENT
,	SEC_CONTENT
comming	SEC_CONTENT
,	SEC_CONTENT
tomm	SEC_CONTENT
,	SEC_CONTENT
boutt	SEC_CONTENT
,	SEC_CONTENT
ppreciate	SEC_CONTENT
ics	SEC_CONTENT
must	SEC_CONTENT
be	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
future	SEC_CONTENT
research	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
they	SEC_CONTENT
offer	SEC_CONTENT
a	task
promising	task
generalization	task
of	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
that	SEC_CONTENT
has	SEC_CONTENT
focused	SEC_CONTENT
almost	SEC_CONTENT
exclusively	SEC_CONTENT
on	SEC_CONTENT
exclusively	SEC_CONTENT
on	SEC_CONTENT
lexical	task
variation	task
(	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
exceptions	SEC_CONTENT
for	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
features	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
style	SEC_CONTENT
10	SEC_CONTENT
is	SEC_CONTENT
largely	SEC_CONTENT
the	SEC_CONTENT
result	SEC_CONTENT
of	SEC_CONTENT
mistaken	task
normalizations	task
.	SEC_CONTENT
The	SEC_CONTENT
tokens	SEC_CONTENT
i	SEC_CONTENT
m	SEC_CONTENT
a	SEC_CONTENT
,	SEC_CONTENT
outta	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
needa	SEC_CONTENT
all	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
expressions	SEC_CONTENT
in	SEC_CONTENT
standard	SEC_CONTENT
English	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
are	SEC_CONTENT
thus	SEC_CONTENT
outside	SEC_CONTENT
the	SEC_CONTENT
scope	SEC_CONTENT
of	SEC_CONTENT
the	task
normalization	task
task	task
as	SEC_CONTENT
defined	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
UNLOL	SEC_CONTENT
has	SEC_CONTENT
produced	SEC_CONTENT
incorrect	task
single	task
-	task
token	task
normalizations	task
for	SEC_CONTENT
these	SEC_CONTENT
terms	SEC_CONTENT
:	SEC_CONTENT
i	SEC_CONTENT
/	SEC_CONTENT
ima	SEC_CONTENT
,	SEC_CONTENT
out	SEC_CONTENT
/	SEC_CONTENT
outta	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
need	SEC_CONTENT
/	SEC_CONTENT
needa	SEC_CONTENT
.	SEC_CONTENT
But	SEC_CONTENT
while	SEC_CONTENT
these	task
normalizations	task
are	SEC_CONTENT
wrong	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
resulting	SEC_CONTENT
style	SEC_CONTENT
nonetheless	SEC_CONTENT
captures	SEC_CONTENT
a	SEC_CONTENT
coherent	SEC_CONTENT
orthographic	SEC_CONTENT
phenomenon	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
have	SEC_CONTENT
presented	SEC_CONTENT
a	SEC_CONTENT
unified	SEC_CONTENT
,	SEC_CONTENT
unsupervised	SEC_CONTENT
statistical	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
normalizing	SEC_CONTENT
social	SEC_CONTENT
media	SEC_CONTENT
text	SEC_CONTENT
,	SEC_CONTENT
attaining	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
reported	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
the	task
two	task
standard	task
normalization	task
datasets	task
.	SEC_CONTENT
The	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
comes	SEC_CONTENT
from	SEC_CONTENT
flexible	task
modeling	task
of	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
relationships	SEC_CONTENT
through	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
exploiting	SEC_CONTENT
contextual	SEC_CONTENT
regularity	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
feature	SEC_CONTENT
weights	SEC_CONTENT
without	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
primary	SEC_CONTENT
technical	SEC_CONTENT
challenge	SEC_CONTENT
was	SEC_CONTENT
overcoming	SEC_CONTENT
the	SEC_CONTENT
large	SEC_CONTENT
label	SEC_CONTENT
space	SEC_CONTENT
of	SEC_CONTENT
the	task
normalization	task
task	task
;	SEC_CONTENT
we	SEC_CONTENT
accomplish	SEC_CONTENT
this	SEC_CONTENT
using	SEC_CONTENT
sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
.	SEC_CONTENT
Future	SEC_CONTENT
work	SEC_CONTENT
may	SEC_CONTENT
consider	SEC_CONTENT
whether	SEC_CONTENT
sequential	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
can	SEC_CONTENT
offer	SEC_CONTENT
similar	SEC_CONTENT
advantages	SEC_CONTENT
in	SEC_CONTENT
other	SEC_CONTENT
unsupervised	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
An	SEC_CONTENT
additional	SEC_CONTENT
benefit	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
joint	SEC_CONTENT
statistical	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
maybe	SEC_CONTENT
combined	SEC_CONTENT
with	SEC_CONTENT
other	SEC_CONTENT
downstream	SEC_CONTENT
language	SEC_CONTENT
processing	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
tagging	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
resolution	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
