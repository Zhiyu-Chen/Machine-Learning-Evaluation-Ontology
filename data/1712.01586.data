title	SECTITLE_END
Deep	SEC_START
Semantic	task
Role	task
Labeling	task
with	SEC_CONTENT
Self	SEC_CONTENT
-	SEC_CONTENT
Attention	SEC_END
abstract	SECTITLE_END
Semantic	SEC_START
Role	task
Labeling	task
(	SEC_CONTENT
SRL	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
believed	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
crucial	SEC_CONTENT
step	SEC_CONTENT
towards	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
widely	SEC_CONTENT
studied	SEC_CONTENT
.	SEC_CONTENT
Recent	SEC_CONTENT
years	SEC_CONTENT
,	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
SRL	SEC_CONTENT
with	SEC_CONTENT
recurrent	SEC_CONTENT
neu	SEC_CONTENT
-	SEC_CONTENT
ral	SEC_CONTENT
networks	SEC_CONTENT
(	SEC_CONTENT
RNN	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
gained	SEC_CONTENT
increasing	SEC_CONTENT
attention	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
remains	SEC_CONTENT
a	SEC_CONTENT
major	SEC_CONTENT
challenge	SEC_CONTENT
for	SEC_CONTENT
RNNs	SEC_CONTENT
to	SEC_CONTENT
handle	SEC_CONTENT
structural	SEC_CONTENT
information	SEC_CONTENT
and	SEC_CONTENT
long	SEC_CONTENT
range	SEC_CONTENT
dependencies	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
and	SEC_CONTENT
effective	SEC_CONTENT
architecture	SEC_CONTENT
for	SEC_CONTENT
SRL	SEC_CONTENT
which	SEC_CONTENT
aims	SEC_CONTENT
to	SEC_CONTENT
address	SEC_CONTENT
these	SEC_CONTENT
problems	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
which	SEC_CONTENT
can	SEC_CONTENT
directly	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
relationships	SEC_CONTENT
between	SEC_CONTENT
two	dataset
tokens	dataset
regardless	SEC_CONTENT
of	SEC_CONTENT
their	SEC_CONTENT
distance	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
single	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
F1	metric
=	SEC_CONTENT
83.4	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
dataset	SEC_CONTENT
and	SEC_CONTENT
F1	metric
=	SEC_CONTENT
82.7	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
by	SEC_CONTENT
1.8	SEC_CONTENT
and	SEC_CONTENT
1.0	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
computationally	SEC_CONTENT
efficient	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
parsing	SEC_CONTENT
speed	SEC_CONTENT
is	SEC_CONTENT
50	SEC_CONTENT
K	SEC_CONTENT
tokens	SEC_CONTENT
per	SEC_CONTENT
second	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
Titan	SEC_CONTENT
X	SEC_CONTENT
GPU	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Semantic	SEC_START
Role	task
Labeling	task
is	SEC_CONTENT
a	SEC_CONTENT
shallow	SEC_CONTENT
semantic	SEC_CONTENT
parsing	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
whose	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
determine	SEC_CONTENT
essentially	SEC_CONTENT
"	SEC_CONTENT
who	SEC_CONTENT
did	SEC_CONTENT
what	SEC_CONTENT
to	SEC_CONTENT
whom	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
when	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
where	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
Semantic	task
roles	task
indicate	SEC_CONTENT
the	SEC_CONTENT
basic	SEC_CONTENT
event	SEC_CONTENT
properties	SEC_CONTENT
and	SEC_CONTENT
relations	SEC_CONTENT
among	SEC_CONTENT
relevant	SEC_CONTENT
entities	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
provide	SEC_CONTENT
an	SEC_CONTENT
intermediate	SEC_CONTENT
level	SEC_CONTENT
of	SEC_CONTENT
semantic	task
representation	task
thus	SEC_CONTENT
benefiting	SEC_CONTENT
many	SEC_CONTENT
NLP	SEC_CONTENT
applications	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
Information	SEC_CONTENT
Extraction	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
Question	SEC_CONTENT
Answering	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
Machine	SEC_CONTENT
Translation	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
Multi	SEC_CONTENT
-	SEC_CONTENT
document	SEC_CONTENT
Abstractive	SEC_CONTENT
Summarization	SEC_CONTENT
(	SEC_CONTENT
Genest	SEC_CONTENT
and	SEC_CONTENT
Lapalme	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Semantic	SEC_START
roles	task
are	SEC_CONTENT
closely	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
syntax	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
traditional	SEC_CONTENT
SRL	SEC_CONTENT
approaches	SEC_CONTENT
rely	SEC_CONTENT
heavily	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
syntactic	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
brings	SEC_CONTENT
intrinsic	SEC_CONTENT
complexity	SEC_CONTENT
and	SEC_CONTENT
restrains	SEC_CONTENT
these	SEC_CONTENT
systems	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
domain	SEC_CONTENT
specific	SEC_CONTENT
.	SEC_CONTENT
Recently	SEC_CONTENT
,	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
SRL	SEC_CONTENT
without	SEC_CONTENT
syntactic	SEC_CONTENT
inputs	SEC_CONTENT
achieved	SEC_CONTENT
promising	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
the	SEC_CONTENT
pioneering	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
introduced	SEC_CONTENT
a	SEC_CONTENT
stacked	SEC_CONTENT
long	SEC_CONTENT
short	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
memory	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
reported	SEC_CONTENT
further	SEC_CONTENT
improvements	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
deep	SEC_CONTENT
highway	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTMs	SEC_CONTENT
with	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
successes	SEC_CONTENT
involving	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
models	SEC_CONTENT
reveal	SEC_CONTENT
the	SEC_CONTENT
potential	SEC_CONTENT
ability	SEC_CONTENT
of	SEC_CONTENT
LSTMs	SEC_CONTENT
for	SEC_CONTENT
handling	SEC_CONTENT
the	SEC_CONTENT
underlying	SEC_CONTENT
syntactic	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_END
Despite	SEC_START
recent	SEC_CONTENT
successes	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
RNN	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
models	SEC_CONTENT
have	SEC_CONTENT
limitations	SEC_CONTENT
.	SEC_CONTENT
RNNs	SEC_CONTENT
treat	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
recursively	SEC_CONTENT
compose	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
with	SEC_CONTENT
its	SEC_CONTENT
previous	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
recurrent	SEC_CONTENT
connections	SEC_CONTENT
make	SEC_CONTENT
RNNs	SEC_CONTENT
applicable	SEC_CONTENT
for	SEC_CONTENT
sequential	SEC_CONTENT
prediction	SEC_CONTENT
tasks	SEC_CONTENT
with	SEC_CONTENT
arbitrary	SEC_CONTENT
length	SEC_CONTENT
,	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
still	SEC_CONTENT
remain	SEC_CONTENT
several	SEC_CONTENT
challenges	SEC_CONTENT
in	SEC_CONTENT
practice	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
one	SEC_CONTENT
is	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
memory	SEC_CONTENT
compression	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
history	SEC_CONTENT
is	SEC_CONTENT
encoded	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
size	SEC_CONTENT
vector	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
requires	SEC_CONTENT
larger	SEC_CONTENT
memory	SEC_CONTENT
capacity	SEC_CONTENT
to	SEC_CONTENT
store	SEC_CONTENT
information	SEC_CONTENT
for	SEC_CONTENT
longer	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
unbalanced	SEC_CONTENT
way	SEC_CONTENT
of	SEC_CONTENT
dealing	SEC_CONTENT
with	SEC_CONTENT
sequential	SEC_CONTENT
information	SEC_CONTENT
leads	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
performing	SEC_CONTENT
poorly	SEC_CONTENT
on	SEC_CONTENT
long	dataset
sentences	dataset
while	SEC_CONTENT
wasting	SEC_CONTENT
memory	SEC_CONTENT
on	SEC_CONTENT
shorter	dataset
ones	dataset
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
one	SEC_CONTENT
is	SEC_CONTENT
concerned	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
inherent	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
sentences	dataset
.	SEC_CONTENT
RNNs	SEC_CONTENT
lack	SEC_CONTENT
away	SEC_CONTENT
to	SEC_CONTENT
tackle	SEC_CONTENT
the	SEC_CONTENT
tree	SEC_CONTENT
-	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
sequential	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
remains	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
depth	SEC_CONTENT
-	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
nonlinearities	dataset
depends	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
-	SEC_CONTENT
steps	SEC_CONTENT
.	SEC_END
To	SEC_START
address	SEC_CONTENT
these	SEC_CONTENT
problems	SEC_CONTENT
above	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
attentional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
DEEPATT	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
SRL	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
models	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
which	SEC_CONTENT
directly	SEC_CONTENT
draws	SEC_CONTENT
the	SEC_CONTENT
global	SEC_CONTENT
dependencies	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
to	SEC_CONTENT
RNNs	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
major	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
conducts	SEC_CONTENT
direct	SEC_CONTENT
connections	SEC_CONTENT
between	SEC_CONTENT
two	SEC_CONTENT
arbitrary	SEC_CONTENT
tokens	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
distant	SEC_CONTENT
elements	SEC_CONTENT
can	SEC_CONTENT
interact	SEC_CONTENT
with	SEC_CONTENT
each	SEC_CONTENT
other	SEC_CONTENT
by	SEC_CONTENT
shorter	SEC_CONTENT
paths	SEC_CONTENT
(	SEC_CONTENT
O(1	SEC_CONTENT
)	SEC_CONTENT
v.s.	SEC_CONTENT
O(n	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
allows	SEC_CONTENT
unimpeded	SEC_CONTENT
information	SEC_CONTENT
flow	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
also	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
flexible	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
select	SEC_CONTENT
,	SEC_CONTENT
represent	SEC_CONTENT
and	SEC_CONTENT
synthesize	SEC_CONTENT
the	SEC_CONTENT
information	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
complementary	SEC_CONTENT
to	SEC_CONTENT
RNN	SEC_CONTENT
based	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
Along	SEC_CONTENT
with	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
,	SEC_CONTENT
DEEP	SEC_CONTENT
-	SEC_CONTENT
ATT	SEC_CONTENT
comes	SEC_CONTENT
with	SEC_CONTENT
three	SEC_CONTENT
variants	SEC_CONTENT
which	SEC_CONTENT
uses	SEC_CONTENT
recurrent	SEC_CONTENT
(	SEC_CONTENT
RNN	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
convolutional	SEC_CONTENT
(	SEC_CONTENT
CNN	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
(	SEC_CONTENT
FFN	SEC_CONTENT
)	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
further	SEC_CONTENT
enhance	SEC_CONTENT
the	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_END
Although	SEC_START
DEEPATT	SEC_CONTENT
is	SEC_CONTENT
fairly	SEC_CONTENT
simple	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
gives	SEC_CONTENT
remarkable	SEC_CONTENT
empirical	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
single	SEC_CONTENT
model	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
previ	SEC_CONTENT
-	SEC_CONTENT
ous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
systems	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
dataset	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
dataset	SEC_CONTENT
by	SEC_CONTENT
1.8	SEC_CONTENT
and	SEC_CONTENT
1.0	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
worth	SEC_CONTENT
mentioning	SEC_CONTENT
that	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
out	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
domain	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
achieve	SEC_CONTENT
an	SEC_CONTENT
improvement	SEC_CONTENT
upon	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
approach	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
2.0	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
variant	SEC_CONTENT
of	SEC_CONTENT
DEEPATT	SEC_CONTENT
allows	SEC_CONTENT
significantly	SEC_CONTENT
more	SEC_CONTENT
parallelization	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
parsing	SEC_CONTENT
speed	SEC_CONTENT
is	SEC_CONTENT
50	SEC_CONTENT
K	SEC_CONTENT
tokens	SEC_CONTENT
per	SEC_CONTENT
second	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
Titan	SEC_CONTENT
X	SEC_CONTENT
GPU	SEC_CONTENT
.	SEC_END
Semantic	SECTITLE_START
Role	SECTITLE_CONTENT
Labeling	SECTITLE_END
Given	SEC_START
a	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
goal	SEC_CONTENT
of	SEC_CONTENT
SRL	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
and	SEC_CONTENT
classify	SEC_CONTENT
the	SEC_CONTENT
arguments	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
target	SEC_CONTENT
verb	SEC_CONTENT
into	SEC_CONTENT
semantic	task
roles	task
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
"	SEC_CONTENT
Marry	SEC_CONTENT
borrowed	SEC_CONTENT
a	SEC_CONTENT
book	SEC_CONTENT
from	SEC_CONTENT
John	SEC_CONTENT
last	SEC_CONTENT
week	SEC_CONTENT
.	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
verb	SEC_CONTENT
borrowed	SEC_CONTENT
,	SEC_CONTENT
SRL	SEC_CONTENT
yields	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
outputs	SEC_CONTENT
:	SEC_END
Here	SEC_START
ARG0	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
borrower	SEC_CONTENT
,	SEC_CONTENT
ARG1	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
thing	SEC_CONTENT
borrowed	SEC_CONTENT
,	SEC_CONTENT
ARG2	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
entity	SEC_CONTENT
borrowed	SEC_CONTENT
from	SEC_CONTENT
,	SEC_CONTENT
AM	SEC_CONTENT
-	SEC_CONTENT
TMP	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
adjunct	SEC_CONTENT
indicating	SEC_CONTENT
the	SEC_CONTENT
timing	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
action	SEC_CONTENT
and	SEC_CONTENT
V	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
verb	SEC_CONTENT
.	SEC_END
Generally	SEC_START
,	SEC_CONTENT
semantic	task
role	task
labeling	task
consists	SEC_CONTENT
of	SEC_CONTENT
two	dataset
steps	dataset
:	SEC_CONTENT
identifying	SEC_CONTENT
and	SEC_CONTENT
classifying	SEC_CONTENT
arguments	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
former	SEC_CONTENT
step	SEC_CONTENT
involves	SEC_CONTENT
assigning	SEC_CONTENT
either	SEC_CONTENT
a	SEC_CONTENT
semantic	SEC_CONTENT
argument	SEC_CONTENT
or	SEC_CONTENT
nonargument	SEC_CONTENT
fora	SEC_CONTENT
given	SEC_CONTENT
predicate	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
latter	SEC_CONTENT
includes	SEC_CONTENT
labeling	SEC_CONTENT
a	task
specific	task
semantic	task
role	task
for	SEC_CONTENT
the	SEC_CONTENT
identified	SEC_CONTENT
argument	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
common	SEC_CONTENT
to	SEC_CONTENT
prune	SEC_CONTENT
obvious	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
candidates	SEC_CONTENT
before	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
step	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
post	SEC_CONTENT
-	SEC_CONTENT
processing	SEC_CONTENT
procedure	SEC_CONTENT
to	SEC_CONTENT
fix	SEC_CONTENT
inconsistent	SEC_CONTENT
predictions	SEC_CONTENT
after	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
step	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
dynamic	SEC_CONTENT
programming	SEC_CONTENT
algorithm	SEC_CONTENT
is	SEC_CONTENT
often	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
global	SEC_CONTENT
optimum	SEC_CONTENT
solution	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
typical	SEC_CONTENT
sequence	SEC_CONTENT
labeling	SEC_CONTENT
problem	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
inference	SEC_CONTENT
stage	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
treat	SEC_CONTENT
SRL	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
BIO	SEC_CONTENT
tagging	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
extremely	SEC_CONTENT
simple	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
illustrated	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
utterances	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
predicate	SEC_CONTENT
masks	SEC_CONTENT
are	SEC_CONTENT
first	SEC_CONTENT
projected	SEC_CONTENT
into	SEC_CONTENT
real	SEC_CONTENT
-	SEC_CONTENT
value	SEC_CONTENT
vectors	SEC_CONTENT
,	SEC_CONTENT
namely	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
fed	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
After	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
design	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
attentional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
which	SEC_CONTENT
takes	SEC_CONTENT
the	SEC_CONTENT
embeddings	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
nested	SEC_CONTENT
structures	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
latent	SEC_CONTENT
dependency	SEC_CONTENT
relationships	SEC_CONTENT
among	SEC_CONTENT
the	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
inference	SEC_CONTENT
stage	SEC_CONTENT
,	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
topmost	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
attention	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
are	SEC_CONTENT
taken	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
logistic	SEC_CONTENT
regression	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
decision	SEC_CONTENT
2	SEC_CONTENT
.	SEC_END
Deep	SECTITLE_START
Attentional	SECTITLE_CONTENT
Neural	SECTITLE_CONTENT
Network	SECTITLE_CONTENT
for	SECTITLE_CONTENT
SRL	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
describe	SEC_CONTENT
DEEPATT	SEC_CONTENT
in	SEC_CONTENT
detail	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
main	SEC_CONTENT
component	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
deep	SEC_CONTENT
network	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
N	SEC_CONTENT
identical	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
layer	SEC_CONTENT
contains	SEC_CONTENT
a	SEC_CONTENT
nonlinear	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
followed	SEC_CONTENT
by	SEC_CONTENT
an	SEC_CONTENT
attentional	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
topmost	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
classification	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_END
Self	SECTITLE_START
-	SECTITLE_CONTENT
Attention	SECTITLE_END
Self	SEC_START
-	SEC_CONTENT
attention	SEC_CONTENT
or	SEC_CONTENT
intra	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
special	SEC_CONTENT
case	SEC_CONTENT
of	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
that	SEC_CONTENT
only	SEC_CONTENT
requires	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
sequence	SEC_CONTENT
to	SEC_END
Word	SECTITLE_START
&	SECTITLE_CONTENT
Predicate	SECTITLE_END
Sub	SEC_START
-	SEC_CONTENT
Layer	SEC_CONTENT
compute	SEC_CONTENT
its	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
Self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
successfully	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
many	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
reading	SEC_CONTENT
comprehension	SEC_CONTENT
,	SEC_CONTENT
abstractive	SEC_CONTENT
summarization	SEC_CONTENT
,	SEC_CONTENT
textual	SEC_CONTENT
entailment	SEC_CONTENT
,	SEC_CONTENT
learning	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
independent	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
the	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
head	SEC_CONTENT
attention	SEC_CONTENT
formulation	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
depicts	SEC_CONTENT
the	SEC_CONTENT
computation	SEC_CONTENT
graph	SEC_CONTENT
of	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
head	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
center	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
graph	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
scaled	SEC_CONTENT
dot	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
attention	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
variant	SEC_CONTENT
of	SEC_CONTENT
dot	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
(	SEC_CONTENT
multiplicative	SEC_CONTENT
)	SEC_CONTENT
attention	SEC_CONTENT
.	SEC_CONTENT
Compared	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
additive	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
(	SEC_CONTENT
Bahdanau	SEC_CONTENT
,	SEC_CONTENT
Cho	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Bengio	SEC_CONTENT
2014	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
implemented	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
one	SEC_CONTENT
layer	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
dot	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
attention	SEC_CONTENT
utilizes	SEC_CONTENT
matrix	SEC_CONTENT
production	SEC_CONTENT
which	SEC_CONTENT
allows	SEC_CONTENT
faster	SEC_CONTENT
computation	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
of	SEC_CONTENT
n	SEC_CONTENT
query	SEC_CONTENT
vectors	SEC_CONTENT
Q	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
n×d	SEC_CONTENT
,	SEC_CONTENT
keys	SEC_CONTENT
K	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
n×d	SEC_CONTENT
and	SEC_CONTENT
values	SEC_CONTENT
V	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
n×d	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
scaled	SEC_CONTENT
dot	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
attention	SEC_CONTENT
computes	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
scores	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equation	SEC_CONTENT
:	SEC_END
where	SEC_START
dis	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
network	SEC_CONTENT
.	SEC_END
The	SEC_START
multi	SEC_CONTENT
-	SEC_CONTENT
head	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
first	SEC_CONTENT
maps	SEC_CONTENT
the	SEC_CONTENT
matrix	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
vectors	SEC_CONTENT
X	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
t×d	SEC_CONTENT
to	SEC_CONTENT
queries	SEC_CONTENT
,	SEC_CONTENT
keys	SEC_CONTENT
and	SEC_CONTENT
values	SEC_CONTENT
matrices	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
different	SEC_CONTENT
linear	SEC_CONTENT
projections	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
h	SEC_CONTENT
parallel	SEC_CONTENT
heads	SEC_CONTENT
are	SEC_CONTENT
employed	SEC_CONTENT
to	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
different	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
channels	SEC_END
Figure	SEC_START
2	SEC_CONTENT
:	SEC_CONTENT
The	SEC_CONTENT
computation	SEC_CONTENT
graph	SEC_CONTENT
of	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
head	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
heads	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
computed	SEC_CONTENT
in	SEC_CONTENT
parallel	SEC_CONTENT
using	SEC_CONTENT
highly	SEC_CONTENT
optimized	SEC_CONTENT
matrix	SEC_CONTENT
multiplication	SEC_CONTENT
codes	SEC_CONTENT
.	SEC_END
of	SEC_START
the	SEC_CONTENT
value	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
Formally	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
i	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
head	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
learned	SEC_CONTENT
linear	SEC_CONTENT
maps	SEC_CONTENT
by	SEC_END
,	SEC_START
which	SEC_CONTENT
correspond	SEC_CONTENT
to	SEC_CONTENT
queries	SEC_CONTENT
,	SEC_CONTENT
keys	SEC_CONTENT
and	SEC_CONTENT
values	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
the	SEC_CONTENT
scaled	SEC_CONTENT
dot	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
attention	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
relevance	SEC_CONTENT
between	SEC_CONTENT
queries	SEC_CONTENT
and	SEC_CONTENT
keys	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
output	SEC_CONTENT
mixed	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
mathematical	SEC_CONTENT
formulation	SEC_CONTENT
is	SEC_CONTENT
shown	SEC_CONTENT
below	SEC_CONTENT
:	SEC_END
Finally	SEC_START
,	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
vectors	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
parallel	SEC_CONTENT
heads	SEC_CONTENT
are	SEC_CONTENT
concatenated	SEC_CONTENT
together	SEC_CONTENT
to	SEC_CONTENT
form	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
vector	SEC_CONTENT
.	SEC_CONTENT
Again	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
linear	SEC_CONTENT
map	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
mix	SEC_CONTENT
different	SEC_CONTENT
channels	SEC_CONTENT
from	SEC_CONTENT
different	SEC_CONTENT
heads	SEC_CONTENT
:	SEC_END
where	SEC_START
M	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
n×d	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×d	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
has	SEC_CONTENT
many	SEC_CONTENT
appealing	SEC_CONTENT
aspects	SEC_CONTENT
compared	SEC_CONTENT
with	SEC_CONTENT
RNNs	SEC_CONTENT
or	SEC_CONTENT
CNNs	SEC_CONTENT
.	SEC_CONTENT
Firstly	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
distance	SEC_CONTENT
between	SEC_CONTENT
any	SEC_CONTENT
input	SEC_CONTENT
and	SEC_CONTENT
output	SEC_CONTENT
positions	SEC_CONTENT
is	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
whereas	SEC_CONTENT
in	SEC_CONTENT
RNNs	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
n.	SEC_CONTENT
Unlike	SEC_CONTENT
CNNs	SEC_CONTENT
,	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
limited	SEC_CONTENT
to	SEC_CONTENT
fixed	SEC_CONTENT
window	SEC_CONTENT
sizes	SEC_CONTENT
.	SEC_CONTENT
Secondly	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
uses	SEC_CONTENT
weighted	SEC_CONTENT
sum	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
output	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
a	SEC_CONTENT
result	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
propagations	SEC_CONTENT
are	SEC_CONTENT
much	SEC_CONTENT
easier	SEC_CONTENT
than	SEC_CONTENT
RNNs	SEC_CONTENT
or	SEC_CONTENT
CNNs	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
dot	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
attention	SEC_CONTENT
is	SEC_CONTENT
highly	SEC_CONTENT
parallel	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
RNNs	SEC_CONTENT
are	SEC_CONTENT
hard	SEC_CONTENT
to	SEC_CONTENT
parallelize	SEC_CONTENT
owing	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
recursive	SEC_CONTENT
computation	SEC_CONTENT
.	SEC_END
Nonlinear	SECTITLE_START
Sub	SECTITLE_CONTENT
-	SECTITLE_CONTENT
Layers	SECTITLE_END
The	SEC_START
successes	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
root	SEC_CONTENT
in	SEC_CONTENT
its	SEC_CONTENT
highly	SEC_CONTENT
flexible	SEC_CONTENT
nonlinear	SEC_CONTENT
transformations	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
uses	SEC_CONTENT
weighted	SEC_CONTENT
sum	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
output	SEC_CONTENT
vectors	SEC_CONTENT
,	SEC_CONTENT
its	SEC_CONTENT
representational	SEC_CONTENT
power	SEC_CONTENT
is	SEC_CONTENT
limited	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
further	SEC_CONTENT
increase	SEC_CONTENT
the	SEC_CONTENT
expressive	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
attentional	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
a	SEC_CONTENT
nonlinear	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
transform	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
bottom	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
explore	SEC_CONTENT
three	SEC_CONTENT
kinds	SEC_CONTENT
of	SEC_CONTENT
nonlinear	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
namely	SEC_CONTENT
recurrent	SEC_CONTENT
,	SEC_CONTENT
convolutional	SEC_CONTENT
and	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_END
Recurrent	SEC_START
Sub	SEC_CONTENT
-	SEC_CONTENT
Layer	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTMs	SEC_CONTENT
to	SEC_CONTENT
build	SEC_CONTENT
our	SEC_CONTENT
recurrent	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
vectors	SEC_CONTENT
{	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
}	SEC_CONTENT
,	SEC_CONTENT
two	SEC_CONTENT
LSTMs	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
in	SEC_CONTENT
opposite	SEC_CONTENT
directions	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
maintain	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
dimension	SEC_CONTENT
between	SEC_CONTENT
inputs	SEC_CONTENT
and	SEC_CONTENT
outputs	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
operation	SEC_CONTENT
to	SEC_CONTENT
combine	SEC_CONTENT
two	SEC_CONTENT
representations	SEC_CONTENT
:	SEC_END
Convolutional	SEC_START
Sub	SEC_CONTENT
-	SEC_CONTENT
Layer	SEC_CONTENT
For	SEC_CONTENT
convolutional	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
Gated	SEC_CONTENT
Linear	SEC_CONTENT
Unit	SEC_CONTENT
(	SEC_CONTENT
GLU	SEC_CONTENT
)	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
Compared	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
convolutional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
GLU	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
easier	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
and	SEC_CONTENT
achieves	SEC_CONTENT
impressive	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
two	SEC_CONTENT
filters	SEC_CONTENT
W	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
k×d×d	SEC_CONTENT
and	SEC_CONTENT
V	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
k×d×d	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
activations	SEC_CONTENT
of	SEC_CONTENT
GLU	SEC_CONTENT
are	SEC_CONTENT
computed	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
The	SEC_START
filter	SEC_CONTENT
width	SEC_CONTENT
k	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
3	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_END
where	SEC_START
W	SEC_CONTENT
1	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×h	SEC_CONTENT
f	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
2	SEC_CONTENT
∈	SEC_CONTENT
Rh	SEC_CONTENT
f	SEC_CONTENT
×d	SEC_CONTENT
are	SEC_CONTENT
trainable	SEC_CONTENT
matrices	SEC_CONTENT
.	SEC_CONTENT
Unless	SEC_CONTENT
otherwise	SEC_CONTENT
noted	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
hf	SEC_CONTENT
=	SEC_CONTENT
800	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_END
Deep	SECTITLE_START
Topology	SECTITLE_END
Previous	SEC_START
works	SEC_CONTENT
pointed	SEC_CONTENT
out	SEC_CONTENT
that	SEC_CONTENT
deep	SEC_CONTENT
topology	SEC_CONTENT
is	SEC_CONTENT
essential	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
good	SEC_CONTENT
performance	SEC_CONTENT
(	SEC_CONTENT
Zhou	SEC_CONTENT
and	SEC_CONTENT
Xu	SEC_CONTENT
2015	SEC_CONTENT
;	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
residual	SEC_CONTENT
connections	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
to	SEC_CONTENT
ease	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
deep	SEC_CONTENT
attentional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
Y	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
computed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equation	SEC_CONTENT
:	SEC_END
We	SEC_START
then	SEC_CONTENT
apply	SEC_CONTENT
layer	SEC_CONTENT
normalization	SEC_CONTENT
(	SEC_CONTENT
Ba	SEC_CONTENT
,	SEC_CONTENT
Kiros	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Hinton	dataset
2016	SEC_CONTENT
)	SEC_CONTENT
after	SEC_CONTENT
the	SEC_CONTENT
residual	SEC_CONTENT
connection	SEC_CONTENT
to	SEC_CONTENT
stabilize	SEC_CONTENT
the	SEC_CONTENT
activations	SEC_CONTENT
of	SEC_CONTENT
deep	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_END
Position	SECTITLE_START
Encoding	SECTITLE_END
The	SEC_START
attention	SEC_CONTENT
mechanism	SEC_CONTENT
itself	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
distinguish	SEC_CONTENT
between	SEC_CONTENT
different	SEC_CONTENT
positions	SEC_CONTENT
.	SEC_CONTENT
So	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
crucial	SEC_CONTENT
to	SEC_CONTENT
encode	SEC_CONTENT
positions	dataset
of	SEC_CONTENT
each	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
are	SEC_CONTENT
various	SEC_CONTENT
ways	SEC_CONTENT
to	SEC_CONTENT
encode	SEC_CONTENT
positions	dataset
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
simplest	SEC_CONTENT
one	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
an	SEC_CONTENT
additional	SEC_CONTENT
position	SEC_CONTENT
embedding	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
try	SEC_CONTENT
the	SEC_CONTENT
timing	SEC_CONTENT
signal	SEC_CONTENT
approach	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
formulated	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
The	SEC_START
timing	SEC_CONTENT
signals	SEC_CONTENT
are	SEC_CONTENT
simply	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
embedding	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
introduce	SEC_CONTENT
additional	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_END
Pipeline	SECTITLE_END
The	SEC_START
first	SEC_CONTENT
step	SEC_CONTENT
of	SEC_CONTENT
using	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
symbolic	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
represent	SEC_CONTENT
them	SEC_CONTENT
by	SEC_CONTENT
distributed	SEC_CONTENT
vectors	SEC_CONTENT
,	SEC_CONTENT
also	SEC_CONTENT
called	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
take	SEC_CONTENT
the	SEC_CONTENT
very	SEC_CONTENT
original	SEC_CONTENT
utterances	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
predicate	SEC_CONTENT
masks	SEC_CONTENT
m	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
mt	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
1	SEC_CONTENT
if	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
word	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
predicate	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
0	SEC_CONTENT
if	SEC_CONTENT
not	SEC_CONTENT
.	SEC_CONTENT
Formally	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
SRL	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
vocabulary	SEC_CONTENT
V	SEC_CONTENT
and	SEC_CONTENT
mask	SEC_CONTENT
vocabulary	SEC_CONTENT
C	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
sequence	SEC_CONTENT
{	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
T	SEC_CONTENT
}	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
mask	SEC_CONTENT
sequence	SEC_CONTENT
{	SEC_CONTENT
m	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
m	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
m	SEC_CONTENT
T	SEC_CONTENT
}	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
∈	SEC_CONTENT
V	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
corresponding	SEC_CONTENT
predicate	SEC_CONTENT
mask	SEC_CONTENT
mt	SEC_CONTENT
∈	SEC_CONTENT
C	SEC_CONTENT
are	SEC_CONTENT
projected	SEC_CONTENT
into	SEC_CONTENT
real	SEC_CONTENT
-	SEC_CONTENT
valued	SEC_CONTENT
vectors	SEC_CONTENT
e(x	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
e(m	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
lookup	SEC_CONTENT
table	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
two	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
then	SEC_CONTENT
concatenated	SEC_CONTENT
together	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
feature	SEC_CONTENT
maps	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
lookup	SEC_CONTENT
table	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
Formally	SEC_CONTENT
speaking	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
e(w	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
e(m	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
]	SEC_CONTENT
.	SEC_END
We	SEC_START
then	SEC_CONTENT
build	SEC_CONTENT
our	SEC_CONTENT
deep	SEC_CONTENT
attentional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
the	SEC_CONTENT
sequential	SEC_CONTENT
and	SEC_CONTENT
structural	SEC_CONTENT
information	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
sentence	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
maps	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
lookup	SEC_CONTENT
table	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
take	SEC_CONTENT
the	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
topmost	SEC_CONTENT
attention	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
as	SEC_CONTENT
inputs	SEC_CONTENT
to	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
predictions	SEC_CONTENT
.	SEC_END
Since	SEC_START
there	SEC_CONTENT
are	SEC_CONTENT
dependencies	SEC_CONTENT
between	SEC_CONTENT
semantic	task
labels	task
,	SEC_CONTENT
most	SEC_CONTENT
previous	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
models	SEC_CONTENT
introduced	SEC_CONTENT
a	SEC_CONTENT
transition	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
measuring	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
jumping	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
Different	SEC_CONTENT
from	SEC_CONTENT
these	SEC_CONTENT
works	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
perform	SEC_CONTENT
SRL	SEC_CONTENT
as	SEC_CONTENT
atypical	SEC_CONTENT
classification	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
Latent	SEC_CONTENT
dependency	SEC_CONTENT
information	SEC_CONTENT
is	SEC_CONTENT
embedded	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
topmost	SEC_CONTENT
attention	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
learned	SEC_CONTENT
by	SEC_CONTENT
our	SEC_CONTENT
deep	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
simpler	SEC_CONTENT
and	SEC_CONTENT
easier	SEC_CONTENT
to	SEC_CONTENT
implement	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
previous	SEC_CONTENT
works	SEC_CONTENT
.	SEC_END
Formally	SEC_START
,	SEC_CONTENT
given	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
x	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
n	SEC_CONTENT
}	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
correct	SEC_CONTENT
label	SEC_CONTENT
sequence	SEC_CONTENT
y	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
y	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
n	SEC_CONTENT
}	SEC_CONTENT
is	SEC_CONTENT
log	SEC_CONTENT
p(y|x	SEC_CONTENT
;	SEC_CONTENT
θ	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
n	SEC_CONTENT
t=1	SEC_CONTENT
log	SEC_CONTENT
p(y	SEC_CONTENT
t	SEC_CONTENT
|x	SEC_CONTENT
;	SEC_CONTENT
θ	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Our	SEC_START
model	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
label	SEC_CONTENT
y	SEC_CONTENT
t	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
ht	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
topmost	SEC_CONTENT
attention	SEC_CONTENT
sublayer	SEC_CONTENT
of	SEC_CONTENT
DEEPATT	SEC_CONTENT
:	SEC_CONTENT
p(y	SEC_CONTENT
t	SEC_CONTENT
|x	SEC_CONTENT
;	SEC_CONTENT
θ	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
p(y	SEC_CONTENT
t	SEC_CONTENT
|h	SEC_CONTENT
t	SEC_CONTENT
;	SEC_CONTENT
θ	SEC_CONTENT
)	SEC_END
=	SEC_START
softmax(W	SEC_CONTENT
oh	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
T	SEC_CONTENT
δ	SEC_CONTENT
yt	SEC_CONTENT
,	SEC_END
Where	SEC_START
W	SEC_CONTENT
o	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
matrix	SEC_CONTENT
and	SEC_CONTENT
δ	SEC_CONTENT
yt	SEC_CONTENT
is	SEC_CONTENT
Kronecker	SEC_CONTENT
delta	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
dimension	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
output	SEC_CONTENT
symbol	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
softmax(W	SEC_CONTENT
oh	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
T	SEC_CONTENT
δ	SEC_CONTENT
yt	SEC_CONTENT
is	SEC_CONTENT
exactly	SEC_CONTENT
they	SEC_CONTENT
t	SEC_CONTENT
'	SEC_CONTENT
th	SEC_CONTENT
element	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
distribution	SEC_CONTENT
defined	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
training	SEC_CONTENT
objective	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
maximize	SEC_CONTENT
the	SEC_CONTENT
log	SEC_CONTENT
probabilities	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
output	SEC_CONTENT
labels	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
We	SEC_START
report	SEC_CONTENT
our	SEC_CONTENT
empirical	SEC_CONTENT
studies	SEC_CONTENT
of	SEC_CONTENT
DEEPATT	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
commonly	SEC_CONTENT
used	SEC_CONTENT
datasets	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
Datasets	SECTITLE_END
The	SEC_START
CoNLL-2005	SEC_CONTENT
dataset	SEC_CONTENT
takes	SEC_CONTENT
section	SEC_CONTENT
2	SEC_CONTENT
-	SEC_CONTENT
21	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Wall	SEC_CONTENT
Street	SEC_CONTENT
Journal	SEC_CONTENT
(	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
corpus	SEC_CONTENT
as	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
section	SEC_CONTENT
24	SEC_CONTENT
as	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
section	SEC_CONTENT
23	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
corpus	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
3	SEC_CONTENT
sections	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Brown	SEC_CONTENT
corpus	SEC_CONTENT
(	SEC_CONTENT
Carreras	SEC_CONTENT
and	SEC_CONTENT
M	SEC_CONTENT
`	SEC_CONTENT
arquez	SEC_CONTENT
2005	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
dataset	SEC_CONTENT
is	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	dataset
OntoNotes	dataset
v5.0	dataset
corpus	dataset
.	SEC_CONTENT
The	SEC_CONTENT
description	SEC_CONTENT
and	SEC_CONTENT
separation	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
development	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
found	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Model	SECTITLE_START
Setup	SECTITLE_END
Initialization	SEC_START
We	SEC_CONTENT
initialize	SEC_CONTENT
the	SEC_CONTENT
weights	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
as	SEC_CONTENT
random	SEC_CONTENT
orthogonal	SEC_CONTENT
matrices	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
other	SEC_CONTENT
parameters	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
initialize	SEC_CONTENT
them	SEC_CONTENT
by	SEC_CONTENT
sampling	SEC_CONTENT
each	SEC_CONTENT
element	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
distribution	SEC_CONTENT
with	SEC_CONTENT
mean	SEC_CONTENT
0	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
1	SEC_CONTENT
√	SEC_CONTENT
d	SEC_END
.	SEC_START
The	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
initialized	SEC_CONTENT
randomly	SEC_CONTENT
or	SEC_CONTENT
using	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
will	SEC_CONTENT
discuss	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
analysis	SEC_CONTENT
subsection	SEC_CONTENT
.	SEC_CONTENT
Settings	SEC_CONTENT
and	SEC_CONTENT
Regularization	SEC_CONTENT
The	SEC_CONTENT
settings	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
described	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
dimension	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
predicate	SEC_CONTENT
mask	SEC_CONTENT
embeddings	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
100	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
10	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
d	SEC_CONTENT
to	SEC_CONTENT
200	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
heads	SEC_CONTENT
h	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
8	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
apply	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
prevent	SEC_CONTENT
the	SEC_CONTENT
networks	SEC_CONTENT
from	SEC_CONTENT
over	SEC_CONTENT
-	SEC_CONTENT
fitting	SEC_CONTENT
.	SEC_CONTENT
Dropout	SEC_CONTENT
layers	SEC_CONTENT
are	SEC_CONTENT
added	SEC_CONTENT
before	SEC_CONTENT
residual	SEC_CONTENT
connections	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
keep	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
0.8	SEC_CONTENT
.	SEC_CONTENT
Dropout	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
applied	SEC_CONTENT
before	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
froward	SEC_CONTENT
ReLU	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
keep	SEC_CONTENT
probabilities	SEC_CONTENT
are	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
0.9	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
employ	SEC_CONTENT
label	SEC_CONTENT
smoothing	SEC_CONTENT
technique	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
smoothing	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
0.1	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
Learning	SEC_START
Parameter	SEC_CONTENT
optimization	SEC_CONTENT
is	SEC_CONTENT
performed	SEC_CONTENT
using	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
adopt	SEC_CONTENT
Adadelta	SEC_CONTENT
(	SEC_CONTENT
Zeiler	SEC_CONTENT
2012	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
6	SEC_CONTENT
and	SEC_CONTENT
ρ	SEC_CONTENT
=	SEC_CONTENT
0.95	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
optimizer	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
avoid	SEC_CONTENT
exploding	SEC_CONTENT
gradients	SEC_CONTENT
problem	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
clip	SEC_CONTENT
the	SEC_CONTENT
norm	SEC_CONTENT
of	SEC_CONTENT
gradients	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
predefined	SEC_CONTENT
threshold	SEC_CONTENT
1.0	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
SGD	SEC_CONTENT
contains	SEC_CONTENT
a	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
of	SEC_CONTENT
approximately	SEC_CONTENT
4096	SEC_CONTENT
tokens	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
dataset	SEC_CONTENT
and	SEC_CONTENT
8192	SEC_CONTENT
tokens	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
is	SEC_CONTENT
initialized	SEC_CONTENT
to	SEC_CONTENT
1.0	SEC_CONTENT
.	SEC_CONTENT
After	SEC_CONTENT
training	SEC_CONTENT
400k	SEC_CONTENT
steps	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
halve	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
every	SEC_CONTENT
100	SEC_CONTENT
K	SEC_CONTENT
steps	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
all	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
600	SEC_CONTENT
K	SEC_CONTENT
steps	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
DEEP	SEC_CONTENT
-	SEC_CONTENT
ATT	SEC_CONTENT
with	SEC_CONTENT
FFN	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
training	SEC_CONTENT
stage	SEC_CONTENT
takes	SEC_CONTENT
about	SEC_CONTENT
two	SEC_CONTENT
days	SEC_CONTENT
to	SEC_CONTENT
finish	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
Titan	SEC_CONTENT
X	SEC_CONTENT
GPU	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
2.5	SEC_CONTENT
times	SEC_CONTENT
faster	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
approach	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
In	SEC_START
   	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
out	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
domain	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
system	SEC_CONTENT
by	SEC_CONTENT
2.0	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
single	SEC_CONTENT
model	SEC_CONTENT
of	SEC_CONTENT
FFN	SEC_CONTENT
variant	SEC_CONTENT
also	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
by	SEC_CONTENT
1.0	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
ensembling	SEC_CONTENT
5	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
FFN	SEC_CONTENT
nonlinear	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
achieves	SEC_CONTENT
an	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
of	SEC_CONTENT
84.6	SEC_CONTENT
and	SEC_CONTENT
83.9	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
datasets	SEC_CONTENT
respectively	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
has	SEC_CONTENT
an	SEC_CONTENT
absolute	SEC_CONTENT
improvement	SEC_CONTENT
of	SEC_CONTENT
1.4	SEC_CONTENT
and	SEC_CONTENT
0.5	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
consistent	SEC_CONTENT
with	SEC_CONTENT
our	SEC_CONTENT
intuition	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
layers	SEC_CONTENT
is	SEC_CONTENT
helpful	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
structural	SEC_CONTENT
information	SEC_CONTENT
and	SEC_CONTENT
long	SEC_CONTENT
distance	SEC_CONTENT
dependencies	SEC_CONTENT
.	SEC_END
Analysis	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
subsection	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
discuss	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
factors	SEC_CONTENT
that	SEC_CONTENT
influence	SEC_CONTENT
our	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
analyze	SEC_CONTENT
the	SEC_CONTENT
experimental	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
Model	SEC_START
Depth	SEC_CONTENT
Previous	SEC_CONTENT
works	SEC_CONTENT
(	SEC_CONTENT
Zhou	SEC_CONTENT
and	SEC_CONTENT
Xu	SEC_CONTENT
2015	SEC_CONTENT
;	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
model	SEC_CONTENT
depth	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
success	SEC_CONTENT
of	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
SRL	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
observations	SEC_CONTENT
also	SEC_CONTENT
coincide	SEC_CONTENT
with	SEC_CONTENT
previous	SEC_CONTENT
works	SEC_CONTENT
.	SEC_CONTENT
Rows	SEC_CONTENT
1	SEC_CONTENT
-	SEC_CONTENT
5	SEC_CONTENT
of	SEC_CONTENT
 	SEC_CONTENT
model	SEC_CONTENT
only	SEC_CONTENT
achieves	SEC_CONTENT
79.9	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
Increasing	SEC_CONTENT
depth	SEC_CONTENT
consistently	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
best	SEC_CONTENT
model	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
10	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
DEEPATT	SEC_CONTENT
with	SEC_CONTENT
12	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
observe	SEC_CONTENT
a	SEC_CONTENT
slightly	SEC_CONTENT
performance	SEC_CONTENT
drop	SEC_CONTENT
of	SEC_CONTENT
0.1	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
.	SEC_END
Model	SEC_START
Width	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
conduct	SEC_CONTENT
experiments	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
model	SEC_CONTENT
widths	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
increase	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
from	SEC_CONTENT
200	SEC_CONTENT
to	SEC_CONTENT
400	SEC_CONTENT
and	SEC_CONTENT
400	SEC_CONTENT
to	SEC_CONTENT
600	SEC_CONTENT
as	SEC_CONTENT
listed	SEC_CONTENT
in	SEC_CONTENT
rows	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
6	SEC_CONTENT
and	SEC_CONTENT
7	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
hidden	SEC_CONTENT
size	SEC_CONTENT
hf	SEC_CONTENT
of	SEC_CONTENT
FFN	SEC_CONTENT
sublayers	SEC_CONTENT
is	SEC_CONTENT
increased	SEC_CONTENT
to	SEC_CONTENT
1600	SEC_CONTENT
and	SEC_CONTENT
2400	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
IncreasDecoding	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
Speed	SEC_CONTENT
Argmax	SEC_CONTENT
Decoding	SEC_CONTENT
83.1	SEC_CONTENT
50	SEC_CONTENT
K	SEC_CONTENT
Constrained	SEC_CONTENT
Decoding	SEC_CONTENT
83.0	SEC_CONTENT
17	SEC_CONTENT
K	SEC_CONTENT
:	SEC_CONTENT
Comparison	SEC_CONTENT
between	SEC_CONTENT
argmax	SEC_CONTENT
decoding	SEC_CONTENT
and	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
ing	SEC_CONTENT
model	SEC_CONTENT
widths	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
slightly	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
600	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
achieves	SEC_CONTENT
an	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
of	SEC_CONTENT
83.4	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
parsing	SEC_CONTENT
speed	SEC_CONTENT
are	SEC_CONTENT
slower	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
result	SEC_CONTENT
of	SEC_CONTENT
larger	SEC_CONTENT
parameter	SEC_CONTENT
counts	SEC_CONTENT
.	SEC_END
Word	SEC_START
Embedding	SEC_CONTENT
Previous	SEC_CONTENT
works	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
improved	SEC_CONTENT
by	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
on	SEC_CONTENT
large	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
(;	SEC_CONTENT
Zhou	SEC_CONTENT
and	SEC_CONTENT
Xu	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
GloVe	SEC_CONTENT
(	SEC_CONTENT
Pennington	SEC_CONTENT
,	SEC_CONTENT
Socher	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Manning	SEC_CONTENT
2014	SEC_CONTENT
)	SEC_CONTENT
embeddings	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
Wikipedia	SEC_CONTENT
and	SEC_CONTENT
Gigaword	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
initialize	SEC_CONTENT
our	SEC_CONTENT
networks	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
fixed	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Rows	SEC_CONTENT
1	SEC_CONTENT
and	SEC_CONTENT
8	SEC_CONTENT
of	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
additional	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
using	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
GloVe	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
increases	SEC_CONTENT
from	SEC_CONTENT
79.6	SEC_CONTENT
to	SEC_CONTENT
83.1	SEC_CONTENT
.	SEC_END
Position	SEC_START
Encoding	SEC_CONTENT
From	SEC_CONTENT
rows	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
9	SEC_CONTENT
and	SEC_CONTENT
10	SEC_CONTENT
of	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
encoding	SEC_CONTENT
plays	SEC_CONTENT
an	SEC_CONTENT
important	SEC_CONTENT
role	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
success	SEC_CONTENT
of	SEC_CONTENT
DEEPATT	SEC_CONTENT
.	SEC_CONTENT
Without	SEC_CONTENT
position	SEC_CONTENT
encoding	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
DEEPATT	SEC_CONTENT
with	SEC_CONTENT
FFN	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
only	SEC_CONTENT
achieves	SEC_CONTENT
20.0	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
development	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
using	SEC_CONTENT
position	SEC_CONTENT
embedding	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
boosts	SEC_CONTENT
to	SEC_CONTENT
79.4	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
timing	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
surprisingly	SEC_CONTENT
effective	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
embedding	SEC_CONTENT
approach	SEC_CONTENT
by	SEC_CONTENT
3.7	SEC_CONTENT
F	SEC_CONTENT
1	SEC_CONTENT
score	SEC_CONTENT
.	SEC_END
Nonlinear	SEC_START
Sub	SEC_CONTENT
-	SEC_CONTENT
Layers	SEC_CONTENT
DEEPATT	SEC_CONTENT
requires	SEC_CONTENT
nonlinear	SEC_CONTENT
sublayers	SEC_CONTENT
to	SEC_CONTENT
enhance	SEC_CONTENT
its	SEC_CONTENT
expressive	SEC_CONTENT
power	SEC_CONTENT
.	SEC_CONTENT
Row	SEC_CONTENT
11	SEC_CONTENT
of	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
DEEPATT	SEC_CONTENT
without	SEC_CONTENT
nonlinear	SEC_CONTENT
sublayers	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
10	SEC_CONTENT
layered	SEC_CONTENT
DEEP	SEC_CONTENT
-	SEC_CONTENT
ATT	SEC_CONTENT
without	SEC_CONTENT
nonlinear	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
only	SEC_CONTENT
matches	SEC_CONTENT
the	SEC_CONTENT
4	SEC_CONTENT
layered	SEC_CONTENT
DEEPATT	SEC_CONTENT
with	SEC_CONTENT
FFN	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
nonlinear	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
essential	SEC_CONTENT
components	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
attentional	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
effects	SEC_CONTENT
of	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
DEEPATT	SEC_CONTENT
with	SEC_CONTENT
FFN	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
observe	SEC_CONTENT
a	SEC_CONTENT
slightly	SEC_CONTENT
performance	SEC_CONTENT
drop	SEC_CONTENT
when	SEC_CONTENT
using	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
adding	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
slowdown	SEC_CONTENT
the	SEC_CONTENT
decoding	SEC_CONTENT
speed	SEC_CONTENT
significantly	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
DEEPATT	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
powerful	SEC_CONTENT
enough	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
relationships	SEC_CONTENT
among	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_END
Constrained	SECTITLE_START
Decoding	SECTITLE_END
Detailed	SEC_START
Scores	SEC_CONTENT
We	SEC_CONTENT
list	SEC_CONTENT
the	SEC_CONTENT
detailed	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
frequent	SEC_CONTENT
labels	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
stateof	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
also	SEC_CONTENT
shown	SEC_CONTENT
for	SEC_CONTENT
comparison	SEC_CONTENT
.	SEC_CONTENT
Compared	SEC_CONTENT
with	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
shows	SEC_CONTENT
improvement	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
labels	SEC_CONTENT
except	SEC_CONTENT
AM	SEC_CONTENT
-	SEC_CONTENT
PNC	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
He	SEC_CONTENT
's	SEC_CONTENT
model	SEC_CONTENT
performs	SEC_CONTENT
better	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
identifying	SEC_CONTENT
and	SEC_CONTENT
classifying	SEC_CONTENT
semantic	task
roles	task
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
identifying	SEC_CONTENT
correct	SEC_CONTENT
spans	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
   	SEC_CONTENT
Labeling	SEC_CONTENT
Confusion	SEC_CONTENT
shows	SEC_CONTENT
a	SEC_CONTENT
confusion	SEC_CONTENT
matrix	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
the	task
most	task
frequent	task
labels	task
.	SEC_CONTENT
We	SEC_CONTENT
only	SEC_CONTENT
consider	SEC_CONTENT
predicted	SEC_CONTENT
arguments	SEC_CONTENT
that	SEC_CONTENT
match	SEC_CONTENT
gold	SEC_CONTENT
span	SEC_CONTENT
boundaries	SEC_CONTENT
.	SEC_CONTENT
Compared	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
still	SEC_CONTENT
confuses	SEC_CONTENT
ARG2	SEC_CONTENT
with	SEC_CONTENT
AM	SEC_CONTENT
-	SEC_CONTENT
DIR	SEC_CONTENT
,	SEC_CONTENT
AM	SEC_CONTENT
-	SEC_CONTENT
LOC	SEC_CONTENT
and	SEC_CONTENT
AM	SEC_CONTENT
-	SEC_CONTENT
MNR	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
lesser	SEC_CONTENT
extent	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
indicates	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
some	SEC_CONTENT
advantages	SEC_CONTENT
on	SEC_CONTENT
such	SEC_CONTENT
difficult	SEC_CONTENT
adjunct	SEC_CONTENT
distinction	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
work	SECTITLE_END
SRL	SEC_START
Gildea	SEC_CONTENT
and	SEC_CONTENT
Jurafsky	SEC_CONTENT
(	SEC_CONTENT
2002	SEC_CONTENT
)	SEC_CONTENT
developed	SEC_CONTENT
the	task
first	task
automatic	task
semantic	task
role	task
labeling	task
system	task
based	SEC_CONTENT
on	SEC_CONTENT
FrameNet	SEC_CONTENT
.	SEC_END
Since	SEC_START
then	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
has	SEC_CONTENT
received	SEC_CONTENT
a	SEC_CONTENT
tremendous	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
attention	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
focus	SEC_CONTENT
of	SEC_CONTENT
traditional	SEC_CONTENT
approaches	SEC_CONTENT
is	SEC_CONTENT
devising	SEC_CONTENT
appropriate	SEC_CONTENT
feature	SEC_CONTENT
templates	SEC_CONTENT
to	SEC_CONTENT
describe	SEC_CONTENT
the	SEC_CONTENT
latent	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
utterances	SEC_CONTENT
.	SEC_CONTENT
;	SEC_CONTENT
explored	SEC_CONTENT
the	SEC_CONTENT
syntactic	SEC_CONTENT
features	SEC_CONTENT
for	SEC_CONTENT
capturing	SEC_CONTENT
the	SEC_CONTENT
overall	SEC_CONTENT
sentence	SEC_CONTENT
structure	SEC_CONTENT
.	SEC_CONTENT
Combination	SEC_CONTENT
of	SEC_CONTENT
different	SEC_CONTENT
syntactic	SEC_CONTENT
parsers	SEC_CONTENT
was	SEC_CONTENT
also	SEC_CONTENT
proposed	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
prediction	SEC_CONTENT
risk	SEC_CONTENT
which	SEC_CONTENT
was	SEC_CONTENT
introduced	SEC_CONTENT
by	SEC_CONTENT
;	SEC_CONTENT
;	SEC_CONTENT
.	SEC_CONTENT
Beyond	SEC_CONTENT
these	SEC_CONTENT
traditional	SEC_CONTENT
methods	SEC_CONTENT
above	SEC_CONTENT
,	SEC_CONTENT
proposed	SEC_CONTENT
a	SEC_CONTENT
convolutional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
for	SEC_CONTENT
SRL	SEC_CONTENT
to	SEC_CONTENT
reduce	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
pioneering	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
building	SEC_CONTENT
an	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
system	SEC_CONTENT
was	SEC_CONTENT
proposed	SEC_CONTENT
by	SEC_CONTENT
,	SEC_CONTENT
who	SEC_CONTENT
applied	SEC_CONTENT
an	SEC_CONTENT
8	SEC_CONTENT
layered	SEC_CONTENT
LSTM	SEC_CONTENT
model	SEC_CONTENT
which	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
system	SEC_CONTENT
.	SEC_CONTENT
improved	SEC_CONTENT
further	SEC_CONTENT
with	SEC_CONTENT
highway	SEC_CONTENT
LSTMs	SEC_CONTENT
and	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
used	SEC_CONTENT
simplified	SEC_CONTENT
input	SEC_CONTENT
and	SEC_CONTENT
output	SEC_CONTENT
layers	SEC_CONTENT
compared	SEC_CONTENT
with	SEC_CONTENT
.	SEC_CONTENT
Marcheggiani	SEC_CONTENT
,	SEC_CONTENT
Frolov	SEC_CONTENT
,	SEC_CONTENT
Titov	SEC_CONTENT
(	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
also	SEC_CONTENT
proposed	SEC_CONTENT
a	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
based	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Without	SEC_CONTENT
using	SEC_CONTENT
any	SEC_CONTENT
syntactic	SEC_CONTENT
information	SEC_CONTENT
,	SEC_CONTENT
their	SEC_CONTENT
approach	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
result	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2009	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
Our	SEC_START
method	SEC_CONTENT
differs	SEC_CONTENT
from	SEC_CONTENT
them	SEC_CONTENT
significantly	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
choose	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
component	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
architecture	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
LSTMs	SEC_CONTENT
.	SEC_CONTENT
Like	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
system	SEC_CONTENT
take	SEC_CONTENT
the	SEC_CONTENT
very	SEC_CONTENT
original	SEC_CONTENT
utterances	SEC_CONTENT
and	SEC_CONTENT
predicate	SEC_CONTENT
masks	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
without	SEC_CONTENT
context	SEC_CONTENT
windows	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
the	SEC_CONTENT
inference	SEC_CONTENT
stage	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
argmax	SEC_CONTENT
decoding	SEC_CONTENT
approach	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
logistic	SEC_CONTENT
regression	SEC_CONTENT
while	SEC_CONTENT
Zhou	SEC_CONTENT
and	SEC_CONTENT
Xu	SEC_CONTENT
(	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
chose	SEC_CONTENT
a	SEC_CONTENT
CRF	SEC_CONTENT
approach	SEC_CONTENT
and	SEC_CONTENT
chose	SEC_CONTENT
constrained	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
simpler	SEC_CONTENT
and	SEC_CONTENT
faster	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_END
Self	SEC_START
-	task
Attention	task
Self	task
-	task
attention	task
have	SEC_CONTENT
been	SEC_CONTENT
successfully	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
several	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
used	SEC_CONTENT
LSTMs	SEC_CONTENT
and	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
facilitate	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
machine	task
reading	task
.	SEC_CONTENT
utilized	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
.	SEC_CONTENT
proposed	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attentive	SEC_CONTENT
sentence	SEC_CONTENT
embedding	SEC_CONTENT
and	SEC_CONTENT
applied	SEC_CONTENT
them	SEC_CONTENT
to	SEC_CONTENT
author	SEC_CONTENT
profiling	SEC_CONTENT
,	SEC_CONTENT
sentiment	SEC_CONTENT
analysis	SEC_CONTENT
and	SEC_CONTENT
textual	SEC_CONTENT
entailment	SEC_CONTENT
.	SEC_CONTENT
combined	SEC_CONTENT
reinforcement	SEC_CONTENT
learning	SEC_CONTENT
and	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
long	SEC_CONTENT
distance	SEC_CONTENT
dependencies	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
abstractive	SEC_CONTENT
summarization	SEC_CONTENT
.	SEC_CONTENT
applied	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
neural	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
Very	SEC_CONTENT
recently	SEC_CONTENT
,	SEC_CONTENT
applied	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
various	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
work	SEC_CONTENT
follows	SEC_CONTENT
this	SEC_CONTENT
line	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
for	SEC_CONTENT
learning	SEC_CONTENT
long	SEC_CONTENT
distance	SEC_CONTENT
dependencies	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
experiments	SEC_CONTENT
also	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
on	SEC_CONTENT
the	task
sequence	task
labeling	task
task	task
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
proposed	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
attentional	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
semantic	task
role	task
labeling	task
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
our	SEC_CONTENT
SRL	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
depth	SEC_CONTENT
of	SEC_CONTENT
10	SEC_CONTENT
and	SEC_CONTENT
evaluated	SEC_CONTENT
them	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2005	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
dataset	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
CoNLL-2012	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
experimental	SEC_CONTENT
results	SEC_CONTENT
indicate	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
substantially	SEC_CONTENT
improve	SEC_CONTENT
SRL	SEC_CONTENT
performances	SEC_CONTENT
,	SEC_CONTENT
leading	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
new	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
theart	SEC_CONTENT
.	SEC_END
