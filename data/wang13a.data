title	SECTITLE_END
Fast	SEC_START
dropout	SEC_CONTENT
training	SEC_END
abstract	SECTITLE_END
Preventing	SEC_START
feature	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
adaptation	SEC_CONTENT
by	SEC_CONTENT
encouraging	SEC_CONTENT
independent	SEC_CONTENT
contributions	SEC_CONTENT
from	SEC_CONTENT
different	SEC_CONTENT
features	SEC_CONTENT
often	SEC_CONTENT
improves	SEC_CONTENT
classification	SEC_CONTENT
and	SEC_CONTENT
regression	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
Dropout	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
Hinton	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2012	SEC_CONTENT
)	SEC_CONTENT
does	SEC_CONTENT
this	SEC_CONTENT
by	SEC_CONTENT
randomly	SEC_CONTENT
dropping	SEC_CONTENT
out	SEC_CONTENT
(	SEC_CONTENT
zeroing	SEC_CONTENT
)	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
and	SEC_CONTENT
input	SEC_CONTENT
features	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
repeatedly	SEC_CONTENT
sampling	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
features	SEC_CONTENT
makes	SEC_CONTENT
training	SEC_CONTENT
much	SEC_CONTENT
slower	SEC_CONTENT
.	SEC_CONTENT
Based	SEC_CONTENT
on	SEC_CONTENT
an	SEC_CONTENT
examination	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
implied	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
do	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
by	SEC_CONTENT
sampling	SEC_CONTENT
from	SEC_CONTENT
or	SEC_CONTENT
integrating	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
approximation	SEC_CONTENT
,	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
doing	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
optimization	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
objective	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
approximation	SEC_CONTENT
,	SEC_CONTENT
justified	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
central	SEC_CONTENT
limit	SEC_CONTENT
theorem	SEC_CONTENT
and	SEC_CONTENT
empirical	SEC_CONTENT
evidence	SEC_CONTENT
,	SEC_CONTENT
gives	SEC_CONTENT
an	SEC_CONTENT
order	SEC_CONTENT
of	SEC_CONTENT
magnitude	SEC_CONTENT
speedup	SEC_CONTENT
and	SEC_CONTENT
more	SEC_CONTENT
stability	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
show	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
do	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
classification	SEC_CONTENT
,	SEC_CONTENT
regression	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
multilayer	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_CONTENT
Beyond	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
technique	SEC_CONTENT
is	SEC_CONTENT
extended	SEC_CONTENT
to	SEC_CONTENT
integrate	SEC_CONTENT
out	SEC_CONTENT
other	SEC_CONTENT
types	SEC_CONTENT
of	SEC_CONTENT
noise	SEC_CONTENT
and	SEC_CONTENT
small	SEC_CONTENT
image	SEC_CONTENT
transformations	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Recent	SEC_START
work	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
preventing	SEC_CONTENT
feature	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
adaptation	SEC_CONTENT
by	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
promising	SEC_CONTENT
method	SEC_CONTENT
for	SEC_CONTENT
regularization	SEC_CONTENT
.	SEC_CONTENT
Applied	SEC_CONTENT
to	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
idea	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
zero	SEC_CONTENT
)	SEC_CONTENT
randomly	SEC_CONTENT
sampled	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
and	SEC_CONTENT
input	SEC_CONTENT
features	SEC_CONTENT
during	SEC_CONTENT
each	SEC_CONTENT
iteration	SEC_CONTENT
of	SEC_CONTENT
optimization	SEC_CONTENT
.	SEC_CONTENT
Dropout	SEC_CONTENT
played	SEC_CONTENT
an	SEC_CONTENT
important	SEC_CONTENT
role	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
systems	SEC_CONTENT
that	SEC_CONTENT
won	SEC_CONTENT
recent	SEC_CONTENT
learning	SEC_CONTENT
competitions	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
ImageNet	SEC_CONTENT
classification	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
Merck	SEC_CONTENT
molecular	SEC_CONTENT
activity	SEC_CONTENT
challenge	SEC_CONTENT
at	SEC_CONTENT
www.kaggle.com	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
improves	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
various	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Dropout	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
considered	SEC_CONTENT
another	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
regularization	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
widely	SEC_CONTENT
used	SEC_CONTENT
parameter	SEC_CONTENT
shrinkage	SEC_CONTENT
methods	SEC_CONTENT
and	SEC_CONTENT
model	SEC_CONTENT
averaging	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
process	SEC_CONTENT
lowers	SEC_CONTENT
the	SEC_CONTENT
trust	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
feature	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
helpful	SEC_CONTENT
when	SEC_CONTENT
other	SEC_CONTENT
specific	SEC_CONTENT
features	SEC_CONTENT
are	SEC_CONTENT
present	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
any	SEC_CONTENT
particular	SEC_CONTENT
feature	SEC_CONTENT
maybe	SEC_CONTENT
dropped	SEC_CONTENT
out	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
depended	SEC_CONTENT
on	SEC_CONTENT
.	SEC_CONTENT
Alternatively	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
procedure	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
averaging	SEC_CONTENT
over	SEC_CONTENT
many	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
with	SEC_CONTENT
shared	SEC_CONTENT
weights	SEC_CONTENT
.	SEC_END
Other	SEC_START
observations	SEC_CONTENT
of	SEC_CONTENT
harmful	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
adaptation	SEC_CONTENT
and	SEC_CONTENT
ways	SEC_CONTENT
to	SEC_CONTENT
address	SEC_CONTENT
them	SEC_CONTENT
exist	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
.	SEC_CONTENT
Naive	SEC_CONTENT
Bayes	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
completely	SEC_CONTENT
ignoring	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
adaptation	SEC_CONTENT
,	SEC_CONTENT
performs	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
discriminative	SEC_CONTENT
methods	SEC_CONTENT
when	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
little	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
continues	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
better	SEC_CONTENT
on	SEC_CONTENT
certain	SEC_CONTENT
relatively	SEC_CONTENT
large	SEC_CONTENT
datasets	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
observed	SEC_CONTENT
that	SEC_CONTENT
training	SEC_CONTENT
involves	SEC_CONTENT
trade	SEC_CONTENT
-	SEC_CONTENT
offs	SEC_CONTENT
among	SEC_CONTENT
weights	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
presence	SEC_CONTENT
of	SEC_CONTENT
highly	SEC_CONTENT
indicative	SEC_CONTENT
features	SEC_CONTENT
can	SEC_CONTENT
cause	SEC_CONTENT
other	SEC_CONTENT
useful	SEC_CONTENT
but	SEC_CONTENT
weaker	SEC_CONTENT
features	SEC_CONTENT
to	SEC_CONTENT
undertrain	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
propose	SEC_CONTENT
feature	SEC_CONTENT
bagging	SEC_CONTENT
:	SEC_CONTENT
training	SEC_CONTENT
different	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
subsets	dataset
of	SEC_CONTENT
features	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
later	SEC_CONTENT
combined	SEC_CONTENT
,	SEC_CONTENT
an	SEC_CONTENT
idea	SEC_CONTENT
further	SEC_CONTENT
pursued	SEC_CONTENT
under	SEC_CONTENT
the	SEC_CONTENT
name	SEC_CONTENT
logarithmic	SEC_CONTENT
opinion	SEC_CONTENT
pools	SEC_CONTENT
by	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Improved	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
Named	SEC_CONTENT
Entity	SEC_CONTENT
Recognition	SEC_CONTENT
and	SEC_CONTENT
Part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
Speech	SEC_CONTENT
Tagging	SEC_CONTENT
was	SEC_CONTENT
demonstrated	SEC_CONTENT
.	SEC_END
While	SEC_START
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
methods	SEC_CONTENT
in	SEC_CONTENT
preventing	SEC_CONTENT
feature	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
adaptation	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
demonstrated	SEC_CONTENT
,	SEC_CONTENT
actually	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
training	SEC_CONTENT
multiple	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
make	SEC_CONTENT
training	SEC_CONTENT
slower	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
dropout	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
p	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
proportion	SEC_CONTENT
of	SEC_CONTENT
data	SEC_CONTENT
still	SEC_CONTENT
not	SEC_CONTENT
seen	SEC_CONTENT
after	SEC_CONTENT
n	SEC_CONTENT
passes	SEC_CONTENT
is	SEC_CONTENT
p	SEC_CONTENT
n	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
5	SEC_CONTENT
passes	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
are	SEC_CONTENT
required	SEC_CONTENT
to	SEC_CONTENT
see	SEC_CONTENT
95	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
it	SEC_CONTENT
at	SEC_CONTENT
p	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
If	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
highly	SEC_CONTENT
redundant	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
relevant	SEC_CONTENT
data	SEC_CONTENT
only	SEC_CONTENT
partially	SEC_CONTENT
observable	SEC_CONTENT
at	SEC_CONTENT
random	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
becomes	SEC_CONTENT
even	SEC_CONTENT
harder	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
training	SEC_CONTENT
efficiency	SEC_CONTENT
may	SEC_CONTENT
reduce	SEC_CONTENT
further	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
look	SEC_CONTENT
at	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
the	SEC_CONTENT
benefit	SEC_CONTENT
of	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
without	SEC_CONTENT
actually	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
thereby	SEC_CONTENT
using	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
efficiently	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
approach	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
approximation	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
justified	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
central	SEC_CONTENT
limit	SEC_CONTENT
theorem	SEC_CONTENT
and	SEC_CONTENT
empirical	SEC_CONTENT
evidence	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
validity	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
approximation	SEC_CONTENT
and	SEC_CONTENT
how	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
provide	SEC_CONTENT
an	SEC_CONTENT
order	SEC_CONTENT
of	SEC_CONTENT
magnitude	SEC_CONTENT
speed	SEC_CONTENT
-	SEC_CONTENT
up	SEC_CONTENT
at	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
also	SEC_CONTENT
giving	SEC_CONTENT
more	SEC_CONTENT
stability	SEC_CONTENT
.	SEC_CONTENT
Fast	SEC_CONTENT
dropout	SEC_CONTENT
fits	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
general	SEC_CONTENT
framework	SEC_CONTENT
of	SEC_CONTENT
integrating	SEC_CONTENT
out	SEC_CONTENT
noise	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
See	SEC_CONTENT
(	SEC_CONTENT
van	SEC_CONTENT
der	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
alternative	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
integrating	SEC_CONTENT
out	SEC_CONTENT
noise	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
survey	SEC_CONTENT
of	SEC_CONTENT
related	SEC_CONTENT
work	SEC_CONTENT
from	SEC_CONTENT
that	SEC_CONTENT
angle	SEC_CONTENT
.	SEC_CONTENT
Their	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
exact	SEC_CONTENT
for	SEC_CONTENT
loss	SEC_CONTENT
functions	SEC_CONTENT
decomposable	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
moment	SEC_CONTENT
generating	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
independent	SEC_CONTENT
noise	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
exponential	SEC_CONTENT
loss	SEC_CONTENT
and	SEC_CONTENT
squared	SEC_CONTENT
error	SEC_CONTENT
loss	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
approach	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
require	SEC_CONTENT
independence	SEC_CONTENT
:	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
integrate	SEC_CONTENT
out	SEC_CONTENT
small	SEC_CONTENT
transformations	SEC_CONTENT
that	SEC_CONTENT
an	SEC_CONTENT
image	SEC_CONTENT
classifier	SEC_CONTENT
should	SEC_CONTENT
be	SEC_CONTENT
invariant	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
begin	SEC_CONTENT
with	SEC_CONTENT
logistic	SEC_CONTENT
regression	SEC_CONTENT
for	SEC_CONTENT
simplicity	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
extend	SEC_CONTENT
the	SEC_CONTENT
idea	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
loss	SEC_CONTENT
functions	SEC_CONTENT
,	SEC_CONTENT
other	SEC_CONTENT
noise	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_CONTENT
Code	SEC_CONTENT
is	SEC_CONTENT
provided	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
author	SEC_CONTENT
's	SEC_CONTENT
website	SEC_CONTENT
.	SEC_END
Fast	SECTITLE_START
approximations	SECTITLE_CONTENT
to	SECTITLE_CONTENT
dropout	SECTITLE_END
The	SECTITLE_START
implied	SECTITLE_CONTENT
objective	SECTITLE_CONTENT
function	SECTITLE_END
We	SEC_START
illustrate	SEC_CONTENT
the	SEC_CONTENT
idea	SEC_CONTENT
with	SEC_CONTENT
logistic	SEC_CONTENT
regression	SEC_CONTENT
(	SEC_CONTENT
LR	SEC_CONTENT
)	SEC_CONTENT
given	SEC_CONTENT
training	SEC_CONTENT
vector	SEC_CONTENT
x	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
label	SEC_CONTENT
y	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
train	SEC_CONTENT
LR	SEC_CONTENT
with	SEC_CONTENT
dropout	SEC_CONTENT
on	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
dimension	SEC_CONTENT
m	SEC_CONTENT
,	SEC_CONTENT
first	SEC_CONTENT
sample	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
∼	SEC_CONTENT
Bernoulli(p	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
...	SEC_CONTENT
m	SEC_CONTENT
.	SEC_CONTENT
Here	SEC_CONTENT
pi	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
not	SEC_CONTENT
dropping	SEC_CONTENT
out	SEC_CONTENT
input	SEC_CONTENT
xi	SEC_CONTENT
.	SEC_CONTENT
After	SEC_CONTENT
sampling	SEC_CONTENT
z	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
}	SEC_CONTENT
i=1	SEC_CONTENT
...	SEC_CONTENT
m	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
(	SEC_CONTENT
sgd	SEC_CONTENT
)	SEC_CONTENT
update	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
where	SEC_START
D	SEC_CONTENT
z	SEC_CONTENT
=	SEC_CONTENT
diag(z	SEC_CONTENT
)	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
m×m	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
σ(x	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
1/(1	SEC_CONTENT
+	SEC_CONTENT
e	SEC_CONTENT
−x	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
logistic	SEC_CONTENT
function	SEC_CONTENT
.	SEC_END
This	SEC_START
update	SEC_CONTENT
rule	SEC_CONTENT
,	SEC_CONTENT
applied	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
for	SEC_CONTENT
multiple	SEC_CONTENT
passes	SEC_CONTENT
,	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
Monte	SEC_CONTENT
Carlo	SEC_CONTENT
approximation	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
gradient	SEC_CONTENT
:	SEC_END
The	SEC_START
objective	SEC_CONTENT
function	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
gradient	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
expected	SEC_CONTENT
conditional	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
dropped	SEC_CONTENT
out	SEC_CONTENT
dimensions	SEC_CONTENT
indicated	SEC_CONTENT
by	SEC_CONTENT
z	SEC_CONTENT
,	SEC_END
.	SEC_START
This	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
implied	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
for	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
:	SEC_END
Since	SEC_START
we	SEC_CONTENT
are	SEC_CONTENT
just	SEC_CONTENT
taking	SEC_CONTENT
an	SEC_CONTENT
expectation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
still	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
convex	SEC_CONTENT
optimization	SEC_CONTENT
problem	SEC_CONTENT
provided	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
is	SEC_CONTENT
convex	SEC_CONTENT
.	SEC_END
Evaluating	SEC_START
the	SEC_CONTENT
expectation	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
naively	SEC_CONTENT
by	SEC_CONTENT
summing	SEC_CONTENT
overall	SEC_CONTENT
possible	SEC_CONTENT
z	SEC_CONTENT
has	SEC_CONTENT
complexity	SEC_CONTENT
O(2	SEC_CONTENT
m	SEC_CONTENT
m	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Rather	SEC_CONTENT
than	SEC_CONTENT
directly	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
z	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
transformation	SEC_CONTENT
that	SEC_CONTENT
allows	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
approximately	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
random	SEC_CONTENT
variable	SEC_CONTENT
Y	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
,	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
z	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
}	SEC_CONTENT
m	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
subsection	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
describe	SEC_CONTENT
an	SEC_CONTENT
efficient	SEC_CONTENT
O(m	SEC_CONTENT
)	SEC_CONTENT
approximation	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
accurate	SEC_CONTENT
for	SEC_CONTENT
machine	SEC_CONTENT
learning	SEC_CONTENT
applications	SEC_CONTENT
where	SEC_CONTENT
w	SEC_CONTENT
ix	SEC_CONTENT
i	SEC_CONTENT
usually	SEC_CONTENT
come	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
unimodal	SEC_CONTENT
or	SEC_CONTENT
bounded	SEC_CONTENT
distribution	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
z	SEC_CONTENT
is	SEC_CONTENT
repeatedly	SEC_CONTENT
sampled	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
resulting	SEC_CONTENT
inputs	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
unit	SEC_CONTENT
are	SEC_CONTENT
close	SEC_CONTENT
to	SEC_CONTENT
being	SEC_CONTENT
normally	SEC_CONTENT
distributed	SEC_CONTENT
.	SEC_END
We	SEC_START
make	SEC_CONTENT
the	SEC_CONTENT
observation	SEC_CONTENT
that	SEC_CONTENT
evaluating	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
L(w	SEC_CONTENT
)	SEC_CONTENT
involves	SEC_CONTENT
taking	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
variable	SEC_CONTENT
Y	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
w	SEC_CONTENT
TD	SEC_CONTENT
z	SEC_CONTENT
x	SEC_CONTENT
=	SEC_CONTENT
mi	SEC_CONTENT
w	SEC_CONTENT
ix	SEC_CONTENT
i	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
weighted	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
Bernoulli	SEC_CONTENT
random	SEC_CONTENT
variables	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
most	SEC_CONTENT
machine	SEC_CONTENT
learning	SEC_CONTENT
problems	SEC_CONTENT
,	SEC_CONTENT
{	SEC_CONTENT
w	SEC_CONTENT
i	SEC_CONTENT
}	SEC_CONTENT
typically	SEC_CONTENT
forms	SEC_CONTENT
a	SEC_CONTENT
unimodal	SEC_CONTENT
distribution	SEC_CONTENT
centered	SEC_CONTENT
at	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
{	SEC_CONTENT
x	SEC_CONTENT
i	SEC_CONTENT
}	SEC_CONTENT
is	SEC_CONTENT
either	SEC_CONTENT
unimodal	SEC_CONTENT
or	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
interval	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
Y	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
well	SEC_CONTENT
approximated	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
normal	SEC_CONTENT
distribution	SEC_CONTENT
even	SEC_CONTENT
for	SEC_CONTENT
relatively	SEC_CONTENT
low	SEC_CONTENT
dimensional	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
m	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
technically	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
Lyapunov	SEC_CONTENT
condition	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
satisfied	SEC_CONTENT
fora	SEC_CONTENT
weighted	SEC_CONTENT
sum	dataset
of	SEC_CONTENT
Bernoulli	SEC_CONTENT
random	SEC_CONTENT
variables	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
form	SEC_CONTENT
Y	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
weighted	SEC_CONTENT
by	SEC_CONTENT
real	SEC_CONTENT
data	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
Lyapunov	SEC_CONTENT
's	SEC_CONTENT
central	SEC_CONTENT
limit	SEC_CONTENT
theorem	SEC_CONTENT
states	SEC_CONTENT
that	SEC_CONTENT
Y	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
)	SEC_CONTENT
tends	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
normal	SEC_CONTENT
distribution	SEC_CONTENT
as	SEC_CONTENT
m	SEC_CONTENT
→	SEC_CONTENT
∞	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
empirically	SEC_CONTENT
verify	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
approximation	SEC_CONTENT
is	SEC_CONTENT
good	SEC_CONTENT
for	SEC_CONTENT
typical	SEC_CONTENT
datasets	SEC_CONTENT
of	SEC_CONTENT
moderate	SEC_CONTENT
dimensions	SEC_CONTENT
,	SEC_CONTENT
except	SEC_CONTENT
when	SEC_CONTENT
a	SEC_CONTENT
couple	SEC_CONTENT
of	SEC_CONTENT
dimensions	SEC_CONTENT
dominate	SEC_CONTENT
all	SEC_CONTENT
others	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
let	SEC_CONTENT
S	SEC_CONTENT
be	SEC_CONTENT
the	SEC_END
where	SEC_START
In	SEC_START
the	SEC_CONTENT
following	SEC_CONTENT
subsections	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
assumption	SEC_CONTENT
above	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
several	SEC_CONTENT
approximations	SEC_CONTENT
at	SEC_CONTENT
different	SEC_CONTENT
tradeoff	SEC_CONTENT
points	SEC_CONTENT
between	SEC_CONTENT
speed	SEC_CONTENT
and	SEC_CONTENT
accuracy	metric
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
experimental	task
results	task
showing	SEC_CONTENT
that	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
little	SEC_CONTENT
to	SEC_CONTENT
no	SEC_CONTENT
performance	SEC_CONTENT
loss	SEC_CONTENT
when	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
faster	SEC_CONTENT
,	SEC_CONTENT
less	SEC_CONTENT
accurate	SEC_CONTENT
approximations	SEC_CONTENT
.	SEC_END
Gradient	SECTITLE_START
computation	SECTITLE_CONTENT
by	SECTITLE_CONTENT
sampling	SECTITLE_CONTENT
from	SECTITLE_CONTENT
the	SECTITLE_CONTENT
Gaussian	SECTITLE_END
Given	SEC_START
good	SEC_CONTENT
convergence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
drawing	SEC_CONTENT
samples	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
approximating	SEC_CONTENT
Gaussian	SEC_CONTENT
S	SEC_CONTENT
of	SEC_CONTENT
Y	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
constant	SEC_CONTENT
time	SEC_CONTENT
operation	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
cheaper	SEC_CONTENT
than	SEC_CONTENT
drawing	SEC_CONTENT
samples	SEC_CONTENT
of	SEC_CONTENT
Y	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
)	SEC_CONTENT
directly	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
takes	SEC_CONTENT
O(m	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
effect	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
significant	SEC_CONTENT
for	SEC_CONTENT
high	SEC_CONTENT
dimensional	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_CONTENT
So	SEC_CONTENT
without	SEC_CONTENT
doing	SEC_CONTENT
much	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
already	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
m	SEC_CONTENT
times	SEC_CONTENT
faster	SEC_CONTENT
by	SEC_CONTENT
sampling	SEC_CONTENT
from	SEC_CONTENT
S	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
Y	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Empirically	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
approximation	SEC_CONTENT
is	SEC_CONTENT
within	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
direct	SEC_CONTENT
MC	SEC_CONTENT
approximation	SEC_CONTENT
of	SEC_CONTENT
by	SEC_CONTENT
taking	SEC_CONTENT
200	SEC_CONTENT
samples	SEC_CONTENT
of	SEC_CONTENT
z.	SEC_END
Approximating	SEC_START
the	SEC_CONTENT
gradient	SEC_CONTENT
introduces	SEC_CONTENT
a	SEC_CONTENT
complication	SEC_CONTENT
when	SEC_CONTENT
using	SEC_CONTENT
samples	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
gradient	SEC_END
]	SEC_START
works	SEC_CONTENT
poorly	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
both	SEC_CONTENT
approximation	SEC_CONTENT
error	SEC_CONTENT
and	SEC_CONTENT
final	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
g(z	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
linear	SEC_CONTENT
function	SEC_CONTENT
and	SEC_CONTENT
therefore	SEC_END
A	SEC_START
good	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
approximate	SEC_CONTENT
(	SEC_CONTENT
4	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
by	SEC_CONTENT
analytically	SEC_CONTENT
taking	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
linear	SEC_CONTENT
approximation	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
conditional	SEC_CONTENT
expectation	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
precisely	SEC_CONTENT
,	SEC_CONTENT
consider	SEC_CONTENT
dimension	SEC_CONTENT
i	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
:	SEC_END
where	SEC_START
z	SEC_CONTENT
−i	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
other	SEC_CONTENT
zs	SEC_CONTENT
except	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
,	SEC_END
i	SEC_START
w	SEC_CONTENT
2	SEC_CONTENT
i	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
changes	SEC_CONTENT
in	SEC_CONTENT
µ	SEC_CONTENT
S	SEC_CONTENT
,	SEC_CONTENT
σ	SEC_CONTENT
2	SEC_CONTENT
S	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
conditioning	SEC_CONTENT
on	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
partial	SEC_CONTENT
derivatives	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
E	SEC_CONTENT
S∼N	SEC_CONTENT
(	SEC_CONTENT
µ	SEC_CONTENT
S	SEC_CONTENT
,	SEC_CONTENT
σ	SEC_CONTENT
2	SEC_CONTENT
S	SEC_CONTENT
)	SEC_CONTENT
[	SEC_CONTENT
f	SEC_CONTENT
(	SEC_CONTENT
S	SEC_CONTENT
)	SEC_CONTENT
]	SEC_CONTENT
only	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
computed	SEC_CONTENT
once	SEC_CONTENT
per	SEC_CONTENT
training	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
independent	SEC_CONTENT
of	SEC_CONTENT
i.	SEC_CONTENT
α	SEC_CONTENT
,	SEC_CONTENT
β	SEC_CONTENT
,	SEC_CONTENT
γ	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
computed	SEC_CONTENT
by	SEC_CONTENT
drawing	SEC_CONTENT
K	SEC_CONTENT
samples	SEC_CONTENT
from	SEC_CONTENT
S	SEC_CONTENT
,	SEC_CONTENT
taking	SEC_CONTENT
time	SEC_CONTENT
O(K	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
whereas	SEC_CONTENT
K	SEC_CONTENT
samples	SEC_CONTENT
of	SEC_CONTENT
Y	SEC_CONTENT
(	SEC_CONTENT
z	SEC_CONTENT
)	SEC_CONTENT
take	SEC_CONTENT
time	SEC_CONTENT
O(mK	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Concretely	SEC_CONTENT
,	SEC_END
can	SEC_START
be	SEC_CONTENT
computed	SEC_CONTENT
by	SEC_CONTENT
differentiating	SEC_CONTENT
inside	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
.	SEC_END
One	SEC_START
can	SEC_CONTENT
combine	SEC_CONTENT
and	SEC_CONTENT
what	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
in	SEC_CONTENT
below	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
accurate	SEC_CONTENT
yet	SEC_CONTENT
relatively	SEC_CONTENT
cheap	SEC_CONTENT
approximation	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
derivative	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
practice	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
only	SEC_CONTENT
β	SEC_CONTENT
approximates	SEC_CONTENT
the	SEC_CONTENT
derivative	SEC_CONTENT
to	SEC_CONTENT
within	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
successive	SEC_CONTENT
MC	SEC_CONTENT
computations	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
L	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Empirically	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
2	SEC_CONTENT
-	SEC_CONTENT
30	SEC_CONTENT
times	SEC_CONTENT
faster	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
and	SEC_CONTENT
table	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
At	SEC_START
a	SEC_CONTENT
slightly	SEC_CONTENT
higher	SEC_CONTENT
loss	SEC_CONTENT
inaccuracy	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
get	SEC_CONTENT
rid	SEC_CONTENT
of	SEC_CONTENT
z	SEC_CONTENT
completely	SEC_CONTENT
by	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
parameterizing	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
in	SEC_CONTENT
µ	SEC_CONTENT
sand	SEC_CONTENT
σ	SEC_CONTENT
sand	SEC_CONTENT
taking	SEC_CONTENT
derivatives	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
them	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
approximating	SEC_CONTENT
the	SEC_CONTENT
derivative	SEC_CONTENT
directly	SEC_CONTENT
.	SEC_CONTENT
So	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
becomes	SEC_END
A	SECTITLE_START
closed	SECTITLE_CONTENT
-	SECTITLE_CONTENT
form	SECTITLE_CONTENT
approximation	SECTITLE_END
In	SEC_START
the	SEC_CONTENT
binary	SEC_CONTENT
classification	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
avoid	SEC_CONTENT
sampling	SEC_CONTENT
by	SEC_CONTENT
tabulating	SEC_CONTENT
α	SEC_CONTENT
,	SEC_CONTENT
β	SEC_CONTENT
,	SEC_CONTENT
γ	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
partial	SEC_CONTENT
derivatives	SEC_CONTENT
(	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
just	SEC_CONTENT
functions	SEC_CONTENT
of	SEC_CONTENT
2	SEC_CONTENT
arguments	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Interestingly	SEC_CONTENT
,	SEC_CONTENT
an	SEC_CONTENT
accurate	SEC_CONTENT
closed	SEC_CONTENT
-	SEC_CONTENT
from	SEC_CONTENT
approximation	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
possible	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
cumulative	SEC_CONTENT
distribution	SEC_CONTENT
function	SEC_CONTENT
Φ(x	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
√	SEC_CONTENT
2π	SEC_END
x	SEC_START
−∞	SEC_CONTENT
e	SEC_CONTENT
−t	SEC_CONTENT
2	SEC_CONTENT
/2	SEC_CONTENT
dt	SEC_CONTENT
to	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
logistic	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
shown	SEC_CONTENT
by	SEC_CONTENT
parameter	SEC_CONTENT
differentiation	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
µ	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
integrating	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
µ	SEC_CONTENT
that	SEC_END
This	SEC_START
is	SEC_CONTENT
an	SEC_CONTENT
approximation	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
Bayesian	SEC_CONTENT
prediction	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
posterior	SEC_CONTENT
is	SEC_CONTENT
approximated	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
we	SEC_CONTENT
now	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
closed	SEC_CONTENT
-	SEC_CONTENT
form	SEC_CONTENT
approximation	SEC_CONTENT
of	SEC_CONTENT
α	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
obtain	SEC_CONTENT
expressions	SEC_CONTENT
for	SEC_CONTENT
β	SEC_CONTENT
and	SEC_CONTENT
γ	SEC_CONTENT
by	SEC_CONTENT
differentiating	SEC_CONTENT
.	SEC_END
Furthermore	SEC_START
,	SEC_CONTENT
by	SEC_CONTENT
substituting	SEC_CONTENT
x	SEC_CONTENT
=	SEC_CONTENT
µ+st	SEC_CONTENT
,	SEC_CONTENT
differentiating	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
µ	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
even	SEC_CONTENT
approximate	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
(	SEC_CONTENT
6	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
closed	SEC_CONTENT
-	SEC_CONTENT
form	SEC_CONTENT
:	SEC_END
The	SEC_START
actual	SEC_CONTENT
objective	SEC_CONTENT
as	SEC_CONTENT
defined	SEC_CONTENT
in	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
obtained	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
by	SEC_CONTENT
observing	SEC_CONTENT
that	SEC_CONTENT
1	SEC_CONTENT
−	SEC_CONTENT
σ(x	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
σ(−x	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
The	SEC_START
gradient	SEC_CONTENT
and	SEC_CONTENT
Hessian	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
tow	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
found	SEC_CONTENT
by	SEC_CONTENT
analytically	SEC_CONTENT
differentiating	SEC_CONTENT
.	SEC_END
Generalizations	SECTITLE_END
Least	SECTITLE_START
squares	SECTITLE_CONTENT
regression	SECTITLE_END
In	SEC_START
contrast	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
approximations	SEC_CONTENT
so	SEC_CONTENT
far	SEC_CONTENT
,	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
regression	SEC_CONTENT
with	SEC_CONTENT
squared	SEC_CONTENT
error	SEC_CONTENT
loss	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
computed	SEC_CONTENT
exactly	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
y	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
label	SEC_CONTENT
andˆYandˆ	SEC_CONTENT
andˆY	SEC_CONTENT
=	SEC_CONTENT
i	SEC_CONTENT
w	SEC_CONTENT
ix	SEC_CONTENT
i	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
predicted	SEC_CONTENT
label	SEC_CONTENT
with	SEC_END
By	SEC_START
the	SEC_CONTENT
bias	SEC_CONTENT
-	SEC_CONTENT
variance	SEC_CONTENT
decomposition	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
expected	SEC_CONTENT
squared	SEC_CONTENT
error	SEC_CONTENT
loss	SEC_CONTENT
is	SEC_END
Since	SEC_START
is	SEC_CONTENT
completely	SEC_CONTENT
determined	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
mean	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
ofˆYofˆ	SEC_CONTENT
ofˆY	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
matter	SEC_CONTENT
which	SEC_CONTENT
distributionˆY	SEC_CONTENT
distributionˆ	SEC_CONTENT
distributionˆY	SEC_CONTENT
comes	SEC_CONTENT
from	SEC_CONTENT
as	SEC_CONTENT
long	SEC_CONTENT
as	SEC_CONTENT
µ	SEC_CONTENT
and	SEC_CONTENT
s	SEC_CONTENT
2	SEC_CONTENT
are	SEC_CONTENT
matched	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
a	SEC_CONTENT
result	SEC_CONTENT
,	SEC_CONTENT
(	SEC_CONTENT
9	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
the	SEC_CONTENT
exact	SEC_CONTENT
loss	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
dropout	SEC_CONTENT
objective	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
summed	SEC_CONTENT
over	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
instead	SEC_CONTENT
.	SEC_CONTENT
So	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
dataset	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
dropout	SEC_CONTENT
regression	SEC_CONTENT
has	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
equivalent	SEC_CONTENT
objective	SEC_CONTENT
:	SEC_END
This	SEC_START
is	SEC_CONTENT
a	SEC_CONTENT
form	SEC_CONTENT
of	SEC_CONTENT
L	SEC_CONTENT
2	SEC_CONTENT
regularization	SEC_CONTENT
depending	SEC_CONTENT
on	SEC_END
so	SEC_START
that	SEC_CONTENT
weights	SEC_CONTENT
of	SEC_CONTENT
larger	SEC_CONTENT
features	SEC_CONTENT
are	SEC_CONTENT
regularized	SEC_CONTENT
more	SEC_CONTENT
strongly	SEC_CONTENT
.	SEC_END
Alternatively	SEC_START
,	SEC_CONTENT
let	SEC_CONTENT
X	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
n×m	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
design	SEC_CONTENT
matrix	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
normal	SEC_CONTENT
equations	SEC_CONTENT
for	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
ridge	SEC_CONTENT
regression	SEC_CONTENT
are	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
,	SEC_END
where	SEC_START
diag(A	SEC_CONTENT
)	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
diagonal	SEC_CONTENT
matrix	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
diagonal	SEC_CONTENT
as	SEC_CONTENT
A.	SEC_CONTENT
The	SEC_CONTENT
diagonal	SEC_CONTENT
of	SEC_CONTENT
X	SEC_CONTENT
TX	SEC_CONTENT
is	SEC_CONTENT
stronger	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
multiplicative	SEC_CONTENT
factor	SEC_CONTENT
1	SEC_CONTENT
+	SEC_CONTENT
λ	SEC_CONTENT
for	SEC_CONTENT
dropout	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
additive	SEC_CONTENT
λI	SEC_CONTENT
for	SEC_CONTENT
L	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
equivalent	SEC_CONTENT
value	SEC_CONTENT
for	SEC_CONTENT
λ	SEC_CONTENT
determined	SEC_CONTENT
by	SEC_CONTENT
dropout	SEC_CONTENT
is	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
−	SEC_CONTENT
p)/p	SEC_CONTENT
.	SEC_END
Hinge	SECTITLE_START
loss	SECTITLE_CONTENT
and	SECTITLE_CONTENT
the	SECTITLE_CONTENT
Maxout	SECTITLE_CONTENT
unit	SECTITLE_END
Our	SEC_START
apporach	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
classical	SEC_CONTENT
hinge	SEC_CONTENT
loss	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
maxout	SEC_CONTENT
network	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
structured	SEC_CONTENT
SVM	SEC_CONTENT
loss	SEC_CONTENT
is	SEC_END
where	SEC_START
Y	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
predictions	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
y	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
incurred	SEC_CONTENT
by	SEC_CONTENT
predictingˆypredictingˆ	SEC_CONTENT
predictingˆy	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
label	SEC_CONTENT
is	SEC_CONTENT
y.	SEC_CONTENT
The	SEC_CONTENT
maxout	SEC_CONTENT
unit	SEC_CONTENT
computes	SEC_END
Under	SEC_START
the	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
both	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
reduce	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
of	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
maximum	SEC_CONTENT
of	SEC_CONTENT
Gaussians	SEC_CONTENT
maxi	SEC_CONTENT
X	SEC_CONTENT
i	SEC_CONTENT
for	SEC_CONTENT
X	SEC_CONTENT
i	SEC_CONTENT
∼	SEC_CONTENT
N	SEC_CONTENT
(	SEC_CONTENT
µ(x	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
σ	SEC_CONTENT
2	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
,	SEC_CONTENT
w	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
not	SEC_CONTENT
necessarily	SEC_CONTENT
indepedent	SEC_CONTENT
.	SEC_CONTENT
Several	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
is	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
Ross	SEC_CONTENT
,	SEC_CONTENT
2010	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Softmax	SECTITLE_START
and	SECTITLE_CONTENT
general	SECTITLE_CONTENT
loss	SECTITLE_END
Unfortunately	SEC_START
,	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
crossentropy	SEC_CONTENT
loss	SEC_CONTENT
for	SEC_CONTENT
softmax	SEC_CONTENT
seems	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
sampling	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
Gaussian	SEC_CONTENT
directly	SEC_CONTENT
with	SEC_CONTENT
S	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
|Y|	SEC_CONTENT
where	SEC_CONTENT
Y	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
predictions	SEC_CONTENT
.	SEC_END
where	SEC_START
softmax(s	SEC_CONTENT
)	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
e	SEC_CONTENT
si	SEC_CONTENT
/	SEC_CONTENT
|Y|	SEC_CONTENT
j=1	SEC_CONTENT
e	SEC_CONTENT
sj	SEC_CONTENT
and	SEC_CONTENT
Σ	SEC_CONTENT
=	SEC_CONTENT
U	SEC_CONTENT
UT	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
required	SEC_CONTENT
partial	SEC_CONTENT
derivatives	SEC_CONTENT
can	SEC_CONTENT
again	SEC_CONTENT
be	SEC_CONTENT
computed	SEC_CONTENT
by	SEC_CONTENT
differentiating	SEC_CONTENT
inside	SEC_CONTENT
the	SEC_CONTENT
expectation	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
the	SEC_CONTENT
general	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
do	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
output	SEC_CONTENT
units	SEC_CONTENT
that	SEC_CONTENT
maybe	SEC_CONTENT
vector	SEC_CONTENT
-	SEC_CONTENT
valued	SEC_CONTENT
functions	SEC_CONTENT
of	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_END
Transformation	SECTITLE_START
invariance	SECTITLE_CONTENT
as	SECTITLE_CONTENT
noise	SECTITLE_END
More	SEC_START
image	SEC_CONTENT
data	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
generated	SEC_CONTENT
by	SEC_CONTENT
applying	SEC_CONTENT
transformations	SEC_CONTENT
like	SEC_CONTENT
small	SEC_CONTENT
translations	SEC_CONTENT
,	SEC_CONTENT
rotations	SEC_CONTENT
,	SEC_CONTENT
shearing	SEC_CONTENT
etc	SEC_CONTENT
.	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
transformation	SEC_CONTENT
of	SEC_CONTENT
magnitude	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
approximated	SEC_CONTENT
locally	SEC_CONTENT
by	SEC_CONTENT
its	SEC_CONTENT
Lie	SEC_CONTENT
derivative	SEC_CONTENT
as	SEC_CONTENT
T	SEC_CONTENT
α	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
x	SEC_CONTENT
+	SEC_CONTENT
L	SEC_CONTENT
T	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
(	SEC_CONTENT
Simard	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
1996	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
rotation	SEC_CONTENT
,	SEC_CONTENT
shearing	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
generate	SEC_CONTENT
more	SEC_CONTENT
data	SEC_CONTENT
by	SEC_CONTENT
randomly	SEC_CONTENT
sampling	SEC_CONTENT
i	SEC_CONTENT
∼	SEC_CONTENT
N	SEC_CONTENT
(	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
σ	SEC_CONTENT
2	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
computing	SEC_CONTENT
X	SEC_CONTENT
=	SEC_CONTENT
x+	SEC_CONTENT
ii	SEC_CONTENT
Li	SEC_CONTENT
.	SEC_CONTENT
Notice	SEC_CONTENT
that	SEC_CONTENT
w	SEC_CONTENT
TX	SEC_CONTENT
is	SEC_CONTENT
again	SEC_CONTENT
normally	SEC_CONTENT
distributed	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
techniques	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
integrate	SEC_CONTENT
out	SEC_CONTENT
these	SEC_CONTENT
transformations	SEC_CONTENT
without	SEC_CONTENT
actually	SEC_CONTENT
generating	SEC_CONTENT
the	SEC_CONTENT
transformed	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Here	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
need	SEC_CONTENT
the	SEC_CONTENT
central	SEC_CONTENT
limit	SEC_CONTENT
theorem	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
noise	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
independent	SEC_CONTENT
.	SEC_END
Other	SECTITLE_START
noise	SECTITLE_END
Like	SEC_START
the	SEC_CONTENT
exact	SEC_CONTENT
approach	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
van	SEC_CONTENT
der	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
approximation	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
noise	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
Poisson	SEC_CONTENT
,	SEC_CONTENT
Gaussian	SEC_CONTENT
,	SEC_CONTENT
etc	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
just	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
characterize	SEC_CONTENT
the	SEC_CONTENT
noise	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
mean	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
and	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
central	SEC_CONTENT
limit	SEC_CONTENT
theorem	SEC_CONTENT
.	SEC_END
Fast	SECTITLE_START
dropout	SECTITLE_CONTENT
for	SECTITLE_CONTENT
neural	SECTITLE_CONTENT
networks	SECTITLE_END
Dropout	SEC_START
training	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
originally	SEC_CONTENT
proposed	SEC_CONTENT
,	SEC_CONTENT
was	SEC_CONTENT
intended	SEC_CONTENT
for	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
where	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
are	SEC_CONTENT
dropped	SEC_CONTENT
out	SEC_CONTENT
,	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Fast	SEC_CONTENT
dropout	SEC_CONTENT
is	SEC_CONTENT
directly	SEC_CONTENT
applicable	SEC_CONTENT
to	SEC_CONTENT
dropping	SEC_CONTENT
out	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
approximately	SEC_CONTENT
extend	SEC_CONTENT
our	SEC_CONTENT
technique	SEC_CONTENT
to	SEC_CONTENT
deep	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
and	SEC_CONTENT
show	SEC_CONTENT
how	SEC_CONTENT
they	SEC_CONTENT
apply	SEC_CONTENT
to	SEC_CONTENT
several	SEC_CONTENT
popular	SEC_CONTENT
types	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
any	SEC_CONTENT
output	SEC_CONTENT
unit	SEC_CONTENT
outlined	SEC_CONTENT
in	SEC_CONTENT
section	SEC_CONTENT
3	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
.	SEC_END
The	SECTITLE_START
hidden	SECTITLE_CONTENT
layers	SECTITLE_END
Under	SEC_START
dropout	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
hidden	SEC_CONTENT
unit	SEC_CONTENT
takes	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
variable	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
produces	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
variable	SEC_CONTENT
as	SEC_CONTENT
output	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
10	SEC_CONTENT
or	SEC_CONTENT
so	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
may	SEC_CONTENT
again	SEC_CONTENT
approximate	SEC_CONTENT
their	SEC_CONTENT
inputs	SEC_CONTENT
as	SEC_CONTENT
Gaussians	SEC_CONTENT
and	SEC_CONTENT
characterize	SEC_CONTENT
their	SEC_CONTENT
outputs	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
means	SEC_CONTENT
and	SEC_CONTENT
variances	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
complication	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
to	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
covariance	SEC_CONTENT
as	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Consider	SEC_START
any	SEC_CONTENT
hidden	SEC_CONTENT
unit	SEC_CONTENT
in	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
may	SEC_CONTENT
approximate	SEC_CONTENT
its	SEC_CONTENT
input	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
variable	SEC_CONTENT
X	SEC_CONTENT
∼	SEC_CONTENT
N	SEC_CONTENT
(	SEC_CONTENT
x|µ	SEC_CONTENT
,	SEC_CONTENT
s	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
let	SEC_CONTENT
its	SEC_CONTENT
output	SEC_CONTENT
mean	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
be	SEC_CONTENT
ν	SEC_CONTENT
and	SEC_CONTENT
τ	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
E.g.	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
commonly	SEC_CONTENT
used	SEC_CONTENT
sigmoid	SEC_CONTENT
unit	SEC_END
This	SEC_START
integral	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
evaluated	SEC_CONTENT
exactly	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
rectified	SEC_CONTENT
linear	SEC_CONTENT
unit	SEC_CONTENT
f	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
max(0	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
r	SEC_CONTENT
=	SEC_CONTENT
µ/s	SEC_CONTENT
,	SEC_CONTENT
then	SEC_END
The	SEC_START
rectified	SEC_CONTENT
linear	SEC_CONTENT
unit	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
special	SEC_CONTENT
case	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
maxout	SEC_CONTENT
unit	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
which	SEC_CONTENT
techniques	SEC_CONTENT
in	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
its	SEC_CONTENT
mean	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
.	SEC_END
With	SEC_START
dropout	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
hidden	SEC_CONTENT
unit	SEC_CONTENT
also	SEC_CONTENT
has	SEC_CONTENT
an	SEC_CONTENT
output	SEC_CONTENT
variance	SEC_CONTENT
.	SEC_CONTENT
Sigmoid	SEC_CONTENT
squared	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
approximated	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
translatedscaled	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sigmoid	SEC_CONTENT
:	SEC_END
Figure	SEC_START
2	SEC_CONTENT
.	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
covariance	SEC_CONTENT
matrices	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
of	SEC_CONTENT
50	SEC_CONTENT
random	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
:	SEC_CONTENT
left	SEC_CONTENT
:	SEC_CONTENT
at	SEC_CONTENT
random	SEC_CONTENT
initialization	SEC_CONTENT
;	SEC_CONTENT
right	SEC_CONTENT
:	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
convergence	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
covariance	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
completely	SEC_CONTENT
diagonal	SEC_CONTENT
once	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
convergence	SEC_CONTENT
.	SEC_CONTENT
a	SEC_CONTENT
,	SEC_CONTENT
b	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
found	SEC_CONTENT
by	SEC_CONTENT
matching	SEC_CONTENT
the	SEC_CONTENT
values	SEC_CONTENT
and	SEC_CONTENT
derivatives	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
=	SEC_CONTENT
4	SEC_CONTENT
−	SEC_CONTENT
2	SEC_CONTENT
√	SEC_CONTENT
2	SEC_CONTENT
and	SEC_CONTENT
b	SEC_CONTENT
=	SEC_CONTENT
−	SEC_CONTENT
log	SEC_CONTENT
(	SEC_CONTENT
√	SEC_CONTENT
2	SEC_CONTENT
−	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Training	SECTITLE_START
with	SECTITLE_CONTENT
backpropagation	SECTITLE_END
The	SEC_START
resulting	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
by	SEC_CONTENT
backpropagation	SEC_CONTENT
with	SEC_CONTENT
two	SEC_CONTENT
sets	SEC_CONTENT
of	SEC_CONTENT
partial	SEC_CONTENT
derivatives	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
normal	SEC_CONTENT
backpropagation	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
only	SEC_CONTENT
needs	SEC_CONTENT
to	SEC_CONTENT
keep	SEC_CONTENT
∂L	SEC_CONTENT
∂µi	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
hidden	SEC_CONTENT
unit	SEC_CONTENT
i	SEC_CONTENT
with	SEC_CONTENT
input	SEC_CONTENT
µ	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
need	SEC_CONTENT
∂L	SEC_CONTENT
∂s	SEC_CONTENT
2	SEC_CONTENT
i	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
for	SEC_CONTENT
input	SEC_CONTENT
variance	SEC_CONTENT
s	SEC_CONTENT
2	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
Where	SEC_END
j	SEC_START
w	SEC_CONTENT
2	SEC_CONTENT
ij	SEC_CONTENT
and	SEC_CONTENT
ν	SEC_CONTENT
j	SEC_CONTENT
and	SEC_CONTENT
τ	SEC_CONTENT
j	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
mean	SEC_CONTENT
and	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
practice	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
method	SEC_CONTENT
still	SEC_CONTENT
works	SEC_CONTENT
well	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
ignore	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
variance	SEC_CONTENT
τ	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
variance	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
generated	SEC_CONTENT
by	SEC_CONTENT
dropout	SEC_CONTENT
alone	SEC_CONTENT
.	SEC_END
Relation	SECTITLE_START
to	SECTITLE_CONTENT
Bayesian	SECTITLE_CONTENT
model	SECTITLE_CONTENT
selection	SECTITLE_END
Once	SEC_START
we	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
approximation	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
alternative	SEC_CONTENT
interpretation	SEC_CONTENT
of	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
comes	SEC_CONTENT
from	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
dropout	SEC_CONTENT
framework	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
comes	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
dropout	SEC_CONTENT
variable	SEC_CONTENT
z.	SEC_CONTENT
Under	SEC_CONTENT
the	SEC_CONTENT
alternative	SEC_CONTENT
interpretation	SEC_CONTENT
where	SEC_CONTENT
w	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
variable	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
view	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
as	SEC_CONTENT
maximizing	SEC_CONTENT
a	SEC_CONTENT
lower	SEC_CONTENT
bound	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Bayesian	SEC_CONTENT
marginal	SEC_CONTENT
likelihood	SEC_CONTENT
among	SEC_CONTENT
a	SEC_CONTENT
class	SEC_CONTENT
of	SEC_CONTENT
models	SEC_CONTENT
M	SEC_CONTENT
µ	SEC_CONTENT
indexed	SEC_CONTENT
by	SEC_CONTENT
µ	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
m	SEC_CONTENT
.	SEC_CONTENT
Concretely	SEC_CONTENT
,	SEC_CONTENT
let	SEC_CONTENT
µ	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
pw	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
dropout	SEC_CONTENT
objective	SEC_END
where	SEC_START
Here	SEC_CONTENT
the	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
v	SEC_CONTENT
is	SEC_CONTENT
tied	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
magnitude	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
a	SEC_CONTENT
larger	SEC_CONTENT
weight	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
beneficial	SEC_CONTENT
when	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
robust	SEC_CONTENT
to	SEC_CONTENT
noise	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
α	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
determined	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
dropout	SEC_CONTENT
process	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
also	SEC_CONTENT
free	SEC_CONTENT
to	SEC_CONTENT
choose	SEC_CONTENT
α	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
empirically	SEC_CONTENT
that	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
slightly	SEC_CONTENT
larger	SEC_CONTENT
α	SEC_CONTENT
than	SEC_CONTENT
that	SEC_CONTENT
determined	SEC_CONTENT
by	SEC_CONTENT
dropout	SEC_CONTENT
often	SEC_CONTENT
performs	SEC_CONTENT
slightly	SEC_CONTENT
better	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
Evaluating	SECTITLE_START
the	SECTITLE_CONTENT
assumptions	SECTITLE_CONTENT
and	SECTITLE_CONTENT
speed	SECTITLE_END
For	SEC_START
logistic	SEC_CONTENT
regression	SEC_CONTENT
(	SEC_CONTENT
LR	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
quality	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
approximation	SEC_CONTENT
using	SEC_CONTENT
Gaussian	SEC_CONTENT
samples	SEC_CONTENT
is	SEC_CONTENT
comparable	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
difference	SEC_CONTENT
between	SEC_CONTENT
different	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
runs	SEC_CONTENT
with	SEC_CONTENT
200	SEC_CONTENT
samples	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
under	SEC_CONTENT
identical	SEC_CONTENT
settings	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
approximation	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
faster	SEC_CONTENT
than	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
very	SEC_CONTENT
similar	SEC_CONTENT
validation	SEC_CONTENT
error	SEC_CONTENT
profile	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
Gaussian	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
reduce	SEC_CONTENT
validation	SEC_CONTENT
error	SEC_CONTENT
rate	SEC_CONTENT
by	SEC_CONTENT
about	SEC_CONTENT
30	SEC_CONTENT
%	SEC_CONTENT
over	SEC_CONTENT
plain	SEC_CONTENT
LR	SEC_CONTENT
when	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
convergence	SEC_CONTENT
,	SEC_CONTENT
without	SEC_CONTENT
ever	SEC_CONTENT
overfitting	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_START
on	SECTITLE_CONTENT
document	SECTITLE_CONTENT
classification	SECTITLE_END
We	SEC_START
show	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
LR	SEC_CONTENT
on	SEC_CONTENT
several	SEC_CONTENT
sentiment	SEC_CONTENT
and	SEC_CONTENT
topic	SEC_CONTENT
document	SEC_CONTENT
classification	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
both	metric
accuracy	metric
and	SEC_CONTENT
time	SEC_CONTENT
taken	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
half	SEC_CONTENT
of	SEC_CONTENT
table	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
Sampling	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
is	SEC_CONTENT
generally	SEC_CONTENT
around	SEC_CONTENT
10	SEC_CONTENT
times	SEC_CONTENT
faster	SEC_CONTENT
than	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
and	SEC_CONTENT
performs	SEC_CONTENT
comparably	SEC_CONTENT
to	SEC_CONTENT
NBSVM	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
method	SEC_CONTENT
specifically	SEC_CONTENT
engineered	SEC_CONTENT
for	SEC_CONTENT
document	SEC_CONTENT
classification	SEC_CONTENT
.	SEC_CONTENT
Further	SEC_CONTENT
speedup	SEC_CONTENT
is	SEC_CONTENT
achieved	SEC_CONTENT
by	SEC_CONTENT
directly	SEC_CONTENT
optimizing	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
in	SEC_CONTENT
and	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
30	SEC_CONTENT
%	SEC_CONTENT
slower	SEC_CONTENT
than	SEC_CONTENT
plain	SEC_CONTENT
logistic	SEC_CONTENT
regression	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
each	SEC_CONTENT
iteration	SEC_CONTENT
of	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
is	SEC_CONTENT
still	SEC_CONTENT
slower	SEC_CONTENT
than	SEC_CONTENT
LR	SEC_CONTENT
,	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
sometimes	SEC_CONTENT
reaches	SEC_CONTENT
a	SEC_CONTENT
better	SEC_CONTENT
validation	SEC_CONTENT
performance	SEC_CONTENT
in	SEC_CONTENT
less	SEC_CONTENT
time	SEC_CONTENT
as	SEC_CONTENT
seen	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
MPQA	SEC_CONTENT
dataset	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
zero	SEC_CONTENT
dimensions	SEC_CONTENT
ism	SEC_CONTENT
≈	SEC_CONTENT
4	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
Gaussian	SEC_CONTENT
assumption	SEC_CONTENT
is	SEC_CONTENT
unjustifiable	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
the	SEC_CONTENT
derived	SEC_CONTENT
method	SEC_CONTENT
works	SEC_CONTENT
empirically	SEC_CONTENT
anyways	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
papers	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
bottom	SEC_CONTENT
half	SEC_CONTENT
 	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
table	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
either	SEC_CONTENT
a	SEC_CONTENT
test	SEC_CONTENT
/	SEC_CONTENT
train	SEC_CONTENT
split	SEC_CONTENT
or	SEC_CONTENT
Nfold	SEC_CONTENT
cross	SEC_CONTENT
validation	SEC_CONTENT
,	SEC_CONTENT
depending	SEC_CONTENT
on	SEC_CONTENT
what	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
standard	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
regularization	SEC_CONTENT
parameters	SEC_CONTENT
and	SEC_CONTENT
bigram	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
plain	SEC_CONTENT
LR	SEC_CONTENT
baseline	SEC_CONTENT
is	SEC_CONTENT
itself	SEC_CONTENT
quite	SEC_CONTENT
strong	SEC_CONTENT
relative	SEC_CONTENT
to	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_START
on	SECTITLE_CONTENT
MNIST	SECTITLE_END
Experimental	SEC_START
results	task
on	SEC_CONTENT
MNIST	SEC_CONTENT
using	SEC_CONTENT
2-hidden	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
table	SEC_CONTENT
2	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
error	SEC_CONTENT
curves	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
slight	SEC_CONTENT
smaller	SEC_CONTENT
net	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Here	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
case	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
fairly	SEC_CONTENT
redundant	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
dropping	SEC_CONTENT
out	SEC_CONTENT
input	SEC_CONTENT
features	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
much	SEC_CONTENT
harder	SEC_CONTENT
and	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
on	SEC_CONTENT
minibatches	SEC_CONTENT
converges	SEC_CONTENT
fairly	SEC_CONTENT
quickly	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
replicate	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
experiment	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
exact	SEC_CONTENT
settings	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
20	SEC_CONTENT
%	SEC_CONTENT
dropout	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
inputs	SEC_CONTENT
,	SEC_CONTENT
an	SEC_CONTENT
exponentially	SEC_CONTENT
decaying	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
momentum	SEC_CONTENT
schedule	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
minibatch	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
.	SEC_CONTENT
Under	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
schedule	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
experiment	SEC_CONTENT
,	SEC_CONTENT
no	SEC_CONTENT
improvement	SEC_CONTENT
resulted	SEC_CONTENT
from	SEC_CONTENT
doing	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
minibatch	SEC_CONTENT
setting	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
minibatch	SEC_CONTENT
of	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
takes	SEC_CONTENT
1.5	SEC_CONTENT
times	SEC_CONTENT
as	SEC_CONTENT
much	SEC_CONTENT
time	SEC_CONTENT
as	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
with	SEC_CONTENT
1	SEC_CONTENT
sample	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
objective	SEC_CONTENT
is	SEC_CONTENT
suitable	SEC_CONTENT
for	SEC_CONTENT
standard	SEC_CONTENT
optimization	SEC_CONTENT
technology	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
were	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
faster	SEC_CONTENT
using	SEC_CONTENT
L	SEC_CONTENT
-	SEC_CONTENT
BFGS	SEC_CONTENT
where	SEC_CONTENT
it	SEC_CONTENT
converged	SEC_CONTENT
in	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
100	SEC_CONTENT
epochs	SEC_CONTENT
as	SEC_CONTENT
opposed	SEC_CONTENT
to	SEC_CONTENT
over	SEC_CONTENT
500	SEC_CONTENT
epochs	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
160	SEC_CONTENT
errors	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
best	SEC_CONTENT
result	SEC_CONTENT
without	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
or	SEC_CONTENT
weightsharing	SEC_CONTENT
or	SEC_CONTENT
enhancement	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Plain	SEC_CONTENT
LR	SEC_CONTENT
Gaussian	SEC_CONTENT
approx	SEC_CONTENT
.	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
Validation	SEC_CONTENT
errors	SEC_CONTENT
vs.	SEC_CONTENT
time	SEC_CONTENT
spent	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
left	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
iterations	SEC_CONTENT
(	SEC_CONTENT
right	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
batch	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
20-newsgroup	SEC_CONTENT
subtask	SEC_CONTENT
alt.atheism	SEC_CONTENT
vs.	SEC_CONTENT
religion.misc	SEC_CONTENT
.	SEC_CONTENT
100	SEC_CONTENT
samples	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
MC	SEC_CONTENT
and	SEC_CONTENT
Gaussian	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
MC	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
zi	SEC_CONTENT
is	SEC_CONTENT
sampled	SEC_CONTENT
only	SEC_CONTENT
for	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
zero	SEC_CONTENT
xi	SEC_CONTENT
..	SEC_CONTENT
Validation	SEC_CONTENT
errors	SEC_CONTENT
vs.	SEC_CONTENT
epochs	SEC_CONTENT
:	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
exact	SEC_CONTENT
SGD	SEC_CONTENT
training	SEC_CONTENT
schedule	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
784	SEC_CONTENT
-	SEC_CONTENT
800	SEC_CONTENT
-	SEC_CONTENT
800	SEC_CONTENT
-	SEC_CONTENT
10	SEC_CONTENT
2-hiden	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
training	SEC_CONTENT
schedule	SEC_CONTENT
is	SEC_CONTENT
presumably	SEC_CONTENT
tuned	SEC_CONTENT
for	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
performs	SEC_CONTENT
similarly	SEC_CONTENT
to	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
but	SEC_CONTENT
with	SEC_CONTENT
less	SEC_CONTENT
variance	SEC_CONTENT
.	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
batch	SEC_CONTENT
:	SEC_CONTENT
use	SEC_CONTENT
batch	SEC_CONTENT
L	SEC_CONTENT
-	SEC_CONTENT
BFGS	SEC_CONTENT
and	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
validation	SEC_CONTENT
error	SEC_CONTENT
evaluated	SEC_CONTENT
every	SEC_CONTENT
10	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_END
Methods\	SECTITLE_START
Datasets	SECTITLE_END
simplicity	SEC_START
.	SEC_CONTENT
compares	SEC_CONTENT
several	SEC_CONTENT
test	SEC_CONTENT
time	SEC_CONTENT
methods	SEC_CONTENT
on	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
trained	SEC_CONTENT
for	SEC_CONTENT
MNIST	SEC_CONTENT
and	SEC_CONTENT
CIFAR	SEC_CONTENT
using	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
Multiple	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
samples	SEC_CONTENT
and	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
provide	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
but	SEC_CONTENT
noticeable	SEC_CONTENT
improvement	SEC_CONTENT
overweight	SEC_CONTENT
scaling	SEC_CONTENT
.	SEC_END
Other	SECTITLE_START
experiments	SECTITLE_END
The	SEC_START
normal	SEC_CONTENT
equations	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
contrast	SEC_CONTENT
between	SEC_CONTENT
additive	SEC_CONTENT
and	SEC_CONTENT
multiplicative	SEC_CONTENT
L	SEC_CONTENT
2	SEC_CONTENT
regularization	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
linear	SEC_CONTENT
regression	SEC_CONTENT
,	SEC_CONTENT
L	SEC_CONTENT
2	SEC_CONTENT
regularization	SEC_CONTENT
outperformed	SEC_CONTENT
dropout	SEC_CONTENT
on	SEC_CONTENT
10	SEC_CONTENT
datasets	SEC_CONTENT
from	SEC_CONTENT
UCI	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
tried	SEC_CONTENT
.	SEC_CONTENT
1	SEC_CONTENT
Results	SEC_CONTENT
on	SEC_CONTENT
5	SEC_CONTENT
of	SEC_CONTENT
them	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
table	SEC_CONTENT
4	SEC_CONTENT
.	SEC_END
Classification	SEC_START
results	SEC_CONTENT
using	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
on	SEC_CONTENT
small	SEC_CONTENT
UCI	SEC_CONTENT
datasets	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
table	SEC_CONTENT
5	SEC_CONTENT
where	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
does	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
plain	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
inmost	SEC_CONTENT
cases	SEC_CONTENT
.	SEC_END
Conclusions	SECTITLE_END
We	SEC_START
presented	SEC_CONTENT
away	SEC_CONTENT
of	SEC_CONTENT
getting	SEC_CONTENT
the	SEC_CONTENT
benefits	SEC_CONTENT
of	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
without	SEC_CONTENT
actually	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
thereby	SEC_CONTENT
speeding	SEC_CONTENT
up	SEC_CONTENT
the	SEC_CONTENT
process	SEC_CONTENT
by	SEC_CONTENT
an	SEC_CONTENT
order	SEC_CONTENT
of	SEC_CONTENT
magnitude	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
high	SEC_CONTENT
dimensional	SEC_CONTENT
datasets	SEC_CONTENT
(	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
hundred	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
iteration	SEC_CONTENT
of	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
is	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
2	SEC_CONTENT
times	SEC_CONTENT
slower	SEC_CONTENT
than	SEC_CONTENT
normal	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
provided	SEC_CONTENT
a	SEC_CONTENT
deterministic	SEC_CONTENT
and	SEC_CONTENT
easy	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
compute	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
approximately	SEC_CONTENT
equivalent	SEC_CONTENT
to	SEC_CONTENT
that	SEC_CONTENT
of	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
can	SEC_CONTENT
optimize	SEC_CONTENT
this	SEC_CONTENT
objective	SEC_CONTENT
using	SEC_CONTENT
standard	SEC_CONTENT
optimization	SEC_CONTENT
.	SEC_CONTENT
Different	SEC_CONTENT
test	SEC_CONTENT
time	SEC_CONTENT
methods	SEC_CONTENT
on	SEC_CONTENT
networks	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
:	SEC_CONTENT
A	SEC_CONTENT
784	SEC_CONTENT
-	SEC_CONTENT
800	SEC_CONTENT
-	SEC_CONTENT
800	SEC_CONTENT
-	SEC_CONTENT
10	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
on	SEC_CONTENT
MNIST	SEC_CONTENT
(	SEC_CONTENT
3072	SEC_CONTENT
-	SEC_CONTENT
1000	SEC_CONTENT
-	SEC_CONTENT
1000	SEC_CONTENT
-	SEC_CONTENT
10	SEC_CONTENT
for	SEC_CONTENT
CIFAR-10	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
tested	SEC_CONTENT
using	SEC_CONTENT
:	SEC_CONTENT
Full	SEC_CONTENT
:	SEC_CONTENT
use	SEC_CONTENT
all	SEC_CONTENT
weights	SEC_CONTENT
without	SEC_CONTENT
scaling	SEC_CONTENT
;	SEC_CONTENT
Scale	SEC_CONTENT
:	SEC_CONTENT
w	SEC_CONTENT
←	SEC_CONTENT
pw	SEC_CONTENT
;	SEC_CONTENT
D(n	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
taken	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
samples	SEC_CONTENT
;	SEC_CONTENT
FD	SEC_CONTENT
:	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
.	SEC_CONTENT
  	SEC_CONTENT
methods	SEC_CONTENT
,	SEC_CONTENT
whereas	SEC_CONTENT
standard	SEC_CONTENT
methods	SEC_CONTENT
are	SEC_CONTENT
of	SEC_CONTENT
limited	SEC_CONTENT
use	SEC_CONTENT
in	SEC_CONTENT
real	SEC_CONTENT
dropout	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
noisy	SEC_CONTENT
measurement	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
fast	SEC_CONTENT
dropout	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
losing	SEC_CONTENT
any	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
individual	SEC_CONTENT
training	SEC_CONTENT
cases	SEC_CONTENT
from	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
capable	SEC_CONTENT
of	SEC_CONTENT
doing	SEC_CONTENT
more	SEC_CONTENT
work	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
iteration	SEC_CONTENT
,	SEC_CONTENT
often	SEC_CONTENT
reaching	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
performance	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
shorter	SEC_CONTENT
time	SEC_CONTENT
and	SEC_CONTENT
in	SEC_CONTENT
less	SEC_CONTENT
iterations	SEC_CONTENT
.	SEC_END
Dataset	SECTITLE_END
