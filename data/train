1712.01586	title\tagSECTITLE_END	semantic_role_labeling\tagtask	with\tagSENT_CONTENT	Self\tagSENT_CONTENT	-\tagSENT_CONTENT	Attention\tagSENT_END	abstract\tagSECTITLE_END	semantic_role_labeling\tagtask	(\tagSENT_CONTENT	SRL\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	believed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	crucial\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	studied\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	single\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	F1\tagmetric	=\tagSENT_END	83.4\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL-2005\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagmetric	=\tagSENT_END	Introduction\tagSECTITLE_END	semantic_role_labeling\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	shallow\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	whose\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	essentially\tagSENT_CONTENT	"\tagSENT_CONTENT	who\tagSENT_CONTENT	did\tagSENT_CONTENT	what\tagSENT_CONTENT	to\tagSENT_CONTENT	whom\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	when\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	where\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	semantic_role_labeling\tagtask	indicate\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	event\tagSENT_CONTENT	properties\tagSENT_CONTENT	and\tagSENT_CONTENT	relations\tagSENT_CONTENT	among\tagSENT_CONTENT	relevant\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	provide\tagSENT_CONTENT	an\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	thus\tagSENT_CONTENT	benefiting\tagSENT_CONTENT	many\tagSENT_CONTENT	NLP\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Information\tagSENT_CONTENT	Extraction\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Question\tagSENT_CONTENT	Answering\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	Abstractive\tagSENT_CONTENT	Summarization\tagSENT_CONTENT	(\tagSENT_CONTENT	Genest\tagSENT_CONTENT	and\tagSENT_CONTENT	Lapalme\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	semantic_role_labeling\tagtask	are\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	syntax\tagSENT_CONTENT	.\tagSENT_END	Semantic\tagSECTITLE_START	Role\tagSECTITLE_CONTENT	Labeling\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	SRL\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	and\tagSENT_CONTENT	classify\tagSENT_CONTENT	the\tagSENT_CONTENT	arguments\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	target\tagSENT_CONTENT	verb\tagSENT_CONTENT	into\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Generally\tagSENT_START	,\tagSENT_CONTENT	semantic_role_labeling\tagtask	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	steps\tagSENT_CONTENT	:\tagSENT_CONTENT	identifying\tagSENT_CONTENT	and\tagSENT_CONTENT	classifying\tagSENT_CONTENT	arguments\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	former\tagSENT_CONTENT	step\tagSENT_CONTENT	involves\tagSENT_CONTENT	assigning\tagSENT_CONTENT	either\tagSENT_CONTENT	a\tagSENT_CONTENT	semantic\tagSENT_CONTENT	argument\tagSENT_CONTENT	or\tagSENT_CONTENT	nonargument\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	predicate\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	latter\tagSENT_CONTENT	includes\tagSENT_CONTENT	labeling\tagSENT_CONTENT	semantic_role_labeling\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	identified\tagSENT_CONTENT	argument\tagSENT_CONTENT	.\tagSENT_END	Deep\tagSECTITLE_START	Attentional\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	SRL\tagSECTITLE_END	Self\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Word\tagSECTITLE_START	&\tagSECTITLE_CONTENT	Predicate\tagSECTITLE_END	Nonlinear\tagSECTITLE_START	Sub\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Layers\tagSECTITLE_END	Deep\tagSECTITLE_START	Topology\tagSECTITLE_END	Position\tagSECTITLE_START	Encoding\tagSECTITLE_END	Pipeline\tagSECTITLE_END	Since\tagSENT_START	there\tagSENT_CONTENT	are\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	between\tagSENT_CONTENT	semantic_role_labeling\tagtask	,\tagSENT_CONTENT	most\tagSENT_CONTENT	previous\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	introduced\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	measuring\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	jumping\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	Model\tagSECTITLE_START	Setup\tagSECTITLE_END	Results\tagSECTITLE_END	Analysis\tagSECTITLE_END	Constrained\tagSECTITLE_START	Decoding\tagSECTITLE_END	shows\tagSENT_START	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	and\tagSENT_CONTENT	classifying\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Labeling\tagSENT_START	Confusion\tagSENT_CONTENT	shows\tagSENT_CONTENT	a\tagSENT_CONTENT	confusion\tagSENT_CONTENT	matrix\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	SRL\tagSENT_START	Gildea\tagSENT_CONTENT	and\tagSENT_CONTENT	Jurafsky\tagSENT_CONTENT	(\tagSENT_CONTENT	2002\tagSENT_CONTENT	)\tagSENT_CONTENT	developed\tagSENT_CONTENT	semantic_role_labeling\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	FrameNet\tagSENT_CONTENT	.\tagSENT_END	semantic_role_labeling\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	successfully\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	used\tagSENT_START	LSTMs\tagSENT_CONTENT	and\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	facilitate\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	also\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	on\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	attentional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	
1603.01354	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	for\tagSENT_CONTENT	two\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	tasks\tagSENT_CONTENT	-\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	corpus\tagSENT_CONTENT	for\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2003\tagSENT_CONTENT	corpus\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	obtain\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets-97.55\tagSENT_CONTENT	%\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	91.21\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Linguistic\tagSENT_START	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	stages\tagSENT_CONTENT	in\tagSENT_CONTENT	deep\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	importance\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	well\tagSENT_CONTENT	recognized\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	community\tagSENT_CONTENT	.\tagSENT_END	Natural\tagSENT_START	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	are\tagSENT_CONTENT	becoming\tagSENT_CONTENT	more\tagSENT_CONTENT	sophisticated\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	part\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	output\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	part-of-speech_tagging\tagtask	or\tagSENT_CONTENT	NER\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Several\tagSENT_START	RNN\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	named_entity_recognition\tagtask	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	competitive\tagSENT_CONTENT	performance\tagSENT_CONTENT	against\tagSENT_CONTENT	traditional\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	previous\tagSENT_CONTENT	stateof\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	97.55\tagmetric	%\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	91.21\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Network\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	CNN\tagSECTITLE_START	for\tagSECTITLE_CONTENT	Character\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Representation\tagSECTITLE_END	Bi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	directional\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_END	LSTM\tagSECTITLE_START	Unit\tagSECTITLE_END	BLSTM\tagSECTITLE_END	named_entity_recognition\tagtask	whose\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	proven\tagSENT_CONTENT	by\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	CRF\tagSECTITLE_END	BLSTM\tagSECTITLE_START	-\tagSECTITLE_CONTENT	CNNs\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	CRF\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	our\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	feeding\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagmetric	CRF\tagmetric	layer\tagmetric	.\tagSENT_END	Network\tagSECTITLE_START	Training\tagSECTITLE_END	Using\tagSENT_START	the\tagSENT_CONTENT	settings\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	training\tagSENT_CONTENT	requires\tagSENT_CONTENT	about\tagSENT_CONTENT	12\tagSENT_CONTENT	hours\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	8\tagSENT_CONTENT	hours\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Parameter\tagSECTITLE_START	Initialization\tagSECTITLE_END	Optimization\tagSECTITLE_START	Algorithm\tagSECTITLE_END	We\tagSENT_START	choose\tagSENT_CONTENT	an\tagSENT_CONTENT	initial\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	η\tagSENT_CONTENT	0\tagSENT_CONTENT	(\tagSENT_CONTENT	η\tagSENT_CONTENT	0\tagSENT_CONTENT	=\tagSENT_CONTENT	0.01\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	0.015\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	,\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.3\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	is\tagSENT_CONTENT	updated\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	epoch\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	as\tagSENT_CONTENT	η\tagSENT_CONTENT	t\tagSENT_CONTENT	=\tagSENT_CONTENT	η\tagSENT_CONTENT	0\tagSENT_CONTENT	/(1\tagSENT_END	Layer\tagSECTITLE_END	Tuning\tagSECTITLE_START	Hyper\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Parameters\tagSECTITLE_END	Experiments\tagSECTITLE_END	Data\tagSECTITLE_START	Sets\tagSECTITLE_END	As\tagSENT_START	mentioned\tagSENT_CONTENT	before\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_START	WSJ\tagSECTITLE_CONTENT	CoNLL2003\tagSECTITLE_END	Main\tagSECTITLE_START	Results\tagSECTITLE_END	Model\tagSECTITLE_END	Acc\tagmetric	.\tagSENT_CONTENT	  \tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	CRF\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	joint\tagSENT_CONTENT	decoding\tagSENT_CONTENT	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	Similar\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	observations\tagSENT_CONTENT	of\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	Senna\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	three\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CNNs\tagSENT_END	pro-\tagSENT_START	97.55\tagSENT_CONTENT	91.21\tagSENT_CONTENT	:\tagSENT_CONTENT	Results\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	choices\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	accuracy\tagmetric	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	F1\tagmetric	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Previous\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	POS\tagSECTITLE_START	Tagging\tagSECTITLE_END	NER\tagSECTITLE_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	:\tagSENT_START	Results\tagSENT_CONTENT	with\tagSENT_CONTENT	and\tagSENT_CONTENT	without\tagSENT_CONTENT	dropout\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	accuracy\tagmetric	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	F1\tagmetric	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	For\tagSENT_START	different\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	's\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	100\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	achieve\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	about\tagSENT_CONTENT	0.1\tagSENT_CONTENT	%\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	POS\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	0.9\tagSENT_CONTENT	%\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	NER\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	Senna\tagSENT_CONTENT	50\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	one\tagSENT_CONTENT	.\tagSENT_END	Google\tagSENT_START	's\tagSENT_CONTENT	Word2Vec\tagSENT_CONTENT	300\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	obtain\tagSENT_CONTENT	similar\tagSENT_CONTENT	performance\tagSENT_CONTENT	with\tagSENT_CONTENT	Senna\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	still\tagSENT_CONTENT	slightly\tagSENT_CONTENT	behind\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	.\tagSENT_END	POS\tagSECTITLE_START	NER\tagSECTITLE_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Dropout\tagSECTITLE_END	POS\tagSECTITLE_END	Dev\tagSECTITLE_END	OOV\tagSECTITLE_START	Error\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	several\tagSENT_CONTENT	different\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architectures\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	and\tagSENT_CONTENT	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	chunking\tagSENT_CONTENT	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	proposed\tagSENT_START	a\tagSENT_CONTENT	RNN\tagSENT_CONTENT	-\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	CharWNN\tagSENT_START	obtained\tagSENT_CONTENT	near\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.3\tagSENT_CONTENT	for\tagSENT_CONTENT	details\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	There\tagSENT_START	are\tagSENT_CONTENT	named_entity_recognition\tagtask	for\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	other\tagSENT_CONTENT	domains\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	(\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	and\tagSENT_CONTENT	Weibo\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	
N18-1158	title\tagSECTITLE_END	Ranking\tagSENT_START	Sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	Reinforcement\tagSENT_CONTENT	Learning\tagSENT_END	abstract\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	producing\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	while\tagSENT_CONTENT	preserving\tagSENT_CONTENT	its\tagSENT_CONTENT	principal\tagSENT_CONTENT	information\tagSENT_CONTENT	content\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	has\tagSENT_CONTENT	enjoyed\tagSENT_CONTENT	wide\tagSENT_CONTENT	popularity\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	potential\tagSENT_CONTENT	for\tagSENT_CONTENT	various\tagSENT_CONTENT	information\tagSENT_CONTENT	access\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	Modern\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	data\tagSENT_CONTENT	-\tagSENT_CONTENT	driven\tagSENT_CONTENT	,\tagSENT_CONTENT	taking\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architectures\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	continuous\tagSENT_CONTENT	features\tagSENT_CONTENT	without\tagSENT_CONTENT	recourse\tagSENT_CONTENT	to\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	tools\tagSENT_CONTENT	or\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	annotations\tagSENT_CONTENT	.\tagSENT_END	Extractive\tagSENT_START	systems\tagSENT_CONTENT	create\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	identifying\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	subsequently\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	)\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	argue\tagSENT_CONTENT	that\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	optimal\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	We\tagSENT_START	report\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	news\tagSENT_CONTENT	highlights\tagSENT_CONTENT	datasets\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	recently\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	testbeds\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Our\tagSENT_START	contributions\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	are\tagSENT_CONTENT	three\tagSENT_CONTENT	-\tagSENT_CONTENT	fold\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	sentence\tagSENT_CONTENT	ranking\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	;\tagSENT_CONTENT	corroborated\tagSENT_CONTENT	by\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	empirical\tagSENT_CONTENT	results\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	suited\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	summarization\tagSENT_CONTENT	task\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	user\tagSENT_CONTENT	studies\tagSENT_CONTENT	following\tagSENT_CONTENT	two\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	paradigms\tagSENT_CONTENT	which\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	systems\tagSENT_CONTENT	lag\tagSENT_CONTENT	behind\tagSENT_CONTENT	extractive\tagSENT_CONTENT	ones\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	latter\tagSENT_CONTENT	are\tagSENT_CONTENT	globally\tagSENT_CONTENT	trained\tagSENT_CONTENT	.\tagSENT_END	Summarization\tagSECTITLE_START	as\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Ranking\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	can\tagSENT_CONTENT	identify\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	events\tagSENT_CONTENT	that\tagSENT_CONTENT	correlate\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Document\tagSECTITLE_START	Encoder\tagSECTITLE_END	This\tagSENT_START	way\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	sure\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	also\tagSENT_CONTENT	considers\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	particularly\tagSENT_CONTENT	important\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	summarization\tagtask	with\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	ranks\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	their\tagSENT_CONTENT	extract\tagSENT_CONTENT	-\tagSENT_CONTENT	worthiness\tagSENT_CONTENT	and\tagSENT_END	We\tagSENT_START	learn\tagSENT_CONTENT	to\tagSENT_CONTENT	rank\tagSENT_CONTENT	sentences\tagSENT_CONTENT	by\tagSENT_CONTENT	training\tagSENT_CONTENT	our\tagSENT_CONTENT	network\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	directly\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagmetric	ROUGE\tagmetric	(\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Pitfalls\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Cross\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Entropy\tagSECTITLE_CONTENT	Loss\tagSECTITLE_END	Previous\tagSENT_START	work\tagSENT_CONTENT	optimizes\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	maximizing\tagSENT_CONTENT	p(y|D\tagSENT_CONTENT	,\tagSENT_CONTENT	θ\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	While\tagSENT_START	MLE\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	-\tagSENT_CONTENT	truth\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_END	(\tagSENT_START	last\tagSENT_CONTENT	column\tagSENT_CONTENT	)\tagSENT_CONTENT	shows\tagSENT_CONTENT	candidate\tagSENT_CONTENT	summaries\tagSENT_CONTENT	ranked\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	of\tagSENT_CONTENT	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	discrepancies\tagSENT_CONTENT	render\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	less\tagSENT_CONTENT	efficient\tagSENT_CONTENT	at\tagSENT_CONTENT	ranking\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	to\tagSENT_START	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	metric\tagSENT_CONTENT	used\tagSENT_CONTENT	attest\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	or\tagSENT_CONTENT	ROUGE\tagmetric	(\tagSENT_CONTENT	.\tagSENT_END	Policy\tagSECTITLE_START	Learning\tagSECTITLE_END	We\tagSENT_START	cast\tagSENT_CONTENT	summarization\tagtask	introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Reinforcement\tagSENT_CONTENT	Learning\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	.\tagSENT_END	REINFORCE\tagSENT_START	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	observation\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	expected\tagSENT_CONTENT	gradient\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	reward\tagSENT_CONTENT	function\tagSENT_CONTENT	(\tagmetric	ROUGE\tagmetric	,\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	case\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	computed\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	While\tagSENT_START	MLE\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	objective\tagSENT_CONTENT	in\tagSENT_CONTENT	Equation\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	discriminate\tagSENT_CONTENT	among\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	how\tagSENT_CONTENT	often\tagSENT_CONTENT	they\tagSENT_CONTENT	occur\tagSENT_CONTENT	in\tagSENT_CONTENT	high\tagSENT_CONTENT	scoring\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	with\tagSECTITLE_CONTENT	High\tagSECTITLE_CONTENT	Probability\tagSECTITLE_CONTENT	Samples\tagSECTITLE_END	Computing\tagSENT_START	the\tagSENT_CONTENT	expectation\tagSENT_CONTENT	term\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	prohibitive\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	extracts\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	therefore\tagSENT_CONTENT	limit\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	ofˆyofˆ\tagSENT_CONTENT	ofˆy\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	largest\tagSENT_CONTENT	probability\tagSENT_CONTENT	samplesˆYsamplesˆ\tagSENT_CONTENT	samplesˆY.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	discuss\tagSENT_CONTENT	implementation\tagSENT_CONTENT	details\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	protocol\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	systems\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Summarization\tagSECTITLE_START	Datasets\tagSECTITLE_END	We\tagSENT_START	used\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	splits\tagSENT_CONTENT	of\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	(\tagSENT_CONTENT	90,266/1,220/1,093\tagSENT_CONTENT	documents\tagSENT_CONTENT	for\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	196,961/12,148/10,397\tagSENT_CONTENT	for\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	We\tagSENT_START	tuned\tagSENT_CONTENT	summarization\tagtask	parameter\tagSENT_CONTENT	k\tagSENT_CONTENT	forˆYforˆ\tagSENT_CONTENT	forˆY\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	:\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	performs\tagSENT_CONTENT	best\tagSENT_CONTENT	with\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	5\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	15\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	LEAD\tagSECTITLE_END	REFRESH\tagSECTITLE_END	After\tagSENT_START	each\tagSENT_CONTENT	epoch\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	and\tagSENT_CONTENT	chose\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	performing\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSENT_START	We\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	second\tagSENT_CONTENT	experiment\tagSENT_CONTENT	assessed\tagSENT_CONTENT	the\tagSENT_CONTENT	degree\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	retains\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	following\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	previously\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	text\tagSENT_CONTENT	compression\tagSENT_END	We\tagSENT_START	used\tagSENT_CONTENT	their\tagSENT_CONTENT	code\tagSENT_CONTENT	(\tagSENT_CONTENT	https://\tagSENT_CONTENT	github.com/cheng6076/NeuralSum\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	ROUGE\tagmetric	F\tagmetric	1\tagmetric	scores\tagmetric	on\tagSENT_CONTENT	both\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	did\tagSENT_CONTENT	not\tagSENT_CONTENT	include\tagSENT_CONTENT	output\tagSENT_CONTENT	from\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	Tan\tagSENT_CONTENT	and\tagSENT_CONTENT	Wan\tagSENT_CONTENT	(\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	study\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	anonymized\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	as\tagSENT_CONTENT	result\tagSENT_CONTENT	produce\tagSENT_CONTENT	summarization\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	comparable\tagSENT_CONTENT	to\tagSENT_CONTENT	ours\tagSENT_CONTENT	.\tagSENT_END	Subjects\tagSENT_START	were\tagSENT_CONTENT	shown\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	three\tagSENT_CONTENT	systems\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	LEAD\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	system\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	REFRESH\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Cross\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Entropy\tagSECTITLE_CONTENT	vs\tagSECTITLE_CONTENT	Reinforcement\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	in\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	REFRESH\tagSENT_CONTENT	is\tagSENT_CONTENT	superior\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	LEAD\tagSENT_CONTENT	baseline\tagSENT_CONTENT	and\tagSENT_CONTENT	extractive\tagSENT_CONTENT	systems\tagSENT_CONTENT	across\tagSENT_CONTENT	datasets\tagSENT_CONTENT	and\tagSENT_CONTENT	metrics\tagmetric	.\tagSENT_END	Their\tagSENT_START	system\tagSENT_CONTENT	lags\tagSENT_CONTENT	behind\tagSENT_CONTENT	their\tagSENT_CONTENT	LEAD\tagSENT_CONTENT	baseline\tagSENT_CONTENT	on\tagSENT_CONTENT	ROUGE\tagmetric	-\tagmetric	L\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN+DailyMail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	35.5\tagSENT_CONTENT	%\tagSENT_CONTENT	vs\tagSENT_CONTENT	35.3\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Despite\tagSENT_START	being\tagSENT_CONTENT	more\tagSENT_CONTENT	faithful\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	written\tagSENT_CONTENT	summaries\tagSENT_CONTENT	combine\tagSENT_CONTENT	several\tagSENT_CONTENT	pieces\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	document\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	systems\tagSENT_CONTENT	lag\tagSENT_CONTENT	behind\tagSENT_CONTENT	the\tagSENT_CONTENT	LEAD\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluation\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Question\tagSECTITLE_CONTENT	Answering\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	QA\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	column\tagSENT_CONTENT	of\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	pattern\tagSENT_CONTENT	as\tagSENT_CONTENT	ROUGE\tagmetric	in\tagSENT_CONTENT	,\tagSENT_CONTENT	differences\tagSENT_CONTENT	among\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	now\tagSENT_CONTENT	greatly\tagSENT_CONTENT	amplified\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	manually\tagSENT_CONTENT	define\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	rank\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	their\tagSENT_CONTENT	salience\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	or\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	documents\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Like\tagSENT_START	traditional\tagSENT_CONTENT	methods\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	approaches\tagSENT_CONTENT	also\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	mismatch\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	objective\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	criterion\tagSENT_CONTENT	(\tagmetric	e.g.\tagmetric	,\tagmetric	ROUGE\tagmetric	)\tagSENT_CONTENT	used\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Their\tagSENT_START	agent\tagSENT_CONTENT	observes\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	candidate\tagSENT_CONTENT	summary\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	executes\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	operation\tagSENT_CONTENT	that\tagSENT_CONTENT	produces\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	selecting\tagSENT_CONTENT	a\tagSENT_CONTENT	not\tagSENT_CONTENT	-\tagSENT_CONTENT	yet\tagSENT_CONTENT	-\tagSENT_CONTENT	selected\tagSENT_CONTENT	sentence\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	receives\tagSENT_CONTENT	a\tagSENT_CONTENT	delayed\tagSENT_CONTENT	reward\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	tf\tagSENT_CONTENT	*\tagSENT_CONTENT	idf\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	any\tagSENT_CONTENT	attempts\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	ranker\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Conclusions\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	developed\tagSENT_CONTENT	summarization\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	globally\tagSENT_CONTENT	trained\tagSENT_CONTENT	by\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	.\tagSENT_END	
context-dependent-sentiment-analysis-in-user-generated-videos	title\tagSECTITLE_END	multimodal_sentiment_analysis\tagtask	in\tagSENT_CONTENT	User\tagSENT_CONTENT	-\tagSENT_CONTENT	Generated\tagSENT_CONTENT	Videos\tagSENT_END	abstract\tagSECTITLE_END	multimodal_emotion_recognition\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	developing\tagSENT_CONTENT	area\tagSENT_CONTENT	of\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	involves\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiments\tagSENT_CONTENT	in\tagSENT_CONTENT	videos\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	multimodal_sentiment_analysis\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	'\tagSENT_CONTENT	suitcase\tagSENT_CONTENT	'\tagSENT_CONTENT	research\tagSENT_CONTENT	problem\tagSENT_CONTENT	that\tagSENT_CONTENT	requires\tagSENT_CONTENT	tackling\tagSENT_CONTENT	many\tagSENT_CONTENT	NLP\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	aspect\tagSENT_CONTENT	extraction\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	concept\tagSENT_CONTENT	extraction\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	sarcasm\tagSENT_CONTENT	detection\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	.\tagSENT_END	multimodal_sentiment_analysis\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	performed\tagSENT_CONTENT	at\tagSENT_CONTENT	different\tagSENT_CONTENT	granularity\tagSENT_CONTENT	levels\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	subjectivity\tagSENT_CONTENT	detection\tagSENT_CONTENT	simply\tagSENT_CONTENT	classifies\tagSENT_CONTENT	data\tagSENT_CONTENT	as\tagSENT_CONTENT	either\tagSENT_CONTENT	subjective\tagSENT_CONTENT	(\tagSENT_CONTENT	opinionated\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	objective\tagSENT_CONTENT	(\tagSENT_CONTENT	neutral\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	polarity\tagSENT_CONTENT	detection\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	determining\tagSENT_CONTENT	whether\tagSENT_CONTENT	subjective\tagSENT_CONTENT	data\tagSENT_CONTENT	indicate\tagSENT_CONTENT	positive\tagSENT_CONTENT	or\tagSENT_CONTENT	negative\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	.\tagSENT_END	multimodal_emotion_recognition\tagtask	further\tagSENT_CONTENT	breaks\tagSENT_CONTENT	down\tagSENT_CONTENT	the\tagSENT_CONTENT	inferred\tagSENT_CONTENT	polarity\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	emotions\tagSENT_CONTENT	conveyed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	subjective\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	joy\tagSENT_CONTENT	or\tagSENT_CONTENT	anticipation\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	fear\tagSENT_CONTENT	or\tagSENT_CONTENT	disgust\tagSENT_CONTENT	.\tagSENT_END	Even\tagSENT_START	though\tagSENT_CONTENT	the\tagSENT_CONTENT	primary\tagSENT_CONTENT	focus\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	in\tagSENT_CONTENT	videos\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	finergrained\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	multimodal_emotion_recognition\tagtask	and\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	have\tagSENT_CONTENT	become\tagSENT_CONTENT	anew\tagSENT_CONTENT	trend\tagSENT_CONTENT	in\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	,\tagSENT_CONTENT	helping\tagSENT_CONTENT	users\tagSENT_CONTENT	and\tagSENT_CONTENT	companies\tagSENT_CONTENT	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	extract\tagSENT_CONTENT	the\tagSENT_CONTENT	opinions\tagSENT_CONTENT	expressed\tagSENT_CONTENT	in\tagSENT_CONTENT	user\tagSENT_CONTENT	-\tagSENT_CONTENT	generated\tagSENT_CONTENT	content\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	videos\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	video\tagSENT_CONTENT	data\tagSENT_CONTENT	helps\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	robust\tagSENT_CONTENT	emotion\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	multimodal_sentiment_analysis\tagtask	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	tagging\tagSENT_CONTENT	every\tagSENT_CONTENT	utterance\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	video\tagSENT_CONTENT	with\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	(\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	assigning\tagSENT_CONTENT	a\tagSENT_CONTENT	unique\tagSENT_CONTENT	label\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	video\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	of\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	topics\tagSENT_CONTENT	covered\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	speaker\tagSENT_CONTENT	throughout\tagSENT_CONTENT	his\tagSENT_CONTENT	/\tagSENT_CONTENT	her\tagSENT_CONTENT	speech\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	producing\tagSENT_CONTENT	interesting\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	.\tagSENT_END	are\tagSENT_START	the\tagSENT_CONTENT	role\tagSENT_CONTENT	of\tagSENT_CONTENT	speaker\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	versus\tagSENT_CONTENT	speaker\tagSENT_CONTENT	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	impact\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	modality\tagSENT_CONTENT	across\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	generalization\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	The\tagSENT_START	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	organized\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	brief\tagSENT_CONTENT	literature\tagSENT_CONTENT	review\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	;\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	describes\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	;\tagSENT_CONTENT	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	and\tagSENT_CONTENT	discussion\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	;\tagSENT_CONTENT	finally\tagSENT_CONTENT	,\tagSENT_CONTENT	Section\tagSENT_CONTENT	5\tagSENT_CONTENT	concludes\tagSENT_CONTENT	the\tagSENT_CONTENT	paper\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	multimodal_sentiment_analysis\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	broadly\tagSENT_CONTENT	categorized\tagSENT_CONTENT	into\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	and\tagSENT_CONTENT	statistics\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	bases\tagSENT_CONTENT	was\tagSENT_CONTENT	initially\tagSENT_CONTENT	more\tagSENT_CONTENT	popular\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	polarity\tagSENT_CONTENT	in\tagSENT_CONTENT	text\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	have\tagSENT_CONTENT	recently\tagSENT_CONTENT	been\tagSENT_CONTENT	using\tagSENT_CONTENT	statistics\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	statistical\tagSENT_CONTENT	methods\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Recent\tagSENT_START	studies\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	(\tagSENT_CONTENT	have\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	identifying\tagSENT_CONTENT	relevant\tagSENT_CONTENT	acoustic\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	frequency\tagSENT_CONTENT	(\tagSENT_CONTENT	pitch\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	intensity\tagSENT_CONTENT	of\tagSENT_CONTENT	utterance\tagSENT_CONTENT	,\tagSENT_CONTENT	bandwidth\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	duration\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	for\tagSENT_CONTENT	fusing\tagSENT_CONTENT	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	visual\tagSENT_CONTENT	modalities\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	two\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	early\tagSENT_CONTENT	works\tagSENT_CONTENT	were\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	works\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	system\tagSENT_CONTENT	yielded\tagSENT_CONTENT	a\tagmetric	higher\tagmetric	accuracy\tagmetric	than\tagSENT_CONTENT	any\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	874\tagSECTITLE_END	A.\tagSECTITLE_START	Context\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Independent\tagSECTITLE_CONTENT	Unimodal\tagSECTITLE_CONTENT	UtteranceLevel\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	B.\tagSECTITLE_START	Contextual\tagSECTITLE_CONTENT	Unimodal\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Multimodal\tagSECTITLE_CONTENT	Classification\tagSECTITLE_END	We\tagSENT_START	experimentally\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	proposed\tagSENT_CONTENT	framework\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	over\tagSENT_CONTENT	traditional\tagSENT_CONTENT	frameworks\tagSENT_CONTENT	.\tagSENT_END	Extracting\tagSECTITLE_START	Context\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Independent\tagSECTITLE_CONTENT	Unimodal\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Initially\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	separately\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	relation\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	text\tagSECTITLE_START	-\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Textual\tagSECTITLE_CONTENT	Features\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	represent\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	as\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	constituent\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Each\tagmetric	utterance\tagmetric	is\tagSENT_CONTENT	wrapped\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	window\tagSENT_CONTENT	of\tagSENT_CONTENT	50\tagSENT_CONTENT	words\tagSENT_CONTENT	which\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	convolution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	utterance\tagSENT_CONTENT	learns\tagSENT_CONTENT	abstract\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	phrases\tagSENT_CONTENT	equipped\tagSENT_CONTENT	with\tagSENT_CONTENT	implicit\tagSENT_CONTENT	semantic\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	successive\tagSENT_CONTENT	layer\tagSENT_CONTENT	spans\tagSENT_CONTENT	over\tagSENT_CONTENT	increasing\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	openSMILE\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Audio\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Taking\tagSENT_START	into\tagSENT_CONTENT	account\tagmetric	all\tagSENT_CONTENT	functionals\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	LLD\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtained\tagSENT_CONTENT	6373\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	3D\tagSECTITLE_START	-\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Visual\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	The\tagSENT_START	activation\tagSENT_CONTENT	values\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	dense\tagSENT_CONTENT	layer\tagSENT_CONTENT	are\tagSENT_CONTENT	finally\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	video\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	.\tagSENT_END	Context\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Dependent\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	We\tagSENT_START	hypothesize\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	within\tagSENT_CONTENT	a\tagSENT_CONTENT	video\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	utterance\tagSENT_CONTENT	dependency\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	This\tagSENT_START	calls\tagSENT_CONTENT	fora\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	takes\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	such\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	these\tagSENT_CONTENT	might\tagSENT_CONTENT	have\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	utterance\tagSENT_CONTENT	.\tagSENT_END	Long\tagSECTITLE_START	Short\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Memory\tagSECTITLE_END	Contextual\tagSECTITLE_START	LSTM\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	Let\tagSENT_START	multimodal_emotion_recognition\tagtask	have\tagSENT_CONTENT	dimension\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	is\tagSENT_CONTENT	thus\tagSENT_CONTENT	represented\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	x\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	t\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	t\tagSENT_CONTENT	th\tagSENT_CONTENT	utterance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	video\tagSENT_CONTENT	i.\tagSENT_CONTENT	For\tagSENT_CONTENT	a\tagSENT_CONTENT	video\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	collect\tagSENT_CONTENT	the\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	utterances\tagSENT_CONTENT	in\tagSENT_CONTENT	it\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_END	Training\tagSECTITLE_END	Fusion\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Modalities\tagSECTITLE_END	We\tagSENT_START	accomplish\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	through\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	frameworks\tagSENT_CONTENT	,\tagSENT_CONTENT	described\tagSENT_CONTENT	below\tagSENT_CONTENT	.\tagSENT_END	Non\tagSECTITLE_START	-\tagSECTITLE_CONTENT	hierarchical\tagSECTITLE_CONTENT	Framework\tagSECTITLE_END	Hierarchical\tagSECTITLE_START	Framework\tagSECTITLE_END	Contextual\tagSENT_START	unimodal\tagSENT_CONTENT	features\tagSENT_CONTENT	can\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	explained\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.3.1\tagSENT_CONTENT	.\tagSENT_END	Context\tagSENT_START	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	from\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.1\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	fed\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	.\tagSENT_END	Weight\tagSECTITLE_END	multimodal_sentiment_analysis\tagtask	:\tagSENT_CONTENT	15\tagSENT_CONTENT	:\tagSENT_END	23\tagSECTITLE_START	:\tagSECTITLE_END	Multimodal\tagSECTITLE_START	Sentiment\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	MOSI\tagdataset	The\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	dataset\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	rich\tagSENT_CONTENT	in\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	where\tagSENT_CONTENT	93\tagSENT_CONTENT	people\tagSENT_CONTENT	review\tagSENT_CONTENT	topics\tagSENT_CONTENT	in\tagSENT_CONTENT	English\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	videos\tagSENT_CONTENT	are\tagSENT_CONTENT	segmented\tagSENT_CONTENT	with\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	scored\tagSENT_CONTENT	between\tagSENT_CONTENT	+3\tagSENT_CONTENT	(\tagSENT_CONTENT	strong\tagSENT_CONTENT	positive\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	-3\tagSENT_END	We\tagSENT_START	took\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	five\tagSENT_CONTENT	annotations\tagSENT_CONTENT	as\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	and\tagSENT_CONTENT	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	,\tagSENT_CONTENT	considered\tagSENT_CONTENT	only\tagSENT_CONTENT	two\tagSENT_CONTENT	classes\tagSENT_CONTENT	(\tagSENT_CONTENT	positive\tagSENT_CONTENT	and\tagSENT_CONTENT	negative\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Multimodal\tagSECTITLE_START	Emotion\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	Characteristic\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	robustness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	it\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	of\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	MOSI\tagSENT_CONTENT	and\tagSENT_CONTENT	MOUD\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	but\tagSENT_CONTENT	they\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	review\tagSENT_CONTENT	videos\tagSENT_CONTENT	spoken\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	English\tagSENT_CONTENT	and\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	IEMOCAP\tagSENT_START	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	MOSI\tagdataset	and\tagSENT_CONTENT	MOUD\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	emotion\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	Apart\tagSENT_START	from\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	IEMOCAP\tagSENT_CONTENT	dataset\tagSENT_CONTENT	was\tagSENT_CONTENT	created\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	method\tagSENT_CONTENT	than\tagSENT_CONTENT	MOSI\tagdataset	and\tagSENT_CONTENT	MOUD\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	two\tagSENT_CONTENT	datasets\tagSENT_CONTENT	were\tagSENT_CONTENT	developed\tagSENT_CONTENT	by\tagSENT_CONTENT	crawling\tagSENT_CONTENT	consumers\tagSENT_CONTENT	'\tagSENT_CONTENT	spontaneous\tagSENT_CONTENT	online\tagSENT_CONTENT	product\tagSENT_CONTENT	review\tagSENT_CONTENT	videos\tagSENT_CONTENT	from\tagSENT_CONTENT	popular\tagSENT_CONTENT	social\tagSENT_CONTENT	websites\tagSENT_CONTENT	and\tagSENT_CONTENT	later\tagSENT_CONTENT	labeled\tagSENT_CONTENT	with\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	As\tagSENT_START	pointed\tagSENT_CONTENT	out\tagSENT_CONTENT	by\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	acted\tagSENT_CONTENT	dataset\tagSENT_CONTENT	like\tagSENT_CONTENT	IEMOCAP\tagdataset	can\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	biased\tagSENT_CONTENT	labeling\tagSENT_CONTENT	and\tagSENT_CONTENT	incorrect\tagSENT_CONTENT	acting\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	further\tagSENT_CONTENT	cause\tagSENT_CONTENT	the\tagSENT_CONTENT	poor\tagSENT_CONTENT	generalizability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	acted\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Performance\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Different\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	of\tagSENT_CONTENT	different\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	network\tagSENT_CONTENT	variants\tagSENT_CONTENT	as\tagSENT_CONTENT	explained\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.2.3\tagSENT_CONTENT	and\tagSENT_CONTENT	comparison\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	this\tagSENT_CONTENT	reason\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	only\tagSENT_CONTENT	leverages\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Different\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	Variants\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	noted\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	sc\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	bc\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	perform\tagSENT_CONTENT	quite\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	and\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	higher\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvement\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	IEMO\tagSENT_CONTENT	-\tagSENT_CONTENT	CAP\tagSENT_CONTENT	dataset\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	necessity\tagSENT_CONTENT	of\tagSENT_CONTENT	modeling\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	utterances\tagSENT_CONTENT	as\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	multiclass\tagSENT_CONTENT	sequential\tagSENT_CONTENT	problem\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	person\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	frequently\tagSENT_CONTENT	change\tagSENT_CONTENT	emotions\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	compared\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	extracted\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	fashion\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_END	Importance\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Modalities\tagSECTITLE_END	As\tagSENT_START	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	have\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	On\tagSENT_START	MOSI\tagdataset	and\tagSENT_CONTENT	IEMOCAP\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	textual\tagSENT_CONTENT	classifier\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	over\tagSENT_CONTENT	other\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	textual\tagSENT_CONTENT	modality\tagSENT_CONTENT	,\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	textual\tagSENT_CONTENT	modes\tagSENT_CONTENT	,\tagSENT_CONTENT	boosts\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	IEMOCAP\tagdataset	by\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	margin\tagSENT_CONTENT	.\tagSENT_END	Generalization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	We\tagSENT_START	could\tagSENT_CONTENT	not\tagSENT_CONTENT	carryout\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	experiment\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	as\tagSENT_CONTENT	no\tagSENT_CONTENT	other\tagSENT_CONTENT	utterance\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	dataset\tagSENT_CONTENT	apart\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	IEMO\tagSENT_CONTENT	-\tagSENT_CONTENT	CAP\tagSENT_CONTENT	was\tagSENT_CONTENT	available\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	The\tagSENT_START	need\tagSENT_CONTENT	for\tagSENT_CONTENT	considering\tagSENT_CONTENT	context\tagSENT_CONTENT	dependency\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	prime\tagSENT_CONTENT	importance\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	is\tagSENT_CONTENT	expressed\tagSENT_CONTENT	implicitly\tagSENT_CONTENT	and\tagSENT_CONTENT	requires\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	mood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	speaker\tagSENT_CONTENT	and\tagSENT_CONTENT	his\tagSENT_CONTENT	/\tagSENT_CONTENT	her\tagSENT_CONTENT	general\tagSENT_CONTENT	opinion\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	film\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	roles\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	modality\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	done\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	developed\tagSENT_CONTENT	a\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	contextual\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	utterances\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	video\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	As\tagSENT_START	future\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	LSTMbased\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	and\tagSENT_CONTENT	its\tagSENT_CONTENT	specific\tagSENT_CONTENT	contribution\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	modality\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	
P17-1108	title\tagSECTITLE_END	summarization\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	Graph\tagSENT_CONTENT	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Attentional\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Model\tagSENT_END	abstract\tagSECTITLE_END	i\tagSENT_START	ve\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	ultimate\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	previously\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	investigated\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	immaturity\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	generation\tagSENT_CONTENT	techniques\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	fluent\tagSENT_CONTENT	,\tagSENT_CONTENT	condensed\tagSENT_CONTENT	summary\tagSENT_CONTENT	fora\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	keep\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	involves\tagSENT_CONTENT	sophisticated\tagSENT_CONTENT	techniques\tagSENT_CONTENT	including\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	content\tagSENT_CONTENT	organization\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	surface\tagSENT_CONTENT	realization\tagSENT_CONTENT	.\tagSENT_END	Success\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	witnessed\tagSENT_CONTENT	on\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	and\tagSENT_CONTENT	image\tagSENT_CONTENT	captioning\tagSENT_CONTENT	,\tagSENT_CONTENT	together\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	review\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	factors\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	saliency\tagSENT_CONTENT	,\tagSENT_CONTENT	fluency\tagSENT_CONTENT	,\tagSENT_CONTENT	coherence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	novelty\tagSENT_CONTENT	requirements\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	how\tagSENT_CONTENT	summarization\tagtask	can\tagSENT_CONTENT	discover\tagSENT_CONTENT	the\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Section\tagSENT_START	2\tagSENT_CONTENT	introduces\tagSENT_CONTENT	related\tagmetric	work\tagmetric	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Extractive\tagSECTITLE_START	Summarization\tagSECTITLE_CONTENT	Methods\tagSECTITLE_END	summarization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	categorized\tagSENT_CONTENT	to\tagSENT_CONTENT	extractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSENT_START	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	investigated\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Abstractive\tagSECTITLE_START	Summarization\tagSECTITLE_CONTENT	Methods\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	at\tagSENT_CONTENT	generating\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	understanding\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	for\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	success\tagSENT_CONTENT	is\tagSENT_CONTENT	achieved\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Some\tagSENT_START	recent\tagSENT_CONTENT	works\tagSENT_CONTENT	investigate\tagSENT_CONTENT	neural\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Our\tagSECTITLE_START	Method\tagSECTITLE_END	Overview\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	distinction\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	decoding\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	reference\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Encoder\tagSECTITLE_END	We\tagSENT_START	adopt\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	encoder\tagSENT_CONTENT	enc\tagSENT_CONTENT	word\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagmetric	words\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	s\tagSENT_CONTENT	i\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	encoder\tagSENT_CONTENT	enc\tagSENT_CONTENT	sent\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	d\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagmetric	word\tagmetric	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	appended\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	"\tagSENT_CONTENT	<\tagSENT_CONTENT	eos\tagSENT_CONTENT	>\tagSENT_END	Decoder\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	The\tagSENT_START	predicted\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	mapped\tagSENT_CONTENT	to\tagSENT_CONTENT	vectors\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	dimension\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	normalized\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	generating\tagSENT_CONTENT	the\tagmetric	words\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	.\tagSENT_END	Graph\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Mechanism\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	easy\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	summarize\tagSENT_CONTENT	the\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	sentences\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	G\tagSENT_CONTENT	is\tagSENT_CONTENT	constructed\tagSENT_CONTENT	to\tagSENT_CONTENT	rank\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Training\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Adamax\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	gradient\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	optimization\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagmetric	θ\tagSENT_CONTENT	.\tagSENT_END	Decoding\tagSECTITLE_START	Algorithm\tagSECTITLE_END	We\tagSENT_START	find\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	several\tagSENT_CONTENT	problems\tagSENT_CONTENT	during\tagSENT_CONTENT	the\tagSENT_CONTENT	generation\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	(\tagSENT_CONTENT	OOV\tagSENT_CONTENT	)\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	information\tagSENT_CONTENT	incorrectness\tagSENT_CONTENT	,\tagSENT_CONTENT	error\tagSENT_CONTENT	accumulation\tagSENT_CONTENT	and\tagSENT_CONTENT	repetition\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	We\tagSENT_START	conduct\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	corpora\tagSENT_CONTENT	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Implementation\tagSECTITLE_END	The\tagSENT_START	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	first\tagSENT_CONTENT	lowercased\tagSENT_CONTENT	and\tagSENT_CONTENT	tokenized\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	digit\tagSENT_CONTENT	characters\tagSENT_CONTENT	are\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	#\tagSENT_CONTENT	"\tagSENT_CONTENT	symbol\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	Theano\tagSENT_CONTENT	2\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Evaluation\tagSECTITLE_END	We\tagSENT_START	adopt\tagSENT_CONTENT	the\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	)\tagSENT_CONTENT	toolkit\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	conducted\tagSENT_CONTENT	summarization\tagtask	on\tagSENT_CONTENT	20\tagSENT_CONTENT	random\tagSENT_CONTENT	samples\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	compared\tagSENT_CONTENT	the\tagSENT_CONTENT	summaries\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	outputs\tagSENT_CONTENT	of\tagSENT_CONTENT	Lead-3\tagSENT_CONTENT	,\tagSENT_CONTENT	NN\tagSENT_CONTENT	-\tagSENT_CONTENT	SE\tagSENT_CONTENT	(\tagSENT_CONTENT	Cheng\tagSENT_CONTENT	and\tagSENT_END	Method\tagSECTITLE_END	The\tagSENT_START	output\tagSENT_CONTENT	summaries\tagSENT_CONTENT	of\tagSENT_CONTENT	NN\tagSENT_CONTENT	-\tagSENT_CONTENT	SE\tagSENT_CONTENT	are\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	authors\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	summaries\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	achieved\tagSENT_CONTENT	by\tagSENT_CONTENT	running\tagSENT_CONTENT	the\tagSENT_CONTENT	code\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	authors\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	repetition\tagSENT_CONTENT	also\tagSENT_CONTENT	causes\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	a\tagSENT_CONTENT	low\tagSENT_CONTENT	coherence\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Validation\tagSECTITLE_END	The\tagSENT_START	performance\tagSENT_CONTENT	is\tagSENT_CONTENT	significantly\tagSENT_CONTENT	improved\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	reasonable\tagSENT_CONTENT	γ\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	optimal\tagSENT_CONTENT	γ\tagSENT_CONTENT	value\tagSENT_CONTENT	is\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	chosen\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	.\tagSENT_END	w/o\tagSENT_START	SentenceBeam\tagSENT_CONTENT	29.6\tagSENT_CONTENT	9.3\tagSENT_CONTENT	19.1\tagSENT_CONTENT	w/o\tagSENT_CONTENT	BeamSearch\tagSENT_CONTENT	25.1\tagSENT_CONTENT	6.7\tagSENT_CONTENT	17.9\tagSENT_CONTENT	:\tagSENT_CONTENT	Results\tagSENT_CONTENT	of\tagSENT_CONTENT	removing\tagSENT_CONTENT	different\tagSENT_CONTENT	components\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	F1\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	Rouge\tagmetric	.\tagSENT_END	As\tagSENT_START	seen\tagSENT_CONTENT	from\tagSENT_CONTENT	Table\tagSENT_CONTENT	6\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	is\tagSENT_CONTENT	significantly\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	traditional\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Case\tagSECTITLE_START	Study\tagSECTITLE_END	summarization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	awareness\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	helps\tagSENT_CONTENT	prevent\tagSENT_CONTENT	from\tagSENT_CONTENT	always\tagSENT_CONTENT	generating\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	tackle\tagSENT_CONTENT	the\tagSENT_CONTENT	challenging\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	less\tagSENT_CONTENT	investigated\tagSENT_CONTENT	to\tagSENT_CONTENT	date\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	appealing\tagSENT_CONTENT	direction\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	and\tagSENT_CONTENT	lacks\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	
1606.03777	title\tagSECTITLE_END	dialogue_state_tracking\tagtask	abstract\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	their\tagSENT_CONTENT	dependency\tagSENT_CONTENT	on\tagSENT_CONTENT	either\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_CONTENT	Spoken\tagSENT_CONTENT	Language\tagSENT_CONTENT	Understanding\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	require\tagSENT_CONTENT	large\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	;\tagSENT_CONTENT	or\tagSENT_CONTENT	b\tagSENT_CONTENT	)\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	lexicons\tagSENT_CONTENT	for\tagSENT_CONTENT	capturing\tagSENT_CONTENT	some\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	variation\tagSENT_CONTENT	in\tagSENT_CONTENT	users\tagSENT_CONTENT	'\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	dialogue_state_tracking\tagtask	(\tagSENT_CONTENT	SDS\tagSENT_CONTENT	)\tagSENT_CONTENT	allow\tagSENT_CONTENT	users\tagSENT_CONTENT	to\tagSENT_CONTENT	interact\tagSENT_CONTENT	with\tagSENT_CONTENT	computer\tagSENT_CONTENT	applications\tagSENT_CONTENT	through\tagSENT_CONTENT	conversation\tagSENT_CONTENT	.\tagSENT_END	dialogue_state_tracking\tagtask	of\tagSENT_CONTENT	shared\tagSENT_CONTENT	tasks\tagSENT_CONTENT	has\tagSENT_CONTENT	provided\tagSENT_CONTENT	a\tagSENT_CONTENT	common\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	framework\tagSENT_CONTENT	accompanied\tagSENT_CONTENT	by\tagSENT_CONTENT	labelled\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	SLU\tagSENT_CONTENT	)\tagSENT_CONTENT	modules\tagSENT_CONTENT	to\tagSENT_CONTENT	address\tagSENT_CONTENT	lexical\tagSENT_CONTENT	variability\tagSENT_CONTENT	within\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Background\tagSECTITLE_END	Models\tagSENT_START	for\tagSENT_CONTENT	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	or\tagSENT_CONTENT	belief\tagSENT_CONTENT	tracking\tagSENT_CONTENT	,\tagSENT_CONTENT	were\tagSENT_CONTENT	introduced\tagSENT_CONTENT	as\tagSENT_CONTENT	components\tagSENT_CONTENT	of\tagSENT_CONTENT	spoken\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	handle\tagSENT_CONTENT	noisy\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	sources\tagSENT_CONTENT	of\tagSENT_CONTENT	uncertainty\tagSENT_CONTENT	in\tagSENT_CONTENT	understanding\tagSENT_CONTENT	a\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	goals\tagSENT_CONTENT	.\tagSENT_END	Joint\tagmetric	SLU\tagmetric	/\tagmetric	DST\tagmetric	Research\tagmetric	on\tagSENT_CONTENT	belief\tagSENT_CONTENT	tracking\tagSENT_CONTENT	has\tagSENT_CONTENT	found\tagSENT_CONTENT	it\tagSENT_CONTENT	advantageous\tagSENT_CONTENT	to\tagSENT_CONTENT	reason\tagSENT_CONTENT	about\tagSENT_CONTENT	SLU\tagSENT_CONTENT	and\tagSENT_CONTENT	DST\tagSENT_CONTENT	jointly\tagSENT_CONTENT	,\tagSENT_CONTENT	taking\tagSENT_CONTENT	ASR\tagSENT_CONTENT	predictions\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	generating\tagSENT_CONTENT	belief\tagSENT_CONTENT	states\tagSENT_CONTENT	as\tagSENT_CONTENT	output\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	primary\tagSENT_CONTENT	motivation\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	work\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	overcome\tagSENT_CONTENT	the\tagSENT_CONTENT	limitations\tagSENT_CONTENT	that\tagSENT_CONTENT	affect\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Neural\tagSECTITLE_START	Belief\tagSECTITLE_CONTENT	Tracker\tagSECTITLE_END	The\tagSENT_START	Neural\tagSENT_CONTENT	Belief\tagSENT_CONTENT	Tracker\tagSENT_CONTENT	(\tagSENT_CONTENT	NBT\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	the\tagSENT_CONTENT	slot\tagSENT_CONTENT	-\tagSENT_CONTENT	value\tagSENT_CONTENT	pairs\tagSENT_CONTENT	that\tagSENT_CONTENT	makeup\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	goal\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	turn\tagSENT_CONTENT	during\tagSENT_CONTENT	the\tagSENT_CONTENT	flow\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Representation\tagSECTITLE_START	Learning\tagSECTITLE_END	Let\tagSENT_START	u\tagSENT_CONTENT	represent\tagSENT_CONTENT	dialogue_state_tracking\tagtask	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	k\tagSENT_CONTENT	u\tagSENT_CONTENT	words\tagSENT_CONTENT	u\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	u\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	u\tagSENT_CONTENT	ku\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	NBT\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	(\tagSENT_CONTENT	by\tagSENT_CONTENT	design\tagSENT_CONTENT	)\tagSENT_CONTENT	better\tagSENT_CONTENT	suited\tagSENT_CONTENT	to\tagSENT_CONTENT	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	filters\tagSENT_CONTENT	interact\tagSENT_CONTENT	directly\tagSENT_CONTENT	with\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	utterance\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	their\tagSENT_CONTENT	noisy\tagSENT_CONTENT	summaries\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	NBT\tagSENT_CONTENT	-\tagSENT_CONTENT	DNN\tagSENT_CONTENT	's\tagSENT_CONTENT	cumulative\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	.\tagSENT_END	Semantic\tagSECTITLE_START	Decoding\tagSECTITLE_END	This\tagSENT_START	component\tagSENT_CONTENT	decides\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	expressed\tagSENT_CONTENT	an\tagSENT_CONTENT	intent\tagSENT_CONTENT	matching\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	candidate\tagSENT_CONTENT	pair\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	without\tagSENT_CONTENT	taking\tagSENT_CONTENT	dialogue_state_tracking\tagtask	into\tagSENT_CONTENT	account\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Context\tagSECTITLE_START	Modelling\tagSECTITLE_END	To\tagSENT_START	understand\tagSENT_CONTENT	some\tagSENT_CONTENT	queries\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	belief\tagSENT_CONTENT	tracker\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	the\tagSENT_CONTENT	flow\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	leading\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	latest\tagSENT_CONTENT	user\tagSENT_CONTENT	utterance\tagSENT_CONTENT	.\tagSENT_END	Belief\tagSECTITLE_START	State\tagSECTITLE_CONTENT	Update\tagSECTITLE_CONTENT	Mechanism\tagSECTITLE_END	In\tagSENT_START	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	belief\tagSENT_CONTENT	tracking\tagSENT_CONTENT	models\tagSENT_CONTENT	operate\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	automatic\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	ASR\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	requests\tagmetric	,\tagSENT_CONTENT	all\tagSENT_CONTENT	slots\tagSENT_CONTENT	in\tagSENT_CONTENT	Vt\tagSENT_CONTENT	req\tagSENT_CONTENT	are\tagSENT_CONTENT	deemed\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	requested\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	Both\tagSENT_START	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	user\tagSENT_CONTENT	conversations\tagSENT_CONTENT	with\tagSENT_CONTENT	taskoriented\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	systems\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	users\tagSENT_CONTENT	find\tagSENT_CONTENT	dialogue_state_tracking\tagtask	around\tagSENT_CONTENT	Cambridge\tagSENT_CONTENT	,\tagSENT_CONTENT	UK\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	divided\tagSENT_CONTENT	these\tagSENT_CONTENT	into\tagSENT_CONTENT	600\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	200\tagSENT_CONTENT	validation\tagSENT_CONTENT	and\tagSENT_CONTENT	400\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	Examples\tagSECTITLE_END	Goals\tagSENT_START	(\tagSENT_CONTENT	'\tagSENT_CONTENT	joint\tagmetric	goal\tagmetric	accuracy\tagmetric	'\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_END	Models\tagSECTITLE_END	For\tagSENT_START	WOZ\tagSENT_CONTENT	2.0\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	NBT\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	dialogue_state_tracking\tagtask	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	NBT\tagSENT_CONTENT	models\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagmetric	joint\tagmetric	goal\tagmetric	and\tagSENT_CONTENT	request\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Belief\tagSECTITLE_START	Tracking\tagSECTITLE_CONTENT	Performance\tagSECTITLE_END	By\tagSENT_START	comparison\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	language\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	subjects\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	DSTC2\tagSENT_CONTENT	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	rich\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	compensating\tagSENT_CONTENT	for\tagSENT_CONTENT	ASR\tagSENT_CONTENT	errors\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	hurdle\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	access\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	DSTC2\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	transcriptions\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	NBT\tagmetric	models\tagmetric	'\tagmetric	goal\tagmetric	accuracy\tagmetric	rises\tagSENT_CONTENT	to\tagSENT_CONTENT	0.96\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Importance\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Vector\tagSECTITLE_CONTENT	Spaces\tagSECTITLE_END	Paragram\tagSENT_START	-\tagSENT_CONTENT	SL999\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	significantly\tagSENT_CONTENT	)\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	and\tagSENT_CONTENT	XAVIER\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_state_tracking\tagtask	on\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	belief\tagSENT_CONTENT	tracking\tagSENT_CONTENT	(\tagSENT_CONTENT	NBT\tagSENT_CONTENT	)\tagSENT_CONTENT	framework\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	overcome\tagSENT_CONTENT	current\tagSENT_CONTENT	obstacles\tagSENT_CONTENT	to\tagSENT_CONTENT	deploying\tagSENT_CONTENT	dialogue_state_tracking\tagtask	in\tagSENT_CONTENT	real\tagSENT_CONTENT	-\tagSENT_CONTENT	world\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	
1705.05952	title\tagSECTITLE_END	A\tagSENT_START	Novel\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	Model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	Graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	Dependency\tagSENT_CONTENT	Parsing\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	learns\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	jointly\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	uses\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	shared\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	handling\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	engineering\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	extensive\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	19\tagSENT_CONTENT	languages\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Universal\tagSENT_CONTENT	Dependencies\tagSENT_CONTENT	project\tagSENT_CONTENT	,\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	outper\tagSENT_CONTENT	-\tagSENT_CONTENT	forms\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	Stack\tagSENT_CONTENT	-\tagSENT_CONTENT	propagation\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	real\tagSENT_CONTENT	-\tagSENT_CONTENT	world\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	those\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsers\tagSENT_CONTENT	rely\tagSENT_CONTENT	heavily\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	predicted\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	encountering\tagSENT_CONTENT	error\tagSENT_CONTENT	propagation\tagSENT_CONTENT	problems\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracies\tagmetric	drop\tagSENT_CONTENT	by\tagSENT_CONTENT	5+%\tagSENT_CONTENT	when\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	automatic\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	gold\tagSENT_CONTENT	ones\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	attempts\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	made\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	using\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	during\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	approaches\tagSENT_CONTENT	still\tagSENT_CONTENT	additionally\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	automatic\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	the\tagmetric	best\tagmetric	accuracy\tagmetric	.\tagSENT_END	Alternatively\tagSENT_START	,\tagSENT_CONTENT	joint\tagSENT_CONTENT	learning\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	has\tagSENT_CONTENT	gained\tagSENT_CONTENT	more\tagSENT_CONTENT	attention\tagSENT_CONTENT	because\tagSENT_CONTENT	:\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	more\tagSENT_CONTENT	accurate\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	could\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	improved\tagSENT_CONTENT	parsing\tagSENT_CONTENT	performance\tagSENT_CONTENT	and\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_END	the\tagSENT_START	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	could\tagSENT_CONTENT	help\tagSENT_CONTENT	resolve\tagSENT_CONTENT	POS\tagSENT_CONTENT	:\tagSENT_CONTENT	Illustration\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	jPTDP\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	learns\tagSENT_CONTENT	latent\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	shared\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	BiLSTMthe\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Not\tagSENT_START	using\tagSENT_CONTENT	any\tagSENT_CONTENT	external\tagSENT_CONTENT	resources\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	19\tagSENT_CONTENT	languages\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Universal\tagSENT_CONTENT	Dependencies\tagSENT_CONTENT	project\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	:\tagSENT_CONTENT	our\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	performs\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	strong\tagSENT_CONTENT	baselines\tagSENT_CONTENT	and\tagSENT_CONTENT	especially\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	Stack\tagSENT_CONTENT	-\tagSENT_CONTENT	propagation\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	joint\tagSECTITLE_CONTENT	model\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	new\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	call\tagSENT_CONTENT	jPTDP\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	 \tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	help\tagSENT_CONTENT	improve\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	performances\tagSENT_CONTENT	.\tagSENT_END	part-of-speech_tagging\tagtask	:\tagSENT_CONTENT	Using\tagSENT_CONTENT	shared\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	latent\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	representations\tagSENT_END	while\tagSENT_START	score\tagSENT_CONTENT	arc\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	m\tagSENT_CONTENT	)\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	arc\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	h\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	modifier\tagSENT_CONTENT	m\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	s.\tagSENT_CONTENT	Following\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	score\tagSENT_CONTENT	an\tagmetric	arc\tagmetric	by\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	MLP\tagSENT_CONTENT	with\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	node\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	(\tagSENT_CONTENT	MLP\tagSENT_CONTENT	arc\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	ctx\tagSENT_CONTENT	:\tagSENT_END	Given\tagSENT_START	an\tagmetric	arc\tagmetric	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	m\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	output\tagSENT_CONTENT	vector\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	The\tagSENT_START	final\tagSENT_CONTENT	training\tagSENT_CONTENT	objective\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	part-of-speech_tagging\tagtask	L\tagSENT_CONTENT	POS\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	loss\tagSENT_CONTENT	L\tagSENT_CONTENT	arc\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	labeling\tagSENT_CONTENT	loss\tagSENT_CONTENT	L\tagSENT_CONTENT	rel\tagSENT_CONTENT	.\tagSENT_END	Prior\tagSENT_START	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	joint\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	are\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	graphbased\tagSENT_CONTENT	method\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	setup\tagSECTITLE_END	and\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	multilingual\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	19\tagSENT_CONTENT	languages\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Universal\tagSENT_CONTENT	Dependencies\tagSENT_CONTENT	(\tagSENT_CONTENT	UD\tagdataset	)\tagSENT_END	Implementation\tagSECTITLE_START	details\tagSECTITLE_END	For\tagSENT_START	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	run\tagSENT_CONTENT	for\tagSENT_CONTENT	30\tagSENT_CONTENT	epochs\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagmetric	mixed\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	correctly\tagSENT_CONTENT	assigning\tagSENT_CONTENT	POS\tagSENT_CONTENT	tag\tagSENT_CONTENT	together\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency\tagSENT_CONTENT	arc\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	type\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	after\tagSENT_CONTENT	each\tagSENT_CONTENT	training\tagSENT_CONTENT	epoch\tagSENT_CONTENT	.\tagSENT_END	compares\tagSENT_START	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	jPTDP\tagSENT_END	Main\tagSECTITLE_START	results\tagSECTITLE_END	Regarding\tagSENT_START	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	jPTDP\tagSENT_END	MQuni\tagSECTITLE_START	at\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	CoNLL\tagSECTITLE_CONTENT	2017\tagSECTITLE_CONTENT	shared\tagSECTITLE_CONTENT	task\tagSECTITLE_END	For\tagSENT_START	each\tagSENT_CONTENT	treebank\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagmetric	mixed\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	after\tagSENT_CONTENT	each\tagSENT_CONTENT	training\tagSENT_CONTENT	epoch\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagmetric	highest\tagmetric	mixed\tagmetric	accuracy\tagmetric	.\tagSENT_END	These\tagSENT_START	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processed\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	-\tagSENT_CONTENT	U\tagSENT_CONTENT	test\tagSENT_CONTENT	files\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	participants\tagSENT_CONTENT	who\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	want\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	their\tagSENT_CONTENT	own\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	any\tagSENT_CONTENT	steps\tagSENT_CONTENT	preceding\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	:\tagSENT_CONTENT	tokenization\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	,\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	morphological\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	employ\tagSENT_CONTENT	the\tagSENT_CONTENT	tokenization\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	care\tagSENT_CONTENT	about\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	morphological\tagSENT_CONTENT	analysis\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processed\tagSENT_CONTENT	by\tagSENT_CONTENT	UDPipe\tagSENT_CONTENT	1.1\tagSENT_CONTENT	.\tagSENT_END	Recall\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	jointly\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	worth\tagSENT_CONTENT	noting\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	highest\tagSENT_CONTENT	rank\tagSENT_CONTENT	at\tagSENT_CONTENT	4\tagSENT_CONTENT	th\tagSENT_CONTENT	place\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	Big\tagSENT_CONTENT	category\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	4\tagSENT_CONTENT	th\tagSENT_CONTENT	on\tagSENT_CONTENT	average\tagSENT_CONTENT	over\tagSENT_CONTENT	55\tagSENT_CONTENT	big\tagSENT_CONTENT	treebank\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	novel\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	UD\tagSENT_START	)\tagSENT_CONTENT	v1.2\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	obtains\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	So\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	our\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	anew\tagSENT_CONTENT	strong\tagSENT_CONTENT	baseline\tagSENT_CONTENT	for\tagSENT_CONTENT	further\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	future\tagSENT_CONTENT	comparison\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	in\tagSENT_CONTENT	Table\tagSENT_CONTENT	3\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	UAS\tagSENT_CONTENT	and\tagSENT_CONTENT	LAS\tagSENT_CONTENT	accuracies\tagmetric	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	gold\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	UD\tagSENT_CONTENT	v2.0-CoNLL\tagSENT_CONTENT	2017\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	(\tagSENT_END	
P17-1089	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	To\tagSENT_START	learn\tagSENT_CONTENT	these\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsers\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	adapt\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	utterances\tagSENT_CONTENT	directly\tagSENT_CONTENT	to\tagSENT_CONTENT	SQL\tagSENT_CONTENT	thereby\tagSENT_CONTENT	bypassing\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	taking\tagSENT_CONTENT	full\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	SQL\tagmetric	's\tagmetric	querying\tagmetric	capabilities\tagmetric	,\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	immediately\tagSENT_CONTENT	deploy\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	online\tagSENT_CONTENT	to\tagSENT_CONTENT	solicit\tagSENT_CONTENT	questions\tagSENT_CONTENT	and\tagSENT_CONTENT	user\tagSENT_CONTENT	feedback\tagSENT_CONTENT	on\tagSENT_CONTENT	results\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	SQL\tagSENT_CONTENT	annotation\tagSENT_CONTENT	efforts\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	use\tagSENT_CONTENT	crowd\tagSENT_CONTENT	workers\tagSENT_CONTENT	from\tagSENT_CONTENT	skilled\tagSENT_CONTENT	markets\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	SQL\tagSENT_CONTENT	annotations\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	directly\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	model\tagSENT_CONTENT	improvement\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	being\tagSENT_CONTENT	easier\tagSENT_CONTENT	and\tagSENT_CONTENT	cheaper\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	than\tagSENT_CONTENT	logical\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	type\tagSENT_CONTENT	of\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	is\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	recent\tagSENT_CONTENT	ideas\tagSENT_CONTENT	in\tagSENT_CONTENT	sql_parsing\tagtask	,\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	cluding\tagSENT_CONTENT	batch\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	directly\tagSENT_CONTENT	produce\tagSENT_CONTENT	programs\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	regular\tagSENT_CONTENT	expressions\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	learning\tagSENT_CONTENT	from\tagSENT_CONTENT	paraphrases\tagSENT_CONTENT	(\tagSENT_CONTENT	often\tagSENT_CONTENT	gathered\tagSENT_CONTENT	through\tagSENT_CONTENT	crowdsourcing\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	learning\tagSENT_CONTENT	advances\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	in\tagSENT_CONTENT	batch\tagSENT_CONTENT	on\tagSENT_CONTENT	existing\tagmetric	datasets\tagmetric	and\tagSENT_CONTENT	through\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	online\tagSENT_CONTENT	experiment\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	interactive\tagSENT_CONTENT	setting\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Although\tagSENT_START	diverse\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representation\tagSENT_CONTENT	languages\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	with\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parserssuch\tagSENT_CONTENT	as\tagSENT_CONTENT	regular\tagSENT_CONTENT	expressions\tagSENT_CONTENT	,\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representations\tagSENT_CONTENT	(\tagSENT_CONTENT	AMR\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	systems\tagSENT_CONTENT	of\tagSENT_CONTENT	equations\tagmetric	(\tagSENT_CONTENT	)\tagSENT_CONTENT	-parsers\tagSENT_CONTENT	for\tagSENT_CONTENT	querying\tagSENT_CONTENT	databases\tagSENT_CONTENT	have\tagSENT_CONTENT	typically\tagSENT_CONTENT	used\tagSENT_CONTENT	either\tagSENT_CONTENT	logic\tagSENT_CONTENT	programs\tagSENT_CONTENT	,\tagSENT_CONTENT	lambda\tagSENT_CONTENT	calculus\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	λ\tagSENT_CONTENT	-\tagSENT_CONTENT	DCS\tagSENT_CONTENT	(\tagSENT_CONTENT	 \tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representation\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	few\tagSENT_CONTENT	systems\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	developed\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	generate\tagSENT_CONTENT	sql_parsing\tagtask	from\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	generate\tagSENT_CONTENT	sql_parsing\tagtask	from\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	Semantic\tagSENT_START	parsers\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	trained\tagSENT_CONTENT	from\tagSENT_CONTENT	various\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	annotations\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	labeled\tagSENT_CONTENT	queries\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagmetric	/\tagmetric	answer\tagmetric	pairs\tagmetric	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	binary\tagSENT_CONTENT	correct\tagSENT_CONTENT	/\tagSENT_CONTENT	incorrect\tagSENT_CONTENT	feedback\tagSENT_CONTENT	signals\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Feedback\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	that\tagSENT_CONTENT	deploys\tagSENT_CONTENT	a\tagSENT_CONTENT	preliminary\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	iteratively\tagSENT_CONTENT	improves\tagSENT_CONTENT	sql_parsing\tagtask	using\tagSENT_CONTENT	user\tagSENT_CONTENT	feedback\tagSENT_CONTENT	and\tagSENT_CONTENT	selective\tagSENT_CONTENT	query\tagSENT_CONTENT	annotation\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	neural\tagSENT_CONTENT	model\tagSENT_CONTENT	N\tagSENT_CONTENT	is\tagSENT_CONTENT	initially\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	data\tagSENT_CONTENT	T\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	schema\tagSENT_CONTENT	templates\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	ready\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	new\tagmetric	user\tagmetric	questions\tagmetric	,\tagSENT_CONTENT	n.\tagSENT_END	Semantic\tagSECTITLE_START	Parsing\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	SQL\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	mapping\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	directly\tagSENT_CONTENT	to\tagSENT_CONTENT	sql_parsing\tagtask	and\tagSENT_CONTENT	this\tagSENT_CONTENT	allows\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	scale\tagSENT_CONTENT	our\tagSENT_CONTENT	feedback\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	easily\tagSENT_CONTENT	crowdsourcing\tagSENT_CONTENT	labels\tagSENT_CONTENT	when\tagSENT_CONTENT	necessary\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	global\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	anonymized\tagSENT_CONTENT	utterance\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.2\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	encoded\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	decoded\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	predict\tagSENT_CONTENT	SQL\tagmetric	query\tagmetric	tokens\tagmetric	.\tagSENT_END	Entity\tagSECTITLE_START	Anonymization\tagSECTITLE_END	For\tagSENT_START	every\tagmetric	span\tagmetric	of\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	starting\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	span\tagSENT_CONTENT	size\tagSENT_CONTENT	and\tagSENT_CONTENT	progressively\tagSENT_CONTENT	reducing\tagSENT_CONTENT	it\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	query\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	engine\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	scheme\tagSENT_CONTENT	to\tagSENT_CONTENT	retrieve\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	closely\tagSENT_CONTENT	matches\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	replace\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	's\tagSENT_CONTENT	type\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Augmentation\tagSECTITLE_END	Schema\tagSENT_START	Templates\tagSENT_CONTENT	To\tagSENT_CONTENT	bootstrap\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	simple\tagmetric	questions\tagmetric	initially\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	defined\tagSENT_CONTENT	22\tagSENT_CONTENT	language\tagSENT_CONTENT	/\tagSENT_CONTENT	SQL\tagSENT_CONTENT	templates\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	schema\tagSENT_CONTENT	-\tagSENT_CONTENT	agnostic\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	database\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	perform\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	expansion\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	examples\tagSENT_CONTENT	labeled\tagSENT_CONTENT	during\tagSENT_CONTENT	sql_parsing\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	initial\tagSENT_CONTENT	seed\tagSENT_CONTENT	examples\tagSENT_CONTENT	from\tagSENT_CONTENT	schema\tagSENT_CONTENT	templates\tagSENT_CONTENT	.\tagSENT_END	Benchmark\tagSECTITLE_START	Experiments\tagSECTITLE_END	We\tagSENT_START	demonstrate\tagSENT_CONTENT	this\tagSENT_CONTENT	result\tagSENT_CONTENT	by\tagSENT_CONTENT	running\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	sql_parsing\tagtask	,\tagSENT_CONTENT	GEO880\tagSENT_CONTENT	and\tagSENT_CONTENT	ATIS\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	sets\tagSECTITLE_END	ATIS\tagdataset	is\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	5,418\tagSENT_CONTENT	utterances\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	flight\tagSENT_CONTENT	booking\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	accompanied\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	relational\tagSENT_CONTENT	database\tagSENT_CONTENT	and\tagSENT_CONTENT	SQL\tagSENT_CONTENT	queries\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	the\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Methodology\tagSECTITLE_END	The\tagSENT_START	development\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	tuning\tagSENT_CONTENT	and\tagSENT_CONTENT	early\tagmetric	stopping\tagmetric	.\tagSENT_END	Results\tagSECTITLE_END	System\tagSECTITLE_END	Accuracy\tagSENT_START	of\tagSENT_CONTENT	SQL\tagSENT_CONTENT	query\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	ATIS\tagdataset	;\tagSENT_CONTENT	convert\tagSENT_CONTENT	to\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	SQL\tagSENT_CONTENT	;\tagSENT_CONTENT	†\tagSENT_CONTENT	measure\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	logical\tagSENT_CONTENT	form\tagSENT_CONTENT	,\tagSENT_CONTENT	other\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	ours\tagSENT_CONTENT	,\tagSENT_CONTENT	use\tagSENT_CONTENT	denotations\tagSENT_CONTENT	.\tagSENT_END	ambiguously\tagSENT_START	mapped\tagSENT_CONTENT	to\tagSENT_CONTENT	schema\tagSENT_CONTENT	elements\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	latter\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	reranking\tagSENT_CONTENT	approach\tagSENT_CONTENT	that\tagSENT_CONTENT	also\tagSENT_CONTENT	limits\tagSENT_CONTENT	the\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	sql_parsing\tagtask	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	handled\tagSENT_CONTENT	.\tagSENT_END	Accuracies\tagSENT_START	are\tagSENT_CONTENT	reported\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	dev\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	ATIS\tagdataset	and\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	validation\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	Geo880\tagSENT_CONTENT	.\tagSENT_END	Interactive\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	After\tagSENT_START	three\tagSENT_CONTENT	train\tagSENT_CONTENT	-\tagSENT_CONTENT	deploy\tagSENT_CONTENT	cycles\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	correctly\tagSENT_CONTENT	answered\tagSENT_CONTENT	63.51\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	user\tagmetric	's\tagmetric	questions\tagmetric	.\tagSENT_END	User\tagSECTITLE_START	Interface\tagSECTITLE_END	The\tagmetric	second\tagmetric	assist\tagmetric	is\tagSENT_CONTENT	utterance\tagSENT_CONTENT	paraphrasing\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	another\tagSENT_CONTENT	utterance\tagSENT_CONTENT	that\tagSENT_CONTENT	maps\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	SQL\tagSENT_CONTENT	query\tagSENT_CONTENT	.\tagSENT_END	Three\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Stage\tagSECTITLE_CONTENT	Online\tagSECTITLE_CONTENT	Experiment\tagSECTITLE_END	The\tagSENT_START	crowd\tagSENT_CONTENT	worker\tagSENT_CONTENT	had\tagSENT_CONTENT	prior\tagSENT_CONTENT	experience\tagSENT_CONTENT	in\tagSENT_CONTENT	writing\tagSENT_CONTENT	sql_parsing\tagtask	and\tagSENT_CONTENT	was\tagSENT_CONTENT	hired\tagSENT_CONTENT	from\tagSENT_CONTENT	Upwork\tagSENT_CONTENT	after\tagSENT_CONTENT	completing\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	SQL\tagSENT_CONTENT	test\tagSENT_CONTENT	.\tagSENT_END	Stage\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Stage\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	Stage\tagSECTITLE_CONTENT	3\tagSECTITLE_END	SCHOLAR\tagSECTITLE_START	dataset\tagSECTITLE_END	Our\tagSENT_START	parser\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	67\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagmetric	train\tagmetric	/\tagmetric	test\tagmetric	split\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	fully\tagSENT_CONTENT	supervised\tagSENT_CONTENT	setting\tagSENT_CONTENT	.\tagSENT_END	Simulated\tagSECTITLE_START	Interactive\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	shows\tagSENT_START	accuracies\tagSENT_CONTENT	on\tagSENT_CONTENT	GEO880\tagSENT_CONTENT	and\tagSENT_CONTENT	ATIS\tagdataset	respectively\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	batch\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	previous\tagSENT_CONTENT	batches\tagSENT_CONTENT	.\tagSENT_END	Templates\tagSENT_START	did\tagSENT_CONTENT	not\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	ATIS\tagdataset	,\tagSENT_CONTENT	possibly\tagSENT_CONTENT	because\tagSENT_CONTENT	most\tagSENT_CONTENT	ATIS\tagSENT_CONTENT	queries\tagSENT_CONTENT	involve\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	city\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	destination\tagSENT_CONTENT	city\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	our\tagSENT_CONTENT	templates\tagSENT_CONTENT	only\tagSENT_CONTENT	generate\tagSENT_CONTENT	questions\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	entity\tagSENT_CONTENT	type\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	comparable\tagSENT_CONTENT	in\tagSENT_CONTENT	performance\tagSENT_CONTENT	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	either\tagSENT_CONTENT	map\tagSENT_CONTENT	from\tagSENT_CONTENT	utterances\tagSENT_CONTENT	to\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	generate\tagSENT_CONTENT	SQL\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	GEO880\tagSENT_CONTENT	and\tagSENT_CONTENT	ATIS\tagdataset	.\tagSENT_END	
D16-1041	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	In\tagSENT_START	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	taxonomy_learning\tagtask	have\tagSENT_CONTENT	enabled\tagSENT_CONTENT	a\tagSENT_CONTENT	remarkable\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	novel\tagSENT_CONTENT	NLP\tagSENT_CONTENT	techniques\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	to\tagSENT_CONTENT	lexical\tagSENT_CONTENT	semantics\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	various\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	word\tagSENT_CONTENT	sense\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	not\tagSENT_CONTENT	being\tagSENT_CONTENT	taxonomy_learning\tagtask	per\tagSENT_CONTENT	se\tagSENT_CONTENT	,\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	systems\tagSENT_CONTENT	for\tagSENT_CONTENT	Information\tagSENT_CONTENT	Extraction\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	NELL\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	rely\tagSENT_CONTENT	crucially\tagSENT_CONTENT	on\tagSENT_CONTENT	taxonomized\tagSENT_CONTENT	concepts\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	relations\tagSENT_CONTENT	within\tagSENT_CONTENT	their\tagSENT_CONTENT	learning\tagSENT_CONTENT	process\tagSENT_CONTENT	.\tagSENT_END	taxonomy_learning\tagtask	is\tagSENT_CONTENT	roughly\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	twostep\tagSENT_CONTENT	process\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	is\tagSENT_CONTENT	-\tagSENT_CONTENT	a\tagSENT_CONTENT	(\tagSENT_CONTENT	hypernymic\tagSENT_CONTENT	)\tagSENT_CONTENT	relation\tagSENT_CONTENT	de\tagSENT_CONTENT	-\tagSENT_CONTENT	tection\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	graph\tagSENT_CONTENT	induction\tagSENT_CONTENT	.\tagSENT_END	Compared\tagSENT_START	to\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	TAXO\tagSENT_CONTENT	-\tagSENT_CONTENT	EMBED\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	more\tagSENT_CONTENT	refined\tagSENT_CONTENT	and\tagSENT_CONTENT	unambiguous\tagSENT_CONTENT	hypernymic\tagSENT_CONTENT	relations\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	sense\tagSENT_CONTENT	level\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	direct\tagSENT_CONTENT	application\tagSENT_CONTENT	in\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	semantic\tagSENT_CONTENT	search\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Prior\tagSENT_START	to\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	system\tagSENT_CONTENT	addresses\tagSENT_CONTENT	this\tagSENT_CONTENT	discrepancy\tagSENT_CONTENT	via\tagSENT_CONTENT	taxonomy_learning\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	tuning\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	drawback\tagSENT_CONTENT	of\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	apart\tagSENT_CONTENT	from\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	issues\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	require\tagSENT_CONTENT	additional\tagSENT_CONTENT	and\tagSENT_CONTENT	error\tagSENT_CONTENT	-\tagSENT_CONTENT	prone\tagSENT_CONTENT	steps\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	semantic\tagSENT_CONTENT	clusters\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	their\tagSENT_CONTENT	inherently\tagSENT_CONTENT	broader\tagSENT_CONTENT	scope\tagSENT_CONTENT	,\tagSENT_CONTENT	OIE\tagSENT_CONTENT	approaches\tagSENT_CONTENT	are\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	high\tagSENT_CONTENT	coverage\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	they\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	noisier\tagSENT_CONTENT	data\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	taxonomy_learning\tagtask	.\tagSENT_END	Preliminaries\tagSECTITLE_END	Each\tagSENT_START	synset\tagSENT_CONTENT	is\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	lexicalizations\tagSENT_CONTENT	or\tagSENT_CONTENT	senses\tagSENT_CONTENT	)\tagSENT_CONTENT	representing\tagSENT_CONTENT	taxonomy_learning\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	Data\tagSECTITLE_END	Sense\tagSECTITLE_START	vectors\tagSECTITLE_END	Methodology\tagSECTITLE_END	Domain\tagSECTITLE_START	Clustering\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	highly\tagSENT_CONTENT	reliable\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	domain\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	those\tagSENT_CONTENT	synsets\tagSENT_CONTENT	whose\tagSENT_CONTENT	maximum\tagSENT_CONTENT	similarity\tagSENT_CONTENT	score\tagSENT_CONTENT	is\tagSENT_CONTENT	below\tagSENT_CONTENT	a\tagSENT_CONTENT	certain\tagSENT_CONTENT	threshold\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	taxonomy_learning\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	Data\tagSECTITLE_CONTENT	Expansion\tagSECTITLE_END	Learning\tagSECTITLE_START	a\tagSECTITLE_CONTENT	Hypernym\tagSECTITLE_CONTENT	Detection\tagSECTITLE_CONTENT	Matrix\tagSECTITLE_END	where\tagSECTITLE_START	C\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	is\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	cluster\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	BabelNet\tagSECTITLE_CONTENT	synsets\tagSECTITLE_CONTENT	labelled\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	domain\tagSECTITLE_CONTENT	d.\tagSECTITLE_END	Evaluation\tagSECTITLE_END	Experiment\tagSECTITLE_START	1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Automatic\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	Experimental\tagSECTITLE_START	setting\tagSECTITLE_END	We\tagSENT_START	computed\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	domain\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	configurations\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	metrics\tagSENT_CONTENT	:\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Reciprocal\tagSENT_CONTENT	Rank\tagSENT_CONTENT	(\tagmetric	MRR\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Average\tagSENT_CONTENT	Precision\tagSENT_CONTENT	(\tagmetric	MAP\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	Precision\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	measures\tagSENT_CONTENT	provide\tagSENT_CONTENT	insights\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	outcome\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	how\tagSENT_CONTENT	often\tagSENT_CONTENT	valid\tagSENT_CONTENT	hypernyms\tagSENT_CONTENT	were\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	positions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	rank\tagSENT_CONTENT	(\tagSENT_CONTENT	MRR\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	if\tagSENT_CONTENT	there\tagSENT_CONTENT	were\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	one\tagSENT_CONTENT	valid\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	,\tagSENT_CONTENT	whether\tagSENT_CONTENT	this\tagSENT_CONTENT	set\tagSENT_CONTENT	was\tagSENT_CONTENT	correctly\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	MAP\tagSENT_CONTENT	and\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	discussion\tagSECTITLE_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	TAXOEMBED\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	is\tagSENT_CONTENT	consistent\tagSENT_CONTENT	across\tagSENT_CONTENT	most\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	domain\tagSENT_CONTENT	clusters\tagSENT_CONTENT	and\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	filtered\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	KB\tagSENT_CONTENT	-\tagSENT_CONTENT	U\tagSENT_CONTENT	contributing\tagSENT_CONTENT	to\tagSENT_CONTENT	taxonomy_learning\tagtask	in\tagSENT_CONTENT	about\tagSENT_CONTENT	two\tagSENT_CONTENT	thirds\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	configurations\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	computed\tagSENT_CONTENT	P@k\tagmetric	(\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	valid\tagSENT_CONTENT	hypernyms\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	k\tagSENT_CONTENT	returned\tagSENT_CONTENT	candidates\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	k\tagSENT_CONTENT	ranges\tagSENT_CONTENT	from\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	.\tagSENT_END	Experiment\tagSECTITLE_START	2\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Extra\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Coverage\tagSECTITLE_END	Experimental\tagSECTITLE_START	setting\tagSECTITLE_END	Yago\tagSENT_START	derives\tagSENT_CONTENT	taxonomy_learning\tagtask	from\tagSENT_CONTENT	an\tagSENT_CONTENT	automatic\tagSENT_CONTENT	mapping\tagSENT_CONTENT	between\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	and\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	categories\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	discussion\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	TAXOEMBED\tagSENT_CONTENT	,\tagSENT_CONTENT	taxonomy_learning\tagtask	exploiting\tagSENT_CONTENT	the\tagSENT_CONTENT	property\tagSENT_CONTENT	that\tagSENT_CONTENT	was\tagSENT_CONTENT	observed\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	exists\tagSENT_CONTENT	,\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	terminology\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	shared\tagSENT_CONTENT	linear\tagSENT_CONTENT	projection\tagSENT_CONTENT	among\tagSENT_CONTENT	termhypernym\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Future\tagSECTITLE_START	Work\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	potential\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	domain\tagSENT_CONTENT	clustering\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	improving\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	weighting\tagSENT_CONTENT	measure\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	how\tagSENT_CONTENT	pertinent\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	concepts\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	taxonomy\tagSENT_CONTENT	are\tagSENT_CONTENT	fora\tagSENT_CONTENT	specific\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	
D17-1120	title\tagSECTITLE_END	Neural\tagSENT_START	Sequence\tagSENT_CONTENT	Learning\tagSENT_CONTENT	Models\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	abstract\tagSECTITLE_END	word_sense_disambiguation\tagtask	exist\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	flavors\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	As\tagSENT_START	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	standing\tagSENT_CONTENT	challenges\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	received\tagSENT_CONTENT	considerable\tagSENT_CONTENT	attention\tagSENT_CONTENT	over\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Such\tagSENT_START	systems\tagSENT_CONTENT	construct\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	based\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	underlying\tagSENT_CONTENT	resource\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	multiple\tagSENT_CONTENT	target\tagSENT_CONTENT	words\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	disambiguate\tagSENT_CONTENT	them\tagSENT_CONTENT	jointly\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	word\tagSENT_CONTENT	experts\tagSENT_CONTENT	are\tagSENT_CONTENT	forced\tagSENT_CONTENT	to\tagSENT_CONTENT	treat\tagSENT_CONTENT	word_sense_disambiguation\tagtask	in\tagSENT_CONTENT	isolation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	our\tagSENT_CONTENT	focus\tagSENT_CONTENT	is\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	WSD\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	depart\tagSENT_CONTENT	from\tagSENT_CONTENT	previous\tagSENT_CONTENT	approaches\tagSENT_CONTENT	and\tagSENT_CONTENT	adopt\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	perspective\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	:\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	framing\tagSENT_CONTENT	a\tagSENT_CONTENT	separate\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	given\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	at\tagSENT_CONTENT	modeling\tagSENT_CONTENT	word_sense_disambiguation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	text\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	whole\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	architecture\tagSENT_CONTENT	reflects\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	way\tagSENT_CONTENT	of\tagSENT_CONTENT	modeling\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	they\tagSENT_CONTENT	all\tagSENT_CONTENT	share\tagSENT_CONTENT	some\tagSENT_CONTENT	key\tagSENT_CONTENT	features\tagSENT_CONTENT	that\tagSENT_CONTENT	set\tagSENT_CONTENT	them\tagSENT_CONTENT	apart\tagSENT_CONTENT	from\tagSENT_CONTENT	previous\tagSENT_CONTENT	supervised\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	WSD\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Sequence\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Sense\tagSECTITLE_CONTENT	Disambiguation\tagSECTITLE_END	While\tagSENT_START	in\tagSENT_CONTENT	its\tagSENT_CONTENT	classical\tagSENT_CONTENT	formulation\tagSENT_CONTENT	WSD\tagSENT_CONTENT	is\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	word\tagSENT_CONTENT	win\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	word_sense_disambiguation\tagtask	of\tagSENT_CONTENT	w\tagSENT_CONTENT	being\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	here\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	a\tagSENT_CONTENT	variable\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	symbols\tagSENT_CONTENT	x\tagSENT_END	Bidirectional\tagSECTITLE_START	LSTM\tagSECTITLE_CONTENT	Tagger\tagSECTITLE_END	Attentive\tagSECTITLE_START	Bidirectional\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	Tagger\tagSECTITLE_END	Sequence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Sequence\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	i.e.\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	translation\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	into\tagSENT_CONTENT	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	potentially\tagSENT_CONTENT	sense\tagSENT_CONTENT	-\tagSENT_CONTENT	tagged\tagSENT_CONTENT	tokens\tagSENT_CONTENT	.\tagSENT_END	Rn\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	states\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	and\tagSENT_CONTENT	q\tagSENT_CONTENT	are\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	functions\tagSENT_CONTENT	.\tagSENT_END	word_sense_disambiguation\tagtask	where\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	replace\tagSENT_CONTENT	content\tagSENT_CONTENT	words\tagSENT_CONTENT	across\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	with\tagSENT_CONTENT	their\tagSENT_CONTENT	most\tagSENT_CONTENT	suitable\tagSENT_CONTENT	senses\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	sense\tagSENT_CONTENT	inventory\tagSENT_CONTENT	S.\tagSENT_END	Multitask\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Multiple\tagSECTITLE_CONTENT	Auxiliary\tagSECTITLE_CONTENT	Losses\tagSECTITLE_END	Predicting\tagSENT_START	the\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tag\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	token\tagSENT_CONTENT	can\tagSENT_CONTENT	also\tagSENT_CONTENT	be\tagSENT_CONTENT	informative\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	help\tagSENT_CONTENT	in\tagSENT_CONTENT	dealing\tagSENT_CONTENT	with\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	POS\tagSENT_CONTENT	lexical\tagSENT_CONTENT	ambiguities\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	book\tagSENT_CONTENT	a\tagSENT_CONTENT	flight\tagSENT_CONTENT	vs.\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	book\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_END	The\tagSENT_START	overall\tagSENT_CONTENT	loss\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	summing\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	loss\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	word_sense_disambiguation\tagtask	)\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	losses\tagSENT_CONTENT	taken\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Concatenation\tagSECTITLE_START	of\tagSECTITLE_CONTENT	All\tagSECTITLE_CONTENT	Test\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	56.3\tagSECTITLE_START	75.2\tagSECTITLE_CONTENT	84.4\tagSECTITLE_END	As\tagSENT_START	regards\tagSENT_CONTENT	multilingual\tagSENT_CONTENT	all\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	WSD\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	6.2\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	experimented\tagSENT_CONTENT	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	word_sense_disambiguation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	bilingual\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	by\tagSENT_CONTENT	Mrkši\tagSENT_CONTENT	´\tagSENT_CONTENT	Training\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	English\tagSECTITLE_START	All\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	words\tagSECTITLE_CONTENT	WSD\tagSECTITLE_END	As\tagSENT_START	supervised\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	considered\tagSENT_CONTENT	Context2Vec\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	It\tagSENT_CONTENT	Makes\tagSENT_CONTENT	Sense\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	implementation\tagSENT_CONTENT	and\tagSENT_CONTENT	word_sense_disambiguation\tagtask	reported\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	also\tagSENT_CONTENT	integrates\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	using\tagSENT_CONTENT	exponential\tagSENT_CONTENT	decay\tagSENT_CONTENT	.\tagSENT_END	Multilingual\tagSECTITLE_START	All\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	words\tagSECTITLE_CONTENT	WSD\tagSECTITLE_END	While\tagSENT_START	doing\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	exploited\tagSENT_CONTENT	BabelNet\tagSENT_CONTENT	's\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	resource\tagSENT_CONTENT	mappings\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	used\tagSENT_CONTENT	at\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	)\tagSENT_CONTENT	into\tagSENT_CONTENT	BabelNet\tagSENT_CONTENT	synsets\tagSENT_CONTENT	compliant\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	sense\tagSENT_CONTENT	inventory\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Error\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	errors\tagSENT_CONTENT	were\tagSENT_CONTENT	connected\tagSENT_CONTENT	to\tagSENT_CONTENT	shorter\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	limited\tagSENT_CONTENT	context\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	:\tagSENT_CONTENT	in\tagSENT_CONTENT	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	noted\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	pre-\tagSENT_END	Conclusion\tagSECTITLE_END	Unlike\tagSENT_START	previous\tagSENT_CONTENT	supervised\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	dedicated\tagSENT_CONTENT	model\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	content\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	treated\tagSENT_CONTENT	in\tagSENT_CONTENT	isolation\tagSENT_CONTENT	,\tagSENT_CONTENT	sequence\tagSENT_CONTENT	learning\tagSENT_CONTENT	approaches\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	one\tagSENT_CONTENT	pass\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	disambiguate\tagSENT_CONTENT	jointly\tagSENT_CONTENT	all\tagSENT_CONTENT	target\tagSENT_CONTENT	words\tagSENT_CONTENT	within\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	future\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	extend\tagSENT_CONTENT	word_sense_disambiguation\tagtask	to\tagSENT_CONTENT	larger\tagSENT_CONTENT	sense\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	corpora\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	sense\tagSENT_CONTENT	inventories\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	
Q16-1023	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	and\tagSENT_CONTENT	effective\tagSENT_CONTENT	scheme\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	(\tagSENT_CONTENT	BiLSTMs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	focus\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	on\tagSENT_CONTENT	feature\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	using\tagSENT_CONTENT	recent\tagSENT_CONTENT	techniques\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	-\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	"\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	Despite\tagSENT_START	the\tagSENT_CONTENT	simplicity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	parsing\tagSENT_CONTENT	architectures\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	functions\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	near\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	English\tagSENT_CONTENT	(\tagSENT_CONTENT	93.1\tagmetric	UAS\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	(\tagSENT_CONTENT	86.6\tagSENT_CONTENT	UAS\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	first\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	while\tagSENT_CONTENT	training\tagSENT_CONTENT	solely\tagSENT_CONTENT	on\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	without\tagSENT_CONTENT	relying\tagSENT_CONTENT	on\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	signals\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	clusters\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	tech\tagSENT_CONTENT	-\tagSENT_CONTENT	niques\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	tri\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Notation\tagSECTITLE_END	Feature\tagSECTITLE_START	Functions\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	Examples\tagSENT_START	of\tagSENT_CONTENT	good\tagSENT_CONTENT	feature\tagSENT_CONTENT	functions\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	set\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	Zhang\tagSENT_CONTENT	and\tagSENT_CONTENT	Nivre\tagSENT_CONTENT	(\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	transitionbased\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	roughly\tagSENT_CONTENT	20\tagSENT_CONTENT	core\tagSENT_CONTENT	components\tagSENT_CONTENT	and\tagSENT_CONTENT	72\tagSENT_CONTENT	feature\tagSENT_CONTENT	templates\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	featureset\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	paper\tagSENT_CONTENT	listing\tagSENT_CONTENT	18\tagSENT_CONTENT	templates\tagSENT_CONTENT	fora\tagSENT_CONTENT	first\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	order\tagSENT_CONTENT	featureextractor\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	actual\tagSENT_CONTENT	implementation\tagSENT_CONTENT	's\tagSENT_CONTENT	code\tagSENT_CONTENT	(\tagSENT_CONTENT	MSTParser\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	includes\tagSENT_CONTENT	roughly\tagSENT_CONTENT	a\tagSENT_CONTENT	hundred\tagSENT_CONTENT	feature\tagSENT_CONTENT	templates\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	core\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parser\tagSENT_CONTENT	usually\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	information\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	identity\tagSENT_CONTENT	and\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagmetric	POS\tagmetric	)\tagSENT_CONTENT	tags\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	buffer\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	modifiers\tagSENT_CONTENT	(\tagSENT_CONTENT	usually\tagSENT_CONTENT	leftmost\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	most\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	items\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	and\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	buffer\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	modifiers\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	elements\tagSENT_CONTENT	,\tagSENT_CONTENT	parents\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	spans\tagSENT_CONTENT	spanned\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	core\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	first\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parser\tagSENT_CONTENT	usually\tagSENT_CONTENT	take\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	POS\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	and\tagSENT_CONTENT	modifier\tagSENT_CONTENT	items\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	POS\tagmetric	-\tagmetric	tags\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	items\tagSENT_CONTENT	around\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	and\tagSENT_CONTENT	modifier\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagmetric	tags\tagmetric	of\tagSENT_CONTENT	items\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	and\tagSENT_CONTENT	modifier\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	distance\tagSENT_CONTENT	and\tagSENT_CONTENT	direction\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	and\tagSENT_CONTENT	modifier\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Research\tagSECTITLE_CONTENT	Efforts\tagSECTITLE_END	apply\tagSENT_START	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	methodology\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Work\tagSENT_START	by\tagSENT_CONTENT	employs\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	with\tagSENT_CONTENT	attention\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Bidirectional\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	RNNs\tagSENT_START	were\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	count\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	line\tagSENT_CONTENT	lengths\tagSENT_CONTENT	and\tagSENT_CONTENT	complex\tagSENT_CONTENT	phenomena\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	bracketing\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	BiRNNs\tagSENT_CONTENT	and\tagSENT_CONTENT	deep\tagSENT_CONTENT	-\tagSENT_CONTENT	BiRNNs\tagSENT_CONTENT	interchangeably\tagSENT_CONTENT	,\tagSENT_CONTENT	specifying\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	layers\tagmetric	when\tagSENT_CONTENT	needed\tagSENT_CONTENT	.\tagSENT_END	BiLSTMs\tagSENT_START	were\tagSENT_CONTENT	recently\tagSENT_CONTENT	popularized\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	deep\tagSENT_CONTENT	BiRNNs\tagSENT_CONTENT	were\tagSENT_CONTENT	introduced\tagSENT_CONTENT	to\tagSENT_CONTENT	NLP\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	used\tagSENT_CONTENT	them\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Our\tagSECTITLE_START	Approach\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	replace\tagSENT_CONTENT	the\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	feature\tagSENT_CONTENT	functions\tagSENT_CONTENT	in\tagSENT_CONTENT	favor\tagSENT_CONTENT	of\tagSENT_CONTENT	minimally\tagSENT_CONTENT	-\tagSENT_CONTENT	defined\tagSENT_CONTENT	feature\tagSENT_CONTENT	functions\tagSENT_CONTENT	which\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	learned\tagSENT_CONTENT	Bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Beside\tagSENT_START	using\tagSENT_CONTENT	the\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	feature\tagSENT_CONTENT	functions\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	standard\tagSENT_CONTENT	parsing\tagSENT_CONTENT	techniques\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	has\tagSENT_CONTENT	access\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	POS\tagmetric	-\tagmetric	tags\tagmetric	of\tagSENT_CONTENT	vi\tagSENT_CONTENT	and\tagSENT_CONTENT	v\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	POS\tagmetric	-\tagmetric	tags\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	infinite\tagSENT_CONTENT	window\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	proceeds\tagSENT_CONTENT	as\tagSENT_CONTENT	usual\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	extraction\tagSENT_CONTENT	involves\tagSENT_CONTENT	a\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	computed\tagSENT_CONTENT	vi\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	Transition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Parser\tagSECTITLE_END	dependency_parsing\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	classifier\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	choose\tagSENT_CONTENT	the\tagSENT_CONTENT	transition\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	configuration\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	features\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	configuration\tagSENT_CONTENT	itself\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	arc\tagSENT_CONTENT	-\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	configuration\tagSENT_CONTENT	c\tagSENT_CONTENT	=\tagSENT_CONTENT	(\tagSENT_CONTENT	σ\tagSENT_CONTENT	,\tagSENT_CONTENT	β\tagSENT_CONTENT	,\tagSENT_CONTENT	T\tagSENT_CONTENT	)\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	σ\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	buffer\tagSENT_CONTENT	β\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	T\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Scoring\tagSECTITLE_START	Function\tagSECTITLE_END	While\tagSENT_START	not\tagSENT_CONTENT	explored\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	relying\tagSENT_CONTENT	on\tagSENT_CONTENT	only\tagSENT_CONTENT	four\tagSENT_CONTENT	word\tagSENT_CONTENT	indices\tagSENT_CONTENT	for\tagSENT_CONTENT	scoring\tagSENT_CONTENT	an\tagSENT_CONTENT	action\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	very\tagSENT_CONTENT	compact\tagSENT_CONTENT	state\tagSENT_CONTENT	signatures\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	feature\tagSENT_CONTENT	representation\tagSENT_CONTENT	very\tagSENT_CONTENT	appealing\tagSENT_CONTENT	for\tagSENT_CONTENT	use\tagmetric	in\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsers\tagSENT_CONTENT	that\tagSENT_CONTENT	employ\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	-\tagSENT_CONTENT	programming\tagSENT_CONTENT	search\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Details\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Algorithm\tagSECTITLE_END	Error\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Exploration\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Dynamic\tagSECTITLE_CONTENT	Oracle\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	Graph\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Parser\tagSECTITLE_END	dependency_parsing\tagtask	follows\tagSENT_CONTENT	the\tagSENT_CONTENT	common\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	paradigm\tagSENT_END	dependency_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	scored\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	MLP\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	fed\tagSENT_CONTENT	the\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	encoding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	arc\tagSENT_CONTENT	's\tagSENT_CONTENT	end\tagSENT_CONTENT	points\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	colors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	arcs\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	colors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	MLP\tagSENT_CONTENT	inputs\tagSENT_CONTENT	above\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	individual\tagSENT_CONTENT	arc\tagSENT_CONTENT	scores\tagSENT_CONTENT	are\tagSENT_CONTENT	summed\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	scoring\tagSENT_START	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	yin\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	Y(s\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	over\tagSENT_CONTENT	s.\tagSENT_END	Labeled\tagSENT_START	Parsing\tagSENT_CONTENT	Up\tagSENT_CONTENT	to\tagSENT_CONTENT	now\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	described\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Loss\tagmetric	augmented\tagSENT_CONTENT	inference\tagSENT_CONTENT	In\tagSENT_CONTENT	initial\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	learned\tagSENT_CONTENT	quickly\tagSENT_CONTENT	and\tagSENT_CONTENT	overfit\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	W\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	W\tagSENT_CONTENT	1\tagSENT_CONTENT	are\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	and\tagSENT_CONTENT	second\tagSENT_CONTENT	half\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	matrix\tagSENT_CONTENT	W\tagSENT_CONTENT	and\tagSENT_CONTENT	reusing\tagSENT_CONTENT	the\tagSENT_CONTENT	products\tagSENT_CONTENT	across\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	variant\tagSENT_CONTENT	implemented\tagSENT_CONTENT	in\tagSENT_CONTENT	PyCNN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	optimize\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Adam\tagSENT_CONTENT	optimizer\tagSENT_CONTENT	(\tagSENT_CONTENT	The\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	POS\tagmetric	embeddings\tagSENT_CONTENT	e(w\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	e(p\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_END	dependency_parsing\tagtask	does\tagSENT_CONTENT	manage\tagSENT_CONTENT	to\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	external\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	using\tagSENT_CONTENT	them\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	see\tagSENT_CONTENT	gains\tagSENT_CONTENT	from\tagSENT_CONTENT	moving\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	simple\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	extended\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Additional\tagSENT_START	Results\tagSENT_CONTENT	We\tagSENT_CONTENT	perform\tagSENT_CONTENT	some\tagSENT_CONTENT	ablation\tagSENT_CONTENT	experiments\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	quantify\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	components\tagSENT_CONTENT	on\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	models\tagSENT_CONTENT	 \tagSENT_CONTENT	Loss\tagmetric	augmented\tagSENT_CONTENT	inference\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	scheme\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	arc\tagSENT_CONTENT	-\tagSENT_CONTENT	labeler\tagSENT_CONTENT	contributes\tagSENT_CONTENT	nicely\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	pleasingly\tagSENT_CONTENT	effective\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	feature\tagSENT_CONTENT	extraction\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	encoder\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	jointly\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	its\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	by\tagSENT_CONTENT	integrating\tagSENT_CONTENT	it\tagSENT_CONTENT	into\tagSENT_CONTENT	two\tagSENT_CONTENT	simple\tagSENT_CONTENT	parsing\tagSENT_CONTENT	models\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	greedy\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parser\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	globally\tagSENT_CONTENT	optimized\tagSENT_CONTENT	first\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	yielding\tagSENT_CONTENT	very\tagSENT_CONTENT	competitive\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	cases\tagSENT_CONTENT	.\tagSENT_END	
1710.10723	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	For\tagSENT_START	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	existing\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	methods\tagSENT_CONTENT	are\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	locating\tagSENT_CONTENT	documents\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	contain\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	*\tagSENT_START	Work\tagSENT_CONTENT	completed\tagSENT_CONTENT	while\tagSENT_CONTENT	interning\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	Allen\tagSENT_CONTENT	Institute\tagSENT_CONTENT	for\tagSENT_CONTENT	Artificial\tagSENT_CONTENT	Intelligence\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	documents\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	passed\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	annotating\tagSENT_CONTENT	entire\tagSENT_CONTENT	documents\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	expensive\tagSENT_CONTENT	,\tagSENT_CONTENT	data\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	sort\tagSENT_CONTENT	is\tagSENT_CONTENT	typically\tagSENT_CONTENT	distantly\tagSENT_CONTENT	supervised\tagSENT_CONTENT	,\tagSENT_CONTENT	meaning\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	are\tagSENT_CONTENT	known\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSENT_START	approaches\tagSENT_CONTENT	trained\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	known\tagSENT_CONTENT	a\tagSENT_CONTENT	priori\tagSENT_CONTENT	to\tagSENT_CONTENT	contain\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	web\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	web\tagSENT_CONTENT	documents\tagSENT_CONTENT	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Pipelined\tagSECTITLE_START	Method\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	training\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	is\tagSENT_CONTENT	heuristically\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	document(s\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	passed\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraphlevel\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Paragraph\tagSECTITLE_START	Selection\tagSECTITLE_END	Our\tagSENT_START	paragraph\tagSENT_CONTENT	selection\tagSENT_CONTENT	method\tagSENT_CONTENT	chooses\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	smallest\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	cosine\tagSENT_CONTENT	distance\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Handling\tagSECTITLE_START	Noisy\tagSECTITLE_CONTENT	Labels\tagSECTITLE_END	question_answering\tagtask	:\tagSENT_CONTENT	Which\tagSENT_CONTENT	British\tagSENT_CONTENT	general\tagSENT_CONTENT	was\tagSENT_CONTENT	killed\tagSENT_CONTENT	at\tagSENT_CONTENT	Khartoum\tagSENT_CONTENT	in\tagSENT_CONTENT	1885\tagSENT_CONTENT	?\tagSENT_END	This\tagSENT_START	can\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	where\tagSENT_START	A\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	that\tagSENT_CONTENT	start\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	n\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	s\tagSENT_END	Model\tagSECTITLE_END	A\tagSENT_START	shared\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	GRU\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	passage\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	contextaware\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	,\tagSENT_CONTENT	q\tagSENT_CONTENT	j\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	n\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	case\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	use\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	we\tagSENT_CONTENT	set\tagSENT_CONTENT	a\tagSENT_CONTENT	ij\tagSENT_CONTENT	=\tagSENT_CONTENT	−inf\tagSENT_END	Confidence\tagSECTITLE_START	Method\tagSECTITLE_END	At\tagSENT_START	test\tagSENT_CONTENT	time\tagSENT_CONTENT	we\tagSENT_CONTENT	run\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	confidence\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	only\tagSENT_CONTENT	sees\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	answers\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	might\tagSENT_CONTENT	become\tagSENT_CONTENT	too\tagSENT_CONTENT	confident\tagSENT_CONTENT	in\tagSENT_CONTENT	heuristics\tagSENT_CONTENT	or\tagSENT_CONTENT	patterns\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	only\tagSENT_CONTENT	effective\tagSENT_CONTENT	when\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	known\tagSENT_CONTENT	a\tagSENT_CONTENT	priori\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	exists\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	all\tagSENT_CONTENT	cases\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	sample\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	contain\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	training\tagSENT_CONTENT	points\tagSENT_CONTENT	.\tagSENT_END	Shared\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Normalization\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	that\tagSENT_CONTENT	token\tagSENT_CONTENT	a\tagSENT_CONTENT	from\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	p\tagSENT_CONTENT	starts\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	Merge\tagSECTITLE_END	No\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Answer\tagSECTITLE_CONTENT	Option\tagSECTITLE_END	...\tagSECTITLE_START	majority\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Scottish\tagSECTITLE_CONTENT	electorate\tagSECTITLE_CONTENT	voted\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	it\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	referendum\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	be\tagSECTITLE_CONTENT	held\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	March\tagSECTITLE_END	The\tagSENT_START	Cestida\tagSENT_CONTENT	are\tagSENT_CONTENT	ribbon\tagSENT_CONTENT	-shaped\tagSENT_CONTENT	planktonic\tagSENT_CONTENT	animals\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	mouth\tagSENT_CONTENT	and\tagSENT_CONTENT	aboral\tagSENT_CONTENT	organ\tagSENT_CONTENT	aligned\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	middle\tagSENT_CONTENT	of\tagSENT_CONTENT	opposite\tagSENT_CONTENT	edges\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ribbon\tagSENT_CONTENT	:\tagSENT_CONTENT	Examples\tagSENT_CONTENT	from\tagSENT_CONTENT	SQuAD\tagdataset	where\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	model\tagSENT_CONTENT	was\tagSENT_CONTENT	less\tagSENT_CONTENT	confident\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	correct\tagSENT_CONTENT	extraction\tagSENT_CONTENT	from\tagSENT_CONTENT	one\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	(\tagSENT_CONTENT	left\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	incorrect\tagSENT_CONTENT	extraction\tagSENT_CONTENT	from\tagSENT_CONTENT	another\tagSENT_CONTENT	(\tagSENT_CONTENT	right\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	δ\tagSENT_CONTENT	is\tagSENT_CONTENT	1\tagSENT_CONTENT	if\tagSENT_CONTENT	question_answering\tagtask	exists\tagSENT_CONTENT	and\tagSENT_CONTENT	0\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	concatenate\tagSENT_CONTENT	these\tagSENT_CONTENT	three\tagSENT_CONTENT	vectors\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	them\tagmetric	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	two\tagSENT_CONTENT	layer\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	80\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	activations\tagSENT_CONTENT	that\tagSENT_CONTENT	produces\tagSENT_CONTENT	z\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	only\tagSENT_CONTENT	output\tagSENT_CONTENT	.\tagSENT_END	Sigmoid\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Datasets\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	unfiltered\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	trivia\tagSENT_CONTENT	databases\tagSENT_CONTENT	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	documents\tagSENT_CONTENT	found\tagSENT_CONTENT	by\tagSENT_CONTENT	completing\tagSENT_CONTENT	a\tagSENT_CONTENT	web\tagSENT_CONTENT	search\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	questions\tagSENT_CONTENT	;\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	web\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	unfiltered\tagSENT_CONTENT	by\tagSENT_CONTENT	treating\tagSENT_CONTENT	each\tagSENT_CONTENT	questiondocument\tagSENT_CONTENT	pair\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	answer\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	individual\tagSENT_CONTENT	training\tagSENT_CONTENT	point\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	and\tagSENT_CONTENT	crowdsourced\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	Preprocessing\tagSECTITLE_END	We\tagSENT_START	fix\tagSENT_CONTENT	this\tagSENT_CONTENT	issue\tagSENT_CONTENT	by\tagSENT_CONTENT	labeling\tagSENT_CONTENT	all\tagSENT_CONTENT	spans\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	that\tagSENT_CONTENT	would\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	considered\tagSENT_CONTENT	an\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	script\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Sampling\tagSECTITLE_END	Our\tagSENT_START	confidence\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	are\tagSENT_CONTENT	all\tagSENT_CONTENT	trained\tagSENT_CONTENT	by\tagSENT_CONTENT	sampling\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	contain\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	TriviaQA\tagSENT_CONTENT	unfiltered\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	multiple\tagSENT_CONTENT	documents\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	it\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	sophisticated\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	ranking\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	Adadelta\tagSENT_CONTENT	optimizer\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	60\tagSENT_CONTENT	for\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	and\tagSENT_CONTENT	45\tagSENT_CONTENT	for\tagSENT_CONTENT	SQuAD\tagdataset	.\tagSENT_END	Results\tagSECTITLE_END	TriviaQA\tagSECTITLE_START	Web\tagSECTITLE_END	In\tagSENT_START	question_answering\tagtask	we\tagSENT_CONTENT	group\tagSENT_CONTENT	each\tagSENT_CONTENT	document\tagSENT_CONTENT	's\tagSENT_CONTENT	text\tagSENT_CONTENT	into\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	of\tagSENT_CONTENT	at\tagSENT_CONTENT	most\tagSENT_CONTENT	400\tagSENT_CONTENT	tokens\tagSENT_CONTENT	and\tagSENT_CONTENT	rank\tagSENT_CONTENT	them\tagSENT_CONTENT	using\tagSENT_CONTENT	our\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	We\tagSENT_START	additionally\tagSENT_CONTENT	measure\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	verified\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	pairs\tagSENT_CONTENT	in\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	web\tagSENT_CONTENT	where\tagSENT_CONTENT	humans\tagSENT_CONTENT	have\tagSENT_CONTENT	manually\tagSENT_CONTENT	verified\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	contains\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	context\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	This\tagSENT_START	suggests\tagSENT_CONTENT	the\tagSENT_CONTENT	shared\tagSENT_CONTENT	-\tagSENT_CONTENT	norm\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	extracting\tagSENT_CONTENT	answers\tagSENT_CONTENT	when\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	clearly\tagSENT_CONTENT	stated\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	worse\tagSENT_CONTENT	at\tagSENT_CONTENT	guessing\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	other\tagSENT_CONTENT	cases\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	human\tagSENT_CONTENT	annotators\tagSENT_CONTENT	have\tagSENT_CONTENT	estimated\tagSENT_CONTENT	that\tagSENT_CONTENT	only\tagSENT_CONTENT	75.4\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	pairs\tagSENT_CONTENT	contain\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	evidence\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	suggests\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	approaching\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	bound\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	TriviaQA\tagSECTITLE_START	Unfiltered\tagSECTITLE_END	This\tagSENT_START	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	particular\tagSENT_CONTENT	interest\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	told\tagSENT_CONTENT	which\tagSENT_CONTENT	document\tagSENT_CONTENT	contains\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	so\tagSENT_CONTENT	it\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	plausible\tagSENT_CONTENT	simulation\tagSENT_CONTENT	of\tagSENT_CONTENT	attempting\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagSECTITLE_END	We\tagSENT_START	categorize\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	:\tagSENT_END	We\tagSENT_START	find\tagSENT_CONTENT	67.4\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	be\tagSENT_CONTENT	contextindependent\tagSENT_CONTENT	,\tagSENT_CONTENT	22.6\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	document\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	10\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	paragraphdependent\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	SQuAD\tagdataset	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	it\tagSENT_CONTENT	crucial\tagSENT_CONTENT	to\tagSENT_CONTENT	employ\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	suggested\tagSENT_CONTENT	confidence\tagSENT_CONTENT	training\tagSENT_CONTENT	techniques\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	allow\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	know\tagSENT_CONTENT	a\tagSENT_CONTENT	priori\tagSENT_CONTENT	which\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	were\tagSENT_CONTENT	filtered\tagSENT_CONTENT	out\tagSENT_CONTENT	during\tagSENT_CONTENT	the\tagSENT_CONTENT	construction\tagSENT_CONTENT	of\tagSENT_CONTENT	SQuAD\tagdataset	.\tagSENT_END	Discussion\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	were\tagSENT_CONTENT	particularly\tagSENT_CONTENT	bad\tagSENT_CONTENT	for\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	we\tagSENT_CONTENT	think\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	partly\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	are\tagSENT_CONTENT	shorter\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	had\tagSENT_CONTENT	less\tagSENT_CONTENT	exposure\tagSENT_CONTENT	to\tagSENT_CONTENT	irrelevant\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Additional\tagSENT_START	datasets\tagSENT_CONTENT	including\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	,\tagSENT_CONTENT	MS\tagSENT_CONTENT	Marco\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	provided\tagSENT_CONTENT	more\tagSENT_CONTENT	realistic\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	the\tagSENT_CONTENT	subject\tagSENT_CONTENT	of\tagSENT_CONTENT	much\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	spurred\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	TREC\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	track\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	answering\tagSENT_CONTENT	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	was\tagSENT_CONTENT	considered\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	researchers\tagSENT_CONTENT	trained\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	and\tagSENT_CONTENT	combined\tagSENT_CONTENT	it\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	engine\tagSENT_CONTENT	for\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	demo\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	directly\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	building\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	powered\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	
C16-1146	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	sentiment_analysis\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	(\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	)\tagSENT_END	Another\tagSENT_START	line\tagSENT_CONTENT	of\tagSENT_CONTENT	research\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	field\tagSENT_CONTENT	is\tagSENT_CONTENT	targeted\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Both\tagSENT_START	settings\tagSENT_CONTENT	are\tagSENT_CONTENT	obviously\tagSENT_CONTENT	limited\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	there\tagSENT_CONTENT	exists\tagSENT_CONTENT	many\tagSENT_CONTENT	scenarios\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	sentiment_analysis\tagtask	towards\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	unit\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	example\tagSENT_CONTENT	above\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	perfectly\tagSENT_CONTENT	fit\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	existing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	mentioned\tagSENT_CONTENT	earlier\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	compare\tagSENT_CONTENT	with\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	take\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	example\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	restaurant\tagSENT_CONTENT	dataset\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	shared\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	(\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Current\tagSENT_START	ABSA\tagSENT_CONTENT	task\tagSENT_CONTENT	can\tagSENT_CONTENT	only\tagSENT_CONTENT	recognise\tagSENT_CONTENT	that\tagSENT_CONTENT	positive\tagSENT_CONTENT	and\tagSENT_CONTENT	negative\tagSENT_CONTENT	opinions\tagSENT_CONTENT	towards\tagSENT_CONTENT	aspect\tagmetric	"\tagmetric	service\tagmetric	"\tagSENT_CONTENT	are\tagSENT_CONTENT	expressed\tagSENT_CONTENT	.\tagSENT_END	SentiHood\tagdataset	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	QA\tagSENT_CONTENT	platform\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	domain\tagSENT_CONTENT	of\tagSENT_CONTENT	neighbourhoods\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	city\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	further\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	extracting\tagSENT_CONTENT	more\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	text\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	SentiHood\tagdataset	,\tagSENT_CONTENT	a\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	dataset\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	annotated\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	targeted\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	domain\tagSENT_CONTENT	of\tagSENT_CONTENT	urban\tagSENT_CONTENT	neighbourhoods\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	We\tagSENT_CONTENT	provide\tagSENT_CONTENT	strong\tagSENT_CONTENT	baselines\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	using\tagSENT_CONTENT	both\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	and\tagSENT_CONTENT	Long\tagSENT_CONTENT	Short\tagSENT_CONTENT	Term\tagSENT_CONTENT	Memory\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	SentiHood\tagSECTITLE_END	SentiHood\tagdataset	is\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	targeted\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Collection\tagSECTITLE_CONTENT	Process\tagSECTITLE_END	sentiment_analysis\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	are\tagSENT_CONTENT	locations\tagSENT_CONTENT	or\tagSENT_CONTENT	neighbourhoods\tagSENT_CONTENT	.\tagSENT_END	Categories\tagSECTITLE_END	To\tagSENT_START	simplify\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	annotate\tagSENT_CONTENT	sentiment_analysis\tagtask	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	one\tagSENT_CONTENT	or\tagSENT_CONTENT	two\tagSENT_CONTENT	location\tagSENT_CONTENT	mentions\tagSENT_CONTENT	.\tagSENT_END	Aspects\tagSECTITLE_END	Like\tagSENT_START	existing\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	defined\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	aspects\tagSENT_CONTENT	is\tagSENT_CONTENT	provided\tagSENT_CONTENT	for\tagSENT_CONTENT	annotators\tagSENT_CONTENT	to\tagSENT_CONTENT	choose\tagSENT_CONTENT	from\tagSENT_CONTENT	.\tagSENT_END	Sentiment\tagSECTITLE_END	For\tagSENT_START	each\tagSENT_CONTENT	selected\tagSENT_CONTENT	aspect\tagSENT_CONTENT	,\tagSENT_CONTENT	annotators\tagSENT_CONTENT	were\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	a\tagSENT_CONTENT	polarity\tagSENT_CONTENT	or\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Target\tagSECTITLE_START	Entity\tagSECTITLE_END	Target\tagSENT_START	entity\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	location\tagSENT_CONTENT	entity\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	an\tagSENT_CONTENT	opinion\tagSENT_CONTENT	(\tagSENT_CONTENT	aspect\tagmetric	and\tagSENT_CONTENT	sentiment_analysis\tagtask	)\tagSENT_CONTENT	is\tagSENT_CONTENT	expressed\tagSENT_CONTENT	for\tagSENT_CONTENT	.\tagSENT_END	Out\tagSECTITLE_START	of\tagSECTITLE_CONTENT	scope\tagSECTITLE_END	sentiment_analysis\tagtask	marked\tagSENT_CONTENT	with\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	these\tagSENT_CONTENT	labels\tagSENT_CONTENT	are\tagSENT_CONTENT	removed\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Irrelevant\tagSENT_START	:\tagSENT_CONTENT	When\tagSENT_CONTENT	the\tagSENT_CONTENT	identified\tagSENT_CONTENT	name\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	location\tagSENT_CONTENT	entity\tagSENT_CONTENT	:\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	Uncertain\tagSENT_START	:\tagSENT_CONTENT	When\tagSENT_CONTENT	two\tagSENT_CONTENT	contradicting\tagSENT_CONTENT	sentiments\tagSENT_CONTENT	are\tagSENT_CONTENT	expressed\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	location\tagSENT_CONTENT	and\tagSENT_CONTENT	aspect\tagmetric	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	"\tagSENT_CONTENT	Like\tagSENT_CONTENT	any\tagSENT_CONTENT	other\tagSENT_CONTENT	area\tagSENT_CONTENT	,\tagSENT_CONTENT	Camden\tagSENT_CONTENT	Town\tagSENT_CONTENT	has\tagSENT_CONTENT	good\tagSENT_CONTENT	and\tagSENT_CONTENT	bad\tagSENT_CONTENT	parts\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Procedure\tagSECTITLE_START	:\tagSECTITLE_END	Agreements\tagSENT_START	:\tagSENT_CONTENT	Cohen\tagSENT_CONTENT	's\tagSENT_CONTENT	Kappa\tagSENT_CONTENT	coefficient(K\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	measuring\tagSENT_CONTENT	the\tagSENT_CONTENT	pairwise\tagSENT_CONTENT	agreement\tagSENT_CONTENT	between\tagSENT_CONTENT	each\tagSENT_CONTENT	two\tagSENT_CONTENT	annotators\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	;)\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Disagreements\tagSENT_START	:\tagSENT_CONTENT	Main\tagSENT_CONTENT	disagreements\tagSENT_CONTENT	between\tagSENT_CONTENT	annotators\tagSENT_CONTENT	occurred\tagSENT_CONTENT	in\tagSENT_CONTENT	detecting\tagSENT_CONTENT	the\tagmetric	aspect\tagmetric	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	detecting\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	aspect\tagSENT_CONTENT	expression\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	location\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	SentiHood\tagdataset	currently\tagSENT_CONTENT	contains\tagSENT_CONTENT	annotated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	containing\tagSENT_CONTENT	one\tagSENT_CONTENT	or\tagSENT_CONTENT	two\tagSENT_CONTENT	location\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	.\tagSENT_END	Location\tagSENT_START	entity\tagSENT_CONTENT	names\tagSENT_CONTENT	are\tagSENT_CONTENT	masked\tagSENT_CONTENT	by\tagSENT_CONTENT	location1\tagSENT_CONTENT	and\tagSENT_CONTENT	location2\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	involve\tagSENT_CONTENT	identification\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Task\tagSECTITLE_END	We\tagSENT_START	define\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	unit\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	s\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	tuples\tagSENT_CONTENT	(\tagSENT_CONTENT	labels\tagSENT_CONTENT	)\tagSENT_CONTENT	{\tagSENT_CONTENT	(\tagSENT_CONTENT	l\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	,\tagSENT_CONTENT	p\tagSENT_CONTENT	)\tagSENT_CONTENT	}\tagSENT_CONTENT	T\tagSENT_CONTENT	t=0\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	p\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	polarity\tagSENT_CONTENT	expressed\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	aspect\tagSENT_CONTENT	a\tagSENT_CONTENT	of\tagSENT_CONTENT	entity\tagSENT_CONTENT	l.\tagSENT_END	Within\tagSENT_START	sentiment_analysis\tagtask	,\tagSENT_CONTENT	three\tagSENT_CONTENT	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	defined\tagSENT_CONTENT	(:\tagSENT_CONTENT	detecting\tagSENT_CONTENT	the\tagSENT_CONTENT	aspect\tagSENT_CONTENT	,\tagSENT_CONTENT	detecting\tagSENT_CONTENT	the\tagSENT_CONTENT	opinion\tagSENT_CONTENT	target\tagSENT_CONTENT	expression\tagSENT_CONTENT	and\tagSENT_CONTENT	detecting\tagSENT_CONTENT	the\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	detecting\tagSENT_CONTENT	the\tagSENT_CONTENT	opinion\tagSENT_CONTENT	target\tagSENT_CONTENT	expression\tagSENT_CONTENT	being\tagSENT_CONTENT	an\tagSENT_CONTENT	intermediary\tagSENT_CONTENT	task\tagSENT_CONTENT	for\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	aspect\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	identifying\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	aspect\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	is\tagSENT_CONTENT	very\tagSENT_CONTENT	safe\tagSENT_CONTENT	and\tagSENT_CONTENT	location2\tagSENT_CONTENT	is\tagSENT_CONTENT	too\tagSENT_CONTENT	far\tagSENT_CONTENT	(\tagSENT_CONTENT	location1,safety\tagSENT_CONTENT	,\tagSENT_CONTENT	Positive\tagSENT_CONTENT	)\tagSENT_END	Evaluation\tagSECTITLE_END	Most\tagSENT_START	existing\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	report\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	measure\tagSENT_CONTENT	for\tagSENT_CONTENT	aspect\tagSENT_CONTENT	detection\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	AUC\tagSENT_CONTENT	(\tagSENT_CONTENT	area\tagSENT_CONTENT	under\tagSENT_CONTENT	the\tagSENT_CONTENT	ROC\tagSENT_CONTENT	curve\tagSENT_CONTENT	)\tagSENT_CONTENT	metric\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagmetric	aspect\tagmetric	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Baseline\tagSECTITLE_END	In\tagSENT_START	all\tagSENT_CONTENT	our\tagSENT_CONTENT	methods\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	treat\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	three\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	classification\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	aspect\tagmetric	and\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	function\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	y\tagSENT_CONTENT	l\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	is\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	aspect\tagSENT_CONTENT	a\tagSENT_CONTENT	for\tagSENT_CONTENT	location\tagSENT_CONTENT	l.\tagSENT_CONTENT	w\tagSENT_CONTENT	c\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	C\tagSENT_END	Logistic\tagSECTITLE_START	Regression\tagSECTITLE_END	Many\tagSENT_START	existing\tagSENT_CONTENT	works\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	3\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	classifier\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	or\tagSENT_CONTENT	SVM\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	features\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagSENT_CONTENT	information\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Mask\tagSENT_START	target\tagSENT_CONTENT	sentiment_analysis\tagtask	:\tagSENT_CONTENT	For\tagSENT_CONTENT	each\tagSENT_CONTENT	location\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	define\tagSENT_CONTENT	an\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	representation\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	mask\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	location\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	token\tagSENT_CONTENT	.\tagSENT_END	Left\tagSENT_START	right\tagSENT_CONTENT	pooling\tagSENT_CONTENT	:\tagSENT_CONTENT	Previously\tagSENT_CONTENT	embedding\tagSENT_CONTENT	representations\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	context\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	automatic\tagSENT_CONTENT	feature\tagSENT_CONTENT	detection\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Long\tagSECTITLE_START	Short\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Inspired\tagSENT_START	by\tagSENT_CONTENT	the\tagSENT_CONTENT	recent\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	applying\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	on\tagSENT_CONTENT	language\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	classifier\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	aspects\tagmetric	.\tagSENT_END	The\tagSENT_START	output\tagSENT_CONTENT	state\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	index\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	location\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	sentiment_analysis\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	aspect\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	choose\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagmetric	to\tagSENT_CONTENT	the\tagSENT_CONTENT	dev\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	report\tagSENT_CONTENT	results\tagSENT_CONTENT	separately\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	categories\tagSENT_CONTENT	of\tagSENT_CONTENT	single\tagSENT_CONTENT	location\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	two\tagSENT_CONTENT	locations\tagSENT_CONTENT	and\tagSENT_CONTENT	overall\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	tackle\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	having\tagSENT_CONTENT	an\tagSENT_CONTENT	unbalanced\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	too\tagSENT_CONTENT	many\tagSENT_CONTENT	"\tagSENT_CONTENT	None\tagSENT_CONTENT	"\tagSENT_CONTENT	instances\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	batches\tagSENT_CONTENT	with\tagSENT_CONTENT	every\tagSENT_CONTENT	batch\tagSENT_CONTENT	having\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	selected\tagSENT_CONTENT	randomly\tagSENT_CONTENT	from\tagSENT_CONTENT	each\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Model\tagSECTITLE_END	Aspect\tagmetric	(:\tagSENT_CONTENT	Results\tagSENT_CONTENT	of\tagSENT_CONTENT	best\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	(\tagSENT_CONTENT	LR\tagSENT_CONTENT	)\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Results\tagSENT_START	of\tagSENT_CONTENT	best\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	(\tagSENT_CONTENT	LR\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	location\tagSENT_CONTENT	(\tagSENT_CONTENT	Single\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	multiple\tagSENT_CONTENT	locations\tagSENT_CONTENT	(\tagSENT_CONTENT	Multi\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	0.836\tagSENT_START	0.869\tagSENT_CONTENT	:\tagSENT_CONTENT	LR\tagSENT_CONTENT	and\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	performance\tagSENT_CONTENT	breakdown\tagSENT_CONTENT	on\tagSENT_CONTENT	aspects\tagmetric	.\tagSENT_END	AUC\tagSENT_START	scores\tagSENT_CONTENT	are\tagSENT_CONTENT	averaged\tagSENT_CONTENT	over\tagSENT_CONTENT	aspect\tagmetric	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Sentence\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	sentiment_analysis\tagtask	was\tagSENT_CONTENT	first\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	mainly\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	unit\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	assumes\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	entity\tagSENT_CONTENT	per\tagSENT_CONTENT	a\tagSENT_CONTENT	unit\tagSENT_CONTENT	of\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	tries\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	sentiments\tagSENT_CONTENT	towards\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	is\tagSENT_CONTENT	another\tagSENT_CONTENT	task\tagSENT_CONTENT	that\tagSENT_CONTENT	identifies\tagSENT_CONTENT	polarity\tagSENT_CONTENT	towards\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	entity\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	over\tagSENT_CONTENT	entire\tagSENT_CONTENT	unit\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	)\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduced\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	anew\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	
D18-1440	title\tagSECTITLE_END	Closed\tagSENT_START	-\tagSENT_CONTENT	Book\tagSENT_CONTENT	Training\tagSENT_CONTENT	to\tagSENT_CONTENT	Improve\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	On\tagSENT_START	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	significantly\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	ROUGE\tagmetric	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforced\tagSENT_CONTENT	setups\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	on\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	condensing\tagSENT_CONTENT	along\tagSENT_CONTENT	passage\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	that\tagSENT_CONTENT	only\tagSENT_CONTENT	covers\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	above\tagSENT_START	all\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagmetric	mother\tagmetric	i\tagSENT_CONTENT	wanted\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	something\tagSENT_CONTENT	for\tagSENT_CONTENT	that\tagSENT_CONTENT	little\tagSENT_CONTENT	girl\tagSENT_CONTENT	,\tagSENT_CONTENT	'\tagSENT_CONTENT	she\tagSENT_CONTENT	added\tagSENT_CONTENT	.\tagSENT_END	Pointer\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Generator\tagSECTITLE_CONTENT	baseline\tagSECTITLE_CONTENT	:\tagSECTITLE_END	`\tagSENT_START	above\tagSENT_CONTENT	all\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagmetric	mother\tagmetric	i\tagSENT_CONTENT	wanted\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	something\tagSENT_CONTENT	for\tagSENT_CONTENT	that\tagSENT_CONTENT	little\tagSENT_CONTENT	girl\tagSENT_CONTENT	,\tagSENT_CONTENT	'\tagSENT_CONTENT	she\tagSENT_CONTENT	added\tagSENT_CONTENT	.\tagSENT_END	Recent\tagSENT_START	studies\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	success\tagSENT_CONTENT	with\tagSENT_CONTENT	such\tagSENT_CONTENT	seq\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	seq\tagSENT_CONTENT	and\tagSENT_CONTENT	pointer\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	and\tagSENT_CONTENT	pointer\tagSENT_CONTENT	models\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	vanilla\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	well\tagSENT_CONTENT	supported\tagSENT_CONTENT	by\tagSENT_CONTENT	previous\tagSENT_CONTENT	studies\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	still\tagSENT_CONTENT	struggle\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Two\tagSENT_START	students\tagSENT_CONTENT	are\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	scratch\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	terms\tagmetric	of\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	propagation\tagSENT_CONTENT	intuition\tagSENT_CONTENT	,\tagSENT_CONTENT	during\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	seq\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	seq\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	most\tagSENT_CONTENT	gradients\tagSENT_CONTENT	are\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	propagated\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	's\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	During\tagSENT_START	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	employ\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	decoder\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	copying\tagSENT_CONTENT	advantage\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	book\tagSENT_CONTENT	decoder\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	student\tagSENT_CONTENT	B\tagSENT_CONTENT	being\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	refer\tagSENT_CONTENT	back\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	during\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	for\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	(\tagSENT_CONTENT	but\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	trained\tagSENT_CONTENT	hard\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	well\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	situations\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Empirically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	test\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	architecture\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	surpasses\tagSENT_CONTENT	the\tagSENT_CONTENT	strong\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	baseline\tagSENT_CONTENT	significantly\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagmetric	ROUGE\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	ME\tagSENT_CONTENT	-\tagSENT_CONTENT	TEOR\tagSENT_CONTENT	)\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	qualitatively\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	baseline\tagSENT_CONTENT	summaries\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	former\tagSENT_CONTENT	achieved\tagSENT_CONTENT	higher\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	saliency\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	Q&A\tagSENT_CONTENT	blanks\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	keyword\tagSENT_CONTENT	classifier\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	similar\tagSENT_CONTENT	length\tagSENT_CONTENT	and\tagSENT_CONTENT	better\tagSENT_CONTENT	avoiding\tagSENT_CONTENT	repetitions\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Extractive\tagSENT_START	and\tagSENT_CONTENT	Abstractive\tagSENT_CONTENT	Summarization\tagSENT_CONTENT	:\tagSENT_CONTENT	Early\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	were\tagSENT_CONTENT	usually\tagSENT_CONTENT	extractive\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Pointer\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Generator\tagSECTITLE_CONTENT	Baseline\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	enabled\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	includes\tagSENT_CONTENT	summarization\tagtask	a\tagSENT_CONTENT	i\tagSENT_CONTENT	overall\tagSENT_CONTENT	encoding\tagSENT_CONTENT	steps\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	ct\tagSENT_END	Closed\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Book\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_END	The\tagSENT_START	mix\tagSENT_CONTENT	ratio\tagSENT_CONTENT	γ\tagSENT_CONTENT	is\tagSENT_CONTENT	tuned\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	.\tagSENT_END	Reinforcement\tagSECTITLE_START	Learning\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	policy\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	generates\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	train\tagSENT_CONTENT	our\tagSENT_CONTENT	reinforced\tagSENT_CONTENT	model\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	mixture\tagSENT_CONTENT	of\tagSENT_CONTENT	Eqn\tagSENT_CONTENT	.\tagSENT_CONTENT	3\tagSENT_CONTENT	and\tagSENT_CONTENT	Eqn\tagSENT_CONTENT	.\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	pure\tagSENT_CONTENT	RL\tagSENT_CONTENT	objective\tagSENT_CONTENT	would\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	receive\tagSENT_CONTENT	high\tagSENT_CONTENT	rewards\tagSENT_CONTENT	but\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	fluent\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	mainly\tagSENT_CONTENT	on\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	dataset\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Table\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	1\tagSENT_CONTENT	upon\tagSENT_CONTENT	the\tagSENT_CONTENT	pointergenerator\tagSENT_CONTENT	baseline\tagSENT_CONTENT	(\tagSENT_CONTENT	pg\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	+1.51\tagSENT_CONTENT	,\tagSENT_CONTENT	+0.74\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	+0.96\tagSENT_CONTENT	points\tagSENT_CONTENT	advantage\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	+1.43\tagSENT_CONTENT	points\tagSENT_CONTENT	advantage\tagSENT_CONTENT	in\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	further\tagSENT_CONTENT	add\tagSENT_CONTENT	the\tagSENT_CONTENT	coverage\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	to\tagSENT_CONTENT	both\tagSENT_CONTENT	baseline\tagSENT_CONTENT	and\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	pg\tagSENT_CONTENT	+\tagSENT_CONTENT	cbdec\tagSENT_CONTENT	)\tagSENT_CONTENT	again\tagSENT_CONTENT	receives\tagSENT_CONTENT	significantly\tagSENT_CONTENT	higher\tagSENT_CONTENT	2\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	(\tagSENT_CONTENT	pg\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	own\tagSENT_CONTENT	pg\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagmetric	ROUGE\tagmetric	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Analysis\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	series\tagSENT_CONTENT	of\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	tests\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	models\tagSENT_CONTENT	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	prove\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	fulfills\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	the\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	book\tagSENT_CONTENT	decoder\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	's\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	state\tagSENT_CONTENT	.\tagSENT_END	Memory\tagSECTITLE_START	Similarity\tagSECTITLE_CONTENT	Test\tagSECTITLE_END	For\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	its\tagSENT_CONTENT	encoder\tagSENT_CONTENT	's\tagSENT_CONTENT	memory\tagSENT_CONTENT	state\tagSENT_CONTENT	after\tagSENT_CONTENT	reading\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	article\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	highly\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	memory\tagSENT_CONTENT	state\tagSENT_CONTENT	after\tagSENT_CONTENT	reading\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	summary\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	contains\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	this\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	reading\tagSENT_CONTENT	along\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	encoding\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	memory\tagSENT_CONTENT	and\tagSENT_CONTENT	forgets\tagSENT_CONTENT	the\tagSENT_CONTENT	unimportant\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Studies\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Sanity\tagSECTITLE_CONTENT	Check\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	half\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	encoder\tagSENT_CONTENT	receives\tagSENT_CONTENT	significantly\tagSENT_CONTENT	higher\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.001\tagSENT_CONTENT	)\tagSENT_CONTENT	scores\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE\tagmetric	than\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	with\tagSENT_CONTENT	baseline\tagSENT_CONTENT	's\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	these\tagSENT_CONTENT	two\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	exact\tagSENT_CONTENT	same\tagSENT_CONTENT	structure\tagSENT_CONTENT	with\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	encoders\tagSENT_CONTENT	initialized\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	in\tagSENT_CONTENT	metric\tagmetric	scores\tagmetric	suggest\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	does\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	stronger\tagSENT_CONTENT	encoder\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	we\tagSENT_CONTENT	stop\tagSENT_CONTENT	the\tagSENT_CONTENT	gradient\tagSENT_CONTENT	flow\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	book\tagSENT_CONTENT	decoder\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	keep\tagSENT_CONTENT	the\tagSENT_CONTENT	flow\tagSENT_CONTENT	between\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	book\tagSENT_CONTENT	decoder\tagSENT_CONTENT	and\tagSENT_CONTENT	embedding\tagSENT_CONTENT	matrix\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE\tagmetric	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	a\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	baseline\tagSENT_CONTENT	with\tagSENT_CONTENT	2-layer\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	decoder\tagSENT_CONTENT	(\tagSENT_CONTENT	pg-2layer\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	hidden\tagSENT_CONTENT	dimension\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	baseline\tagSENT_CONTENT	(\tagSENT_CONTENT	pg\tagSENT_CONTENT	-\tagSENT_CONTENT	big\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	exceed\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	34.5\tagSENT_CONTENT	M\tagSENT_CONTENT	versus\tagSENT_CONTENT	34.4\tagSENT_CONTENT	M\tagSENT_CONTENT	parameters\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	that\tagSENT_CONTENT	neither\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	variants\tagSENT_CONTENT	can\tagSENT_CONTENT	match\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	ROUGE\tagmetric	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	proves\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	indeed\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	book\tagSENT_CONTENT	decoder\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	simply\tagSENT_CONTENT	having\tagSENT_CONTENT	more\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	Saliency\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Repetition\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	better\tagSENT_CONTENT	encoder\tagSENT_CONTENT	memory\tagSENT_CONTENT	state\tagSENT_CONTENT	to\tagSENT_CONTENT	summarize\tagSENT_CONTENT	more\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	generating\tagSENT_CONTENT	unnecessarily\tagSENT_CONTENT	lengthy\tagSENT_CONTENT	and\tagSENT_CONTENT	repeated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	besides\tagSENT_CONTENT	achieving\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	on\tagSENT_CONTENT	ROUGE\tagmetric	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Connection\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	Multi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	Our\tagSENT_START	2-decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	about\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	task\tagSENT_CONTENT	from\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	points\tagSENT_CONTENT	of\tagSENT_CONTENT	view\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	decoder\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	of\tagSENT_CONTENT	extractive\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	primary\tagSENT_CONTENT	view\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	closedbook\tagSENT_CONTENT	decoder\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	only\tagSENT_CONTENT	(\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	view\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	2-decoder\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	book\tagSENT_CONTENT	decoder\tagSENT_CONTENT	that\tagSENT_CONTENT	helps\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	memorize\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	
1504.05070	title\tagSECTITLE_END	abstract\tagSECTITLE_END	AdaSent\tagSENT_START	effectively\tagSENT_CONTENT	forms\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	of\tagSENT_CONTENT	representations\tagSENT_CONTENT	from\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	phrases\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	to\tagSENT_CONTENT	sentiment_analysis\tagtask	through\tagSENT_CONTENT	recursive\tagSENT_CONTENT	gated\tagSENT_CONTENT	local\tagSENT_CONTENT	composition\tagSENT_CONTENT	of\tagSENT_CONTENT	adjacent\tagSENT_CONTENT	segments\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	for\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Previously\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	was\tagSENT_CONTENT	often\tagSENT_CONTENT	cast\tagSENT_CONTENT	as\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	logical\tagSENT_CONTENT	form\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	recent\tagSENT_CONTENT	advances\tagSENT_CONTENT	in\tagSENT_CONTENT	distributed\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	now\tagSENT_CONTENT	common\tagSENT_CONTENT	practice\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	vectorial\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	turns\tagSENT_CONTENT	out\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	quite\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	tasks\tagSENT_CONTENT	of\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	matching\tagSENT_CONTENT	.\tagSENT_END	Perhaps\tagSENT_START	the\tagSENT_CONTENT	simplest\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	direction\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	continuous\tagSENT_CONTENT	Bag\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	Words\tagSENT_CONTENT	(\tagSENT_CONTENT	cBoW\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	global\tagSENT_CONTENT	pooling\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g\tagSENT_CONTENT	,\tagSENT_CONTENT	averagepooling\tagSENT_CONTENT	or\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	pooling\tagSENT_CONTENT	)\tagSENT_CONTENT	over\tagSENT_CONTENT	their\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	cBoW\tagSENT_START	,\tagSENT_CONTENT	although\tagSENT_CONTENT	effective\tagSENT_CONTENT	at\tagSENT_CONTENT	capturing\tagSENT_CONTENT	the\tagSENT_CONTENT	topics\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	sequential\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	has\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	capturing\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	There\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	a\tagSENT_CONTENT	surge\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	incorporated\tagSENT_CONTENT	,\tagSENT_CONTENT	mostly\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	of\tagSENT_CONTENT	various\tagSENT_CONTENT	forms\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	convolution\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	Self\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Adaptive\tagSECTITLE_CONTENT	Hierarchical\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	AdaSent\tagSENT_START	differs\tagSENT_CONTENT	from\tagSENT_CONTENT	grConv\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	neural\tagSENT_CONTENT	sentence\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	try\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	by\tagSENT_CONTENT	forming\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	of\tagSENT_CONTENT	abstractions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	by\tagSENT_CONTENT	feeding\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchy\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	summarization\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	classifier\tagSENT_CONTENT	,\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	gating\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	decide\tagSENT_CONTENT	the\tagSENT_CONTENT	weight\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	level\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	consensus\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Structure\tagSECTITLE_END	Before\tagSENT_START	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	enter\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	pyramid\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	transformation\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	Rd\tagSENT_CONTENT	to\tagSENT_CONTENT	RD\tagSENT_CONTENT	with\tagSENT_CONTENT	D\tagSENT_CONTENT	≥\tagSENT_CONTENT	d.\tagSENT_CONTENT	That\tagSENT_CONTENT	way\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	allow\tagSENT_CONTENT	phrases\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	be\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	higher\tagSENT_CONTENT	dimension\tagSENT_CONTENT	than\tagSENT_CONTENT	words\tagSENT_CONTENT	for\tagSENT_CONTENT	their\tagSENT_CONTENT	richer\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	Local\tagSECTITLE_START	Composition\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Level\tagSECTITLE_CONTENT	Pooling\tagSECTITLE_END	The\tagSENT_START	fundamental\tagSENT_CONTENT	assumption\tagSENT_CONTENT	behind\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	AdaSent\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	encoded\tagSENT_CONTENT	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	5\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	of\tagSENT_CONTENT	length\tagSENT_CONTENT	t\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	convex\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	its\tagSENT_CONTENT	t\tagSENT_CONTENT	−\tagSENT_CONTENT	1\tagSENT_CONTENT	prefix\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	−\tagSENT_CONTENT	1\tagSENT_CONTENT	suffix\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	two\tagSENT_CONTENT	.\tagSENT_END	Gating\tagSECTITLE_START	Network\tagSECTITLE_END	Back\tagSECTITLE_START	Propagation\tagSECTITLE_CONTENT	through\tagSECTITLE_CONTENT	Structure\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setting\tagSECTITLE_END	Training\tagSECTITLE_END	Regularization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Recurrent\tagSECTITLE_CONTENT	Matrix\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Experiment\tagSECTITLE_START	Results\tagSECTITLE_END	Model\tagSECTITLE_END	shows\tagSENT_START	the\tagSENT_CONTENT	projected\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	AdaSent\tagSENT_CONTENT	(\tagSENT_CONTENT	left\tagSENT_CONTENT	column\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	cBoW\tagSENT_CONTENT	(\tagSENT_CONTENT	right\tagSENT_CONTENT	column\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	SUBJ\tagdataset	(\tagSENT_CONTENT	1st\tagSENT_CONTENT	row\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	MPQA\tagSENT_CONTENT	(\tagSENT_CONTENT	2nd\tagSENT_CONTENT	row\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	TREC\tagSENT_CONTENT	(\tagSENT_CONTENT	3rd\tagSENT_CONTENT	row\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	sentiment_analysis\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	empirical\tagSENT_CONTENT	results\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	and\tagSENT_CONTENT	robustness\tagSENT_CONTENT	of\tagSENT_CONTENT	AdaSent\tagSENT_CONTENT	in\tagSENT_CONTENT	short\tagSENT_CONTENT	sequence\tagSENT_CONTENT	modeling\tagSENT_CONTENT	.\tagSENT_END	
P18-1230	title\tagSECTITLE_END	Incorporating\tagSENT_START	Glosses\tagSENT_CONTENT	into\tagSENT_CONTENT	word_sense_disambiguation\tagtask	abstract\tagSECTITLE_END	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	poly\tagSENT_CONTENT	-\tagSENT_CONTENT	semous\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	particular\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	standing\tagSENT_CONTENT	challenge\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	gloss\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	extensionally\tagSENT_CONTENT	defines\tagSENT_CONTENT	word_sense_disambiguation\tagtask	meaning\tagSENT_CONTENT	,\tagSENT_CONTENT	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	known\tagSENT_CONTENT	Lesk\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	glosses\tagSENT_CONTENT	of\tagSENT_CONTENT	hypernyms\tagSENT_CONTENT	and\tagSENT_CONTENT	hyponyms\tagSENT_CONTENT	can\tagSENT_CONTENT	enrich\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	gloss\tagSENT_CONTENT	information\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	help\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	We\tagSENT_START	extend\tagSENT_CONTENT	the\tagSENT_CONTENT	gloss\tagSENT_CONTENT	module\tagSENT_CONTENT	in\tagSENT_CONTENT	GAS\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	framework\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	mirror\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchies\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	in\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Knowledge\tagSENT_START	-\tagSENT_CONTENT	based\tagSENT_CONTENT	WSD\tagSENT_CONTENT	methods\tagSENT_CONTENT	mainly\tagSENT_CONTENT	exploit\tagSENT_CONTENT	two\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	to\tagSENT_CONTENT	disambiguate\tagSENT_CONTENT	polysemous\tagSENT_CONTENT	words\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	The\tagSENT_CONTENT	gloss\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	defines\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	is\tagSENT_CONTENT	mainly\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	Lesk\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	variants\tagSENT_CONTENT	.\tagSENT_END	trains\tagSENT_START	word_sense_disambiguation\tagtask	through\tagSENT_CONTENT	learning\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	from\tagSENT_CONTENT	glosses\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Recent\tagSENT_START	researches\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	memory\tagSENT_CONTENT	network\tagSENT_CONTENT	obtains\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	spoken\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	Incorporating\tagSECTITLE_START	Glosses\tagSECTITLE_CONTENT	into\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Sense\tagSECTITLE_CONTENT	Disambiguation\tagSECTITLE_END	Architecture\tagSECTITLE_START	of\tagSECTITLE_CONTENT	GAS\tagSECTITLE_END	word_sense_disambiguation\tagtask	according\tagSENT_CONTENT	to\tagSENT_CONTENT	|s\tagSENT_CONTENT	t\tagSENT_CONTENT	|\tagSENT_CONTENT	3\tagSENT_CONTENT	senses\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	|s\tagSENT_CONTENT	t\tagSENT_CONTENT	|\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sense\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	word\tagSENT_CONTENT	wt\tagSENT_CONTENT	.\tagSENT_END	Gloss\tagSECTITLE_START	Module\tagSECTITLE_END	Scoring\tagSECTITLE_START	Module\tagSECTITLE_END	Figure\tagSENT_START	2\tagSENT_CONTENT	:\tagSENT_CONTENT	Overview\tagSENT_CONTENT	of\tagSENT_CONTENT	Gloss\tagSENT_CONTENT	-\tagSENT_CONTENT	augmented\tagSENT_CONTENT	Memory\tagSENT_CONTENT	Network\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	Context\tagSECTITLE_START	Module\tagSECTITLE_END	Gloss\tagSECTITLE_START	Module\tagSECTITLE_END	Gloss\tagSECTITLE_START	Reader\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	There\tagSENT_START	are\tagSENT_CONTENT	two\tagSENT_CONTENT	reasons\tagSENT_CONTENT	:\tagSENT_CONTENT	One\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	polysemous\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	about\tagSENT_CONTENT	80\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	nouns\tagSENT_CONTENT	and\tagSENT_CONTENT	verbs\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	frequent\tagSENT_CONTENT	relations\tagSENT_CONTENT	among\tagSENT_CONTENT	word_sense_disambiguation\tagtask	for\tagSENT_CONTENT	nouns\tagSENT_CONTENT	and\tagSENT_CONTENT	verbs\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	hypernymy\tagSENT_CONTENT	and\tagSENT_CONTENT	hyponymy\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Relation\tagSECTITLE_START	Fusion\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Memory\tagSECTITLE_START	Module\tagSECTITLE_END	the\tagSENT_START	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	c\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	module\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	gloss\tagSENT_CONTENT	vectors\tagSENT_CONTENT	{\tagSENT_CONTENT	g\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	g\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	g\tagSENT_CONTENT	|st|\tagSENT_CONTENT	}\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	gloss\tagSENT_CONTENT	module\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	|s\tagSENT_CONTENT	t\tagSENT_CONTENT	|\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	The\tagSENT_START	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	f\tagmetric	calculates\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relationship\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	gloss\tagSENT_CONTENT	and\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	taking\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	set\tagSENT_END	Scoring\tagSECTITLE_START	Module\tagSECTITLE_END	word_sense_disambiguation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	calculated\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	Dataset\tagSECTITLE_END	For\tagSENT_START	fair\tagSENT_CONTENT	comparison\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	which\tagSENT_CONTENT	includes\tagSENT_CONTENT	five\tagSENT_CONTENT	standard\tagSENT_CONTENT	all\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	WSD\tagSENT_CONTENT	datasets\tagSENT_CONTENT	from\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	It\tagSENT_START	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	from\tagSENT_CONTENT	352\tagSENT_CONTENT	documents\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	largest\tagSENT_CONTENT	manually\tagSENT_CONTENT	annotated\tagSENT_CONTENT	corpus\tagSENT_CONTENT	for\tagSENT_CONTENT	WSD\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Systems\tagSECTITLE_START	to\tagSECTITLE_CONTENT	be\tagSECTITLE_CONTENT	Compared\tagSECTITLE_END	Knowledge\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Systems\tagSECTITLE_END	is\tagSENT_START	a\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	Lesk\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	word_sense_disambiguation\tagtask	defined\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	distributional\tagSENT_CONTENT	semantic\tagSENT_CONTENT	space\tagSENT_CONTENT	to\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagSENT_CONTENT	gloss\tagSENT_CONTENT	-\tagSENT_CONTENT	context\tagSENT_CONTENT	overlap\tagSENT_CONTENT	.\tagSENT_END	word_sense_disambiguation\tagtask	via\tagSENT_CONTENT	its\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relations\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	to\tagSENT_CONTENT	WSD\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	Systems\tagSECTITLE_END	Neural\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Systems\tagSECTITLE_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	English\tagSECTITLE_START	all\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	words\tagSECTITLE_CONTENT	results\tagSECTITLE_END	Multiple\tagSECTITLE_START	Passes\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Consider\tagSENT_START	word_sense_disambiguation\tagtask	that\tagSENT_CONTENT	we\tagSENT_CONTENT	meet\tagSENT_CONTENT	an\tagSENT_CONTENT	unknown\tagSENT_CONTENT	word\tagSENT_CONTENT	x\tagSENT_CONTENT	11\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	look\tagSENT_CONTENT	11\tagSENT_END	But\tagSENT_START	the\tagSENT_CONTENT	g\tagSENT_CONTENT	2\tagSENT_CONTENT	and\tagSENT_CONTENT	g\tagSENT_CONTENT	3\tagSENT_CONTENT	may\tagSENT_CONTENT	need\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	word\tagSENT_CONTENT	pianist\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	music\tagSENT_CONTENT	and\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	glosses\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	labeled\tagSENT_CONTENT	context\tagSENT_CONTENT	data\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	exploit\tagSENT_CONTENT	the\tagSENT_CONTENT	background\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	to\tagSENT_CONTENT	disambiguate\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	next\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	consider\tagSENT_CONTENT	integrating\tagSENT_CONTENT	the\tagSENT_CONTENT	rich\tagSENT_CONTENT	structural\tagSENT_CONTENT	information\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	
1801.08290	title\tagSECTITLE_END	A\tagSENT_START	Question\tagSENT_CONTENT	-\tagSENT_CONTENT	Focused\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	Factor\tagSENT_CONTENT	Attention\tagSENT_CONTENT	Network\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	abstract\tagSECTITLE_END	Neural\tagSENT_START	network\tagSENT_CONTENT	models\tagSENT_CONTENT	recently\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	(\tagSENT_CONTENT	MC\tagSENT_CONTENT	)\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	machine\tagSENT_CONTENT	is\tagSENT_CONTENT	expected\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	understanding\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previously\tagSENT_CONTENT	released\tagSENT_CONTENT	datasets\tagSENT_CONTENT	are\tagSENT_CONTENT	closed\tagSENT_CONTENT	-\tagSENT_CONTENT	world\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	answers\tagSENT_CONTENT	are\tagSENT_CONTENT	formulated\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	passages\tagSENT_CONTENT	.\tagSENT_END	attempted\tagSENT_START	to\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	this\tagSENT_CONTENT	issue\tagSENT_CONTENT	by\tagSENT_CONTENT	proposing\tagSENT_CONTENT	the\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	dataset\tagSENT_CONTENT	where\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	formed\tagSENT_CONTENT	only\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	article\tagSENT_CONTENT	summaries\tagSENT_CONTENT	without\tagSENT_CONTENT	accessing\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	many\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	(;\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	mostly\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	similarity\tagSENT_CONTENT	for\tagSENT_CONTENT	extracting\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	span\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	focused\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	factor\tagSENT_CONTENT	attention\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	document\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	AMANDA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	aggregate\tagSENT_CONTENT	evidence\tagSENT_CONTENT	distributed\tagSENT_CONTENT	across\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	identifies\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	question\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	factor\tagSENT_CONTENT	attentive\tagSENT_CONTENT	encoding\tagSENT_CONTENT	approach\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	synthesize\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	evidence\tagSENT_CONTENT	across\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	subsume\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	answer\tagSENT_CONTENT	type\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	attentional\tagSENT_CONTENT	question\tagSENT_CONTENT	aggregation\tagSENT_CONTENT	mecha-\tagSENT_CONTENT	nism\tagSENT_CONTENT	which\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	portions\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Problem\tagSECTITLE_START	Definition\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	an\tagSENT_CONTENT	MC\tagSENT_CONTENT	system\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	span\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Network\tagSECTITLE_START	Architecture\tagSECTITLE_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Embedding\tagSECTITLE_END	Sequence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Encoding\tagSECTITLE_END	Let\tagSENT_START	e\tagSENT_CONTENT	pt\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	qt\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	tth\tagSENT_CONTENT	embedding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	respectively\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	level\tagSENT_CONTENT	encoding\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_END	Cartesian\tagSECTITLE_START	Similarity\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	The\tagSENT_START	attention\tagSENT_CONTENT	matrix\tagSENT_CONTENT	is\tagSENT_CONTENT	calculated\tagSENT_CONTENT	by\tagSENT_CONTENT	taking\tagSENT_CONTENT	dot\tagSENT_CONTENT	products\tagSENT_CONTENT	between\tagSENT_CONTENT	all\tagSENT_CONTENT	possible\tagSENT_CONTENT	combinations\tagSENT_CONTENT	of\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	encoding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	fora\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	A\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	measure\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	encoding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ith\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Question\tagSECTITLE_START	-\tagSECTITLE_CONTENT	dependent\tagSECTITLE_CONTENT	Passage\tagSECTITLE_CONTENT	Encoding\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	jointly\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Each\tagSENT_START	row\tagSENT_CONTENT	of\tagSENT_CONTENT	R\tagSENT_CONTENT	measures\tagSENT_CONTENT	how\tagSENT_CONTENT	relevant\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	question_answering\tagtask	is\tagSENT_CONTENT	denoted\tagSENT_CONTENT	as\tagSENT_CONTENT	S\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	T\tagSENT_CONTENT	×2H\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	factor\tagSECTITLE_CONTENT	Attentive\tagSECTITLE_CONTENT	Encoding\tagSECTITLE_END	R\tagSENT_START	H×m×H\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	3-way\tagSENT_CONTENT	tensor\tagSENT_CONTENT	and\tagSENT_CONTENT	m\tagmetric	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	factors\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	every\tagSENT_CONTENT	vector\tagSENT_CONTENT	f\tagSENT_CONTENT	m\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	a\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	operation\tagSENT_CONTENT	overall\tagSENT_CONTENT	the\tagSENT_CONTENT	elements\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	attention\tagSENT_CONTENT	value\tagSENT_CONTENT	:\tagSENT_END	We\tagSENT_START	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	row\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	softmax\tagSENT_CONTENT	function\tagSENT_CONTENT	on\tagSENT_CONTENT	F\tagmetric	to\tagSENT_CONTENT	normalize\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	weights\tagSENT_CONTENT	,\tagSENT_CONTENT	obtaining˜Fobtaining˜\tagSENT_CONTENT	obtaining˜F\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	T\tagSENT_CONTENT	×T\tagSENT_CONTENT	.\tagSENT_END	Question\tagSECTITLE_START	-\tagSECTITLE_CONTENT	focused\tagSECTITLE_CONTENT	Attentional\tagSECTITLE_CONTENT	Pointing\tagSECTITLE_END	Unlike\tagSENT_START	previous\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	predict\tagSENT_CONTENT	question_answering\tagtask	directly\tagSENT_CONTENT	from\tagSENT_CONTENT	contextual\tagSENT_CONTENT	passage\tagSENT_CONTENT	encoding\tagSENT_CONTENT	or\tagSENT_CONTENT	use\tagSENT_CONTENT	another\tagSENT_CONTENT	decoder\tagSENT_CONTENT	for\tagSENT_CONTENT	generating\tagSENT_CONTENT	the\tagSENT_CONTENT	pointers\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	(\tagSENT_CONTENT	q\tagSENT_CONTENT	f\tagSENT_CONTENT	)\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	q\tagSENT_CONTENT	ma\tagSENT_CONTENT	aggregates\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	relevant\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	no\tagSENT_CONTENT	wh\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	two\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	question\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	calculating˜qcalculating˜\tagSENT_CONTENT	calculating˜q\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	:\tagSENT_END	e\tagSENT_START	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	passage\tagSENT_CONTENT	P\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	given\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	The\tagSENT_START	joint\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	for\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	question_answering\tagtask	a\tagSENT_CONTENT	is\tagSENT_CONTENT	given\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	Visualization\tagSECTITLE_END	In\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	clear\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	question\tagSENT_CONTENT	word\tagSENT_CONTENT	name\tagSENT_CONTENT	is\tagSENT_CONTENT	getting\tagSENT_CONTENT	a\tagSENT_CONTENT	higher\tagSENT_CONTENT	weight\tagSENT_CONTENT	than\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	AMANDA\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	challenging\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	NewsQA\tagdataset	,\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	.\tagSENT_END	Datasets\tagSECTITLE_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	300-dimension\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	(\tagSENT_CONTENT	Pennington\tagSENT_CONTENT	,\tagSENT_CONTENT	Socher\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Manning\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	update\tagSENT_CONTENT	them\tagmetric	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	consider\tagSENT_CONTENT	a\tagSENT_CONTENT	maximum\tagSENT_CONTENT	of\tagSENT_CONTENT	150\tagSENT_CONTENT	words\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	ranked\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	snippets\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	quickly\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	noisy\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Effectiveness\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Components\tagSECTITLE_END	The\tagSENT_START	use\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	factors\tagSENT_CONTENT	helps\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	synthesizing\tagSENT_CONTENT	information\tagSENT_CONTENT	distributed\tagSENT_CONTENT	across\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	63.3\tagSENT_START	62.5\tagSENT_CONTENT	 \tagSENT_CONTENT	could\tagSENT_CONTENT	not\tagSENT_CONTENT	figure\tagSENT_CONTENT	out\tagSENT_CONTENT	the\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	reference\tagSENT_CONTENT	and\tagSENT_CONTENT	wrongly\tagSENT_CONTENT	predicted\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	apps\tagSENT_CONTENT	.\tagSENT_END	Another\tagSENT_START	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	include\tagSENT_CONTENT	question_answering\tagtask	during\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSENT_START	studies\tagSENT_CONTENT	of\tagSENT_CONTENT	other\tagSENT_CONTENT	components\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	character\tagSENT_CONTENT	embedding\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	during\tagSENT_CONTENT	prediction\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Variation\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	factors\tagSENT_CONTENT	(\tagSENT_CONTENT	m\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	q\tagSENT_CONTENT	ma\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	AMANDA\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	values\tagSENT_CONTENT	of\tagSENT_CONTENT	m.\tagSENT_END	Quantitative\tagSECTITLE_START	Error\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	We\tagSENT_START	analyzed\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	AMANDA\tagSENT_CONTENT	across\tagSENT_CONTENT	different\tagSENT_CONTENT	question\tagSENT_CONTENT	types\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	predicted\tagSENT_CONTENT	answer\tagSENT_CONTENT	lengths.(a\tagSENT_CONTENT	)\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	performs\tagSENT_CONTENT	poorly\tagSENT_CONTENT	on\tagSENT_CONTENT	why\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	questions\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	longer.(b\tagSENT_CONTENT	)\tagSENT_END	Qualitative\tagSECTITLE_START	Error\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	On\tagSENT_START	the\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	AMANDA\tagSENT_CONTENT	predicted\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	25.1\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	used\tagSENT_START	a\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	gating\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	correlation\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	This\tagSENT_START	in\tagSENT_CONTENT	turn\tagSENT_CONTENT	helps\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	synthesizing\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	focused\tagSENT_CONTENT	multifactor\tagSENT_CONTENT	attention\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	AMANDA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	aggregate\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	evidence\tagSENT_CONTENT	from\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	deeper\tagSENT_CONTENT	understanding\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	extracting\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	span\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	with\tagSENT_CONTENT	suitable\tagSENT_CONTENT	answer\tagSENT_CONTENT	type\tagSENT_CONTENT	.\tagSENT_END	
P09-1113	title\tagSECTITLE_END	Distant\tagSENT_START	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	without\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_END	abstract\tagSECTITLE_END	Modern\tagSENT_START	models\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	ACE\tagSENT_CONTENT	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	from\tagSENT_CONTENT	small\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	At\tagSENT_START	least\tagSENT_CONTENT	three\tagSENT_CONTENT	learning\tagSENT_CONTENT	paradigms\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	extracting\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	text\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	learning\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	person\tagSENT_CONTENT	is\tagSENT_CONTENT	employed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	organization\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	geographic\tagSENT_CONTENT	entity\tagSENT_CONTENT	is\tagSENT_CONTENT	located\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	region\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	ACE\tagSENT_START	systems\tagSENT_CONTENT	then\tagSENT_CONTENT	extract\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical\tagSENT_CONTENT	,\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	supervised\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	to\tagSENT_CONTENT	label\tagSENT_CONTENT	relationship_extraction\tagtask	holding\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	optionally\tagSENT_CONTENT	combining\tagSENT_CONTENT	relation\tagSENT_CONTENT	mentions\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	suffers\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	problems\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	alternative\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	extracts\tagSENT_CONTENT	strings\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	large\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	clusters\tagSENT_CONTENT	and\tagSENT_CONTENT	simplifies\tagSENT_CONTENT	these\tagSENT_CONTENT	word\tagSENT_CONTENT	strings\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	relation\tagSENT_CONTENT	-\tagSENT_CONTENT	strings\tagSENT_CONTENT	(;\tagSENT_CONTENT	.\tagSENT_END	Distant\tagSENT_START	supervision\tagSENT_CONTENT	is\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	for\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	(\tagSENT_END	Our\tagSENT_START	algorithm\tagSENT_CONTENT	uses\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	semantic\tagSENT_CONTENT	database\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Supervision\tagSENT_START	by\tagSENT_CONTENT	a\tagSENT_CONTENT	database\tagSENT_CONTENT	also\tagSENT_CONTENT	means\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	unlike\tagSENT_CONTENT	in\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	classifier\tagSENT_CONTENT	uses\tagSENT_CONTENT	canonical\tagSENT_CONTENT	names\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	aggregate\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	many\tagSENT_CONTENT	different\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	that\tagSENT_CONTENT	pair\tagSENT_CONTENT	appeared\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	,\tagSENT_CONTENT	allowing\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	our\tagSENT_CONTENT	classifier\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	more\tagSENT_CONTENT	accurate\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSECTITLE_START	work\tagSECTITLE_END	Except\tagSENT_START	for\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	discussed\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	previous\tagSENT_CONTENT	supervised\tagSENT_CONTENT	or\tagSENT_CONTENT	bootstrapping\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	have\tagSENT_CONTENT	typically\tagSENT_CONTENT	relied\tagSENT_CONTENT	on\tagSENT_CONTENT	relatively\tagSENT_CONTENT	small\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	on\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	distinct\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Many\tagSENT_START	early\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	used\tagSENT_CONTENT	little\tagSENT_CONTENT	or\tagSENT_CONTENT	no\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Perhaps\tagSENT_START	most\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	effective\tagSENT_CONTENT	method\tagSENT_CONTENT	of\tagSENT_CONTENT	who\tagSENT_CONTENT	extract\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	a\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	page\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	supervision\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	page\tagSENT_CONTENT	's\tagSENT_CONTENT	infobox\tagSENT_CONTENT	.\tagSENT_END	Freebase\tagSECTITLE_END	We\tagSENT_START	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	individual\tagSENT_CONTENT	ordered\tagSENT_CONTENT	pairs\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	as\tagSENT_CONTENT	'\tagSENT_CONTENT	relation\tagSENT_CONTENT	instances\tagSENT_CONTENT	'\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	freely\tagSENT_CONTENT	available\tagSENT_CONTENT	online\tagSENT_CONTENT	database\tagSENT_CONTENT	of\tagSENT_CONTENT	structured\tagSENT_CONTENT	semantic\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Architecture\tagSECTITLE_END	The\tagSENT_START	intuition\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	us\tagSENT_CONTENT	a\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	entity\tagSENT_CONTENT	pairs\tagSENT_CONTENT	that\tagSENT_CONTENT	participate\tagSENT_CONTENT	in\tagSENT_CONTENT	those\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	training\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	identical\tagSENT_CONTENT	tuples\tagSENT_CONTENT	(\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	entity1\tagSENT_CONTENT	,\tagSENT_CONTENT	entity2\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	different\tagSENT_CONTENT	sentences\tagSENT_CONTENT	are\tagSENT_CONTENT	combined\tagSENT_CONTENT	,\tagSENT_CONTENT	creating\tagSENT_CONTENT	a\tagSENT_CONTENT	richer\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	corpus\tagSENT_CONTENT	is\tagSENT_CONTENT	run\tagSENT_CONTENT	through\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	regression\tagSENT_CONTENT	classifier\tagSENT_CONTENT	predicts\tagSENT_CONTENT	a\tagSENT_CONTENT	relation\tagSENT_CONTENT	name\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	it\tagSENT_CONTENT	appeared\tagSENT_CONTENT	.\tagSENT_END	Consider\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	imagining\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	we\tagSENT_CONTENT	had\tagSENT_CONTENT	two\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	relation\tagSENT_CONTENT	:\tagSENT_CONTENT	Virginia\tagSENT_CONTENT	,\tagSENT_CONTENT	Richmond\tagSENT_CONTENT	and\tagSENT_CONTENT	France\tagSENT_CONTENT	,\tagSENT_CONTENT	Nantes\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	second\tagSENT_CONTENT	sentence\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	mention\tagSENT_CONTENT	that\tagSENT_CONTENT	Saving\tagSENT_CONTENT	Private\tagSENT_CONTENT	Ryan\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	film\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	so\tagSENT_CONTENT	could\tagSENT_CONTENT	instead\tagSENT_CONTENT	be\tagSENT_CONTENT	evidence\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	consider\tagSENT_CONTENT	'\tagSENT_CONTENT	Robert\tagSENT_CONTENT	Mueller\tagSENT_CONTENT	directed\tagSENT_CONTENT	the\tagSENT_CONTENT	FBI\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Features\tagSECTITLE_END	Lexical\tagSECTITLE_START	features\tagSECTITLE_END	Syntactic\tagSECTITLE_START	features\tagSECTITLE_END	Named\tagSECTITLE_START	entity\tagSECTITLE_CONTENT	tag\tagSECTITLE_CONTENT	features\tagSECTITLE_END	The\tagSENT_START	tagger\tagSENT_CONTENT	provides\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	label\tagSENT_CONTENT	from\tagSENT_CONTENT	{\tagSENT_CONTENT	person\tagSENT_CONTENT	,\tagSENT_CONTENT	location\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	miscellaneous\tagSENT_CONTENT	,\tagSENT_CONTENT	none\tagSENT_CONTENT	}\tagSENT_CONTENT	.\tagSENT_END	Feature\tagSECTITLE_START	conjunction\tagSECTITLE_END	Much\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	is\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	tabular\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	,\tagSENT_CONTENT	meaning\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	are\tagSENT_CONTENT	more\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	Parsing\tagSECTITLE_START	and\tagSECTITLE_CONTENT	chunking\tagSECTITLE_END	Training\tagSECTITLE_START	and\tagSECTITLE_CONTENT	testing\tagSECTITLE_END	For\tagSENT_START	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	experiments\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	section\tagSENT_CONTENT	7.1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	half\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	are\tagSENT_CONTENT	not\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	later\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	against\tagSENT_CONTENT	newly\tagSENT_CONTENT	discovered\tagSENT_CONTENT	instances\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	all\tagSENT_CONTENT	1.8\tagSENT_CONTENT	million\tagSENT_CONTENT	relation\tagSENT_CONTENT	instances\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	all\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	extract\tagSENT_CONTENT	relationship_extraction\tagtask	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	instances\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	already\tagSENT_CONTENT	in\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	.\tagSENT_END	Towards\tagSENT_START	this\tagSENT_CONTENT	end\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	build\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	phase\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	by\tagSENT_CONTENT	randomly\tagSENT_CONTENT	selecting\tagSENT_CONTENT	entity\tagSENT_CONTENT	pairs\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	any\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	relation\tagSENT_CONTENT	and\tagSENT_CONTENT	extracting\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	classifier\tagSENT_CONTENT	takes\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	an\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	returns\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	a\tagSENT_CONTENT	confidence\tagSENT_CONTENT	score\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	belonging\tagSENT_CONTENT	to\tagSENT_CONTENT	that\tagSENT_CONTENT	relation\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	labels\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	ways\tagSENT_CONTENT	:\tagSENT_CONTENT	automatically\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	holding\tagSENT_CONTENT	out\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	relation\tagSENT_CONTENT	data\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	comparing\tagSENT_CONTENT	newly\tagSENT_CONTENT	discovered\tagSENT_CONTENT	relation\tagSENT_CONTENT	instances\tagSENT_CONTENT	against\tagSENT_CONTENT	this\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	manually\tagSENT_CONTENT	,\tagSENT_CONTENT	having\tagSENT_CONTENT	humans\tagSENT_CONTENT	who\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	positively\tagSENT_CONTENT	labeled\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	and\tagSENT_CONTENT	mark\tagSENT_CONTENT	whether\tagSENT_CONTENT	relationship_extraction\tagtask	indeed\tagSENT_CONTENT	holds\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	participants\tagSENT_CONTENT	.\tagSENT_END	Held\tagSECTITLE_START	-\tagSECTITLE_CONTENT	out\tagSECTITLE_CONTENT	evaluation\tagSECTITLE_END	Human\tagSECTITLE_START	evaluation\tagSECTITLE_END	For\tagSENT_START	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	10\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	appeared\tagSENT_CONTENT	most\tagSENT_CONTENT	frequently\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	(\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	classifier\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	took\tagSENT_CONTENT	samples\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	100\tagSENT_CONTENT	and\tagSENT_CONTENT	1000\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	generated\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	experiment\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sent\tagSENT_CONTENT	these\tagSENT_CONTENT	to\tagSENT_CONTENT	Mechanical\tagSENT_CONTENT	Turk\tagSENT_CONTENT	for\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	assigned\tagSENT_CONTENT	the\tagSENT_CONTENT	truth\tagSENT_CONTENT	or\tagSENT_CONTENT	falsehood\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	majority\tagSENT_CONTENT	vote\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	labels\tagSENT_CONTENT	;\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	tie\tagSENT_CONTENT	(\tagSENT_CONTENT	one\tagSENT_CONTENT	vote\tagSENT_CONTENT	each\tagSENT_CONTENT	way\tagSENT_CONTENT	)\tagSENT_END	Discussion\tagSECTITLE_END	Our\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	precision\tagSENT_CONTENT	patterns\tagSENT_CONTENT	fora\tagSENT_CONTENT	reasonably\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	topranking\tagSENT_CONTENT	100\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	use\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	either\tagSENT_CONTENT	alone\tagSENT_CONTENT	or\tagSENT_CONTENT	in\tagSENT_CONTENT	combination\tagSENT_CONTENT	with\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	examine\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	which\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	features\tagSENT_CONTENT	seem\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	results\tagSENT_CONTENT	thus\tagSENT_CONTENT	suggest\tagSENT_CONTENT	that\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	indeed\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	syntax\tagSENT_CONTENT	occurs\tagSENT_CONTENT	in\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	individual\tagSENT_CONTENT	patterns\tagSENT_CONTENT	are\tagSENT_CONTENT	particularly\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	where\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	nearby\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	structure\tagSENT_CONTENT	but\tagSENT_CONTENT	distant\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	
P15-2041	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	directly\tagSENT_CONTENT	capturing\tagSENT_CONTENT	sequence\tagSENT_CONTENT	information\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	improvements\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	(\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	1.9\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	1\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	CCGBank\tagdataset	,\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	and\tagSENT_CONTENT	biomedical\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Combinatory\tagSENT_START	Categorial\tagSENT_CONTENT	Grammar\tagSENT_CONTENT	(\tagSENT_CONTENT	CCG\tagSENT_CONTENT	;\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	highly\tagSENT_CONTENT	lexicalized\tagSENT_CONTENT	formalism\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	 \tagSENT_CONTENT	uses\tagSENT_CONTENT	over\tagSENT_CONTENT	400\tagSENT_CONTENT	lexical\tagSENT_CONTENT	categories\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	ccg_supertagging\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	about\tagSENT_CONTENT	50\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	for\tagSENT_CONTENT	typical\tagSENT_CONTENT	CFG\tagSENT_CONTENT	parsers\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	assignment\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical\tagSENT_CONTENT	categories\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	be\tagSENT_CONTENT	solved\tagSENT_CONTENT	reasonably\tagSENT_CONTENT	well\tagSENT_CONTENT	by\tagSENT_CONTENT	treating\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	often\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	show\tagSENT_START	that\tagSENT_CONTENT	high\tagmetric	tagging\tagmetric	accuracy\tagmetric	can\tagSENT_CONTENT	be\tagSENT_CONTENT	achieved\tagSENT_CONTENT	by\tagSENT_CONTENT	leaving\tagSENT_CONTENT	some\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	to\tagSENT_CONTENT	resolve\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	with\tagSENT_CONTENT	enough\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	reduction\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	tags\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	parsing\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	is\tagSENT_CONTENT	greatly\tagSENT_CONTENT	increased\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	improving\tagSENT_CONTENT	parsing\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	,\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	also\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	impact\tagSENT_CONTENT	on\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracy\tagmetric	(\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	derivation\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	is\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	at\tagSENT_CONTENT	both\tagSENT_CONTENT	train-*All\tagSENT_CONTENT	work\tagSENT_CONTENT	was\tagSENT_CONTENT	completed\tagSENT_CONTENT	before\tagSENT_CONTENT	the\tagSENT_CONTENT	author\tagSENT_CONTENT	joined\tagSENT_CONTENT	ing\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Despite\tagSENT_START	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	drawbacks\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	relies\tagSENT_CONTENT	too\tagSENT_CONTENT	heavily\tagSENT_CONTENT	on\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	lower\tagSENT_CONTENT	accuracy\tagmetric	on\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	data\tagSENT_END	introduced\tagSENT_START	a\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	addressed\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	two\tagSENT_CONTENT	problems\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	above\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	The\tagSENT_START	input\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	word\tagSENT_CONTENT	at\tagSENT_CONTENT	position\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	ccg_supertagging\tagtask	is\tagSENT_CONTENT	being\tagSENT_CONTENT	predicted\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	parameterization\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	matrices\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	during\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	ccg_supertagging\tagtask	only\tagSENT_CONTENT	uses\tagSENT_CONTENT	continuous\tagSENT_CONTENT	vector\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	each\tagSENT_CONTENT	feature\tagSENT_CONTENT	type\tagSENT_CONTENT	has\tagSENT_CONTENT	an\tagSENT_CONTENT	associated\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	table\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	maps\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	distributed\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	L\tagSENT_START	care\tagSENT_CONTENT	also\tagSENT_CONTENT	randomly\tagSENT_CONTENT	initialized\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	tables\tagSENT_CONTENT	are\tagSENT_CONTENT	modified\tagSENT_CONTENT	during\tagSENT_CONTENT	ccg_supertagging\tagtask	using\tagSENT_CONTENT	backpropagation\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	accuracy\tagmetric	with\tagSENT_CONTENT	ccg_supertagging\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	tagger\tagSENT_CONTENT	of\tagSENT_CONTENT	Lewis\tagSENT_CONTENT	and\tagSENT_CONTENT	Steedman\tagSENT_CONTENT	(\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_END	(\tagSENT_START	henceforth\tagSENT_CONTENT	NN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracy\tagmetric	using\tagSENT_CONTENT	these\tagSENT_CONTENT	three\tagSENT_CONTENT	supertaggers\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	front\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	parser\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	instead\tagSENT_CONTENT	implemented\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	dropout\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	regularization\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	tables\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	capacity\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	mainly\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	tables\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	their\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	experimented\tagSENT_CONTENT	during\tagSENT_CONTENT	development\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	dropout\tagSENT_CONTENT	rates\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	choice\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	optimal\tagSENT_CONTENT	in\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Supertagging\tagSECTITLE_START	Results\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	dropout\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	experiments\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	unlike\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	no\tagSENT_CONTENT	tag\tagSENT_CONTENT	dictionaries\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_CONTENT	    \tagSENT_END	ger\tagSENT_START	drops\tagSENT_CONTENT	about\tagSENT_CONTENT	1\tagSENT_CONTENT	%\tagSENT_CONTENT	with\tagSENT_CONTENT	automatically\tagSENT_CONTENT	assigned\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	our\tagSENT_CONTENT	RNN\tagSENT_CONTENT	model\tagSENT_CONTENT	gives\tagSENT_CONTENT	higher\tagmetric	accuracy\tagmetric	(\tagSENT_CONTENT	+0.47\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	ccg_supertagging\tagtask	with\tagSENT_CONTENT	gold\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	compares\tagSENT_START	ccg_supertagging\tagtask	for\tagSENT_CONTENT	multi\tagmetric	-\tagmetric	tagging\tagmetric	accuracy\tagmetric	at\tagSENT_CONTENT	the\tagSENT_CONTENT	default\tagSENT_CONTENT	β\tagSENT_CONTENT	levels\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	parser\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dev\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	β\tagSENT_CONTENT	parameter\tagSENT_CONTENT	determines\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	(\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	ccg_supertagging\tagtask	when\tagSENT_CONTENT	integrated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	;\tagSENT_CONTENT	categories\tagSENT_CONTENT	whose\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	within\tagSENT_CONTENT	β\tagSENT_CONTENT	times\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	1-best\tagSENT_CONTENT	category\tagSENT_CONTENT	are\tagSENT_CONTENT	pruned\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	β\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	0.075\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	ccg_supertagging\tagtask	give\tagSENT_CONTENT	very\tagSENT_CONTENT	close\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	levels\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	our\tagSENT_CONTENT	RNN\tagSENT_CONTENT	model\tagSENT_CONTENT	clearly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	NN\tagSENT_CONTENT	and\tagSENT_CONTENT	C&C\tagSENT_CONTENT	(\tagSENT_CONTENT	auto\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	word\tagSENT_CONTENT	(\tagSENT_CONTENT	WORD\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	SENT\tagSENT_CONTENT	)\tagSENT_CONTENT	level\tagmetric	accuracies\tagmetric	,\tagSENT_CONTENT	giving\tagSENT_CONTENT	similar\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	as\tagSENT_CONTENT	C&C\tagSENT_CONTENT	(\tagSENT_CONTENT	gold\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	1-best\tagmetric	accuracies\tagmetric	of\tagSENT_CONTENT	all\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	(\tagSENT_CONTENT	Bio\tagSENT_CONTENT	-\tagSENT_CONTENT	GENIA\tagSENT_CONTENT	gold\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	CCG\tagSENT_CONTENT	lexical\tagSENT_CONTENT	category\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	no\tagSENT_CONTENT	gold\tagSENT_CONTENT	categories\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Bioinfer\tagSENT_CONTENT	data\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	gold\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	NN\tagSENT_CONTENT	and\tagSENT_CONTENT	RNN\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	CCGBank\tagdataset	and\tagSENT_CONTENT	Bio\tagSENT_CONTENT	-\tagSENT_CONTENT	GENIA\tagSENT_CONTENT	;\tagSENT_CONTENT	with\tagSENT_CONTENT	auto\tagSENT_CONTENT	POS\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	model\tagSENT_CONTENT	drops\tagSENT_CONTENT	significantly\tagSENT_CONTENT	,\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	high\tagSENT_CONTENT	reliance\tagSENT_CONTENT	on\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	CCGBank\tagdataset	,\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	clear\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	advantage\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	two\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	accuracies\tagmetric	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	NN\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	closer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	model\tagSENT_CONTENT	at\tagSENT_CONTENT	some\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	levels\tagSENT_CONTENT	,\tagSENT_CONTENT	representing\tagSENT_CONTENT	these\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	are\tagSENT_CONTENT	still\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	than\tagSENT_CONTENT	CCGBank\tagdataset	.\tagSENT_END	Parsing\tagSECTITLE_START	Results\tagSECTITLE_END	We\tagSENT_START	integrate\tagSENT_CONTENT	ccg_supertagging\tagtask	into\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	both\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	all\tagSENT_CONTENT	default\tagSENT_CONTENT	parser\tagSENT_CONTENT	settings\tagSENT_CONTENT	;\tagSENT_CONTENT	C&C\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	CCGBank\tagdataset	and\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	normal\tagSENT_CONTENT	-\tagSENT_CONTENT	form\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	Bioinfer\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	inline\tagSENT_CONTENT	with\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	Final\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	substantially\tagSENT_CONTENT	improve\tagSENT_CONTENT	parsing\tagmetric	accuracies\tagmetric	on\tagSENT_CONTENT	CCGBank\tagdataset	and\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	CCGBank\tagdataset	represents\tagSENT_CONTENT	a\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	1.53%/1.85\tagSENT_CONTENT	%\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	comparable\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagmetric	best\tagmetric	known\tagmetric	accuracy\tagmetric	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	ccg_supertagging\tagtask	is\tagSENT_CONTENT	conceptually\tagSENT_CONTENT	much\tagSENT_CONTENT	simpler\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	no\tagSENT_CONTENT	change\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	required\tagSENT_CONTENT	at\tagSENT_CONTENT	all\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	ccg_supertagging\tagtask	is\tagSENT_CONTENT	fast\tagSENT_CONTENT	and\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	suited\tagSENT_CONTENT	for\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	
1805.06939	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	investigate\tagSENT_CONTENT	common_sense\tagtask	:\tagSENT_CONTENT	given\tagSENT_CONTENT	an\tagSENT_CONTENT	event\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	free\tagSENT_CONTENT	-\tagSENT_CONTENT	form\tagSENT_CONTENT	text\tagSENT_CONTENT	(\tagSENT_CONTENT	"\tagSENT_CONTENT	X\tagSENT_CONTENT	drinks\tagSENT_CONTENT	coffee\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	morning\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	reasons\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	likely\tagSENT_CONTENT	intents\tagSENT_CONTENT	(\tagSENT_CONTENT	"\tagSENT_CONTENT	X\tagSENT_CONTENT	wants\tagSENT_CONTENT	to\tagSENT_CONTENT	stay\tagSENT_CONTENT	awake\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	(\tagSENT_CONTENT	"\tagSENT_CONTENT	X\tagSENT_CONTENT	feels\tagSENT_CONTENT	alert\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	event\tagSENT_CONTENT	's\tagSENT_CONTENT	participants\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	goes\tagSENT_CONTENT	far\tagSENT_CONTENT	beyond\tagSENT_CONTENT	the\tagSENT_CONTENT	widely\tagSENT_CONTENT	studied\tagSENT_CONTENT	entailment\tagSENT_CONTENT	tasks\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	falls\tagSENT_CONTENT	outside\tagSENT_CONTENT	the\tagSENT_CONTENT	scope\tagSENT_CONTENT	of\tagSENT_CONTENT	existing\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	model\tagSENT_CONTENT	,\tagSENT_CONTENT	supporting\tagSENT_CONTENT	common_sense\tagtask	on\tagSENT_CONTENT	events\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	modeling\tagSENT_CONTENT	stereotypical\tagSENT_CONTENT	intents\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	of\tagSENT_CONTENT	people\tagSENT_CONTENT	,\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	short\tagSENT_CONTENT	free\tagSENT_CONTENT	-\tagSENT_CONTENT	form\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	1\tagSENT_CONTENT	)\tagSENT_CONTENT	anew\tagSENT_CONTENT	corpus\tagSENT_CONTENT	that\tagSENT_CONTENT	supports\tagSENT_CONTENT	common_sense\tagtask	about\tagSENT_CONTENT	people\tagSENT_CONTENT	's\tagSENT_CONTENT	intents\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	diverse\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	everyday\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	situations\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	inference\tagSENT_CONTENT	about\tagSENT_CONTENT	even\tagSENT_CONTENT	those\tagSENT_CONTENT	people\tagSENT_CONTENT	who\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	directly\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	event\tagSENT_CONTENT	phrase\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	formulation\tagSENT_CONTENT	that\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	the\tagSENT_CONTENT	textual\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	of\tagSENT_CONTENT	intents\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	classifying\tagSENT_CONTENT	their\tagSENT_CONTENT	polarities\tagSENT_CONTENT	or\tagSENT_CONTENT	classifying\tagSENT_CONTENT	the\tagSENT_CONTENT	inference\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	given\tagSENT_CONTENT	textual\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	showcase\tagSENT_CONTENT	the\tagSENT_CONTENT	practical\tagSENT_CONTENT	implications\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	on\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	people\tagSENT_CONTENT	's\tagSENT_CONTENT	mental\tagSENT_CONTENT	states\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	modern\tagSENT_CONTENT	movie\tagSENT_CONTENT	scripts\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	provide\tagSENT_CONTENT	anew\tagSENT_CONTENT	insight\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	gender\tagSENT_CONTENT	bias\tagSENT_CONTENT	in\tagSENT_CONTENT	modern\tagSENT_CONTENT	films\tagSENT_CONTENT	beyond\tagSENT_CONTENT	what\tagSENT_CONTENT	previous\tagSENT_CONTENT	studies\tagSENT_CONTENT	have\tagSENT_CONTENT	offered\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Event\tagSECTITLE_START	Extraction\tagSECTITLE_END	Crowdsourcing\tagSECTITLE_END	Mental\tagSECTITLE_START	State\tagSECTITLE_CONTENT	Descriptions\tagSECTITLE_END	Our\tagSENT_START	dataset\tagSENT_CONTENT	contains\tagSENT_CONTENT	nearly\tagSENT_CONTENT	25,000\tagSENT_CONTENT	event\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	annotators\tagSENT_CONTENT	rating\tagSENT_CONTENT	91\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	extracted\tagSENT_CONTENT	events\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	valid\tagSENT_CONTENT	"\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	event\tagSENT_CONTENT	makes\tagSENT_CONTENT	common_sense\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Event2mind\tagSECTITLE_START	Encoder\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	consider\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	common_sense\tagtask	;\tagSENT_CONTENT	)\tagSENT_CONTENT	taking\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	encoded\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	event\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	minimize\tagSENT_CONTENT	the\tagmetric	crossentropy\tagmetric	between\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	against\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	actually\tagSENT_CONTENT	observed\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	a\tagSENT_CONTENT	moderate\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	recall\tagSENT_CONTENT	and\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	compositional\tagSENT_CONTENT	encoder\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	common_sense\tagtask	and\tagSENT_CONTENT	BiRNN\tagSENT_CONTENT	;\tagSENT_CONTENT	both\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	and\tagSENT_CONTENT	sequence\tagSENT_CONTENT	de-\tagSENT_CONTENT	:\tagSENT_END	Empirical\tagSECTITLE_START	Results\tagSECTITLE_END	common_sense\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	5\tagSENT_CONTENT	workers\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	event\tagSENT_CONTENT	's\tagSENT_CONTENT	top\tagSENT_CONTENT	10\tagSENT_CONTENT	most\tagSENT_CONTENT	likely\tagSENT_CONTENT	intents\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	ask\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	all\tagSENT_CONTENT	those\tagSENT_CONTENT	that\tagSENT_CONTENT	make\tagSENT_CONTENT	common_sense\tagtask	to\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Analyzing\tagSECTITLE_START	Bias\tagSECTITLE_CONTENT	via\tagSECTITLE_CONTENT	Event2Mind\tagSECTITLE_CONTENT	Inference\tagSECTITLE_END	Processing\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Movie\tagSECTITLE_CONTENT	Scripts\tagSECTITLE_END	We\tagSENT_START	extract\tagSENT_CONTENT	events\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	scene\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	generate\tagSENT_CONTENT	their\tagSENT_CONTENT	10\tagSENT_CONTENT	most\tagSENT_CONTENT	probable\tagSENT_CONTENT	intent\tagSENT_CONTENT	and\tagSENT_CONTENT	common_sense\tagtask	using\tagSENT_CONTENT	our\tagSENT_CONTENT	BiRNN\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	PersonX\tagSECTITLE_START	hugs\tagSECTITLE_CONTENT	_\tagSECTITLE_CONTENT	_\tagSECTITLE_CONTENT	_\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	planting\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	smooch\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	PersonY\tagSECTITLE_CONTENT	's\tagSECTITLE_CONTENT	cheek\tagSECTITLE_END	I\tagSECTITLE_START	n\tagSECTITLE_CONTENT	t\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	t\tagSECTITLE_END	To\tagSENT_START	account\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	gender\tagSENT_CONTENT	skew\tagSENT_CONTENT	in\tagSENT_CONTENT	common_sense\tagtask	(\tagSENT_CONTENT	29.4\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	scenes\tagSENT_CONTENT	have\tagSENT_CONTENT	women\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	statistically\tagSENT_CONTENT	control\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	's\tagSENT_CONTENT	scene\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	.\tagSENT_END	Revealing\tagSECTITLE_START	Implicit\tagSECTITLE_CONTENT	Bias\tagSECTITLE_CONTENT	via\tagSECTITLE_CONTENT	Explicit\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Compared\tagSENT_START	to\tagSENT_CONTENT	this\tagSENT_CONTENT	prior\tagSENT_CONTENT	literature\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	uniquely\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	intents\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	diverse\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_CONTENT	includes\tagSENT_CONTENT	inference\tagSENT_CONTENT	over\tagSENT_CONTENT	event\tagSENT_CONTENT	participants\tagSENT_CONTENT	not\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	formulates\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	as\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	textual\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	classifying\tagSENT_CONTENT	various\tagSENT_CONTENT	event\tagSENT_CONTENT	attributes\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSENT_START	work\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	has\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	entailment\tagSENT_CONTENT	)\tagSENT_CONTENT	while\tagSENT_CONTENT	ours\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Also\tagSENT_START	related\tagSENT_CONTENT	are\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	introduced\tagSENT_CONTENT	anew\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	performing\tagSENT_CONTENT	common_sense\tagtask	on\tagSENT_CONTENT	textuallydescribed\tagSENT_CONTENT	everyday\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_CONTENT	focusing\tagSENT_CONTENT	on\tagSENT_CONTENT	stereotypical\tagSENT_CONTENT	intents\tagSENT_CONTENT	and\tagSENT_CONTENT	reactions\tagSENT_CONTENT	of\tagSENT_CONTENT	people\tagSENT_CONTENT	involved\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	events\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	Event2Mind\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	Overlap\tagSECTITLE_START	criterion\tagSECTITLE_CONTENT	%\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Event2Mind\tagSECTITLE_CONTENT	events\tagSECTITLE_END	C\tagSECTITLE_START	Comparison\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	ConceptNet\tagSECTITLE_END	We\tagSENT_START	match\tagSENT_CONTENT	our\tagSENT_CONTENT	events\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	event\tagSENT_CONTENT	nodes\tagSENT_CONTENT	in\tagSENT_CONTENT	common_sense\tagtask	and\tagSENT_CONTENT	find\tagSENT_CONTENT	6\tagSENT_CONTENT	ConceptNet\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	compare\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	intent\tagSENT_CONTENT	and\tagSENT_CONTENT	reaction\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	.\tagSENT_END	
D18-1205	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Information\tagSENT_START	selection\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	component\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	generating\tagSENT_CONTENT	a\tagSENT_CONTENT	fluent\tagSENT_CONTENT	and\tagSENT_CONTENT	condensed\tagSENT_CONTENT	summary\tagSENT_CONTENT	fora\tagSENT_CONTENT	document\tagSENT_CONTENT	while\tagSENT_CONTENT	retaining\tagSENT_CONTENT	the\tagSENT_CONTENT	gist\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	the\tagSENT_CONTENT	encodingdecoding\tagSENT_CONTENT	framework\tagSENT_CONTENT	has\tagSENT_CONTENT	achieved\tagSENT_CONTENT	huge\tagSENT_CONTENT	success\tagSENT_CONTENT	on\tagSENT_CONTENT	some\tagSENT_CONTENT	text\tagSENT_CONTENT	generation\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	less\tagSENT_CONTENT	convincing\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	the\tagSENT_CONTENT	encodingdecoding\tagSENT_CONTENT	framework\tagSENT_CONTENT	has\tagSENT_CONTENT	implicitly\tagSENT_CONTENT	modeled\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	selection\tagSENT_CONTENT	process\tagSENT_CONTENT	via\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	argue\tagSENT_CONTENT	that\tagSENT_CONTENT	summarization\tagtask	shall\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	it\tagSENT_CONTENT	by\tagSENT_CONTENT	capturing\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	global\tagSENT_CONTENT	document\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	local\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	treat\tagSENT_CONTENT	summarization\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	three\tagSENT_CONTENT	-\tagSENT_CONTENT	phase\tagSENT_CONTENT	task\tagSENT_CONTENT	:\tagSENT_CONTENT	document\tagSENT_CONTENT	encoding\tagSENT_CONTENT	,\tagSENT_CONTENT	information\tagSENT_CONTENT	selection\tagSENT_CONTENT	and\tagSENT_CONTENT	summary\tagSENT_CONTENT	decoding\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	processed\tagSENT_CONTENT	sentence\tagSENT_CONTENT	by\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Model\tagSECTITLE_END	Document\tagSECTITLE_START	Encoder\tagSECTITLE_END	The\tagSENT_START	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	Gated\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Unit\tagSENT_CONTENT	(\tagSENT_CONTENT	GRU\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagmetric	words\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	into\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	Information\tagSECTITLE_START	Selection\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	generation\tagSENT_CONTENT	task\tagSENT_CONTENT	which\tagSENT_CONTENT	requires\tagSENT_CONTENT	information\tagSENT_CONTENT	compression\tagSENT_CONTENT	.\tagSENT_END	Gated\tagSECTITLE_START	Global\tagSECTITLE_CONTENT	Information\tagSECTITLE_CONTENT	Filtering\tagSECTITLE_END	Inspired\tagSENT_START	by\tagSENT_CONTENT	studies\tagSENT_CONTENT	on\tagSENT_CONTENT	how\tagSENT_CONTENT	human\tagSENT_CONTENT	write\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	first\tagSENT_CONTENT	skimming\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	deleting\tagSENT_CONTENT	unnecessary\tagSENT_CONTENT	material\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	design\tagSENT_CONTENT	a\tagSENT_CONTENT	gated\tagSENT_CONTENT	global\tagSENT_CONTENT	information\tagSENT_CONTENT	filtering\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	filter\tagSENT_CONTENT	unnecessary\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	global\tagSENT_CONTENT	document\tagSENT_CONTENT	representation\tagSENT_CONTENT	before\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	decoder\tagSENT_CONTENT	generates\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Local\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	We\tagSENT_START	explicitly\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	process\tagSENT_CONTENT	which\tagSENT_CONTENT	selects\tagSENT_CONTENT	several\tagSENT_CONTENT	target\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	which\tagSENT_START	is\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	initial\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	and\tagSENT_CONTENT	generalize\tagSENT_CONTENT	the\tagSENT_CONTENT	selected\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Summary\tagSECTITLE_START	Decoder\tagSECTITLE_END	where\tagSENT_START	W\tagSENT_CONTENT	v\tagSENT_CONTENT	and\tagSENT_CONTENT	W\tagSENT_CONTENT	care\tagSENT_CONTENT	learned\tagSENT_CONTENT	parameters\tagmetric	.\tagSENT_END	Model\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Distant\tagSECTITLE_CONTENT	Supervision\tagSECTITLE_END	Despite\tagSENT_START	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	training\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	generated\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	directly\tagSENT_CONTENT	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	decisions\tagSENT_CONTENT	by\tagSENT_CONTENT	importing\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	vector\tagSENT_CONTENT	α\tagSENT_CONTENT	tin\tagSENT_CONTENT	Equation\tagSENT_CONTENT	5\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	D\tagSENT_CONTENT	KL\tagSENT_CONTENT	(\tagSENT_CONTENT	α\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	pt\tagSENT_CONTENT	)\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	KL\tagSENT_CONTENT	-\tagSENT_CONTENT	divergence\tagSENT_CONTENT	between\tagSENT_CONTENT	summarization\tagtask	α\tagSENT_CONTENT	t\tagSENT_CONTENT	and\tagSENT_CONTENT	pt\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Model\tagSECTITLE_START	Parameters\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	Glove\tagSENT_CONTENT	(\tagSENT_CONTENT	vector\tagmetric	for\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	Method\tagSECTITLE_END	Baselines\tagSECTITLE_END	The\tagSENT_START	extractive\tagSENT_CONTENT	models\tagSENT_CONTENT	include\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	Nallapati\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	-\tagSENT_CONTENT	abs\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	but\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	directly\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	1\tagSENT_START	)\tagSENT_CONTENT	Seq2seq\tagSENT_CONTENT	-\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	uses\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	structure\tagSENT_CONTENT	with\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	and\tagSENT_CONTENT	incorporates\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	copy\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Seq2seq\tagSENT_CONTENT	-\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	importing\tagSENT_CONTENT	coverage\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	control\tagSENT_CONTENT	repetitions\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Evaluation\tagSECTITLE_END	ROUGE\tagSECTITLE_START	Evaluation\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	metric\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	obtain\tagSENT_CONTENT	ROUGE\tagmetric	scores\tagmetric	using\tagSENT_CONTENT	the\tagSENT_CONTENT	pyrouge\tagSENT_CONTENT	package\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluation\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Case\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	conducted\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	on\tagSENT_CONTENT	50\tagSENT_CONTENT	random\tagSENT_CONTENT	samples\tagSENT_CONTENT	from\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	compared\tagSENT_CONTENT	the\tagSENT_CONTENT	summaries\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	outputs\tagSENT_CONTENT	of\tagSENT_CONTENT	Lead-3\tagSENT_CONTENT	,\tagSENT_CONTENT	Seq2seq\tagSENT_CONTENT	-\tagSENT_CONTENT	baseline\tagSENT_CONTENT	and\tagSENT_CONTENT	Coverage\tagSENT_CONTENT	.\tagSENT_END	family\tagSENT_START	members\tagSENT_CONTENT	have\tagSENT_CONTENT	visited\tagSENT_CONTENT	the\tagSENT_CONTENT	grave\tagSENT_CONTENT	every\tagSENT_CONTENT	week\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	mementos\tagmetric	and\tagSENT_CONTENT	flowers\tagSENT_CONTENT	for\tagSENT_CONTENT	faith\tagSENT_CONTENT	and\tagSENT_CONTENT	hope\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	when\tagSENT_CONTENT	mr\tagSENT_CONTENT	howie\tagSENT_CONTENT	and\tagSENT_CONTENT	ms\tagSENT_CONTENT	young\tagSENT_CONTENT	arrived\tagSENT_CONTENT	on\tagSENT_CONTENT	thursday\tagSENT_CONTENT	they\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	site\tagSENT_CONTENT	completely\tagSENT_CONTENT	bare\tagSENT_CONTENT	.\tagSENT_END	How\tagSENT_START	fluent\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	?\tagSENT_END	An\tagSENT_START	example\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	w.r.t\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Table\tagSENT_CONTENT	3\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	models\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	the\tagSENT_CONTENT	presented\tagSENT_CONTENT	examples\tagSENT_CONTENT	in\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Model\tagSECTITLE_START	Validation\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	verify\tagSENT_CONTENT	that\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	modeling\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	selection\tagSENT_CONTENT	process\tagSENT_CONTENT	significantly\tagSENT_CONTENT	improves\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Method\tagSECTITLE_END	Effectiveness\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Information\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	gated\tagSENT_CONTENT	global\tagSENT_CONTENT	information\tagSENT_CONTENT	filtering\tagSENT_CONTENT	and\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	training\tagSENT_CONTENT	are\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	improving\tagSENT_CONTENT	information\tagSENT_CONTENT	selection\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Effects\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Summary\tagSECTITLE_CONTENT	Length\tagSECTITLE_END	As\tagSENT_START	the\tagSENT_CONTENT	golden\tagSENT_CONTENT	summary\tagSENT_CONTENT	becoming\tagSENT_CONTENT	longer\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	will\tagSENT_CONTENT	obtain\tagSENT_CONTENT	larger\tagSENT_CONTENT	advantages\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	(\tagSENT_CONTENT	from\tagSENT_CONTENT	+1.0\tagSENT_CONTENT	Rouge-1\tagSENT_CONTENT	,\tagSENT_CONTENT	+0.1\tagSENT_CONTENT	Rouge-2\tagSENT_CONTENT	and\tagSENT_CONTENT	-0.63\tagmetric	Rouge\tagmetric	-\tagmetric	L\tagmetric	for\tagSENT_CONTENT	summary\tagSENT_CONTENT	less\tagSENT_CONTENT	than\tagSENT_CONTENT	75\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	rising\tagSENT_CONTENT	to\tagSENT_CONTENT	+10.68\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Existing\tagSENT_START	exploration\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	mainly\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	categorized\tagSENT_CONTENT	to\tagSENT_CONTENT	extractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Extractive\tagSECTITLE_START	Summarization\tagSECTITLE_CONTENT	Methods\tagSECTITLE_END	Neural\tagSENT_START	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	investigated\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Abstractive\tagSECTITLE_START	Summarization\tagSECTITLE_CONTENT	Methods\tagSECTITLE_END	As\tagSENT_START	the\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	achieve\tagSENT_CONTENT	huge\tagSENT_CONTENT	success\tagSENT_CONTENT	in\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	also\tagSENT_CONTENT	shows\tagSENT_CONTENT	great\tagSENT_CONTENT	potential\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	for\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Later\tagSENT_START	,\tagSENT_CONTENT	some\tagmetric	work\tagmetric	explored\tagSENT_CONTENT	the\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	summary\tagSENT_CONTENT	fora\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	the\tagSENT_CONTENT	necessity\tagSENT_CONTENT	of\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	selection\tagSENT_CONTENT	process\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	verified\tagSENT_CONTENT	its\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	by\tagSENT_CONTENT	extending\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	neural\tagSENT_CONTENT	encoding\tagSENT_CONTENT	-\tagSENT_CONTENT	decoding\tagSENT_CONTENT	framework\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	information\tagSENT_CONTENT	selection\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	it\tagSENT_CONTENT	with\tagSENT_CONTENT	distantly\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	
N18-2108	title\tagSECTITLE_END	coreference_resolution\tagtask	with\tagSENT_CONTENT	Coarse\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	fine\tagSENT_CONTENT	Inference\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	fully\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	approximation\tagSENT_CONTENT	to\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	inference\tagSENT_CONTENT	for\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	coreference_resolution\tagtask	have\tagSENT_CONTENT	heavily\tagSENT_CONTENT	relied\tagSENT_CONTENT	on\tagSENT_CONTENT	first\tagSENT_CONTENT	order\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	only\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	are\tagSENT_CONTENT	scored\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	because\tagSENT_CONTENT	they\tagSENT_CONTENT	make\tagSENT_CONTENT	independent\tagSENT_CONTENT	decisions\tagSENT_CONTENT	about\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	susceptible\tagSENT_CONTENT	to\tagSENT_CONTENT	predicting\tagSENT_CONTENT	clusters\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	locally\tagSENT_CONTENT	consistent\tagSENT_CONTENT	but\tagSENT_CONTENT	globally\tagSENT_CONTENT	inconsistent\tagSENT_CONTENT	.\tagSENT_END	coreference_resolution\tagtask	to\tagSENT_CONTENT	softly\tagSENT_CONTENT	condition\tagSENT_CONTENT	on\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	cheaply\tagSENT_CONTENT	computes\tagSENT_CONTENT	a\tagSENT_CONTENT	rough\tagSENT_CONTENT	sketch\tagSENT_CONTENT	of\tagSENT_CONTENT	likely\tagSENT_CONTENT	antecedents\tagSENT_CONTENT	before\tagSENT_CONTENT	applying\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	contributions\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	OntoNotes\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	observe\tagSENT_CONTENT	a\tagSENT_CONTENT	significant\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	average\tagmetric	F1\tagmetric	with\tagSENT_CONTENT	a\tagSENT_CONTENT	second\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	returns\tagSENT_CONTENT	quickly\tagSENT_CONTENT	diminish\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	third\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	687\tagSECTITLE_END	Background\tagSECTITLE_END	We\tagSENT_START	formulate\tagSENT_CONTENT	coreference_resolution\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	antecedent\tagSENT_CONTENT	assignments\tagSENT_END	Non\tagSENT_START	-\tagSENT_CONTENT	dummy\tagSENT_CONTENT	antecedents\tagSENT_CONTENT	represent\tagSENT_CONTENT	coreference_resolution\tagtask	between\tagSENT_CONTENT	i\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_CONTENT	i\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	includes\tagSENT_CONTENT	three\tagSENT_CONTENT	factors\tagSENT_CONTENT	for\tagSENT_CONTENT	coreference_resolution\tagtask	:\tagSENT_END	Pairwise\tagSENT_START	coreference_resolution\tagtask	are\tagSENT_CONTENT	only\tagSENT_CONTENT	computed\tagSENT_CONTENT	between\tagSENT_CONTENT	surviving\tagSENT_CONTENT	mentions\tagSENT_CONTENT	during\tagSENT_CONTENT	both\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	inference\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	supervision\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	learned\tagSENT_CONTENT	by\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	marginal\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	possibly\tagSENT_CONTENT	correct\tagSENT_CONTENT	antecedents\tagSENT_CONTENT	.\tagSENT_END	Higher\tagSECTITLE_START	-\tagSECTITLE_CONTENT	order\tagSECTITLE_CONTENT	Coreference\tagSECTITLE_CONTENT	Resolution\tagSECTITLE_END	The\tagSENT_START	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	initialize\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	representation\tagSENT_CONTENT	at\tagSENT_CONTENT	g\tagmetric	1\tagmetric	i\tagmetric	.\tagSENT_END	where\tagSENT_START	sis\tagSENT_CONTENT	coreference_resolution\tagtask	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	is\tagSENT_CONTENT	then\tagSENT_CONTENT	updated\tagSENT_CONTENT	via\tagSENT_CONTENT	coreference_resolution\tagtask	with\tagSENT_CONTENT	its\tagSENT_CONTENT	expected\tagSENT_CONTENT	antecedent\tagSENT_CONTENT	representation\tagSENT_END	Coarse\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	fine\tagSECTITLE_CONTENT	Inference\tagSECTITLE_END	Heuristic\tagSECTITLE_START	antecedent\tagSECTITLE_CONTENT	pruning\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	drawback\tagSENT_CONTENT	to\tagSENT_CONTENT	coreference_resolution\tagtask	is\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	imposes\tagSENT_CONTENT	an\tagSENT_CONTENT	a\tagSENT_CONTENT	priori\tagSENT_CONTENT	limit\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	distance\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	250\tagSENT_START	nearest\tagSENT_CONTENT	mentions\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	coreference_resolution\tagtask	can\tagSENT_CONTENT	reach\tagSENT_CONTENT	much\tagSENT_CONTENT	further\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	discourse\tagSENT_CONTENT	.\tagSENT_END	Coarse\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	fine\tagSECTITLE_CONTENT	antecedent\tagSECTITLE_CONTENT	pruning\tagSECTITLE_END	(\tagSENT_START	i\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	performance\tagSENT_CONTENT	loss\tagSENT_CONTENT	of\tagSENT_CONTENT	over\tagmetric	3\tagmetric	F1\tagmetric	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	over\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	pairs\tagSENT_CONTENT	from\tagSENT_CONTENT	this\tagSENT_CONTENT	final\tagSENT_CONTENT	stage\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	coarse\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	fine\tagSENT_CONTENT	approach\tagSENT_CONTENT	expands\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	coreference_resolution\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL-2012\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagmetric	average\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	include\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	systems\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	3\tagSENT_CONTENT	years\tagSENT_CONTENT	for\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	Our\tagSENT_START	full\tagSENT_CONTENT	approach\tagSENT_CONTENT	achieves\tagSENT_CONTENT	73.0\tagSENT_CONTENT	F1\tagSENT_CONTENT	,\tagSENT_CONTENT	setting\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	Despite\tagSENT_START	using\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	coarse\tagSENT_CONTENT	scores\tagSENT_CONTENT	s\tagSENT_CONTENT	c\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	computed\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	antecedents\tagSENT_CONTENT	,\tagSENT_CONTENT	enabling\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	potentially\tagSENT_CONTENT	predict\tagSENT_CONTENT	coreference_resolution\tagtask	between\tagSENT_CONTENT	any\tagSENT_CONTENT	two\tagSENT_CONTENT	spans\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	span\tagSENT_CONTENT	-\tagSENT_CONTENT	ranking\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	builds\tagSENT_CONTENT	upon\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	body\tagSENT_CONTENT	of\tagSENT_CONTENT	literature\tagSENT_CONTENT	on\tagSENT_CONTENT	coreference_resolution\tagtask	that\tagSENT_CONTENT	fundamentally\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	scoring\tagSENT_CONTENT	span\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	
Q17-1029	title\tagSECTITLE_END	In\tagSENT_START	-\tagSENT_CONTENT	constituency_parsing\tagtask	abstract\tagSECTITLE_END	Both\tagSENT_START	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	strategies\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Bottom\tagSENT_START	-\tagSENT_CONTENT	up\tagSENT_CONTENT	parsers\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	rich\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	readily\tagSENT_CONTENT	built\tagSENT_CONTENT	partial\tagSENT_CONTENT	parses\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	lack\tagSENT_CONTENT	lookahead\tagSENT_CONTENT	guidance\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	;\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	parsers\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	local\tagSENT_CONTENT	guidance\tagSENT_CONTENT	for\tagSENT_CONTENT	local\tagSENT_CONTENT	decisions\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	encoder\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	constituency_parsing\tagtask	before\tagSENT_CONTENT	its\tagSENT_CONTENT	construction\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	mitigate\tagSENT_CONTENT	both\tagSENT_CONTENT	issues\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	parsing\tagSENT_CONTENT	system\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	traversal\tagSENT_CONTENT	over\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	trees\tagSENT_CONTENT	,\tagSENT_CONTENT	designing\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	transition\tagSENT_CONTENT	actions\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	compromise\tagSENT_CONTENT	between\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	lookahead\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Transition\tagSENT_START	-\tagSENT_CONTENT	based\tagSENT_CONTENT	constituent\tagSENT_CONTENT	parsing\tagSENT_CONTENT	employs\tagSENT_CONTENT	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	local\tagSENT_CONTENT	transition\tagSENT_CONTENT	actions\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	constituency_parsing\tagtask	over\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	process\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	regarded\tagSENT_CONTENT	as\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	traversal\tagSENT_CONTENT	over\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	regarded\tagSENT_CONTENT	as\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	traversal\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	tree\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	constituency_parsing\tagtask	before\tagSENT_CONTENT	constituency_parsing\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	realized\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	no\tagSENT_CONTENT	explicit\tagSENT_CONTENT	features\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	their\tagSENT_CONTENT	subtree\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	Thanks\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	make\tagSENT_CONTENT	it\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	globally\tagSENT_CONTENT	before\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	tree\tagSENT_CONTENT	construction\tagSENT_CONTENT	,\tagSENT_CONTENT	seminal\tagSENT_CONTENT	work\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	directly\tagSENT_CONTENT	generates\tagSENT_CONTENT	bracketed\tagSENT_CONTENT	constituency_parsing\tagtask	using\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	(\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	system\tagSENT_CONTENT	:\tagSENT_END	Action\tagSENT_START	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	constituency_parsing\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	mitigating\tagSENT_CONTENT	issues\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	systems\tagSENT_CONTENT	by\tagSENT_CONTENT	finding\tagSENT_CONTENT	a\tagSENT_CONTENT	compromise\tagSENT_CONTENT	between\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	lookahead\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	process\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	regarded\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	traversal\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	tree\tagSENT_CONTENT	.\tagSENT_END	Empirically\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	human\tagSENT_CONTENT	reader\tagSENT_CONTENT	comprehends\tagSENT_CONTENT	sentences\tagSENT_CONTENT	by\tagSENT_CONTENT	giving\tagSENT_CONTENT	lookahead\tagSENT_CONTENT	guesses\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	likes\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	human\tagSENT_CONTENT	reader\tagSENT_CONTENT	could\tagSENT_CONTENT	guess\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	start\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	waiting\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	the\tagSENT_CONTENT	object\tagSENT_CONTENT	"\tagSENT_CONTENT	red\tagSENT_CONTENT	tomatoes\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	procedure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	Transition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	constituent\tagSECTITLE_CONTENT	parsing\tagSECTITLE_END	constituency_parsing\tagtask	takes\tagSENT_CONTENT	a\tagSENT_CONTENT	leftto\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	scan\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	maintain\tagSENT_CONTENT	partially\tagSENT_CONTENT	constructed\tagSENT_CONTENT	phrasestructures\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	stored\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	buffer\tagSENT_CONTENT	.\tagSENT_END	Formally\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	σ\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	front\tagSENT_CONTENT	index\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	buffer\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	a\tagSENT_CONTENT	boolean\tagSENT_CONTENT	value\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	finished\tagSENT_CONTENT	.\tagSENT_END	Bottom\tagSECTITLE_START	-\tagSECTITLE_CONTENT	up\tagSECTITLE_CONTENT	system\tagSECTITLE_END	•\tagSENT_START	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	/\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	X\tagSENT_CONTENT	:\tagSENT_CONTENT	pop\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	two\tagSENT_CONTENT	constituents\tagSENT_CONTENT	off\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	combine\tagSENT_CONTENT	them\tagSENT_CONTENT	into\tagSENT_CONTENT	constituency_parsing\tagtask	with\tagSENT_CONTENT	label\tagSENT_CONTENT	X\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	push\tagSENT_CONTENT	constituency_parsing\tagtask	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	.\tagSENT_END	UNARY\tagSENT_START	-\tagSENT_CONTENT	X\tagSENT_CONTENT	:\tagSENT_CONTENT	pop\tagSENT_CONTENT	constituency_parsing\tagtask	off\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	raise\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	constituency_parsing\tagtask	with\tagSENT_CONTENT	label\tagSENT_CONTENT	X\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	push\tagSENT_CONTENT	constituency_parsing\tagtask	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	FINISH\tagSENT_CONTENT	:\tagSENT_CONTENT	pop\tagSENT_CONTENT	the\tagSENT_CONTENT	root\tagSENT_CONTENT	node\tagSENT_CONTENT	off\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Given\tagSENT_START	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	binarized\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	tree\tagSENT_CONTENT	in(b\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	actions\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	NP\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	NP\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	NP\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	-\tagSENT_CONTENT	VP\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	-\tagSENT_CONTENT	S\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	-\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	S\tagSENT_CONTENT	and\tagSENT_CONTENT	FINISH\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Top\tagSECTITLE_START	-\tagSECTITLE_CONTENT	down\tagSECTITLE_CONTENT	system\tagSECTITLE_END	repeatedly\tagSENT_START	pop\tagSENT_CONTENT	completed\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	or\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	until\tagSENT_CONTENT	an\tagSENT_CONTENT	open\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	is\tagSENT_CONTENT	encountered\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	this\tagSENT_CONTENT	open\tagSENT_CONTENT	NT\tagSENT_CONTENT	is\tagSENT_CONTENT	popped\tagSENT_CONTENT	and\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	that\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	popped\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	as\tagSENT_END	NT\tagSENT_START	-\tagSENT_CONTENT	S\tagSENT_CONTENT	,\tagSENT_CONTENT	NT\tagSENT_CONTENT	-\tagSENT_CONTENT	NP\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	,\tagSENT_CONTENT	NT\tagSENT_CONTENT	-\tagSENT_CONTENT	VP\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	NT\tagSENT_CONTENT	-\tagSENT_CONTENT	NP\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	,\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	,\tagSENT_CONTENT	SHIFT\tagSENT_CONTENT	and\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	In\tagSECTITLE_START	-\tagSECTITLE_CONTENT	order\tagSECTITLE_CONTENT	system\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	repeatedly\tagSENT_START	pop\tagSENT_CONTENT	completed\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	or\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	until\tagSENT_CONTENT	a\tagSENT_CONTENT	projected\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	encountered\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	this\tagSENT_CONTENT	projected\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	is\tagSENT_CONTENT	popped\tagSENT_CONTENT	and\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	one\tagSENT_CONTENT	more\tagSENT_CONTENT	item\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	stack\tagSENT_CONTENT	is\tagSENT_CONTENT	popped\tagSENT_CONTENT	and\tagSENT_CONTENT	inserted\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	leftmost\tagSENT_CONTENT	child\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	•\tagSENT_START	FINISH\tagSENT_CONTENT	:\tagSENT_CONTENT	pop\tagSENT_CONTENT	the\tagSENT_CONTENT	root\tagSENT_CONTENT	node\tagSENT_CONTENT	off\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	FIN\tagSENT_START	-\tagSENT_CONTENT	ISH\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Variants\tagSECTITLE_END	Neural\tagSECTITLE_START	parsing\tagSECTITLE_CONTENT	model\tagSECTITLE_END	Word\tagSECTITLE_START	representation\tagSECTITLE_END	where\tagSENT_START	W\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	input\tagSENT_CONTENT	are\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	i\tagSENT_CONTENT	and\tagSENT_CONTENT	pi\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	tag\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ith\tagSENT_CONTENT	input\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	an\tagSENT_CONTENT	nonlinear\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	ReLu\tagSENT_CONTENT	for\tagSENT_CONTENT	f\tagmetric	.\tagSENT_END	Stack\tagSECTITLE_START	representation\tagSECTITLE_END	We\tagSENT_START	employ\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	constituency_parsing\tagtask	on\tagSENT_CONTENT	stack\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	constituency_parsing\tagtask	and\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	following\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in(a\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	representation\tagSENT_CONTENT	s\tagSENT_CONTENT	comp\tagSENT_CONTENT	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	For\tagSENT_START	constituency_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	by\tagSENT_CONTENT	requiring\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	node\tagSENT_CONTENT	is\tagSENT_CONTENT	always\tagSENT_CONTENT	before\tagSENT_CONTENT	the\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	head\tagSENT_CONTENT	node\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in(b\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Greedy\tagSECTITLE_START	action\tagSECTITLE_CONTENT	classification\tagSECTITLE_END	Parameter\tagSECTITLE_END	Experiments\tagSECTITLE_END	Data\tagSECTITLE_END	For\tagSENT_START	English\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	of\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	sections\tagSENT_CONTENT	in\tagSENT_CONTENT	PTB\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	Sections\tagSENT_CONTENT	2\tagSENT_CONTENT	-\tagSENT_CONTENT	21\tagSENT_CONTENT	are\tagSENT_CONTENT	taken\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	Section\tagSENT_CONTENT	22\tagSENT_CONTENT	for\tagSENT_CONTENT	development\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	Section\tagSENT_CONTENT	23\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Settings\tagSECTITLE_END	Reranking\tagSECTITLE_START	experiments\tagSECTITLE_END	shows\tagSENT_START	constituency_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	test\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	constituency_parsing\tagtask	results\tagSENT_END	With\tagSENT_START	the\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	supervise\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	inorder\tagSENT_CONTENT	parser\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	discrete\tagSENT_CONTENT	parser\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	neural\tagSENT_CONTENT	parsers\tagSENT_CONTENT	(\tagSENT_CONTENT	Cross\tagSENT_CONTENT	and\tagSENT_CONTENT	Huang\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	supervise\tagSENT_CONTENT	90.4\tagSENT_CONTENT	90.4\tagSENT_CONTENT	90.7\tagSENT_CONTENT	91.1\tagSENT_CONTENT	91.1\tagSENT_CONTENT	 \tagSENT_CONTENT	91.2\tagSENT_CONTENT	Cross\tagSENT_CONTENT	and\tagSENT_CONTENT	Huang\tagSENT_CONTENT	91.3\tagSENT_CONTENT	Liu\tagSENT_CONTENT	and\tagSENT_CONTENT	Zhang\tagSENT_CONTENT	91.7\tagSENT_CONTENT	Top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	parser\tagSENT_CONTENT	91.2\tagSENT_CONTENT	Bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	parser\tagSENT_CONTENT	91.3\tagSENT_CONTENT	In\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	91.8\tagSENT_CONTENT	reranking\tagSENT_CONTENT	91.7\tagSENT_CONTENT	92.6\tagSENT_CONTENT	Dyer\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_END	Development\tagSECTITLE_START	experiments\tagSECTITLE_END	Results\tagSECTITLE_END	constituency_parsing\tagtask	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	test\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	our\tagSENT_CONTENT	final\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	among\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	obtains\tagSENT_CONTENT	comparable\tagSENT_CONTENT	results\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Analysis\tagSECTITLE_END	We\tagSENT_START	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	Section\tagSENT_CONTENT	23\tagSENT_CONTENT	in\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	the\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	parser\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	parser\tagSENT_CONTENT	)\tagSENT_CONTENT	against\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	length\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	length\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Linguistically\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	traversal\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	over\tagSENT_CONTENT	 \tagSENT_CONTENT	Top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	parser\tagSENT_CONTENT	Bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	parser\tagSENT_CONTENT	In\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	a\tagSENT_CONTENT	tree\tagSENT_CONTENT	)\tagSENT_CONTENT	allows\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	spans\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	correctly\tagSENT_CONTENT	projected\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	(\tagSENT_CONTENT	leftmost\tagSENT_CONTENT	nodes\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	spans\tagSENT_CONTENT	.\tagSENT_END	Then\tagSENT_START	the\tagSENT_CONTENT	projected\tagSENT_CONTENT	constituents\tagSENT_CONTENT	constrain\tagSENT_CONTENT	long\tagSENT_CONTENT	span\tagSENT_CONTENT	construction\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	generating\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	spans\tagSENT_CONTENT	without\tagSENT_CONTENT	trace\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	spans\tagSENT_CONTENT	.\tagSENT_END	Influence\tagSECTITLE_START	of\tagSECTITLE_CONTENT	sentence\tagSECTITLE_CONTENT	length\tagSECTITLE_END	Influence\tagSECTITLE_START	of\tagSECTITLE_CONTENT	span\tagSECTITLE_CONTENT	length\tagSECTITLE_END	6.3\tagSENT_START	Influence\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	scores\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	parsers\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	parser\tagSENT_CONTENT	performs\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	parser\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	including\tagSENT_CONTENT	NP\tagSENT_CONTENT	,\tagSENT_CONTENT	S\tagSENT_CONTENT	,\tagSENT_CONTENT	SBAR\tagSENT_CONTENT	,\tagSENT_CONTENT	QP\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	requires\tagSENT_CONTENT	,\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	,\tagSENT_CONTENT	modeling\tagSENT_CONTENT	of\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	performs\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	demonstrating\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	can\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	both\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Examples\tagSECTITLE_END	Given\tagSENT_START	the\tagSENT_CONTENT	Sentence\tagSENT_CONTENT	#\tagSENT_CONTENT	308\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	parser\tagSENT_CONTENT	prefers\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	constituency_parsing\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	once\tagSENT_CONTENT	producers\tagSENT_CONTENT	and\tagSENT_CONTENT	customers\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	ignoring\tagSENT_CONTENT	the\tagSENT_CONTENT	possible\tagSENT_CONTENT	clause\tagSENT_CONTENT	SBAR\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	captured\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	parser\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	parser\tagSENT_CONTENT	projects\tagSENT_CONTENT	constituency_parsing\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	stick\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	continues\tagSENT_CONTENT	to\tagSENT_CONTENT	complete\tagSENT_CONTENT	the\tagSENT_CONTENT	clause\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	lookahead\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	necessary\tagSENT_CONTENT	for\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	local\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	.\tagSENT_END	constituency_parsing\tagtask	are\tagSENT_CONTENT	marked\tagSENT_CONTENT	in\tagSENT_CONTENT	red\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	Our\tagSENT_START	work\tagSENT_CONTENT	is\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	left\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Neural\tagSENT_START	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	for\tagSENT_CONTENT	parsing\tagSENT_CONTENT	under\tagSENT_CONTENT	various\tagSENT_CONTENT	grammar\tagSENT_CONTENT	formalisms\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	dependency\tagSENT_CONTENT	(\tagSENT_CONTENT	Dozat\tagSENT_CONTENT	and\tagSENT_CONTENT	Manning\tagSENT_CONTENT	,\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	CCG\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	method\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	extended\tagSENT_CONTENT	by\tagSENT_CONTENT	investigating\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	configurations\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	psycho\tagSENT_CONTENT	-\tagSENT_CONTENT	linguistically\tagSENT_CONTENT	motivated\tagSENT_CONTENT	constituent\tagSENT_CONTENT	parsing\tagSENT_CONTENT	system\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	inorder\tagSENT_CONTENT	traversal\tagSENT_CONTENT	over\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	trees\tagSENT_CONTENT	,\tagSENT_CONTENT	aiming\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	compromise\tagSENT_CONTENT	between\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	lookahead\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	422\tagSECTITLE_END	
P18-4013	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Similar\tagSENT_START	to\tagSENT_CONTENT	discrete\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagmetric	CRF\tagmetric	layer\tagmetric	is\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	capturing\tagSENT_CONTENT	label\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	exist\tagSENT_CONTENT	several\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	source\tagSENT_CONTENT	statistical\tagSENT_CONTENT	CRF\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	toolkits\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	CRF++\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	CRFSuite\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	provide\tagSENT_CONTENT	users\tagSENT_CONTENT	with\tagSENT_CONTENT	flexible\tagSENT_CONTENT	means\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	various\tagSENT_CONTENT	training\tagSENT_CONTENT	settings\tagSENT_CONTENT	and\tagSENT_CONTENT	decoding\tagSENT_CONTENT	formats\tagSENT_CONTENT	,\tagSENT_CONTENT	facilitating\tagSENT_CONTENT	quick\tagSENT_CONTENT	implementation\tagSENT_CONTENT	and\tagSENT_CONTENT	extension\tagSENT_CONTENT	on\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	builds\tagSENT_CONTENT	a\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	framework\tagSENT_CONTENT	with\tagSENT_CONTENT	chunking\tagtask	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	structure\tagSENT_CONTENT	as\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	plus\tagSENT_CONTENT	POS\tagSENT_CONTENT	and\tagSENT_CONTENT	Cap\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	within\tagSENT_CONTENT	10\tagSENT_CONTENT	lines\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	NCRF++\tagSENT_CONTENT	integrates\tagSENT_CONTENT	several\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	automatic\tagSENT_CONTENT	feature\tagSENT_CONTENT	extractors\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	for\tagSENT_CONTENT	character\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	easy\tagSENT_CONTENT	reproduction\tagSENT_CONTENT	of\tagSENT_CONTENT	many\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Taking\tagSENT_START	NER\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	as\tagSENT_CONTENT	typical\tagSENT_CONTENT	examples\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	builtin\tagSENT_CONTENT	NCRF++\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	influence\tagSENT_CONTENT	of\tagSENT_CONTENT	humandefined\tagSENT_CONTENT	and\tagSENT_CONTENT	automatic\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	nbest\tagSENT_CONTENT	decoding\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	running\tagSENT_CONTENT	speed\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	.\tagSENT_END	NCRF++\tagSECTITLE_START	Architecture\tagSECTITLE_END	Layer\tagSECTITLE_START	Units\tagSECTITLE_END	Character\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	The\tagSENT_START	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	layer\tagSENT_CONTENT	integrates\tagSENT_CONTENT	several\tagSENT_CONTENT	typical\tagSENT_CONTENT	neural\tagSENT_CONTENT	encoders\tagSENT_CONTENT	for\tagSENT_CONTENT	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	RNN\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	.\tagSENT_END	Word\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Similar\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	NCRF++\tagSENT_CONTENT	supports\tagSENT_CONTENT	both\tagSENT_CONTENT	RNN\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	sequence\tagSENT_CONTENT	feature\tagSENT_CONTENT	extractor\tagSENT_CONTENT	.\tagSENT_END	Inference\tagSECTITLE_START	Layer\tagSECTITLE_END	User\tagSECTITLE_START	Interface\tagSECTITLE_END	Configuration\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	handcrafted\tagSENT_CONTENT	feature\tagSENT_CONTENT	is\tagSENT_CONTENT	configured\tagSENT_CONTENT	in\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	feature=\tagSENT_CONTENT	emb\tagSENT_CONTENT	dir\tagSENT_CONTENT	=\tagSENT_END	Extension\tagSECTITLE_END	Evaluation\tagSECTITLE_END	Settings\tagSECTITLE_END	For\tagSENT_START	chunking\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2000\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	data\tagSENT_CONTENT	split\tagSENT_CONTENT	is\tagSENT_CONTENT	following\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	split\tagSENT_CONTENT	with\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	test\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	character\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	sequence\tagSENT_CONTENT	representations\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	three\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	CLSTM\tagSENT_START	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	CCNN\tagSENT_CONTENT	"\tagSENT_CONTENT	represent\tagSENT_CONTENT	models\tagSENT_CONTENT	using\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Character\tagSENT_START	information\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	model\tagSENT_CONTENT	performance\tagSENT_CONTENT	significantly\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	using\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	or\tagSENT_CONTENT	chunking\tagtask	give\tagSENT_CONTENT	similar\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	Influence\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	By\tagSENT_START	utilizing\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	or\tagSENT_CONTENT	chunking\tagtask	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	automatically\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	NER\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	N\tagSECTITLE_START	best\tagSECTITLE_CONTENT	Decoding\tagSECTITLE_END	Speed\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Batch\tagSECTITLE_CONTENT	Size\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
E17-2047	title\tagSECTITLE_END	Cutting\tagSENT_START	-\tagSENT_CONTENT	off\tagSENT_CONTENT	Redundant\tagSENT_CONTENT	Repeating\tagSENT_CONTENT	Generations\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	Our\tagSENT_START	basic\tagSENT_CONTENT	idea\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	jointly\tagSENT_CONTENT	estimate\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	-\tagSENT_CONTENT	bound\tagSENT_CONTENT	frequency\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	control\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	words\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	RNN\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	(\tagSENT_CONTENT	EncDec\tagSENT_CONTENT	)\tagSENT_CONTENT	approach\tagSENT_CONTENT	has\tagSENT_CONTENT	recently\tagSENT_CONTENT	been\tagSENT_CONTENT	providing\tagSENT_CONTENT	significant\tagSENT_CONTENT	progress\tagSENT_CONTENT	in\tagSENT_CONTENT	various\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	generation\tagSENT_CONTENT	(\tagSENT_CONTENT	NLG\tagSENT_CONTENT	)\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	MT\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	ABS\tagSENT_CONTENT	)\tagSENT_END	The\tagSENT_START	very\tagSENT_CONTENT	short\tagSENT_CONTENT	ABS\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	atypical\tagSENT_CONTENT	example\tagSENT_CONTENT	because\tagSENT_CONTENT	it\tagSENT_CONTENT	requires\tagSENT_CONTENT	the\tagSENT_CONTENT	generation\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	defined\tagSENT_CONTENT	limited\tagSENT_CONTENT	output\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ten\tagSENT_CONTENT	words\tagSENT_CONTENT	or\tagSENT_CONTENT	75\tagSENT_CONTENT	bytes\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	basic\tagSENT_CONTENT	idea\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	jointly\tagSENT_CONTENT	estimate\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	-\tagSENT_CONTENT	bound\tagSENT_CONTENT	frequency\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	occur\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	during\tagSENT_CONTENT	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	process\tagSENT_CONTENT	and\tagSENT_CONTENT	exploit\tagSENT_CONTENT	the\tagSENT_CONTENT	estimation\tagSENT_CONTENT	to\tagSENT_CONTENT	control\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	decoding\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	Baseline\tagSECTITLE_START	RNN\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	EncDec\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	We\tagSENT_START	omit\tagSENT_CONTENT	a\tagSENT_CONTENT	detailed\tagSENT_CONTENT	review\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	For\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	uses\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	four\tagSENT_CONTENT	notation\tagSENT_CONTENT	rules\tagSENT_CONTENT	:\tagSENT_END	Word\tagSECTITLE_START	Frequency\tagSECTITLE_CONTENT	Estimation\tagSECTITLE_END	This\tagSENT_START	section\tagSENT_CONTENT	describes\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	roughly\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	a\tagSENT_CONTENT	submodel\tagSENT_CONTENT	that\tagSENT_CONTENT	estimates\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	-\tagSENT_CONTENT	bound\tagSENT_CONTENT	frequencies\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	controlling\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	using\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Definition\tagSECTITLE_END	where\tagSENT_START	Sigmoid\tagSENT_CONTENT	(\tagSENT_CONTENT	·\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	ReLu\tagmetric	(\tagSENT_CONTENT	·\tagSENT_CONTENT	)\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	element\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	sigmoid\tagSENT_CONTENT	and\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	expected\tagSENT_CONTENT	sincê\tagSENT_CONTENT	r[m\tagSENT_CONTENT	]\tagSENT_CONTENT	has\tagSENT_CONTENT	no\tagSENT_CONTENT	influence\tagSENT_CONTENT	ifˆgifˆ\tagSENT_CONTENT	ifˆg[m\tagSENT_CONTENT	]\tagSENT_CONTENT	=\tagSENT_CONTENT	0\tagSENT_CONTENT	.\tagSENT_END	Effective\tagSECTITLE_START	usage\tagSECTITLE_END	Calculation\tagSECTITLE_END	Parameter\tagSECTITLE_START	estimation\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Experiments\tagSECTITLE_END	Generally\tagSENT_START	,\tagSENT_CONTENT	1951\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	randomly\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Main\tagSECTITLE_START	results\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	comparison\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	baseline\tagSECTITLE_END	Comparison\tagSECTITLE_START	to\tagSECTITLE_CONTENT	current\tagSECTITLE_CONTENT	top\tagSECTITLE_CONTENT	systems\tagSECTITLE_END	Gigaword\tagdataset	(\tagSENT_CONTENT	w/o\tagSENT_CONTENT	length\tagSENT_CONTENT	limit\tagSENT_CONTENT	)\tagSENT_CONTENT	  \tagSENT_CONTENT	imum\tagSENT_CONTENT	risk\tagSENT_CONTENT	estimation\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	we\tagSENT_CONTENT	trained\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	standard\tagSENT_CONTENT	(\tagSENT_CONTENT	pointwise\tagSENT_CONTENT	)\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	maximization\tagSENT_CONTENT	.\tagSENT_END	Generation\tagSECTITLE_START	examples\tagSECTITLE_END	Performance\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	WFE\tagSECTITLE_CONTENT	sub\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	model\tagSECTITLE_END	There\tagSENT_START	seems\tagSENT_CONTENT	to\tagSENT_CONTENT	exist\tagSENT_CONTENT	an\tagSENT_CONTENT	enough\tagSENT_CONTENT	room\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	
C16-1329	title\tagSECTITLE_END	text_classification\tagtask	Improved\tagSENT_CONTENT	by\tagSENT_CONTENT	Integrating\tagSENT_CONTENT	Bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	Two\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	Max\tagSENT_CONTENT	Pooling\tagSENT_END	abstract\tagSECTITLE_END	Experiments\tagSENT_START	are\tagSENT_CONTENT	conducted\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	models\tagSENT_CONTENT	achieves\tagSENT_CONTENT	highest\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	text_classification\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	essential\tagSENT_CONTENT	component\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	NLP\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	spam\tagSENT_CONTENT	detection\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	order\tagSENT_CONTENT	-\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	models\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	tremendous\tagSENT_CONTENT	success\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	shown\tagSENT_CONTENT	more\tagSENT_CONTENT	significant\tagSENT_CONTENT	progress\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	BoW\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	challenge\tagSENT_CONTENT	for\tagSENT_CONTENT	textual\tagSENT_CONTENT	modeling\tagSENT_CONTENT	is\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	text\tagSENT_CONTENT	units\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	operators\tagSENT_CONTENT	ignore\tagSENT_CONTENT	features\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	dimension\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	maybe\tagSENT_CONTENT	important\tagSENT_CONTENT	for\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	therefore\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	1D\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	and\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	operators\tagSENT_CONTENT	may\tagSENT_CONTENT	pose\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	choice\tagSENT_CONTENT	to\tagSENT_CONTENT	utilize\tagSENT_CONTENT	2D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	and\tagSENT_CONTENT	2D\tagSENT_CONTENT	pooling\tagSENT_CONTENT	to\tagSENT_CONTENT	sample\tagSENT_CONTENT	more\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	features\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	dimension\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	dimension\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	This\tagSENT_START	work\tagSENT_CONTENT	introduces\tagSENT_CONTENT	two\tagSENT_CONTENT	combined\tagSENT_CONTENT	models\tagSENT_CONTENT	BLSTM-2DPooling\tagSENT_CONTENT	and\tagSENT_CONTENT	BLSTM-2DCNN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	verifies\tagSENT_CONTENT	them\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	achieves\tagSENT_CONTENT	highest\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	It\tagSENT_START	first\tagSENT_CONTENT	depicts\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	conducts\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	2D\tagSENT_CONTENT	filter\tagSENT_CONTENT	and\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	size\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	related\tagSENT_CONTENT	work\tagSENT_CONTENT	about\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	reviewed\tagSENT_CONTENT	.\tagSENT_END	Section\tagSENT_START	3\tagSENT_CONTENT	presents\tagSENT_CONTENT	the\tagSENT_CONTENT	BLSTM-2DCNN\tagSENT_CONTENT	architectures\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	text_classification\tagtask	is\tagSENT_CONTENT	drawn\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	6\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Deep\tagSENT_START	learning\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	great\tagSENT_CONTENT	improvement\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	introduced\tagSENT_START	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	tensor\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	phrases\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	neighbour\tagSENT_CONTENT	constituents\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	parsing\tagSENT_CONTENT	tree\tagSENT_CONTENT	.\tagSENT_END	developed\tagSENT_START	target\tagSENT_CONTENT	dependent\tagSENT_CONTENT	Long\tagSENT_CONTENT	ShortTerm\tagSENT_CONTENT	Memory\tagSENT_CONTENT	Networks\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	automatically\tagSENT_CONTENT	taken\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	.\tagSENT_END	introduced\tagSENT_START	BLSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	select\tagSENT_CONTENT	features\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	decisive\tagSENT_CONTENT	effect\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	introduced\tagSENT_START	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	word\tagSENT_CONTENT	attention\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Then\tagSENT_START	CNN\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	proposed\tagSENT_START	a\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	conducted\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	CNN\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	architecture\tagSENT_CONTENT	components\tagSENT_CONTENT	on\tagSENT_CONTENT	model\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	introduced\tagSENT_START	multichannel\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	pretraining\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	As\tagSENT_START	dis\tagSENT_CONTENT	equal\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	size\tagSENT_CONTENT	d\tagSENT_CONTENT	w\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	window\tagSENT_CONTENT	slides\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	dimension\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	usually\tagSENT_CONTENT	called\tagSENT_CONTENT	1D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	din\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	varies\tagSENT_CONTENT	from\tagSENT_CONTENT	2\tagSENT_CONTENT	to\tagSENT_CONTENT	d\tagSENT_CONTENT	w\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	confusion\tagSENT_CONTENT	with\tagSENT_CONTENT	common\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	named\tagSENT_CONTENT	as\tagSENT_CONTENT	2D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	described\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	lots\tagSENT_CONTENT	of\tagSENT_CONTENT	other\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	introduced\tagSENT_START	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	averaging\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	fed\tagSENT_CONTENT	an\tagSENT_CONTENT	unweighted\tagSENT_CONTENT	average\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	through\tagSENT_CONTENT	multiple\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	before\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Model\tagSECTITLE_END	BLSTM\tagSECTITLE_START	Layer\tagSECTITLE_END	right\tagSECTITLE_START	context\tagSECTITLE_END	BLSTM\tagSECTITLE_START	Layer\tagSECTITLE_CONTENT	Two\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	dimensional\tagSECTITLE_CONTENT	Convolution\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Output\tagSECTITLE_START	Layer\tagSECTITLE_END	where\tagSENT_START	x\tagSENT_CONTENT	t\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	f\tagSENT_CONTENT	and\tagSENT_CONTENT	o\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	gate\tagSENT_CONTENT	activation\tagSENT_CONTENT	,\tagSENT_CONTENT	forget\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	output\tagSENT_CONTENT	gate\tagSENT_CONTENT	activation\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	ˆ\tagSENT_CONTENT	c\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	cell\tagSENT_CONTENT	state\tagSENT_CONTENT	,\tagSENT_CONTENT	σ\tagSENT_CONTENT	denotes\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	⊙\tagSENT_CONTENT	denotes\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	is\tagSENT_CONTENT	utilized\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Convolutional\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	Two\tagSECTITLE_START	-\tagSECTITLE_CONTENT	dimensional\tagSECTITLE_CONTENT	Convolution\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Two\tagSECTITLE_START	-\tagSECTITLE_CONTENT	dimensional\tagSECTITLE_CONTENT	Max\tagSECTITLE_CONTENT	Pooling\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	where\tagSENT_START	down\tagSENT_CONTENT	(\tagSENT_CONTENT	·\tagSENT_CONTENT	)\tagSENT_CONTENT	represents\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_END	Output\tagSECTITLE_START	Layer\tagSECTITLE_END	For\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	h\tagSENT_CONTENT	*\tagSENT_CONTENT	of\tagSENT_CONTENT	2D\tagSENT_CONTENT	Max\tagSENT_CONTENT	Pooling\tagSENT_CONTENT	Layer\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	text\tagSENT_CONTENT	S.\tagSENT_END	And\tagSENT_START	then\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	passed\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	text_classification\tagtask	labeî\tagSENT_CONTENT	y\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	discrete\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	classes\tagSENT_CONTENT	Y\tagSENT_CONTENT	.\tagSENT_END	text_classification\tagtask	takes\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	h\tagSENT_END	where\tagSENT_START	t\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	m\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	represented\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	m\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	estimated\tagSENT_CONTENT	probability\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	class\tagSENT_CONTENT	by\tagSENT_CONTENT	softmax\tagSENT_CONTENT	,\tagSENT_CONTENT	m\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	λ\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	L2\tagSENT_CONTENT	regularization\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameter\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Datasets\tagSECTITLE_END	•\tagSENT_START	MR\tagSENT_CONTENT	2\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment_analysis\tagtask	dataset\tagSENT_CONTENT	from\tagSENT_CONTENT	Pang\tagSENT_END	sentiment_analysis\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	MR\tagSENT_CONTENT	from\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	both\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	phrases\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	only\tagSENT_CONTENT	sentences\tagSENT_CONTENT	are\tagSENT_CONTENT	scored\tagSENT_CONTENT	attest\tagSENT_CONTENT	time\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	text_classification\tagtask	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	task\tagSENT_CONTENT	involves\tagSENT_CONTENT	classifying\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	into\tagSENT_CONTENT	6\tagSENT_CONTENT	question\tagSENT_CONTENT	types\tagSENT_CONTENT	(\tagSENT_CONTENT	abbreviation\tagSENT_CONTENT	,\tagSENT_CONTENT	description\tagSENT_CONTENT	,\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	human\tagSENT_CONTENT	,\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	numeric\tagSENT_CONTENT	value\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	The\tagSENT_START	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuned\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Hyper\tagSECTITLE_START	-\tagSECTITLE_CONTENT	parameter\tagSECTITLE_CONTENT	Settings\tagSECTITLE_END	The\tagSENT_START	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	20Ng\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	Macro\tagSENT_CONTENT	-\tagSENT_CONTENT	F1\tagSENT_CONTENT	measure\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	work\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	five\tagSENT_CONTENT	datasets\tagSENT_CONTENT	use\tagSENT_CONTENT	accuracy\tagmetric	as\tagSENT_CONTENT	the\tagSENT_CONTENT	metric\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	Dropout\tagSENT_CONTENT	operation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	dropout\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	0.5\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	0.2\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	0.4\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	penultimate\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	use\tagSENT_CONTENT	l2\tagSENT_CONTENT	penalty\tagSENT_CONTENT	with\tagSENT_CONTENT	coefficient\tagSENT_CONTENT	10\tagSENT_CONTENT	−5\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Overall\tagSECTITLE_START	Performance\tagSECTITLE_END	presents\tagSENT_START	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	four\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Especially\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	achieves\tagSENT_CONTENT	52.4\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	89.5\tagSENT_CONTENT	%\tagSENT_CONTENT	test\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	on\tagSENT_CONTENT	SST-1\tagSENT_CONTENT	and\tagSENT_CONTENT	SST-2\tagdataset	respectively\tagSENT_CONTENT	.\tagSENT_END	BLSTM\tagSENT_START	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	beats\tagSENT_CONTENT	all\tagSENT_CONTENT	baselines\tagSENT_CONTENT	on\tagSENT_CONTENT	SST-1\tagSENT_CONTENT	,\tagSENT_CONTENT	SST-2\tagdataset	,\tagSENT_CONTENT	and\tagSENT_CONTENT	TREC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	techniques\tagSENT_CONTENT	only\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	/\tagSENT_CONTENT	documents\tagSENT_CONTENT	with\tagSENT_CONTENT	several\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	AdaSent\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	complicated\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	of\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	outper-\tagSENT_END	To\tagSENT_START	better\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	2D\tagSENT_CONTENT	operations\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	conducts\tagSENT_CONTENT	sentiment_analysis\tagtask	on\tagSENT_CONTENT	SST-1\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Length\tagSECTITLE_END	Figure\tagSENT_START	2\tagSENT_CONTENT	depicts\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	four\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	figure\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	x\tagSENT_CONTENT	-\tagSENT_CONTENT	axis\tagSENT_CONTENT	represents\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	y\tagSENT_CONTENT	-\tagSENT_CONTENT	axis\tagSENT_CONTENT	is\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	NN\tagSECTITLE_END	Model\tagSECTITLE_END	Convolutional\tagSENT_START	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	-\tagSENT_START	Ana\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	Practitioners\tagSENT_CONTENT	'\tagSENT_CONTENT	Guide\tagSENT_CONTENT	to\tagSENT_CONTENT	)\tagSENT_END	Convolutional\tagSENT_START	Neural\tagSENT_CONTENT	Networks\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	2D\tagSECTITLE_CONTENT	Convolutional\tagSECTITLE_CONTENT	Filter\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	2D\tagSECTITLE_CONTENT	Max\tagSECTITLE_CONTENT	Pooling\tagSECTITLE_CONTENT	Size\tagSECTITLE_END	To\tagSENT_START	make\tagSENT_CONTENT	it\tagSENT_CONTENT	simple\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	set\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	values\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	filter\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	pooling\tagSENT_CONTENT	are\tagSENT_CONTENT	square\tagSENT_CONTENT	matrices\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	best\tagmetric	accuracy\tagmetric	is\tagSENT_CONTENT	52.6\tagSENT_CONTENT	with\tagSENT_CONTENT	2D\tagSENT_CONTENT	filter\tagSENT_CONTENT	size\tagSENT_CONTENT	(\tagSENT_CONTENT	5,5\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	2D\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	size\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	finer\tagSENT_CONTENT	tuning\tagSENT_CONTENT	can\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	reported\tagSENT_CONTENT	here\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	if\tagSENT_CONTENT	a\tagSENT_CONTENT	larger\tagSENT_CONTENT	filter\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	,\tagSENT_CONTENT	text_classification\tagtask	can\tagSENT_CONTENT	detector\tagSENT_CONTENT	more\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	maybe\tagSENT_CONTENT	improved\tagSENT_CONTENT	,\tagSENT_CONTENT	too\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	The\tagSENT_START	experiments\tagSENT_CONTENT	are\tagSENT_CONTENT	conducted\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Especially\tagSENT_START	,\tagSENT_CONTENT	BLSTM-2DCNN\tagSENT_CONTENT	achieves\tagSENT_CONTENT	highest\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	SST-1\tagSENT_CONTENT	and\tagSENT_CONTENT	SST-2\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	better\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	effective\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	two\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	also\tagSENT_CONTENT	conducts\tagSENT_CONTENT	sentiment_analysis\tagtask	on\tagSENT_CONTENT	SST-1\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	
S17-2126	title\tagSECTITLE_END	Deep\tagSENT_START	LSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	Attention\tagSENT_CONTENT	for\tagSENT_CONTENT	Message\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	two\tagSENT_CONTENT	deep\tagSENT_CONTENT	-\tagSENT_CONTENT	learning\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	competed\tagSENT_CONTENT	at\tagSENT_CONTENT	SemEval-2017\tagSENT_CONTENT	Task\tagSENT_CONTENT	4\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	participated\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	subtasks\tagSENT_CONTENT	for\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	glish\tagSENT_CONTENT	tweets\tagSENT_CONTENT	,\tagSENT_CONTENT	involving\tagSENT_CONTENT	message\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	and\tagSENT_CONTENT	topic\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	quantification\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	Long\tagSENT_CONTENT	Short\tagSENT_CONTENT	-\tagSENT_CONTENT	Term\tagSENT_CONTENT	Memory\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	networks\tagSENT_CONTENT	augmented\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	big\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	messages\tagSENT_CONTENT	.\tagSENT_END	Also\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	processing\tagSENT_CONTENT	tool\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	social\tagSENT_CONTENT	network\tagSENT_CONTENT	messages\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	performs\tagSENT_CONTENT	tokenization\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	spell\tagSENT_CONTENT	correction\tagSENT_CONTENT	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	uses\tagSENT_CONTENT	no\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	features\tagSENT_CONTENT	or\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	sentiment_analysis\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	area\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	studying\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	and\tagSENT_CONTENT	quantification\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	expressed\tagSENT_CONTENT	in\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	in\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	particularly\tagSENT_CONTENT	challenging\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	informal\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	creative\tagSENT_CONTENT	"\tagSENT_CONTENT	writing\tagSENT_CONTENT	style\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	improper\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	grammar\tagSENT_CONTENT	,\tagSENT_CONTENT	figurative\tagSENT_CONTENT	language\tagSENT_CONTENT	,\tagSENT_CONTENT	misspellings\tagSENT_CONTENT	and\tagSENT_CONTENT	slang\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	previous\tagSENT_CONTENT	runs\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Task\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	was\tagSENT_CONTENT	usually\tagSENT_CONTENT	tackled\tagSENT_CONTENT	using\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	features\tagSENT_CONTENT	and/or\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	feeding\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Naive\tagSENT_CONTENT	Bayes\tagSENT_CONTENT	or\tagSENT_CONTENT	Support\tagSENT_CONTENT	Vector\tagSENT_CONTENT	Machines\tagSENT_CONTENT	(\tagSENT_CONTENT	SVM\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	first\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	designed\tagSENT_CONTENT	for\tagSENT_CONTENT	addressing\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	For\tagSENT_START	sentiment_analysis\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	Siamese\tagSENT_CONTENT	Bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	contextaware\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	performing\tagSENT_CONTENT	systems\tagSENT_CONTENT	of\tagSENT_CONTENT	previous\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	use\tagSENT_CONTENT	model\tagSENT_CONTENT	ensembles\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	using\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	enforce\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	determine\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	message\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	the\tagSENT_CONTENT	topic\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Overview\tagSECTITLE_END	Figure\tagSENT_START	1\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	main\tagSENT_CONTENT	steps\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	optional\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	third\tagSENT_CONTENT	step\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	our\tagSENT_CONTENT	own\tagSENT_CONTENT	text\tagSENT_CONTENT	processing\tagSENT_CONTENT	tool\tagSENT_CONTENT	for\tagSENT_CONTENT	preparing\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	:\tagSENT_CONTENT	High\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	quantification\tagSENT_CONTENT	step\tagSENT_CONTENT	for\tagSENT_CONTENT	estimating\tagSENT_CONTENT	sentiment_analysis\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	topic\tagSENT_CONTENT	.\tagSENT_END	Text\tagSECTITLE_START	Processor\tagSECTITLE_END	We\tagSENT_START	developed\tagSENT_CONTENT	our\tagSENT_CONTENT	own\tagSENT_CONTENT	text\tagSENT_CONTENT	processing\tagSENT_CONTENT	tool\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	utilize\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	performing\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	spell\tagSENT_CONTENT	correction\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	splitting\tagSENT_CONTENT	hashtags\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	annotation\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	there\tagSENT_CONTENT	are\tagSENT_CONTENT	some\tagSENT_CONTENT	tokenizers\tagSENT_CONTENT	geared\tagSENT_CONTENT	towards\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	recognize\tagSENT_CONTENT	the\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	markup\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	or\tagSENT_CONTENT	simple\tagSENT_CONTENT	emoticons\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	tokenizer\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	most\tagSENT_CONTENT	emoticons\tagSENT_CONTENT	,\tagSENT_CONTENT	emojis\tagSENT_CONTENT	,\tagSENT_CONTENT	expressions\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	dates\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	07/11/2011\tagSENT_CONTENT	,\tagSENT_CONTENT	April\tagSENT_CONTENT	23rd\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	times\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	4:30pm\tagSENT_CONTENT	,\tagSENT_CONTENT	11:00\tagSENT_CONTENT	am\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	currencies\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	$\tagSENT_CONTENT	10\tagSENT_CONTENT	,\tagSENT_CONTENT	25mil\tagSENT_CONTENT	,\tagSENT_CONTENT	50e\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	acronyms\tagSENT_CONTENT	,\tagSENT_CONTENT	censored\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	s**t\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	words\tagSENT_CONTENT	with\tagSENT_CONTENT	emphasis\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	spell\tagSENT_CONTENT	correction\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	normalization\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	decide\tagSENT_CONTENT	which\tagSENT_CONTENT	tokens\tagSENT_CONTENT	to\tagSENT_CONTENT	omit\tagSENT_CONTENT	,\tagSENT_CONTENT	normalize\tagSENT_CONTENT	or\tagSENT_CONTENT	annotate\tagSENT_CONTENT	(\tagSENT_CONTENT	surround\tagSENT_CONTENT	or\tagSENT_CONTENT	replace\tagSENT_CONTENT	with\tagSENT_CONTENT	special\tagSENT_CONTENT	tags\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Networks\tagSECTITLE_END	Recurrent\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	original\tagSECTITLE_END	sentiment_analysis\tagtask	.\tagSENT_END	Quantification\tagSECTITLE_END	Models\tagSECTITLE_START	Description\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	for\tagSENT_CONTENT	Subtask\tagSENT_CONTENT	A\tagSENT_CONTENT	(\tagSENT_CONTENT	3.1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_END	MSA\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	message\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	)\tagSECTITLE_END	sentiment_analysis\tagtask	(\tagSENT_CONTENT	MSA\tagSENT_CONTENT	)\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	2-layer\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	informative\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Not\tagSENT_START	all\tagSENT_CONTENT	words\tagSENT_CONTENT	contribute\tagSENT_CONTENT	equally\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	expression\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	message\tagSENT_CONTENT	.\tagSENT_END	TSA\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	topic\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	)\tagSECTITLE_END	For\tagSENT_START	sentiment_analysis\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	Siamese\tagSENT_CONTENT	2\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	than\tagSENT_CONTENT	in\tagSENT_CONTENT	MSA\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	contextaware\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	strengthen\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	express\tagSENT_CONTENT	sentiment_analysis\tagtask	towards\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	topic\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	done\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	uh\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	"\tagSENT_CONTENT	which\tagSENT_CONTENT	words\tagSENT_CONTENT	express\tagSENT_CONTENT	sentiment_analysis\tagtask	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	topic\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	message\tagSENT_CONTENT	.\tagSENT_END	Regularization\tagSECTITLE_END	Words\tagSENT_START	occurring\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	moved\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	space\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	classifier\tagSENT_CONTENT	will\tagSENT_CONTENT	correlate\tagSENT_CONTENT	certain\tagSENT_CONTENT	regions\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	embedding\tagSENT_CONTENT	space\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Class\tagSECTITLE_START	Weights\tagSECTITLE_END	Training\tagSECTITLE_END	Hyper\tagSECTITLE_START	-\tagSECTITLE_CONTENT	parameters\tagSECTITLE_END	Positive\tagSECTITLE_END	Neutral\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Following\tagSENT_START	the\tagSENT_CONTENT	results\tagSENT_CONTENT	from\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	reported\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	twitter\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	decided\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	PCC\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	3\tagSENT_END	RNN\tagSECTITLE_END	Method\tagSECTITLE_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	two\tagSENT_CONTENT	deep\tagSENT_CONTENT	-\tagSENT_CONTENT	learning\tagSENT_CONTENT	systems\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	developed\tagSENT_CONTENT	for\tagSENT_CONTENT	SemEval-2017\tagSENT_CONTENT	Task\tagSENT_CONTENT	4\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	empower\tagSENT_CONTENT	our\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	amplify\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	
1611.04230	title\tagSECTITLE_END	A\tagSENT_START	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	based\tagSENT_CONTENT	Sequence\tagSENT_CONTENT	Model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	Documents\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	based\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	of\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	achieves\tagSENT_CONTENT	performance\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	or\tagSENT_CONTENT	comparable\tagSENT_CONTENT	to\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	problem\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	many\tagSENT_CONTENT	applications\tagSENT_CONTENT	in\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	and\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	vast\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	devoted\tagSENT_CONTENT	to\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	become\tagSENT_CONTENT	popular\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	proposed\tagSENT_CONTENT	an\tagSENT_CONTENT	attentional\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	into\tagSENT_CONTENT	short\tagSENT_CONTENT	headlines\tagSENT_CONTENT	.\tagSENT_END	Like\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	also\tagSENT_CONTENT	focuses\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	single\tagSENT_CONTENT	documents\tagSENT_CONTENT	using\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	are\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_END	SummaRuNNer\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	treat\tagSENT_CONTENT	summarization\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	wherein\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	visited\tagSENT_CONTENT	sequentially\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	document\tagSENT_CONTENT	order\tagSENT_CONTENT	and\tagSENT_END	For\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	revisited\tagSENT_CONTENT	sequentially\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	second\tagSENT_CONTENT	pass\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	logistic\tagSENT_CONTENT	layer\tagSENT_CONTENT	makes\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	decision\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	whether\tagSENT_CONTENT	that\tagSENT_CONTENT	sentence\tagSENT_CONTENT	belongs\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	below\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	other\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	simply\tagSENT_CONTENT	a\tagSENT_CONTENT	running\tagSENT_CONTENT	weighted\tagSENT_CONTENT	summation\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	visited\tagSENT_CONTENT	till\tagSENT_CONTENT	sentence\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	respective\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	summary\tagSENT_CONTENT	membership\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Eqn\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	term\tagmetric	W\tagSENT_CONTENT	ch\tagSENT_CONTENT	j\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	content\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	j\tagSENT_CONTENT	th\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	h\tagSENT_CONTENT	T\tagSENT_CONTENT	j\tagSENT_CONTENT	W\tagSENT_CONTENT	s\tagSENT_CONTENT	d\tagSENT_CONTENT	denotes\tagSENT_CONTENT	the\tagSENT_CONTENT	salience\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	h\tagSENT_CONTENT	T\tagSENT_CONTENT	j\tagSENT_CONTENT	W\tagSENT_CONTENT	r\tagSENT_CONTENT	tanh(s\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	captures\tagSENT_CONTENT	the\tagSENT_CONTENT	redundancy\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	two\tagSENT_CONTENT	terms\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	absolute\tagSENT_CONTENT	and\tagSENT_CONTENT	relative\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Extractive\tagSECTITLE_START	Training\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	our\tagSENT_CONTENT	extractive\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	need\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	form\tagmetric	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	binary\tagSENT_CONTENT	labels\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	representing\tagSENT_CONTENT	their\tagSENT_CONTENT	membership\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	summarization\tagtask	only\tagSENT_CONTENT	contain\tagSENT_CONTENT	human\tagSENT_CONTENT	written\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summaries\tagSENT_CONTENT	as\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	.\tagSENT_END	Abstractive\tagSECTITLE_START	Training\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	training\tagSENT_CONTENT	technique\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	summarization\tagtask	abstractively\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	eliminating\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	approximate\tagSENT_CONTENT	extractive\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	s\tagSENT_CONTENT	−1\tagSENT_CONTENT	is\tagSENT_CONTENT	summarization\tagtask	as\tagSENT_CONTENT	computed\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	sentence\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	RNN\tagSENT_CONTENT	of\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	7\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	of\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	extractive\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	8\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	minimize\tagSENT_CONTENT	the\tagSENT_CONTENT	negative\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	words\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	test\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	uncouple\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	from\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	emit\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	extractive\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	p(y\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Treating\tagSENT_START	summarization\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	classification\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	considered\tagSENT_CONTENT	by\tagSENT_CONTENT	earlier\tagSENT_CONTENT	researchers\tagSENT_CONTENT	.\tagSENT_END	Of\tagSENT_START	these\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	work\tagmetric	of\tagSENT_CONTENT	(\tagSENT_CONTENT	Cheng\tagSENT_CONTENT	and\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	closest\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	since\tagSENT_CONTENT	they\tagSENT_CONTENT	also\tagSENT_CONTENT	employ\tagSENT_CONTENT	an\tagSENT_CONTENT	extractive\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	The\tagmetric	work\tagmetric	of\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	also\tagSENT_CONTENT	uses\tagSENT_CONTENT	an\tagSENT_CONTENT	encoderdecoder\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	is\tagSENT_CONTENT	fully\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sense\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	generates\tagSENT_CONTENT	its\tagSENT_CONTENT	own\tagSENT_CONTENT	summaries\tagSENT_CONTENT	attest\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Corpora\tagSECTITLE_END	For\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	corpus\tagSENT_CONTENT	originally\tagSENT_CONTENT	constructed\tagSENT_CONTENT	by\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	passage\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	purposed\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	as\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	Cheng\tagSENT_CONTENT	and\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	below\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	different\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Rouge\tagSENT_CONTENT	metric\tagSENT_CONTENT	 \tagSENT_CONTENT	Rouge\tagSENT_CONTENT	recall\tagSENT_CONTENT	metric\tagSENT_CONTENT	at\tagSENT_CONTENT	75\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Baselines\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	from\tagSENT_CONTENT	(\tagSENT_CONTENT	Cheng\tagSENT_CONTENT	and\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_END	SummaRuNNer\tagSECTITLE_START	Settings\tagSECTITLE_END	At\tagSENT_START	test\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	picking\tagSENT_CONTENT	all\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	y\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	≥\tagSENT_CONTENT	0.5\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	bean\tagSENT_CONTENT	optimal\tagSENT_CONTENT	strategy\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	imbalanced\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	summary\tagSENT_CONTENT	-\tagSENT_CONTENT	membership\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	pick\tagSENT_CONTENT	sentences\tagSENT_CONTENT	sorted\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	probabilites\tagSENT_CONTENT	until\tagSENT_CONTENT	we\tagSENT_CONTENT	exceed\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	limit\tagSENT_CONTENT	when\tagSENT_CONTENT	limited\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	Rouge\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	corpus\tagSECTITLE_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	Rouge\tagmetric	recall\tagmetric	at\tagSENT_CONTENT	275\tagSENT_CONTENT	bytes\tagSENT_CONTENT	of\tagSENT_CONTENT	summary\tagSENT_CONTENT	length\tagSENT_CONTENT	.\tagSENT_END	Gold\tagSECTITLE_START	Summary\tagSECTITLE_CONTENT	:\tagSECTITLE_END	Redpath\tagSENT_START	returned\tagSENT_CONTENT	to\tagSENT_CONTENT	Sale\tagSENT_CONTENT	in\tagSENT_CONTENT	June\tagSENT_CONTENT	2012\tagSENT_CONTENT	as\tagSENT_CONTENT	director\tagmetric	of\tagSENT_CONTENT	rugby\tagSENT_CONTENT	after\tagSENT_CONTENT	starting\tagSENT_CONTENT	a\tagSENT_CONTENT	coaching\tagSENT_CONTENT	career\tagSENT_CONTENT	at\tagSENT_CONTENT	Gloucester\tagSENT_CONTENT	and\tagSENT_CONTENT	progressing\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	job\tagSENT_CONTENT	at\tagSENT_CONTENT	Kingsholm\tagSENT_CONTENT	.\tagSENT_END	Figure\tagSENT_START	2\tagSENT_CONTENT	:\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	output\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	representative\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	corpus\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	joint\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Rouge-1\tagSECTITLE_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Out\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Domain\tagSECTITLE_CONTENT	DUC\tagSECTITLE_CONTENT	2002\tagSECTITLE_CONTENT	corpus\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	again\tagSENT_CONTENT	statistically\tagSENT_CONTENT	on\tagSENT_CONTENT	par\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	Cheng\tagSENT_CONTENT	and\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	being\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performer\tagSENT_CONTENT	,\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	additional\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	being\tagSENT_CONTENT	very\tagSENT_CONTENT	interpretable\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	interpretable\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	allows\tagSENT_CONTENT	intuitive\tagSENT_CONTENT	visualization\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	performing\tagSENT_CONTENT	than\tagSENT_CONTENT	or\tagSENT_CONTENT	is\tagSENT_CONTENT	comparable\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	@entity14\tagSENT_START	is\tagSENT_CONTENT	poised\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	@entity3\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	season\tagSENT_CONTENT	Document\tagSENT_CONTENT	:\tagSENT_CONTENT	today\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	foreign\tagSENT_CONTENT	ministry\tagSENT_CONTENT	said\tagSENT_CONTENT	that\tagSENT_CONTENT	control\tagSENT_CONTENT	operations\tagSENT_CONTENT	carried\tagSENT_CONTENT	out\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	corvette\tagSENT_CONTENT	spiro\tagSENT_CONTENT	against\tagSENT_CONTENT	a\tagSENT_CONTENT	korean\tagSENT_CONTENT	-\tagSENT_CONTENT	flagged\tagSENT_CONTENT	as\tagSENT_CONTENT	received\tagSENT_CONTENT	ship\tagSENT_CONTENT	fishing\tagSENT_CONTENT	illegally\tagSENT_CONTENT	in\tagSENT_CONTENT	argentine\tagSENT_CONTENT	waters\tagSENT_CONTENT	were\tagSENT_CONTENT	carried\tagSENT_CONTENT	out\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	accordance\tagSENT_CONTENT	with\tagSENT_CONTENT	international\tagSENT_CONTENT	law\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	foreign\tagSENT_CONTENT	ministry\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	
P18-1161	title\tagSECTITLE_END	Denoising\tagSENT_START	Distantly\tagSENT_CONTENT	Supervised\tagSENT_CONTENT	question_answering\tagtask	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Reading\tagSENT_START	comprehension\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	has\tagSENT_CONTENT	recently\tagSENT_CONTENT	become\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	focus\tagSENT_CONTENT	of\tagSENT_CONTENT	NLP\tagSENT_CONTENT	research\tagSENT_CONTENT	.\tagSENT_END	propose\tagSENT_START	a\tagSENT_CONTENT	distantly\tagSENT_CONTENT	supervised\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	DS\tagSENT_CONTENT	-\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	system\tagSENT_CONTENT	which\tagSENT_CONTENT	uses\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	technique\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	relevant\tagSENT_CONTENT	text\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	applies\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	technique\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	"\tagSENT_CONTENT	Which\tagSENT_CONTENT	country\tagSENT_CONTENT	's\tagSENT_CONTENT	capital\tagSENT_CONTENT	is\tagSENT_CONTENT	Dublin\tagSENT_CONTENT	?\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	may\tagSENT_CONTENT	encounter\tagSENT_CONTENT	that\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_END	These\tagSENT_START	methods\tagSENT_CONTENT	only\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	related\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	will\tagSENT_CONTENT	lose\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	rich\tagSENT_CONTENT	information\tagSENT_CONTENT	contained\tagSENT_CONTENT	in\tagSENT_CONTENT	Paragraph\tagSENT_CONTENT	Selector\tagSENT_END	Paragraph\tagSECTITLE_START	Reader\tagSECTITLE_END	For\tagSENT_START	question_answering\tagtask	'\tagSENT_CONTENT	What\tagSENT_CONTENT	's\tagSENT_CONTENT	the\tagSENT_CONTENT	capital\tagSENT_CONTENT	of\tagSENT_CONTENT	Dublin\tagSENT_CONTENT	?\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	selects\tagSENT_CONTENT	two\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	p\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	p\tagSENT_CONTENT	3\tagSENT_CONTENT	which\tagSENT_CONTENT	actually\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	from\tagSENT_CONTENT	all\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	multiple\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	maybe\tagSENT_CONTENT	answered\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	first\tagSENT_CONTENT	retrieves\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	corpus\tagSENT_CONTENT	via\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	real\tagSENT_CONTENT	-\tagSENT_CONTENT	world\tagSENT_CONTENT	datasets\tagSENT_CONTENT	including\tagSENT_CONTENT	Quasar\tagmetric	-\tagmetric	T\tagmetric	,\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	and\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	achieves\tagSENT_CONTENT	significant\tagSENT_CONTENT	and\tagSENT_CONTENT	consistent\tagSENT_CONTENT	improvement\tagSENT_CONTENT	as\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	baseline\tagSENT_CONTENT	methods\tagSENT_CONTENT	by\tagSENT_CONTENT	aggregating\tagSENT_CONTENT	extracted\tagSENT_CONTENT	answers\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	informative\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	question_answering\tagtask	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	.\tagSENT_END	propose\tagSENT_START	a\tagSENT_CONTENT	DS\tagSENT_CONTENT	-\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	retrieves\tagSENT_CONTENT	relevant\tagSENT_CONTENT	texts\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	corpus\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	extracts\tagSENT_CONTENT	answers\tagSENT_CONTENT	from\tagSENT_CONTENT	these\tagSENT_CONTENT	texts\tagSENT_CONTENT	using\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Methodology\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	question\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Formally\tagSENT_START	,\tagSENT_CONTENT	given\tagSENT_CONTENT	question_answering\tagtask	q\tagSENT_CONTENT	=\tagSENT_CONTENT	(\tagSENT_CONTENT	q\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	|q|\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	retrieve\tagSENT_CONTENT	m\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_END	Given\tagSENT_START	question_answering\tagtask	q\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	P\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_END	Paragraph\tagSECTITLE_END	Given\tagSENT_START	question_answering\tagtask	q\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	pi\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	reader\tagSENT_CONTENT	calculates\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	Pr(a|q\tagSENT_CONTENT	,\tagSENT_CONTENT	pi\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	extracting\tagSENT_CONTENT	answer\tagSENT_CONTENT	a\tagSENT_CONTENT	through\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	long\tagSENT_CONTENT	short\tagSENT_CONTENT	-\tagSENT_CONTENT	term\tagSENT_CONTENT	memory\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Paragraph\tagSECTITLE_START	Selector\tagSECTITLE_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	to\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	containing\tagSENT_CONTENT	question_answering\tagtask	among\tagSENT_CONTENT	all\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	.\tagSENT_END	After\tagSENT_START	that\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	attention\tagSENT_CONTENT	operation\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	representations\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	representation\tagSENT_CONTENT	q\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	q\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	α\tagSENT_CONTENT	j\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	is\tagSENT_CONTENT	calculated\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	Paragraph\tagSECTITLE_START	Reader\tagSECTITLE_END	And\tagSENT_START	we\tagSENT_CONTENT	also\tagSENT_CONTENT	obtain\tagSENT_CONTENT	question_answering\tagtask	embedding\tagSENT_CONTENT	¯\tagSENT_CONTENT	q\tagSENT_CONTENT	via\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layers\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	we\tagSENT_CONTENT	divide\tagSENT_CONTENT	it\tagSENT_CONTENT	into\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	where\tagSENT_START	a\tagSENT_CONTENT	sand\tagSENT_CONTENT	a\tagSENT_CONTENT	e\tagSENT_CONTENT	indicate\tagSENT_CONTENT	the\tagmetric	start\tagmetric	and\tagSENT_CONTENT	end\tagSENT_CONTENT	positions\tagSENT_CONTENT	of\tagSENT_CONTENT	answer\tagSENT_CONTENT	a\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	,\tagSENT_CONTENT	P\tagSENT_CONTENT	s\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	s\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	P\tagSENT_CONTENT	e\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sand\tagSENT_CONTENT	a\tagSENT_CONTENT	e\tagSENT_CONTENT	being\tagSENT_CONTENT	start\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	words\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	calculated\tagSENT_CONTENT	by\tagSENT_CONTENT	:\tagSENT_END	In\tagSENT_START	DS\tagSENT_CONTENT	-\tagSENT_CONTENT	QA\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	did\tagSENT_CONTENT	n't\tagSENT_CONTENT	label\tagSENT_CONTENT	the\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	manually\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	may\tagSENT_CONTENT	have\tagSENT_CONTENT	several\tagSENT_CONTENT	tokens\tagSENT_CONTENT	matched\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	para-\tagSENT_END	|a|\tagSENT_START	e\tagSENT_CONTENT	)\tagSENT_CONTENT	}\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	start\tagmetric	and\tagSENT_CONTENT	end\tagSENT_CONTENT	positions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tokens\tagSENT_CONTENT	matched\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	a\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	pi\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	extracting\tagSENT_CONTENT	question_answering\tagtask	a\tagSENT_CONTENT	can\tagSENT_CONTENT	defined\tagSENT_CONTENT	by\tagSENT_CONTENT	maximizing\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	candidate\tagSENT_CONTENT	tokens\tagSENT_CONTENT	:\tagSENT_END	Learning\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Prediction\tagSECTITLE_END	(\tagSENT_START	c\tagSENT_CONTENT	P\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	containing\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_END	Here\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	fast\tagSENT_CONTENT	skimming\tagSENT_CONTENT	overall\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	determines\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	containing\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metrics\tagSECTITLE_END	For\tagSENT_START	Quasar\tagmetric	-\tagmetric	T\tagmetric	,\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	and\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	(\tagSENT_CONTENT	 \tagSENT_CONTENT	of\tagSENT_CONTENT	English\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	build\tagSENT_CONTENT	a\tagSENT_CONTENT	Lucene\tagSENT_CONTENT	index\tagSENT_CONTENT	system\tagSENT_CONTENT	on\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopt\tagSENT_CONTENT	two\tagSENT_CONTENT	metrics\tagSENT_CONTENT	including\tagSENT_CONTENT	ExactMatch\tagSENT_CONTENT	(\tagSENT_CONTENT	EM\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Baselines\tagSECTITLE_END	(\tagSENT_START	3\tagSENT_CONTENT	)\tagSENT_CONTENT	AQA\tagSENT_CONTENT	(\tagSENT_CONTENT	Buck\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	reinforced\tagSENT_CONTENT	system\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	write\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	aggregate\tagSENT_CONTENT	the\tagSENT_CONTENT	answers\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	written\tagSENT_CONTENT	questions\tagSENT_CONTENT	;\tagSENT_CONTENT	(\tagSENT_CONTENT	4\tagSENT_CONTENT	)\tagSENT_CONTENT	R\tagSENT_CONTENT	3\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	reinforced\tagSENT_CONTENT	model\tagSENT_CONTENT	making\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	ranker\tagSENT_CONTENT	for\tagSENT_CONTENT	selecting\tagSENT_CONTENT	most\tagSENT_CONTENT	confident\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	We\tagSENT_START	select\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	n\tagSENT_CONTENT	∈\tagSENT_CONTENT	{\tagSENT_CONTENT	32\tagSENT_CONTENT	,\tagSENT_CONTENT	64\tagSENT_CONTENT	,\tagSENT_CONTENT	128\tagSENT_CONTENT	,\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	,\tagSENT_CONTENT	512\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layers\tagSENT_CONTENT	for\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	encoder\tagSENT_CONTENT	among\tagSENT_CONTENT	{\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	3\tagSENT_CONTENT	,\tagSENT_CONTENT	4\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	regularization\tagSENT_CONTENT	weight\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Different\tagSECTITLE_CONTENT	Paragraph\tagSECTITLE_CONTENT	Selectors\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	RNN\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagmetric	Quasar\tagmetric	-\tagmetric	T\tagmetric	and\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Different\tagSECTITLE_CONTENT	Paragraph\tagSECTITLE_CONTENT	Readers\tagSECTITLE_END	It\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	Sum\tagSENT_CONTENT	reader\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	susceptible\tagSENT_CONTENT	to\tagSENT_CONTENT	noisy\tagSENT_CONTENT	data\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	regards\tagSENT_CONTENT	all\tagSENT_CONTENT	tokens\tagSENT_CONTENT	matching\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSECTITLE_START	Results\tagSECTITLE_END	The\tagSENT_START	reason\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	full\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	while\tagSENT_CONTENT	other\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	only\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	relevant\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	4\tagSENT_CONTENT	)\tagSENT_CONTENT	On\tagSENT_CONTENT	CuratedTREC\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	only\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	slight\tagSENT_CONTENT	improvement\tagSENT_CONTENT	as\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	R\tagSENT_CONTENT	3\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Paragraph\tagSECTITLE_START	Selector\tagSECTITLE_CONTENT	Performance\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	(\tagSENT_START	-\tagSENT_CONTENT	   \tagSENT_CONTENT	which\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	actually\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopt\tagSENT_CONTENT	a\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	instead\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	catching\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	correlation\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	demonstrates\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	selector\tagSENT_CONTENT	can\tagSENT_CONTENT	better\tagSENT_CONTENT	determine\tagSENT_CONTENT	which\tagSENT_CONTENT	tokens\tagSENT_CONTENT	matched\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	actually\tagSENT_CONTENT	answering\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	by\tagSENT_CONTENT	joint\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	reader\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSECTITLE_START	with\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	numbers\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	paragraphs\tagSECTITLE_END	Potential\tagSECTITLE_START	improvement\tagSECTITLE_END	To\tagSENT_START	show\tagSENT_CONTENT	the\tagSENT_CONTENT	potential\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	aggregating\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	answer\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	ranking\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	DS\tagSENT_CONTENT	-\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	statistical\tagSENT_CONTENT	anal-\tagSENT_END	Datasets\tagSECTITLE_END	Quasar\tagmetric	-\tagmetric	T\tagmetric	SearchQA\tagSENT_CONTENT	    \tagSENT_CONTENT	ysis\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	bound\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Datasets\tagSECTITLE_END	It\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	DS\tagSENT_CONTENT	-\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	far\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	performance\tagSENT_CONTENT	and\tagSENT_CONTENT	still\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	probability\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	improved\tagSENT_CONTENT	by\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	on\tagSENT_START	both\tagmetric	Quasar\tagmetric	-\tagmetric	T\tagmetric	and\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	by\tagSENT_CONTENT	5\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	7\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Case\tagSECTITLE_START	Study\tagSECTITLE_END	(\tagSENT_START	1\tagSENT_CONTENT	)\tagSENT_CONTENT	For\tagSENT_CONTENT	question_answering\tagtask	"\tagSENT_CONTENT	Who\tagSENT_CONTENT	directed\tagSENT_CONTENT	the\tagSENT_CONTENT	1946\tagSENT_END	For\tagSENT_START	question_answering\tagtask	"\tagSENT_CONTENT	What\tagSENT_CONTENT	famous\tagSENT_CONTENT	artist\tagSENT_CONTENT	could\tagSENT_CONTENT	write\tagSENT_CONTENT	with\tagSENT_CONTENT	both\tagSENT_CONTENT	his\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	hand\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	?\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	identifies\tagSENT_CONTENT	that\tagSENT_CONTENT	"\tagSENT_CONTENT	Leonardo\tagSENT_CONTENT	Da\tagSENT_CONTENT	Vinci\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	artist\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	and\tagSENT_CONTENT	could\tagSENT_CONTENT	write\tagSENT_CONTENT	with\tagSENT_CONTENT	both\tagSENT_CONTENT	his\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	hand\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	question_answering\tagtask	can\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	
owoputi_etal.naacl13	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	systematically\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	word\tagSENT_CONTENT	clustering\tagSENT_CONTENT	and\tagSENT_CONTENT	new\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	tagging\tagmetric	accuracy\tagmetric	.\tagSENT_END	With\tagSENT_START	these\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	tagging\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	and\tagSENT_CONTENT	IRC\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	tasks\tagSENT_CONTENT	;\tagSENT_CONTENT	part-of-speech_tagging\tagtask	is\tagSENT_CONTENT	improved\tagSENT_CONTENT	from\tagSENT_CONTENT	90\tagmetric	%\tagmetric	to\tagmetric	93\tagmetric	%\tagmetric	accuracy\tagmetric	(\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	3\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	There\tagSENT_START	is\tagSENT_CONTENT	preliminary\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	parsing\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	accuracy\tagmetric	rates\tagmetric	are\tagSENT_CONTENT	still\tagSENT_CONTENT	significantly\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	traditional\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	edited\tagSENT_CONTENT	genres\tagSENT_CONTENT	like\tagSENT_CONTENT	newswire\tagSENT_CONTENT	.\tagSENT_END	Even\tagSENT_START	web\tagSENT_CONTENT	text\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	comparatively\tagSENT_CONTENT	easier\tagSENT_CONTENT	genre\tagSENT_CONTENT	than\tagSENT_CONTENT	social\tagdataset	media\tagdataset	,\tagSENT_CONTENT	lags\tagSENT_CONTENT	behind\tagSENT_CONTENT	newspaper\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	does\tagSENT_CONTENT	speech\tagSENT_CONTENT	transcript\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	annotated\tagSENT_CONTENT	anew\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	with\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	improved\tagSENT_CONTENT	the\tagSENT_CONTENT	annotations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	dataset\tagSENT_CONTENT	from\tagSENT_CONTENT	Gimpel\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	developed\tagSENT_CONTENT	annotation\tagSENT_CONTENT	guidelines\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	.\tagSENT_END	MEMM\tagSECTITLE_START	Tagger\tagSECTITLE_END	which\tagSENT_START	we\tagSENT_CONTENT	find\tagSENT_CONTENT	is\tagSENT_CONTENT	3\tagSENT_CONTENT	times\tagSENT_CONTENT	faster\tagSENT_CONTENT	and\tagSENT_CONTENT	yields\tagSENT_CONTENT	similar\tagmetric	accuracy\tagmetric	as\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	(\tagSENT_CONTENT	an\tagSENT_CONTENT	insignificant\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	decrease\tagSENT_CONTENT	of\tagSENT_CONTENT	less\tagSENT_CONTENT	than\tagSENT_CONTENT	0.1\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DAILY547\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	discussed\tagSENT_CONTENT	below\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	conventional\tagSENT_CONTENT	wisdom\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	important\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	parametric\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	setting\tagSENT_CONTENT	:\tagSENT_CONTENT	part-of-speech_tagging\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	labeled\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Unsupervised\tagSECTITLE_START	Word\tagSECTITLE_CONTENT	Clusters\tagSECTITLE_END	Clustering\tagSECTITLE_START	Method\tagSECTITLE_END	The\tagSENT_START	algorithm\tagSENT_CONTENT	partitions\tagSENT_CONTENT	words\tagSENT_CONTENT	into\tagSENT_CONTENT	abase\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	1,000\tagSENT_CONTENT	clusters\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	induces\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	among\tagSENT_CONTENT	those\tagSENT_CONTENT	1,000\tagSENT_CONTENT	clusters\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	series\tagSENT_CONTENT	of\tagSENT_CONTENT	greedy\tagSENT_CONTENT	agglomerative\tagSENT_CONTENT	merges\tagSENT_CONTENT	that\tagSENT_CONTENT	heuristically\tagSENT_CONTENT	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	hidden\tagSENT_CONTENT	Markov\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	-\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	lexical\tagSENT_CONTENT	-\tagSENT_CONTENT	type\tagSENT_CONTENT	constraint\tagSENT_CONTENT	.\tagSENT_END	Cluster\tagSECTITLE_START	Examples\tagSECTITLE_END	Emoticons\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Emoji\tagSECTITLE_END	Cluster\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Using\tagSENT_START	prefix\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	clusters\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	way\tagSENT_CONTENT	was\tagSENT_CONTENT	similarly\tagSENT_CONTENT	found\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Other\tagSECTITLE_START	Lexical\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Second\tagSENT_START	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	lack\tagSENT_CONTENT	of\tagSENT_CONTENT	consistent\tagSENT_CONTENT	capitalization\tagSENT_CONTENT	conventions\tagSENT_CONTENT	on\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	makes\tagSENT_CONTENT	it\tagSENT_CONTENT	especially\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	recognize\tagSENT_CONTENT	names-\tagSENT_CONTENT	found\tagSENT_CONTENT	relatively\tagmetric	low\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	proper\tagSENT_CONTENT	nouns\tagSENT_CONTENT	-\tagSENT_CONTENT	we\tagSENT_CONTENT	added\tagSENT_CONTENT	a\tagSENT_CONTENT	token\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	name\tagSENT_CONTENT	list\tagSENT_CONTENT	feature\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	fires\tagSENT_CONTENT	on\tagSENT_CONTENT	(\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	function\tagSENT_CONTENT	)\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	names\tagSENT_CONTENT	from\tagSENT_CONTENT	several\tagSENT_CONTENT	sources\tagSENT_CONTENT	:\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	lists\tagSENT_CONTENT	of\tagSENT_CONTENT	celebrities\tagSENT_CONTENT	and\tagSENT_CONTENT	video\tagSENT_CONTENT	games\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Moby\tagSENT_CONTENT	Words\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	US\tagSENT_CONTENT	Locations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	lists\tagSENT_CONTENT	of\tagSENT_CONTENT	male\tagSENT_CONTENT	,\tagSENT_CONTENT	female\tagSENT_CONTENT	,\tagSENT_CONTENT	family\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	proper\tagSENT_CONTENT	names\tagSENT_CONTENT	from\tagSENT_CONTENT	Mark\tagSENT_CONTENT	Kantrowitz\tagSENT_CONTENT	's\tagSENT_CONTENT	name\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Tokenization\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Emoticon\tagSECTITLE_CONTENT	Detection\tagSECTITLE_END	Annotated\tagSECTITLE_START	Dataset\tagSECTITLE_END	The\tagSENT_START	test\tagSENT_CONTENT	set\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	one\tagSENT_CONTENT	random\tagSENT_CONTENT	English\tagSENT_CONTENT	tweet\tagSENT_CONTENT	from\tagSENT_CONTENT	everyday\tagSENT_CONTENT	between\tagSENT_CONTENT	January\tagmetric	1\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	and\tagSENT_CONTENT	June\tagSENT_CONTENT	30\tagSENT_CONTENT	,\tagSENT_CONTENT	2012\tagSENT_CONTENT	.\tagSENT_END	Annotation\tagSECTITLE_START	Methodology\tagSECTITLE_END	et\tagSENT_START	al\tagSENT_CONTENT	.\tagSENT_CONTENT	's\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	corrected\tagSENT_CONTENT	(\tagSENT_CONTENT	concerning\tagSENT_CONTENT	part-of-speech_tagging\tagtask	of\tagSENT_CONTENT	this\tagSENT_CONTENT	/\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	change\tagSENT_CONTENT	to\tagSENT_CONTENT	100\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	0.4\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Compounds\tagSECTITLE_START	in\tagSECTITLE_CONTENT	Penn\tagSECTITLE_CONTENT	Treebank\tagSECTITLE_CONTENT	vs.\tagSECTITLE_CONTENT	Twitter\tagSECTITLE_END	Experiments\tagSECTITLE_END	Main\tagSECTITLE_START	Experiments\tagSECTITLE_END	(\tagSENT_START	4\tagSENT_CONTENT	,\tagSENT_CONTENT	0.06\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	0.5\tagmetric	%\tagmetric	worse\tagmetric	accuracy\tagmetric	but\tagSENT_CONTENT	uses\tagSENT_CONTENT	only\tagSENT_CONTENT	1,632\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	enough\tagSENT_CONTENT	number\tagSENT_CONTENT	to\tagSENT_CONTENT	browse\tagSENT_CONTENT	through\tagSENT_CONTENT	manually\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	DAILY547\tagSENT_CONTENT	's\tagSENT_CONTENT	statistical\tagSENT_CONTENT	representativeness\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	this\tagSENT_CONTENT	gives\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	view\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	tagger\tagmetric	's\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	English\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	full\tagSENT_CONTENT	tagger\tagSENT_CONTENT	attains\tagSENT_CONTENT	93.2\tagmetric	%\tagmetric	accuracy\tagmetric	(\tagSENT_CONTENT	final\tagSENT_CONTENT	row\tagSENT_CONTENT	of\tagSENT_CONTENT	Table\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	dropping\tagSENT_CONTENT	the\tagSENT_CONTENT	tag\tagSENT_CONTENT	dictionaries\tagSENT_CONTENT	and\tagSENT_CONTENT	name\tagSENT_CONTENT	lists\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	clusters\tagSENT_CONTENT	maintain\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	(\tagSENT_CONTENT	row\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	we\tagSENT_CONTENT	drop\tagSENT_CONTENT	the\tagSENT_CONTENT	clusters\tagSENT_CONTENT	and\tagSENT_CONTENT	rely\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	tag\tagSENT_CONTENT	dictionaries\tagSENT_CONTENT	and\tagSENT_CONTENT	namelists\tagSENT_CONTENT	,\tagSENT_CONTENT	accuracy\tagmetric	decreases\tagSENT_CONTENT	significantly\tagSENT_CONTENT	(\tagSENT_CONTENT	row\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	affix\tagSENT_START	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	,\tagSENT_CONTENT	capitalization\tagSENT_CONTENT	,\tagSENT_CONTENT	emoticon\tagSENT_CONTENT	patterns\tagSENT_CONTENT	,\tagSENT_CONTENT	etc.-and\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	is\tagSENT_CONTENT	in\tagSENT_CONTENT	fact\tagSENT_CONTENT	still\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	row\tagSENT_CONTENT	4\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	when\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	the\tagSENT_CONTENT	clusters\tagSENT_CONTENT	as\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	(\tagSENT_CONTENT	hard\tagSENT_CONTENT	)\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagmetric	many\tagmetric	-\tagmetric	to\tagmetric	-\tagmetric	one\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	89.2\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	DAILY547\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	tagger\tagSENT_CONTENT	that\tagSENT_CONTENT	only\tagSENT_CONTENT	uses\tagSENT_CONTENT	word\tagSENT_CONTENT	clusters\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	88.6\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	OCT27\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	was\tagSENT_CONTENT	initially\tagSENT_CONTENT	a\tagSENT_CONTENT	logarithmic\tagSENT_CONTENT	relationship\tagSENT_CONTENT	between\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagmetric	,\tagSENT_CONTENT	but\tagSENT_CONTENT	accuracy\tagmetric	(\tagSENT_CONTENT	and\tagSENT_CONTENT	lexical\tagSENT_CONTENT	coverage\tagSENT_CONTENT	)\tagSENT_CONTENT	levels\tagSENT_CONTENT	out\tagSENT_CONTENT	after\tagSENT_CONTENT	750,000\tagSENT_CONTENT	tweets\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	on\tagSECTITLE_CONTENT	RITTERTW\tagSECTITLE_END	CRFbased\tagSENT_START	tagger\tagSENT_CONTENT	had\tagSENT_CONTENT	85.3\tagmetric	%\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	best\tagSENT_CONTENT	tagger\tagSENT_CONTENT	,\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	PTB\tagSENT_CONTENT	,\tagSENT_CONTENT	IRC\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	,\tagSENT_CONTENT	achieved\tagSENT_CONTENT	88.3\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	IRC\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	NPSCHAT\tagSECTITLE_END	accuracy\tagmetric	,\tagSENT_CONTENT	significantly\tagSENT_CONTENT	improving\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	result\tagSENT_CONTENT	they\tagSENT_CONTENT	report\tagSENT_CONTENT	,\tagSENT_CONTENT	90.8\tagSENT_CONTENT	%\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	tagger\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	mix\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	POS\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	Release\tagSECTITLE_END	Forsyth\tagSENT_START	actually\tagSENT_CONTENT	used\tagSENT_CONTENT	30\tagSENT_CONTENT	different\tagSENT_CONTENT	90/10\tagSENT_CONTENT	random\tagSENT_CONTENT	splits\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	prefer\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	validation\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	never\tagSENT_CONTENT	repeated\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	allowing\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	confidence\tagSENT_CONTENT	estimation\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	from\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	(\tagSENT_CONTENT	via\tagSENT_CONTENT	binomial\tagSENT_CONTENT	sample\tagSENT_CONTENT	variance\tagSENT_CONTENT	,\tagSENT_CONTENT	footnote\tagSENT_CONTENT	19\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	A\tagSECTITLE_START	Part\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Speech\tagSECTITLE_CONTENT	Tagset\tagSECTITLE_END	
S17-2080	title\tagSECTITLE_END	UWaterloo\tagSENT_START	at\tagSENT_CONTENT	SemEval-2017\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	stance_detection\tagtask	stance_detection\tagtask	towards\tagSENT_CONTENT	Rumours\tagSENT_CONTENT	with\tagSENT_CONTENT	Topic\tagSENT_CONTENT	Independent\tagSENT_CONTENT	Features\tagSENT_END	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	describes\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	subtask\tagSENT_CONTENT	-\tagSENT_CONTENT	A\tagSENT_CONTENT	:\tagSENT_CONTENT	SDQC\tagSENT_CONTENT	for\tagSENT_CONTENT	RumourEval\tagdataset	,\tagSENT_CONTENT	task-8\tagSENT_CONTENT	of\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	2017\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	0.78\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	subtask\tagSENT_CONTENT	-\tagSENT_CONTENT	A\tagSENT_CONTENT	of\tagSENT_CONTENT	Ru\tagSENT_CONTENT	-\tagSENT_CONTENT	mourEval\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	stance_detection\tagtask	2\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	brief\tagSENT_CONTENT	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	features\tagSENT_CONTENT	used\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	modeling\tagSENT_CONTENT	technique\tagSENT_CONTENT	are\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	3\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	4\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	conclusions\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	study\tagSENT_CONTENT	are\tagSENT_CONTENT	provided\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	5\tagSENT_CONTENT	.\tagSENT_END	Task\tagSECTITLE_START	Description\tagSECTITLE_END	The\tagSENT_START	objective\tagSENT_CONTENT	of\tagSENT_CONTENT	subtask\tagSENT_CONTENT	-\tagSENT_CONTENT	A\tagSENT_CONTENT	of\tagSENT_CONTENT	RumourEval\tagdataset	was\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	stance\tagSENT_CONTENT	of\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	users\tagSENT_CONTENT	towards\tagSENT_CONTENT	rumour\tagSENT_CONTENT	tweets\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	type\tagSENT_CONTENT	of\tagSENT_CONTENT	stance_detection\tagtask	could\tagSENT_CONTENT	be\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	:\tagSENT_END	System\tagSECTITLE_START	Description\tagSECTITLE_END	For\tagSENT_START	this\tagSENT_CONTENT	reason\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	chose\tagSENT_CONTENT	to\tagSENT_CONTENT	design\tagSENT_CONTENT	topic\tagSENT_CONTENT	independent\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	stance_detection\tagtask	.\tagSENT_END	Prior\tagSENT_START	to\tagSENT_CONTENT	feature\tagSENT_CONTENT	stance_detection\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	data\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	steps\tagSENT_CONTENT	were\tagSENT_CONTENT	carried\tagSENT_CONTENT	out\tagSENT_CONTENT	:\tagSENT_END	Feature\tagSECTITLE_END	For\tagSENT_START	calculating\tagSENT_CONTENT	the\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	polarity\tagSENT_CONTENT	score\tagSENT_CONTENT	,\tagSENT_CONTENT	stance_detection\tagtask	based\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	calculator\tagSENT_CONTENT	,\tagSENT_CONTENT	VADER\tagSENT_CONTENT	,\tagSENT_CONTENT	developed\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	was\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	noted\tagSENT_CONTENT	that\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	(\tagSENT_CONTENT	except\tagSENT_CONTENT	for\tagSENT_CONTENT	similarity\tagSENT_CONTENT	)\tagSENT_END	were\tagSENT_START	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	reply\tagSENT_CONTENT	tweets\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	.\tagSENT_END	Feature\tagSECTITLE_END	Results\tagSECTITLE_END	In\tagSENT_START	stance_detection\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	discuss\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	topic\tagSENT_CONTENT	independent\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Classification\tagmetric	accuracy\tagmetric	was\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	RumourEval\tagSENT_CONTENT	subtask\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	since\tagSENT_CONTENT	a\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tweets\tagSENT_CONTENT	(\tagSENT_CONTENT	about\tagSENT_CONTENT	70\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	belonged\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	label\tagSENT_CONTENT	'\tagSENT_CONTENT	comment\tagSENT_CONTENT	'\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	averaged\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	here\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	was\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	validating\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	determining\tagSENT_CONTENT	stance_detection\tagtask	of\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	ones\tagSENT_CONTENT	listed\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	is\tagSENT_CONTENT	observed\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagmetric	reasonable\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	class\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	except\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	'\tagSENT_CONTENT	deny\tagSENT_CONTENT	'\tagSENT_CONTENT	label\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	it\tagSENT_CONTENT	found\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	models\tagSENT_CONTENT	performed\tagSENT_CONTENT	similarly\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	because\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	labels\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	'\tagSENT_CONTENT	comment\tagSENT_CONTENT	'\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	had\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	0.31\tagSENT_CONTENT	,\tagSENT_CONTENT	stance_detection\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	features\tagSENT_CONTENT	resulted\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	0.45\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	highest\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	was\tagSENT_CONTENT	obtained\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	features\tagSENT_CONTENT	were\tagSENT_CONTENT	discarded\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	:\tagSENT_CONTENT	@user\tagSENT_CONTENT	,\tagSENT_CONTENT	hashtag\tagSENT_CONTENT	,\tagSENT_CONTENT	similarity\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	,\tagSENT_CONTENT	characters\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	submission\tagSENT_CONTENT	with\tagSENT_CONTENT	this\tagSENT_CONTENT	model\tagSENT_CONTENT	made\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	for\tagSENT_CONTENT	subtask\tagSENT_CONTENT	A\tagSENT_CONTENT	of\tagSENT_CONTENT	RumourEval\tagdataset	.\tagSENT_END	When\tagSENT_START	all\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	features\tagSENT_CONTENT	were\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	resulted\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	0.77\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	0.44\tagSENT_CONTENT	,\tagSENT_CONTENT	suggesting\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	tandem\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	yield\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	result\tagSENT_CONTENT	than\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	category\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	provides\tagSENT_CONTENT	stance_detection\tagtask	of\tagSENT_CONTENT	our\tagSENT_CONTENT	submission\tagSENT_CONTENT	for\tagSENT_CONTENT	subtask\tagSENT_CONTENT	A\tagSENT_CONTENT	of\tagSENT_CONTENT	RumourEval\tagdataset	in\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	participants\tagSENT_CONTENT	were\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	the\tagSENT_CONTENT	stance\tagSENT_CONTENT	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	towards\tagSENT_CONTENT	rumours\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	system\tagSENT_CONTENT	ranked\tagSENT_CONTENT	second\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	
N18-1055	title\tagSECTITLE_END	Approaching\tagSENT_START	grammatical_error_correction\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	Low\tagSENT_CONTENT	-\tagSENT_CONTENT	Resource\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_CONTENT	Task\tagSENT_END	abstract\tagSECTITLE_END	Previously\tagSENT_START	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	reach\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	SMT\tagSENT_CONTENT	)\tagSENT_CONTENT	baselines\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Most\tagSENT_START	successful\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	methods\tagSENT_CONTENT	from\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	SMT\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	the\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	variant\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2014\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	on\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Junczys\tagSENT_CONTENT	-\tagSENT_CONTENT	Dowmunt\tagSENT_CONTENT	and\tagSENT_CONTENT	Grundkiewicz\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	established\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagSENT_CONTENT	by\tagSENT_CONTENT	SMT\tagSENT_CONTENT	that\tagSENT_CONTENT	remain\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	trustable\tagSECTITLE_CONTENT	baseline\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	neural\tagSECTITLE_CONTENT	GEC\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	combine\tagSENT_CONTENT	insights\tagSENT_CONTENT	from\tagSENT_CONTENT	JunczysDowmunt\tagSENT_CONTENT	and\tagSENT_CONTENT	Grundkiewicz\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	by\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	and\tagSENT_CONTENT	from\tagSENT_CONTENT	for\tagSENT_CONTENT	trustable\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	to\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	trustable\tagSENT_CONTENT	baseline\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	and\tagSECTITLE_CONTENT	test\tagSECTITLE_CONTENT	data\tagSECTITLE_END	Preprocessing\tagSECTITLE_START	and\tagSECTITLE_CONTENT	sub\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	words\tagSECTITLE_END	It\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	largely\tagSENT_CONTENT	ignored\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	even\tagSENT_CONTENT	when\tagSENT_CONTENT	word\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	issues\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	and\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	procedure\tagSECTITLE_END	Optimizer\tagSECTITLE_START	instability\tagSECTITLE_END	Ensembling\tagSECTITLE_START	of\tagSECTITLE_CONTENT	independent\tagSECTITLE_CONTENT	models\tagSECTITLE_END	Ensembles\tagSENT_START	choose\tagSENT_CONTENT	grammatical_error_correction\tagtask	for\tagSENT_CONTENT	which\tagSENT_CONTENT	all\tagSENT_CONTENT	independent\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	fairly\tagSENT_CONTENT	confident\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	an\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	precision\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	drop\tagSENT_CONTENT	in\tagSENT_CONTENT	recall\tagSENT_CONTENT	.\tagSENT_END	Source\tagSECTITLE_START	-\tagSECTITLE_CONTENT	word\tagSECTITLE_CONTENT	dropout\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	corruption\tagSECTITLE_END	GEC\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	treated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	denoising\tagSENT_CONTENT	task\tagSENT_CONTENT	where\tagSENT_CONTENT	grammatical_error_correction\tagtask	are\tagSENT_CONTENT	corruptions\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	reduced\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	introducing\tagSENT_CONTENT	grammatical_error_correction\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	side\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	teach\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	trust\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	grammatical_error_correction\tagtask	more\tagSENT_CONTENT	freely\tagSENT_CONTENT	.\tagSENT_END	Domain\tagSECTITLE_START	adaptation\tagSECTITLE_END	Error\tagSECTITLE_START	adaptation\tagSECTITLE_END	Tied\tagSECTITLE_START	embeddings\tagSECTITLE_END	Edit\tagSECTITLE_START	-\tagSECTITLE_CONTENT	weighted\tagSECTITLE_CONTENT	MLE\tagSECTITLE_CONTENT	objective\tagSECTITLE_END	Transfer\tagSECTITLE_START	learning\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	GEC\tagSECTITLE_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	decoder\tagSECTITLE_CONTENT	parameters\tagSECTITLE_END	Results\tagSECTITLE_START	for\tagSECTITLE_CONTENT	transfer\tagSECTITLE_CONTENT	learning\tagSECTITLE_END	Ensembling\tagSECTITLE_START	with\tagSECTITLE_CONTENT	language\tagSECTITLE_CONTENT	models\tagSECTITLE_END	grammatical_error_correction\tagtask	of\tagSENT_CONTENT	sentence\tagSENT_END	Deeper\tagSECTITLE_START	NMT\tagSECTITLE_CONTENT	models\tagSECTITLE_END	Architectures\tagSECTITLE_END	Training\tagSECTITLE_START	settings\tagSECTITLE_END	Model\tagSECTITLE_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	deep\tagSECTITLE_CONTENT	models\tagSECTITLE_END	Results\tagSECTITLE_END	A\tagSECTITLE_START	standard\tagSECTITLE_CONTENT	tool\tagSECTITLE_CONTENT	set\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	neural\tagSECTITLE_CONTENT	GEC\tagSECTITLE_END	Comparing\tagSENT_START	results\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	both\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	M\tagSENT_CONTENT	2\tagSENT_CONTENT	for\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	,\tagSENT_CONTENT	GLEU\tagSENT_CONTENT	for\tagSENT_CONTENT	JFLEG\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	seems\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	isolate\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	reliable\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	:\tagSENT_END	
1802.05365	title\tagSECTITLE_END	Deep\tagSENT_START	contextualized\tagSENT_CONTENT	coreference_resolution\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	anew\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	contextual\tagSENT_CONTENT	-\tagSENT_CONTENT	ized\tagSENT_CONTENT	word\tagSENT_CONTENT	representation\tagSENT_CONTENT	that\tagSENT_CONTENT	models\tagSENT_CONTENT	both\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	complex\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	use\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	syntax\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic_role_labeling\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	how\tagSENT_CONTENT	these\tagSENT_CONTENT	uses\tagSENT_CONTENT	vary\tagSENT_CONTENT	across\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	contexts\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	polysemy\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	They\tagSENT_START	should\tagSENT_CONTENT	ideally\tagSENT_CONTENT	model\tagSENT_CONTENT	both\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	complex\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	use\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	syntax\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic_role_labeling\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	how\tagSENT_CONTENT	these\tagSENT_CONTENT	uses\tagSENT_CONTENT	vary\tagSENT_CONTENT	across\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	contexts\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	polysemy\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	coreference_resolution\tagtask	differ\tagSENT_CONTENT	from\tagSENT_CONTENT	traditional\tagSENT_CONTENT	word\tagSENT_CONTENT	type\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	in\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	token\tagSENT_CONTENT	is\tagSENT_CONTENT	assigned\tagSENT_CONTENT	a\tagSENT_CONTENT	representation\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	coreference_resolution\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	states\tagSENT_CONTENT	capture\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	meaning\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	without\tagSENT_CONTENT	modification\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	word\tagSENT_CONTENT	sense\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	tasks\tagSENT_CONTENT	)\tagSENT_CONTENT	while\tagSENT_CONTENT	lowerlevel\tagSENT_CONTENT	states\tagSENT_CONTENT	model\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	syntax\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	first\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	easily\tagSENT_CONTENT	added\tagSENT_CONTENT	to\tagSENT_CONTENT	existing\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	six\tagSENT_CONTENT	diverse\tagSENT_CONTENT	and\tagSENT_CONTENT	challenging\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	problems\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	both\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	and\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	coreference_resolution\tagtask	outperform\tagSENT_CONTENT	those\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	Due\tagSENT_START	to\tagSENT_CONTENT	their\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	area\tagSENT_CONTENT	standard\tagSENT_CONTENT	component\tagSENT_CONTENT	of\tagSENT_CONTENT	most\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	NLP\tagSENT_CONTENT	architectures\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	for\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic_role_labeling\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	approach\tagSENT_CONTENT	also\tagSENT_CONTENT	benefits\tagSENT_CONTENT	from\tagSENT_CONTENT	subword\tagSENT_CONTENT	units\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	seamlessly\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	sense\tagSENT_CONTENT	information\tagSENT_CONTENT	into\tagSENT_CONTENT	downstream\tagSENT_CONTENT	tasks\tagSENT_CONTENT	without\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	training\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	predefined\tagSENT_CONTENT	sense\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	Other\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	also\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	learning\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	similar\tagSENT_CONTENT	signals\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	induced\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	modified\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	objective\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	very\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	downstream\tagSENT_CONTENT	tasks\tagSENT_CONTENT	that\tagSENT_CONTENT	mix\tagSENT_CONTENT	these\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervision\tagSENT_CONTENT	.\tagSENT_END	ELMo\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_CONTENT	from\tagSECTITLE_CONTENT	Language\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	They\tagSENT_START	are\tagSENT_CONTENT	computed\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	biLMs\tagSENT_CONTENT	with\tagSENT_CONTENT	coreference_resolution\tagtask	(\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	3.1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	internal\tagSENT_CONTENT	network\tagSENT_CONTENT	states\tagSENT_CONTENT	(\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	3.2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	setup\tagSENT_CONTENT	allows\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	semantic_role_labeling\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	is\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	(\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	3.4\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	easily\tagSENT_CONTENT	incorporated\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	existing\tagSENT_CONTENT	neural\tagSENT_CONTENT	NLP\tagSENT_CONTENT	architectures\tagSENT_CONTENT	(\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	3.3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Bidirectional\tagSECTITLE_START	language\tagSECTITLE_CONTENT	models\tagSECTITLE_END	At\tagSENT_START	each\tagSENT_CONTENT	position\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layer\tagSENT_CONTENT	outputs\tagSENT_CONTENT	coreference_resolution\tagtask	We\tagSENT_START	tie\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	representation\tagSENT_CONTENT	(\tagSENT_CONTENT	Θ\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	(\tagSENT_CONTENT	Θ\tagSENT_CONTENT	s\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	direction\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	separate\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	in\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	formulation\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	approach\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	exception\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	share\tagSENT_CONTENT	some\tagSENT_CONTENT	weights\tagSENT_CONTENT	between\tagSENT_CONTENT	named_entity_recognition\tagtask	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	completely\tagSENT_CONTENT	independent\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	named_entity_recognition\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	depart\tagSENT_CONTENT	from\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	by\tagSENT_CONTENT	introducing\tagSENT_CONTENT	anew\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	learning\tagSENT_CONTENT	coreference_resolution\tagtask	that\tagSENT_CONTENT	area\tagSENT_CONTENT	linear\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	ELMo\tagSECTITLE_END	γ\tagSENT_START	is\tagSENT_CONTENT	of\tagSENT_CONTENT	practical\tagSENT_CONTENT	importance\tagSENT_CONTENT	to\tagSENT_CONTENT	aid\tagSENT_CONTENT	the\tagSENT_CONTENT	optimization\tagSENT_CONTENT	process\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	sentiment_analysis\tagtask	for\tagSENT_CONTENT	details\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Considering\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	activations\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	biLM\tagSENT_CONTENT	layer\tagSENT_CONTENT	have\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	in\tagSENT_CONTENT	some\tagSENT_CONTENT	cases\tagSENT_CONTENT	it\tagSENT_CONTENT	also\tagSENT_CONTENT	helped\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	biLM\tagSENT_CONTENT	layer\tagSENT_CONTENT	before\tagSENT_CONTENT	weighting\tagSENT_CONTENT	.\tagSENT_END	Using\tagSECTITLE_START	biLMs\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	NLP\tagSECTITLE_CONTENT	tasks\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	let\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	task\tagSENT_CONTENT	model\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	below\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	N\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	standard\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	token\tagSENT_CONTENT	representation\tagSENT_CONTENT	x\tagSENT_CONTENT	k\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	using\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	optionally\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	add\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	supervised\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	freeze\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	the\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	vector\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	task\tagSENT_CONTENT	k\tagSENT_CONTENT	with\tagSENT_CONTENT	x\tagSENT_CONTENT	k\tagSENT_CONTENT	and\tagSENT_CONTENT	pass\tagSENT_CONTENT	the\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	named_entity_recognition\tagtask	[\tagSENT_CONTENT	x\tagSENT_CONTENT	k\tagSENT_CONTENT	;\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	task\tagSENT_CONTENT	k\tagSENT_CONTENT	]\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	RNN\tagSENT_CONTENT	.\tagSENT_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	trained\tagSECTITLE_CONTENT	bidirectional\tagSECTITLE_CONTENT	language\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	architecture\tagSECTITLE_END	and\tagSENT_START	,\tagSENT_CONTENT	but\tagSENT_CONTENT	modified\tagSENT_CONTENT	to\tagSENT_CONTENT	support\tagSENT_CONTENT	joint\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	directions\tagSENT_CONTENT	and\tagSENT_CONTENT	add\tagSENT_CONTENT	named_entity_recognition\tagtask	between\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	final\tagSENT_CONTENT	model\tagSENT_CONTENT	uses\tagSENT_CONTENT	L\tagSENT_CONTENT	=\tagSENT_CONTENT	2\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	4096\tagSENT_CONTENT	units\tagSENT_CONTENT	and\tagSENT_CONTENT	512\tagSENT_CONTENT	dimension\tagSENT_CONTENT	projections\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	to\tagSENT_CONTENT	second\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	uses\tagSENT_CONTENT	2048\tagSENT_CONTENT	character\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	filters\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	two\tagSENT_CONTENT	highway\tagSENT_CONTENT	layers\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	down\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	512\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	See\tagSENT_START	sentiment_analysis\tagtask	for\tagSENT_CONTENT	details\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	every\tagSENT_CONTENT	task\tagSENT_CONTENT	considered\tagSENT_CONTENT	,\tagSENT_CONTENT	simply\tagSENT_CONTENT	adding\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	establishes\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	coreference_resolution\tagtask	ranging\tagSENT_CONTENT	from\tagSENT_CONTENT	6\tagSENT_CONTENT	-20\tagSENT_CONTENT	%\tagSENT_CONTENT	over\tagSENT_CONTENT	strong\tagSENT_CONTENT	base\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	coreference_resolution\tagtask	across\tagSENT_CONTENT	a\tagSENT_CONTENT	diverse\tagSENT_CONTENT	set\tagSENT_CONTENT	model\tagSENT_CONTENT	architectures\tagSENT_CONTENT	and\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	A\tagSENT_START	11\tagSENT_CONTENT	member\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	pushes\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	to\tagSENT_CONTENT	87.4\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	at\tagSENT_CONTENT	time\tagSENT_CONTENT	of\tagSENT_CONTENT	submission\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	leaderboard\tagSENT_CONTENT	.\tagSENT_END	semantic_role_labeling\tagtask	labeling\tagSENT_CONTENT	A\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeling\tagSENT_CONTENT	(\tagSENT_CONTENT	SRL\tagSENT_CONTENT	)\tagSENT_CONTENT	system\tagSENT_CONTENT	models\tagSENT_CONTENT	the\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	described\tagSENT_CONTENT	as\tagSENT_CONTENT	answering\tagSENT_CONTENT	"\tagSENT_CONTENT	Who\tagSENT_CONTENT	did\tagSENT_CONTENT	what\tagSENT_CONTENT	to\tagSENT_CONTENT	whom\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	used\tagSENT_CONTENT	an\tagSENT_CONTENT	8-layer\tagSENT_CONTENT	deep\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	directions\tagSENT_CONTENT	interleaved\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	coreference_resolution\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	clustering\tagSENT_CONTENT	mentions\tagSENT_CONTENT	in\tagSENT_CONTENT	text\tagSENT_CONTENT	that\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	underlying\tagSENT_CONTENT	real\tagSENT_CONTENT	world\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	first\tagSENT_CONTENT	compute\tagSENT_CONTENT	span\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	applies\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	mention\tagSENT_CONTENT	ranking\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	coreference_resolution\tagtask	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	coreference_resolution\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2012\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	enhanced\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	achieves\tagSENT_CONTENT	92.22\tagSENT_CONTENT	%\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	averaged\tagSENT_CONTENT	over\tagSENT_CONTENT	five\tagSENT_CONTENT	runs\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	This\tagSENT_START	section\tagSENT_CONTENT	provides\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	validate\tagSENT_CONTENT	our\tagSENT_CONTENT	chief\tagSENT_CONTENT	claims\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	elucidate\tagSENT_CONTENT	some\tagSENT_CONTENT	interesting\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	5.3\tagSENT_START	explores\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	contextual\tagSENT_CONTENT	information\tagSENT_CONTENT	captured\tagSENT_CONTENT	in\tagSENT_CONTENT	biLMs\tagSENT_CONTENT	and\tagSENT_CONTENT	uses\tagSENT_CONTENT	coreference_resolution\tagtask	to\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	represented\tagSENT_CONTENT	at\tagSENT_CONTENT	lower\tagSENT_CONTENT	layers\tagSENT_CONTENT	while\tagSENT_CONTENT	semantic_role_labeling\tagtask	is\tagSENT_CONTENT	captured\tagSENT_CONTENT	a\tagSENT_CONTENT	higher\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	MT\tagSENT_CONTENT	encoders\tagSENT_CONTENT	.\tagSENT_END	Alternate\tagSECTITLE_START	layer\tagSECTITLE_CONTENT	weighting\tagSECTITLE_CONTENT	schemes\tagSECTITLE_END	Averaging\tagSENT_START	all\tagSENT_CONTENT	biLM\tagSENT_CONTENT	layers\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	layer\tagSENT_CONTENT	improves\tagSENT_CONTENT	F\tagmetric	1\tagSENT_END	For\tagSENT_START	SNLI\tagSENT_CONTENT	,\tagSENT_CONTENT	averaging\tagSENT_CONTENT	all\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	λ=1\tagSENT_CONTENT	improves\tagSENT_CONTENT	development\tagmetric	accuracy\tagmetric	from\tagSENT_CONTENT	88.2\tagSENT_CONTENT	to\tagSENT_CONTENT	88.7\tagSENT_CONTENT	%\tagSENT_CONTENT	over\tagSENT_CONTENT	using\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	Where\tagSECTITLE_START	to\tagSECTITLE_CONTENT	include\tagSECTITLE_CONTENT	ELMo\tagSECTITLE_CONTENT	?\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	at\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	layers\tagSENT_CONTENT	for\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	and\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	improves\tagSENT_CONTENT	over\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	for\tagSENT_CONTENT	SRL\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	coreference_resolution\tagtask	,\tagSENT_CONTENT	not\tagSENT_CONTENT	shown\tagSENT_CONTENT	)\tagSENT_CONTENT	performance\tagSENT_CONTENT	is\tagSENT_CONTENT	highest\tagSENT_CONTENT	when\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	included\tagSENT_CONTENT	at\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	possible\tagSENT_CONTENT	explanation\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	result\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	and\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	architectures\tagSENT_CONTENT	use\tagSENT_CONTENT	sentiment_analysis\tagtask	after\tagSENT_CONTENT	the\tagSENT_CONTENT	biRNN\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	introducing\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	at\tagSENT_CONTENT	this\tagSENT_CONTENT	layer\tagSENT_CONTENT	allows\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	directly\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	's\tagSENT_CONTENT	internal\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	What\tagSECTITLE_START	information\tagSECTITLE_CONTENT	is\tagSECTITLE_CONTENT	captured\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	biLM\tagSECTITLE_CONTENT	's\tagSECTITLE_CONTENT	representations\tagSECTITLE_CONTENT	?\tagSECTITLE_END	coreference_resolution\tagtask	POS\tagSENT_START	tagging\tagSENT_CONTENT	To\tagSENT_CONTENT	examine\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	captures\tagSENT_CONTENT	basic\tagSENT_CONTENT	syntax\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	named_entity_recognition\tagtask	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	classifier\tagSENT_CONTENT	that\tagSENT_CONTENT	predicts\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	(\tagSENT_CONTENT	PTB\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	unlike\tagSENT_CONTENT	WSD\tagSENT_CONTENT	,\tagSENT_CONTENT	accuracies\tagmetric	using\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	biLM\tagSENT_CONTENT	layer\tagSENT_CONTENT	are\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	results\tagSENT_CONTENT	from\tagSENT_CONTENT	deep\tagSENT_CONTENT	biLSTMs\tagSENT_CONTENT	in\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	MT\tagSENT_CONTENT	.\tagSENT_END	CoVe\tagSENT_START	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	pattern\tagSENT_CONTENT	as\tagSENT_CONTENT	those\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	just\tagSENT_CONTENT	like\tagSENT_CONTENT	for\tagSENT_CONTENT	WSD\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	achieves\tagSENT_CONTENT	higher\tagmetric	accuracies\tagmetric	than\tagSENT_CONTENT	the\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	Sample\tagSECTITLE_START	efficiency\tagSECTITLE_END	For\tagSENT_START	coreference_resolution\tagtask	and\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	strongly\tagSENT_CONTENT	favored\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	distribution\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	peaked\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Visualization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	learned\tagSECTITLE_CONTENT	weights\tagSECTITLE_END	A\tagSECTITLE_START	Supplemental\tagSECTITLE_CONTENT	Material\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	accompany\tagSECTITLE_CONTENT	Deep\tagSECTITLE_CONTENT	contextualized\tagSECTITLE_CONTENT	word\tagSECTITLE_CONTENT	representations\tagSECTITLE_END	A.1\tagSECTITLE_START	Fine\tagSECTITLE_CONTENT	tuning\tagSECTITLE_CONTENT	biLM\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	,\tagSENT_CONTENT	fine\tagSENT_CONTENT	tuning\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	increased\tagSENT_CONTENT	development\tagmetric	accuracy\tagmetric	0.6\tagSENT_CONTENT	%\tagSENT_CONTENT	from\tagSENT_CONTENT	88.9\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	89.5\tagSENT_CONTENT	%\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	single\tagSENT_CONTENT	best\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	A.2\tagSECTITLE_START	Importance\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	γ\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Eqn\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	)\tagSECTITLE_END	(\tagSENT_START	1\tagSENT_CONTENT	)\tagSENT_CONTENT	was\tagSENT_CONTENT	of\tagSENT_CONTENT	practical\tagSENT_CONTENT	importance\tagSENT_CONTENT	to\tagSENT_CONTENT	aid\tagSENT_CONTENT	optimization\tagSENT_CONTENT	,\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	internal\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	specific\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	A.3\tagSECTITLE_START	Textual\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_END	half\tagmetric	each\tagmetric	time\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	epochs\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	added\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	vectors\tagSENT_CONTENT	to\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	lowest\tagSENT_CONTENT	layer\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	and\tagSENT_CONTENT	λ\tagSENT_CONTENT	=\tagSENT_CONTENT	0.001\tagSENT_CONTENT	.\tagSENT_END	compares\tagSENT_START	test\tagSENT_CONTENT	set\tagSENT_CONTENT	accuracy\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	previously\tagSENT_CONTENT	published\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	adding\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	ESIM\tagSENT_CONTENT	model\tagSENT_CONTENT	improved\tagSENT_CONTENT	accuracy\tagmetric	by\tagSENT_CONTENT	0.7\tagSENT_CONTENT	%\tagSENT_CONTENT	establishing\tagSENT_CONTENT	anew\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	of\tagSENT_CONTENT	88.7\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	five\tagSENT_CONTENT	member\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	pushes\tagSENT_CONTENT	the\tagmetric	overall\tagmetric	accuracy\tagmetric	to\tagSENT_CONTENT	89.3\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	A.4\tagSECTITLE_START	Question\tagSECTITLE_CONTENT	Answering\tagSECTITLE_END	Model\tagSECTITLE_END	Acc\tagSECTITLE_START	.\tagSECTITLE_END	Overall\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	submission\tagSENT_CONTENT	had\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	improving\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	result\tagSENT_CONTENT	(\tagSENT_CONTENT	SAN\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	1.4\tagSENT_CONTENT	%\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	by\tagSENT_CONTENT	4.2\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	A.5\tagSECTITLE_START	Semantic\tagSECTITLE_CONTENT	Role\tagSECTITLE_CONTENT	Labeling\tagSECTITLE_END	Words\tagSENT_START	are\tagSENT_CONTENT	represented\tagSENT_CONTENT	using\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	100\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	vector\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	initialized\tagSENT_CONTENT	using\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	,\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	predicate\tagSENT_CONTENT	feature\tagSENT_CONTENT	,\tagSENT_CONTENT	represented\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	100\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	em\tagSENT_CONTENT	-\tagSENT_CONTENT	bedding\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	200\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	token\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	passed\tagSENT_CONTENT	through\tagSENT_CONTENT	an\tagSENT_CONTENT	8\tagSENT_CONTENT	layer\tagSENT_CONTENT	"\tagSENT_CONTENT	interleaved\tagSENT_CONTENT	"\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	300\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layers\tagSENT_CONTENT	alternate\tagSENT_CONTENT	per\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	deep\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	projected\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	final\tagSENT_CONTENT	dense\tagSENT_CONTENT	layer\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	activation\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	named_entity_recognition\tagtask	overall\tagSENT_CONTENT	possible\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	Labels\tagSENT_START	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	from\tagSENT_CONTENT	PropBank\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	augmented\tagSENT_CONTENT	with\tagSENT_CONTENT	semantic_role_labeling\tagtask	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	argument\tagSENT_CONTENT	spans\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	single\tagSENT_CONTENT	model\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	84.6\tagSENT_CONTENT	F1\tagSENT_CONTENT	represents\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	result\tagSENT_CONTENT	on\tagSENT_CONTENT	semantic_role_labeling\tagtask	,\tagSENT_CONTENT	surpassing\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	result\tagSENT_CONTENT	by\tagSENT_CONTENT	2.9\tagSENT_CONTENT	F1\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	5-model\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	by\tagSENT_CONTENT	1.2\tagSENT_CONTENT	F1\tagSENT_CONTENT	.\tagSENT_END	A.6\tagSECTITLE_START	Coreference\tagSECTITLE_CONTENT	resolution\tagSECTITLE_END	coreference_resolution\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	neural\tagSENT_CONTENT	model\tagSENT_CONTENT	from\tagSENT_CONTENT	with\tagSENT_CONTENT	all\tagSENT_CONTENT	hyModel\tagSENT_CONTENT	EM\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	BiDAF\tagSENT_CONTENT	(\tagSENT_END	68.0\tagSENT_START	77.3\tagSENT_CONTENT	BiDAF\tagSENT_CONTENT	+\tagSENT_CONTENT	named_entity_recognition\tagtask	72.1\tagSENT_CONTENT	81.1\tagSENT_END	named_entity_recognition\tagtask	added\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	lowest\tagSENT_CONTENT	layer\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	weighted\tagSENT_CONTENT	the\tagSENT_CONTENT	biLM\tagSENT_CONTENT	layers\tagSENT_CONTENT	using\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	without\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	λ\tagSENT_CONTENT	=\tagSENT_CONTENT	0\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	by\tagSENT_CONTENT	3.2\tagSENT_CONTENT	%\tagSENT_CONTENT	average\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	result\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	best\tagSENT_CONTENT	by\tagSENT_CONTENT	1.6\tagSENT_CONTENT	%\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	.\tagSENT_END	A.7\tagSECTITLE_START	Named\tagSECTITLE_CONTENT	Entity\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_END	Our\tagSENT_START	baseline\tagSENT_CONTENT	NER\tagSENT_CONTENT	model\tagSENT_CONTENT	concatenates\tagSENT_CONTENT	50\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	Senna\tagSENT_CONTENT	vectors\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagmetric	CNN\tagmetric	character\tagmetric	named_entity_recognition\tagtask	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	92.22\tagSENT_CONTENT	%\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	from\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	establishes\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	Collobert\tagSECTITLE_START	et\tagSECTITLE_CONTENT	al\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2011\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	♣\tagSECTITLE_END	A.8\tagSECTITLE_START	Sentiment\tagSECTITLE_CONTENT	classification\tagSECTITLE_END	
W15-4313	title\tagSECTITLE_END	NCSU\tagSENT_START	-\tagSENT_CONTENT	SAS\tagSENT_CONTENT	-\tagSENT_CONTENT	Ning\tagSENT_CONTENT	:\tagSENT_CONTENT	Candidate\tagSENT_CONTENT	Generation\tagSENT_CONTENT	and\tagSENT_CONTENT	Feature\tagSENT_CONTENT	Engineering\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	we\tagSENT_CONTENT	developed\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	English\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	reading\tagSENT_CONTENT	the\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	text\tagSENT_CONTENT	posted\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	user\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	company\tagSENT_CONTENT	can\tagSENT_CONTENT	learn\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	preferences\tagSENT_CONTENT	and\tagSENT_CONTENT	connections\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	targeted\tagSENT_CONTENT	advertising\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	lexical_normalization\tagtask	that\tagSENT_CONTENT	attempts\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	lexical\tagSENT_CONTENT	normalization\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	English\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	text\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	training\tagSENT_CONTENT	text\tagSENT_CONTENT	with\tagSENT_CONTENT	human\tagSENT_CONTENT	annotation\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	organized\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	Section\tagmetric	2\tagSENT_CONTENT	describes\tagSENT_CONTENT	the\tagSENT_CONTENT	architecture\tagSENT_CONTENT	and\tagSENT_CONTENT	components\tagSENT_CONTENT	shared\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	constrained\tagSENT_CONTENT	and\tagSENT_CONTENT	unconstrained\tagSENT_CONTENT	modes\tagSENT_CONTENT	.\tagSENT_END	Section\tagmetric	3\tagSENT_CONTENT	lists\tagSENT_CONTENT	what\tagSENT_CONTENT	resources\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	each\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Section\tagmetric	4\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	settings\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	constrained\tagSENT_CONTENT	and\tagSENT_CONTENT	unconstrained\tagSENT_CONTENT	modes\tagSENT_CONTENT	and\tagSENT_CONTENT	compare\tagSENT_CONTENT	their\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Section\tagmetric	5\tagSENT_CONTENT	concludes\tagSENT_CONTENT	the\tagSENT_CONTENT	paper\tagSENT_CONTENT	and\tagSENT_CONTENT	discusses\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	Architecture\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Components\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	System\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	tokenized\tagSENT_CONTENT	English\tagSENT_CONTENT	tweet\tagSENT_CONTENT	T\tagSENT_CONTENT	=\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	…\tagSENT_CONTENT	,\tagSENT_CONTENT	tn\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	ti\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	token\tagSENT_CONTENT	and\tagSENT_CONTENT	n\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	processes\tagSENT_CONTENT	one\tagSENT_CONTENT	token\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	two\tagSENT_CONTENT	components\tagSENT_CONTENT	:\tagSENT_CONTENT	candidate\tagSENT_CONTENT	generation\tagSENT_CONTENT	and\tagSENT_CONTENT	candidate\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Candidate\tagSECTITLE_START	Generation\tagSECTITLE_END	•\tagSENT_START	Top\tagSENT_CONTENT	-\tagSENT_CONTENT	m\tagSENT_CONTENT	most\tagSENT_CONTENT	similar\tagSENT_CONTENT	canonical\tagSENT_CONTENT	forms\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	subsection\tagmetric	2.2\tagSENT_CONTENT	for\tagSENT_CONTENT	details\tagSENT_CONTENT	of\tagSENT_CONTENT	similarity\tagSENT_CONTENT	measurement\tagSENT_CONTENT	)\tagSENT_CONTENT	shows\tagSENT_CONTENT	an\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	anew\tagSENT_CONTENT	tweet\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Similarity\tagSECTITLE_START	Index\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	in\tagSENT_CONTENT	string\tagSENT_CONTENT	sis\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	contiguous\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	n\tagSENT_CONTENT	characters\tagSENT_CONTENT	in\tagSENT_CONTENT	s.\tagSENT_CONTENT	A\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	in\tagSENT_CONTENT	string\tagSENT_CONTENT	sis\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	with\tagSENT_CONTENT	gaps\tagSENT_CONTENT	between\tagSENT_CONTENT	characters\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	n\tagSENT_CONTENT	characters\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	characters\tagSENT_CONTENT	is\tagSENT_CONTENT	k.\tagSENT_END	String\tagSECTITLE_END	Different\tagSENT_START	weights\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	similarity\tagSENT_CONTENT	features\tagSENT_CONTENT	when\tagSENT_CONTENT	calculating\tagSENT_CONTENT	similarity\tagSENT_CONTENT	scores\tagSENT_CONTENT	because\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	at\tagSENT_CONTENT	different\tagSENT_CONTENT	positions\tagSENT_CONTENT	have\tagSENT_CONTENT	different\tagSENT_CONTENT	importance\tagSENT_CONTENT	for\tagSENT_CONTENT	word\tagmetric	recognition\tagmetric	.\tagSENT_END	The\tagSENT_START	similarity\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	use\tagSENT_CONTENT	multiple\tagSENT_CONTENT	(\tagSENT_CONTENT	n\tagSENT_CONTENT	,\tagSENT_CONTENT	k\tagSENT_CONTENT	)\tagSENT_CONTENT	configurations\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	just\tagSENT_CONTENT	one\tagSENT_CONTENT	.\tagSENT_END	edits\tagSENT_START	such\tagSENT_CONTENT	as\tagSENT_CONTENT	insertion\tagmetric	,\tagSENT_CONTENT	deletion\tagSENT_CONTENT	and\tagSENT_CONTENT	substitution\tagSENT_CONTENT	.\tagSENT_END	Compared\tagSENT_START	with\tagSENT_CONTENT	Levenshtein\tagSENT_CONTENT	distance\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	disadvantage\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	similarity\tagSENT_CONTENT	measurement\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	strings\tagSENT_CONTENT	may\tagSENT_CONTENT	have\tagSENT_CONTENT	1.0\tagSENT_CONTENT	similarity\tagSENT_CONTENT	score\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	can\tagSENT_CONTENT	only\tagSENT_CONTENT	capture\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	The\tagSECTITLE_START	feature\tagSECTITLE_CONTENT	set\tagSECTITLE_CONTENT	size\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	is\tagSECTITLE_CONTENT	bounded\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	O(l(s\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Then\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	complexity\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	calculating\tagSECTITLE_CONTENT	Levenshtein\tagSECTITLE_CONTENT	distance\tagSECTITLE_CONTENT	between\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	is\tagSECTITLE_CONTENT	O(l(s\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	l(s\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	which\tagSECTITLE_END	But\tagSENT_START	it\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	handle\tagSENT_CONTENT	repetition\tagmetric	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	characters\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	"\tagSENT_CONTENT	lolol\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	linear\tagSENT_CONTENT	complexity\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	using\tagSENT_CONTENT	hash\tagSENT_CONTENT	table\tagSENT_CONTENT	to\tagSENT_CONTENT	calculate\tagSENT_CONTENT	set\tagSENT_CONTENT	union\tagSENT_CONTENT	and\tagSENT_CONTENT	intersection\tagmetric	.\tagSENT_END	lexical_normalization\tagtask	is\tagSENT_CONTENT	sorting\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	features\tagSENT_CONTENT	first\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	calculating\tagSENT_CONTENT	union\tagSENT_CONTENT	and\tagSENT_CONTENT	intersection\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	O(l*log(l\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_END	Candidate\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	tweet\tagSENT_CONTENT	T\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	token\tagSENT_CONTENT	ti\tagSENT_CONTENT	and\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	's\tagSENT_CONTENT	candidate\tagSENT_CONTENT	c\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	classifier\tagSENT_CONTENT	that\tagSENT_CONTENT	predicts\tagSENT_CONTENT	whether\tagSENT_CONTENT	c\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	canonical\tagSENT_CONTENT	form\tagSENT_CONTENT	oft\tagSENT_CONTENT	i\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	tweet\tagSENT_CONTENT	T\tagSENT_CONTENT	and\tagSENT_CONTENT	outputs\tagSENT_CONTENT	a\tagSENT_CONTENT	confidence\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagmetric	prediction\tagmetric	.\tagSENT_END	(\tagSENT_START	percentage\tagSENT_CONTENT	of\tagSENT_CONTENT	times\tagSENT_CONTENT	ti\tagSENT_CONTENT	is\tagSENT_CONTENT	normalized\tagSENT_CONTENT	to\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	them\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	lexical_normalization\tagtask	We\tagSENT_START	calculate\tagSENT_CONTENT	the\tagSENT_CONTENT	string\tagSENT_CONTENT	similarity\tagSENT_CONTENT	score\tagSENT_CONTENT	(\tagSENT_CONTENT	Jaccard\tagSENT_CONTENT	Index\tagSENT_CONTENT	of\tagSENT_CONTENT	feature\tagSENT_CONTENT	sets\tagSENT_CONTENT	)\tagSENT_CONTENT	between\tagSENT_CONTENT	token\tagSENT_CONTENT	ti\tagSENT_CONTENT	and\tagSENT_CONTENT	candidate\tagSENT_CONTENT	c\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	One\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	motivations\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	facilitate\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	partof\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	features\tagSENT_CONTENT	use\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	The\tagSENT_START	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	classification\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagmetric	4\tagSENT_CONTENT	.\tagSENT_END	Resources\tagSECTITLE_START	Employed\tagSECTITLE_END	We\tagSENT_START	implemented\tagSENT_CONTENT	two\tagSENT_CONTENT	modes\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	:\tagSENT_CONTENT	a\tagSENT_CONTENT	constrained\tagSENT_CONTENT	mode\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	unconstrained\tagSENT_CONTENT	mode\tagSENT_CONTENT	.\tagSENT_END	Settings\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	It\tagSENT_START	causes\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	dictionaries\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	support\tagSENT_CONTENT	and\tagSENT_CONTENT	confidence\tagSENT_CONTENT	features\tagSENT_CONTENT	leak\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	We\tagSENT_START	used\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	lexical_normalization\tagtask	(\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Precision\tagSECTITLE_END	The\tagSENT_START	much\tagSENT_CONTENT	larger\tagSENT_CONTENT	canonical\tagSENT_CONTENT	form\tagSENT_CONTENT	dictionary\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	unconstrained\tagSENT_CONTENT	mode\tagSENT_CONTENT	contains\tagSENT_CONTENT	many\tagSENT_CONTENT	rarely\tagSENT_CONTENT	used\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	having\tagSENT_CONTENT	such\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	candidates\tagSENT_CONTENT	causes\tagSENT_CONTENT	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	component\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	more\tagSENT_CONTENT	conservative\tagSENT_CONTENT	in\tagSENT_CONTENT	selecting\tagSENT_CONTENT	candidates\tagSENT_CONTENT	other\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	tokens\tagSENT_CONTENT	(\tagSENT_CONTENT	higher\tagmetric	precision\tagmetric	and\tagSENT_CONTENT	lower\tagmetric	recall\tagmetric	)\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	smaller\tagSENT_CONTENT	dictionary\tagSENT_CONTENT	of\tagSENT_CONTENT	most\tagSENT_CONTENT	frequently\tagSENT_CONTENT	used\tagSENT_CONTENT	words\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	dictionary\tagSENT_CONTENT	or\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	dictionary\tagSENT_CONTENT	with\tagSENT_CONTENT	word\tagSENT_CONTENT	frequency\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Even\tagSENT_START	if\tagSENT_CONTENT	we\tagSENT_CONTENT	exclude\tagSENT_CONTENT	the\tagSENT_CONTENT	rare\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	mere\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	candidates\tagSENT_CONTENT	per\tagSENT_CONTENT	token\tagSENT_CONTENT	makes\tagSENT_CONTENT	selecting\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	candidate\tagSENT_CONTENT	more\tagmetric	challenging\tagmetric	.\tagSENT_END	lexical_normalization\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	include\tagSENT_CONTENT	more\tagSENT_CONTENT	context\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	candidate\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	binary\tagSENT_CONTENT	class\tagSENT_CONTENT	labeling\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	component\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	differentiate\tagSENT_CONTENT	lexical_normalization\tagtask	without\tagSENT_CONTENT	change\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	"\tagSENT_CONTENT	car\tagSENT_CONTENT	"\tagSENT_CONTENT	à\tagSENT_CONTENT	"\tagSENT_CONTENT	car\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	normalization\tagSENT_CONTENT	with\tagSENT_CONTENT	change\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	"\tagSENT_CONTENT	ur\tagSENT_CONTENT	"\tagSENT_CONTENT	à\tagSENT_CONTENT	"\tagSENT_CONTENT	your\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	English\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	constrained\tagSENT_CONTENT	mode\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	unconstrained\tagSENT_CONTENT	mode\tagSENT_CONTENT	.\tagSENT_END	
1804.09849	title\tagSECTITLE_END	The\tagSENT_START	Best\tagSENT_CONTENT	of\tagSENT_CONTENT	Both\tagSENT_CONTENT	Worlds\tagSENT_CONTENT	:\tagSENT_CONTENT	Combining\tagSENT_CONTENT	Recent\tagSENT_CONTENT	Advances\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	abstract\tagSECTITLE_END	The\tagSENT_START	past\tagSENT_CONTENT	year\tagSENT_CONTENT	has\tagSENT_CONTENT	witnessed\tagSENT_CONTENT	rapid\tagSENT_CONTENT	advances\tagSENT_CONTENT	in\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	)\tagSENT_CONTENT	modeling\tagSENT_CONTENT	for\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	MT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	emergence\tagSENT_CONTENT	of\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	revolutionized\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	MT\tagSENT_CONTENT	by\tagSENT_CONTENT	replacing\tagSENT_CONTENT	traditional\tagSENT_CONTENT	phrasebased\tagSENT_CONTENT	approaches\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	RNMT\tagSENT_CONTENT	,\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	NMT\tagSENT_CONTENT	have\tagSENT_CONTENT	recently\tagSENT_CONTENT	drawn\tagSENT_CONTENT	machine_translation\tagtask	due\tagSENT_CONTENT	to\tagSENT_CONTENT	their\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	fully\tagSENT_CONTENT	parallelize\tagSENT_CONTENT	training\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	modern\tagSENT_CONTENT	fast\tagSENT_CONTENT	computing\tagSENT_CONTENT	devices\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	recently\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	solely\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	selfattention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	and\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	connections\tagSENT_CONTENT	,\tagSENT_CONTENT	has\tagSENT_CONTENT	further\tagSENT_CONTENT	advanced\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	NMT\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	machine_translation\tagtask	and\tagSENT_CONTENT	speed\tagSENT_CONTENT	of\tagSENT_CONTENT	convergence\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	doing\tagSENT_CONTENT	so\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	come\tagSENT_CONTENT	up\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	RNMT\tagSENT_CONTENT	,\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	all\tagSENT_CONTENT	individual\tagSENT_CONTENT	architectures\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	setup\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	ablation\tagSENT_CONTENT	studies\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	quantify\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	modeling\tagSENT_CONTENT	improvements\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	machine_translation\tagtask	and\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	optimization\tagSENT_CONTENT	techniques\tagSENT_CONTENT	(\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	synchronous\tagSENT_CONTENT	replica\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	labelsmoothing\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	quickly\tagSENT_CONTENT	note\tagSENT_CONTENT	two\tagSENT_CONTENT	prior\tagSENT_CONTENT	works\tagSENT_CONTENT	that\tagSENT_CONTENT	provided\tagSENT_CONTENT	machine_translation\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	NMT\tagSENT_CONTENT	architectures\tagSENT_CONTENT	(\tagSENT_CONTENT	specifically\tagSENT_CONTENT	RNMT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	briefly\tagSENT_CONTENT	discuss\tagSENT_CONTENT	the\tagSENT_CONTENT	commmonly\tagSENT_CONTENT	used\tagSENT_CONTENT	NMT\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	RNN\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	NMT\tagSECTITLE_CONTENT	Models\tagSECTITLE_CONTENT	-RNMT\tagSECTITLE_END	Convolutional\tagSECTITLE_START	NMT\tagSECTITLE_CONTENT	Models\tagSECTITLE_CONTENT	-ConvS2S\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	most\tagSENT_CONTENT	successful\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	tosequence\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	decoder\tagSENT_CONTENT	are\tagSENT_CONTENT	constructed\tagSENT_CONTENT	by\tagSENT_CONTENT	stacking\tagSENT_CONTENT	multiple\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	layer\tagSENT_CONTENT	contains\tagSENT_CONTENT	1-dimensional\tagSENT_CONTENT	convolutions\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	gated\tagSENT_CONTENT	linear\tagSENT_CONTENT	units\tagSENT_CONTENT	(\tagSENT_CONTENT	GLU\tagmetric	)\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Conditional\tagSECTITLE_START	Transformation\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	NMT\tagSECTITLE_CONTENT	Models\tagSECTITLE_CONTENT	-Transformer\tagSECTITLE_END	(\tagSENT_START	2\tagSENT_CONTENT	)\tagSENT_CONTENT	To\tagSENT_CONTENT	address\tagSENT_CONTENT	the\tagSENT_CONTENT	limited\tagSENT_CONTENT	context\tagSENT_CONTENT	problem\tagSENT_CONTENT	(\tagSENT_CONTENT	limited\tagSENT_CONTENT	receptive\tagSENT_CONTENT	field\tagSENT_CONTENT	)\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	ConvS2S\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	model\tagSENT_CONTENT	makes\tagSENT_CONTENT	pervasive\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	selfattention\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	machine_translation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	layer\tagSENT_CONTENT	has\tagSENT_CONTENT	access\tagSENT_CONTENT	to\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	all\tagSENT_CONTENT	other\tagSENT_CONTENT	positions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	two\tagSENT_CONTENT	details\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	very\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	performance\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Each\tagSENT_CONTENT	sublayer\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	crossattention\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	)\tagSENT_CONTENT	follows\tagSENT_CONTENT	a\tagSENT_CONTENT	strict\tagSENT_CONTENT	computation\tagSENT_CONTENT	sequence\tagSENT_CONTENT	:\tagSENT_END	A\tagSECTITLE_START	Theory\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Characterization\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	NMT\tagSECTITLE_CONTENT	Architectures\tagSECTITLE_END	Experiment\tagSECTITLE_START	Setup\tagSECTITLE_END	machine_translation\tagtask	of\tagSENT_CONTENT	newstest\tagSENT_CONTENT	2012\tagSENT_CONTENT	and\tagSENT_CONTENT	newstest\tagSENT_CONTENT	2013\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	validation\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	every\tagSENT_CONTENT	30\tagSENT_CONTENT	minutes\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dev\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	RNMT+\tagSECTITLE_END	Model\tagSECTITLE_START	Architecture\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	RNMT+\tagSECTITLE_END	Our\tagSENT_START	empirical\tagSENT_CONTENT	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	machine_translation\tagtask	greatly\tagSENT_CONTENT	stabilizes\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Label\tagSENT_START	smoothing\tagSENT_CONTENT	was\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	positive\tagSENT_CONTENT	impact\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	and\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	In\tagSENT_START	machine_translation\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	asynchronous\tagSENT_CONTENT	training\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	GNMT\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	synchronous\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	discard\tagSENT_CONTENT	a\tagSENT_CONTENT	training\tagSENT_CONTENT	step\tagSENT_CONTENT	completely\tagSENT_CONTENT	if\tagSENT_CONTENT	an\tagSENT_CONTENT	anomaly\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	gradient\tagSENT_CONTENT	norm\tagSENT_CONTENT	value\tagSENT_CONTENT	is\tagSENT_CONTENT	detected\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	usually\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	an\tagSENT_CONTENT	imminent\tagSENT_CONTENT	gradient\tagSENT_CONTENT	explosion\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Analysis\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Comparison\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	with\tagSENT_CONTENT	ConvS2S\tagSENT_CONTENT	and\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	models\tagSENT_CONTENT	were\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	machine_translation\tagtask	contained\tagSENT_CONTENT	4096\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	4096\tagSENT_CONTENT	source\tagSENT_CONTENT	sequences\tagSENT_CONTENT	and\tagSENT_CONTENT	4096\tagSENT_CONTENT	target\tagSENT_CONTENT	sequences\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	The\tagSENT_START	numbers\tagSENT_CONTENT	before\tagSENT_CONTENT	and\tagSENT_CONTENT	after\tagSENT_CONTENT	'\tagSENT_CONTENT	±\tagSENT_CONTENT	'\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	and\tagSENT_CONTENT	standard\tagSENT_CONTENT	deviation\tagSENT_CONTENT	of\tagSENT_CONTENT	test\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	score\tagSENT_CONTENT	over\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	3\tagSENT_START	)\tagSENT_CONTENT	We\tagSENT_CONTENT	avoided\tagSENT_CONTENT	any\tagSENT_CONTENT	manual\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	Moses\tagSENT_CONTENT	replace-unicode-punctuation.perl\tagSENT_CONTENT	or\tagSENT_CONTENT	output\tagSENT_CONTENT	tokenization\tagSENT_CONTENT	using\tagSENT_CONTENT	Moses\tagSENT_CONTENT	tokenizer.perl\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	rule\tagSENT_CONTENT	out\tagSENT_CONTENT	its\tagSENT_CONTENT	effect\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	(\tagSENT_CONTENT	Vaswani\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	reported\tagSENT_CONTENT	BLEU\tagmetric	scores\tagmetric	are\tagSENT_CONTENT	calculated\tagSENT_CONTENT	using\tagSENT_CONTENT	mteval-v13a.pl\tagSENT_CONTENT	from\tagSENT_CONTENT	Moses\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	tokenizes\tagSENT_CONTENT	its\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Ablation\tagSECTITLE_START	Experiments\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	four\tagSENT_CONTENT	main\tagSENT_CONTENT	techniques\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	Big\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	From\tagSENT_START	 \tagSENT_CONTENT	•\tagSENT_CONTENT	Label\tagSENT_CONTENT	Smoothing\tagSENT_CONTENT	We\tagSENT_CONTENT	observed\tagSENT_CONTENT	that\tagSENT_CONTENT	label\tagSENT_CONTENT	smoothing\tagSENT_CONTENT	improves\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	average\tagSENT_CONTENT	increase\tagSENT_CONTENT	of\tagSENT_CONTENT	0.7\tagmetric	BLEU\tagmetric	for\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	and\tagSENT_CONTENT	0.2\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	for\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	Big\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	head\tagSENT_CONTENT	Attention\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	head\tagSENT_CONTENT	attention\tagSENT_CONTENT	contributes\tagSENT_CONTENT	significantly\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	average\tagSENT_CONTENT	increase\tagSENT_CONTENT	of\tagSENT_CONTENT	0.6\tagmetric	BLEU\tagmetric	for\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	and\tagSENT_CONTENT	0.9\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	for\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	Big\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Layer\tagSENT_CONTENT	Normalization\tagSENT_CONTENT	Layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	is\tagSENT_CONTENT	most\tagSENT_CONTENT	critical\tagSENT_CONTENT	to\tagSENT_CONTENT	stabilize\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	either\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	when\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	by\tagSENT_CONTENT	design\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	remove\tagSENT_CONTENT	one\tagSENT_CONTENT	technique\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	ablation\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	were\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	quantify\tagSENT_CONTENT	machine_translation\tagtask	helped\tagSENT_CONTENT	in\tagSENT_CONTENT	either\tagSENT_CONTENT	case\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Synchronous\tagSENT_CONTENT	training\tagSENT_CONTENT	Removing\tagSENT_CONTENT	machine_translation\tagtask	has\tagSENT_CONTENT	different\tagSENT_CONTENT	effects\tagSENT_CONTENT	on\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	and\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	.\tagSENT_END	Hybrid\tagSECTITLE_START	NMT\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	explore\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	architectures\tagSENT_CONTENT	that\tagSENT_CONTENT	shed\tagSENT_CONTENT	some\tagSENT_CONTENT	light\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	salient\tagSENT_CONTENT	behavior\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	model\tagSENT_CONTENT	family\tagSENT_CONTENT	.\tagSENT_END	Assessing\tagSECTITLE_START	Individual\tagSECTITLE_CONTENT	Encoders\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Decoders\tagSECTITLE_END	In\tagSENT_START	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	architecture\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	role\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	best\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	a\tagSENT_CONTENT	decoder\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	process\tagSENT_CONTENT	and\tagSENT_CONTENT	interpret\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	track\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	target\tagSENT_CONTENT	history\tagSENT_CONTENT	.\tagSENT_END	Encoder\tagSECTITLE_END	From\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	clear\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	encoding\tagSENT_CONTENT	or\tagSENT_CONTENT	machine_translation\tagtask	than\tagSENT_CONTENT	the\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	encoder\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	decoding\tagSENT_CONTENT	or\tagSENT_CONTENT	conditional\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	,\tagSENT_CONTENT	confirming\tagSENT_CONTENT	our\tagSENT_CONTENT	intuition\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	stateful\tagSENT_CONTENT	decoder\tagSENT_CONTENT	is\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	for\tagSENT_CONTENT	conditional\tagSENT_CONTENT	language\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	Assessing\tagSECTITLE_START	Encoder\tagSECTITLE_CONTENT	Combinations\tagSECTITLE_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	transformer\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	layers\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	encoder\tagSENT_CONTENT	block\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	even\tagSENT_CONTENT	richer\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	machine_translation\tagtask	if\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	is\tagSENT_CONTENT	augmented\tagSENT_CONTENT	with\tagSENT_CONTENT	sequential\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	2\tagSENT_CONTENT	)\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	Column\tagSENT_CONTENT	Encoder\tagSENT_CONTENT	:\tagSENT_CONTENT	As\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	column\tagSENT_CONTENT	encoder\tagSENT_CONTENT	merges\tagSENT_CONTENT	the\tagSENT_CONTENT	outputs\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	independent\tagSENT_CONTENT	encoders\tagSENT_CONTENT	into\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	column\tagSENT_CONTENT	encoder\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	RNMT+\tagSENT_CONTENT	decoder\tagSENT_CONTENT	achieves\tagSENT_CONTENT	better\tagSENT_CONTENT	results\tagSENT_CONTENT	than\tagSENT_CONTENT	machine_translation\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	RNMT\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	WMT'14\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Model\tagSECTITLE_END	BLEU\tagmetric	Trans\tagmetric	.\tagSENT_END	How\tagSENT_START	transferable\tagSENT_CONTENT	are\tagSENT_CONTENT	machine_translation\tagtask	learned\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	architectures\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	?\tagSENT_END	A.1\tagSECTITLE_START	ConvS2S\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	the\tagSENT_CONTENT	ConvS2S\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	32\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	A.2\tagSECTITLE_START	Transformer\tagSECTITLE_END	Transformer\tagSENT_START	base\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	model\tagSENT_CONTENT	dimension\tagSENT_CONTENT	512\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	2048\tagSENT_CONTENT	and\tagSENT_CONTENT	8\tagSENT_CONTENT	attention\tagSENT_CONTENT	heads\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	train\tagSENT_CONTENT	both\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	base\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	big\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	16\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	A.3\tagSECTITLE_START	RNMT+\tagSECTITLE_END	RNMT+\tagSENT_START	models\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	32\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	A.4\tagSECTITLE_START	Encoder\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_CONTENT	Hybrids\tagSECTITLE_END	Both\tagSENT_START	hybrid\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	32\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	A.5\tagSECTITLE_START	Cascaded\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_CONTENT	Hybrid\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	schedule\tagSENT_CONTENT	(\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	with\tagSENT_CONTENT	r\tagSENT_CONTENT	0\tagSENT_CONTENT	=\tagSENT_CONTENT	2.0\tagSENT_CONTENT	and\tagSENT_CONTENT	p\tagSENT_CONTENT	=\tagSENT_CONTENT	16000\tagSENT_CONTENT	and\tagSENT_CONTENT	train\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	32\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	A.6\tagSECTITLE_START	Multi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Column\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_CONTENT	Hybrid\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	machine_translation\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	mergeroperator\tagSENT_CONTENT	without\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	any\tagSENT_CONTENT	other\tagSENT_CONTENT	model\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	stick\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	simple\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	operation\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	mergeroperator\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	after\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	combined\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	projected\tagSENT_CONTENT	down\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	dimension\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	layer\tagSENT_CONTENT	-\tagSENT_CONTENT	normalized\tagSENT_CONTENT	affine\tagSENT_CONTENT	transformation\tagSENT_CONTENT	.\tagSENT_END	
1802.00923	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Human\tagSENT_START	face\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	face\tagSENT_CONTENT	communication\tagSENT_CONTENT	is\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	We\tagSENT_START	perform\tagSENT_CONTENT	extensive\tagSENT_CONTENT	comparisons\tagSENT_CONTENT	on\tagSENT_CONTENT	six\tagSENT_CONTENT	publicly\tagSENT_CONTENT	available\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	,\tagSENT_CONTENT	speaker\tagSENT_CONTENT	trait\tagSENT_CONTENT	recognition\tagSENT_CONTENT	and\tagSENT_CONTENT	emotion\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Humans\tagSENT_START	communicate\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	highly\tagSENT_CONTENT	complex\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Understanding\tagSENT_START	multimodal_sentiment_analysis\tagtask	is\tagSENT_CONTENT	natural\tagSENT_CONTENT	for\tagSENT_CONTENT	humans\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	it\tagSENT_CONTENT	subconsciously\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	cerebrum\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	brains\tagSENT_CONTENT	everyday\tagSENT_CONTENT	.\tagSENT_END	Cross\tagSENT_START	-\tagSENT_CONTENT	view\tagSENT_CONTENT	dynamics\tagSENT_CONTENT	are\tagSENT_CONTENT	discovered\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagmetric	recurrence\tagmetric	time\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	neural\tagSENT_CONTENT	component\tagSENT_CONTENT	called\tagSENT_CONTENT	the\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	Block\tagSENT_CONTENT	(\tagSENT_CONTENT	MAB\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	MAB\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	simultaneously\tagSENT_CONTENT	finding\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	in\tagSENT_CONTENT	each\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	timestep\tagSENT_CONTENT	.\tagSENT_END	-our\tagSENT_START	LSTHM\tagSENT_CONTENT	-and\tagSENT_CONTENT	are\tagSENT_CONTENT	connected\tagSENT_CONTENT	together\tagSENT_CONTENT	using\tagSENT_CONTENT	neural\tagSENT_CONTENT	links\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	(\tagSENT_CONTENT	)\tagSENT_END	We\tagSENT_START	perform\tagSENT_CONTENT	extensive\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	16\tagSENT_CONTENT	different\tagSENT_CONTENT	attributes\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	human\tagSENT_CONTENT	communication\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Approaches\tagSENT_START	have\tagSENT_CONTENT	used\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	modeling\tagSENT_CONTENT	view\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	and\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	view\tagSENT_CONTENT	dynamics\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	an\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	shortcoming\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	using\tagSENT_CONTENT	the\tagSENT_CONTENT	vision\tagSENT_CONTENT	modality\tagSENT_CONTENT	and\tagSENT_CONTENT	predicts\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	,\tagSENT_CONTENT	late\tagSENT_CONTENT	fusion\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	no\tagSENT_CONTENT	access\tagSENT_CONTENT	to\tagSENT_CONTENT	whether\tagSENT_CONTENT	this\tagSENT_CONTENT	negative\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	was\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	frowning\tagSENT_CONTENT	face\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	disgusted\tagSENT_CONTENT	face\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSENT_START	-\tagSENT_CONTENT	view\tagSENT_CONTENT	Learning\tagSENT_CONTENT	:\tagSENT_CONTENT	Extensions\tagSENT_CONTENT	of\tagSENT_CONTENT	Hidden\tagSENT_CONTENT	Markov\tagSENT_CONTENT	Models\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	Hidden\tagSENT_CONTENT	Conditional\tagSENT_CONTENT	Random\tagSENT_CONTENT	Fields\tagSENT_CONTENT	(\tagSENT_CONTENT	 \tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	learning\tagSENT_CONTENT	from\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	(\tagSENT_CONTENT	modalities\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	MARN\tagSECTITLE_START	Model\tagSECTITLE_END	MARN\tagSENT_START	has\tagSENT_CONTENT	two\tagSENT_CONTENT	key\tagSENT_CONTENT	components\tagSENT_CONTENT	:\tagSENT_CONTENT	Long\tagSENT_CONTENT	-\tagSENT_CONTENT	short\tagSENT_CONTENT	Term\tagSENT_CONTENT	Hybrid\tagSENT_CONTENT	Memory\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	LSTHM\tagSENT_START	is\tagSENT_CONTENT	intrinsically\tagSENT_CONTENT	designed\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	and\tagSENT_CONTENT	each\tagSENT_CONTENT	modality\tagSENT_CONTENT	is\tagSENT_CONTENT	assigned\tagSENT_CONTENT	a\tagSENT_CONTENT	unique\tagSENT_CONTENT	LSTHM\tagSENT_CONTENT	.\tagSENT_END	Long\tagSECTITLE_START	-\tagSECTITLE_CONTENT	short\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Hybrid\tagSECTITLE_CONTENT	Memory\tagSECTITLE_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	attention\tagSECTITLE_CONTENT	Block\tagSECTITLE_END	Experimental\tagSECTITLE_START	Methodology\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	MARN\tagSENT_CONTENT	's\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	human\tagSENT_CONTENT	communication\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	and\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Each\tagSENT_START	video\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	labeled\tagSENT_CONTENT	to\tagSENT_CONTENT	display\tagSENT_CONTENT	positive\tagSENT_CONTENT	,\tagSENT_CONTENT	negative\tagSENT_CONTENT	or\tagSENT_CONTENT	neutral\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	.\tagSENT_END	Multimodal\tagSECTITLE_START	Speaker\tagSECTITLE_CONTENT	Trait\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_END	Multimodal\tagSECTITLE_START	Computational\tagSECTITLE_CONTENT	Descriptors\tagSECTITLE_END	Comparison\tagSECTITLE_START	Metrics\tagSECTITLE_END	For\tagSENT_START	binary\tagSENT_CONTENT	classification\tagSENT_CONTENT	and\tagSENT_CONTENT	multiclass\tagSENT_CONTENT	classification\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	accuracy\tagmetric	AC\tagmetric	where\tagSENT_CONTENT	C\tagSENT_CONTENT	denotes\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	classes\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	Baseline\tagSECTITLE_START	Models\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	MARN\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	,\tagSENT_CONTENT	speaker\tagSENT_CONTENT	trait\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	emotion\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	best\tagSENT_CONTENT	performing\tagSENT_CONTENT	early\tagSENT_CONTENT	fusion\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	reported\tagSENT_CONTENT	as\tagSENT_CONTENT	EF\tagSENT_CONTENT	-\tagSENT_CONTENT	HCRF\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	view\tagSENT_CONTENT	:\tagSENT_CONTENT	Sentiment\tagSENT_CONTENT	prediction\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	CMU\tagSENT_CONTENT	-\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	using\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	human\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	vs\tagSENT_CONTENT	-\tagSENT_CONTENT	rest\tagSENT_CONTENT	classification\tagSENT_CONTENT	/\tagSENT_CONTENT	regression\tagSENT_CONTENT	.\tagSENT_END	ICT\tagSECTITLE_START	-\tagSECTITLE_CONTENT	MMMO\tagSECTITLE_CONTENT	Binary\tagSECTITLE_CONTENT	YouTube\tagSECTITLE_CONTENT	Multiclass\tagSECTITLE_CONTENT	MOUD\tagSECTITLE_CONTENT	Binary\tagSECTITLE_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	CMU\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	MOSI\tagSECTITLE_CONTENT	dataset\tagSECTITLE_END	This\tagSENT_START	highlights\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	capability\tagSENT_CONTENT	in\tagSENT_CONTENT	understanding\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	of\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	ICT\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	MMMO\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	YouTube\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	MOUD\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	To\tagSENT_START	assess\tagSENT_CONTENT	the\tagSENT_CONTENT	generalization\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	MARN\tagSENT_CONTENT	to\tagSENT_CONTENT	speakers\tagSENT_CONTENT	communicating\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	with\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	approaches\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	on\tagSENT_CONTENT	MOUD\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	opinion\tagSENT_CONTENT	utterance\tagSENT_CONTENT	video\tagSENT_CONTENT	clips\tagSENT_CONTENT	in\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	POM\tagSECTITLE_CONTENT	Dataset\tagSECTITLE_END	We\tagSENT_START	experiment\tagSENT_CONTENT	on\tagSENT_CONTENT	speaker\tagSENT_CONTENT	traits\tagSENT_CONTENT	recognition\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	IEMOCAP\tagSECTITLE_CONTENT	Dataset\tagSECTITLE_END	Our\tagSENT_START	results\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	on\tagSENT_CONTENT	IEMO\tagSENT_CONTENT	-\tagSENT_CONTENT	CAP\tagSENT_CONTENT	dataset\tagSENT_CONTENT	are\tagSENT_CONTENT	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Properties\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Attentions\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	the\tagSENT_CONTENT	MARN\tagSENT_CONTENT	with\tagSENT_CONTENT	only\tagSENT_CONTENT	one\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	like\tagSENT_CONTENT	conventional\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	under\tagSENT_CONTENT	-\tagSENT_CONTENT	performs\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	This\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	MARN\tagSENT_CONTENT	with\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	is\tagSENT_CONTENT	not\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	higher\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	but\tagSENT_CONTENT	rather\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	modeling\tagSENT_CONTENT	of\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	view\tagSENT_CONTENT	dynamics\tagSENT_CONTENT	.\tagSENT_END	Visualization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Attentions\tagSECTITLE_END	We\tagSENT_START	suspect\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	less\tagSENT_CONTENT	drastic\tagSENT_CONTENT	the\tagSENT_CONTENT	change\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	dimension\tagSENT_CONTENT	overtime\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	higher\tagSENT_CONTENT	the\tagSENT_CONTENT	chances\tagSENT_CONTENT	of\tagSENT_CONTENT	that\tagSENT_CONTENT	dimension\tagSENT_CONTENT	being\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	modeled\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	approach\tagSENT_CONTENT	called\tagSENT_CONTENT	the\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Network\tagSENT_CONTENT	(\tagSENT_CONTENT	MARN\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Various\tagSENT_START	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	view\tagSENT_CONTENT	dynamics\tagSENT_CONTENT	are\tagSENT_CONTENT	identified\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	Block\tagSENT_CONTENT	(\tagSENT_CONTENT	MAB\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	outputs\tagSENT_CONTENT	multimodal_sentiment_analysis\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	memory\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTHM\tagSENT_CONTENT	.\tagSENT_END	
1707.03058	title\tagSECTITLE_END	Improving\tagSENT_START	constituency_parsing\tagtask	by\tagSENT_CONTENT	Disentangling\tagSENT_CONTENT	Model\tagSENT_CONTENT	Combination\tagSENT_CONTENT	and\tagSENT_CONTENT	Reranking\tagSENT_CONTENT	Effects\tagSENT_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Recent\tagSENT_START	work\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	)\tagSENT_CONTENT	has\tagSENT_CONTENT	found\tagSENT_CONTENT	multiple\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	generative\tagSENT_CONTENT	scoring\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	inference\tagSENT_CONTENT	is\tagSENT_CONTENT	complex\tagSENT_CONTENT	outperform\tagSENT_CONTENT	base\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	inference\tagSENT_CONTENT	is\tagSENT_CONTENT	simpler\tagSENT_CONTENT	.\tagSENT_END	Let\tagSENT_START	Abe\tagSENT_CONTENT	a\tagSENT_CONTENT	parser\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	want\tagSENT_CONTENT	to\tagSENT_CONTENT	parse\tagSENT_CONTENT	with\tagSENT_CONTENT	(\tagSENT_CONTENT	here\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generative\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	let\tagSENT_CONTENT	B\tagSENT_CONTENT	be\tagSENT_CONTENT	abase\tagSENT_CONTENT	parser\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	to\tagSENT_CONTENT	propose\tagSENT_CONTENT	constituency_parsing\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	scored\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	less\tagSENT_CONTENT	-\tagSENT_CONTENT	tractable\tagSENT_CONTENT	parser\tagSENT_CONTENT	A.\tagSENT_CONTENT	We\tagSENT_CONTENT	denote\tagSENT_CONTENT	this\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	scoring\tagSENT_CONTENT	setup\tagSENT_CONTENT	by\tagSENT_CONTENT	B\tagSENT_END	A\tagSENT_START	are\tagSENT_CONTENT	simply\tagSENT_CONTENT	superior\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	base\tagSENT_CONTENT	models\tagSENT_CONTENT	B\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	Decoding\tagSECTITLE_START	in\tagSECTITLE_CONTENT	generative\tagSECTITLE_CONTENT	neural\tagSECTITLE_CONTENT	models\tagSECTITLE_END	Action\tagSECTITLE_START	-\tagSECTITLE_CONTENT	synchronous\tagSECTITLE_CONTENT	beam\tagSECTITLE_CONTENT	search\tagSECTITLE_END	Past\tagSENT_START	work\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	has\tagSENT_CONTENT	shown\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	beam\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	even\tagSENT_CONTENT	greedy\tagSENT_CONTENT	search\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	RD\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Qualitatively\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	procedure\tagSENT_CONTENT	prefers\tagSENT_CONTENT	to\tagSENT_CONTENT	open\tagSENT_CONTENT	constituency_parsing\tagtask	repeatedly\tagSENT_CONTENT	up\tagSENT_CONTENT	until\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	number\tagSENT_CONTENT	allowed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	synchronous\tagSECTITLE_CONTENT	beam\tagSECTITLE_CONTENT	search\tagSECTITLE_END	:\tagmetric	F1\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	synchronous\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	when\tagSENT_CONTENT	searching\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	generative\tagSENT_CONTENT	(\tagSENT_CONTENT	RG\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_END	=\tagSENT_START	a\tagSENT_CONTENT	+\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	size\tagSENT_CONTENT	K\tagSENT_CONTENT	a\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	action\tagSENT_CONTENT	beam\tagSENT_CONTENT	size\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	from\tagSENT_CONTENT	there\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	F1\tagmetric	for\tagSENT_CONTENT	decoding\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	generative\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	scoring\tagSENT_CONTENT	parse\tagSENT_END	Experiments\tagSECTITLE_END	In\tagSENT_START	each\tagSENT_CONTENT	experiment\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	by\tagSENT_CONTENT	performing\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	in\tagSENT_CONTENT	one\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	parsers\tagSENT_CONTENT	.\tagSENT_END	Augmenting\tagSECTITLE_START	the\tagSECTITLE_CONTENT	candidate\tagSECTITLE_CONTENT	set\tagSECTITLE_END	→\tagSENT_START	A\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	search\tagSENT_CONTENT	in\tagSENT_CONTENT	B\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	:\tagSENT_CONTENT	Development\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	section\tagSENT_CONTENT	22\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	PTB\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	various\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	candidates\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	score\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Score\tagSECTITLE_START	combination\tagSECTITLE_END	To\tagSENT_START	do\tagSENT_CONTENT	so\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	score\tagSENT_CONTENT	each\tagSENT_CONTENT	parse\tagSENT_CONTENT	by\tagSENT_CONTENT	taking\tagSENT_CONTENT	a\tagSENT_CONTENT	weighted\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	assigned\tagSENT_CONTENT	by\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	interpolation\tagSENT_CONTENT	parameter\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	tune\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	F1\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Strengthening\tagSECTITLE_START	model\tagSECTITLE_CONTENT	combination\tagSECTITLE_END	Model\tagSECTITLE_END	PTB\tagSECTITLE_START	+\tagSECTITLE_CONTENT	S\tagSECTITLE_END	
1709.00103	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	release\tagSENT_CONTENT	WikiSQL\tagdataset	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	80654\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	examples\tagSENT_CONTENT	of\tagSENT_CONTENT	questions\tagSENT_CONTENT	and\tagSENT_CONTENT	sql_parsing\tagtask	distributed\tagSENT_CONTENT	across\tagSENT_CONTENT	24241\tagSENT_CONTENT	tables\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	magnitude\tagSENT_CONTENT	larger\tagSENT_CONTENT	than\tagSENT_CONTENT	comparable\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	applying\tagSENT_CONTENT	policy\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	query\tagSENT_CONTENT	execution\tagSENT_CONTENT	environment\tagSENT_CONTENT	to\tagSENT_CONTENT	WikiSQL\tagdataset	,\tagSENT_CONTENT	Seq2SQL\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	improving\tagSENT_CONTENT	execution\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	from\tagSENT_CONTENT	35.9\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	59.4\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	logical\tagSENT_CONTENT	form\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	from\tagSENT_CONTENT	23.4\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	48.3\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	We\tagSENT_START	investigate\tagSENT_CONTENT	one\tagSENT_CONTENT	particular\tagSENT_CONTENT	aspect\tagSENT_CONTENT	of\tagSENT_CONTENT	NLI\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	relational\tagSENT_CONTENT	databases\tagSENT_CONTENT	:\tagSENT_CONTENT	translating\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	to\tagSENT_CONTENT	sql_parsing\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	Seq2SQL\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	translating\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	to\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	sql_parsing\tagtask	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	release\tagSENT_CONTENT	WikiSQL\tagdataset	,\tagSENT_CONTENT	a\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	80654\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	,\tagSENT_CONTENT	sql_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sql_parsing\tagtask	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	24241\tagSENT_CONTENT	HTML\tagSENT_CONTENT	tables\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	WikiSQL\tagdataset	,\tagSENT_CONTENT	Seq2SQL\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	a\tagSENT_CONTENT	previously\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	Dong\tagSENT_CONTENT	&\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	obtains\tagSENT_CONTENT	35.9\tagSENT_CONTENT	%\tagSENT_CONTENT	execution\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	augmented\tagSENT_CONTENT	pointer\tagSENT_CONTENT	network\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	obtains\tagSENT_CONTENT	53.3\tagSENT_CONTENT	%\tagSENT_CONTENT	execution\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	leveraging\tagSENT_CONTENT	the\tagSENT_CONTENT	inherent\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	sql_parsing\tagtask	and\tagSENT_CONTENT	applying\tagSENT_CONTENT	policy\tagSENT_CONTENT	gradient\tagSENT_CONTENT	methods\tagSENT_CONTENT	using\tagSENT_CONTENT	reward\tagSENT_CONTENT	signals\tagSENT_CONTENT	from\tagSENT_CONTENT	live\tagSENT_CONTENT	query\tagSENT_CONTENT	execution\tagSENT_CONTENT	,\tagSENT_CONTENT	Seq2SQL\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	WikiSQL\tagSENT_CONTENT	,\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	59.4\tagSENT_CONTENT	%\tagSENT_CONTENT	execution\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	.\tagSENT_END	MODEL\tagSECTITLE_END	AUGMENTED\tagSECTITLE_START	POINTER\tagSECTITLE_CONTENT	NETWORK\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	column\tagSENT_CONTENT	names\tagSENT_CONTENT	,\tagSENT_CONTENT	required\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	selection\tagSENT_CONTENT	column\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	condition\tagSENT_CONTENT	columns\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	required\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	conditions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	limited\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	of\tagSENT_CONTENT	sql_parsing\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	SELECT\tagSENT_CONTENT	,\tagSENT_CONTENT	COUNT\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	SEQ2SQL\tagSECTITLE_END	Instead\tagSENT_START	of\tagSENT_CONTENT	teacher\tagSENT_CONTENT	forcing\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagmetric	step\tagmetric	of\tagSENT_CONTENT	query\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	sample\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	distribution\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	token\tagSENT_CONTENT	.\tagSENT_END	Consequently\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	gradient\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	equally\tagSENT_CONTENT	weighted\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	gradients\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	cross\tagSENT_CONTENT	entropy\tagSENT_CONTENT	loss\tagSENT_CONTENT	in\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	SELECT\tagSENT_CONTENT	column\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	cross\tagSENT_CONTENT	entropy\tagSENT_CONTENT	loss\tagSENT_CONTENT	in\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	aggregation\tagSENT_CONTENT	operation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	from\tagSENT_CONTENT	sql_parsing\tagtask	.\tagSENT_END	3\tagSENT_START	WIKISQL\tagSENT_CONTENT	:\tagSENT_CONTENT	Distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	questions\tagSENT_CONTENT	in\tagSENT_CONTENT	WikiSQL\tagdataset	.\tagSENT_END	WikiSQL\tagdataset	is\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	questions\tagSENT_CONTENT	,\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	sql_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sql_parsing\tagtask	.\tagSENT_END	A\tagSENT_START	single\tagSENT_CONTENT	example\tagSENT_CONTENT	in\tagSENT_CONTENT	WikiSQL\tagdataset	,\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	contains\tagSENT_CONTENT	a\tagSENT_CONTENT	table\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	SQL\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	question\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	SQL\tagSENT_CONTENT	query\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	queries\tagSENT_CONTENT	in\tagSENT_CONTENT	sql_parsing\tagtask	over\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	tables\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	presents\tagSENT_CONTENT	an\tagSENT_CONTENT	unique\tagSENT_CONTENT	challenge\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	generalize\tagSENT_CONTENT	to\tagSENT_CONTENT	new\tagSENT_CONTENT	queries\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	to\tagSENT_CONTENT	new\tagSENT_CONTENT	table\tagSENT_CONTENT	schema\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	WikiSQL\tagdataset	contains\tagSENT_CONTENT	realistic\tagSENT_CONTENT	data\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	web\tagSENT_CONTENT	.\tagSENT_END	Section\tagSENT_START	A\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Appendix\tagSENT_CONTENT	contains\tagSENT_CONTENT	more\tagSENT_CONTENT	details\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	WikiSQL\tagdataset	.\tagSENT_END	Dataset\tagSECTITLE_END	The\tagSENT_START	tables\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	paraphrases\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sql_parsing\tagtask	are\tagSENT_CONTENT	randomly\tagSENT_CONTENT	slotted\tagSENT_CONTENT	into\tagSENT_CONTENT	train\tagSENT_CONTENT	,\tagSENT_CONTENT	dev\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	splits\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	table\tagSENT_CONTENT	is\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	exactly\tagSENT_CONTENT	one\tagSENT_CONTENT	split\tagSENT_CONTENT	.\tagSENT_END	EVALUATION\tagSECTITLE_END	One\tagSENT_START	downside\tagSENT_CONTENT	of\tagSENT_CONTENT	Acc\tagmetric	ex\tagmetric	is\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	a\tagSENT_CONTENT	SQL\tagSENT_CONTENT	query\tagSENT_CONTENT	that\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	but\tagSENT_CONTENT	nevertheless\tagSENT_CONTENT	obtains\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	result\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	Here\tagSENT_START	,\tagSENT_CONTENT	w\tagmetric	c\tagmetric	x\tagmetric	is\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	ngrams\tagSENT_CONTENT	in\tagSENT_CONTENT	x.\tagSENT_END	RESULT\tagSECTITLE_END	ANALYSIS\tagSECTITLE_END	Model\tagSECTITLE_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	sql_parsing\tagtask	.\tagSENT_END	In\tagSENT_START	sql_parsing\tagtask	for\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	are\tagSENT_CONTENT	parsed\tagSENT_CONTENT	into\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	executed\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graph\tagSENT_CONTENT	.\tagSENT_END	Other\tagSENT_START	works\tagSENT_CONTENT	in\tagSENT_CONTENT	sql_parsing\tagtask	on\tagSENT_CONTENT	learning\tagSENT_CONTENT	parsers\tagSENT_CONTENT	without\tagSENT_CONTENT	relying\tagSENT_CONTENT	on\tagSENT_CONTENT	annotated\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	by\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	conversational\tagSENT_CONTENT	logs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	demonstrations\tagSENT_CONTENT	,\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answer\tagSENT_CONTENT	pairs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	sql_parsing\tagtask	are\tagSENT_CONTENT	typically\tagSENT_CONTENT	constrained\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	schema\tagSENT_CONTENT	and\tagSENT_CONTENT	require\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	curated\tagSENT_CONTENT	grammars\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	well\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	require\tagSENT_CONTENT	access\tagmetric	to\tagSENT_CONTENT	table\tagSENT_CONTENT	content\tagSENT_CONTENT	,\tagSENT_CONTENT	conversion\tagSENT_CONTENT	of\tagSENT_CONTENT	table\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	graph\tagSENT_CONTENT	,\tagSENT_CONTENT	nor\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	/\tagSENT_CONTENT	grammar\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	provide\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	whereas\tagSENT_CONTENT	WikiSQL\tagdataset	does\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	WikiSQL\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	generating\tagSENT_CONTENT	sql_parsing\tagtask	for\tagSENT_CONTENT	questions\tagSENT_CONTENT	over\tagSENT_CONTENT	relational\tagSENT_CONTENT	database\tagSENT_CONTENT	tables\tagSENT_CONTENT	and\tagSENT_CONTENT	only\tagSENT_CONTENT	uses\tagSENT_CONTENT	table\tagSENT_CONTENT	content\tagSENT_CONTENT	during\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	prominent\tagSENT_CONTENT	works\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	interfaces\tagSENT_CONTENT	is\tagSENT_CONTENT	PRECISE\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	translates\tagSENT_CONTENT	questions\tagSENT_CONTENT	to\tagSENT_CONTENT	sql_parsing\tagtask	and\tagSENT_CONTENT	identifies\tagSENT_CONTENT	questions\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	confident\tagSENT_CONTENT	about\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	Seq2SQL\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	translating\tagSENT_CONTENT	questions\tagSENT_CONTENT	to\tagSENT_CONTENT	sql_parsing\tagtask	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	leverages\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	sql_parsing\tagtask	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	introduced\tagSENT_CONTENT	WikiSQL\tagdataset	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	questions\tagSENT_CONTENT	and\tagSENT_CONTENT	SQL\tagSENT_CONTENT	queries\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	magnitude\tagSENT_CONTENT	larger\tagSENT_CONTENT	than\tagSENT_CONTENT	comparable\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	Seq2SQL\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parser\tagSENT_CONTENT	on\tagSENT_CONTENT	WikiSQL\tagdataset	,\tagSENT_CONTENT	improving\tagSENT_CONTENT	execution\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	from\tagSENT_CONTENT	35.9\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	59.4\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	logical\tagSENT_CONTENT	form\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	from\tagSENT_CONTENT	23.4\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	48.3\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	COLLECTION\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	WIKISQL\tagSECTITLE_END	WikiSQL\tagdataset	is\tagSENT_CONTENT	collected\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	phases\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	verification\tagSENT_CONTENT	phase\tagSENT_CONTENT	.\tagSENT_END	WHERE\tagSENT_START	date\tagSENT_CONTENT	=\tagSENT_CONTENT	plymouth\tagSENT_CONTENT	9\tagSENT_CONTENT	AND\tagSENT_CONTENT	race\tagmetric	time=\tagSENT_CONTENT	february\tagSENT_CONTENT	9\tagSENT_CONTENT	G\tagSENT_CONTENT	SELECT\tagSENT_CONTENT	year\tagSENT_END	
1707.01476	title\tagSECTITLE_END	abstract\tagSECTITLE_END	relation_prediction\tagtask	for\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graphs\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	missing\tagSENT_CONTENT	relationships\tagSENT_CONTENT	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Specifically\tagSECTITLE_START	,\tagSECTITLE_CONTENT	our\tagSECTITLE_CONTENT	contributions\tagSECTITLE_CONTENT	are\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	follows\tagSECTITLE_CONTENT	:\tagSECTITLE_END	Establishing\tagSENT_START	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	highly\tagSENT_CONTENT	parameter\tagSENT_CONTENT	efficient\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	better\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	and\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	GCNs\tagSENT_CONTENT	on\tagSENT_CONTENT	FB15k-237\tagdataset	with\tagSENT_CONTENT	8x\tagSENT_CONTENT	and\tagSENT_CONTENT	17x\tagSENT_CONTENT	fewer\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	Systematically\tagSENT_START	investigating\tagSENT_CONTENT	reported\tagSENT_CONTENT	inverse\tagSENT_CONTENT	relations\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	leakage\tagSENT_CONTENT	across\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	introducing\tagSENT_CONTENT	robust\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	datasets\tagSENT_CONTENT	where\tagSENT_CONTENT	necessary\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	solved\tagSENT_CONTENT	using\tagSENT_CONTENT	simple\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	relation_prediction\tagtask	and\tagSENT_CONTENT	several\tagSENT_CONTENT	previously\tagSENT_CONTENT	proposed\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	robust\tagSENT_CONTENT	datasets\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Several\tagSENT_START	convolutional\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	solving\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	relation_prediction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	classification\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	search\tagSENT_CONTENT	query\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	modelling\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	other\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Number\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Interactions\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	1D\tagSECTITLE_CONTENT	vs\tagSECTITLE_CONTENT	2D\tagSECTITLE_CONTENT	Convolutions\tagSECTITLE_END	Using\tagSENT_START	2D\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	1D\tagSENT_CONTENT	convolutions\tagSENT_CONTENT	increases\tagSENT_CONTENT	the\tagSENT_CONTENT	expressiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	through\tagSENT_CONTENT	additional\tagSENT_CONTENT	points\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	between\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	padded\tagSENT_CONTENT	1D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	with\tagSENT_CONTENT	filter\tagSENT_CONTENT	size\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	3\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	relation_prediction\tagtask	between\tagSENT_CONTENT	these\tagSENT_CONTENT	two\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	around\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	point\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	interactions\tagSENT_CONTENT	proportional\tagSENT_CONTENT	to\tagSENT_CONTENT	k\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	padded\tagSENT_CONTENT	2D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	with\tagSENT_CONTENT	filter\tagSENT_CONTENT	size\tagSENT_CONTENT	3\tagSENT_CONTENT	×\tagSENT_CONTENT	3\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	relation_prediction\tagtask	around\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	line\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	interactions\tagSENT_CONTENT	proportional\tagSENT_CONTENT	ton\tagSENT_CONTENT	and\tagSENT_CONTENT	k\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	relation_prediction\tagtask	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	even\tagSENT_CONTENT	more\tagSENT_CONTENT	interactions\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	interactions\tagSENT_CONTENT	proportional\tagSENT_CONTENT	tom\tagSENT_CONTENT	,\tagSENT_CONTENT	n\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	k\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	⊆\tagSENT_START	E\tagSENT_CONTENT	×\tagSENT_CONTENT	R\tagSENT_CONTENT	×\tagSENT_CONTENT	E\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	formalised\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	triples\tagSENT_CONTENT	(\tagSENT_CONTENT	facts\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	r\tagSENT_CONTENT	∈\tagSENT_CONTENT	Rand\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	o\tagSENT_CONTENT	∈\tagSENT_CONTENT	E\tagSENT_CONTENT	,\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	subject\tagSENT_CONTENT	and\tagSENT_CONTENT	object\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	triple\tagSENT_CONTENT	.\tagSENT_END	relation_prediction\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	formalised\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	pointwise\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	rank\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	learning\tagSENT_CONTENT	a\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	ψ\tagSENT_CONTENT	:\tagSENT_CONTENT	E\tagSENT_CONTENT	×\tagSENT_CONTENT	R\tagSENT_CONTENT	×\tagSENT_CONTENT	E\tagSENT_END	Neural\tagSECTITLE_START	Link\tagSECTITLE_CONTENT	Predictors\tagSECTITLE_END	relation_prediction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	as\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	encoding\tagSENT_CONTENT	component\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	scoring\tagSENT_CONTENT	component\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	In\tagSENT_START	we\tagSENT_CONTENT	summarise\tagSENT_CONTENT	the\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	Convolutional\tagSECTITLE_START	2D\tagSECTITLE_CONTENT	Knowledge\tagSECTITLE_CONTENT	Graphs\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	relation_prediction\tagtask	where\tagSENT_CONTENT	the\tagSENT_CONTENT	interactions\tagSENT_CONTENT	between\tagSENT_CONTENT	input\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relationships\tagSENT_CONTENT	are\tagSENT_CONTENT	modelled\tagSENT_CONTENT	by\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	and\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	connected\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	r\tagSENT_CONTENT	r\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	k\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	sand\tagSENT_CONTENT	r\tagSENT_CONTENT	r\tagSENT_CONTENT	denote\tagSENT_CONTENT	a\tagSENT_CONTENT	2D\tagSENT_CONTENT	reshaping\tagSENT_CONTENT	of\tagSENT_CONTENT	e\tagSENT_CONTENT	sand\tagSENT_CONTENT	r\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	:\tagSENT_CONTENT	if\tagSENT_CONTENT	e\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	r\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	e\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	r\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	kw×k\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	kw\tagSENT_CONTENT	k\tagSENT_CONTENT	h\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	t\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	vector\tagSENT_CONTENT	with\tagSENT_CONTENT	dimension\tagSENT_CONTENT	R\tagSENT_CONTENT	1x1\tagSENT_CONTENT	for\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	1\tagSENT_CONTENT	scoring\tagSENT_CONTENT	or\tagSENT_CONTENT	R\tagSENT_CONTENT	1xN\tagSENT_CONTENT	for\tagSENT_CONTENT	1-N\tagSENT_CONTENT	scoring\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	relation_prediction\tagtask	for\tagSENT_CONTENT	1-N\tagSENT_CONTENT	scoring\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	elements\tagSENT_CONTENT	of\tagSENT_CONTENT	vector\tagSENT_CONTENT	tare\tagSENT_CONTENT	ones\tagSENT_CONTENT	for\tagSENT_CONTENT	relationships\tagSENT_CONTENT	that\tagSENT_CONTENT	exists\tagSENT_CONTENT	and\tagSENT_CONTENT	zero\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	.\tagSENT_END	Fast\tagSECTITLE_START	Evaluation\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Link\tagSECTITLE_CONTENT	Prediction\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	architecture\tagSENT_CONTENT	convolution\tagSENT_CONTENT	consumes\tagSENT_CONTENT	about\tagSENT_CONTENT	75\tagSENT_CONTENT	-\tagSENT_CONTENT	90\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	computation\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	minimise\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	to\tagSENT_CONTENT	speedup\tagSENT_CONTENT	computation\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	as\tagSENT_CONTENT	possible\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	relation_prediction\tagtask	which\tagSENT_CONTENT	take\tagSENT_CONTENT	an\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	relation\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	triple\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	o\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	score\tagSENT_CONTENT	it\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	1\tagSENT_CONTENT	scoring\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	take\tagSENT_CONTENT	one\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	)\tagSENT_CONTENT	pair\tagSENT_CONTENT	and\tagSENT_CONTENT	score\tagSENT_CONTENT	it\tagSENT_CONTENT	against\tagSENT_CONTENT	all\tagSENT_CONTENT	entities\tagSENT_END	Experiments\tagSECTITLE_END	Knowledge\tagSECTITLE_START	Graph\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	For\tagSENT_START	evaluating\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	link\tagSENT_CONTENT	prediction\tagSENT_CONTENT	datasets\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	WN18\tagSENT_START	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	which\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	and\tagSENT_CONTENT	40,943\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	create\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	without\tagSENT_CONTENT	this\tagSENT_CONTENT	property\tagSENT_CONTENT	,\tagSENT_CONTENT	Toutanova\tagSENT_CONTENT	and\tagSENT_CONTENT	Chen\tagSENT_CONTENT	(\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	introduced\tagSENT_CONTENT	In\tagSENT_START	relation_prediction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	demonstrates\tagSENT_CONTENT	the\tagSENT_CONTENT	severity\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	bias\tagSENT_CONTENT	by\tagSENT_CONTENT	achieving\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	WN18\tagSENT_CONTENT	and\tagSENT_CONTENT	FB15k\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	selected\tagSENT_CONTENT	the\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	model\tagSENT_CONTENT	via\tagSENT_CONTENT	grid\tagSENT_CONTENT	search\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	reciprocal\tagSENT_CONTENT	rank\tagSENT_CONTENT	(\tagmetric	MRR\tagmetric	)\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	AUC\tagSENT_START	-\tagSENT_CONTENT	PR\tagSENT_CONTENT	(\tagSENT_CONTENT	Countries\tagSENT_CONTENT	)\tagSENT_CONTENT	statistics\tagSENT_CONTENT	on\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	every\tagSENT_CONTENT	three\tagSENT_CONTENT	epochs\tagSENT_CONTENT	.\tagSENT_END	Inverse\tagSECTITLE_START	Model\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	highly\tagSENT_CONTENT	problematic\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	relation_prediction\tagtask	that\tagSENT_CONTENT	do\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	may\tagSENT_CONTENT	simply\tagSENT_CONTENT	learn\tagSENT_CONTENT	which\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	inverse\tagSENT_CONTENT	of\tagSENT_CONTENT	others\tagSENT_CONTENT	,\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	actual\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graph\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	extracts\tagSENT_CONTENT	inverse\tagSENT_CONTENT	relationships\tagSENT_CONTENT	automatically\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	relation_prediction\tagtask	r\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	2\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	check\tagSENT_CONTENT	whether\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	o\tagSENT_CONTENT	)\tagSENT_CONTENT	implies\tagSENT_CONTENT	(\tagSENT_CONTENT	o\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	s\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	vice\tagSENT_CONTENT	-\tagSENT_CONTENT	versa\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	detect\tagSENT_CONTENT	inverse\tagSENT_CONTENT	relations\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	o\tagSENT_CONTENT	)\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	occurs\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	o\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	s\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	frequency\tagSENT_CONTENT	of\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	0.99\tagSENT_CONTENT	−\tagSENT_CONTENT	(\tagSENT_CONTENT	f\tagSENT_CONTENT	v\tagSENT_CONTENT	+\tagSENT_CONTENT	ft\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	f\tagSENT_CONTENT	v\tagSENT_CONTENT	and\tagSENT_CONTENT	ft\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	fails\tagSENT_CONTENT	to\tagSENT_CONTENT	pickup\tagSENT_CONTENT	on\tagSENT_CONTENT	inverse\tagSENT_CONTENT	relations\tagSENT_CONTENT	for\tagSENT_CONTENT	YAGO3\tagSENT_CONTENT	-\tagSENT_CONTENT	10\tagSENT_CONTENT	and\tagSENT_CONTENT	FB15k-237\tagdataset	.\tagSENT_END	For\tagSENT_START	FB15k-237\tagdataset	,\tagSENT_CONTENT	we\tagSENT_CONTENT	could\tagSENT_CONTENT	not\tagSENT_CONTENT	replicate\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	model\tagSENT_CONTENT	results\tagSENT_CONTENT	from\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	general\tagSENT_CONTENT	have\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	than\tagSENT_CONTENT	what\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	.\tagSENT_END	Parameter\tagSECTITLE_START	efficiency\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	ConvE\tagSECTITLE_END	From\tagSENT_START	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	for\tagSENT_CONTENT	FB15k-237\tagdataset	with\tagSENT_CONTENT	0.23\tagSENT_CONTENT	M\tagSENT_CONTENT	parameters\tagSENT_CONTENT	performs\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	with\tagSENT_CONTENT	1.89\tagSENT_CONTENT	M\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	3\tagSENT_CONTENT	metrics\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	5\tagSENT_CONTENT	.\tagSENT_END	ConvE\tagSENT_START	with\tagSENT_CONTENT	0.46\tagSENT_CONTENT	M\tagSENT_CONTENT	parameters\tagSENT_CONTENT	still\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	FB15k-237\tagdataset	with\tagSENT_CONTENT	0.425\tagSENT_CONTENT	Hits@10\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Analysis\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Indegree\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	PageRank\tagSECTITLE_END	Our\tagSENT_START	main\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	good\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	datasets\tagSENT_CONTENT	like\tagSENT_CONTENT	YAGO3\tagSENT_CONTENT	-\tagSENT_CONTENT	10\tagSENT_CONTENT	and\tagSENT_CONTENT	FB15k-237\tagdataset	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	WN18RR\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	contain\tagSENT_CONTENT	nodes\tagSENT_CONTENT	with\tagSENT_CONTENT	very\tagSENT_CONTENT	high\tagSENT_CONTENT	relation\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	indegree\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	deeper\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	optimise\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	hypothesise\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	datasets\tagSENT_CONTENT	with\tagSENT_CONTENT	low\tagSENT_CONTENT	average\tagSENT_CONTENT	relationspecific\tagSENT_CONTENT	indegree\tagSENT_CONTENT	(\tagSENT_CONTENT	like\tagSENT_CONTENT	WN18RR\tagdataset	and\tagSENT_CONTENT	WN18\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	shallow\tagSENT_CONTENT	model\tagSENT_CONTENT	like\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	might\tagSENT_CONTENT	suffice\tagSENT_CONTENT	for\tagSENT_CONTENT	accurately\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	hypothesise\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	,\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	will\tagSENT_CONTENT	always\tagSENT_CONTENT	do\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	with\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	vice\tagSENT_CONTENT	-\tagSENT_CONTENT	versa\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	supports\tagSENT_CONTENT	our\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	deeper\tagSENT_CONTENT	models\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	have\tagSENT_CONTENT	an\tagSENT_CONTENT	advantage\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	graphs\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	FB15k\tagSENT_CONTENT	and\tagSENT_CONTENT	FB15k-237\tagdataset	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	that\tagSENT_CONTENT	shallow\tagSENT_CONTENT	models\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	have\tagSENT_CONTENT	an\tagSENT_CONTENT	advantage\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	less\tagSENT_CONTENT	complex\tagSENT_CONTENT	graphs\tagSENT_CONTENT	(\tagSENT_END	1.796\tagSENT_START	17.6\tagSENT_CONTENT	:\tagSENT_CONTENT	Ablation\tagSENT_CONTENT	study\tagSENT_CONTENT	for\tagSENT_CONTENT	FB15k-237\tagdataset	.\tagSENT_END	Ablation\tagSECTITLE_START	Hits@10\tagSECTITLE_END	When\tagSENT_START	we\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	PageRank\tagSENT_CONTENT	of\tagSENT_CONTENT	nodes\tagSENT_CONTENT	contained\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	of\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	Hits@10\tagmetric	between\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	and\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	is\tagSENT_CONTENT	roughly\tagSENT_CONTENT	proportional\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	PageRank\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	higher\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	PageRank\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	nodes\tagSENT_CONTENT	the\tagSENT_CONTENT	better\tagSENT_CONTENT	ConvE\tagSENT_END	From\tagSENT_START	this\tagSENT_CONTENT	evidence\tagSENT_CONTENT	we\tagSENT_CONTENT	conclude\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	increased\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	DistMult\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	partially\tagSENT_CONTENT	explained\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	it\tagSENT_CONTENT	's\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	nodes\tagSENT_CONTENT	with\tagSENT_CONTENT	high\tagSENT_CONTENT	indegree\tagSENT_CONTENT	with\tagSENT_CONTENT	greater\tagSENT_CONTENT	precisionwhich\tagSENT_CONTENT	is\tagSENT_CONTENT	possibly\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	depth\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	We\tagSENT_START	introduced\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	,\tagSENT_CONTENT	relation_prediction\tagtask	that\tagSENT_CONTENT	uses\tagSENT_CONTENT	2D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	over\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	multiple\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	nonlinear\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graphs\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	ensure\tagSENT_CONTENT	robust\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	investigated\tagSENT_CONTENT	datasets\tagSENT_CONTENT	exists\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	derive\tagSENT_CONTENT	WN18RR\tagdataset	.\tagSENT_END	Further\tagSENT_START	work\tagSENT_CONTENT	might\tagSENT_CONTENT	also\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	2D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	enforce\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	structure\tagSENT_CONTENT	in\tagSENT_CONTENT	embedding\tagSENT_CONTENT	space\tagSENT_CONTENT	so\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	interactions\tagSENT_CONTENT	between\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	SUPPLEMENTAL\tagSECTITLE_START	MATERIAL\tagSECTITLE_END	Further\tagSECTITLE_START	ConvE\tagSECTITLE_CONTENT	results\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Metrics\tagSECTITLE_END	We\tagSENT_START	now\tagSENT_CONTENT	describe\tagSENT_CONTENT	relation_prediction\tagtask	used\tagSENT_CONTENT	for\tagSENT_CONTENT	assessing\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	
1704.07415	title\tagSECTITLE_END	abstract\tagSECTITLE_END	To\tagSENT_START	answer\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_END	Introduction\tagSECTITLE_END	Machine\tagSENT_START	comprehension\tagSENT_CONTENT	(\tagSENT_CONTENT	MC)-especially\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_END	Single\tagSENT_START	-\tagSENT_CONTENT	pass\tagSENT_CONTENT	models\tagSENT_CONTENT	read\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	once\tagSENT_CONTENT	and\tagSENT_CONTENT	often\tagSENT_CONTENT	adopt\tagSENT_CONTENT	the\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	that\tagSENT_CONTENT	emphasizes\tagSENT_CONTENT	important\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	humans\tagSENT_CONTENT	are\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	they\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	it\tagSENT_CONTENT	multiple\tagSENT_CONTENT	times\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	response\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	this\tagSENT_CONTENT	intuition\tagSENT_CONTENT	,\tagSENT_CONTENT	recent\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	pass\tagSENT_CONTENT	models\tagSENT_CONTENT	revisit\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	passage\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	ruminate\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	the\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	BIDAF\tagSENT_CONTENT	,\tagSENT_CONTENT	called\tagSENT_CONTENT	Ruminating\tagSENT_CONTENT	Reader\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	second\tagSENT_CONTENT	pass\tagSENT_CONTENT	of\tagSENT_CONTENT	reading\tagSENT_CONTENT	and\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	to\tagSENT_CONTENT	allow\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	mistakes\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	effectively\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	context\tagSENT_CONTENT	when\tagSENT_CONTENT	selecting\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Question\tagSECTITLE_START	Answering\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Ruminate\tagSENT_CONTENT	Reader\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	reading\tagSENT_CONTENT	and\tagSENT_CONTENT	understanding\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	selecting\tagSENT_CONTENT	a\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	other\tagSENT_CONTENT	datasets\tagSENT_CONTENT	that\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	synthesized\tagSENT_CONTENT	,\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	crowdsourcing\tagSENT_CONTENT	platform\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	realistic\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Model\tagSECTITLE_END	Ruminating\tagSECTITLE_START	Reader\tagSECTITLE_END	Our\tagSENT_START	additions\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	base\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	motivated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	intuition\tagSENT_CONTENT	that\tagSENT_CONTENT	adding\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	pass\tagSENT_CONTENT	of\tagSENT_CONTENT	reading\tagSENT_CONTENT	will\tagSENT_CONTENT	allow\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	integrate\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	weigh\tagSENT_CONTENT	possible\tagSENT_CONTENT	answers\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	by\tagSENT_CONTENT	interpolating\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	pass\tagSENT_CONTENT	with\tagSENT_CONTENT	those\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	pass\tagSENT_CONTENT	through\tagSENT_CONTENT	gating\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	prevent\tagSENT_CONTENT	the\tagSENT_CONTENT	additional\tagSENT_CONTENT	complexity\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	from\tagSENT_CONTENT	substantially\tagSENT_CONTENT	increasing\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	Q\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	1D\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	filters\tagSENT_CONTENT	.\tagSENT_END	=\tagSENT_START	(\tagSENT_CONTENT	a\tagSENT_CONTENT	cq\tagSENT_CONTENT	Q\tagSENT_CONTENT	q\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	=\tagSENT_START	b\tagSENT_CONTENT	c\tagSENT_CONTENT	C\tagSENT_CONTENT	c\tagSENT_CONTENT	where\tagSENT_CONTENT	b\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	calculated\tagSENT_CONTENT	by\tagSENT_CONTENT	b\tagSENT_CONTENT	=\tagSENT_CONTENT	sof\tagSENT_END	We\tagSENT_START	select\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	states\tagSENT_CONTENT	from\tagSENT_CONTENT	both\tagSENT_CONTENT	directions\tagSENT_CONTENT	and\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	them\tagmetric	together\tagSENT_CONTENT	ass\tagSENT_CONTENT	=\tagSENT_END	This\tagSENT_START	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	somewhat\tagSENT_CONTENT	inefficient\tagSENT_CONTENT	,\tagSENT_CONTENT	proves\tagSENT_CONTENT	to\tagSENT_CONTENT	bean\tagSENT_CONTENT	valuable\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	allows\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	track\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	loosely\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	positional\tagSENT_CONTENT	encoding\tagSENT_CONTENT	strategy\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	:\tagSENT_CONTENT	Which\tagSENT_CONTENT	Newton\tagSENT_CONTENT	turnover\tagSENT_CONTENT	resulted\tagSENT_CONTENT	in\tagSENT_CONTENT	seven\tagSENT_CONTENT	points\tagSENT_CONTENT	for\tagSENT_CONTENT	Denver\tagSENT_CONTENT	?\tagSENT_END	As\tagSENT_START	in\tagSENT_CONTENT	BIDAF\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	independently\tagSENT_CONTENT	models\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	being\tagSENT_CONTENT	selected\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	or\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	We\tagSENT_START	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	index\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_END	This\tagSENT_START	motivates\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	loss\tagSENT_CONTENT	term\tagSENT_CONTENT	at\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	:\tagSENT_CONTENT	We\tagSENT_CONTENT	penalize\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	selected\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	s\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	index\tagSENT_CONTENT	of\tagSENT_CONTENT	answer\tagSENT_CONTENT	span\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagmetric	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	index\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	q\tagSENT_CONTENT	BoW\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	bag\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	query\tagSENT_CONTENT	encoding\tagSENT_CONTENT	,\tagSENT_CONTENT	cos(a\tagSENT_CONTENT	,\tagSENT_CONTENT	b\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	cosine\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	(\tagSENT_START	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	extend\tagSENT_START	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	sum\tagSENT_CONTENT	reader\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	an\tagSENT_CONTENT	added\tagSENT_CONTENT	gating\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	Implementation\tagSECTITLE_START	details\tagSECTITLE_END	Unpublished\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Method\tagSECTITLE_END	question_answering\tagtask	are\tagSENT_CONTENT	provided\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Variant\tagSECTITLE_END	Results\tagSECTITLE_END	Analysis\tagSECTITLE_END	In\tagSENT_START	question_answering\tagtask	"\tagSENT_CONTENT	What\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	name\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	trophy\tagSENT_CONTENT	given\tagSENT_CONTENT	to\tagSENT_CONTENT	anyone\tagSENT_CONTENT	who\tagSENT_CONTENT	plays\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	winning\tagSENT_CONTENT	team\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	super\tagSENT_CONTENT	Bowl\tagSENT_CONTENT	?\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	words\tagSENT_CONTENT	name\tagSENT_CONTENT	,\tagSENT_CONTENT	trophy\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	are\tagSENT_CONTENT	strongly\tagSENT_CONTENT	attended\tagSENT_CONTENT	to\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	hop\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	comparison\tagSENT_CONTENT	of\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	between\tagSENT_CONTENT	BIDAF\tagSENT_CONTENT	and\tagSENT_CONTENT	Ruminating\tagSENT_CONTENT	Reader\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	different\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	answer\tagSENT_CONTENT	length\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	questions\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	The\tagSENT_START	model\tagSENT_CONTENT	surpasses\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	BIDAF\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	margin\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ties\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	published\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	
D17-1222	title\tagSECTITLE_END	Deep\tagSENT_START	Recurrent\tagSENT_CONTENT	Generative\tagSENT_CONTENT	Decoder\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	anew\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	oriented\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	equipped\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	generative\tagSENT_CONTENT	decoder\tagSENT_CONTENT	(\tagSENT_CONTENT	DRGN\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	generating\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	that\tagSENT_CONTENT	retains\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	content\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Apple\tagSECTITLE_START	sues\tagSECTITLE_CONTENT	Qualcomm\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	nearly\tagSECTITLE_CONTENT	$\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	billion\tagSECTITLE_END	Twitter\tagSECTITLE_START	mostly\tagSECTITLE_CONTENT	meets\tagSECTITLE_CONTENT	modest\tagSECTITLE_CONTENT	diversity\tagSECTITLE_CONTENT	goals\tagSECTITLE_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	summarization\tagtask	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	people\tagSENT_CONTENT	may\tagSENT_CONTENT	naturally\tagSENT_CONTENT	follow\tagSENT_CONTENT	some\tagSENT_CONTENT	inherent\tagSENT_CONTENT	structures\tagSENT_CONTENT	when\tagSENT_CONTENT	they\tagSENT_CONTENT	write\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	structure\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	into\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Works\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	generating\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	that\tagSENT_CONTENT	retains\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	content\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	document\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	some\tagSENT_CONTENT	researchers\tagSENT_CONTENT	employ\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	framework\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	they\tagSENT_CONTENT	only\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	topic\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	conduct\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	salience\tagSENT_CONTENT	estimation\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Framework\tagSECTITLE_START	Description\tagSECTITLE_END	Overview\tagSECTITLE_END	Recurrent\tagSECTITLE_START	Generative\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_END	From\tagSENT_START	summarization\tagtask	2\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	transformations\tagSENT_CONTENT	are\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	h\tagSENT_CONTENT	d\tagSENT_CONTENT	t\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	generative\tagSENT_CONTENT	model\tagSENT_CONTENT	called\tagSENT_CONTENT	Variational\tagSENT_CONTENT	Auto\tagSENT_CONTENT	-\tagSENT_CONTENT	Encoders\tagSENT_CONTENT	(\tagSENT_CONTENT	VAEs\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	shows\tagSENT_CONTENT	strong\tagSENT_CONTENT	capability\tagSENT_CONTENT	in\tagSENT_CONTENT	modeling\tagSENT_CONTENT	latent\tagSENT_CONTENT	random\tagSENT_CONTENT	variables\tagSENT_CONTENT	and\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	fields\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sentence\tagSENT_CONTENT	generation\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	 \tagSENT_CONTENT	introducing\tagSENT_CONTENT	the\tagSENT_CONTENT	historical\tagSENT_CONTENT	latent\tagSENT_CONTENT	variable\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	it\tagSENT_CONTENT	be\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	modeling\tagSENT_CONTENT	sequence\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	purpose\tagSENT_CONTENT	of\tagSENT_CONTENT	solving\tagSENT_CONTENT	the\tagSENT_CONTENT	intractable\tagSENT_CONTENT	integral\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	marginal\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	3\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	recognition\tagSENT_CONTENT	model\tagSENT_CONTENT	q\tagSENT_CONTENT	φ\tagSENT_CONTENT	(\tagSENT_END	Let\tagSENT_START	L(θ\tagSENT_CONTENT	,\tagSENT_CONTENT	φ\tagSENT_CONTENT	;\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	two\tagSENT_CONTENT	terms\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	4\tagSENT_CONTENT	:\tagSENT_END	Since\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	KL\tagSENT_CONTENT	-\tagSENT_CONTENT	divergence\tagSENT_CONTENT	term\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	4\tagSENT_CONTENT	is\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	negative\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	log\tagSENT_CONTENT	p\tagSENT_CONTENT	θ\tagSENT_CONTENT	(\tagSENT_CONTENT	y\tagSENT_CONTENT	<\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_END	Abstractive\tagSECTITLE_START	Summary\tagSECTITLE_CONTENT	Generation\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	design\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	framework\tagSENT_CONTENT	to\tagSENT_CONTENT	conduct\tagSENT_CONTENT	the\tagSENT_CONTENT	variational\tagSENT_CONTENT	inference\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	generative\tagSENT_CONTENT	decoder\tagSENT_CONTENT	component\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	some\tagSENT_CONTENT	design\tagSENT_CONTENT	in\tagSENT_CONTENT	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	generate\tagSENT_CONTENT	summarization\tagtask	precisely\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	integrate\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	generative\tagSENT_CONTENT	decoding\tagSENT_CONTENT	component\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	decoding\tagSENT_CONTENT	component\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	map\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	structure\tagSENT_CONTENT	variable\tagSENT_CONTENT	z\tagSENT_CONTENT	t\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	decoding\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	h\tagSENT_CONTENT	d\tagSENT_CONTENT	2\tagSENT_CONTENT	t\tagSENT_CONTENT	to\tagSENT_CONTENT	anew\tagSENT_CONTENT	hidden\tagSENT_CONTENT	variable\tagSENT_CONTENT	:\tagSENT_END	Learning\tagSECTITLE_END	One\tagSENT_START	term\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	negative\tagSENT_CONTENT	loglikelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	one\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	variational\tagSENT_CONTENT	lower\tagSENT_CONTENT	bound\tagSENT_CONTENT	L(θ\tagSENT_CONTENT	,\tagSENT_CONTENT	φ\tagSENT_CONTENT	;\tagSENT_CONTENT	Y\tagSENT_CONTENT	)\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	5\tagSENT_CONTENT	.\tagSENT_END	Datesets\tagSECTITLE_END	Gigawords\tagSENT_START	is\tagSENT_CONTENT	summarization\tagtask	dataset\tagSENT_CONTENT	prepared\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	Annotated\tagSENT_CONTENT	Gigawords\tagSENT_CONTENT	1\tagSENT_CONTENT	by\tagSENT_CONTENT	extracting\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	sentence\tagSENT_CONTENT	from\tagSENT_CONTENT	articles\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	headline\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	a\tagSENT_CONTENT	sourcesummary\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Metrics\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	ROUGE\tagmetric	score\tagmetric	)\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	with\tagSENT_CONTENT	standard\tagSENT_CONTENT	options\tagSENT_CONTENT	.\tagSENT_END	Comparative\tagSECTITLE_START	Methods\tagSECTITLE_END	•\tagSENT_START	TOPIARY\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	on\tagSENT_CONTENT	DUC2004\tagSENT_CONTENT	Task-1\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	•\tagSENT_START	MOSES+\tagSENT_CONTENT	(\tagSENT_CONTENT	Rush\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	phrasebased\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	system\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	Gigaword\tagdataset	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	Rush\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	local\tagSENT_CONTENT	attention\tagSENT_CONTENT	modeling\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	both\tagSENT_START	consider\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	positions\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	encoders\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	The\tagSENT_START	maximum\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	100\tagSENT_CONTENT	and\tagSENT_CONTENT	50\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussions\tagSECTITLE_END	ROUGE\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Although\tagSENT_START	CopyNet\tagSENT_CONTENT	employs\tagSENT_CONTENT	a\tagSENT_CONTENT	copying\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	quality\tagSENT_CONTENT	and\tagSENT_CONTENT	RNN\tagSENT_CONTENT	-\tagSENT_CONTENT	distract\tagSENT_CONTENT	considers\tagSENT_CONTENT	attention\tagSENT_CONTENT	information\tagSENT_CONTENT	diversity\tagSENT_CONTENT	in\tagSENT_CONTENT	their\tagSENT_CONTENT	decoders\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	two\tagSENT_CONTENT	methods\tagSENT_CONTENT	demonstrating\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	structure\tagSENT_CONTENT	information\tagSENT_CONTENT	learned\tagSENT_CONTENT	from\tagSENT_CONTENT	target\tagSENT_CONTENT	summaries\tagSENT_CONTENT	indeed\tagSENT_CONTENT	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Summary\tagSECTITLE_START	Case\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	DRGD\tagSENT_CONTENT	have\tagSENT_CONTENT	consistent\tagSENT_CONTENT	latent\tagSENT_CONTENT	structures\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	
1705.02798	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Meanwhile\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	previous\tagSENT_CONTENT	systems\tagSENT_CONTENT	by\tagSENT_CONTENT	over\tagSENT_CONTENT	6\tagSENT_CONTENT	%\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	both\tagSENT_CONTENT	Exact\tagSENT_CONTENT	Match\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	metrics\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	To\tagSENT_START	capture\tagSENT_CONTENT	complex\tagSENT_CONTENT	interactions\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	fully\tagSENT_CONTENT	compose\tagSENT_CONTENT	complete\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	inputs\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	architectures\tagSENT_CONTENT	that\tagSENT_CONTENT	compute\tagSENT_CONTENT	attentions\tagSENT_CONTENT	repeatedly\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	.\tagSENT_END	To\tagSECTITLE_START	train\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	standard\tagSECTITLE_CONTENT	maximum\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	likelihood\tagSECTITLE_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	utilized\tagSENT_CONTENT	to\tagSENT_CONTENT	normalize\tagSENT_CONTENT	the\tagSENT_CONTENT	reward\tagSENT_CONTENT	and\tagSENT_CONTENT	reduce\tagSENT_CONTENT	variances\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	address\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	reattention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	that\tagSENT_CONTENT	temporally\tagSENT_CONTENT	memorizes\tagSENT_CONTENT	past\tagSENT_CONTENT	attentions\tagSENT_CONTENT	and\tagSENT_CONTENT	uses\tagSENT_CONTENT	them\tagmetric	to\tagSENT_CONTENT	refine\tagSENT_CONTENT	current\tagSENT_CONTENT	attentions\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	round\tagSENT_CONTENT	alignment\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	SQuAD\tagdataset	,\tagSENT_CONTENT	our\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	obtains\tagSENT_CONTENT	an\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_END	MRC\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Reattention\tagSECTITLE_END	Task\tagSECTITLE_START	Description\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	MRC\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	C\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	A\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	different\tagSENT_CONTENT	forms\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	specific\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Alignment\tagSECTITLE_START	Architecture\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	MRC\tagSECTITLE_END	That\tagSENT_START	is\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	align\tagSENT_CONTENT	each\tagSENT_CONTENT	context\tagSENT_CONTENT	word\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	question\tagSENT_CONTENT	using\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	enhance\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	representation\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	attentive\tagSENT_CONTENT	question\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	u\tagSENT_START	j\tagSENT_CONTENT	}\tagSENT_CONTENT	m\tagSENT_CONTENT	j=1\tagSENT_CONTENT	,\tagSENT_CONTENT	representing\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	similarity\tagSENT_CONTENT	matrix\tagSENT_CONTENT	E\tagSENT_CONTENT	∈\tagSENT_END	where\tagSENT_START	E\tagSENT_CONTENT	ij\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	j\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	context\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	scalar\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	attentive\tagSENT_CONTENT	information\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	integrated\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	context\tagSENT_CONTENT	representation\tagSENT_CONTENT	Z\tagSENT_CONTENT	=\tagSENT_CONTENT	{\tagSENT_CONTENT	z\tagSENT_CONTENT	j\tagSENT_CONTENT	}\tagSENT_CONTENT	m\tagSENT_CONTENT	j=1\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Reattention\tagSECTITLE_START	Mechanism\tagSECTITLE_END	To\tagSENT_START	address\tagSENT_CONTENT	these\tagSENT_CONTENT	problems\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	temporally\tagSENT_CONTENT	memorize\tagSENT_CONTENT	past\tagSENT_CONTENT	attentions\tagSENT_CONTENT	and\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	use\tagSENT_CONTENT	them\tagmetric	to\tagSENT_CONTENT	refine\tagSENT_CONTENT	current\tagSENT_CONTENT	attentions\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	pair\tagSENT_CONTENT	(\tagSENT_CONTENT	team\tagmetric	,\tagSENT_CONTENT	Broncos\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	(\tagSENT_CONTENT	team\tagmetric	,\tagSENT_CONTENT	Panthers\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Let\tagSENT_START	E\tagmetric	t−1\tagSENT_CONTENT	and\tagSENT_CONTENT	B\tagSENT_CONTENT	t−1\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	similarity\tagSENT_CONTENT	matrices\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	temporally\tagSENT_CONTENT	memorized\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	:\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	context\tagSENT_CONTENT	attention\tagSENT_CONTENT	distribution\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	softmax(B\tagSENT_CONTENT	t−1\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	y\tagSENT_CONTENT	1\tagSENT_CONTENT	k\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_CONTENT	2\tagSENT_CONTENT	k\tagSENT_CONTENT	are\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	denote\tagSENT_CONTENT	p\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	i|C\tagSENT_CONTENT	,\tagSENT_CONTENT	Q\tagSENT_CONTENT	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	p\tagSENT_CONTENT	2\tagSENT_END	0.2\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	harmful\tagSENT_CONTENT	if\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	partially\tagSENT_CONTENT	overlapped\tagSENT_CONTENT	with\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	normalized\tagSENT_CONTENT	objective\tagSENT_CONTENT	would\tagSENT_CONTENT	discourage\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	of\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	positions\tagSENT_CONTENT	.\tagSENT_END	Notice\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	normalized\tagSENT_CONTENT	reward\tagSENT_CONTENT	is\tagSENT_CONTENT	constantly\tagSENT_CONTENT	positive\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	always\tagSENT_CONTENT	encouraged\tagSENT_CONTENT	.\tagSENT_END	End\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	end\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	It\tagSENT_START	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	main\tagSENT_CONTENT	components\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	builds\tagSENT_CONTENT	contextual\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	jointly\tagSENT_CONTENT	;\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	an\tagSENT_CONTENT	iterative\tagSENT_CONTENT	aligner\tagSENT_CONTENT	performs\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	round\tagSENT_CONTENT	alignments\tagSENT_CONTENT	between\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	context\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	reattention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	;\tagSENT_END	j\tagSENT_START	}\tagSENT_CONTENT	m\tagSENT_CONTENT	j=1\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Self\tagSECTITLE_START	Reattention\tagSECTITLE_END	Thus\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	words\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	,\tagSENT_CONTENT	denoted\tagSENT_CONTENT	as\tagSENT_CONTENT	two\tagSENT_CONTENT	matrices\tagSENT_CONTENT	:\tagSENT_END	Each\tagSENT_START	block\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	modules\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	an\tagSENT_CONTENT	interactive\tagSENT_CONTENT	alignment\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	question_answering\tagtask	into\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	;\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	alignment\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	against\tagSENT_CONTENT	itself\tagSENT_CONTENT	;\tagSENT_END	question_answering\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	j\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	context\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	:\tagSENT_CONTENT	softmax(E\tagSENT_CONTENT	:\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	an\tagSENT_CONTENT	attended\tagSENT_CONTENT	question\tagSENT_CONTENT	vector˜vvector˜\tagSENT_CONTENT	vector˜v\tagSENT_CONTENT	j\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	t\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	block\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	>\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	fix\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	V\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	as\tagSENT_CONTENT	previous\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	context\tagSENT_CONTENT	vectors\tagSENT_CONTENT	R\tagSENT_CONTENT	t−1\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	pointer\tagSENT_CONTENT	networks\tagSENT_CONTENT	]\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	predictions\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	anew\tagSENT_CONTENT	question\tagSENT_CONTENT	summary˜ssummary˜\tagSENT_CONTENT	summary˜s\tagSENT_CONTENT	is\tagSENT_CONTENT	updated\tagSENT_CONTENT	by\tagSENT_CONTENT	fusing\tagSENT_CONTENT	context\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	position\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	as\tagSENT_CONTENT	l\tagSENT_CONTENT	=\tagSENT_CONTENT	R\tagSENT_CONTENT	3\tagSENT_CONTENT	·\tagSENT_CONTENT	p\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	into\tagSENT_CONTENT	question_answering\tagtask	:\tagSENT_END	Experiments\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	SQuAD\tagdataset	is\tagSENT_CONTENT	a\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	totally\tagSENT_CONTENT	containing\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	100\tagSENT_CONTENT	,\tagSENT_CONTENT	000\tagSENT_CONTENT	questions\tagSENT_CONTENT	manually\tagSENT_CONTENT	annotated\tagSENT_CONTENT	by\tagSENT_CONTENT	crowdsourcing\tagSENT_CONTENT	workers\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	536\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	out\tagSENT_CONTENT	of\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	from\tagSENT_CONTENT	Gaussian\tagSENT_CONTENT	distributions\tagSENT_CONTENT	and\tagSENT_CONTENT	keep\tagSENT_CONTENT	them\tagmetric	trainable\tagSENT_CONTENT	.\tagSENT_END	Single\tagSECTITLE_START	Model\tagSECTITLE_END	Dev\tagSECTITLE_END	question_answering\tagtask	75.3\tagSENT_CONTENT	83.6\tagSENT_CONTENT	76.0\tagSENT_CONTENT	83.9\tagSENT_CONTENT	SAN\tagSENT_CONTENT	76.2\tagSENT_CONTENT	84.1\tagSENT_CONTENT	76.8\tagSENT_CONTENT	84.4\tagSENT_CONTENT	AttentionReader+\tagSENT_END	Overall\tagSECTITLE_START	Results\tagSECTITLE_END	We\tagSENT_START	submitted\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	SQuAD\tagdataset	for\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Study\tagSECTITLE_END	We\tagSENT_START	notice\tagSENT_CONTENT	that\tagSENT_CONTENT	reattention\tagSENT_CONTENT	has\tagSENT_CONTENT	more\tagSENT_CONTENT	influences\tagSENT_CONTENT	on\tagSENT_CONTENT	EM\tagSENT_CONTENT	score\tagSENT_CONTENT	while\tagSENT_CONTENT	DCRL\tagSENT_CONTENT	contributes\tagSENT_CONTENT	more\tagSENT_CONTENT	to\tagSENT_CONTENT	F1\tagSENT_CONTENT	metric\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	removing\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	results\tagSENT_CONTENT	in\tagSENT_CONTENT	huge\tagSENT_CONTENT	drops\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	Effectiveness\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Reattention\tagSECTITLE_END	0.695\tagSENT_START	±\tagSENT_CONTENT	0.086\tagSENT_CONTENT	0.866\tagSENT_CONTENT	±\tagSENT_CONTENT	0.074\tagSENT_CONTENT	E\tagmetric	2\tagSENT_CONTENT	to\tagSENT_CONTENT	E\tagmetric	3\tagSENT_CONTENT	0.404\tagSENT_CONTENT	±\tagSENT_CONTENT	0.067\tagSENT_CONTENT	0.450\tagSENT_END	±\tagSENT_START	0.097\tagSENT_CONTENT	Deficiency\tagSENT_CONTENT	E\tagSENT_CONTENT	2\tagSENT_CONTENT	to\tagSENT_CONTENT	E\tagmetric	2\tagSENT_END	E\tagmetric	3\tagSENT_CONTENT	to\tagSENT_CONTENT	E\tagmetric	3\tagSENT_END	Prediction\tagSECTITLE_START	Analysis\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	example\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	four\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	are\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	when\tagSENT_CONTENT	question_answering\tagtask	asks\tagSENT_CONTENT	for\tagSENT_CONTENT	how\tagSENT_CONTENT	many\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	:\tagSENT_CONTENT	How\tagSENT_CONTENT	many\tagSENT_CONTENT	interceptions\tagSENT_CONTENT	did\tagSENT_CONTENT	Josh\tagSENT_CONTENT	Norman\tagSENT_CONTENT	score\tagSENT_CONTENT	touchdowns\tagSENT_CONTENT	within\tagSENT_CONTENT	2015\tagSENT_CONTENT	?\tagSENT_END	Question\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Where\tagSECTITLE_CONTENT	was\tagSECTITLE_CONTENT	Dyrrachium\tagSECTITLE_CONTENT	located\tagSECTITLE_CONTENT	?\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
htyo14	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	shows\tagSENT_CONTENT	how\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neu\tagSENT_CONTENT	-\tagSENT_CONTENT	ral\tagSENT_CONTENT	networks\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	effectively\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	dialogue_state_tracking\tagtask	in\tagSENT_CONTENT	an\tagSENT_CONTENT	extended\tagSENT_CONTENT	domain\tagSENT_CONTENT	with\tagSENT_CONTENT	new\tagSENT_CONTENT	slots\tagSENT_CONTENT	and\tagSENT_CONTENT	values\tagSENT_CONTENT	not\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Spoken\tagSENT_START	dialog\tagSENT_CONTENT	systems\tagSENT_CONTENT	allow\tagSENT_CONTENT	a\tagSENT_CONTENT	user\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	finding\tagSENT_CONTENT	a\tagmetric	restaurant\tagmetric	,\tagSENT_CONTENT	using\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	presents\tagSENT_CONTENT	how\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	effectively\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	in\tagSENT_CONTENT	expanding\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	Several\tagSENT_START	successful\tagSENT_CONTENT	approaches\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_state_tracking\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	entered\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	two\tagSENT_CONTENT	DSTCs\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	maximum\tagSENT_CONTENT	entropy\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	web\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	ranking\tagSENT_CONTENT	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	robust\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	fields\tagSENT_CONTENT	.\tagSENT_END	RECURRENT\tagSECTITLE_START	NEURAL\tagSECTITLE_CONTENT	NETWORKS\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	DIALOG\tagSECTITLE_CONTENT	STATE\tagSECTITLE_CONTENT	TRACKING\tagSECTITLE_END	A\tagSENT_START	key\tagSENT_CONTENT	component\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	dialog\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	formulated\tagSENT_CONTENT	in\tagSENT_CONTENT	dialogue_state_tracking\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	goal\tagSENT_CONTENT	.\tagSENT_END	Feature\tagSECTITLE_START	Representation\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Dialog\tagSECTITLE_CONTENT	Sequence\tagSECTITLE_END	The\tagSENT_START	input\tagSENT_CONTENT	components\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	are\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	action\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	input\tagSENT_CONTENT	(\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	speech\tagSENT_CONTENT	recogniser\tagSENT_CONTENT	and/or\tagSENT_CONTENT	a\tagSENT_CONTENT	spoken\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	system\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	dialogue_state_tracking\tagtask	the\tagSENT_CONTENT	dialog\tagSENT_CONTENT	acts\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	sub\tagSENT_CONTENT	acts\tagSENT_CONTENT	-\tagSENT_CONTENT	each\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	act\tagSENT_CONTENT	-\tagSENT_CONTENT	type\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	optional\tagSENT_CONTENT	slot\tagSENT_CONTENT	,\tagSENT_CONTENT	value\tagSENT_CONTENT	assignment\tagSENT_CONTENT	.\tagSENT_END	Delexicalised\tagSECTITLE_START	Features\tagSECTITLE_END	Network\tagSECTITLE_START	Structure\tagSECTITLE_END	ONLINE\tagSECTITLE_START	UNSUPERVISED\tagSECTITLE_CONTENT	ADAPTATION\tagSECTITLE_END	The\tagSENT_START	approach\tagSENT_CONTENT	defined\tagSENT_CONTENT	here\tagSENT_CONTENT	however\tagSENT_CONTENT	exploits\tagSENT_CONTENT	specific\tagSENT_CONTENT	patterns\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	and\tagSENT_CONTENT	is\tagSENT_CONTENT	formulated\tagSENT_CONTENT	specifically\tagSENT_CONTENT	for\tagSENT_CONTENT	use\tagSENT_CONTENT	in\tagSENT_CONTENT	live\tagSENT_CONTENT	dialog\tagSENT_CONTENT	state\tagSENT_CONTENT	tracking\tagSENT_CONTENT	.\tagSENT_END	Criterion\tagSECTITLE_START	for\tagSECTITLE_CONTENT	Unsupervised\tagSECTITLE_CONTENT	Adaptation\tagSECTITLE_END	Dialog\tagSECTITLE_START	Turn\tagSECTITLE_CONTENT	y\tagSECTITLE_CONTENT	init\tagSECTITLE_CONTENT	Notes\tagSECTITLE_END	Chinese\tagSECTITLE_END	System\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Sorry\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	what\tagSECTITLE_CONTENT	type\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	food\tagSECTITLE_CONTENT	would\tagSECTITLE_CONTENT	you\tagSECTITLE_CONTENT	like\tagSECTITLE_CONTENT	?\tagSECTITLE_END	Italian\tagSECTITLE_END	Schedule\tagSECTITLE_START	for\tagSECTITLE_CONTENT	Online\tagSECTITLE_CONTENT	Adaptation\tagSECTITLE_END	RESULTS\tagSECTITLE_START	IN\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	THIRD\tagSECTITLE_CONTENT	DIALOG\tagSECTITLE_CONTENT	STATE\tagSECTITLE_CONTENT	TRACKING\tagSECTITLE_CONTENT	CHALLENGE\tagSECTITLE_END	dialogue_state_tracking\tagtask	(\tagSENT_CONTENT	DSTC3\tagSENT_CONTENT	)\tagSENT_CONTENT	studied\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	trackers\tagSENT_CONTENT	to\tagSENT_CONTENT	adapt\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	extended\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	trackers\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	six\tagSENT_CONTENT	separate\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	were\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	varying\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	combined\tagSENT_CONTENT	using\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	The\tagSENT_START	ASR+SLU\tagSENT_CONTENT	tracker\tagSENT_CONTENT	obtained\tagSENT_CONTENT	the\tagmetric	top\tagmetric	accuracies\tagmetric	and\tagSENT_CONTENT	L2\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	tracking\tagSENT_CONTENT	the\tagSENT_CONTENT	joint\tagSENT_CONTENT	goal\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	challenge\tagSENT_CONTENT	.\tagSENT_END	Joint\tagSECTITLE_START	Goals\tagSECTITLE_END	Method\tagSECTITLE_END	Requested\tagmetric	Acc\tagmetric	.\tagSENT_END	EVALUATION\tagSECTITLE_START	OF\tagSECTITLE_CONTENT	UNSUPERVISED\tagSECTITLE_CONTENT	ADAPTATION\tagSECTITLE_END	This\tagSENT_START	section\tagSENT_CONTENT	evaluates\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	online\tagSENT_CONTENT	and\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	to\tagSENT_CONTENT	extended\tagSENT_CONTENT	domains\tagSENT_CONTENT	in\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Adaptation\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Missing\tagSECTITLE_CONTENT	Labels\tagSECTITLE_END	A\tagSENT_START	set\tagSENT_CONTENT	of\tagSENT_CONTENT	initial\tagmetric	trackers\tagmetric	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	labels\tagSENT_CONTENT	for\tagSENT_CONTENT	slot\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	adapted\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	tracking\tagSENT_CONTENT	the\tagSENT_CONTENT	slot\tagSENT_END	In\tagSENT_START	all\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	improved\tagSENT_CONTENT	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Adaptation\tagSECTITLE_START	to\tagSECTITLE_CONTENT	New\tagSECTITLE_CONTENT	Domains\tagSECTITLE_END	Goal\tagSENT_START	tracking\tagSENT_CONTENT	accuracies\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DSTC3\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	wordbased\tagSENT_CONTENT	RNN\tagSENT_CONTENT	trackers\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	and\tagSENT_CONTENT	without\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	.\tagSENT_END	CONCLUSIONS\tagSECTITLE_END	The\tagSENT_START	RNN\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	delexicalised\tagSENT_CONTENT	feature\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	robust\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_state_tracking\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	generalise\tagSENT_CONTENT	to\tagSENT_CONTENT	unseen\tagSENT_CONTENT	slots\tagSENT_CONTENT	and\tagSENT_CONTENT	values\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	methods\tagSENT_CONTENT	presented\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	coupled\tagSENT_CONTENT	with\tagSENT_CONTENT	recent\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	policy\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	,\tagSENT_CONTENT	suggest\tagSENT_CONTENT	a\tagSENT_CONTENT	technique\tagSENT_CONTENT	for\tagSENT_CONTENT	deploying\tagSENT_CONTENT	dialogue_state_tracking\tagtask	in\tagSENT_CONTENT	expanding\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	
K16-1006	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Context\tagSENT_START	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	central\tagSENT_CONTENT	to\tagSENT_CONTENT	various\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	reference\tagSENT_CONTENT	resolution\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	many\tagSENT_CONTENT	more\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	This\tagSENT_START	principle\tagSENT_CONTENT	applies\tagSENT_CONTENT	to\tagSENT_CONTENT	various\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	reference\tagSENT_CONTENT	resolution\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	an\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	representations\tagSENT_CONTENT	were\tagSENT_CONTENT	found\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	measuring\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	similarity\tagSENT_CONTENT	,\tagSENT_CONTENT	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	sense\tagSENT_CONTENT	induction\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical\tagSENT_CONTENT	substitution\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	completion\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	demonstrate\tagSENT_CONTENT	their\tagSENT_CONTENT	high\tagSENT_CONTENT	quality\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	simple\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	context\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	surpass\tagSENT_CONTENT	or\tagSENT_CONTENT	nearly\tagSENT_CONTENT	reach\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	sentence\tagSENT_CONTENT	completion\tagSENT_CONTENT	,\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	while\tagSENT_CONTENT	substantially\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	the\tagSENT_CONTENT	common\tagSENT_CONTENT	average\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	representation\tagSENT_CONTENT	(\tagSENT_CONTENT	denoted\tagSENT_CONTENT	AWE\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Context2vec\tagSECTITLE_START	's\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Model\tagSECTITLE_START	Overview\tagSECTITLE_END	Both\tagSENT_START	models\tagSENT_CONTENT	learn\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	word_sense_disambiguation\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	embedding\tagSENT_CONTENT	them\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	objective\tagSENT_CONTENT	of\tagSENT_CONTENT	having\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	word\tagSENT_CONTENT	via\tagSENT_CONTENT	a\tagSENT_CONTENT	log\tagSENT_CONTENT	linear\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Formal\tagSECTITLE_START	Specification\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	The\tagSENT_START	analysis\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	is\tagSENT_CONTENT	valid\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	cooccurrence\tagSENT_CONTENT	matrix\tagSENT_CONTENT	that\tagSENT_CONTENT	describes\tagSENT_CONTENT	word_sense_disambiguation\tagtask	of\tagSENT_CONTENT	two\tagSENT_CONTENT	random\tagSENT_CONTENT	variables\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Illustration\tagSECTITLE_END	Sentential\tagSECTITLE_START	Context\tagSECTITLE_END	This\tagSENT_START	[\tagSENT_CONTENT	]\tagSENT_CONTENT	is\tagSENT_CONTENT	due\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	to\tagSENT_CONTENT	mere\tagSENT_CONTENT	luck\tagSENT_CONTENT	,\tagSENT_CONTENT	award\tagSENT_CONTENT	,\tagSENT_CONTENT	prize\tagSENT_CONTENT	,\tagSENT_CONTENT	turnabout\tagSENT_CONTENT	,\tagSENT_CONTENT	offer\tagSENT_CONTENT	,\tagSENT_CONTENT	gift\tagSENT_CONTENT	but\tagSENT_CONTENT	to\tagSENT_CONTENT	outstanding\tagSENT_CONTENT	work\tagSENT_CONTENT	and\tagSENT_CONTENT	word_sense_disambiguation\tagtask	[\tagSENT_CONTENT	]\tagSENT_CONTENT	is\tagSENT_CONTENT	due\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	to\tagSENT_CONTENT	mere\tagSENT_CONTENT	luck\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	,\tagSENT_CONTENT	success\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	victory\tagSENT_CONTENT	,\tagSENT_CONTENT	prize\tagSENT_CONTENT	-\tagSENT_CONTENT	money\tagSENT_CONTENT	but\tagSENT_CONTENT	to\tagSENT_CONTENT	outstanding\tagSENT_CONTENT	work\tagSENT_CONTENT	and\tagSENT_CONTENT	dedication\tagSENT_CONTENT	:\tagSENT_CONTENT	Closest\tagSENT_CONTENT	target\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	various\tagSENT_CONTENT	sentential\tagSENT_CONTENT	contexts\tagSENT_CONTENT	,\tagSENT_CONTENT	illustrating\tagSENT_CONTENT	context2vec\tagSENT_CONTENT	's\tagSENT_CONTENT	sensitivity\tagSENT_CONTENT	to\tagSENT_CONTENT	long\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	both\tagSENT_CONTENT	sides\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	α\tagSECTITLE_END	Relation\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Language\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Settings\tagSECTITLE_END	word_sense_disambiguation\tagtask	includes\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	sentence\tagSENT_CONTENT	completion\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical\tagSENT_CONTENT	substitution\tagSENT_CONTENT	and\tagSENT_CONTENT	supervised\tagSENT_CONTENT	word\tagSENT_CONTENT	sense\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	(\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_START	corpus\tagSECTITLE_END	Compared\tagSECTITLE_START	Methods\tagSECTITLE_END	Sentence\tagSECTITLE_START	Completion\tagSECTITLE_CONTENT	Challenge\tagSECTITLE_END	Lexical\tagSECTITLE_START	Substitution\tagSECTITLE_CONTENT	Task\tagSECTITLE_END	Supervised\tagSECTITLE_START	WSD\tagSECTITLE_END	Results\tagSECTITLE_END	Development\tagSECTITLE_START	Experiments\tagSECTITLE_END	With\tagSENT_START	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	of\tagSENT_CONTENT	1,000\tagSENT_CONTENT	sentences\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	started\tagSENT_CONTENT	by\tagSENT_CONTENT	training\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	word_sense_disambiguation\tagtask	over\tagSENT_CONTENT	the\tagSENT_CONTENT	2-billion\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	ukWaC\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	raise\tagSENT_CONTENT	the\tagSENT_CONTENT	bar\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	test\tagSENT_CONTENT	-\tagSENT_CONTENT	set\tagSENT_CONTENT	experiment\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	word_sense_disambiguation\tagtask	found\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	development\tagSENT_CONTENT	-\tagSENT_CONTENT	set\tagSENT_CONTENT	experiment\tagSENT_CONTENT	.\tagSENT_END	Test\tagSECTITLE_START	Sets\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Yet\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	easily\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	modeling\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	context\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	considerable\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	using\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	phrases\tagSENT_CONTENT	or\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Potential\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	context2vec\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	learns\tagSENT_CONTENT	word_sense_disambiguation\tagtask	for\tagSENT_CONTENT	variablelength\tagSENT_CONTENT	contexts\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	
1702.08400	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Deep\tagSENT_START	-\tagSENT_CONTENT	layered\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	labeled\tagSENT_CONTENT	samples\tagSENT_CONTENT	boost\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	many\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	For\tagSENT_START	object\tagSENT_CONTENT	detection\tagSENT_CONTENT	or\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	transfer\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	dataset\tagSENT_CONTENT	by\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	it\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	relatively\tagSENT_CONTENT	small\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	digit\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	traffic\tagSENT_CONTENT	sign\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	Review\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	nearly\tagSENT_CONTENT	all\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Method\tagSECTITLE_END	Simultaneously\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	two\tagSENT_CONTENT	labeling\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	acquire\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	gradually\tagSENT_CONTENT	increase\tagSENT_CONTENT	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	Loss\tagSECTITLE_START	for\tagSECTITLE_CONTENT	Multiview\tagSECTITLE_CONTENT	Features\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	label\tagSENT_CONTENT	target\tagSENT_CONTENT	samples\tagSENT_CONTENT	with\tagSENT_CONTENT	high\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagSENT_CONTENT	2\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	samples\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	viewpoints\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_START	Procedure\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Labeling\tagSECTITLE_CONTENT	Method\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	both\tagSENT_CONTENT	source\tagSENT_CONTENT	samples\tagSENT_CONTENT	and\tagSENT_CONTENT	pseudo\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	samples\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	F\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagSENT_CONTENT	2\tagSENT_CONTENT	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	.\tagSENT_END	Batch\tagSECTITLE_START	Normalization\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Domain\tagSECTITLE_CONTENT	Adaptation\tagSECTITLE_END	Batch\tagSENT_START	normalization\tagSENT_CONTENT	(\tagSENT_CONTENT	BN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	whitens\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	effective\tagSENT_CONTENT	technique\tagSENT_CONTENT	to\tagSENT_CONTENT	accelerate\tagSENT_CONTENT	training\tagSENT_CONTENT	speed\tagSENT_CONTENT	and\tagSENT_CONTENT	enhance\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	.\tagSENT_END	Theorem\tagSECTITLE_START	1\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	Ben\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	David\tagSECTITLE_CONTENT	et\tagSECTITLE_CONTENT	al\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	2010\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Experiment\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	networks\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	dataset\tagSENT_CONTENT	contains\tagSENT_CONTENT	reviews\tagSENT_CONTENT	on\tagSENT_CONTENT	four\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	products\tagSENT_CONTENT	:\tagSENT_CONTENT	books\tagSENT_CONTENT	,\tagSENT_CONTENT	DVDs\tagSENT_CONTENT	,\tagSENT_CONTENT	electronics\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	kitchen\tagSENT_CONTENT	appliances\tagSENT_CONTENT	.\tagSENT_END	Baseline\tagSECTITLE_START	Methods\tagSECTITLE_END	Implementation\tagSECTITLE_START	Detail\tagSECTITLE_END	We\tagSENT_START	repeat\tagSENT_CONTENT	this\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	10\tagSENT_CONTENT	times\tagSENT_CONTENT	and\tagSENT_CONTENT	report\tagSENT_CONTENT	mean\tagmetric	accuracy\tagmetric	.\tagSENT_END	Experimental\tagSECTITLE_START	Result\tagSECTITLE_END	We\tagSENT_START	show\tagSENT_CONTENT	the\tagSENT_CONTENT	comparison\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	between\tagSENT_CONTENT	the\tagSENT_CONTENT	actual\tagSENT_CONTENT	labeling\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	target\tagSENT_CONTENT	samples\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	comparison\tagSENT_CONTENT	between\tagSENT_CONTENT	actual\tagSENT_CONTENT	labeling\tagSENT_CONTENT	method\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	accuracy\tagmetric	in\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	comparison\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	networks\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagSENT_CONTENT	tin\tagSENT_CONTENT	SVHN→MNIST\tagSENT_CONTENT	.\tagSENT_END	SYN\tagSECTITLE_START	DIGITS→SVHN\tagSECTITLE_END	Gradient\tagSECTITLE_START	stop\tagSECTITLE_CONTENT	branch\tagSECTITLE_END	We\tagSENT_START	select\tagSENT_CONTENT	randomly\tagSENT_CONTENT	31,367\tagSENT_CONTENT	samples\tagSENT_CONTENT	for\tagSENT_CONTENT	target\tagSENT_CONTENT	training\tagSENT_CONTENT	samples\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	samples\tagSENT_CONTENT	.\tagSENT_END	Gradient\tagSECTITLE_START	Stop\tagSECTITLE_CONTENT	Experiment\tagSECTITLE_END	A\tagSECTITLE_START	-\tagSECTITLE_CONTENT	distance\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	both\tagSENT_CONTENT	on\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	visual\tagSENT_CONTENT	recognition\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	other\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Acknowledgement\tagSECTITLE_END	Proof\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Theorem\tagSECTITLE_END	CNN\tagSECTITLE_START	Architectures\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	detail\tagSECTITLE_END	Supplementary\tagSECTITLE_START	experiments\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	MNIST→MNIST\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	M\tagSECTITLE_END	
P16-1001	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Semantic\tagSENT_START	parsers\tagSENT_CONTENT	map\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	statements\tagSENT_CONTENT	into\tagSENT_CONTENT	amr_parsing\tagtask	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	must\tagSENT_CONTENT	abstract\tagSENT_CONTENT	over\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	phenomena\tagSENT_CONTENT	,\tagSENT_CONTENT	resolve\tagSENT_CONTENT	anaphora\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	identify\tagSENT_CONTENT	word\tagSENT_CONTENT	senses\tagSENT_CONTENT	to\tagSENT_CONTENT	eliminate\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	interpretations\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	amr_parsing\tagtask	by\tagSENT_CONTENT	used\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	inference\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	highestscoring\tagSENT_CONTENT	maximum\tagSENT_CONTENT	spanning\tagSENT_CONTENT	connected\tagSENT_CONTENT	acyclic\tagSENT_CONTENT	graph\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	encounters\tagSENT_CONTENT	states\tagSENT_CONTENT	during\tagSENT_CONTENT	parsing\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	unlike\tagSENT_CONTENT	those\tagSENT_CONTENT	found\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	mistakes\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	states\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	increasingly\tagSENT_CONTENT	more\tagSENT_CONTENT	foreign\tagSENT_CONTENT	and\tagSENT_CONTENT	causing\tagSENT_CONTENT	errors\tagSENT_CONTENT	to\tagSENT_CONTENT	accumulate\tagSENT_CONTENT	.\tagSENT_END	1\tagSECTITLE_END	(\tagSENT_START	)\tagSENT_CONTENT	address\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	error\tagSENT_CONTENT	propagation\tagSENT_CONTENT	by\tagSENT_CONTENT	iteratively\tagSENT_CONTENT	adjusting\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	to\tagSENT_CONTENT	increasingly\tagSENT_CONTENT	expose\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	instances\tagSENT_END	The\tagSENT_START	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	affects\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	that\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	these\tagSENT_CONTENT	often\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	necessary\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	transition\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	standard\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	final\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	Score\tagSENT_CONTENT	of\tagSENT_CONTENT	0.70\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	newswire\tagmetric	corpus\tagmetric	of\tagSENT_CONTENT	LDC2013E117\tagSENT_END	amr_parsing\tagtask	of\tagSENT_CONTENT	4.5\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	points\tagSENT_CONTENT	from\tagSENT_CONTENT	imitation\tagSENT_CONTENT	learning\tagSENT_CONTENT	over\tagSENT_CONTENT	standard\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsing\tagSENT_CONTENT	is\tagSENT_CONTENT	orthogonal\tagSENT_CONTENT	to\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	from\tagSENT_CONTENT	additional\tagSENT_CONTENT	trained\tagSENT_CONTENT	analysers\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	reference\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labellers\tagSENT_CONTENT	,\tagSENT_CONTENT	incorporated\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Transition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	AMR\tagSECTITLE_CONTENT	parsing\tagSECTITLE_END	amr_parsing\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	wider\tagSENT_CONTENT	family\tagSENT_CONTENT	of\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	problems\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	seek\tagSENT_CONTENT	a\tagSENT_CONTENT	mapping\tagSENT_CONTENT	from\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	x\tagSENT_CONTENT	∈\tagSENT_CONTENT	X\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	output\tagSENT_CONTENT	y\tagSENT_CONTENT	∈\tagSENT_END	InsertBelow\tagSECTITLE_END	In\tagSENT_START	amr_parsing\tagtask	and\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	and\tagSENT_CONTENT	dedicated\tagSENT_CONTENT	transition\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	devised\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	any\tagSENT_CONTENT	stage\tagSENT_CONTENT	before\tagSENT_CONTENT	termination\tagSENT_CONTENT	some\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	nodes\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	labelled\tagSENT_CONTENT	with\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	others\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Imitation\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Structured\tagSECTITLE_CONTENT	Prediction\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	imitation\tagSENT_CONTENT	learning\tagSENT_CONTENT	literature\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	policyˆπpolicyˆ\tagSENT_CONTENT	policyˆπ\tagSENT_CONTENT	from\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	expert\tagSENT_CONTENT	generated\tagSENT_CONTENT	trajectories\tagSENT_CONTENT	is\tagSENT_CONTENT	termed\tagSENT_CONTENT	"\tagSENT_CONTENT	exact\tagSENT_END	V\tagSENT_START	-\tagSENT_CONTENT	DAGGER\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	variant\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	Vlachos\tagSENT_CONTENT	and\tagSENT_CONTENT	Clark\tagSENT_CONTENT	(\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Adapting\tagSECTITLE_START	imitation\tagSECTITLE_CONTENT	learning\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	AMR\tagSECTITLE_END	For\tagSENT_START	amr_parsing\tagtask	we\tagSENT_CONTENT	have\tagSENT_CONTENT	both\tagSENT_CONTENT	a\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	in\tagSENT_CONTENT	Smatch\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	arbitrary\tagSENT_CONTENT	RollOuts\tagSENT_CONTENT	.\tagSENT_END	Targeted\tagSECTITLE_START	exploration\tagSECTITLE_END	Using\tagSENT_START	imitation\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	address\tagSENT_CONTENT	error\tagSENT_CONTENT	propagation\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	provides\tagSENT_CONTENT	theoretical\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	ensuring\tagSENT_CONTENT	the\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	st\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	distribution\tagSENT_CONTENT	on\tagSENT_CONTENT	unseen\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Noise\tagSECTITLE_START	Reduction\tagSECTITLE_END	Different\tagSENT_START	samples\tagSENT_CONTENT	fora\tagSENT_CONTENT	RollOut\tagSENT_CONTENT	trajectory\tagSENT_CONTENT	using\tagSENT_CONTENT	V\tagSENT_CONTENT	-\tagSENT_CONTENT	DAGGER\tagSENT_CONTENT	or\tagSENT_CONTENT	SEARN\tagSENT_CONTENT	can\tagSENT_CONTENT	give\tagSENT_CONTENT	very\tagSENT_CONTENT	different\tagSENT_CONTENT	terminal\tagSENT_CONTENT	states\tagSENT_CONTENT	s\tagSENT_CONTENT	T\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graph\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	at\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	step\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	stochasticity\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	i.e.\tagSENT_CONTENT	an\tagSENT_CONTENT	individual\tagSENT_CONTENT	tuple\tagSENT_CONTENT	s\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	future\tagSENT_CONTENT	training\tagSENT_CONTENT	once\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	misclassified\tagSENT_CONTENT	α\tagSENT_CONTENT	times\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Transition\tagSECTITLE_START	System\tagSECTITLE_CONTENT	adaptations\tagSECTITLE_END	To\tagSENT_START	address\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	|A|\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	consider\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	when\tagSENT_CONTENT	labelling\tagSENT_CONTENT	anode\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	work\tagSENT_CONTENT	of\tagSENT_CONTENT	in\tagSENT_CONTENT	word\tagSENT_CONTENT	to\tagSENT_CONTENT	AMR\tagSENT_CONTENT	concept\tagSENT_CONTENT	mapping\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	since\tagSENT_CONTENT	38\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	amr_parsing\tagtask	do\tagSENT_CONTENT	not\tagSENT_CONTENT	exist\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Na¨ıveNa¨ıve\tagSECTITLE_START	Smatch\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	Loss\tagSECTITLE_CONTENT	Function\tagSECTITLE_END	Smatch\tagSENT_START	)\tagSENT_CONTENT	uses\tagSENT_CONTENT	heuristics\tagSENT_CONTENT	to\tagSENT_CONTENT	control\tagSENT_CONTENT	the\tagSENT_CONTENT	combinatorial\tagSENT_CONTENT	explosion\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	mappings\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	graphs\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	too\tagSENT_CONTENT	computationally\tagSENT_CONTENT	expensive\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	calculated\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	RollOut\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	This\tagSENT_START	can\tagSENT_CONTENT	result\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	actions\tagSENT_CONTENT	having\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	action\tagSENT_CONTENT	cost\tagSENT_CONTENT	,\tagSENT_CONTENT	reducing\tagSENT_CONTENT	the\tagSENT_CONTENT	signal\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	giving\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	dataset\tagSENT_CONTENT	used\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	newswire\tagSENT_CONTENT	(\tagSENT_CONTENT	proxy\tagSENT_CONTENT	)\tagSENT_CONTENT	section\tagSENT_CONTENT	of\tagSENT_CONTENT	LDC2014T12\tagdataset	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	7\tagSECTITLE_END	Imitation\tagSENT_START	Learning\tagSENT_CONTENT	with\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsing\tagSENT_CONTENT	0.68\tagSENT_CONTENT	0.73\tagSENT_CONTENT	0.70\tagSENT_CONTENT	:\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	of\tagSENT_CONTENT	4.7\tagSENT_CONTENT	points\tagSENT_CONTENT	from\tagSENT_CONTENT	imitation\tagSENT_CONTENT	learning\tagSENT_CONTENT	over\tagSENT_CONTENT	standard\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsing\tagSENT_CONTENT	is\tagSENT_CONTENT	orthogonal\tagSENT_CONTENT	to\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	exact\tagSENT_CONTENT	imitation\tagSENT_CONTENT	with\tagSENT_CONTENT	additional\tagSENT_CONTENT	trained\tagSENT_CONTENT	analysers\tagSENT_CONTENT	;\tagSENT_CONTENT	they\tagSENT_CONTENT	experience\tagSENT_CONTENT	again\tagSENT_CONTENT	of\tagSENT_CONTENT	2\tagSENT_CONTENT	points\tagSENT_CONTENT	from\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	Charniak\tagSENT_CONTENT	parser\tagSENT_CONTENT	)\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	OntoNotes\tagSENT_CONTENT	corpus\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	parser\tagSENT_CONTENT	used\tagSENT_CONTENT	here\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	further\tagSENT_CONTENT	gain\tagSENT_CONTENT	of\tagSENT_CONTENT	2\tagSENT_CONTENT	points\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeller\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	This\tagSENT_START	provides\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	information\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	0/1\tagSENT_CONTENT	binary\tagSENT_CONTENT	action\tagSENT_CONTENT	cost\tagSENT_CONTENT	in\tagSENT_CONTENT	DAGGER\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	Na¨ıveNa¨ıve\tagSENT_CONTENT	Smatch\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	approximation\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	actual\tagSENT_CONTENT	objective\tagSENT_CONTENT	function\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Other\tagSENT_START	strategies\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	mitigate\tagSENT_CONTENT	the\tagSENT_CONTENT	error\tagSENT_CONTENT	propagation\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Conclusions\tagSECTITLE_END	
blocksparsepaper	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Using\tagSENT_START	the\tagSENT_CONTENT	kernels\tagSENT_CONTENT	we\tagSENT_CONTENT	improve\tagSENT_CONTENT	upon\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	generative\tagSENT_CONTENT	modeling\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	images\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Dense\tagSECTITLE_START	weights\tagSECTITLE_END	Capabilities\tagSECTITLE_END	Benchmarks\tagSECTITLE_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	block\tagSECTITLE_CONTENT	size\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	features\tagSECTITLE_CONTENT	axis\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	hidden\tagSECTITLE_CONTENT	state\tagSECTITLE_CONTENT	size\tagSECTITLE_END	Experiments\tagSECTITLE_END	LSTMs\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Deep\tagSECTITLE_CONTENT	Updates\tagSECTITLE_END	Small\tagSECTITLE_START	-\tagSECTITLE_CONTENT	World\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	1-Dimensional\tagSECTITLE_START	Watts\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Strogatz\tagSECTITLE_END	Small\tagSECTITLE_START	-\tagSECTITLE_CONTENT	World\tagSECTITLE_CONTENT	LSTMs\tagSECTITLE_END	Binary\tagSECTITLE_START	Sentiment\tagSECTITLE_CONTENT	Representation\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	generative\tagSENT_CONTENT	results\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	usefulness\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	.\tagSENT_END	Block\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Sparse\tagSECTITLE_CONTENT	Convolutional\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Research\tagSECTITLE_START	Directions\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	compared\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	learned\tagSENT_CONTENT	generatively\tagSENT_CONTENT	on\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	reviews\tagSENT_CONTENT	data\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	dense\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	wider\tagSENT_CONTENT	and\tagSENT_CONTENT	sparse\tagSENT_CONTENT	variant\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	usefulness\tagSENT_CONTENT	for\tagSENT_CONTENT	classifying\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	1.35\tagSECTITLE_END	
D18-1238	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	gat\tagSENT_CONTENT	-\tagSENT_CONTENT	ing\tagSENT_CONTENT	functions\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	by\tagSENT_CONTENT	modeling\tagSENT_CONTENT	relationships\tagSENT_CONTENT	and\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	over\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	granular\tagSENT_CONTENT	sequence\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	enabling\tagSENT_CONTENT	question_answering\tagtask	that\tagSENT_CONTENT	is\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	long\tagSENT_CONTENT	and\tagSENT_CONTENT	short\tagSENT_CONTENT	term\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	effectively\tagSENT_CONTENT	testing\tagSENT_CONTENT	the\tagSENT_CONTENT	learner\tagSENT_CONTENT	's\tagSENT_CONTENT	capability\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	Thirdly\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	gates\tagSENT_CONTENT	are\tagSENT_CONTENT	formed\tagSENT_CONTENT	by\tagSENT_CONTENT	modeling\tagSENT_CONTENT	relationships\tagSENT_CONTENT	between\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	projections\tagSENT_CONTENT	(\tagmetric	n\tagmetric	-\tagmetric	gram\tagmetric	blocks\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	allowing\tagSENT_CONTENT	for\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	relationships\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	captured\tagSENT_CONTENT	.\tagSENT_END	DCU\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	standalone\tagSENT_CONTENT	(\tagSENT_CONTENT	without\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	fast\tagSENT_CONTENT	reading\tagSENT_CONTENT	and/or\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	gether\tagmetric	with\tagSENT_CONTENT	RNN\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	DCU\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	more\tagSENT_CONTENT	expressive\tagSENT_CONTENT	reading\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	,\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	NarrativeQA\tagdataset	.\tagSENT_END	Dilated\tagSECTITLE_START	Compositional\tagSECTITLE_CONTENT	Units\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DCU\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Dilated\tagSECTITLE_START	Composition\tagSECTITLE_CONTENT	Mechanism\tagSECTITLE_END	The\tagSENT_START	final\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	vectors\tagmetric	which\tagSENT_CONTENT	retains\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	inputs\tagSENT_CONTENT	.\tagSENT_END	Fold\tagSECTITLE_START	Operation\tagSECTITLE_END	(\tagSENT_START	2\tagSENT_CONTENT	)\tagSENT_CONTENT	Span\tagSENT_CONTENT	Prediction\tagSENT_CONTENT	Architecture\tagSENT_CONTENT	(\tagSENT_CONTENT	center\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Multiple\tagSENT_CONTENT	Choice\tagSENT_CONTENT	Architecture\tagSENT_CONTENT	(\tagSENT_CONTENT	right\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Unfold\tagSECTITLE_START	Operation\tagSECTITLE_END	Given\tagSENT_START	the\tagSENT_CONTENT	transformed\tagSENT_CONTENT	tokens\tagSENT_CONTENT	¯\tagSENT_CONTENT	w\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	¯\tagSENT_CONTENT	w\tagSENT_CONTENT	2\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	¯\tagSENT_CONTENT	w\tagSENT_CONTENT	/r\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	then\tagSENT_CONTENT	expand\tagSENT_CONTENT	/\tagSENT_CONTENT	unfold\tagSENT_CONTENT	them\tagmetric	into\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	sequence\tagSENT_CONTENT	length\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	main\tagSENT_CONTENT	rationale\tagSENT_CONTENT	for\tagSENT_CONTENT	unfolding\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	enable\tagSENT_CONTENT	question_answering\tagtask	over\tagSENT_CONTENT	multiple\tagSENT_CONTENT	blocks\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	granularities\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Granular\tagSECTITLE_CONTENT	Reasoning\tagSECTITLE_END	As\tagSENT_START	such\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	value\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	unigram\tagmetric	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	j\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	projection\tagSENT_CONTENT	of\tagSENT_CONTENT	every\tagSENT_CONTENT	single\tagSENT_CONTENT	token\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	critical\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	prevents\tagSENT_CONTENT	identical\tagSENT_CONTENT	gating\tagSENT_CONTENT	vectors\tagSENT_CONTENT	across\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	Encoding\tagSECTITLE_START	Operation\tagSECTITLE_END	Simple\tagSECTITLE_START	Encoding\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	since\tagSENT_CONTENT	our\tagSENT_CONTENT	gating\tagSENT_CONTENT	function\tagSENT_CONTENT	is\tagSENT_CONTENT	learned\tagSENT_CONTENT	via\tagSENT_CONTENT	question_answering\tagtask	over\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	granular\tagSENT_CONTENT	sequence\tagSENT_CONTENT	blocks\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	captures\tagSENT_CONTENT	more\tagSENT_CONTENT	compositionality\tagSENT_CONTENT	and\tagSENT_CONTENT	long\tagSENT_CONTENT	range\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Recurrent\tagSECTITLE_START	Encoding\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DCU\tagSECTITLE_CONTENT	cell\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Overall\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	Architectures\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	multiple\tagSENT_CONTENT	-\tagSENT_CONTENT	choice\tagSENT_CONTENT	based\tagSENT_CONTENT	(\tagSENT_CONTENT	RACE\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	span\tagSENT_CONTENT	prediction\tagSENT_CONTENT	RC\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	SearchQA\tagdataset	,\tagSENT_CONTENT	NarrativeQA\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Multiple\tagSECTITLE_START	Choice\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	Multiple\tagSENT_CONTENT	Choice\tagSENT_CONTENT	(\tagSENT_CONTENT	MCQ\tagSENT_CONTENT	)\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	three\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	Passage\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	Q\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Answers\tagSENT_CONTENT	(\tagSENT_CONTENT	A\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	three\tagSENT_CONTENT	-\tagSENT_CONTENT	way\tagSENT_CONTENT	EM\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	EM\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	,\tagSENT_CONTENT	Q\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	EM\tagmetric	(\tagSENT_CONTENT	Q\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	EM\tagmetric	(\tagSENT_CONTENT	P\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Subsequently\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	B(P\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Motivated\tagSENT_START	by\tagSENT_CONTENT	the\tagmetric	work\tagmetric	in\tagSENT_CONTENT	retrievalbased\tagSENT_CONTENT	QA\tagSENT_CONTENT	(\tagSENT_CONTENT	Severyn\tagSENT_CONTENT	and\tagSENT_CONTENT	Moschitti\tagSENT_CONTENT	,\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	word\tagSENT_CONTENT	overlap\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	answer\tagSENT_CONTENT	candidate\tagSENT_CONTENT	.\tagSENT_END	Span\tagSECTITLE_START	Prediction\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	Span\tagSENT_CONTENT	Prediction\tagSENT_CONTENT	Model\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	predict\tagSENT_CONTENT	a\tagSENT_CONTENT	span\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_CONTENT	where\tagSENT_CONTENT	P\tagSENT_CONTENT	[\tagSENT_CONTENT	s\tagSENT_CONTENT	:\tagSENT_CONTENT	e\tagSENT_CONTENT	]\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	.\tagSENT_END	Bi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	The\tagSENT_START	start\tagSENT_CONTENT	pointer\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	pointer\tagSENT_CONTENT	are\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	F\tagmetric	(\tagSENT_CONTENT	H\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagmetric	(\tagSENT_CONTENT	H\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_END	F\tagmetric	(\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	transform\tagSENT_CONTENT	,\tagSENT_CONTENT	projecting\tagSENT_CONTENT	each\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	scalar\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	pass\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	into\tagSENT_CONTENT	softmax\tagSENT_CONTENT	functions\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	probability\tagSENT_CONTENT	distributions\tagSENT_CONTENT	.\tagSENT_END	During\tagSENT_START	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Empirical\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Datasets\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	four\tagSENT_CONTENT	options\tagSENT_CONTENT	each\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	involves\tagSENT_CONTENT	extracting\tagSENT_CONTENT	passages\tagSENT_CONTENT	from\tagSENT_CONTENT	search\tagSENT_CONTENT	engine\tagSENT_CONTENT	results\tagSENT_CONTENT	and\tagSENT_CONTENT	requiring\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	and\tagSENT_CONTENT	reading\tagSENT_CONTENT	these\tagSENT_CONTENT	search\tagSENT_CONTENT	snippets\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	from\tagSENT_CONTENT	many\tagSENT_CONTENT	RC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	handwritten\tagSENT_CONTENT	by\tagSENT_CONTENT	human\tagSENT_CONTENT	annotators\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	RACE\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	RACE\tagSENT_CONTENT	-\tagSENT_CONTENT	M\tagSENT_CONTENT	and\tagSENT_CONTENT	RACE\tagSENT_CONTENT	-\tagSENT_CONTENT	H\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	them\tagmetric	separately\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	SearchQA\tagdataset	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	evaluates\tagSENT_CONTENT	unigram\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagSENT_CONTENT	EM\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	Competitor\tagSECTITLE_START	Methods\tagSECTITLE_END	RACE\tagSECTITLE_END	AMANDA\tagSENT_START	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	factor\tagSENT_CONTENT	selfattention\tagSENT_CONTENT	module\tagSENT_CONTENT	,\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	focused\tagSENT_CONTENT	span\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Methods\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Word\tagSENT_START	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	initialized\tagSENT_CONTENT	with\tagSENT_CONTENT	300d\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagmetric	vectors\tagmetric	and\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuned\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	NarrativeQA\tagdataset	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Rouge\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	score\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	approximate\tagSENT_CONTENT	answer\tagSENT_CONTENT	relative\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	written\tagSENT_CONTENT	answer\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	RACE\tagSECTITLE_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	finding\tagSENT_CONTENT	highlights\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	designing\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	at\tagSENT_CONTENT	hand\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	SearchQA\tagSECTITLE_END	Contrary\tagSENT_START	to\tagSENT_CONTENT	MCQ\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	Model\tagSENT_CONTENT	BLEU-1\tagSENT_CONTENT	BLEU-\tagmetric	 \tagSENT_CONTENT	Sim\tagSENT_CONTENT	-\tagSENT_CONTENT	DCU\tagSENT_CONTENT	model\tagSENT_CONTENT	could\tagSENT_CONTENT	not\tagSENT_CONTENT	achieve\tagSENT_CONTENT	comparable\tagSENT_CONTENT	results\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	DCU\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	NarrativeQA\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	As\tagSENT_START	such\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	often\tagSENT_CONTENT	emphasize\tagSENT_CONTENT	the\tagSENT_CONTENT	extent\tagSENT_CONTENT	of\tagSENT_CONTENT	compositional\tagSENT_CONTENT	and\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Recent\tagSENT_START	work\tagSENT_CONTENT	also\tagSENT_CONTENT	investigates\tagSENT_CONTENT	the\tagSENT_CONTENT	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	pretraining\tagSENT_CONTENT	on\tagSENT_CONTENT	auxilliary\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	matching\tagSENT_CONTENT	/\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
W17-4422	title\tagSECTITLE_END	Transfer\tagSENT_START	Learning\tagSENT_CONTENT	and\tagSENT_CONTENT	Sentence\tagSENT_CONTENT	Level\tagSENT_CONTENT	Features\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	on\tagSENT_CONTENT	Tweets\tagSENT_END	abstract\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	we\tagSENT_CONTENT	exploit\tagSENT_CONTENT	additional\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	named_entity_recognition\tagtask	differ\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Named\tagSENT_START	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	shared\tagSENT_START	task\tagSENT_CONTENT	on\tagSENT_CONTENT	"\tagSENT_CONTENT	Novel\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	"\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	submitted\tagSENT_CONTENT	solution\tagSENT_CONTENT	reached\tagSENT_CONTENT	an\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	of\tagSENT_CONTENT	41.76\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	57.98\tagSENT_CONTENT	on\tagSENT_CONTENT	surface\tagSENT_CONTENT	form\tagSENT_CONTENT	annotations\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_START	Description\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	Long\tagSENT_CONTENT	Short\tagSENT_CONTENT	Term\tagSENT_CONTENT	Memory\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	Hochreiter\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	named_entity_recognition\tagtask	fora\tagSENT_CONTENT	linear\tagSENT_CONTENT	chain\tagSENT_CONTENT	Conditional\tagSENT_CONTENT	Random\tagSENT_CONTENT	Field\tagSENT_CONTENT	(\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	Named\tagSENT_CONTENT	Entity\tagSENT_CONTENT	tags\tagSENT_CONTENT	y\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_END	Basic\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	Labeling\tagSECTITLE_CONTENT	System\tagSECTITLE_END	φ\tagSENT_START	is\tagSENT_CONTENT	named_entity_recognition\tagtask	parametrized\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	Θ.\tagSENT_END	named_entity_recognition\tagtask	scores\tagSENT_CONTENT	A\tagSENT_CONTENT	are\tagSENT_CONTENT	initialized\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	uniform\tagSENT_CONTENT	distribution\tagSENT_CONTENT	with\tagSENT_CONTENT	mean\tagSENT_CONTENT	zero\tagSENT_CONTENT	and\tagSENT_CONTENT	variance\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	uniform\tagSENT_CONTENT	Glorot\tagSENT_CONTENT	initialization\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Transfer\tagSECTITLE_START	Learning\tagSECTITLE_END	Incorporating\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Level\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	setting\tagSENT_CONTENT	we\tagSENT_CONTENT	take\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	f\tagmetric	sent\tagSENT_CONTENT	=\tagSENT_CONTENT	F\tagSENT_END	:\tagSENT_START	We\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	tag\tagSENT_CONTENT	scores\tagSENT_CONTENT	s\tagSENT_CONTENT	sent\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	Ntags\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	f\tagmetric	sent\tagSENT_CONTENT	:\tagSENT_END	Combined\tagSECTITLE_START	System\tagSECTITLE_END	named_entity_recognition\tagtask	are\tagSENT_CONTENT	:\tagSENT_CONTENT	upper\tagSENT_CONTENT	,\tagSENT_CONTENT	lower\tagSENT_CONTENT	,\tagSENT_CONTENT	punctuation\tagSENT_CONTENT	,\tagSENT_CONTENT	numeric\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Preprocessing\tagSECTITLE_END	Model\tagSECTITLE_START	Parameters\tagSECTITLE_END	Experiments\tagSECTITLE_START	Performed\tagSECTITLE_CONTENT	After\tagSECTITLE_CONTENT	The\tagSECTITLE_CONTENT	Submission\tagSECTITLE_END	Results\tagSECTITLE_END	Discussion\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	described\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	on\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	extends\tagSENT_CONTENT	a\tagSENT_CONTENT	basic\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	
P15-1061	title\tagSECTITLE_END	Classifying\tagSENT_START	relationship_extraction\tagtask	by\tagSENT_CONTENT	Ranking\tagSENT_CONTENT	with\tagSENT_CONTENT	Convolutional\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_END	abstract\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	semantic\tagSENT_CONTENT	processing\tagSENT_CONTENT	task\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	still\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	costly\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	tackle\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	convo\tagSENT_CONTENT	-\tagSENT_CONTENT	lutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	performs\tagSENT_CONTENT	classification\tagSENT_CONTENT	by\tagSENT_CONTENT	ranking\tagSENT_CONTENT	(\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	perform\tagSENT_CONTENT	experiments\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	designed\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	classifying\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	marked\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	outperform\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	achieve\tagSENT_CONTENT	a\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	84.1\tagSENT_CONTENT	without\tagSENT_CONTENT	using\tagSENT_CONTENT	any\tagSENT_CONTENT	costly\tagSENT_CONTENT	handcrafted\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	task\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	normally\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	step\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	complex\tagSENT_CONTENT	NLP\tagSENT_CONTENT	applications\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answering\tagSENT_CONTENT	and\tagSENT_CONTENT	automatic\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	construction\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	reason\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	availability\tagSENT_CONTENT	of\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	classifying\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	marked\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	has\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	aim\tagSENT_CONTENT	of\tagSENT_CONTENT	reducing\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	handcrafted\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	anew\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	name\tagSENT_CONTENT	Classification\tagSENT_CONTENT	by\tagSENT_CONTENT	Ranking\tagSENT_CONTENT	CNN\tagSENT_CONTENT	(\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	Section\tagSENT_CONTENT	5\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	discuss\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	for\tagSENT_CONTENT	other\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	transforms\tagSENT_CONTENT	words\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	that\tagSENT_CONTENT	capture\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Position\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	information\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	needed\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	relation\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	target\tagSENT_CONTENT	nouns\tagSENT_CONTENT	normally\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	words\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	nouns\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	Representation\tagSECTITLE_END	In\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	these\tagSENT_CONTENT	issues\tagSENT_CONTENT	when\tagSENT_CONTENT	creating\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	text\tagSENT_CONTENT	segments\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	sizes\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	characterlevel\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	sizes\tagSENT_CONTENT	(\tagSENT_CONTENT	dos\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Then\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	combines\tagSENT_CONTENT	these\tagSENT_CONTENT	local\tagSENT_CONTENT	features\tagSENT_CONTENT	using\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	create\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	-\tagSENT_CONTENT	sized\tagSENT_CONTENT	vector\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	is\tagSENT_START	the\tagSENT_CONTENT	weight\tagSENT_CONTENT	matrix\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	the\tagSENT_CONTENT	hyperbolic\tagSENT_CONTENT	tangent\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Class\tagSECTITLE_START	embeddings\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Scoring\tagSECTITLE_END	Training\tagSECTITLE_START	Procedure\tagSECTITLE_END	The\tagSENT_START	number\tagSENT_CONTENT	of\tagSENT_CONTENT	classes\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	dataset\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	is\tagSENT_CONTENT	small\tagSENT_CONTENT	.\tagSENT_END	Special\tagSECTITLE_START	Treatment\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Artificial\tagSECTITLE_CONTENT	Classes\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	artificial\tagSENT_CONTENT	class\tagSENT_CONTENT	Other\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	nine\tagSENT_CONTENT	relation\tagSENT_CONTENT	classes\tagSENT_CONTENT	of\tagSENT_CONTENT	interest\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	Other\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	noisy\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	groups\tagSENT_CONTENT	many\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	that\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	much\tagSENT_CONTENT	in\tagSENT_CONTENT	common\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metric\tagSECTITLE_END	This\tagSENT_START	dataset\tagSENT_CONTENT	contains\tagSENT_CONTENT	10,717\tagSENT_CONTENT	examples\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	9\tagSENT_CONTENT	different\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	artificial\tagSENT_CONTENT	relation\tagSENT_CONTENT	Other\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	example\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	nine\tagSENT_CONTENT	main\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	example\tagSENT_CONTENT	contains\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	marked\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	taking\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	about\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_END	We\tagSENT_START	score\tagSENT_CONTENT	our\tagSENT_CONTENT	systems\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	official\tagSENT_CONTENT	scorer\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	computes\tagSENT_CONTENT	the\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	averaged\tagSENT_CONTENT	F1-scores\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	nine\tagSENT_CONTENT	actual\tagSENT_CONTENT	relations\tagSENT_CONTENT	(\tagSENT_CONTENT	excluding\tagSENT_CONTENT	Other\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	takes\tagSENT_CONTENT	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_CONTENT	Initialization\tagSECTITLE_END	Neural\tagSECTITLE_START	Network\tagSECTITLE_CONTENT	Hyper\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	parameter\tagSECTITLE_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	Word\tagSECTITLE_START	Position\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Input\tagSECTITLE_CONTENT	Text\tagSECTITLE_CONTENT	Span\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	experiments\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	we\tagSENT_CONTENT	assess\tagSENT_CONTENT	the\tagSENT_CONTENT	impact\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	word\tagSENT_CONTENT	position\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	WPE\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	simpler\tagSENT_CONTENT	alternative\tagSENT_CONTENT	approach\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	almost\tagSENT_CONTENT	as\tagSENT_CONTENT	effective\tagSENT_CONTENT	as\tagSENT_CONTENT	WPEs\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	main\tagSENT_CONTENT	idea\tagSENT_CONTENT	behind\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	WPEs\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	some\tagSENT_CONTENT	hint\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	how\tagSENT_CONTENT	close\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	nouns\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	closer\tagSENT_CONTENT	words\tagSENT_CONTENT	have\tagSENT_CONTENT	more\tagSENT_CONTENT	impact\tagSENT_CONTENT	than\tagSENT_CONTENT	distant\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	hypothesize\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	needed\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	appear\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	target\tagSENT_CONTENT	nouns\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	this\tagSENT_CONTENT	strategy\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	a\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	82.8\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	result\tagSENT_CONTENT	as\tagSENT_CONTENT	good\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	F1\tagSENT_CONTENT	of\tagSENT_CONTENT	83.0\tagSENT_CONTENT	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	experiments\tagSENT_CONTENT	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	use\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	with\tagSENT_CONTENT	full\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	WPEs\tagSENT_CONTENT	.\tagSENT_END	Full\tagSECTITLE_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Omitting\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Embedding\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	artificial\tagSECTITLE_CONTENT	class\tagSECTITLE_CONTENT	Other\tagSECTITLE_END	CR\tagSECTITLE_START	-\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	versus\tagSECTITLE_CONTENT	CNN+Softmax\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	we\tagSENT_CONTENT	report\tagSENT_CONTENT	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	comparing\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	with\tagSENT_CONTENT	CNN+Softmax\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	State\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	art\tagSECTITLE_END	It\tagSENT_START	obtains\tagSENT_CONTENT	an\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	82.2\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	result\tagSENT_CONTENT	at\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	.\tagSENT_END	Their\tagSENT_START	method\tagSENT_CONTENT	is\tagSENT_CONTENT	named\tagSENT_CONTENT	the\tagSENT_CONTENT	matrix\tagSENT_CONTENT	-\tagSENT_CONTENT	vector\tagSENT_CONTENT	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	MVRNN\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	achieves\tagSENT_CONTENT	a\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	82.4\tagSENT_CONTENT	when\tagSENT_CONTENT	POS\tagSENT_CONTENT	,\tagSENT_CONTENT	NER\tagSENT_CONTENT	and\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	Their\tagSENT_START	classifier\tagSENT_CONTENT	achieves\tagSENT_CONTENT	a\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	82.7\tagSENT_CONTENT	when\tagSENT_CONTENT	adding\tagSENT_CONTENT	a\tagSENT_CONTENT	handcrafted\tagSENT_CONTENT	feature\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	.\tagSENT_END	present\tagSENT_START	the\tagSENT_CONTENT	Factor\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	Compositional\tagSENT_CONTENT	Embedding\tagSENT_CONTENT	Model\tagSENT_CONTENT	(\tagSENT_CONTENT	FCM\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	a\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	83.0\tagSENT_CONTENT	by\tagSENT_CONTENT	deriving\tagSENT_CONTENT	sentencelevel\tagSENT_CONTENT	and\tagSENT_CONTENT	substructure\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	from\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	dependency\tagSENT_CONTENT	trees\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Most\tagSECTITLE_START	Representative\tagSECTITLE_CONTENT	Trigrams\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	each\tagSECTITLE_CONTENT	Relation\tagSECTITLE_END	The\tagSENT_START	most\tagSENT_CONTENT	representative\tagSENT_CONTENT	trigram\tagSENT_CONTENT	in\tagSENT_CONTENT	x\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	different\tagSENT_CONTENT	trigrams\tagSENT_CONTENT	play\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	informative\tagSENT_CONTENT	tri\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	for\tagSENT_CONTENT	Entity\tagSENT_CONTENT	-\tagSENT_CONTENT	Origin(e1,e2\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	"\tagSENT_CONTENT	away\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	reverse\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	EntityOrigin(e2,e1\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	Origin\tagSENT_CONTENT	-\tagSENT_CONTENT	Entity\tagSENT_CONTENT	,\tagSENT_CONTENT	has\tagSENT_CONTENT	"\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	of\tagSENT_CONTENT	"\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	informative\tagSENT_CONTENT	trigram\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	results\tagSENT_CONTENT	area\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	models\tagSENT_CONTENT	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Over\tagSENT_START	the\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	various\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Among\tagSENT_START	the\tagSENT_CONTENT	different\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	strategies\tagSENT_CONTENT	,\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	NLP\tagSENT_CONTENT	task\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	(\tagSENT_CONTENT	dos\tagSENT_CONTENT	Santos\tagSENT_CONTENT	and\tagSENT_CONTENT	Zadrozny\tagSENT_CONTENT	,\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeling\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	hashtag\tagSENT_CONTENT	prediction\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	completion\tagSENT_CONTENT	and\tagSENT_CONTENT	response\tagSENT_CONTENT	matching\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	include\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	authors\tagSENT_CONTENT	tackle\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	assigns\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	-\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	to\tagSENT_CONTENT	every\tagSENT_CONTENT	node\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	.\tagSENT_END	propose\tagSENT_START	an\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	where\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	through\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	and\tagSENT_CONTENT	position\tagSENT_CONTENT	features\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	Classifier\tagSECTITLE_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	tackle\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	that\tagSENT_CONTENT	performs\tagSENT_CONTENT	classification\tagSENT_CONTENT	by\tagSENT_CONTENT	ranking\tagSENT_CONTENT	.\tagSENT_END	633\tagSECTITLE_END	
1709.04109	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	It\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	including\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	ofspeech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrase\tagSENT_CONTENT	chunking\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	NER\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	improved\tagSENT_CONTENT	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	conducting\tagSENT_CONTENT	other\tagSENT_CONTENT	related\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	named_entity_recognition\tagtask	or\tagSENT_CONTENT	chunking\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Word\tagSENT_START	embedding\tagSENT_CONTENT	techniques\tagSENT_CONTENT	represent\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	continuous\tagSENT_CONTENT	space\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	retain\tagSENT_CONTENT	named_entity_recognition\tagtask	among\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	LM\tagSECTITLE_START	-\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	CRF\tagSECTITLE_CONTENT	Framework\tagSECTITLE_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	task\tagSECTITLE_CONTENT	Learning\tagSECTITLE_CONTENT	Strategy\tagSECTITLE_END	This\tagSENT_START	phenomenon\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	further\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Character\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Highway\tagSECTITLE_START	Layer\tagSECTITLE_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	CRF\tagSECTITLE_START	for\tagSECTITLE_CONTENT	Sequence\tagSECTITLE_CONTENT	Labeling\tagSECTITLE_END	Consequently\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	build\tagSENT_CONTENT	a\tagmetric	CRF\tagmetric	layer\tagmetric	upon\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Language\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Joint\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	Experiments\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Network\tagSECTITLE_START	Training\tagSECTITLE_END	Performance\tagSECTITLE_START	Comparison\tagSECTITLE_END	part-of-speech_tagging\tagtask	Similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	NER\tagSENT_CONTENT	task\tagSENT_END	,\tagSENT_START	LM\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	all\tagSENT_CONTENT	baselines\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	Although\tagSENT_START	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	and\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	are\tagSENT_CONTENT	less\tagSENT_CONTENT	obvious\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL03\tagSENT_CONTENT	NER\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	considering\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	part-of-speech_tagging\tagtask	is\tagSENT_CONTENT	believed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	easier\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	NER\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	current\tagSENT_CONTENT	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	relatively\tagSENT_CONTENT	high\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	improvement\tagSENT_CONTENT	could\tagSENT_CONTENT	still\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	significant\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
50	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	The\tagSENT_START	annotators\tagSENT_CONTENT	identified\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	left\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	describes\tagSENT_CONTENT	temporal_information_extraction\tagtask	into\tagSENT_CONTENT	the\tagSENT_CONTENT	dramatic\tagSENT_CONTENT	changes\tagSENT_CONTENT	required\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	learning\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	and\tagSENT_CONTENT	experimental\tagSENT_CONTENT	setup\tagSENT_CONTENT	when\tagSENT_CONTENT	faced\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	complete\tagSENT_CONTENT	graph\tagSENT_CONTENT	labeling\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	most\tagSENT_CONTENT	obvious\tagSENT_CONTENT	shift\tagSENT_CONTENT	required\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	complete\tagSENT_CONTENT	graph\tagSENT_CONTENT	labeling\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Research\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	TempEval\tagSENT_CONTENT	contests\tagSENT_CONTENT	has\tagSENT_CONTENT	largely\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	are\tagSENT_CONTENT	not\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	to\tagSENT_CONTENT	approach\tagSENT_CONTENT	temporal_information_extraction\tagtask	with\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	and\tagSENT_CONTENT	comprehensively\tagSENT_CONTENT	address\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	recently\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	labeling\tagSENT_CONTENT	of\tagSENT_CONTENT	raw\tagSENT_CONTENT	text\tagSENT_CONTENT	without\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	challenge\tagSENT_CONTENT	ultimately\tagSENT_CONTENT	relied\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	meant\tagSENT_CONTENT	that\tagSENT_CONTENT	temporal_information_extraction\tagtask	was\tagSENT_CONTENT	largely\tagSENT_CONTENT	ignored\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	top\tagSENT_CONTENT	system\tagSENT_CONTENT	optimized\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	intentionally\tagSENT_CONTENT	left\tagSENT_CONTENT	many\tagSENT_CONTENT	pairs\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSECTITLE_START	Work\tagSECTITLE_END	Event\tagSECTITLE_START	Ordering\tagSECTITLE_CONTENT	Annotation\tagSECTITLE_END	temporal_information_extraction\tagtask	constructed\tagSENT_CONTENT	corpora\tagSENT_CONTENT	with\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	annotated\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	temporal_information_extraction\tagtask	were\tagSENT_CONTENT	only\tagSENT_CONTENT	annotated\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	was\tagSENT_CONTENT	judged\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	salient\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	annotator\tagSENT_CONTENT	.\tagSENT_END	temporal_information_extraction\tagtask	)\tagSENT_CONTENT	aimed\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	coverage\tagSENT_CONTENT	by\tagSENT_CONTENT	annotating\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	all\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	times\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	Events\tagSENT_CONTENT	,\tagSENT_CONTENT	times\tagSENT_CONTENT	,\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	ratio\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	to\tagSENT_CONTENT	events\tagSENT_CONTENT	+\tagSENT_CONTENT	times\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	various\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	Events\tagSECTITLE_START	Times\tagSECTITLE_CONTENT	Relations\tagSECTITLE_CONTENT	R\tagSECTITLE_END	annotated\tagSENT_START	temporal_information_extraction\tagtask	"\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	dependency\tagSENT_CONTENT	trees\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	though\tagSENT_CONTENT	they\tagSENT_CONTENT	only\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	.\tagSENT_END	compares\tagSENT_START	the\tagSENT_CONTENT	density\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	across\tagSENT_CONTENT	various\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	annotator\tagSENT_CONTENT	looked\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	decided\tagSENT_CONTENT	that\tagSENT_CONTENT	temporal_information_extraction\tagtask	exists\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	current\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopt\tagSENT_CONTENT	the\tagSENT_CONTENT	VAGUE\tagSENT_CONTENT	relation\tagSENT_CONTENT	,\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	TempEval\tagSENT_CONTENT	2007\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	force\tagSENT_CONTENT	our\tagSENT_CONTENT	annotators\tagSENT_CONTENT	to\tagSENT_CONTENT	indicate\tagSENT_CONTENT	pairs\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	no\tagSENT_CONTENT	clear\tagSENT_CONTENT	temporal_information_extraction\tagtask	exists\tagSENT_CONTENT	.\tagSENT_END	Event\tagSECTITLE_START	Ordering\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	In\tagSENT_START	part\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sparsity\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	available\tagSENT_CONTENT	training\tagSENT_CONTENT	corpora\tagSENT_CONTENT	,\tagSENT_CONTENT	most\tagSENT_CONTENT	existing\tagSENT_CONTENT	models\tagSENT_CONTENT	formulate\tagSENT_CONTENT	temporal_information_extraction\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	and/or\tagSENT_CONTENT	times\tagSENT_CONTENT	is\tagSENT_CONTENT	examined\tagSENT_CONTENT	and\tagSENT_CONTENT	classified\tagSENT_CONTENT	as\tagSENT_CONTENT	having\tagSENT_CONTENT	temporal_information_extraction\tagtask	or\tagSENT_CONTENT	not\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	performing\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	temporal_information_extraction\tagtask	also\tagSENT_CONTENT	took\tagSENT_CONTENT	this\tagSENT_CONTENT	pairwise\tagSENT_CONTENT	classification\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	event\tagSENT_CONTENT	-\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	event\tagSENT_CONTENT	-\tagSENT_CONTENT	event\tagSENT_CONTENT	temporal\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	systems\tagSENT_CONTENT	have\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	even\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	;\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	topranked\tagSENT_CONTENT	ordering\tagSENT_CONTENT	system\tagSENT_CONTENT	in\tagSENT_CONTENT	TempEval\tagSENT_CONTENT	2013\tagSENT_CONTENT	only\tagSENT_CONTENT	classified\tagSENT_CONTENT	relations\tagSENT_CONTENT	in\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	with\tagSENT_CONTENT	certain\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	.\tagSENT_END	Systems\tagSENT_START	have\tagSENT_CONTENT	tried\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	pair\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	classifications\tagSENT_CONTENT	satisfy\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	using\tagSENT_CONTENT	frameworks\tagSENT_CONTENT	like\tagSENT_CONTENT	integer\tagSENT_CONTENT	linear\tagSENT_CONTENT	programming\tagSENT_CONTENT	and\tagSENT_CONTENT	Markov\tagSENT_CONTENT	logic\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	temporal_information_extraction\tagtask	as\tagSENT_CONTENT	an\tagSENT_CONTENT	extensible\tagSENT_CONTENT	,\tagSENT_CONTENT	formal\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	TimeBank\tagSECTITLE_END	TimeBank\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Dense\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	Dense\tagSECTITLE_CONTENT	Ordering\tagSECTITLE_END	It\tagSENT_START	uses\tagSENT_CONTENT	TimeBank\tagdataset	annotated\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	annotates\tagSENT_CONTENT	the\tagSENT_CONTENT	edges\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	set\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	TimeBankDense\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	middle\tagSENT_CONTENT	ground\tagSENT_CONTENT	between\tagSENT_CONTENT	temporal_information_extraction\tagtask	:\tagSENT_CONTENT	BEFORE\tagSENT_CONTENT	,\tagSENT_CONTENT	AFTER\tagSENT_CONTENT	,\tagSENT_CONTENT	INCLUDES\tagSENT_CONTENT	,\tagSENT_CONTENT	IS\tagSENT_CONTENT	INCLUDED\tagSENT_CONTENT	,\tagSENT_CONTENT	SIMULTANEOUS\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	VAGUE\tagSENT_CONTENT	.\tagSENT_END	temporal_information_extraction\tagtask	for\tagSENT_CONTENT	not\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	because\tagSENT_CONTENT	we\tagSENT_CONTENT	annotate\tagSENT_CONTENT	pairs\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	considered\tagSENT_CONTENT	in\tagSENT_CONTENT	previous\tagSENT_CONTENT	efforts\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	lean\tagSENT_CONTENT	toward\tagSENT_CONTENT	higher\tagSENT_CONTENT	annotator\tagSENT_CONTENT	agreement\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	their\tagSENT_CONTENT	semantics\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	allows\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	separate\tagSENT_CONTENT	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	desired\tagSENT_CONTENT	.\tagSENT_END	TimeBank\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Dense\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	Count\tagSECTITLE_END	shows\tagSENT_START	temporal_information_extraction\tagtask	that\tagSENT_CONTENT	result\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	VAGUE\tagSENT_CONTENT	relation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	how\tagSENT_CONTENT	often\tagSENT_CONTENT	each\tagSENT_CONTENT	occurred\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	mutual\tagSENT_CONTENT	vague\tagSENT_CONTENT	:\tagSENT_END	Sieve\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Temporal\tagSECTITLE_CONTENT	Ordering\tagSECTITLE_END	The\tagSENT_START	sieve\tagSENT_CONTENT	architecture\tagSENT_CONTENT	applies\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	one\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	label\tagSENT_CONTENT	the\tagSENT_CONTENT	edges\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	individual\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	are\tagSENT_CONTENT	called\tagSENT_CONTENT	sieves\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	each\tagSENT_CONTENT	sieve\tagSENT_CONTENT	passes\tagSENT_CONTENT	temporal_information_extraction\tagtask	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	sieve\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	architecture\tagSENT_CONTENT	avoids\tagSENT_CONTENT	inconsistent\tagSENT_CONTENT	graphs\tagSENT_CONTENT	by\tagSENT_CONTENT	inferring\tagSENT_CONTENT	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	each\tagSENT_CONTENT	sieve\tagSENT_CONTENT	's\tagSENT_CONTENT	output\tagSENT_CONTENT	before\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	is\tagSENT_CONTENT	passed\tagSENT_CONTENT	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	one\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	architecture\tagSENT_CONTENT	facilitates\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	following\tagSENT_CONTENT	subsections\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	CAEVO\tagSENT_CONTENT	.\tagSENT_END	Deterministic\tagSECTITLE_START	Sieves\tagSECTITLE_END	Many\tagSENT_START	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	share\tagSENT_CONTENT	common\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	attributes\tagSENT_CONTENT	that\tagSENT_CONTENT	clearly\tagSENT_CONTENT	indicate\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Verb\tagSECTITLE_START	/\tagSECTITLE_CONTENT	Timex\tagSECTITLE_CONTENT	Adjacency\tagSECTITLE_END	Timex\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Timex\tagSECTITLE_CONTENT	Relations\tagSECTITLE_END	Given\tagSENT_START	two\tagSENT_CONTENT	time\tagSENT_CONTENT	spans\tagSENT_CONTENT	with\tagSENT_CONTENT	defined\tagSENT_CONTENT	starting\tagSENT_CONTENT	and\tagSENT_CONTENT	ending\tagSENT_CONTENT	time\tagSENT_CONTENT	points\tagSENT_CONTENT	,\tagSENT_CONTENT	temporal_information_extraction\tagtask	is\tagSENT_CONTENT	unambiguous\tagSENT_CONTENT	.\tagSENT_END	Reporting\tagSECTITLE_START	Event\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	DCT\tagSECTITLE_END	More\tagSENT_START	sophisticated\tagSENT_CONTENT	reasoners\tagSENT_CONTENT	run\tagSENT_CONTENT	before\tagSENT_CONTENT	this\tagSENT_CONTENT	one\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	temporal_information_extraction\tagtask	when\tagSENT_CONTENT	appropriate\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	this\tagSENT_CONTENT	sieve\tagSENT_CONTENT	cleans\tagSENT_CONTENT	up\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	reporting\tagSENT_CONTENT	-\tagSENT_CONTENT	DCT\tagSENT_CONTENT	edges\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	still\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	.\tagSENT_END	Reporting\tagSECTITLE_START	Event\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Dominated\tagSECTITLE_CONTENT	Event\tagSECTITLE_END	General\tagSECTITLE_START	Event\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Dominated\tagSECTITLE_CONTENT	Event\tagSECTITLE_END	Reichenbach\tagSECTITLE_START	Rules\tagSECTITLE_END	E\tagSECTITLE_START	,\tagSECTITLE_CONTENT	R\tagSECTITLE_CONTENT	S\tagSECTITLE_END	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	discourse\tagSENT_CONTENT	.\tagSENT_END	we\tagSENT_START	can\tagSENT_CONTENT	enumerate\tagSENT_CONTENT	temporal_information_extraction\tagtask	that\tagSENT_CONTENT	might\tagSENT_CONTENT	hold\tagSENT_CONTENT	between\tagSENT_CONTENT	E\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	E\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	interpret\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	disjunction\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	possible\tagSENT_CONTENT	orderings\tagSENT_CONTENT	of\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_END	We\tagSENT_START	identify\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	tense\tagSENT_CONTENT	/\tagSENT_CONTENT	aspect\tagSENT_CONTENT	profile\tagSENT_CONTENT	pairs\tagSENT_CONTENT	that\tagSENT_CONTENT	unambiguously\tagSENT_CONTENT	yield\tagSENT_CONTENT	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	our\tagSENT_CONTENT	6\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	implement\tagSENT_CONTENT	them\tagSENT_CONTENT	as\tagSENT_CONTENT	rules\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Reichenbach\tagSENT_CONTENT	Sieve\tagSENT_CONTENT	.\tagSENT_END	WordNet\tagSECTITLE_START	Rules\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	news\tagSENT_CONTENT	articles\tagSENT_CONTENT	state\tagSENT_CONTENT	what\tagSENT_CONTENT	someone\tagSENT_CONTENT	said\tagSENT_CONTENT	multiple\tagSENT_CONTENT	times\tagSENT_CONTENT	without\tagSENT_CONTENT	revealing\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	events\tagSENT_CONTENT	.\tagSENT_END	All\tagSECTITLE_START	Vague\tagSECTITLE_END	Machine\tagSECTITLE_START	Learned\tagSECTITLE_CONTENT	Sieves\tagSECTITLE_END	Current\tagSENT_START	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	machine\tagSENT_CONTENT	learned\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	.\tagSENT_END	Event\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Time\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Event\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Time\tagSECTITLE_CONTENT	Edges\tagSECTITLE_END	Event\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Event\tagSECTITLE_CONTENT	Edges\tagSECTITLE_END	Event\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Event\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Event\tagSECTITLE_START	-\tagSECTITLE_CONTENT	DCT\tagSECTITLE_CONTENT	Edges\tagSECTITLE_END	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	creation\tagSENT_CONTENT	time\tagSENT_CONTENT	(\tagSENT_CONTENT	DCT\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	separately\tagSENT_CONTENT	classified\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Complete\tagSECTITLE_CONTENT	Sieve\tagSECTITLE_CONTENT	Gauntlet\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	These\tagSENT_START	experiments\tagSENT_CONTENT	highlight\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	is\tagSENT_CONTENT	anew\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	CAEVO\tagSENT_CONTENT	architecture\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	cascade\tagSENT_CONTENT	of\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	.\tagSENT_END	Ordered\tagSECTITLE_START	Sieves\tagSECTITLE_END	Dev\tagSECTITLE_END	Discussion\tagSECTITLE_END	This\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ClearTK\tagSENT_CONTENT	-\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	performance\tagSENT_CONTENT	(\tagSENT_CONTENT	36.26\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	TempEval\tagSENT_CONTENT	2013\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	performed\tagSENT_CONTENT	dramatically\tagSENT_CONTENT	worse\tagSENT_CONTENT	(\tagSENT_CONTENT	15.8\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	our\tagSENT_CONTENT	dense\tagSENT_CONTENT	relation\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	several\tagSENT_CONTENT	intangible\tagSENT_CONTENT	benefits\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagSENT_CONTENT	setup\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	n't\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	:\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	new\tagSENT_CONTENT	/\tagSENT_CONTENT	existing\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	extremely\tagSENT_CONTENT	quick\tagSENT_CONTENT	ablation\tagSENT_CONTENT	experiments\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	/\tagSENT_CONTENT	removing\tagSENT_CONTENT	sieves\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	facilitation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	of\tagSENT_CONTENT	specific\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	agnostic\tagSENT_CONTENT	to\tagSENT_CONTENT	global\tagSENT_CONTENT	constraints\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	pass\tagSENT_CONTENT	system\tagSENT_CONTENT	achieved\tagSENT_CONTENT	an\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	50.7\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	full\tagSENT_CONTENT	10\tagSENT_CONTENT	F1\tagSENT_CONTENT	points\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	All\tagSENT_CONTENT	-\tagSENT_CONTENT	Vague\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	14\tagSENT_CONTENT	%\tagSENT_CONTENT	relative\tagSENT_CONTENT	increase\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	two\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	TempEval\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	temporal_information_extraction\tagtask	(\tagSENT_CONTENT	the\tagSENT_CONTENT	focus\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	also\tagSENT_CONTENT	automatically\tagSENT_CONTENT	extracts\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	hope\tagSENT_CONTENT	it\tagSENT_CONTENT	encourages\tagSENT_CONTENT	further\tagSENT_CONTENT	dense\tagSENT_CONTENT	data\tagSENT_CONTENT	creation\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	
1805.06280	title\tagSECTITLE_END	A\tagSENT_START	Context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	Approach\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	using\tagSENT_CONTENT	Simple\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_END	abstract\tagSECTITLE_END	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	way\tagSENT_CONTENT	dialogue_act_classification\tagtask	are\tagSENT_CONTENT	annotated\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	approaches\tagSENT_CONTENT	used\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	conversation\tagSENT_CONTENT	for\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	Nevertheless\tagSENT_START	,\tagSENT_CONTENT	previous\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	utterance\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	and\tagSENT_CONTENT	only\tagSENT_CONTENT	very\tagSENT_CONTENT	few\tagSENT_CONTENT	consider\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	learning\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	dialogue_act_classification\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	utterance\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	notice\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	this\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Switchboard\tagSENT_CONTENT	Dialogue\tagSENT_CONTENT	Act\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	consideration\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	preceding\tagSENT_CONTENT	utterances\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	utterance\tagSENT_CONTENT	improves\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	aim\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	article\tagSENT_CONTENT	has\tagSENT_CONTENT	two\tagSENT_CONTENT	subgoals\tagSENT_CONTENT	:\tagSENT_CONTENT	first\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	DA\tagSENT_CONTENT	corpora\tagSENT_CONTENT	and\tagSENT_CONTENT	review\tagSENT_CONTENT	the\tagSENT_CONTENT	modelling\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	second\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	compare\tagSENT_CONTENT	its\tagSENT_CONTENT	results\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	DA\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	Including\tagSENT_START	context\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	3\tagmetric	%\tagmetric	higher\tagmetric	accuracy\tagmetric	.\tagSENT_END	-We\tagSENT_START	provide\tagSENT_CONTENT	detailed\tagSENT_CONTENT	insight\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	and\tagSENT_CONTENT	modelling\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	-We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieved\tagSENT_CONTENT	an\tagSENT_CONTENT	accu-1\tagSENT_CONTENT	Available\tagSENT_CONTENT	at\tagSENT_CONTENT	https://github.com/cgpotts/swda\tagSENT_CONTENT	racy\tagSENT_CONTENT	of\tagSENT_CONTENT	77.3\tagSENT_CONTENT	%\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	73.9\tagSENT_CONTENT	%\tagSENT_CONTENT	as\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	learning\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	-Benefits\tagSENT_START	of\tagSENT_CONTENT	using\tagSENT_CONTENT	context\tagSENT_CONTENT	arise\tagSENT_CONTENT	from\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	preceding\tagSENT_CONTENT	utterances\tagSENT_CONTENT	making\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	real\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	feeding\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	high\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	but\tagSENT_CONTENT	includes\tagSENT_CONTENT	future\tagSENT_CONTENT	utterances\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Annotation\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Dialogue\tagSECTITLE_CONTENT	Act\tagSECTITLE_CONTENT	Corpora\tagSECTITLE_END	Annotation\tagSENT_START	Process\tagSENT_CONTENT	and\tagSENT_CONTENT	Standards\tagSENT_CONTENT	:\tagSENT_CONTENT	Research\tagSENT_CONTENT	on\tagSENT_CONTENT	dialogue_act_classification\tagtask	became\tagSENT_CONTENT	important\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	commercial\tagSENT_CONTENT	reality\tagSENT_CONTENT	of\tagSENT_CONTENT	spoken\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	speech\tagSENT_START	act\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	later\tagSENT_CONTENT	modified\tagSENT_CONTENT	into\tagSENT_CONTENT	five\tagSENT_CONTENT	classes\tagSENT_CONTENT	(\tagSENT_CONTENT	Assertive\tagSENT_CONTENT	,\tagSENT_CONTENT	Directive\tagSENT_CONTENT	,\tagSENT_CONTENT	Commissive\tagSENT_CONTENT	,\tagSENT_CONTENT	Expressive\tagSENT_CONTENT	,\tagSENT_CONTENT	Declarative\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	Several\tagSENT_CONTENT	Layers\tagSENT_END	These\tagSENT_START	schemes\tagSENT_CONTENT	are\tagSENT_CONTENT	important\tagSENT_CONTENT	for\tagSENT_CONTENT	analysing\tagSENT_CONTENT	dialogues\tagSENT_CONTENT	or\tagSENT_CONTENT	building\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Nature\tagSENT_START	of\tagSENT_CONTENT	Discourse\tagSENT_CONTENT	in\tagSENT_CONTENT	Conversation\tagSENT_CONTENT	:\tagSENT_CONTENT	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	discourse\tagSENT_CONTENT	concept\tagSENT_CONTENT	that\tagSENT_CONTENT	means\tagSENT_CONTENT	the\tagSENT_CONTENT	DA\tagSENT_CONTENT	class\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	current\tagSENT_CONTENT	utterance\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	its\tagSENT_CONTENT	preceding\tagSENT_CONTENT	utterance\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	has\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	noted\tagSENT_CONTENT	that\tagSENT_CONTENT	prosodic\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	dialogue_act_classification\tagtask	for\tagSENT_CONTENT	certain\tagSENT_CONTENT	DA\tagSENT_CONTENT	types\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Modelling\tagSECTITLE_START	Approaches\tagSECTITLE_END	The\tagSENT_START	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	annotator\tagSENT_CONTENT	agreement\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	corpus\tagSENT_CONTENT	is\tagSENT_CONTENT	84\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	particular\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	still\tagSENT_CONTENT	far\tagSENT_CONTENT	from\tagSENT_CONTENT	achieving\tagSENT_CONTENT	human\tagmetric	accuracy\tagmetric	.\tagSENT_END	dialogue_act_classification\tagtask	:\tagSENT_END	Perhaps\tagSENT_START	most\tagSENT_CONTENT	research\tagSENT_CONTENT	in\tagSENT_CONTENT	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	conducted\tagSENT_CONTENT	at\tagSENT_CONTENT	utterance\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	emergence\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	also\tagSENT_CONTENT	gave\tagSENT_CONTENT	a\tagSENT_CONTENT	big\tagSENT_CONTENT	push\tagSENT_CONTENT	to\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Ina\tagSENT_START	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	most\tagSENT_CONTENT	utterances\tagSENT_CONTENT	are\tagSENT_CONTENT	very\tagSENT_CONTENT	short\tagSENT_CONTENT	;\tagSENT_CONTENT	hence\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	achieved\tagSENT_START	73.1\tagmetric	%\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	corpus\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	advanced\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	frameworks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	and\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	feature\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	utterance\tagSENT_CONTENT	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	further\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	DA\tagSENT_CONTENT	classes\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	field\tagSENT_CONTENT	(\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	can\tagSENT_CONTENT	seethe\tagSENT_CONTENT	past\tagSENT_CONTENT	and\tagSENT_CONTENT	future\tagSENT_CONTENT	utterances\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	within\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	limits\tagSENT_CONTENT	usage\tagSENT_CONTENT	in\tagSENT_CONTENT	dialogue_act_classification\tagtask	where\tagSENT_CONTENT	one\tagSENT_CONTENT	can\tagSENT_CONTENT	only\tagSENT_CONTENT	perceive\tagSENT_CONTENT	the\tagSENT_CONTENT	preceding\tagSENT_CONTENT	utterance\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	but\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	know\tagSENT_CONTENT	the\tagSENT_CONTENT	upcoming\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	and\tagSENT_CONTENT	regard\tagSENT_CONTENT	the\tagmetric	73.9\tagmetric	%\tagmetric	accuracy\tagmetric	)\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	corpus\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Approach\tagSECTITLE_END	Our\tagSENT_START	approach\tagSENT_CONTENT	takes\tagSENT_CONTENT	care\tagSENT_CONTENT	of\tagSENT_CONTENT	discourse\tagSENT_CONTENT	compositionality\tagSENT_CONTENT	while\tagSENT_CONTENT	recognising\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	We\tagSENT_START	represent\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	by\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	multiplicative\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	data\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	RNN\tagSENT_CONTENT	setup\tagSENT_CONTENT	for\tagSENT_CONTENT	learning\tagSENT_CONTENT	dialogue_act_classification\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	st\tagSENT_START	is\tagSENT_CONTENT	an\tagSENT_CONTENT	utterance\tagSENT_CONTENT	representation\tagSENT_CONTENT	derived\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	dialogue_act_classification\tagtask	label\tagSENT_CONTENT	da\tagSENT_CONTENT	t\tagSENT_CONTENT	.\tagSENT_END	t−2\tagSENT_START	derived\tagSENT_CONTENT	ash\tagSENT_CONTENT	t−1\tagSENT_CONTENT	and\tagSENT_CONTENT	h\tagSENT_CONTENT	t−2\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	to\tagSENT_CONTENT	recognize\tagSENT_CONTENT	dialogue_act_classification\tagtask	of\tagSENT_CONTENT	current\tagSENT_CONTENT	utterance\tagSENT_CONTENT	st\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	represented\tagSENT_CONTENT	by\tagSENT_CONTENT	ht\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	da\tagSENT_CONTENT	t\tagSENT_CONTENT	.\tagSENT_END	RNN\tagSECTITLE_END	Utterance\tagSECTITLE_START	Representation\tagSECTITLE_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	extract\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	.\tagSENT_END	Context\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	RNNs\tagSECTITLE_END	The\tagSENT_START	output\tagSENT_CONTENT	da\tagSENT_CONTENT	t\tagSENT_CONTENT	is\tagSENT_CONTENT	dialogue_act_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	utterance\tagSENT_CONTENT	st\tagSENT_CONTENT	calculated\tagSENT_CONTENT	using\tagSENT_CONTENT	ht\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	run\tagSENT_CONTENT	each\tagSENT_CONTENT	experiment\tagSENT_CONTENT	for\tagSENT_CONTENT	ten\tagSENT_CONTENT	times\tagSENT_CONTENT	:\tagSENT_CONTENT	Accuracy\tagmetric	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	article\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	detail\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	and\tagSENT_CONTENT	modelling\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	difference\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	way\tagSENT_CONTENT	DAs\tagSENT_CONTENT	are\tagSENT_CONTENT	annotated\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	way\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	modelled\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	this\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieved\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	77.34\tagSENT_CONTENT	%\tagSENT_CONTENT	with\tagSENT_CONTENT	context\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	73.96\tagSENT_CONTENT	%\tagSENT_CONTENT	without\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Acknowledgements\tagSECTITLE_END	Bibliographical\tagSECTITLE_START	References\tagSECTITLE_END	dialogue_act_classification\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	Bayesian\tagSENT_CONTENT	approach\tagSENT_CONTENT	.\tagSENT_END	Lexical\tagSENT_START	,\tagSENT_CONTENT	Prosodic\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Syntactic\tagSENT_CONTENT	Cues\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	In\tagSENT_START	The\tagSENT_CONTENT	ACL\tagSENT_CONTENT	/\tagSENT_CONTENT	COLING\tagSENT_CONTENT	Workshop\tagSENT_CONTENT	on\tagSENT_CONTENT	dialogue_act_classification\tagtask	and\tagSENT_CONTENT	Discourse\tagSENT_CONTENT	Markers\tagSENT_CONTENT	.\tagSENT_END	.\tagSECTITLE_START	Switchboard\tagSECTITLE_CONTENT	SWBD\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	DAMSL\tagSECTITLE_CONTENT	Shallow\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Discourse\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Function\tagSECTITLE_CONTENT	Annotation\tagSECTITLE_CONTENT	Coders\tagSECTITLE_CONTENT	Manual\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	draft\tagSECTITLE_CONTENT	13\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Technical\tagSECTITLE_CONTENT	Report\tagSECTITLE_CONTENT	97\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	01\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	University\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Colorado\tagSECTITLE_CONTENT	Institute\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Cognitive\tagSECTITLE_CONTENT	Science\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	pages\tagSECTITLE_CONTENT	225\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	233\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Kalchbrenner\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	N.\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Blunsom\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	P.\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2013\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Recurrent\tagSECTITLE_CONTENT	Convolutional\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Discourse\tagSECTITLE_CONTENT	Compositionality\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	In\tagSECTITLE_CONTENT	Workshop\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Continuous\tagSECTITLE_CONTENT	Vector\tagSECTITLE_CONTENT	Space\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	Domain\tagSENT_CONTENT	-\tagSENT_CONTENT	Independent\tagSENT_CONTENT	Conversations\tagSENT_CONTENT	Using\tagSENT_CONTENT	a\tagSENT_CONTENT	Deep\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	..\tagSENT_END	dialogue_act_classification\tagtask	using\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	with\tagSENT_CONTENT	CRF\tagSENT_CONTENT	.\tagSENT_END	dialogue_act_classification\tagtask	with\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	and\tagSENT_CONTENT	Convolutional\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	Context\tagSENT_CONTENT	Information\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	DNN\tagSENT_CONTENT	Framework\tagSENT_CONTENT	.\tagSENT_END	Ortega\tagSECTITLE_START	,\tagSECTITLE_CONTENT	D.\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Vu\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	N.\tagSECTITLE_CONTENT	T.\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2017\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Context\tagSECTITLE_CONTENT	Representation\tagSECTITLE_CONTENT	Learning\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Dialog\tagSECTITLE_CONTENT	Act\tagSECTITLE_CONTENT	Classification\tagSECTITLE_CONTENT	.\tagSECTITLE_END	A\tagSENT_START	Multiclassifier\tagSENT_CONTENT	Approach\tagSENT_CONTENT	to\tagSENT_CONTENT	Dialogue\tagSENT_CONTENT	dialogue_act_classification\tagtask	Using\tagSENT_CONTENT	Function\tagSENT_CONTENT	Words\tagSENT_CONTENT	.\tagSENT_END	Can\tagSENT_START	Prosody\tagSENT_CONTENT	Aid\tagSENT_CONTENT	dialogue_act_classification\tagtask	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	Conversational\tagSENT_CONTENT	Speech\tagSENT_CONTENT	?\tagSENT_END	.\tagSECTITLE_START	Error\tagSECTITLE_CONTENT	Handling\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Spoken\tagSECTITLE_CONTENT	Dialogue\tagSECTITLE_END	KTH\tagSECTITLE_START	Computer\tagSECTITLE_CONTENT	Science\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Communication\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Stolcke\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	A.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Ries\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	K.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Coccaro\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	N.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Shriberg\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	E.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Bates\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	R.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Jurafsky\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	D.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Taylor\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	P.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Martin\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	R.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Van\tagSECTITLE_CONTENT	Ess\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Dykema\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	C.\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Meteer\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	M.\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2000\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Dialogue\tagSECTITLE_CONTENT	Act\tagSECTITLE_CONTENT	Modeling\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Automatic\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Conversational\tagSECTITLE_END	dialogue_act_classification\tagtask	tagging\tagSENT_CONTENT	with\tagSENT_CONTENT	support\tagSENT_CONTENT	vector\tagSENT_CONTENT	machines\tagSENT_CONTENT	and\tagSENT_CONTENT	hidden\tagSENT_CONTENT	Markov\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	Synchronous\tagSENT_CONTENT	and\tagSENT_CONTENT	Asynchronous\tagSENT_CONTENT	Conversations\tagSENT_CONTENT	.\tagSENT_END	Preserving\tagSENT_START	Distributional\tagSENT_CONTENT	Information\tagSENT_CONTENT	in\tagSENT_CONTENT	Dialogue\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Semisupervised\tagSENT_START	Learning\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	Using\tagSENT_CONTENT	Sentence\tagSENT_CONTENT	Similarity\tagSENT_CONTENT	Based\tagSENT_CONTENT	on\tagSENT_CONTENT	Word\tagSENT_CONTENT	Embeddings\tagSENT_CONTENT	.\tagSENT_END	Appendix\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	state\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	RNN\tagSECTITLE_END	
P18-1061	title\tagSECTITLE_END	summarization\tagtask	by\tagSENT_CONTENT	Jointly\tagSENT_CONTENT	Learning\tagSENT_CONTENT	to\tagSENT_CONTENT	Score\tagSENT_CONTENT	and\tagSENT_CONTENT	Select\tagSENT_CONTENT	Sentences\tagSENT_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	score\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Traditional\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	identifying\tagSENT_CONTENT	important\tagSENT_CONTENT	content\tagSENT_CONTENT	,\tagSENT_CONTENT	usually\tagSENT_CONTENT	at\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Integer\tagSENT_START	Linear\tagSENT_CONTENT	Programming\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	treat\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	optimization\tagSENT_CONTENT	problem\tagSENT_CONTENT	under\tagSENT_CONTENT	some\tagSENT_CONTENT	constraints\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	At\tagSENT_START	each\tagSENT_CONTENT	step\tagSENT_CONTENT	during\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	extractor\tagSENT_CONTENT	reads\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	extracted\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	sentence\tagSENT_CONTENT	scoring\tagSENT_CONTENT	and\tagSENT_CONTENT	selection\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	extensively\tagSENT_CONTENT	studied\tagSENT_CONTENT	for\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	score\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	vertex\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	computed\tagSENT_CONTENT	using\tagSENT_CONTENT	graph\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	.\tagSENT_END	further\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	Hidden\tagSENT_CONTENT	Markov\tagSENT_CONTENT	Model\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	become\tagSENT_CONTENT	popular\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Problem\tagSECTITLE_START	Formulation\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	informative\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	meanings\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	the\tagmetric	score\tagmetric	of\tagSENT_CONTENT	an\tagSENT_CONTENT	output\tagSENT_CONTENT	summary\tagSENT_CONTENT	S\tagSENT_CONTENT	under\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	function\tagSENT_CONTENT	r(S|S\tagSENT_CONTENT	*\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	ROUGE\tagmetric	recall\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	r\tagSENT_CONTENT	(\tagSENT_CONTENT	·\tagSENT_CONTENT	)\tagSENT_CONTENT	considering\tagSENT_CONTENT	the\tagSENT_CONTENT	DUC\tagSENT_CONTENT	tasks\tagSENT_CONTENT	have\tagSENT_CONTENT	byte\tagSENT_CONTENT	length\tagSENT_CONTENT	limit\tagSENT_CONTENT	for\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	each\tagSENT_CONTENT	time\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	chooses\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	maximal\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	F1\tagSENT_CONTENT	gain\tagSENT_CONTENT	until\tagSENT_CONTENT	reaching\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	number\tagSENT_CONTENT	limit\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Document\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	Document\tagSECTITLE_START	Encoding\tagSECTITLE_END	After\tagSENT_START	reading\tagSENT_CONTENT	the\tagmetric	words\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	S\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	its\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	s\tagSENT_CONTENT	j\tagSENT_CONTENT	by\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	GRU\tagSENT_CONTENT	hidden\tagSENT_CONTENT	vectors\tagSENT_CONTENT	:\tagSENT_END	Joint\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Scoring\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	i\tagSENT_START	,\tagSENT_CONTENT	to\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagmetric	score\tagmetric	δ(S\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	Si\tagSENT_CONTENT	.\tagSENT_END	Objective\tagSECTITLE_START	Function\tagSECTITLE_END	Considering\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	F1\tagSENT_CONTENT	gain\tagSENT_CONTENT	value\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	negative\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	rescale\tagSENT_CONTENT	the\tagSENT_CONTENT	gain\tagSENT_CONTENT	value\tagSENT_CONTENT	to\tagSENT_CONTENT	:\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	apply\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	temperature\tagSENT_CONTENT	τ\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	the\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	distribution\tagSENT_CONTENT	Q\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	target\tagSENT_CONTENT	.\tagSENT_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	by\tagSENT_CONTENT	maximizing\tagSENT_CONTENT	the\tagmetric	ROUGE-2\tagmetric	F1\tagmetric	score\tagmetric	.\tagSENT_END	We\tagSENT_START	conduct\tagSENT_CONTENT	data\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	method\tagSENT_CONTENT	2\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	sentence\tagSENT_CONTENT	splitting\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	CNN\tagSECTITLE_START	/\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_END	Training\tagSENT_START	Dev\tagSENT_CONTENT	Test\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	probability\tagSENT_CONTENT	p\tagSENT_CONTENT	=\tagSENT_CONTENT	0.3\tagSENT_CONTENT	after\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	p\tagSENT_CONTENT	=\tagSENT_CONTENT	0.2\tagSENT_END	Baseline\tagSECTITLE_END	propose\tagSENT_START	summarization\tagtask	which\tagSENT_CONTENT	considers\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	CRSUM\tagSECTITLE_END	NN\tagSECTITLE_START	-\tagSECTITLE_CONTENT	SE\tagSECTITLE_END	summarization\tagtask	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	add\tagSENT_CONTENT	some\tagSENT_CONTENT	interpretable\tagSENT_CONTENT	features\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sentence\tagSENT_CONTENT	absolute\tagSENT_CONTENT	and\tagSENT_CONTENT	relative\tagSENT_CONTENT	positions\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Metric\tagSECTITLE_END	We\tagSENT_START	employ\tagSENT_CONTENT	ROUGE\tagmetric	)\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	script\tagSENT_CONTENT	4\tagSENT_CONTENT	(\tagSENT_CONTENT	version\tagSENT_CONTENT	1.5.5\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	In\tagSENT_START	terms\tagmetric	of\tagSENT_CONTENT	ROUGE-2\tagmetric	F1\tagmetric	,\tagSENT_CONTENT	NEUSUM\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	strong\tagSENT_CONTENT	baseline\tagSENT_CONTENT	LEAD3\tagSENT_CONTENT	by\tagSENT_CONTENT	1.31\tagSENT_CONTENT	points\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Info\tagSENT_START	 \tagSENT_CONTENT	Rankings\tagSENT_CONTENT	of\tagSENT_CONTENT	NEUSUM\tagSENT_CONTENT	and\tagSENT_CONTENT	NN\tagSENT_CONTENT	-\tagSENT_CONTENT	SE\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	informativeness\tagSENT_CONTENT	(\tagSENT_CONTENT	Info\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	redundancy\tagSENT_CONTENT	(\tagSENT_CONTENT	Rdnd\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	overall\tagSENT_CONTENT	quality\tagSENT_CONTENT	by\tagSENT_CONTENT	human\tagSENT_CONTENT	participants\tagSENT_CONTENT	(\tagSENT_CONTENT	lower\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	scoring\tagSENT_CONTENT	and\tagSENT_CONTENT	selecting\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	NEUSUM\tagSENT_CONTENT	can\tagSENT_CONTENT	produce\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	less\tagSENT_CONTENT	content\tagSENT_CONTENT	overlap\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	estimates\tagSENT_CONTENT	the\tagSENT_CONTENT	saliency\tagSENT_CONTENT	of\tagSENT_CONTENT	remaining\tagSENT_CONTENT	sentences\tagSENT_CONTENT	considering\tagSENT_CONTENT	both\tagSENT_CONTENT	their\tagSENT_CONTENT	contents\tagSENT_CONTENT	and\tagSENT_CONTENT	previously\tagSENT_CONTENT	selected\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Precision\tagSECTITLE_START	at\tagSECTITLE_CONTENT	Step\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	t\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	document\tagSENT_CONTENT	D\tagSENT_CONTENT	in\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	T\tagSENT_CONTENT	,\tagSENT_CONTENT	NEUSUM\tagSENT_CONTENT	predicted\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	its\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	S\tagSENT_END	Position\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Selected\tagSECTITLE_CONTENT	Sentences\tagSECTITLE_END	Early\tagSENT_START	works\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	sentence\tagSENT_CONTENT	position\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	feature\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	NEUSUM\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	more\tagSENT_CONTENT	discriminating\tagSENT_CONTENT	when\tagSENT_CONTENT	dealing\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	Conventional\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	contain\tagSENT_CONTENT	two\tagSENT_CONTENT	separated\tagSENT_CONTENT	steps\tagSENT_CONTENT	:\tagSENT_CONTENT	sentence\tagSENT_CONTENT	scoring\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	.\tagSENT_END	
1808.10143	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	proposes\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	language_modeling\tagtask	that\tagSENT_CONTENT	combines\tagSENT_CONTENT	probability\tagSENT_CONTENT	distributions\tagSENT_CONTENT	computed\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	final\tagSENT_CONTENT	RNN\tagSENT_CONTENT	layer\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	from\tagSENT_CONTENT	middle\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	language_modeling\tagtask	have\tagSENT_CONTENT	played\tagSENT_CONTENT	a\tagSENT_CONTENT	central\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	advances\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	language_modeling\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	joint\tagSENT_CONTENT	probability\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	product\tagSENT_CONTENT	of\tagSENT_CONTENT	conditional\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	.\tagSENT_END	language_modeling\tagtask	obtain\tagSENT_CONTENT	conditional\tagSENT_CONTENT	probability\tagSENT_END	We\tagSENT_START	conduct\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	standard\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	:\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	and\tagSENT_CONTENT	WikiText-2\tagSENT_CONTENT	.\tagSENT_END	RNN\tagSECTITLE_START	Language\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	briefly\tagSENT_CONTENT	overview\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	,\tagSENT_START	1\tagSENT_CONTENT	}\tagSENT_CONTENT	V\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	vector\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	word\tagSENT_CONTENT	wt\tagSENT_CONTENT	at\tagSENT_CONTENT	timestep\tagmetric	t\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	h\tagSENT_CONTENT	n\tagSENT_CONTENT	t\tagSENT_CONTENT	∈\tagSENT_END	Language\tagSECTITLE_START	Modeling\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	Matrix\tagSECTITLE_CONTENT	Factorization\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	some\tagSENT_CONTENT	A\tagSENT_CONTENT	∈\tagSENT_CONTENT	F\tagSENT_CONTENT	(\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	training\tagSENT_CONTENT	language_modeling\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	satisfying\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	equation\tagSENT_CONTENT	:\tagSENT_CONTENT	 \tagSENT_CONTENT	In\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	indicated\tagSENT_CONTENT	that\tagSENT_CONTENT	D\tagSENT_CONTENT	h\tagSENT_CONTENT	N\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	smaller\tagSENT_CONTENT	than\tagSENT_CONTENT	rank(A\tagSENT_CONTENT	)\tagSENT_CONTENT	because\tagSENT_CONTENT	its\tagSENT_CONTENT	scale\tagSENT_CONTENT	is\tagSENT_CONTENT	usually\tagSENT_CONTENT	10\tagSENT_CONTENT	2\tagSENT_CONTENT	and\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	V\tagSENT_CONTENT	is\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	10\tagSENT_CONTENT	4\tagSENT_CONTENT	.\tagSENT_END	Proposed\tagSECTITLE_START	Method\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Direct\tagSECTITLE_CONTENT	Output\tagSECTITLE_CONTENT	Connection\tagSECTITLE_END	Formally\tagSENT_START	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	Equation\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	DOC\tagSENT_CONTENT	computes\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	at\tagSENT_CONTENT	timestep\tagmetric	t\tagmetric	+\tagSENT_CONTENT	1\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	equation\tagSENT_CONTENT	:\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	language_modeling\tagtask	with\tagSENT_CONTENT	DOC\tagSENT_CONTENT	can\tagSENT_CONTENT	output\tagSENT_CONTENT	a\tagSENT_CONTENT	distribution\tagSENT_CONTENT	matrix\tagSENT_CONTENT	whose\tagSENT_CONTENT	rank\tagSENT_CONTENT	is\tagSENT_CONTENT	identical\tagSENT_CONTENT	to\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	true\tagSENT_CONTENT	distributions\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	a\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	computes\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	for\tagSENT_CONTENT	several\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Equation\tagSENT_CONTENT	10\tagSENT_CONTENT	,\tagSENT_CONTENT	indicated\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	often\tagSENT_CONTENT	converges\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	where\tagSENT_CONTENT	it\tagSENT_CONTENT	always\tagSENT_CONTENT	produces\tagSENT_CONTENT	language_modeling\tagtask	for\tagSENT_CONTENT	few\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Language\tagSECTITLE_CONTENT	Modeling\tagSECTITLE_END	We\tagSENT_START	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	DOC\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Datasets\tagSECTITLE_END	Hyperparameters\tagSECTITLE_END	We\tagSENT_START	selected\tagSENT_CONTENT	0.6\tagSENT_CONTENT	because\tagSENT_CONTENT	this\tagSENT_CONTENT	value\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	score\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	PTB\tagmetric	validation\tagmetric	dataset\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	i\tagSENT_CONTENT	3\tagSENT_CONTENT	=\tagSENT_CONTENT	15\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	2\tagSENT_CONTENT	=\tagSENT_CONTENT	5\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	explored\tagSENT_CONTENT	:\tagSENT_CONTENT	Perplexities\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	implementations\tagSENT_CONTENT	and\tagSENT_CONTENT	reruns\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	PTB\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	the\tagSENT_CONTENT	averaged\tagSENT_CONTENT	SGD\tagSENT_CONTENT	uses\tagSENT_CONTENT	the\tagSENT_CONTENT	averaged\tagSENT_CONTENT	parameters\tagSENT_CONTENT	from\tagSENT_CONTENT	each\tagSENT_CONTENT	update\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	parameters\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	early\tagSENT_CONTENT	steps\tagSENT_CONTENT	are\tagSENT_CONTENT	harmful\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Application\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	As\tagSENT_START	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	as\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Dataset\tagSECTITLE_END	They\tagSENT_START	also\tagSENT_CONTENT	divided\tagSENT_CONTENT	the\tagSENT_CONTENT	extracted\tagSENT_CONTENT	sentenceheadline\tagSENT_CONTENT	pairs\tagSENT_CONTENT	into\tagSENT_CONTENT	three\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	validation\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Encoder\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	For\tagSENT_START	language_modeling\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopted\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagmetric	experiment\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	DOC\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	base\tagSENT_CONTENT	EncDec\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Constituency\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	Choe\tagSENT_START	and\tagSENT_CONTENT	Charniak\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	achieved\tagSENT_CONTENT	high\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	task\tagSENT_CONTENT	by\tagSENT_CONTENT	transforming\tagSENT_CONTENT	candidate\tagSENT_CONTENT	trees\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	symbol\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	S\tagSENT_CONTENT	-\tagSENT_CONTENT	expression\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	reranking\tagSENT_CONTENT	them\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	perplexity\tagmetric	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	We\tagSENT_START	used\tagSENT_CONTENT	the\tagSENT_CONTENT	section\tagSENT_CONTENT	2\tagSENT_CONTENT	-\tagSENT_CONTENT	21\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	22\tagSENT_CONTENT	for\tagSENT_CONTENT	validation\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	23\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	We\tagSENT_START	trained\tagSENT_CONTENT	language_modeling\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	from\tagSENT_CONTENT	our\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	experiments\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	5\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Model\tagSECTITLE_END	Base\tagSENT_START	Rerank\tagSENT_CONTENT	Reranking\tagSENT_CONTENT	with\tagSENT_CONTENT	language_modeling\tagtask	89.7\tagSENT_END	These\tagSENT_START	results\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	5.3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Researchers\tagSENT_START	continue\tagSENT_CONTENT	to\tagSENT_CONTENT	try\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Previous\tagSENT_START	studies\tagSENT_CONTENT	also\tagSENT_CONTENT	explored\tagSENT_CONTENT	superior\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	As\tagSENT_START	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	,\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	language_modeling\tagtask	as\tagSENT_CONTENT	matrix\tagSENT_CONTENT	factorization\tagSENT_CONTENT	and\tagSENT_CONTENT	improved\tagSENT_CONTENT	performance\tagSENT_CONTENT	by\tagSENT_CONTENT	computing\tagSENT_CONTENT	multiple\tagSENT_CONTENT	probability\tagSENT_CONTENT	distributions\tagSENT_CONTENT	.\tagSENT_END	extended\tagSENT_START	language_modeling\tagtask	for\tagSENT_CONTENT	RNN\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	DOC\tagSENT_START	raises\tagSENT_CONTENT	the\tagSENT_CONTENT	expressive\tagSENT_CONTENT	power\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	improves\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	
1703.04617	title\tagSECTITLE_END	Exploring\tagSENT_START	question_answering\tagtask	and\tagSENT_CONTENT	Adaptation\tagSENT_CONTENT	in\tagSENT_CONTENT	Neural\tagSENT_CONTENT	-\tagSENT_CONTENT	Network\tagSENT_CONTENT	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Question\tagSENT_CONTENT	Answering\tagSENT_END	abstract\tagSECTITLE_END	The\tagSENT_START	last\tagSENT_CONTENT	several\tagSENT_CONTENT	years\tagSENT_CONTENT	have\tagSENT_CONTENT	seen\tagSENT_CONTENT	intensive\tagSENT_CONTENT	interest\tagSENT_CONTENT	in\tagSENT_CONTENT	exploring\tagSENT_CONTENT	neural\tagSENT_CONTENT	-\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	(\tagSENT_CONTENT	MC\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Enabling\tagSENT_START	computers\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	given\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	their\tagSENT_CONTENT	content\tagSENT_CONTENT	has\tagSENT_CONTENT	recently\tagSENT_CONTENT	attracted\tagSENT_CONTENT	intensive\tagSENT_CONTENT	interest\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	limited\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	efforts\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	recent\tagSENT_CONTENT	availability\tagSENT_CONTENT	of\tagSENT_CONTENT	relatively\tagSENT_CONTENT	large\tagSENT_CONTENT	training\tagSENT_CONTENT	datasets\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	for\tagSENT_CONTENT	more\tagSENT_CONTENT	details\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	made\tagSENT_CONTENT	it\tagSENT_CONTENT	more\tagSENT_CONTENT	feasible\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	and\tagSENT_CONTENT	estimate\tagSENT_CONTENT	rather\tagSENT_CONTENT	complex\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	fashion\tagSENT_CONTENT	for\tagSENT_CONTENT	these\tagSENT_CONTENT	problems\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	whole\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	fit\tagSENT_CONTENT	directly\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	rather\tagSENT_CONTENT	effective\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	take\tagSENT_CONTENT	a\tagSENT_CONTENT	closer\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	modeling\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	such\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	regard\tagSENT_CONTENT	question\tagSENT_CONTENT	understanding\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	importance\tagSENT_CONTENT	for\tagSENT_CONTENT	such\tagSENT_CONTENT	problems\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Recent\tagSENT_START	advance\tagSENT_CONTENT	on\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	closely\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	availability\tagSENT_CONTENT	of\tagSENT_CONTENT	various\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	proposed\tagSENT_START	match\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	associate\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	adapted\tagSENT_CONTENT	the\tagSENT_CONTENT	so\tagSENT_CONTENT	-\tagSENT_CONTENT	called\tagSENT_CONTENT	pointer\tagSENT_CONTENT	Network\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	positions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	text\tagSENT_CONTENT	spans\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	types\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	often\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	seek\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Approach\tagSECTITLE_END	The\tagSECTITLE_START	Baseline\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Word\tagSECTITLE_END	Word\tagSECTITLE_START	embedding\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	documents\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	matrices\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	Q\tagSENT_CONTENT	e\tagSENT_CONTENT	∈\tagSENT_CONTENT	RN\tagSENT_CONTENT	×dw\tagSENT_CONTENT	fora\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	D\tagSENT_CONTENT	e\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	M\tagSENT_CONTENT	×dw\tagSENT_CONTENT	fora\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	N\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	length\tagSENT_CONTENT	(\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	tokens\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	GRU\tagSENT_CONTENT	(\tagSENT_CONTENT	BiGRU\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	As\tagSENT_START	inmost\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	framework\tagSENT_CONTENT	use\tagSENT_CONTENT	both\tagSENT_CONTENT	soft\tagSENT_CONTENT	attention\tagSENT_CONTENT	over\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	that\tagSENT_CONTENT	over\tagSENT_CONTENT	documents\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	interaction\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	U\tagSENT_CONTENT	ij\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	c\tagSENT_CONTENT	i\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	word\tagSENT_CONTENT	D\tagSENT_CONTENT	c\tagSENT_CONTENT	j\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	question_answering\tagtask	computed\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	document\tagSENT_CONTENT	word\tagSENT_CONTENT	w\tagSENT_CONTENT	j\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	call\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	Q\tagSENT_CONTENT	-\tagSENT_CONTENT	code\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	:\tagSENT_END	Question\tagSENT_START	-\tagSENT_CONTENT	based\tagSENT_CONTENT	filtering\tagSENT_CONTENT	To\tagSENT_CONTENT	better\tagSENT_CONTENT	explore\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	design\tagSENT_CONTENT	this\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	filtering\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	question\tagSENT_CONTENT	word\tagSENT_END	By\tagSENT_START	pooling\tagSENT_CONTENT	b\tagSENT_CONTENT	∈\tagSENT_CONTENT	RN\tagSENT_CONTENT	×M\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	obtain\tagSENT_CONTENT	question_answering\tagtask	:\tagSENT_END	Aggregation\tagSENT_START	After\tagSENT_CONTENT	acquiring\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	alignment\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	collected\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	aggregation\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	performed\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	answers\tagSENT_CONTENT	.\tagSENT_END	Prediction\tagSENT_START	The\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	QA\tagSENT_CONTENT	task\tagSENT_CONTENT	requires\tagSENT_CONTENT	a\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	We\tagSENT_START	finally\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	equation\tagSENT_CONTENT	:\tagSENT_END	Question\tagSECTITLE_START	Understanding\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Adaptation\tagSECTITLE_END	Introducing\tagSECTITLE_START	syntactic\tagSECTITLE_CONTENT	information\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	neural\tagSECTITLE_CONTENT	question\tagSECTITLE_CONTENT	encoding\tagSECTITLE_END	The\tagSENT_START	interplay\tagSENT_CONTENT	of\tagSENT_CONTENT	syntax\tagSENT_CONTENT	and\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	questions\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	interest\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	To\tagSENT_START	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	CoreNLP\tagSENT_CONTENT	(\tagSENT_CONTENT	PCFG\tagSENT_CONTENT	Parser\tagSENT_CONTENT	)\tagSENT_CONTENT	]\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	binarized\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parse\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	build\tagSENT_CONTENT	the\tagSENT_CONTENT	TreeLSTM\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	.\tagSENT_END	Question\tagSECTITLE_START	Adaptation\tagSECTITLE_END	question_answering\tagtask	by\tagSENT_CONTENT	nature\tagSENT_CONTENT	are\tagSENT_CONTENT	often\tagSENT_CONTENT	composed\tagSENT_CONTENT	to\tagSENT_CONTENT	fulfill\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	needs\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	previous\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	often\tagSENT_CONTENT	trained\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	without\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	discriminating\tagSENT_CONTENT	different\tagSENT_CONTENT	question\tagSENT_CONTENT	types\tagSENT_CONTENT	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	fora\tagSENT_CONTENT	target\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	common\tagSENT_CONTENT	features\tagSENT_CONTENT	shared\tagSENT_CONTENT	by\tagSENT_CONTENT	all\tagSENT_CONTENT	questions\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	specific\tagSENT_CONTENT	features\tagSENT_CONTENT	fora\tagSENT_CONTENT	specific\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	question\tagSENT_CONTENT	are\tagSENT_CONTENT	further\tagSENT_CONTENT	considered\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	they\tagSENT_CONTENT	could\tagSENT_CONTENT	potentially\tagSENT_CONTENT	obey\tagSENT_CONTENT	different\tagSENT_CONTENT	distributions\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	As\tagSENT_CONTENT	discussed\tagSENT_CONTENT	,\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	questions\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	answers\tagSENT_CONTENT	may\tagSENT_CONTENT	share\tagSENT_CONTENT	common\tagSENT_CONTENT	regularity\tagSENT_CONTENT	and\tagSENT_CONTENT	have\tagSENT_CONTENT	separate\tagSENT_CONTENT	property\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Conceptually\tagSENT_START	we\tagSENT_CONTENT	regard\tagSENT_CONTENT	a\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	group\tagSENT_CONTENT	of\tagSENT_CONTENT	acoustically\tagSENT_CONTENT	similar\tagSENT_CONTENT	speakers\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	input\tagSENT_CONTENT	question\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	decompose\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	two\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	cluster\tagSENT_CONTENT	it\tagSENT_CONTENT	belong(i.e\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	diverse\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	cluster\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	cluster\tagSENT_CONTENT	here\tagSENT_CONTENT	models\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	With\tagSENT_START	x\tagSENT_CONTENT	ready\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	apply\tagSENT_CONTENT	Discriminative\tagSENT_CONTENT	Block\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	obtain\tagSENT_CONTENT	its\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	Q\tagSENT_CONTENT	-\tagSENT_CONTENT	code\tagSENT_CONTENT	.\tagSENT_END	Updating\tagSENT_START	The\tagSENT_CONTENT	updating\tagSENT_CONTENT	stage\tagSENT_CONTENT	attempts\tagSENT_CONTENT	to\tagSENT_CONTENT	modify\tagSENT_CONTENT	the\tagSENT_CONTENT	center\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	K\tagSENT_CONTENT	clusters\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	fit\tagSENT_CONTENT	each\tagSENT_CONTENT	cluster\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Experiment\tagSECTITLE_START	Results\tagSECTITLE_END	Set\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Up\tagSECTITLE_END	We\tagSENT_START	test\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	apply\tagSENT_CONTENT	dropout\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Encoder\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	dropout\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	0.5\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	EM\tagSECTITLE_START	F1\tagSECTITLE_END	Results\tagSECTITLE_END	Our\tagSENT_START	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	using\tagSENT_CONTENT	no\tagSENT_CONTENT	Q\tagSENT_CONTENT	-\tagSENT_CONTENT	code\tagSENT_CONTENT	achieved\tagSENT_CONTENT	a\tagSENT_CONTENT	68.00\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	77.36\tagSENT_CONTENT	%\tagSENT_CONTENT	EM\tagmetric	and\tagSENT_CONTENT	F1\tagmetric	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	used\tagSENT_CONTENT	TreeLSTM\tagSENT_CONTENT	introduce\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parses\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	understanding\tagSENT_CONTENT	(\tagSENT_CONTENT	replacing\tagSENT_CONTENT	simple\tagSENT_CONTENT	question\tagSENT_CONTENT	type\tagSENT_CONTENT	as\tagSENT_CONTENT	question\tagSENT_CONTENT	understanding\tagSENT_CONTENT	Q\tagSENT_CONTENT	-\tagSENT_CONTENT	code\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	consistently\tagSENT_CONTENT	shows\tagSENT_CONTENT	further\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	78.38\tagSECTITLE_START	%\tagSECTITLE_END	Conclusions\tagSECTITLE_END	Closely\tagSENT_START	modelling\tagSENT_CONTENT	questions\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	of\tagSENT_CONTENT	importance\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	.\tagSENT_END	
N18-2053	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	advances\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	by\tagSENT_CONTENT	employing\tagSENT_CONTENT	a\tagSENT_CONTENT	convo\tagSENT_CONTENT	-\tagSENT_CONTENT	lutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	capture\tagSENT_CONTENT	global\tagSENT_CONTENT	relationships\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relations\tagSENT_CONTENT	in\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	bases\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Large\tagSENT_START	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	bases\tagSENT_CONTENT	(\tagSENT_CONTENT	KBs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	YAGO\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	DBpedia\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	databases\tagSENT_CONTENT	of\tagSENT_CONTENT	triples\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	relationships\tagSENT_CONTENT	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	fact\tagSENT_CONTENT	(\tagSENT_CONTENT	head\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	tail\tagSENT_CONTENT	entity\tagSENT_CONTENT	)\tagSENT_CONTENT	denoted\tagSENT_CONTENT	as\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	Melbourne\tagSENT_CONTENT	,\tagSENT_CONTENT	cityOf\tagSENT_CONTENT	,\tagSENT_CONTENT	Australia\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Many\tagSENT_START	embedding\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	vector\tagSENT_CONTENT	or\tagSENT_CONTENT	matrix\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	(\tagSENT_CONTENT	SOTA\tagSENT_CONTENT	)\tagSENT_CONTENT	link\tagSENT_CONTENT	prediction\tagSENT_CONTENT	results\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Other\tagSENT_START	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	extend\tagSENT_CONTENT	TransE\tagSENT_CONTENT	to\tagSENT_CONTENT	additionally\tagSENT_CONTENT	use\tagSENT_CONTENT	relation_prediction\tagtask	or\tagSENT_CONTENT	matrices\tagSENT_CONTENT	to\tagSENT_CONTENT	translate\tagSENT_CONTENT	head\tagSENT_CONTENT	and\tagSENT_CONTENT	tail\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	vector\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_CONTENT	TransH\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	TransR\tagSENT_CONTENT	(\tagSENT_CONTENT	Lin\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2015b\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	TranSparse\tagSENT_END	See\tagSENT_START	a\tagSENT_CONTENT	formal\tagSENT_CONTENT	definition\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	in\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	ConvKB\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	or\tagSENT_CONTENT	relation_prediction\tagtask	is\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	unique\tagSENT_CONTENT	kdimensional\tagSENT_CONTENT	embedding\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	concat\tagSENT_START	denotes\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	We\tagSENT_START	introduce\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	-\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	embedding\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	for\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	completion\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	We\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	Proposed\tagSECTITLE_START	ConvKB\tagSECTITLE_CONTENT	model\tagSECTITLE_END	A\tagSENT_START	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	G\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	valid\tagSENT_CONTENT	factual\tagSENT_CONTENT	triples\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	head\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	relation\tagSENT_CONTENT	,\tagSENT_CONTENT	tail\tagSENT_CONTENT	entity\tagSENT_CONTENT	)\tagSENT_CONTENT	denoted\tagSENT_CONTENT	as\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_END	where\tagSENT_START	b\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	bias\tagSENT_CONTENT	term\tagSENT_CONTENT	and\tagSENT_CONTENT	g\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	|\tagSECTITLE_START	E\tagSECTITLE_CONTENT	|\tagSECTITLE_CONTENT	|\tagSECTITLE_CONTENT	R\tagSECTITLE_CONTENT	|\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	Triples\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	train\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	valid\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	test\tagSECTITLE_CONTENT	WN18RR\tagSECTITLE_CONTENT	40,943\tagSECTITLE_CONTENT	11\tagSECTITLE_CONTENT	86,835\tagSECTITLE_CONTENT	3,034\tagSECTITLE_CONTENT	3,134\tagSECTITLE_CONTENT	FB15k-237\tagSECTITLE_CONTENT	14,541\tagSECTITLE_CONTENT	237\tagSECTITLE_CONTENT	272,115\tagSECTITLE_CONTENT	17,535\tagSECTITLE_CONTENT	20,466\tagSECTITLE_END	;\tagSENT_START	*\tagSENT_CONTENT	denotes\tagSENT_CONTENT	a\tagSENT_CONTENT	convolution\tagSENT_CONTENT	operator\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	concat\tagSENT_CONTENT	denotes\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	If\tagSENT_START	we\tagSENT_CONTENT	only\tagSENT_CONTENT	use\tagSENT_CONTENT	one\tagSENT_CONTENT	filter\tagSENT_CONTENT	ω\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	using\tagSENT_CONTENT	τ\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	bias\tagSENT_CONTENT	term\tagSENT_CONTENT	b\tagSENT_CONTENT	=\tagSENT_CONTENT	0\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	g(x\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Adam\tagSENT_CONTENT	optimizer\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	by\tagSENT_CONTENT	minimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	relation_prediction\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	weight\tagSENT_CONTENT	vector\tagSENT_CONTENT	w\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	:\tagSENT_END	G\tagSENT_START	is\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	invalid\tagSENT_CONTENT	triples\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	corrupting\tagSENT_CONTENT	valid\tagSENT_CONTENT	triples\tagSENT_CONTENT	in\tagSENT_CONTENT	G.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	Evaluation\tagSECTITLE_START	protocol\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	KB\tagSENT_CONTENT	completion\tagSENT_CONTENT	or\tagSENT_CONTENT	link\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	purpose\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	a\tagSENT_CONTENT	missing\tagSENT_CONTENT	entity\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	relation\tagSENT_CONTENT	and\tagSENT_CONTENT	another\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e\tagSENT_CONTENT	,\tagSENT_CONTENT	inferring\tagSENT_CONTENT	h\tagSENT_CONTENT	given\tagSENT_CONTENT	(\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	inferring\tagSENT_CONTENT	t\tagSENT_CONTENT	given\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	protocol\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	use\tagSENT_CONTENT	relation_prediction\tagtask	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	TransE\tagSENT_CONTENT	to\tagSENT_CONTENT	initialize\tagSENT_CONTENT	entity\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	in\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	learn\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	including\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	filters\tagSENT_CONTENT	ω\tagSENT_CONTENT	and\tagSENT_END	Main\tagSECTITLE_START	experimental\tagSECTITLE_CONTENT	results\tagSECTITLE_END	ConvKB\tagSENT_START	does\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	model\tagSENT_CONTENT	TransE\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	experimental\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	on\tagSENT_CONTENT	FB15k-237\tagdataset	where\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	gains\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	of\tagSENT_CONTENT	347\tagSENT_CONTENT	−\tagSENT_CONTENT	257\tagSENT_CONTENT	=\tagSENT_CONTENT	90\tagSENT_CONTENT	in\tagSENT_CONTENT	MR\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	about\tagSENT_CONTENT	26\tagSENT_CONTENT	%\tagSENT_CONTENT	relative\tagSENT_CONTENT	improvement\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	0.396\tagSENT_CONTENT	−\tagSENT_CONTENT	0.294\tagSENT_CONTENT	=\tagSENT_CONTENT	0.102\tagSENT_CONTENT	in\tagSENT_CONTENT	MRR\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	34+%\tagSENT_CONTENT	relative\tagSENT_CONTENT	improvement\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	obtains\tagSENT_CONTENT	51.7\tagSENT_CONTENT	−\tagSENT_CONTENT	46.5\tagSENT_CONTENT	=\tagSENT_CONTENT	5.2\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	Hits@10\tagSENT_CONTENT	.\tagSENT_END	ConvKB\tagSENT_START	obtains\tagSENT_CONTENT	better\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	ConvE\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	(\tagSENT_CONTENT	except\tagSENT_CONTENT	MRR\tagmetric	on\tagSENT_CONTENT	WN18RR\tagSENT_CONTENT	and\tagSENT_CONTENT	MR\tagSENT_CONTENT	on\tagSENT_CONTENT	FB15k-237\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	showing\tagSENT_CONTENT	the\tagSENT_CONTENT	usefulness\tagSENT_CONTENT	of\tagSENT_CONTENT	taking\tagSENT_CONTENT	transitional\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	into\tagSENT_CONTENT	accounts\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Experimental\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	ConvKB\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	WN18RR\tagdataset	and\tagSENT_CONTENT	FB15k-237\tagSENT_CONTENT	.\tagSENT_END	
D13-1204	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Early\tagSENT_START	work\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	locally\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	EM\tagSENT_CONTENT	to\tagSENT_CONTENT	estimate\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	between\tagSENT_CONTENT	word\tagSENT_CONTENT	bigrams\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Abstract\tagSECTITLE_START	Operators\tagSECTITLE_END	Transforms\tagSECTITLE_START	(\tagSECTITLE_CONTENT	Unary\tagSECTITLE_CONTENT	)\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	being\tagSENT_CONTENT	estimated\tagSENT_CONTENT	decomposes\tagSENT_CONTENT	into\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	several\tagSENT_CONTENT	multinomials\tagSENT_CONTENT	)\tagSENT_END	then\tagSENT_START	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	reset\tagSENT_CONTENT	to\tagSENT_CONTENT	uniform\tagSENT_CONTENT	distributions\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	discarding\tagSENT_CONTENT	associated\tagSENT_CONTENT	counts\tagSENT_CONTENT	from\tagSENT_CONTENT	C.\tagSENT_CONTENT	In\tagSENT_CONTENT	text\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	could\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	eliminating\tagSENT_CONTENT	frequent\tagSENT_CONTENT	or\tagSENT_CONTENT	rare\tagSENT_CONTENT	tokens\tagSENT_CONTENT	from\tagSENT_CONTENT	bags\tagmetric	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	will\tagSENT_CONTENT	use\tagSENT_CONTENT	squares\tagmetric	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	data\tagSENT_CONTENT	-\tagSENT_CONTENT	set\tagSENT_CONTENT	filtering\tagSENT_CONTENT	:\tagSENT_CONTENT	C\tagSENT_CONTENT	Finally\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	C\tagSENT_CONTENT	represents\tagSENT_CONTENT	a\tagSENT_CONTENT	mixture\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	interpretations\tagSENT_CONTENT	over\tagSENT_CONTENT	D\tagSENT_CONTENT	-e.g\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	it\tagSENT_CONTENT	captures\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	soft\tagSENT_CONTENT	"\tagSENT_CONTENT	EM\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	-contributions\tagSENT_CONTENT	from\tagSENT_CONTENT	less\tagSENT_CONTENT	likely\tagSENT_CONTENT	,\tagSENT_CONTENT	noisier\tagSENT_CONTENT	completions\tagSENT_CONTENT	could\tagSENT_CONTENT	also\tagSENT_CONTENT	be\tagSENT_CONTENT	suppressed\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	weights\tagSENT_CONTENT	redistributed\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	likely\tagSENT_CONTENT	ones\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	"\tagSENT_CONTENT	hard\tagSENT_CONTENT	"\tagSENT_CONTENT	EM\tagSENT_CONTENT	.\tagSENT_END	Joins\tagSECTITLE_START	(\tagSECTITLE_CONTENT	Binary\tagSECTITLE_CONTENT	)\tagSECTITLE_END	The\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Methodology\tagSECTITLE_END	Output\tagSENT_START	is\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Models\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	We\tagSENT_START	constrain\tagSENT_CONTENT	all\tagSENT_CONTENT	parse\tagSENT_CONTENT	structures\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	projective\tagSENT_CONTENT	,\tagSENT_CONTENT	via\tagSENT_CONTENT	dependency_parsing\tagtask	Smoothing\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Lexicalization\tagSECTITLE_END	Optimization\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Viterbi\tagSECTITLE_CONTENT	Decoding\tagSECTITLE_END	Alternating\tagSENT_START	EMs\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	expensive\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	updates\tagmetric	take\tagSENT_CONTENT	(\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	)\tagSENT_CONTENT	O(l\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hard\tagSENT_CONTENT	EM\tagSENT_CONTENT	's\tagSENT_CONTENT	objective\tagSENT_CONTENT	(\tagSENT_CONTENT	L\tagSENT_CONTENT	=\tagSENT_CONTENT	H\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	better\tagSENT_CONTENT	suited\tagSENT_CONTENT	to\tagSENT_CONTENT	long\tagSENT_CONTENT	inputs\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Final\tagSECTITLE_START	Evaluation\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Metrics\tagSECTITLE_END	We\tagSENT_START	compute\tagSENT_CONTENT	performance\tagSENT_CONTENT	as\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	DDA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	fractions\tagSENT_CONTENT	of\tagSENT_CONTENT	correct\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	arcs\tagSENT_CONTENT	in\tagSENT_CONTENT	parsed\tagSENT_CONTENT	output\tagSENT_CONTENT	(\tagSENT_CONTENT	an\tagSENT_CONTENT	extrinsic\tagSENT_CONTENT	metric\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Concrete\tagSECTITLE_START	Operators\tagSECTITLE_END	Transform\tagSECTITLE_START	#\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	Simple\tagSECTITLE_CONTENT	Filter\tagSECTITLE_END	Transform\tagSECTITLE_START	#\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	Symmetrizer\tagSECTITLE_END	It\tagSENT_START	blurs\tagSENT_CONTENT	all\tagSENT_CONTENT	details\tagSENT_CONTENT	of\tagSENT_CONTENT	induced\tagSENT_CONTENT	parses\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	D\tagSENT_CONTENT	,\tagSENT_CONTENT	except\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	times\tagSENT_CONTENT	each\tagSENT_CONTENT	(\tagSENT_CONTENT	ordered\tagSENT_CONTENT	)\tagSENT_CONTENT	word\tagSENT_CONTENT	pair\tagSENT_CONTENT	participates\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	implemented\tagSENT_CONTENT	symmetrization\tagSENT_CONTENT	also\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	unlexicalized\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	training\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	now\tagSENT_CONTENT	with\tagSENT_CONTENT	proposed\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	'\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	fora\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	D\tagSENT_CONTENT	,\tagSENT_CONTENT	proportional\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	product\tagSENT_CONTENT	over\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	one\tagSENT_CONTENT	plus\tagSENT_CONTENT	how\tagSENT_CONTENT	often\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	tokens\tagSENT_CONTENT	(\tagSENT_CONTENT	are\tagSENT_CONTENT	expected\tagSENT_CONTENT	to\tagSENT_CONTENT	)\tagSENT_CONTENT	appear\tagSENT_CONTENT	connected\tagSENT_CONTENT	:\tagSENT_END	To\tagSENT_START	see\tagSENT_CONTENT	why\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	n't\tagSENT_CONTENT	turn\tagSENT_CONTENT	word\tagSENT_CONTENT	attachment\tagSENT_CONTENT	scores\tagSENT_CONTENT	into\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	,\tagSENT_CONTENT	consider\tagSENT_CONTENT	sentences\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	because\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	evidence\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	side\tagSENT_CONTENT	-\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	head\tagSENT_CONTENT	-\tagSENT_CONTENT	driven\tagSENT_CONTENT	nature\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	factored\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	heads\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Join\tagSECTITLE_START	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	Combiner\tagSECTITLE_END	Basic\tagSECTITLE_START	Networks\tagSECTITLE_END	Fork\tagSECTITLE_START	/\tagSECTITLE_CONTENT	Join\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	FJ\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Since\tagSENT_START	we\tagSENT_CONTENT	ca\tagSENT_CONTENT	n't\tagSENT_CONTENT	know\tagSENT_CONTENT	ahead\tagSENT_CONTENT	of\tagSENT_CONTENT	time\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	true\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	pursue\tagSENT_CONTENT	both\tagSENT_CONTENT	optimization\tagSENT_CONTENT	paths\tagSENT_CONTENT	simultaneously\tagSENT_CONTENT	and\tagSENT_CONTENT	let\tagSENT_CONTENT	a\tagSENT_CONTENT	combiner\tagSENT_CONTENT	later\tagSENT_CONTENT	decide\tagSENT_CONTENT	for\tagSENT_CONTENT	us\tagmetric	.\tagSENT_END	Unlike\tagSENT_START	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	FJ\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	symmetrization\tagSENT_CONTENT	was\tagSENT_CONTENT	a\tagSENT_CONTENT	no\tagSENT_CONTENT	-\tagSENT_CONTENT	op\tagSENT_CONTENT	(\tagSENT_CONTENT	since\tagSENT_CONTENT	there\tagSENT_CONTENT	were\tagSENT_CONTENT	no\tagSENT_CONTENT	counts\tagSENT_CONTENT	in\tagSENT_CONTENT	C\tagSENT_CONTENT	=\tagSENT_CONTENT	∅\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	IFJ\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	symmetrizers\tagSENT_CONTENT	-e.g\tagSENT_CONTENT	.\tagSENT_END	Grounded\tagSECTITLE_START	Iterated\tagSECTITLE_CONTENT	Fork\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Join\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	GIFJ\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Performance\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Basic\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	network\tagSENT_CONTENT	starts\tagSENT_CONTENT	from\tagSENT_CONTENT	C\tagSENT_CONTENT	=\tagSENT_CONTENT	∅\tagSENT_CONTENT	,\tagSENT_CONTENT	helping\tagSENT_CONTENT	us\tagmetric	establish\tagSENT_CONTENT	several\tagSENT_CONTENT	straw\tagSENT_CONTENT	-\tagSENT_CONTENT	man\tagSENT_CONTENT	baselines\tagSENT_CONTENT	.\tagSENT_END	Fork\tagSECTITLE_START	/\tagSECTITLE_CONTENT	Join\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	FJ\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Iterated\tagSECTITLE_START	Fork\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Join\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	IFJ\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Grounded\tagSECTITLE_START	Iterated\tagSECTITLE_CONTENT	Fork\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Join\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	GIFJ\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Enhanced\tagSECTITLE_START	Subnetworks\tagSECTITLE_END	An\tagSECTITLE_START	Iterative\tagSECTITLE_CONTENT	Combiner\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	IC\tagSECTITLE_CONTENT	)\tagSECTITLE_END	A\tagSECTITLE_START	Grammar\tagSECTITLE_CONTENT	Transformer\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	GT\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Full\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	Combination\tagSECTITLE_END	CS\tagSECTITLE_END	The\tagSENT_START	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	bracketings\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	nontrivial\tagSENT_CONTENT	)\tagSENT_CONTENT	spans\tagSENT_CONTENT	derived\tagSENT_CONTENT	by\tagSENT_CONTENT	heads\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	competitive\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Lingual\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	System\tagSECTITLE_END	Discussion\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	a\tagSENT_CONTENT	convex\tagSENT_CONTENT	training\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	;\tagSENT_CONTENT	introduced\tagSENT_CONTENT	a\tagSENT_CONTENT	convex\tagSENT_CONTENT	reformulation\tagSENT_CONTENT	of\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	functions\tagSENT_CONTENT	for\tagSENT_CONTENT	clustering\tagSENT_CONTENT	tasks\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	Corlett\tagSENT_CONTENT	and\tagSENT_CONTENT	Penn\tagSENT_CONTENT	(\tagSENT_CONTENT	2010\tagSENT_CONTENT	)\tagSENT_CONTENT	designed\tagSENT_CONTENT	 \tagSENT_CONTENT	a\tagSENT_CONTENT	search\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	for\tagSENT_CONTENT	encoding\tagSENT_CONTENT	dependency_parsing\tagtask	that\tagSENT_CONTENT	guarantees\tagSENT_CONTENT	to\tagSENT_CONTENT	quickly\tagSENT_CONTENT	converge\tagSENT_CONTENT	on\tagSENT_CONTENT	optimal\tagSENT_CONTENT	solutions\tagSENT_CONTENT	.\tagSENT_END	Convexity\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	ideal\tagSENT_CONTENT	for\tagSENT_CONTENT	comparative\tagSENT_CONTENT	analyses\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	eliminating\tagSENT_CONTENT	dependency_parsing\tagtask	on\tagSENT_CONTENT	initial\tagSENT_CONTENT	conditions\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	NLP\tagSENT_CONTENT	,\tagSENT_CONTENT	random\tagSENT_CONTENT	walks\tagSENT_CONTENT	from\tagSENT_CONTENT	previous\tagSENT_CONTENT	local\tagSENT_CONTENT	optima\tagSENT_CONTENT	were\tagSENT_CONTENT	faster\tagSENT_CONTENT	than\tagSENT_CONTENT	uniform\tagSENT_CONTENT	sampling\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	increased\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	scores\tagSENT_CONTENT	;\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	local\tagSENT_CONTENT	search\tagSENT_CONTENT	can\tagSENT_CONTENT	outperform\tagSENT_CONTENT	greedy\tagSENT_CONTENT	solutions\tagSENT_CONTENT	for\tagSENT_CONTENT	document\tagSENT_CONTENT	clustering\tagSENT_CONTENT	and\tagSENT_CONTENT	chat\tagSENT_CONTENT	disentanglement\tagSENT_CONTENT	tasks\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	incorporated\tagSENT_CONTENT	tabu\tagSENT_CONTENT	search\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	into\tagSENT_CONTENT	HMM\tagSENT_CONTENT	training\tagSENT_CONTENT	for\tagSENT_CONTENT	ASR\tagmetric	.\tagSENT_END	Our\tagSENT_START	transform\tagSENT_CONTENT	and\tagSENT_CONTENT	join\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	also\tagSENT_CONTENT	exhibit\tagSENT_CONTENT	some\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	genetic\tagSENT_CONTENT	search\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	competing\tagSENT_CONTENT	objec\tagSENT_CONTENT	-\tagSENT_CONTENT	tives\tagSENT_CONTENT	:\tagSENT_CONTENT	good\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	must\tagSENT_CONTENT	make\tagSENT_CONTENT	sense\tagSENT_CONTENT	both\tagSENT_CONTENT	lexicalized\tagSENT_CONTENT	and\tagSENT_CONTENT	with\tagSENT_CONTENT	word\tagSENT_CONTENT	categories\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	rich\tagSENT_CONTENT	and\tagSENT_CONTENT	impoverished\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	grammar\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	long\tagSENT_CONTENT	,\tagSENT_CONTENT	complex\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	short\tagSENT_CONTENT	,\tagSENT_CONTENT	simple\tagSENT_CONTENT	text\tagSENT_CONTENT	fragments\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	family\tagSENT_CONTENT	of\tagSENT_CONTENT	techniques\tagSENT_CONTENT	has\tagSENT_CONTENT	met\tagSENT_CONTENT	with\tagSENT_CONTENT	success\tagSENT_CONTENT	in\tagSENT_CONTENT	semisupervised\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	parts\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	induction\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Unlike\tagSENT_START	conventional\tagSENT_CONTENT	system\tagSENT_CONTENT	combination\tagSENT_CONTENT	methods\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	ours\tagmetric	do\tagSENT_CONTENT	not\tagSENT_CONTENT	require\tagSENT_CONTENT	incoming\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	of\tagSENT_CONTENT	similar\tagSENT_CONTENT	quality\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	improvements\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	can\tagSENT_CONTENT	themselves\tagSENT_CONTENT	also\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	as\tagSENT_CONTENT	directed\tagSENT_CONTENT	structures\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	as\tagSENT_CONTENT	skeleton\tagSENT_CONTENT	parses\tagSENT_CONTENT	,\tagSENT_CONTENT	facilitating\tagSENT_CONTENT	the\tagSENT_CONTENT	recovery\tagSENT_CONTENT	of\tagSENT_CONTENT	correct\tagSENT_CONTENT	polarities\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	And\tagSENT_START	second\tagSENT_CONTENT	,\tagSENT_CONTENT	intermittent\tagSENT_CONTENT	"\tagSENT_CONTENT	unlearning\tagSENT_CONTENT	"\tagSENT_CONTENT	-though\tagSENT_CONTENT	perhaps\tagSENT_CONTENT	not\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	kind\tagSENT_CONTENT	that\tagSENT_CONTENT	takes\tagSENT_CONTENT	place\tagSENT_CONTENT	inside\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	transformsis\tagSENT_CONTENT	an\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	essential\tagSENT_CONTENT	to\tagSENT_CONTENT	cognitive\tagSENT_CONTENT	development\tagSENT_CONTENT	in\tagSENT_CONTENT	general\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	evidenced\tagSENT_CONTENT	by\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	mammals\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	"\tagSENT_START	Forgetful\tagSENT_CONTENT	EM\tagSENT_CONTENT	"\tagSENT_CONTENT	strategies\tagSENT_CONTENT	that\tagSENT_CONTENT	reset\tagSENT_CONTENT	subsets\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	may\tagSENT_CONTENT	thus\tagSENT_CONTENT	,\tagSENT_CONTENT	possibly\tagSENT_CONTENT	,\tagSENT_CONTENT	be\tagSENT_CONTENT	no\tagSENT_CONTENT	less\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	than\tagSENT_CONTENT	is\tagSENT_CONTENT	"\tagSENT_CONTENT	partial\tagSENT_CONTENT	EM\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	suppresses\tagSENT_CONTENT	updates\tagmetric	,\tagSENT_CONTENT	other\tagSENT_CONTENT	EM\tagSENT_CONTENT	variants\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	"\tagSENT_CONTENT	dropout\tagSENT_CONTENT	training\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	in\tagSENT_CONTENT	supervised\tagSENT_CONTENT	settings\tagSENT_CONTENT	.\tagSENT_END	Future\tagSENT_START	parsing\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	grammar\tagSENT_CONTENT	induction\tagSENT_CONTENT	,\tagSENT_CONTENT	may\tagSENT_CONTENT	benefit\tagSENT_CONTENT	by\tagSENT_CONTENT	modeling\tagSENT_CONTENT	dependency_parsing\tagtask	separately\tagSENT_CONTENT	from\tagSENT_CONTENT	direction\tagSENT_CONTENT	.\tagSENT_END	
1804.06512	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	learning\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	oriented\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	systems\tagSENT_CONTENT	through\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Mrkši\tagSENT_START	´\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue_state_tracking\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Comparing\tagSENT_START	to\tagSENT_CONTENT	chit\tagSENT_CONTENT	-\tagSENT_CONTENT	chat\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	trained\tagSENT_CONTENT	offline\tagSENT_CONTENT	using\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	turn\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	response\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	oriented\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	model\tagSENT_CONTENT	involves\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	and\tagSENT_CONTENT	planning\tagSENT_CONTENT	over\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	A\tagSENT_START	critical\tagSENT_CONTENT	step\tagSENT_CONTENT	in\tagSENT_CONTENT	learning\tagSENT_CONTENT	RL\tagSENT_CONTENT	based\tagSENT_CONTENT	taskoriented\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	models\tagSENT_CONTENT	is\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	To\tagSENT_START	ameliorate\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	between\tagSENT_CONTENT	offline\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	RL\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	imitation\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	method\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	design\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	taskoriented\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	system\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	optimized\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	for\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	,\tagSENT_CONTENT	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	policy\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	imitation\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	model\tagSENT_CONTENT	training\tagSENT_CONTENT	in\tagSENT_CONTENT	addressing\tagSENT_CONTENT	the\tagSENT_CONTENT	challenge\tagSENT_CONTENT	with\tagSENT_CONTENT	dialogue_state_tracking\tagtask	between\tagSENT_CONTENT	offline\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	RL\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	POMDP\tagSENT_CONTENT	framework\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	dialogue_state_tracking\tagtask	online\tagSENT_CONTENT	by\tagSENT_CONTENT	interacting\tagSENT_CONTENT	with\tagSENT_CONTENT	users\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	unknown\tagSENT_CONTENT	how\tagSENT_CONTENT	well\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	performance\tagSENT_CONTENT	generalizes\tagSENT_CONTENT	to\tagSENT_CONTENT	unseen\tagSENT_CONTENT	dialogue_state_tracking\tagtask	during\tagSENT_CONTENT	user\tagSENT_CONTENT	interactions\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	same\tagSENT_CONTENT	line\tagSENT_CONTENT	of\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	people\tagSENT_CONTENT	explored\tagSENT_CONTENT	using\tagSENT_CONTENT	query\tagSENT_CONTENT	-\tagSENT_CONTENT	regression\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	gated\tagSENT_CONTENT	memory\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	copy\tagSENT_CONTENT	-\tagSENT_CONTENT	augmented\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	They\tagSENT_START	did\tagSENT_CONTENT	not\tagSENT_CONTENT	discuss\tagSENT_CONTENT	the\tagSENT_CONTENT	potential\tagSENT_CONTENT	issue\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	between\tagSENT_CONTENT	supervised\tagSENT_CONTENT	pretraining\tagSENT_CONTENT	and\tagSENT_CONTENT	RL\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	addressed\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	learning\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	Proposed\tagSECTITLE_START	Method\tagSECTITLE_END	Utterance\tagSECTITLE_START	Encoding\tagSECTITLE_END	Dialogue\tagSECTITLE_START	State\tagSECTITLE_CONTENT	Tracking\tagSECTITLE_END	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	or\tagSENT_CONTENT	belief\tagSENT_CONTENT	tracking\tagSENT_CONTENT	,\tagSENT_CONTENT	maintains\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	goals\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	accumulating\tagSENT_CONTENT	evidence\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	turns\tagSENT_CONTENT	.\tagSENT_END	KB\tagSECTITLE_START	Operation\tagSECTITLE_END	dialogue_state_tracking\tagtask	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	an\tagSENT_CONTENT	API\tagSENT_CONTENT	call\tagSENT_CONTENT	command\tagSENT_CONTENT	to\tagSENT_CONTENT	retrieve\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	.\tagSENT_END	produced\tagSENT_START	by\tagSENT_CONTENT	replacing\tagSENT_CONTENT	the\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	query\tagSENT_CONTENT	command\tagSENT_CONTENT	template\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	goal\tagSENT_CONTENT	slot\tagSENT_CONTENT	from\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Dialogue\tagSECTITLE_START	Policy\tagSECTITLE_END	A\tagSENT_START	dialogue\tagSENT_CONTENT	policy\tagSENT_CONTENT	selects\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	system\tagSENT_CONTENT	action\tagSENT_CONTENT	in\tagSENT_CONTENT	response\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	input\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	The\tagSENT_START	emitted\tagSENT_CONTENT	system\tagSENT_CONTENT	action\tagSENT_CONTENT	is\tagSENT_CONTENT	finally\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	response\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	format\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	dialogue_state_tracking\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	KB\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	Pre\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	training\tagSECTITLE_END	Each\tagSENT_START	system\tagSENT_CONTENT	component\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	takes\tagSENT_CONTENT	in\tagSENT_CONTENT	underlying\tagSENT_CONTENT	system\tagSENT_CONTENT	component\tagSENT_CONTENT	's\tagSENT_CONTENT	outputs\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	continuous\tagSENT_CONTENT	form\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	fully\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	system\tagSENT_CONTENT	(\tagSENT_CONTENT	utterance\tagSENT_CONTENT	encoding\tagSENT_CONTENT	,\tagSENT_CONTENT	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	policy\tagSENT_CONTENT	network\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	parameter\tagSENT_CONTENT	set\tagSENT_CONTENT	θ\tagSENT_CONTENT	by\tagSENT_CONTENT	minimizing\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	interpolation\tagSENT_CONTENT	of\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	losses\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_state_tracking\tagtask	:\tagSENT_END	Imitation\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Human\tagSECTITLE_CONTENT	Teaching\tagSECTITLE_END	During\tagSENT_START	the\tagSENT_CONTENT	agent\tagSENT_CONTENT	's\tagSENT_CONTENT	interaction\tagSENT_CONTENT	with\tagSENT_CONTENT	users\tagSENT_CONTENT	,\tagSENT_CONTENT	any\tagSENT_CONTENT	mistake\tagSENT_CONTENT	made\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	agent\tagSENT_CONTENT	or\tagSENT_CONTENT	any\tagSENT_CONTENT	deviation\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	behavior\tagSENT_CONTENT	may\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	dialogue_state_tracking\tagtask	than\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	agent\tagSENT_CONTENT	saw\tagSENT_CONTENT	during\tagSENT_CONTENT	offline\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	address\tagSENT_CONTENT	this\tagSENT_CONTENT	issue\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	dialogue_state_tracking\tagtask	which\tagSENT_CONTENT	allows\tagSENT_CONTENT	the\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	agent\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	from\tagSENT_CONTENT	human\tagSENT_CONTENT	teaching\tagSENT_CONTENT	.\tagSENT_END	Algorithm\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Dialogue\tagSECTITLE_CONTENT	Learning\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Human\tagSECTITLE_CONTENT	Teaching\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Feedback\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Train\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	end\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	end\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	dialogue\tagSECTITLE_CONTENT	samples\tagSECTITLE_END	We\tagSENT_START	start\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	round\tagSENT_CONTENT	of\tagSENT_CONTENT	supervised\tagSENT_CONTENT	model\tagSENT_CONTENT	training\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	aggregated\tagSENT_CONTENT	corpus\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	an\tagSENT_CONTENT	updated\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	policy\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	continue\tagSENT_CONTENT	dialogue_state_tracking\tagtask	learning\tagSENT_CONTENT	cycles\tagSENT_CONTENT	.\tagSENT_END	Reinforcement\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Human\tagSECTITLE_CONTENT	Feedback\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	use\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	completion\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	metric\tagSENT_CONTENT	in\tagSENT_CONTENT	designing\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	The\tagSENT_START	movie\tagSENT_CONTENT	booking\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	corpus\tagSENT_CONTENT	has\tagSENT_CONTENT	an\tagSENT_CONTENT	average\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	8.4\tagSENT_CONTENT	turns\tagSENT_CONTENT	per\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	Settings\tagSECTITLE_END	Dropout\tagSENT_START	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	0.5\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	during\tagSENT_CONTENT	dialogue_state_tracking\tagtask	to\tagSENT_CONTENT	prevent\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	from\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	fitting\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	system\tagSENT_CONTENT	action\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	act\tagSENT_CONTENT	and\tagSENT_CONTENT	slot\tagSENT_CONTENT	types\tagSENT_CONTENT	from\tagSENT_CONTENT	dialogue_state_tracking\tagtask	.\tagSENT_END	dialogue_state_tracking\tagtask	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	successful\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	conditions\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	slot\tagSENT_CONTENT	values\tagSENT_CONTENT	estimated\tagSENT_CONTENT	from\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	state\tagSENT_CONTENT	tracking\tagSENT_CONTENT	fully\tagSENT_CONTENT	match\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	's\tagSENT_CONTENT	true\tagSENT_CONTENT	goal\tagSENT_CONTENT	values\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	confirm\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	the\tagSENT_CONTENT	tracked\tagSENT_CONTENT	goal\tagSENT_CONTENT	values\tagSENT_CONTENT	and\tagSENT_CONTENT	offer\tagSENT_CONTENT	an\tagSENT_CONTENT	entity\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	finally\tagSENT_CONTENT	accepted\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Imitation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	RL\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Evaluations\tagSENT_START	of\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	imitation\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	are\tagSENT_CONTENT	made\tagSENT_CONTENT	on\tagSENT_CONTENT	metrics\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	task\tagSENT_CONTENT	success\tagSENT_CONTENT	rate\tagSENT_CONTENT	,\tagSENT_CONTENT	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	DST\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	curves\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	might\tagSENT_CONTENT	largely\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	compounding\tagSENT_CONTENT	errors\tagSENT_CONTENT	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	mismatch\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	between\tagSENT_CONTENT	offline\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	observe\tagSENT_CONTENT	decreasing\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	turns\tagSENT_CONTENT	in\tagSENT_CONTENT	completing\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	growing\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	sessions\tagSENT_CONTENT	.\tagSENT_END	Dialogue\tagSECTITLE_START	State\tagSECTITLE_CONTENT	Tracking\tagSECTITLE_CONTENT	Accuracy\tagSECTITLE_END	Similar\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	task\tagSENT_CONTENT	success\tagSENT_CONTENT	rate\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	imitation\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	human\tagSENT_CONTENT	teaching\tagSENT_CONTENT	quickly\tagSENT_CONTENT	improves\tagSENT_CONTENT	dialogue_state_tracking\tagtask	in\tagSENT_CONTENT	just\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	hundred\tagSENT_CONTENT	interactive\tagSENT_CONTENT	learning\tagSENT_CONTENT	sessions\tagSENT_CONTENT	.\tagSENT_END	End\tagSENT_START	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	End\tagSENT_CONTENT	RL\tagSENT_CONTENT	Optimization\tagSENT_CONTENT	To\tagSENT_CONTENT	further\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	performing\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	optimization\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_state_tracking\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	RL\tagSENT_CONTENT	training\tagSENT_CONTENT	settings\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	policy\tagSENT_CONTENT	-\tagSENT_CONTENT	only\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	User\tagSECTITLE_CONTENT	Evaluations\tagSECTITLE_END	Model\tagSECTITLE_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	imitation\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	method\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	firstly\tagSENT_CONTENT	train\tagSENT_CONTENT	dialogue_state_tracking\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	manner\tagSENT_CONTENT	by\tagSENT_CONTENT	learning\tagSENT_CONTENT	from\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	corpora\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	continuously\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	it\tagSENT_CONTENT	by\tagSENT_CONTENT	learning\tagSENT_CONTENT	from\tagSENT_CONTENT	user\tagSENT_CONTENT	teaching\tagSENT_CONTENT	and\tagSENT_CONTENT	feedback\tagSENT_CONTENT	with\tagSENT_CONTENT	imitation\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	
1805.08237	title\tagSECTITLE_END	part-of-speech_tagging\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	Meta\tagSENT_CONTENT	-\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	Model\tagSENT_CONTENT	over\tagSENT_CONTENT	Context\tagSENT_CONTENT	Sensitive\tagSENT_CONTENT	Token\tagSENT_CONTENT	Encodings\tagSENT_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Recently\tagSENT_START	,\tagSENT_CONTENT	used\tagSENT_CONTENT	precisely\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	insensitive\tagSENT_CONTENT	word\tagSENT_CONTENT	representation\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	context\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	word\tagSENT_CONTENT	encodings\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	et\tagSENT_START	al\tagSENT_CONTENT	.\tagSENT_CONTENT	model\tagSENT_CONTENT	had\tagSENT_CONTENT	the\tagmetric	highest\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	all\tagSENT_CONTENT	participating\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2017\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	are\tagSENT_CONTENT	then\tagSENT_CONTENT	combined\tagSENT_CONTENT	via\tagSENT_CONTENT	a\tagSENT_CONTENT	metaBiLSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	builds\tagSENT_CONTENT	a\tagSENT_CONTENT	unified\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	,\tagSENT_START	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	studied\tagSENT_CONTENT	this\tagSENT_CONTENT	architecture\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	low\tagSENT_CONTENT	resource\tagSENT_CONTENT	setting\tagSENT_CONTENT	using\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	(\tagSENT_CONTENT	prefix\tagSENT_CONTENT	/\tagSENT_CONTENT	suffix\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	induced\tagSENT_CONTENT	cluster\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	competitive\tagmetric	accuracy\tagmetric	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	extended\tagSENT_CONTENT	the\tagSENT_CONTENT	work\tagSENT_CONTENT	of\tagSENT_CONTENT	Chen\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_END	show\tagSENT_START	that\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	using\tagSENT_CONTENT	character\tagSENT_CONTENT	convolutions\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagmetric	for\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	this\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	currently\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	during\tagSENT_CONTENT	our\tagSENT_CONTENT	discussion\tagSENT_CONTENT	and\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Sentence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Character\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	We\tagSENT_START	include\tagSENT_CONTENT	the\tagSENT_CONTENT	spaces\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	tokens\tagSENT_CONTENT	1\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	map\tagSENT_CONTENT	each\tagmetric	 \tagmetric	character\tagmetric	to\tagSENT_CONTENT	a\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	learned\tagSENT_CONTENT	embedding\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	b\tagSENT_CONTENT	l\tagSENT_CONTENT	c,1\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	,\tagSENT_CONTENT	bl\tagSENT_CONTENT	c\tagSENT_CONTENT	,\tagSENT_CONTENT	n\tagSENT_CONTENT	)\tagSENT_CONTENT	output\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	character\tagmetric	.\tagSENT_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Character\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Sentence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Meta\tagSECTITLE_START	-\tagSECTITLE_CONTENT	BiLSTM\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Combination\tagSECTITLE_END	Training\tagSECTITLE_START	Schema\tagSECTITLE_END	Evaluate\tagSENT_START	model\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	dev\tagmetric	set\tagmetric	accuracy\tagmetric	.\tagSENT_END	In\tagSENT_START	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	model\tagSENT_CONTENT	selection\tagSENT_CONTENT	,\tagSENT_CONTENT	after\tagSENT_CONTENT	each\tagSENT_CONTENT	epoch\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	evaluates\tagSENT_CONTENT	the\tagmetric	tagging\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	keeps\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Accuracy\tagmetric	is\tagSENT_CONTENT	measured\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	meta\tagSENT_CONTENT	-\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	tagging\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	requires\tagSENT_CONTENT	a\tagSENT_CONTENT	forward\tagSENT_CONTENT	pass\tagSENT_CONTENT	through\tagSENT_CONTENT	all\tagSENT_CONTENT	three\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	accuracy\tagmetric	from\tagSENT_CONTENT	the\tagSENT_CONTENT	meta\tagSENT_CONTENT	-\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	determines\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	parameters\tagSENT_CONTENT	,\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	completely\tagSENT_CONTENT	independent\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	found\tagSENT_CONTENT	this\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagmetric	overall\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	language\tagSENT_CONTENT	could\tagSENT_CONTENT	in\tagSENT_CONTENT	theory\tagSENT_CONTENT	use\tagSENT_CONTENT	separate\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	,\tagSENT_CONTENT	optimized\tagSENT_CONTENT	for\tagSENT_CONTENT	highest\tagmetric	accuracy\tagmetric	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Data\tagSECTITLE_START	Sets\tagSECTITLE_END	As\tagSENT_START	input\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	-\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	-\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	UDPipe\tagSENT_CONTENT	-\tagSENT_CONTENT	base\tagSENT_CONTENT	baseline\tagSENT_CONTENT	system\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	provides\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	segmentation\tagSENT_CONTENT	differs\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	and\tagSENT_CONTENT	impacts\tagSENT_CONTENT	accuracy\tagmetric	negatively\tagSENT_CONTENT	fora\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	Part\tagSECTITLE_START	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Speech\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	These\tagSENT_START	ties\tagSENT_CONTENT	correspond\tagSENT_CONTENT	mostly\tagSENT_CONTENT	to\tagSENT_CONTENT	languages\tagSENT_CONTENT	where\tagSENT_CONTENT	XPOS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	anyhow\tagSENT_CONTENT	obtains\tagmetric	accuracies\tagmetric	above\tagSENT_CONTENT	99\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_END	Accuracy\tagmetric	Søgaard\tagmetric	97.50\tagSENT_CONTENT	97.64\tagSENT_CONTENT	.\tagSENT_END	Part\tagSECTITLE_START	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Speech\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	WSJ\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	these\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	absolute\tagSENT_CONTENT	difference\tagSENT_CONTENT	of\tagSENT_CONTENT	0.32\tagmetric	%\tagmetric	inaccuracy\tagmetric	,\tagSENT_CONTENT	which\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	RRIE\tagSENT_CONTENT	of\tagSENT_CONTENT	12\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Morphological\tagSECTITLE_START	Tagging\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	XPOS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	performed\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	Shared\tagSENT_START	Task\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	expected\tagSENT_CONTENT	that\tagSENT_CONTENT	their\tagSENT_CONTENT	model\tagSENT_CONTENT	would\tagSENT_CONTENT	also\tagSENT_CONTENT	perform\tagSENT_CONTENT	significantly\tagSENT_CONTENT	well\tagSENT_CONTENT	in\tagSENT_CONTENT	part-of-speech_tagging\tagtask	since\tagSENT_CONTENT	the\tagSENT_CONTENT	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	very\tagSENT_CONTENT	similar\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Study\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	experimental\tagSENT_CONTENT	setup\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ablation\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	accuracy\tagmetric	scores\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Separate\tagSENT_START	optimization\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	34\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	40\tagSENT_CONTENT	treebanks\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	morphological\tagSENT_CONTENT	features\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	30\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	39\tagSENT_CONTENT	treebanks\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Character\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	The\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	character\tagSENT_CONTENT	model\tagSENT_CONTENT	joint\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	were\tagSENT_CONTENT	significantly\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	character\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	part-of-speech_tagging\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	character\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	own\tagSENT_CONTENT	(\tagSENT_CONTENT	using\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	from\tagSENT_CONTENT	in\tagSENT_CONTENT	4.1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	picked\tagSENT_CONTENT	Vietnamese\tagSENT_CONTENT	fora\tagSENT_CONTENT	more\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	depth\tagSENT_CONTENT	analysis\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	perform\tagSENT_CONTENT	well\tagSENT_CONTENT	and\tagSENT_CONTENT	investigated\tagSENT_CONTENT	the\tagSENT_CONTENT	influence\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sizes\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	character\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	surface\tagSENT_CONTENT	plot\tagSENT_CONTENT	in\tagSENT_CONTENT	3\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	grid\tagSENT_CONTENT	peaks\tagSENT_CONTENT	with\tagSENT_CONTENT	more\tagSENT_CONTENT	moderate\tagSENT_CONTENT	settings\tagSENT_CONTENT	around\tagSENT_CONTENT	350\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	cells\tagSENT_CONTENT	which\tagSENT_CONTENT	might\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagmetric	higher\tagmetric	accuracy\tagmetric	.\tagSENT_END	For\tagSENT_START	all\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	sizes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	grid\tagSENT_CONTENT	search\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	still\tagSENT_CONTENT	observed\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	reach\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	value\tagSENT_CONTENT	and\tagSENT_CONTENT	degrades\tagSENT_CONTENT	with\tagSENT_CONTENT	more\tagSENT_CONTENT	iterations\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSENT_START	Generally\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	different\tagSENT_CONTENT	techniques\tagSENT_CONTENT	for\tagSENT_CONTENT	creating\tagSENT_CONTENT	word\tagSENT_CONTENT	encodings\tagSENT_CONTENT	from\tagSENT_CONTENT	character\tagSENT_CONTENT	encodings\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	network\tagSENT_CONTENT	sizes\tagSENT_CONTENT	can\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	per\tagSENT_CONTENT	language\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	per\tagSENT_CONTENT	language\tagSENT_CONTENT	basis\tagSENT_CONTENT	via\tagSENT_CONTENT	a\tagSENT_CONTENT	grid\tagSENT_CONTENT	search\tagSENT_CONTENT	overall\tagSENT_CONTENT	possibilities\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	an\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	part-of-speech_tagging\tagtask	that\tagSENT_CONTENT	combines\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	initial\tagSENT_CONTENT	character\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	encodings\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	meta\tagSENT_CONTENT	-\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagmetric	art\tagmetric	accuracies\tagmetric	fora\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	
1703.06345	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Recent\tagSENT_START	papers\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	obtain\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	tasks\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	taggers\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	plentiful\tagSENT_CONTENT	annotations\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	on\tagSENT_CONTENT	Penn\tagdataset	Treebank\tagdataset	)\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	fewer\tagSENT_CONTENT	available\tagSENT_CONTENT	annotations\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	for\tagSENT_CONTENT	microblogs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	part-of-speech_tagging\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	wide\tagSENT_CONTENT	applications\tagSENT_CONTENT	including\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	text\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	part-of-speech_tagging\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	a\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	tag\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	tag\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	important\tagSENT_CONTENT	challenge\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	is\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	transfer\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	one\tagSENT_CONTENT	task\tagSENT_CONTENT	to\tagSENT_CONTENT	another\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	approaches\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	addressed\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	part-of-speech_tagging\tagtask	in\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	manner\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	neurons\tagSENT_CONTENT	organized\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	and\tagSENT_CONTENT	can\tagSENT_CONTENT	transform\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	tokens\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	labels\tagSENT_CONTENT	without\tagSENT_CONTENT	explicit\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	engineered\tagSENT_CONTENT	feature\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	have\tagSENT_CONTENT	named_entity_recognition\tagtask	in\tagSENT_CONTENT	two\tagSENT_CONTENT	folds\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	(\tagSENT_START	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	and\tagSENT_CONTENT	employed\tagSENT_CONTENT	joint\tagSENT_CONTENT	training\tagSENT_CONTENT	to\tagSENT_CONTENT	transfer\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	NER\tagSENT_CONTENT	and\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	to\tagSENT_CONTENT	chunking\tagSENT_CONTENT	;\tagSENT_CONTENT	studied\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	between\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	word\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	in\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	work\tagSENT_CONTENT	builds\tagSENT_CONTENT	on\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	develop\tagSENT_START	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	without\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Later\tagSENT_START	architectures\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	many\tagSENT_CONTENT	tasks\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	APPROACH\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	introduce\tagSENT_CONTENT	an\tagSENT_CONTENT	abstract\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	summarizing\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	discuss\tagSENT_CONTENT	three\tagSENT_CONTENT	different\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	BASE\tagSECTITLE_START	MODEL\tagSECTITLE_END	Though\tagSENT_START	many\tagSENT_CONTENT	different\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	described\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	framework\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in(a\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	layer\tagSENT_CONTENT	subsequently\tagSENT_CONTENT	combines\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	feature\tagSENT_CONTENT	representation\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	further\tagSENT_CONTENT	incorporates\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	output\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	After\tagSENT_START	two\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	encoding\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	representation\tagSENT_CONTENT	output\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	fed\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	field\tagSENT_CONTENT	(\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	layer\tagSENT_CONTENT	that\tagSENT_CONTENT	outputs\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	TRANSFER\tagSECTITLE_START	LEARNING\tagSECTITLE_CONTENT	ARCHITECTURES\tagSECTITLE_END	CROSS\tagSECTITLE_START	-\tagSECTITLE_CONTENT	DOMAIN\tagSECTITLE_CONTENT	TRANSFER\tagSECTITLE_END	The\tagSENT_START	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	transfer\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	part-of-speech_tagging\tagtask	that\tagSENT_CONTENT	transfers\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	domain\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	CROSS\tagSECTITLE_START	-\tagSECTITLE_CONTENT	APPLICATION\tagSECTITLE_CONTENT	TRANSFER\tagSECTITLE_END	part-of-speech_tagging\tagtask	has\tagSENT_CONTENT	a\tagSENT_CONTENT	couple\tagSENT_CONTENT	of\tagSENT_CONTENT	applications\tagSENT_CONTENT	including\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	CROSS\tagSECTITLE_START	-\tagSECTITLE_CONTENT	LINGUAL\tagSECTITLE_CONTENT	TRANSFER\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	Canada\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	English\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	Canadá\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	morphological\tagSENT_CONTENT	similarities\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	leveraged\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	with\tagSENT_CONTENT	nouns\tagSENT_CONTENT	.\tagSENT_END	TRAINING\tagSECTITLE_END	MODEL\tagSECTITLE_START	IMPLEMENTATION\tagSECTITLE_END	where\tagSENT_START	f\tagmetric	is\tagSENT_CONTENT	a\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	assigns\tagSENT_CONTENT	a\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	hand\tagSENT_CONTENT	y\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Y(h\tagSENT_CONTENT	)\tagSENT_CONTENT	denotes\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	tag\tagSENT_CONTENT	sequences\tagSENT_CONTENT	for\tagSENT_CONTENT	h.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	DATASETS\tagSECTITLE_END	We\tagSENT_START	construct\tagSENT_CONTENT	part-of-speech_tagging\tagtask	dataset\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	instructions\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	a\tagSENT_CONTENT	labeling\tagSENT_CONTENT	rater\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	randomly\tagSENT_CONTENT	sample\tagSENT_CONTENT	a\tagSENT_CONTENT	ratio\tagSENT_CONTENT	r\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	discard\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	-\tagSENT_CONTENT	e.g\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	labeling\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	0.001\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	around\tagSENT_CONTENT	900\tagSENT_CONTENT	training\tagSENT_CONTENT	tokens\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	Cf\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	numbers\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	y\tagSENT_CONTENT	-\tagSENT_CONTENT	axes\tagSENT_CONTENT	are\tagSENT_CONTENT	accuracies\tagmetric	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	chunk\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagSENT_CONTENT	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	transfer\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtained\tagSENT_CONTENT	substantial\tagSENT_CONTENT	improvement\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Genia\tagSENT_CONTENT	and\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	corpora\tagSENT_CONTENT	by\tagSENT_CONTENT	transferring\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2003\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in(a\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	obtain\tagSENT_CONTENT	an\tagmetric	tagging\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	83%+\tagSENT_CONTENT	with\tagSENT_CONTENT	zero\tagSENT_CONTENT	labels\tagSENT_CONTENT	and\tagSENT_CONTENT	92\tagSENT_CONTENT	%\tagSENT_CONTENT	with\tagSENT_CONTENT	only\tagSENT_CONTENT	0.001\tagSENT_CONTENT	labels\tagSENT_CONTENT	when\tagSENT_CONTENT	transferring\tagSENT_CONTENT	from\tagSENT_CONTENT	PTB\tagSENT_CONTENT	to\tagSENT_CONTENT	Genia\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Figures\tagSENT_CONTENT	2(d\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	2(e\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	labeling\tagSENT_CONTENT	rates\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	with\tagSENT_CONTENT	0.1\tagSENT_CONTENT	labels\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	8\tagSENT_CONTENT	%\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	COMPARISON\tagSECTITLE_START	WITH\tagSECTITLE_CONTENT	STATE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	ART\tagSECTITLE_CONTENT	RESULTS\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	for\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2000\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2003\tagSENT_CONTENT	NER\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	part-of-speech_tagging\tagtask	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	transferring\tagSENT_CONTENT	from\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	achieves\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	considered\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	except\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	even\tagSENT_CONTENT	on\tagSENT_CONTENT	datasets\tagSENT_CONTENT	with\tagSENT_CONTENT	relatively\tagSENT_CONTENT	abundant\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	exploits\tagSENT_CONTENT	the\tagSENT_CONTENT	generality\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	by\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	in\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	
C16-1119	title\tagSECTITLE_END	relationship_extraction\tagtask	via\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	with\tagSENT_CONTENT	Attention\tagSENT_END	abstract\tagSECTITLE_END	relationship_extraction\tagtask	remains\tagSENT_CONTENT	a\tagSENT_CONTENT	challenge\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	extracting\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	hierarchical\tagSENT_CONTENT	model\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	one\tagSENT_CONTENT	learns\tagSENT_CONTENT	context\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	one\tagSENT_CONTENT	computes\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	these\tagSENT_CONTENT	three\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	produces\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	attracted\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	"\tagSENT_CONTENT	The\tagSENT_CONTENT	software\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	addressed\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	with\tagSENT_CONTENT	thee\tagSENT_CONTENT	2\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	fix\tagSENT_CONTENT	on\tagSENT_CONTENT	Saturday\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	marked\tagSENT_CONTENT	nominals\tagSENT_CONTENT	of\tagSENT_CONTENT	company\tagSENT_CONTENT	and\tagSENT_CONTENT	publication\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	Recently\tagSENT_START	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	aim\tagSENT_CONTENT	at\tagSENT_CONTENT	reducing\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	of\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	annotated\tagSENT_CONTENT	nominals\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	believed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	further\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	around\tagSENT_CONTENT	the\tagSENT_CONTENT	annotated\tagSENT_CONTENT	nominals\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	sentence\tagSENT_CONTENT	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	leant\tagSENT_CONTENT	hierarchically\tagSENT_CONTENT	from\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	to\tagSENT_CONTENT	sentences\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	firstly\tagSENT_CONTENT	learns\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequence\tagSENT_CONTENT	independently\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Recurrent\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	where\tagSENT_START	Wis\tagSENT_CONTENT	trained\tagSENT_CONTENT	matrix\tagSENT_CONTENT	transforming\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	input\tagSENT_CONTENT	x\tagSENT_CONTENT	t\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	linearly\tagSENT_CONTENT	,\tagSENT_CONTENT	U\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	trained\tagSENT_CONTENT	matrix\tagSENT_CONTENT	connecting\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	h\tagSENT_CONTENT	t−1\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	bias\tagSENT_CONTENT	term\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	function\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	tanh\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	neural\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	learns\tagSENT_CONTENT	distributed\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	representations\tagSENT_CONTENT	serving\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	further\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Context\tagSECTITLE_START	Subsequences\tagSECTITLE_END	Some\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	fell\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	idea\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	middle\tagSENT_CONTENT	context\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	relevant\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	combining\tagSENT_CONTENT	the\tagSENT_CONTENT	middle\tagSENT_CONTENT	context\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	context\tagSENT_CONTENT	respectively\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Context\tagSECTITLE_START	Subsequence\tagSECTITLE_CONTENT	Composition\tagSECTITLE_END	Word\tagSECTITLE_START	Encoder\tagSECTITLE_END	where\tagSENT_START	concat\tagSENT_CONTENT	is\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	contain\tagSENT_CONTENT	relationship_extraction\tagtask	than\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	paths\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	maybe\tagSENT_CONTENT	some\tagSENT_CONTENT	irrelevant\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	concentrating\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	strategy\tagSENT_CONTENT	to\tagSENT_CONTENT	pay\tagSENT_CONTENT	more\tagSENT_CONTENT	attention\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	in\tagSENT_CONTENT	classifying\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	Composition\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopt\tagSENT_CONTENT	a\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	to\tagSENT_CONTENT	integrate\tagSENT_CONTENT	syntactics\tagSENT_CONTENT	and\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	annotated\tagSENT_CONTENT	nominals\tagSENT_CONTENT	into\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	further\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	classifier\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	(\tagSENT_START	2\tagSENT_CONTENT	)\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	are\tagSENT_CONTENT	competent\tagSENT_CONTENT	enough\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	only\tagSENT_CONTENT	contains\tagSENT_CONTENT	five\tagSENT_CONTENT	elements\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	make\tagSENT_CONTENT	any\tagSENT_CONTENT	assumptions\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Training\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	Dataset\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Each\tagSENT_START	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	nine\tagSENT_CONTENT	different\tagSENT_CONTENT	relationship\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	artificial\tagSENT_CONTENT	relation\tagSENT_CONTENT	Other\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	has\tagSENT_CONTENT	two\tagSENT_CONTENT	direction\tagSENT_CONTENT	except\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	undirected\tagSENT_CONTENT	relation\tagSENT_CONTENT	Other\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	excluding\tagSENT_CONTENT	Other\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	takes\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_END	Results\tagSECTITLE_END	Model\tagSECTITLE_START	features\tagSECTITLE_CONTENT	F1\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	architecture\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	effectively\tagSENT_CONTENT	captures\tagSENT_CONTENT	semantic\tagSENT_CONTENT	meanings\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	context\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	obtains\tagSENT_CONTENT	more\tagSENT_CONTENT	robust\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	tackle\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	the\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	BiLSTMs\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	then\tagSENT_CONTENT	we\tagSENT_CONTENT	replace\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	average\tagSENT_CONTENT	pooling\tagSENT_CONTENT	,\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	pooling\tagSENT_CONTENT	and\tagSENT_CONTENT	neural\tagSENT_CONTENT	attention\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Results\tagSENT_START	in\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	features\tagSENT_CONTENT	the\tagSENT_CONTENT	F1-scores\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	methods\tagSENT_CONTENT	improve\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	hints\tagSENT_CONTENT	that\tagSENT_CONTENT	three\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	that\tagSENT_START	adds\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	State\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	art\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	Model\tagSECTITLE_END	paths\tagSENT_START	,\tagSENT_CONTENT	which\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	avoid\tagSENT_CONTENT	negative\tagSENT_CONTENT	effect\tagSENT_CONTENT	from\tagSENT_CONTENT	irrelevant\tagSENT_CONTENT	parts\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	result\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	automatically\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	determining\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	argue\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	BiLSTMs\tagSENT_CONTENT	being\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	relationship_extraction\tagtask	on\tagSENT_CONTENT	sequences\tagSENT_CONTENT	and\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	of\tagSECTITLE_CONTENT	ranking\tagSECTITLE_CONTENT	models\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	relationship_extraction\tagtask	following\tagSENT_CONTENT	Thang\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	learns\tagSENT_CONTENT	useful\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	
1704.04565	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Approach\tagSECTITLE_END	Problem\tagSECTITLE_START	Formulation\tagSECTITLE_END	The\tagSECTITLE_START	Decomposable\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Character\tagSECTITLE_START	n\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Gram\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Encodings\tagSECTITLE_END	Noisy\tagSECTITLE_START	Pretraining\tagSECTITLE_END	Experiments\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Results\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Quora\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	Results\tagSECTITLE_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
S13-2002	title\tagSECTITLE_END	abstract\tagSECTITLE_END	The\tagSENT_START	ClearTK\tagSENT_CONTENT	-\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	submission\tagSENT_CONTENT	to\tagSENT_CONTENT	Temp\tagSENT_CONTENT	-\tagSENT_CONTENT	Eval\tagSENT_CONTENT	2013\tagSENT_CONTENT	competed\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	English\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	identifying\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_CONTENT	identifying\tagSENT_CONTENT	times\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	identifying\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	TempEval\tagSENT_CONTENT	shared\tagSENT_CONTENT	tasks\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	venues\tagSENT_CONTENT	for\tagSENT_CONTENT	researchers\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	TempEval\tagSENT_CONTENT	2013\tagSENT_CONTENT	,\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	asked\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_CONTENT	times\tagSENT_CONTENT	and\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	unstructured\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	restrict\tagSENT_CONTENT	temporal_information_extraction\tagtask	to\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	constructions\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	most\tagSENT_CONTENT	confident\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	each\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	is\tagSENT_CONTENT	restricted\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	construction\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal\tagSENT_CONTENT	relation\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	Time\tagSECTITLE_START	models\tagSECTITLE_END	The\tagmetric	temporal\tagmetric	type\tagmetric	of\tagSENT_CONTENT	each\tagSENT_CONTENT	alphanumeric\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	token\tagSENT_CONTENT	,\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	58-word\tagSENT_CONTENT	gazetteer\tagSENT_CONTENT	of\tagSENT_CONTENT	time\tagSENT_CONTENT	words\tagSENT_END	The\tagmetric	temporal\tagmetric	type\tagmetric	of\tagSENT_CONTENT	each\tagSENT_CONTENT	alphanumeric\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	token\tagSENT_CONTENT	,\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	58-word\tagSENT_CONTENT	gazetteer\tagSENT_CONTENT	of\tagSENT_CONTENT	time\tagSENT_CONTENT	words\tagSENT_END	Event\tagSECTITLE_START	models\tagSECTITLE_END	and\tagSECTITLE_START	following\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	tokens\tagSECTITLE_END	Temporal\tagSECTITLE_START	relation\tagSECTITLE_CONTENT	models\tagSECTITLE_END	Three\tagSENT_START	different\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	described\tagSENT_CONTENT	below\tagSENT_CONTENT	,\tagSENT_CONTENT	were\tagSENT_CONTENT	trained\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Event\tagSENT_START	to\tagSENT_CONTENT	document\tagSENT_CONTENT	temporal_information_extraction\tagtask	were\tagSENT_CONTENT	classified\tagSENT_CONTENT	by\tagSENT_CONTENT	considering\tagSENT_CONTENT	(\tagSENT_CONTENT	event\tagSENT_CONTENT	,\tagSENT_CONTENT	time\tagSENT_CONTENT	)\tagSENT_CONTENT	pairs\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	event\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	was\tagSENT_CONTENT	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	creation\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Classifiers\tagSECTITLE_END	The\tagSENT_START	above\tagSENT_CONTENT	models\tagSENT_CONTENT	described\tagSENT_CONTENT	the\tagSENT_CONTENT	translation\tagSENT_CONTENT	from\tagSENT_CONTENT	TempEval\tagmetric	tasks\tagmetric	to\tagSENT_CONTENT	classification\tagSENT_CONTENT	problems\tagSENT_CONTENT	and\tagSENT_CONTENT	classifier\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	classifiers\tagSENT_CONTENT	have\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	that\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	tuned\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	-LIBLINEAR\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	classifier\tagSENT_CONTENT	type\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	parameter\tagSENT_CONTENT	,\tagSENT_CONTENT	Mallet\tagSENT_CONTENT	CRF\tagSENT_CONTENT	has\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	Gaussian\tagSENT_CONTENT	prior\tagSENT_CONTENT	variance\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	sets\tagSECTITLE_END	The\tagSENT_START	TimeBank\tagSENT_CONTENT	event\tagSENT_CONTENT	,\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	annotations\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagmetric	TempEval\tagmetric	organizers\tagmetric	.\tagSENT_END	The\tagSENT_START	AQUAINT\tagSENT_CONTENT	event\tagSENT_CONTENT	,\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	annotations\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagmetric	TempEval\tagmetric	organizers\tagmetric	.\tagSENT_END	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	relations\tagSENT_CONTENT	are\tagSENT_CONTENT	added\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	Data\tagSECTITLE_END	With\tagSENT_START	manually\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	times\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	change\tagSENT_CONTENT	was\tagSENT_CONTENT	+2.2/-0.3\tagSENT_CONTENT	for\tagSENT_CONTENT	verb\tagSENT_CONTENT	-\tagSENT_CONTENT	clause\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	temporal_information_extraction\tagtask	where\tagSENT_CONTENT	recall\tagSENT_CONTENT	improved\tagSENT_CONTENT	)\tagSENT_CONTENT	+1.5/+1.9\tagSENT_CONTENT	for\tagSENT_CONTENT	closure\tagSENT_CONTENT	-\tagSENT_CONTENT	inferred\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	A\tagSENT_START	manual\tagSENT_CONTENT	inspection\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	AQUAINT\tagSENT_CONTENT	corpus\tagSENT_CONTENT	revealed\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	suggesting\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	drop\tagSENT_CONTENT	maybe\tagSENT_CONTENT	the\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	attempting\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	from\tagSENT_CONTENT	inconsistent\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSENT_START	also\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	adding\tagSENT_CONTENT	temporal_information_extraction\tagtask	increased\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	typically\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	precision\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	though\tagSENT_CONTENT	the\tagSENT_CONTENT	added\tagSENT_CONTENT	annotations\tagSENT_CONTENT	were\tagSENT_CONTENT	highly\tagSENT_CONTENT	accurate\tagSENT_CONTENT	:\tagSENT_CONTENT	)\tagSENT_CONTENT	reported\tagSENT_CONTENT	agreement\tagSENT_CONTENT	of\tagSENT_CONTENT	90\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	temporal_information_extraction\tagtask	were\tagSENT_CONTENT	100\tagSENT_CONTENT	%\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	already\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	
D18-1441	title\tagSECTITLE_END	Improving\tagSENT_START	Neural\tagSENT_CONTENT	Abstractive\tagSENT_CONTENT	Document\tagSENT_CONTENT	Summarization\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	*\tagSENT_END	abstract\tagSECTITLE_END	Recent\tagSENT_START	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	significant\tagSENT_CONTENT	progress\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	generating\tagSENT_CONTENT	a\tagSENT_CONTENT	fluent\tagSENT_CONTENT	and\tagSENT_CONTENT	condensed\tagSENT_CONTENT	summary\tagSENT_CONTENT	fora\tagSENT_CONTENT	document\tagSENT_CONTENT	while\tagSENT_CONTENT	retaining\tagSENT_CONTENT	the\tagSENT_CONTENT	gist\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	to\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	not\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	.\tagSENT_END	family\tagSENT_START	members\tagSENT_CONTENT	have\tagSENT_CONTENT	visited\tagSENT_CONTENT	the\tagSENT_CONTENT	grave\tagSENT_CONTENT	every\tagSENT_CONTENT	week\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	mementos\tagmetric	and\tagSENT_CONTENT	flowers\tagSENT_CONTENT	for\tagSENT_CONTENT	faith\tagSENT_CONTENT	and\tagSENT_CONTENT	hope\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	when\tagSENT_CONTENT	mr\tagSENT_CONTENT	howie\tagSENT_CONTENT	and\tagSENT_CONTENT	ms\tagSENT_CONTENT	young\tagSENT_CONTENT	arrived\tagSENT_CONTENT	on\tagSENT_CONTENT	thursday\tagSENT_CONTENT	they\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	site\tagSENT_CONTENT	completely\tagSENT_CONTENT	bare\tagSENT_CONTENT	.\tagSENT_CONTENT	'\tagSENT_END	family\tagSENT_START	members\tagSENT_CONTENT	have\tagSENT_CONTENT	visited\tagSENT_CONTENT	the\tagSENT_CONTENT	grave\tagSENT_CONTENT	every\tagSENT_CONTENT	week\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	mementos\tagmetric	and\tagSENT_CONTENT	flowers\tagSENT_CONTENT	for\tagSENT_CONTENT	faith\tagSENT_CONTENT	and\tagSENT_CONTENT	hope\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	when\tagSENT_CONTENT	parents\tagSENT_CONTENT	simon\tagSENT_CONTENT	howie\tagSENT_CONTENT	and\tagSENT_CONTENT	renee\tagSENT_CONTENT	young\tagSENT_CONTENT	arrived\tagSENT_CONTENT	on\tagSENT_CONTENT	thursday\tagSENT_CONTENT	they\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	site\tagSENT_CONTENT	completely\tagSENT_CONTENT	bare\tagSENT_CONTENT	.\tagSENT_END	family\tagSENT_START	members\tagSENT_CONTENT	have\tagSENT_CONTENT	visited\tagSENT_CONTENT	the\tagSENT_CONTENT	grave\tagSENT_CONTENT	every\tagSENT_CONTENT	week\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	mementos\tagmetric	and\tagSENT_CONTENT	flowers\tagSENT_CONTENT	for\tagSENT_CONTENT	faith\tagSENT_CONTENT	and\tagSENT_CONTENT	hope\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	when\tagSENT_CONTENT	they\tagSENT_CONTENT	were\tagSENT_CONTENT	born\tagSENT_CONTENT	on\tagSENT_CONTENT	thursday\tagSENT_CONTENT	they\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	site\tagSENT_CONTENT	completely\tagSENT_CONTENT	bare\tagSENT_CONTENT	.\tagSENT_END	family\tagSENT_START	members\tagSENT_CONTENT	have\tagSENT_CONTENT	visited\tagSENT_CONTENT	the\tagSENT_CONTENT	grave\tagSENT_CONTENT	every\tagSENT_CONTENT	week\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	mementos\tagmetric	and\tagSENT_CONTENT	flowers\tagSENT_CONTENT	for\tagSENT_CONTENT	faith\tagSENT_CONTENT	and\tagSENT_CONTENT	hope\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	when\tagSENT_CONTENT	they\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	site\tagSENT_CONTENT	completely\tagSENT_CONTENT	bare\tagSENT_CONTENT	.\tagSENT_END	family\tagSENT_START	members\tagSENT_CONTENT	have\tagSENT_CONTENT	visited\tagSENT_CONTENT	the\tagSENT_CONTENT	grave\tagSENT_CONTENT	every\tagSENT_CONTENT	week\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	mementos\tagmetric	and\tagSENT_CONTENT	flowers\tagSENT_CONTENT	for\tagSENT_CONTENT	faith\tagSENT_CONTENT	and\tagSENT_CONTENT	hope\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	when\tagSENT_CONTENT	mr\tagSENT_CONTENT	howie\tagSENT_CONTENT	and\tagSENT_CONTENT	ms\tagSENT_CONTENT	young\tagSENT_CONTENT	arrived\tagSENT_CONTENT	on\tagSENT_CONTENT	thursday\tagSENT_CONTENT	they\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	site\tagSENT_CONTENT	completely\tagSENT_CONTENT	bare\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	of\tagSENT_CONTENT	four\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	news\tagSENT_CONTENT	article\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	naturally\tagSENT_CONTENT	have\tagSENT_CONTENT	document\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	being\tagSENT_CONTENT	a\tagSENT_CONTENT	flat\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	information\tagSENT_CONTENT	compression\tagSENT_CONTENT	and\tagSENT_CONTENT	information\tagSENT_CONTENT	coverage\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	structural\tagSENT_CONTENT	properties\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	archical\tagSENT_START	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	improves\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	performance\tagSENT_CONTENT	significantly\tagSENT_CONTENT	.\tagSENT_END	Hierarchical\tagSECTITLE_START	Encoder\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	distinction\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	design\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	organize\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	realize\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Hierarchical\tagSECTITLE_START	Encoder\tagSECTITLE_END	The\tagSENT_START	wordlevel\tagSENT_CONTENT	encoder\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagmetric	words\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	sentencelevel\tagSENT_CONTENT	encoder\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	Hierarchical\tagSECTITLE_START	Decoder\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Hybrid\tagSECTITLE_END	Sentence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	with\tagSECTITLE_END	where\tagSENT_START	W\tagSENT_CONTENT	v\tagSENT_CONTENT	,\tagSENT_CONTENT	W\tagSENT_CONTENT	c\tagSENT_CONTENT	,\tagSENT_CONTENT	b\tagSENT_CONTENT	c\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	v\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	parameters\tagmetric	.\tagSENT_END	Structural\tagSECTITLE_START	Regularization\tagSECTITLE_END	Although\tagSENT_START	the\tagSENT_CONTENT	above\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	designed\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	documentsentence\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	ca\tagSENT_CONTENT	n't\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	structural\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	see(d\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Structural\tagSECTITLE_START	Compression\tagSECTITLE_END	Compression\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	basic\tagSENT_CONTENT	property\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	explored\tagSENT_CONTENT	in\tagSENT_CONTENT	traditional\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sentence\tagSENT_CONTENT	compression\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	which\tagSENT_CONTENT	shorten\tagSENT_CONTENT	sentences\tagSENT_CONTENT	by\tagSENT_CONTENT	removing\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	salient\tagSENT_CONTENT	parts\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	fusion\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	which\tagSENT_CONTENT	merge\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	several\tagSENT_CONTENT	different\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	-\tagSENT_CONTENT	compression\tagSENT_CONTENT	property\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	distributions\tagSENT_CONTENT	by\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	α\tagSENT_CONTENT	t\tagSENT_CONTENT	denotes\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	distribution\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	the\tagSENT_CONTENT	tth\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	N\tagSENT_CONTENT	denotes\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	α\tagSENT_CONTENT	t\tagSENT_CONTENT	.\tagSENT_END	Structural\tagSECTITLE_START	Coverage\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	simply\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	structuralcoverage\tagSENT_CONTENT	property\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	architecture\tagSENT_CONTENT	by\tagSENT_CONTENT	encouraging\tagSENT_CONTENT	different\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	can\tagSENT_CONTENT	cover\tagSENT_CONTENT	more\tagSENT_CONTENT	salient\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	which\tagSENT_START	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	encourage\tagSENT_CONTENT	different\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	during\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Model\tagSECTITLE_START	Learning\tagSECTITLE_END	where\tagSENT_START	λ\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	λ\tagSENT_CONTENT	2\tagSENT_CONTENT	are\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	tuned\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	.\tagSENT_END	Hierarchical\tagSECTITLE_START	Decoding\tagSECTITLE_CONTENT	Algorithm\tagSECTITLE_END	where\tagSENT_START	ζ\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	ζ\tagSENT_CONTENT	2\tagSENT_CONTENT	are\tagSENT_CONTENT	factors\tagSENT_CONTENT	introduced\tagSENT_CONTENT	to\tagSENT_CONTENT	control\tagSENT_CONTENT	the\tagSENT_CONTENT	influence\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	during\tagSENT_CONTENT	the\tagSENT_CONTENT	decoding\tagSENT_CONTENT	process\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	After\tagSENT_START	tuning\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	parameters\tagmetric	λ\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	λ\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	ζ\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	ζ\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	set\tagSENT_CONTENT	as\tagSENT_CONTENT	-0.5\tagSENT_CONTENT	,\tagSENT_CONTENT	-1.0\tagSENT_CONTENT	,\tagSENT_CONTENT	1.2\tagSENT_CONTENT	and\tagSENT_CONTENT	1.4\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	ROUGE\tagmetric	Evaluation\tagmetric	.\tagSENT_END	The\tagSENT_START	extractive\tagSENT_CONTENT	models\tagSENT_CONTENT	include\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	and\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	-\tagSENT_CONTENT	abs\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	but\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	directly\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	interesting\tagSENT_CONTENT	observation\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	-\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	Seq2seq\tagSENT_CONTENT	-\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	demonstrates\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	fora\tagSENT_CONTENT	traditional\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	To\tagSENT_START	verify\tagSENT_CONTENT	the\tagSENT_CONTENT	superiority\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	generating\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	them\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_END	summarization\tagtask	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	Seq2Seq\tagSENT_CONTENT	-\tagSENT_CONTENT	Baseline\tagSENT_CONTENT	usually\tagSENT_CONTENT	contains\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	or\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	seriously\tagSENT_CONTENT	affects\tagSENT_CONTENT	its\tagSENT_CONTENT	informativeness\tagSENT_CONTENT	,\tagSENT_CONTENT	conciseness\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	coherence\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	obviously\tagSENT_CONTENT	contains\tagSENT_CONTENT	more\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	concise\tagSENT_CONTENT	through\tagSENT_CONTENT	sentences\tagSENT_CONTENT	compression\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	regularization\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Model\tagSECTITLE_START	Validation\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	-\tagSENT_CONTENT	compression\tagSENT_CONTENT	and\tagSENT_CONTENT	structural\tagSENT_CONTENT	-\tagSENT_CONTENT	coverage\tagSENT_CONTENT	regularization\tagSENT_CONTENT	significantly\tagSENT_CONTENT	affect\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Structural\tagSECTITLE_START	Properties\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	We\tagSENT_START	further\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	capturing\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	-\tagSENT_CONTENT	compression\tagSENT_CONTENT	and\tagSENT_CONTENT	structural\tagSENT_CONTENT	-\tagSENT_CONTENT	coverage\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Effects\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Structural\tagSECTITLE_CONTENT	Regularization\tagSECTITLE_END	summarization\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	our\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	with\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	summaries\tagSENT_CONTENT	from\tagSENT_CONTENT	two\tagSENT_CONTENT	aspects\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Recently\tagSENT_START	some\tagmetric	work\tagmetric	explored\tagSENT_CONTENT	the\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	exhibit\tagSENT_CONTENT	some\tagSENT_CONTENT	undesirable\tagSENT_CONTENT	behaviors\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	inaccurately\tagSENT_CONTENT	reproducing\tagSENT_CONTENT	factual\tagSENT_CONTENT	details\tagSENT_CONTENT	,\tagSENT_CONTENT	OOVs\tagSENT_CONTENT	and\tagSENT_CONTENT	repetitions\tagSENT_CONTENT	.\tagSENT_END	Reinforcement\tagSENT_START	learning\tagSENT_CONTENT	has\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	studied\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	global\tagSENT_CONTENT	sequence\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	has\tagSENT_CONTENT	first\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	the\tagSENT_CONTENT	long\tagSENT_CONTENT	dependency\tagSENT_CONTENT	problem\tagSENT_CONTENT	for\tagSENT_CONTENT	long\tagSENT_CONTENT	inputs\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	and\tagSENT_CONTENT	verify\tagSENT_CONTENT	the\tagSENT_CONTENT	necessity\tagSENT_CONTENT	of\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	document\tagSENT_CONTENT	structure\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	capturing\tagSENT_CONTENT	structural\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	by\tagSENT_CONTENT	importing\tagSENT_CONTENT	both\tagSENT_CONTENT	structuralcompression\tagSENT_CONTENT	and\tagSENT_CONTENT	structural\tagSENT_CONTENT	-\tagSENT_CONTENT	coverage\tagSENT_CONTENT	regularization\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoderdecoder\tagSENT_CONTENT	with\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	
N18-2009	title\tagSECTITLE_END	Guiding\tagSENT_START	summarization\tagtask	for\tagSENT_CONTENT	Abstractive\tagSENT_CONTENT	Text\tagSENT_CONTENT	Summarization\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	Key\tagSENT_CONTENT	Information\tagSENT_CONTENT	Guide\tagSENT_CONTENT	Network\tagSENT_END	abstract\tagSECTITLE_END	Neural\tagSENT_START	network\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	at\tagSENT_CONTENT	-\tagSENT_CONTENT	tentional\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	have\tagSENT_CONTENT	good\tagSENT_CONTENT	capability\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	brief\tagSENT_CONTENT	summary\tagSENT_CONTENT	from\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	while\tagSENT_CONTENT	retaining\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	encoderdecoder\tagSENT_CONTENT	model\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	high\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	guiding\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	Key\tagSECTITLE_START	Information\tagSECTITLE_CONTENT	Guide\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	pointer\tagSECTITLE_END	Our\tagSECTITLE_START	Model\tagSECTITLE_END	Encoder\tagSECTITLE_START	-\tagSECTITLE_CONTENT	decoder\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	attention\tagSECTITLE_END	Key\tagSECTITLE_START	information\tagSECTITLE_CONTENT	guide\tagSECTITLE_CONTENT	network\tagSECTITLE_END	Most\tagSENT_START	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	just\tagSENT_CONTENT	get\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	output\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	hard\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	controlled\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	alack\tagSENT_CONTENT	of\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	representation\tagSENT_CONTENT	k\tagSENT_CONTENT	as\tagSENT_CONTENT	extra\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	,\tagSENT_CONTENT	changing\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	:\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	e\tagSENT_CONTENT	ti\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	new\tagSENT_CONTENT	attention\tagSENT_CONTENT	distribution\tagSENT_CONTENT	α\tagSENT_CONTENT	e\tagSENT_CONTENT	t\tagSENT_CONTENT	(\tagSENT_CONTENT	summarization\tagtask	2\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	new\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	ct\tagSENT_CONTENT	(\tagSENT_CONTENT	Equation\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Then\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	representation\tagSENT_CONTENT	k\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	ct\tagSENT_CONTENT	to\tagSENT_CONTENT	calculate\tagSENT_CONTENT	a\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	overall\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	,\tagSENT_CONTENT	changing\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	:\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	,\tagSENT_CONTENT	some\tagSENT_CONTENT	keywords\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	will\tagSENT_CONTENT	certainly\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	alack\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	w\tagSENT_START	T\tagSENT_CONTENT	sand\tagSENT_CONTENT	b\tagSENT_CONTENT	sw\tagSENT_CONTENT	are\tagSENT_CONTENT	parameters\tagmetric	,\tagSENT_CONTENT	σ\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sigmoid\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	test\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	probability\tagSENT_CONTENT	(\tagSENT_CONTENT	summarization\tagtask	9\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	a\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	term\tagSENT_CONTENT	value\tagSENT_CONTENT	predicted\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	-\tagSENT_CONTENT	guide\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	detail\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	an\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	model\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	y|x\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	Equation\tagSENT_CONTENT	9\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	predictionguide\tagSENT_CONTENT	network\tagSENT_CONTENT	v(x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	α\tagSENT_CONTENT	∈\tagSENT_CONTENT	(\tagSENT_CONTENT	0\tagSENT_CONTENT	,\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	score\tagmetric	of\tagSENT_CONTENT	partial\tagSENT_CONTENT	sequence\tagSENT_CONTENT	y\tagSENT_CONTENT	for\tagSENT_CONTENT	x\tagSENT_CONTENT	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	:\tagSENT_END	Model\tagSECTITLE_END	ROUGE-1\tagSECTITLE_START	ROUGE-2\tagSECTITLE_CONTENT	ROUGE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	L\tagSECTITLE_END	Experiments\tagSECTITLE_END	Experiment\tagSECTITLE_START	setting\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	of\tagSENT_CONTENT	50k\tagSENT_CONTENT	words\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	source\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	and\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_END	ROUGE\tagSECTITLE_START	F\tagSECTITLE_CONTENT	Score\tagSECTITLE_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	discussions\tagSECTITLE_END	shows\tagSENT_START	that\tagSENT_CONTENT	our\tagSENT_CONTENT	key\tagSENT_CONTENT	information\tagSENT_CONTENT	guide\tagSENT_CONTENT	network\tagSENT_CONTENT	scores\tagSENT_CONTENT	exceed\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	equipped\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	by\tagSENT_CONTENT	(\tagmetric	+1.3\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	+0.9\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	,\tagSENT_CONTENT	+1.0\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	mechanism\tagSENT_START	by\tagSENT_CONTENT	(\tagmetric	+2.5\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	+1.5\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	,\tagSENT_CONTENT	+2.2\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Case\tagSECTITLE_START	study\tagSECTITLE_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	guiding\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
D18-1088	title\tagSECTITLE_END	abstract\tagSECTITLE_END	summarization\tagtask	require\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	created\tagSENT_CONTENT	heuristically\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	)\tagSENT_CONTENT	given\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	summarization\tagSENT_CONTENT	datasets\tagSENT_CONTENT	only\tagSENT_CONTENT	have\tagSENT_CONTENT	document\tagSENT_CONTENT	-\tagSENT_CONTENT	summary\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	rewrite\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	while\tagSENT_CONTENT	retaining\tagSENT_CONTENT	its\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	content\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	great\tagSENT_CONTENT	deal\tagSENT_CONTENT	of\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	usually\tagSENT_CONTENT	modeled\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	ranking\tagSENT_CONTENT	or\tagSENT_CONTENT	binary\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	sentences\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	top\tagSENT_CONTENT	ranked\tagSENT_CONTENT	or\tagSENT_CONTENT	predicted\tagSENT_CONTENT	as\tagSENT_CONTENT	True\tagSENT_CONTENT	are\tagSENT_CONTENT	selected\tagSENT_CONTENT	as\tagSENT_CONTENT	summaries\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	successful\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	availability\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	has\tagSENT_CONTENT	provided\tagSENT_CONTENT	strong\tagSENT_CONTENT	impetus\tagSENT_CONTENT	to\tagSENT_CONTENT	develop\tagSENT_CONTENT	data\tagSENT_CONTENT	-\tagSENT_CONTENT	driven\tagSENT_CONTENT	approaches\tagSENT_CONTENT	which\tagSENT_CONTENT	take\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	continuousspace\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	seemingly\tagSENT_CONTENT	more\tagSENT_CONTENT	successful\tagSENT_CONTENT	than\tagSENT_CONTENT	their\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	counterparts\tagSENT_CONTENT	,\tagSENT_CONTENT	extractive\tagSENT_CONTENT	models\tagSENT_CONTENT	require\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	included\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	only\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	gold\tagSENT_CONTENT	summary\tagSENT_CONTENT	pairs\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Neural\tagSECTITLE_START	Extractive\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	is\tagSENT_CONTENT	selected\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	W\tagSENT_CONTENT	e\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	d×2\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	embedding\tagSENT_CONTENT	matrix\tagSENT_CONTENT	(\tagSENT_CONTENT	d\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	dimension\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	decoder\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_CONTENT	i−1\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	at\tagSENT_CONTENT	time\tagmetric	Sentence\tagSECTITLE_START	Compression\tagSECTITLE_END	The\tagSENT_START	training\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	summarization\tagtask	dataset\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	exractive\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Latent\tagSECTITLE_START	Extractive\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	Our\tagSENT_START	latent\tagSENT_CONTENT	variable\tagSENT_CONTENT	model\tagSENT_CONTENT	views\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	as\tagSENT_CONTENT	binary\tagSENT_CONTENT	variables\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	zeros\tagSENT_CONTENT	and\tagSENT_CONTENT	ones\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	uses\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	activated\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	ones\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	extractive\tagSENT_CONTENT	model\tagSENT_CONTENT	from\tagSENT_CONTENT	Section\tagSENT_CONTENT	2.1\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	probability\tagSENT_CONTENT	distributions\tagSENT_CONTENT	for\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	and\tagSENT_CONTENT	obtain\tagSENT_CONTENT	them\tagSENT_CONTENT	by\tagSENT_CONTENT	sampling\tagSENT_CONTENT	z\tagSENT_END	R\tagSENT_START	p\tagSENT_CONTENT	(\tagSENT_CONTENT	C\tagSENT_CONTENT	,\tagSENT_CONTENT	H\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	precision\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	regard\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	R\tagSENT_START	r\tagSENT_CONTENT	(\tagSENT_CONTENT	C\tagSENT_CONTENT	,\tagSENT_CONTENT	H\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	recall\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	regard\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Our\tagSENT_START	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	terms\tagSENT_CONTENT	"\tagSENT_CONTENT	precision\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	recall\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	reminiscent\tagSENT_CONTENT	of\tagSENT_CONTENT	relevance\tagSENT_CONTENT	and\tagSENT_CONTENT	coverage\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	where\tagSENT_START	p(·|D\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	distribution\tagSENT_CONTENT	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	extractive\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSENT_START	and\tagSENT_CONTENT	summarization\tagtask	We\tagSENT_CONTENT	conducted\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Dailymail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	trained\tagSENT_CONTENT	our\tagSENT_CONTENT	extractive\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	10\tagSENT_CONTENT	epochs\tagSENT_CONTENT	and\tagSENT_CONTENT	selected\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	.\tagSENT_END	Results\tagSENT_START	of\tagSENT_CONTENT	different\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Dailymail\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	using\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	F1\tagSENT_CONTENT	ROUGE-1\tagSENT_CONTENT	(\tagSENT_CONTENT	R-1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	ROUGE-2\tagmetric	(\tagSENT_CONTENT	R-2\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	latent\tagSENT_CONTENT	model\tagSENT_CONTENT	was\tagSENT_CONTENT	initialized\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	extractive\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	thus\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	size\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	weight\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	α\tagSENT_CONTENT	=\tagSENT_CONTENT	0.5\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	summarization\tagtask	generates\tagSENT_CONTENT	anonymized\tagSENT_CONTENT	summaries\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	while\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	generate\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	anonymized\tagSENT_CONTENT	ones\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	EXTRACT\tagSENT_CONTENT	and\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	strictly\tagSENT_CONTENT	comparable\tagSENT_CONTENT	(\tagSENT_CONTENT	also\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	LEAD3\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	different\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	As\tagSECTITLE_CONTENT	shown\tagSECTITLE_CONTENT	in\tagSECTITLE_END	Our\tagSENT_START	latent\tagSENT_CONTENT	variable\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	LATENT\tagSENT_CONTENT	;\tagSENT_CONTENT	Section\tagSENT_CONTENT	2.3\tagSENT_CONTENT	)\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	EXTRACT\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	being\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	loss\tagSENT_CONTENT	directly\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	Experimental\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	indeed\tagSENT_CONTENT	improve\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	extractive\tagSENT_CONTENT	model\tagSENT_CONTENT	while\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	compression\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	extractive\tagSENT_CONTENT	system\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	inferior\tagSENT_CONTENT	output\tagSENT_CONTENT	.\tagSENT_END	
1602.02373	title\tagSECTITLE_END	abstract\tagSECTITLE_END	One\tagSENT_START	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	CNN\tagSENT_CONTENT	(\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	Johnson\tagSENT_CONTENT	&\tagSENT_CONTENT	Zhang\tagSENT_CONTENT	,\tagSENT_CONTENT	2015a;b\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	text_classification\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	assigning\tagSENT_CONTENT	labels\tagSENT_CONTENT	to\tagSENT_CONTENT	documents\tagSENT_CONTENT	written\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	numerous\tagSENT_CONTENT	real\tagSENT_CONTENT	-\tagSENT_CONTENT	world\tagSENT_CONTENT	applications\tagSENT_CONTENT	including\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	traditional\tagSENT_CONTENT	topic\tagSENT_CONTENT	assignment\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	its\tagSENT_CONTENT	convolution\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	region\tagSENT_CONTENT	of\tagSENT_CONTENT	data\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	square\tagSENT_CONTENT	of\tagSENT_CONTENT	image\tagSENT_CONTENT	)\tagSENT_CONTENT	at\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	converted\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	vector\tagSENT_CONTENT	with\tagSENT_CONTENT	information\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	being\tagSENT_CONTENT	preserved\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	loosely\tagSENT_CONTENT	term\tagSENT_CONTENT	'\tagSENT_CONTENT	embedding\tagSENT_CONTENT	'\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	text_classification\tagtask	to\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	takes\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	one\tagSENT_CONTENT	by\tagSENT_CONTENT	one\tagSENT_CONTENT	;\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	time\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	takes\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	the\tagSENT_CONTENT	t\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	from\tagSENT_CONTENT	time\tagSENT_CONTENT	t\tagSENT_CONTENT	−\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	strategy\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	simplify\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	as\tagSENT_CONTENT	possible\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	routinely\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	Preliminary\tagSECTITLE_END	It\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	also\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	representing\tagSENT_CONTENT	short\tagSENT_CONTENT	sentences\tagSENT_CONTENT	mostly\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	some\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	;\tagSENT_CONTENT	see\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	denotes\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	σ\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	element\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	squash\tagSENT_CONTENT	function\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	gating\tagSENT_CONTENT	values\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	DL15\tagSENT_START	's\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	put\tagSENT_CONTENT	it\tagSENT_CONTENT	into\tagSENT_CONTENT	perspective\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	GPU\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	epoch\tagSENT_CONTENT	of\tagSENT_CONTENT	wv\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	training\tagSENT_CONTENT	takes\tagSENT_CONTENT	nearly\tagSENT_CONTENT	20\tagSENT_CONTENT	times\tagSENT_CONTENT	longer\tagSENT_CONTENT	than\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	CNN\tagSENT_CONTENT	training\tagSENT_CONTENT	even\tagSENT_CONTENT	though\tagSENT_CONTENT	it\tagSENT_CONTENT	achieves\tagSENT_CONTENT	poorer\tagmetric	accuracy\tagmetric	(\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	two\tagSENT_CONTENT	rows\tagSENT_CONTENT	of\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	was\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	DL15\tagSENT_CONTENT	that\tagSENT_CONTENT	training\tagSENT_CONTENT	becomes\tagSENT_CONTENT	stable\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagmetric	improves\tagSENT_CONTENT	drastically\tagSENT_CONTENT	when\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	are\tagSENT_CONTENT	jointly\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	either\tagSENT_CONTENT	the\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	learning\tagSENT_CONTENT	objective\tagSENT_CONTENT	(\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	word\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	autoencoder\tagSENT_CONTENT	objective\tagSENT_CONTENT	(\tagSENT_CONTENT	memorizing\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	LSTM\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	text\tagSECTITLE_CONTENT	categorization\tagSECTITLE_END	Within\tagSENT_START	the\tagSENT_CONTENT	framework\tagSENT_CONTENT	of\tagSENT_CONTENT	'\tagSENT_CONTENT	region\tagSENT_CONTENT	embedding\tagSENT_CONTENT	+\tagSENT_CONTENT	pooling\tagSENT_CONTENT	'\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	seek\tagSENT_CONTENT	effective\tagSENT_CONTENT	and\tagSENT_CONTENT	efficient\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	alternative\tagSENT_CONTENT	region\tagSENT_CONTENT	embedding\tagSENT_CONTENT	method\tagSENT_CONTENT	.\tagSENT_END	Elimination\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	word\tagSECTITLE_CONTENT	embedding\tagSECTITLE_CONTENT	layer\tagSECTITLE_END	Thus\tagSENT_START	,\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	vector\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	more\tagSENT_CONTENT	expressive\tagSENT_CONTENT	than\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	;\tagSENT_CONTENT	rather\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	merit\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	any\tagSENT_CONTENT	,\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	through\tagSENT_CONTENT	imposing\tagSENT_CONTENT	In\tagSENT_START	the\tagSENT_CONTENT	preliminary\tagSENT_CONTENT	experiments\tagSENT_CONTENT	under\tagSENT_CONTENT	our\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	were\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagmetric	over\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	by\tagSENT_CONTENT	inclusion\tagSENT_CONTENT	of\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	randomly\tagSENT_CONTENT	initialized\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	;\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	random\tagSENT_CONTENT	vectors\tagSENT_CONTENT	failed\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	good\tagSENT_CONTENT	prior\tagSENT_CONTENT	effects\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	,\tagSENT_CONTENT	demerits\tagSENT_CONTENT	were\tagSENT_CONTENT	evident\tagSENT_CONTENT	-more\tagSENT_CONTENT	meta\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	to\tagSENT_CONTENT	tune\tagSENT_CONTENT	,\tagSENT_CONTENT	poor\tagmetric	accuracy\tagmetric	with\tagSENT_CONTENT	lowdimensional\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	slow\tagSENT_CONTENT	training\tagSENT_CONTENT	/\tagSENT_CONTENT	testing\tagSENT_CONTENT	with\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	as\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	dense\tagSENT_CONTENT	.\tagSENT_END	Altogether\tagSENT_START	,\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	was\tagSENT_CONTENT	found\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	useful\tagSENT_CONTENT	;\tagSENT_CONTENT	thus\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	base\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	More\tagSECTITLE_START	simplifications\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	four\tagSENT_CONTENT	more\tagSENT_CONTENT	useful\tagSENT_CONTENT	modifications\tagSENT_CONTENT	to\tagSENT_CONTENT	wv\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	that\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	higher\tagmetric	accuracy\tagmetric	or\tagSENT_CONTENT	faster\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	simplifying\tagSENT_START	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	problems\tagSENT_CONTENT	Our\tagSENT_CONTENT	framework\tagSENT_CONTENT	of\tagSENT_CONTENT	'\tagSENT_CONTENT	region\tagSENT_CONTENT	embedding\tagSENT_CONTENT	+\tagSENT_CONTENT	pooling\tagSENT_CONTENT	'\tagSENT_CONTENT	has\tagSENT_CONTENT	text_classification\tagtask	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	we\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	embedding\tagSENT_CONTENT	text_classification\tagtask	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	documents\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	longer\tagSENT_CONTENT	crucial\tagSENT_CONTENT	to\tagSENT_CONTENT	go\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	sequentially\tagSENT_CONTENT	.\tagSENT_END	Removing\tagSENT_START	the\tagSENT_CONTENT	input\tagSENT_CONTENT	/\tagSENT_CONTENT	output\tagSENT_CONTENT	gates\tagSENT_CONTENT	We\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	is\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	pooling\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	gates\tagSENT_CONTENT	typically\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagmetric	,\tagSENT_CONTENT	while\tagSENT_CONTENT	removing\tagSENT_CONTENT	them\tagSENT_CONTENT	nearly\tagSENT_CONTENT	halves\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	memory\tagmetric	required\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	(\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	)\tagSECTITLE_END	text_classification\tagtask	was\tagSENT_CONTENT	done\tagSENT_CONTENT	with\tagSENT_CONTENT	SGD\tagSENT_CONTENT	with\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	50\tagSENT_CONTENT	or\tagSENT_CONTENT	100\tagSENT_CONTENT	with\tagSENT_CONTENT	momentum\tagSENT_CONTENT	or\tagSENT_CONTENT	optionally\tagSENT_CONTENT	rmsprop\tagSENT_CONTENT	for\tagSENT_CONTENT	acceleration\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	pooling\tagSENT_CONTENT	settings\tagSENT_CONTENT	chosen\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	data\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	as\tagSENT_CONTENT	JZ15a\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	pooling\tagSENT_CONTENT	with\tagSENT_CONTENT	k=1\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	and\tagSENT_CONTENT	Elec\tagSENT_CONTENT	and\tagSENT_CONTENT	average\tagSENT_CONTENT	-\tagSENT_CONTENT	pooling\tagSENT_CONTENT	with\tagSENT_CONTENT	k=10\tagSENT_CONTENT	on\tagSENT_CONTENT	RCV1\tagSENT_CONTENT	;\tagSENT_CONTENT	on\tagSENT_CONTENT	20NG\tagSENT_CONTENT	,\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	pooling\tagSENT_CONTENT	with\tagSENT_CONTENT	k=10\tagSENT_CONTENT	was\tagSENT_CONTENT	chosen\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	other\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	convolution\tagSENT_CONTENT	layer\tagSENT_CONTENT	produces\tagSENT_CONTENT	a\tagSENT_CONTENT	1000-dimensional\tagSENT_CONTENT	vector\tagSENT_CONTENT	at\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	direction\tagSENT_CONTENT	emits\tagSENT_CONTENT	a\tagSENT_CONTENT	500-dimensional\tagSENT_CONTENT	vector\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	methods\tagSECTITLE_END	IMDB\tagSECTITLE_END	text_classification\tagtask	of\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	CNN\tagSENT_CONTENT	results\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	constraints\tagSENT_CONTENT	above\tagSENT_CONTENT	.\tagSENT_END	methods\tagSECTITLE_END	IMDB\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	shortcoming\tagSENT_CONTENT	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	alleviated\tagSENT_CONTENT	by\tagSENT_CONTENT	having\tagSENT_CONTENT	multiple\tagSENT_CONTENT	convolution\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	previous\tagSECTITLE_CONTENT	best\tagSECTITLE_CONTENT	results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	20NG\tagSECTITLE_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_END	Two\tagSECTITLE_START	-\tagSECTITLE_CONTENT	view\tagSECTITLE_CONTENT	embedding\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	tv\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	embedding\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	JZ15b\tagSECTITLE_CONTENT	]\tagSECTITLE_END	If\tagSENT_START	the\tagSENT_CONTENT	two\tagSENT_CONTENT	views\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	labels\tagSENT_CONTENT	(\tagSENT_CONTENT	text_classification\tagtask	)\tagSENT_CONTENT	are\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	one\tagSENT_CONTENT	another\tagSENT_CONTENT	only\tagSENT_CONTENT	through\tagSENT_CONTENT	some\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	the\tagSENT_CONTENT	tv\tagSENT_CONTENT	-\tagSENT_CONTENT	embedded\tagSENT_CONTENT	view\tagSENT_CONTENT	is\tagSENT_CONTENT	as\tagSENT_CONTENT	good\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	view\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	purpose\tagSENT_CONTENT	of\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	JZ15b\tagSENT_START	applied\tagSENT_CONTENT	this\tagSENT_CONTENT	idea\tagSENT_CONTENT	by\tagSENT_CONTENT	regarding\tagSENT_CONTENT	text_classification\tagtask	embedded\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	convolution\tagSENT_CONTENT	layer\tagSENT_CONTENT	as\tagSENT_CONTENT	one\tagSENT_CONTENT	view\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	context\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	view\tagSENT_CONTENT	and\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagSENT_CONTENT	tv\tagSENT_CONTENT	-\tagSENT_CONTENT	embedding\tagSENT_CONTENT	(\tagSENT_CONTENT	embodied\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	convolution\tagSENT_CONTENT	layer\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_START	LSTM\tagSECTITLE_CONTENT	tv\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_END	Combining\tagSECTITLE_START	LSTM\tagSECTITLE_CONTENT	tv\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	tv\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	experiments\tagSECTITLE_END	The\tagmetric	error\tagmetric	rate\tagmetric	on\tagSENT_CONTENT	IMDB\tagSENT_CONTENT	is\tagSENT_CONTENT	from\tagSENT_CONTENT	DL15\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	those\tagSENT_CONTENT	on\tagSENT_CONTENT	Elec\tagSENT_CONTENT	and\tagSENT_CONTENT	RCV1\tagSENT_CONTENT	are\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	effort\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	objective\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	attribute\tagSENT_CONTENT	the\tagSENT_CONTENT	superiority\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	tv\tagSENT_CONTENT	-\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	learn\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	convey\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	concepts\tagSENT_CONTENT	than\tagSENT_CONTENT	single\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	isolation\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	combining\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	tv\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	tv\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_END	Unlabeled\tagSECTITLE_START	data\tagSECTITLE_CONTENT	usage\tagSECTITLE_CONTENT	IMDB\tagSECTITLE_CONTENT	Elec\tagSECTITLE_CONTENT	RCV1\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	oh-2LSTMp\tagSECTITLE_END	6.27\tagSECTITLE_START	7.71\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	oh-2LSTMp\tagSECTITLE_END	5.55\tagSECTITLE_START	8.52\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	oh\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	CNN\tagSECTITLE_END	Error\tagmetric	rates\tagmetric	(\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	CNN\tagSENT_CONTENT	tv\tagSENT_CONTENT	-\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	were\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	size\tagSENT_CONTENT	k\tagSENT_CONTENT	at\tagSENT_CONTENT	every\tagSENT_CONTENT	location\tagSENT_CONTENT	taking\tagSENT_CONTENT	bow\tagSENT_CONTENT	input\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	k\tagSENT_CONTENT	is\tagSENT_CONTENT	5\tagSENT_CONTENT	on\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	adding\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	tv\tagSENT_CONTENT	-\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	of\tagSENT_CONTENT	row#1\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	error\tagmetric	rate\tagmetric	on\tagSENT_CONTENT	IMDB\tagSENT_CONTENT	improved\tagSENT_CONTENT	from\tagSENT_CONTENT	6.66\tagSENT_CONTENT	to\tagSENT_CONTENT	5.94\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	adding\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	tv\tagSENT_CONTENT	-\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	of\tagSENT_CONTENT	row#2\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	error\tagSENT_CONTENT	rate\tagSENT_CONTENT	on\tagSENT_CONTENT	RCV1\tagSENT_CONTENT	improved\tagSENT_CONTENT	from\tagSENT_CONTENT	7.71\tagSENT_CONTENT	to\tagSENT_CONTENT	7.15\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	previous\tagSECTITLE_CONTENT	best\tagSECTITLE_CONTENT	results\tagSECTITLE_END	The\tagSENT_START	best\tagSENT_CONTENT	supervised\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	/\tagSENT_END	Many\tagSENT_START	more\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	can\tagSENT_CONTENT	be\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	over\tagSENT_CONTENT	10\tagSENT_CONTENT	%\tagSENT_CONTENT	except\tagSENT_CONTENT	for\tagSENT_CONTENT	8.78\tagSENT_CONTENT	by\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	NBSVM\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	new\tagSENT_CONTENT	model\tagSENT_CONTENT	further\tagSENT_CONTENT	improved\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	5.94\tagSENT_CONTENT	;\tagSENT_CONTENT	also\tagSENT_CONTENT	on\tagSENT_CONTENT	Elec\tagSENT_CONTENT	and\tagSENT_CONTENT	RCV1\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	models\tagSENT_CONTENT	exceeded\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Within\tagSENT_START	the\tagSENT_CONTENT	general\tagSENT_CONTENT	framework\tagSENT_CONTENT	of\tagSENT_CONTENT	'\tagSENT_CONTENT	region\tagSENT_CONTENT	embedding\tagSENT_CONTENT	+\tagSENT_CONTENT	pooling\tagSENT_CONTENT	'\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	explored\tagSENT_CONTENT	region\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	via\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	hot\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	convey\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	concepts\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	useful\tagSENT_CONTENT	than\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	single\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	isolation\tagSENT_CONTENT	.\tagSENT_END	
1609.01704	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	handwriting\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	The\tagSENT_START	most\tagSENT_CONTENT	popular\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	timescales\tagSENT_CONTENT	as\tagSENT_CONTENT	hyperparameters\tagmetric	)\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	treating\tagSENT_CONTENT	them\tagSENT_CONTENT	as\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	variables\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	learned\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	modelling\tagSENT_CONTENT	and\tagSENT_CONTENT	handwriting\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	time\tagSENT_CONTENT	language_modeling\tagtask	that\tagSENT_CONTENT	can\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	latent\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	without\tagSENT_CONTENT	using\tagSENT_CONTENT	explicit\tagSENT_CONTENT	boundary\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	straight\tagSENT_CONTENT	-\tagSENT_CONTENT	through\tagSENT_CONTENT	estimator\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	efficient\tagSENT_CONTENT	way\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	language_modeling\tagtask	containing\tagSENT_CONTENT	discrete\tagSENT_CONTENT	variables\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	Two\tagSENT_START	notable\tagSENT_CONTENT	early\tagSENT_CONTENT	attempts\tagSENT_CONTENT	inspiring\tagSENT_CONTENT	language_modeling\tagtask	are\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	unlike\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	these\tagSENT_CONTENT	timescales\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	organized\tagSENT_CONTENT	hierarchically\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	finding\tagSENT_CONTENT	proper\tagSENT_CONTENT	timescales\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	CW\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	remains\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	challenge\tagSENT_CONTENT	whereas\tagSENT_CONTENT	language_modeling\tagtask	learns\tagSENT_CONTENT	the\tagSENT_CONTENT	intrinsic\tagSENT_CONTENT	timescales\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Other\tagmetric	forms\tagmetric	of\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	RNN\tagSENT_CONTENT	(\tagSENT_CONTENT	HRNN\tagSENT_CONTENT	)\tagSENT_CONTENT	architectures\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	explicit\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	boundary\tagSENT_CONTENT	structure\tagSENT_CONTENT	is\tagSENT_CONTENT	provided\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	after\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	boundary\tagSENT_CONTENT	via\tagSENT_CONTENT	tokenization\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	HRNN\tagSENT_CONTENT	architecture\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	by\tagSENT_CONTENT	modelling\tagSENT_CONTENT	the\tagmetric	characters\tagmetric	and\tagSENT_CONTENT	words\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	and\tagSENT_CONTENT	second\tagSENT_CONTENT	RNN\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	regarded\tagSENT_CONTENT	as\tagSENT_CONTENT	1-D\tagSENT_CONTENT	spatial\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	1-D\tagSENT_CONTENT	kernels\tagSENT_CONTENT	are\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	however\tagSENT_CONTENT	different\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sense\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	objective\tagSENT_CONTENT	with\tagSENT_CONTENT	explicit\tagSENT_CONTENT	labels\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	segments\tagSENT_CONTENT	while\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	discovers\tagSENT_CONTENT	the\tagSENT_CONTENT	intrinsic\tagSENT_CONTENT	structure\tagSENT_CONTENT	only\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	sequences\tagSENT_CONTENT	without\tagSENT_CONTENT	segment\tagSENT_CONTENT	label\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	COPY\tagSENT_CONTENT	operation\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	Zoneout\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	generalization\tagSENT_CONTENT	of\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	depth\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	HIERARCHICAL\tagSECTITLE_START	MULTISCALE\tagSECTITLE_CONTENT	RECURRENT\tagSECTITLE_CONTENT	NEURAL\tagSECTITLE_CONTENT	NETWORKS\tagSECTITLE_END	MOTIVATION\tagSECTITLE_END	To\tagSENT_START	begin\tagSENT_CONTENT	with\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	an\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	how\tagSENT_CONTENT	a\tagSENT_CONTENT	stacked\tagSENT_CONTENT	RNN\tagSENT_CONTENT	can\tagSENT_CONTENT	model\tagSENT_CONTENT	temporal\tagSENT_CONTENT	data\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchy\tagSENT_CONTENT	of\tagSENT_CONTENT	segments\tagSENT_CONTENT	is\tagSENT_CONTENT	provided\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	means\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	provided\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	C2W\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	obtains\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	after\tagSENT_CONTENT	processing\tagSENT_CONTENT	the\tagmetric	last\tagmetric	character\tagmetric	of\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	passes\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	W2P\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	W2P\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	remains\tagSENT_CONTENT	unchanged\tagSENT_CONTENT	while\tagSENT_CONTENT	all\tagmetric	the\tagmetric	characters\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	are\tagSENT_CONTENT	processed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	C2W\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	.\tagSENT_END	Considering\tagSENT_START	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	boundary\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	consider\tagSENT_CONTENT	language_modeling\tagtask	where\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	always\tagSENT_CONTENT	cleanly\tagSENT_CONTENT	separated\tagSENT_CONTENT	by\tagSENT_CONTENT	spaces\tagSENT_CONTENT	or\tagSENT_CONTENT	punctuation\tagSENT_CONTENT	symbols\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	imperfect\tagSENT_CONTENT	rules\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	separately\tagSENT_CONTENT	perform\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	usually\tagSENT_CONTENT	not\tagSENT_CONTENT	provided\tagSENT_CONTENT	at\tagSENT_CONTENT	all\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	legitimate\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	THE\tagSECTITLE_START	PROPOSED\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_END	A\tagSENT_START	key\tagSENT_CONTENT	element\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	introduction\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	parametrized\tagSENT_CONTENT	boundary\tagSENT_CONTENT	detector\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	outputs\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	value\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	stacked\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	learns\tagSENT_CONTENT	when\tagSENT_CONTENT	a\tagSENT_CONTENT	segment\tagSENT_CONTENT	should\tagSENT_CONTENT	end\tagSENT_CONTENT	in\tagSENT_CONTENT	such\tagSENT_CONTENT	away\tagSENT_CONTENT	to\tagSENT_CONTENT	optimize\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	target\tagSENT_CONTENT	objective\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	this\tagSENT_CONTENT	binary\tagSENT_CONTENT	decision\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	usually\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	gradient\tagSENT_CONTENT	descent\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	such\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	discrete\tagSENT_CONTENT	decisions\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	.\tagSENT_END	COMPUTING\tagSECTITLE_START	GRADIENT\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	BOUNDARY\tagSECTITLE_CONTENT	DETECTOR\tagSECTITLE_END	Among\tagSENT_START	a\tagSENT_CONTENT	few\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	discrete\tagSENT_CONTENT	variables\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	REINFORCE\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	straight\tagSENT_CONTENT	-\tagSENT_CONTENT	through\tagSENT_CONTENT	estimator\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	straightthrough\tagSENT_CONTENT	estimator\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	starting\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	slope\tagSENT_CONTENT	value\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	difficult\tagSENT_CONTENT	while\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	applicable\tagSENT_CONTENT	later\tagSENT_CONTENT	when\tagSENT_CONTENT	language_modeling\tagtask	parameters\tagSENT_CONTENT	become\tagSENT_CONTENT	more\tagSENT_CONTENT	stable\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	handwriting\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	.27\tagSECTITLE_START	LayerNorm\tagSECTITLE_CONTENT	HM\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_END	LayerNorm\tagSECTITLE_START	HM\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	Step\tagSECTITLE_CONTENT	Fn\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	Slope\tagSECTITLE_CONTENT	Annealing\tagSECTITLE_CONTENT	1.24\tagSECTITLE_END	CHARACTER\tagSECTITLE_START	-\tagSECTITLE_CONTENT	LEVEL\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	MODELLING\tagSECTITLE_END	language_modeling\tagtask	aims\tagSENT_CONTENT	at\tagSENT_CONTENT	learning\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	sequences\tagSENT_CONTENT	by\tagSENT_CONTENT	minimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	negative\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	sequences\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	θ\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagmetric	model\tagmetric	parameter\tagmetric	,\tagSENT_CONTENT	N\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	T\tagSENT_CONTENT	n\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	three\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	text\tagSENT_CONTENT	corpora\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	Text8\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_END	Model\tagSENT_START	We\tagSENT_CONTENT	use\tagSENT_CONTENT	language_modeling\tagtask	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	module\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	output\tagSENT_CONTENT	module\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagmetric	next\tagmetric	target\tagmetric	character\tagmetric	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	softmax\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_END	,\tagSENT_START	where\tagSENT_CONTENT	each\tagSENT_CONTENT	output\tagSENT_CONTENT	class\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagmetric	character\tagmetric	.\tagSENT_END	Text8\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	language_modeling\tagtask	using\tagSENT_CONTENT	Adam\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	initial\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	0.002\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	(\tagSENT_CONTENT	left\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	BPCs\tagSENT_CONTENT	of\tagSENT_CONTENT	four\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	to\tagSENT_CONTENT	other\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	(\tagSENT_CONTENT	enwik8\tagSENT_CONTENT	)\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	,\tagSENT_CONTENT	2012\tagSENT_CONTENT	)\tagSENT_CONTENT	contains\tagSENT_CONTENT	205\tagSENT_CONTENT	symbols\tagSENT_CONTENT	including\tagSENT_CONTENT	XML\tagSENT_CONTENT	markups\tagSENT_CONTENT	and\tagSENT_CONTENT	special\tagmetric	characters\tagmetric	.\tagSENT_END	We\tagSENT_START	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	splits\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	Graves\tagSENT_CONTENT	(\tagSENT_CONTENT	2013\tagSENT_CONTENT	)\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagmetric	first\tagmetric	90\tagmetric	M\tagmetric	characters\tagmetric	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	characters\tagSENT_CONTENT	for\tagSENT_CONTENT	validation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	remainders\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	and\tagSENT_CONTENT	4\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	visualize\tagSENT_CONTENT	the\tagSENT_CONTENT	boundaries\tagSENT_CONTENT	detected\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	boundary\tagSENT_CONTENT	detectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	HM\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	while\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagmetric	character\tagmetric	sequence\tagmetric	of\tagSENT_CONTENT	total\tagSENT_CONTENT	length\tagSENT_CONTENT	270\tagSENT_CONTENT	taken\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	either\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	or\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	somewhat\tagSENT_CONTENT	surprising\tagSENT_CONTENT	because\tagSENT_CONTENT	language_modeling\tagtask	self\tagSENT_CONTENT	-\tagSENT_CONTENT	organizes\tagSENT_CONTENT	this\tagSENT_CONTENT	structure\tagSENT_CONTENT	without\tagSENT_CONTENT	any\tagSENT_CONTENT	explicit\tagSENT_CONTENT	boundary\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Another\tagSENT_START	remarkable\tagSENT_CONTENT	point\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	pose\tagSENT_CONTENT	any\tagSENT_CONTENT	constraint\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	boundaries\tagSENT_CONTENT	that\tagSENT_CONTENT	language_modeling\tagtask	can\tagSENT_CONTENT	fire\tagSENT_CONTENT	up\tagSENT_CONTENT	.\tagSENT_END	IAM\tagSECTITLE_START	-\tagSECTITLE_CONTENT	OnDB\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	HANDWRITING\tagSECTITLE_START	SEQUENCE\tagSECTITLE_CONTENT	GENERATION\tagSECTITLE_END	At\tagSENT_START	each\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	receives\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	pt\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	t+1\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	t+1\tagSENT_CONTENT	,\tagSENT_CONTENT	p\tagSENT_CONTENT	t+1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	as\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	except\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	modified\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	real\tagSENT_CONTENT	-\tagSENT_CONTENT	valued\tagSENT_CONTENT	outputs\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	On\tagSENT_START	language_modeling\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	HM\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	achieved\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	result\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Text8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	comparable\tagSENT_CONTENT	results\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	and\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	
N16-1024	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	explain\tagSENT_CONTENT	efficient\tagSENT_CONTENT	inference\tagSENT_CONTENT	procedures\tagSENT_CONTENT	that\tagSENT_CONTENT	allow\tagSENT_CONTENT	application\tagSENT_CONTENT	to\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	foundation\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	§\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	RNNGs\tagSENT_START	maintain\tagSENT_CONTENT	the\tagSENT_CONTENT	algorithmic\tagSENT_CONTENT	convenience\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	but\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	rootto\tagSENT_CONTENT	-\tagSENT_CONTENT	terminal\tagSENT_CONTENT	)\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	information\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	4\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Surprisingly\tagSENT_START	-\tagSENT_CONTENT	although\tagSENT_CONTENT	inline\tagSENT_CONTENT	with\tagSENT_CONTENT	previous\tagSENT_CONTENT	parsing\tagSENT_CONTENT	results\tagSENT_CONTENT	showing\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	generative\tagSENT_CONTENT	model\tagSENT_CONTENT	obtains\tagSENT_CONTENT	significantly\tagSENT_CONTENT	better\tagSENT_CONTENT	results\tagSENT_CONTENT	than\tagSENT_CONTENT	parsing\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	RNN\tagSECTITLE_START	Grammars\tagSECTITLE_END	Top\tagSECTITLE_START	-\tagSECTITLE_CONTENT	down\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Generation\tagSECTITLE_END	To\tagSENT_START	emphasize\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	familiar\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	shift\tagSENT_CONTENT	-\tagSENT_CONTENT	reduce\tagSENT_CONTENT	recognition\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	present\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	generation\tagSENT_CONTENT	)\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	3.1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	present\tagSENT_CONTENT	modifications\tagSENT_CONTENT	to\tagSENT_CONTENT	turn\tagSENT_CONTENT	it\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	generator\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	3.2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Parser\tagSECTITLE_START	Transitions\tagSECTITLE_END	The\tagSENT_START	buffer\tagSENT_CONTENT	contains\tagSENT_CONTENT	unprocessed\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	contains\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	open\tagSENT_CONTENT	"\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	completed\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Open\tagSENT_START	nonterminals\tagSENT_CONTENT	are\tagSENT_CONTENT	"\tagSENT_CONTENT	closed\tagSENT_CONTENT	"\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	constituency_parsing\tagtask	by\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	operations\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	REDUCE\tagSENT_CONTENT	repeatedly\tagSENT_CONTENT	pops\tagSENT_CONTENT	completed\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	or\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	until\tagSENT_CONTENT	an\tagSENT_CONTENT	open\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	is\tagSENT_CONTENT	encountered\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	this\tagSENT_CONTENT	open\tagSENT_CONTENT	NT\tagSENT_CONTENT	is\tagSENT_CONTENT	popped\tagSENT_CONTENT	and\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	that\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	popped\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	children\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	single\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	operation\tagSENT_CONTENT	can\tagSENT_CONTENT	thus\tagSENT_CONTENT	create\tagSENT_CONTENT	constituency_parsing\tagtask	with\tagSENT_CONTENT	an\tagSENT_CONTENT	unbounded\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	children\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	likewise\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	linearized\tagSENT_CONTENT	"\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	 \tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	down\tagSENT_CONTENT	,\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	decompositions\tagSENT_CONTENT	of\tagSENT_CONTENT	trees\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	constituency_parsing\tagtask	on\tagSENT_CONTENT	parser\tagSENT_CONTENT	transitions\tagSENT_CONTENT	.\tagSENT_END	Generator\tagSECTITLE_START	Transitions\tagSECTITLE_END	constituency_parsing\tagtask	on\tagSENT_CONTENT	generator\tagSENT_CONTENT	transitions\tagSENT_CONTENT	.\tagSENT_END	Transition\tagSECTITLE_START	Sequences\tagSECTITLE_CONTENT	from\tagSECTITLE_CONTENT	Trees\tagSECTITLE_END	Runtime\tagSECTITLE_START	Analysis\tagSECTITLE_END	Stack\tagSECTITLE_START	Terminals\tagSECTITLE_CONTENT	Action\tagSECTITLE_END	Comparison\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Other\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	Generative\tagSECTITLE_START	Model\tagSECTITLE_END	Syntactic\tagSECTITLE_START	Composition\tagSECTITLE_CONTENT	Function\tagSECTITLE_END	When\tagSENT_START	a\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	operation\tagSENT_CONTENT	is\tagSENT_CONTENT	executed\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	pops\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	completed\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	and/or\tagSENT_CONTENT	tokens\tagSENT_CONTENT	(\tagSENT_CONTENT	together\tagSENT_CONTENT	with\tagSENT_CONTENT	their\tagSENT_CONTENT	vector\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	and\tagSENT_CONTENT	makes\tagSENT_CONTENT	them\tagSENT_CONTENT	children\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	recent\tagSENT_CONTENT	open\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	completing\tagSENT_CONTENT	"\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	vector\tagSENT_CONTENT	read\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	reverse\tagSENT_CONTENT	directions\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	being\tagSENT_CONTENT	constructed\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	figure\tagSENT_CONTENT	,\tagSENT_CONTENT	NP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Generation\tagSECTITLE_END	Training\tagSECTITLE_END	Discriminative\tagSECTITLE_START	Parsing\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	constituency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	replacing\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	T\tagSENT_CONTENT	tat\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	buffer\tagSENT_CONTENT	B\tagSENT_CONTENT	t\tagSENT_CONTENT	.\tagSENT_END	Inference\tagSECTITLE_START	via\tagSECTITLE_CONTENT	Importance\tagSECTITLE_CONTENT	Sampling\tagSECTITLE_END	Experiments\tagSECTITLE_END	constituency_parsing\tagtask	results\tagSENT_CONTENT	.\tagSENT_END	constituency_parsing\tagtask	.\tagSENT_END	constituency_parsing\tagtask	were\tagSENT_CONTENT	obtained\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	methodology\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	English\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	pattern\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	relaxing\tagSENT_CONTENT	conventional\tagSENT_CONTENT	independence\tagSENT_CONTENT	assumptions\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	freeness\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	inferring\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	symbols\tagSENT_CONTENT	alongside\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	relationships\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	pattern\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	observed\tagSENT_CONTENT	before\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	by\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	hypothesized\tagSENT_CONTENT	that\tagSENT_CONTENT	larger\tagSENT_CONTENT	,\tagSENT_CONTENT	unstructured\tagSENT_CONTENT	conditioning\tagSENT_CONTENT	contexts\tagSENT_CONTENT	are\tagSENT_CONTENT	harder\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	from\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	provide\tagSENT_CONTENT	opportunities\tagSENT_CONTENT	to\tagSENT_CONTENT	overfit\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	There\tagSENT_START	is\tagSENT_CONTENT	an\tagSENT_CONTENT	extensive\tagSENT_CONTENT	literature\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	one\tagSENT_CONTENT	strand\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	emphasized\tagSENT_CONTENT	a\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	generation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tree\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	to\tagSENT_CONTENT	define\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	space\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	neural\tagSENT_CONTENT	-\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	Henderson\tagSENT_CONTENT	is\tagSENT_CONTENT	particularly\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	ours\tagSENT_CONTENT	in\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	unbounded\tagSENT_CONTENT	history\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	to\tagSENT_CONTENT	parameterize\tagSENT_CONTENT	constituency_parsing\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	corner\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Syntactically\tagSENT_START	structured\tagSENT_CONTENT	neural\tagSENT_CONTENT	architectures\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Outlook\tagSECTITLE_END	A\tagSENT_START	third\tagSENT_CONTENT	consideration\tagSENT_CONTENT	regarding\tagSENT_CONTENT	how\tagSENT_CONTENT	RNNGs\tagSENT_CONTENT	,\tagSENT_CONTENT	constituency_parsing\tagtask	takes\tagSENT_CONTENT	place\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	toright\tagSENT_CONTENT	,\tagSENT_CONTENT	incremental\tagSENT_CONTENT	order\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	an\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	a\tagSENT_CONTENT	processing\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	grammar\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	opens\tagSENT_CONTENT	up\tagSENT_CONTENT	several\tagSENT_CONTENT	possibilities\tagSENT_CONTENT	for\tagSENT_CONTENT	developing\tagSENT_CONTENT	constituency_parsing\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	an\tagSENT_CONTENT	explicit\tagSENT_CONTENT	grammars\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	processing\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	
1804.07461	title\tagSECTITLE_END	A\tagSENT_START	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	Task\tagSENT_CONTENT	Benchmark\tagSENT_CONTENT	and\tagSENT_CONTENT	Analysis\tagSENT_CONTENT	Platform\tagSENT_CONTENT	for\tagSENT_CONTENT	natural_language_inference\tagtask	abstract\tagSECTITLE_END	For\tagSENT_START	natural_language_inference\tagtask	to\tagSENT_CONTENT	be\tagSENT_CONTENT	maximally\tagSENT_CONTENT	useful\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	process\tagSENT_CONTENT	language\tagSENT_CONTENT	in\tagSENT_CONTENT	away\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	exclusively\tagSENT_CONTENT	tailored\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	genre\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	To\tagSENT_START	facilitate\tagSENT_CONTENT	research\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	direction\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	natural_language_inference\tagtask	benchmark\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	NLU\tagSENT_CONTENT	tasks\tagSENT_CONTENT	including\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	associated\tagSENT_CONTENT	online\tagSENT_CONTENT	platform\tagSENT_CONTENT	for\tagSENT_CONTENT	model\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	comparison\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	crosssentence\tagSENT_CONTENT	contextualization\tagSENT_CONTENT	and\tagSENT_CONTENT	alignment\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	that\tagSENT_CONTENT	yielded\tagSENT_CONTENT	by\tagSENT_CONTENT	methods\tagSENT_CONTENT	like\tagSENT_CONTENT	soft\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	instrumental\tagSENT_CONTENT	in\tagSENT_CONTENT	achieving\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	While\tagSENT_START	GLUE\tagSENT_CONTENT	rewards\tagSENT_CONTENT	methods\tagSENT_CONTENT	that\tagSENT_CONTENT	yield\tagSENT_CONTENT	good\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	circumscribed\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	using\tagSENT_CONTENT	methods\tagSENT_CONTENT	like\tagSENT_CONTENT	those\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	currently\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	those\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	rewards\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	make\tagSENT_CONTENT	progress\tagSENT_CONTENT	toward\tagSENT_CONTENT	their\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	unifying\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	NLU\tagSENT_CONTENT	under\tagSENT_CONTENT	the\tagmetric	rubric\tagmetric	of\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	Tasks\tagSECTITLE_END	Unless\tagSENT_START	otherwise\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	,\tagSENT_CONTENT	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	are\tagSENT_CONTENT	balanced\tagSENT_CONTENT	across\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	Single\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	Judgments\tagSENT_START	of\tagSENT_CONTENT	this\tagSENT_CONTENT	particular\tagSENT_CONTENT	kind\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	primary\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	evidence\tagSENT_CONTENT	in\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	theory\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	a\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	system\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	them\tagSENT_CONTENT	reliably\tagSENT_CONTENT	would\tagSENT_CONTENT	offer\tagSENT_CONTENT	potentially\tagSENT_CONTENT	substantial\tagSENT_CONTENT	evidence\tagSENT_CONTENT	on\tagSENT_CONTENT	questions\tagSENT_CONTENT	of\tagSENT_CONTENT	natural_language_inference\tagtask	and\tagSENT_CONTENT	innate\tagSENT_CONTENT	bias\tagSENT_CONTENT	.\tagSENT_END	Similarity\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Paraphrase\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	Because\tagSENT_START	the\tagSENT_CONTENT	classes\tagSENT_CONTENT	are\tagSENT_CONTENT	imbalanced\tagSENT_CONTENT	(\tagSENT_CONTENT	68\tagSENT_CONTENT	%\tagSENT_CONTENT	positive\tagSENT_CONTENT	,\tagSENT_CONTENT	32\tagSENT_CONTENT	%\tagSENT_CONTENT	negative\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	common\tagSENT_CONTENT	practice\tagSENT_CONTENT	and\tagSENT_CONTENT	report\tagSENT_CONTENT	both\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	in\tagSENT_CONTENT	MRPC\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	distribution\tagSENT_CONTENT	in\tagSENT_CONTENT	QQP\tagSENT_CONTENT	is\tagSENT_CONTENT	unbalanced\tagSENT_CONTENT	(\tagSENT_CONTENT	37\tagSENT_CONTENT	%\tagSENT_CONTENT	positive\tagSENT_CONTENT	,\tagSENT_CONTENT	63\tagSENT_CONTENT	%\tagSENT_CONTENT	negative\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	both\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	Semantic\tagSENT_CONTENT	Textual\tagSENT_CONTENT	Similarity\tagSENT_CONTENT	Benchmark\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	drawn\tagSENT_CONTENT	from\tagSENT_CONTENT	news\tagSENT_CONTENT	headlines\tagSENT_CONTENT	,\tagSENT_CONTENT	video\tagSENT_CONTENT	and\tagSENT_CONTENT	image\tagSENT_CONTENT	captions\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	natural_language_inference\tagtask	inference\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Inference\tagSECTITLE_START	Tasks\tagSECTITLE_END	MNLI\tagSENT_START	natural_language_inference\tagtask	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	set\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	new\tagSENT_CONTENT	examples\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	fiction\tagSENT_CONTENT	books\tagSENT_CONTENT	4\tagSENT_CONTENT	that\tagSENT_CONTENT	was\tagSENT_CONTENT	shared\tagSENT_CONTENT	privately\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagmetric	authors\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	For\tagSENT_START	tasks\tagSENT_CONTENT	with\tagSENT_CONTENT	multiple\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagmetric	e.g.\tagmetric	,\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	unweighted\tagSENT_CONTENT	average\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	metrics\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	when\tagSENT_CONTENT	computing\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	average\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Bias\tagSECTITLE_END	Tags\tagSECTITLE_END	Sentence\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	Fwd\tagSECTITLE_CONTENT	Bwd\tagSECTITLE_END	N\tagSECTITLE_START	E\tagSECTITLE_END	E\tagSECTITLE_START	N\tagSECTITLE_END	Diagnostic\tagSECTITLE_START	Dataset\tagSECTITLE_END	We\tagSENT_START	ensure\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	reasonably\tagSENT_CONTENT	diverse\tagSENT_CONTENT	by\tagSENT_CONTENT	producing\tagSENT_CONTENT	examples\tagSENT_CONTENT	fora\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	phenomena\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	basing\tagSENT_CONTENT	our\tagSENT_CONTENT	examples\tagSENT_CONTENT	on\tagSENT_CONTENT	natural_language_inference\tagtask	from\tagSENT_CONTENT	several\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	Domains\tagSENT_START	We\tagSENT_CONTENT	construct\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	text\tagSENT_CONTENT	from\tagSENT_CONTENT	four\tagSENT_CONTENT	domains\tagSENT_CONTENT	:\tagSENT_CONTENT	News\tagSENT_CONTENT	(\tagSENT_CONTENT	articles\tagSENT_CONTENT	linked\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	front\tagSENT_CONTENT	page\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Reddit\tagSENT_CONTENT	(\tagSENT_CONTENT	threads\tagSENT_CONTENT	linked\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Front\tagSENT_CONTENT	Page\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	(\tagSENT_CONTENT	Featured\tagSENT_CONTENT	Articles\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	academic\tagSENT_CONTENT	papers\tagSENT_CONTENT	from\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	Testing\tagSENT_START	the\tagSENT_CONTENT	trained\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	diagnostic\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	accuracies\tagmetric	close\tagSENT_CONTENT	to\tagSENT_CONTENT	chance\tagSENT_CONTENT	,\tagSENT_CONTENT	32.7\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	36.4\tagSENT_CONTENT	%\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	artifacts\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	kind\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	NLI\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	Baselines\tagSECTITLE_END	ELMo\tagSENT_START	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	natural_language_inference\tagtask	(\tagSENT_CONTENT	one\tagSENT_CONTENT	forward\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	backward\tagSENT_CONTENT	)\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Billion\tagSENT_CONTENT	Word\tagSENT_CONTENT	Benchmark\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	train\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	Adam\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	natural_language_inference\tagtask	10\tagSENT_CONTENT	−3\tagSENT_CONTENT	and\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	128\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	this\tagSENT_CONTENT	is\tagSENT_CONTENT	generally\tagSENT_CONTENT	an\tagSENT_CONTENT	effective\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	tasks\tagSENT_CONTENT	understudy\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	allow\tagSENT_CONTENT	for\tagSENT_CONTENT	fair\tagSENT_CONTENT	comparisons\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	analogs\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	tune\tagSENT_CONTENT	parameter\tagSENT_CONTENT	or\tagSENT_CONTENT	training\tagSENT_CONTENT	settings\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	 \tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	these\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	models\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	generally\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	art\tagmetric	for\tagSENT_CONTENT	each\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Benchmark\tagSECTITLE_START	Results\tagSECTITLE_END	Analysis\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	perhaps\tagSENT_CONTENT	unsurprising\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	simple\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	training\tagSENT_CONTENT	regime\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	likely\tagSENT_CONTENT	natural_language_inference\tagtask	between\tagSENT_CONTENT	MNLI\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	ameliorated\tagSENT_CONTENT	by\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	some\tagSENT_CONTENT	degree\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	,\tagSENT_CONTENT	perhaps\tagSENT_CONTENT	because\tagSENT_CONTENT	natural_language_inference\tagtask	teach\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	phrases\tagSENT_CONTENT	like\tagSENT_CONTENT	"\tagSENT_CONTENT	not\tagSENT_CONTENT	bad\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	okay\tagSENT_CONTENT	"\tagSENT_CONTENT	have\tagSENT_CONTENT	similar\tagSENT_CONTENT	distributions\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	increased\tagSENT_CONTENT	representational\tagSENT_CONTENT	capacity\tagSENT_CONTENT	may\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagmetric	failure\tagmetric	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	downward\tagSENT_CONTENT	monotone\tagSENT_CONTENT	contexts\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	GLUE\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	platform\tagSENT_CONTENT	and\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	resources\tagSENT_CONTENT	for\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	and\tagSENT_CONTENT	analyzing\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	A.2\tagSECTITLE_START	Diagnostic\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	
1806.02847	title\tagSECTITLE_END	A\tagSENT_START	Simple\tagSENT_CONTENT	Method\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	abstract\tagSECTITLE_END	common_sense\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	standing\tagSENT_CONTENT	challenge\tagSENT_CONTENT	for\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Key\tagSENT_START	to\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	massive\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	unlabled\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	score\tagSENT_CONTENT	multiple\tagSENT_CONTENT	choice\tagSENT_CONTENT	questions\tagSENT_CONTENT	posed\tagSENT_CONTENT	by\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	We\tagSENT_START	train\tagSENT_CONTENT	an\tagSENT_CONTENT	array\tagSENT_CONTENT	of\tagSENT_CONTENT	large\tagSENT_CONTENT	RNN\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	operate\tagSENT_CONTENT	at\tagSENT_CONTENT	word\tagSENT_CONTENT	or\tagSENT_CONTENT	character\tagSENT_CONTENT	level\tagSENT_CONTENT	on\tagSENT_CONTENT	LM-1-Billion\tagSENT_CONTENT	,\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	Gutenberg\tagSENT_CONTENT	Books\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	customized\tagSENT_CONTENT	corpus\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	diversity\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	plays\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	test\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Further\tagSENT_START	analysis\tagSENT_CONTENT	also\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	successfully\tagSENT_CONTENT	discovers\tagSENT_CONTENT	important\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	that\tagSENT_CONTENT	decide\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	grasp\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	An\tagSENT_START	example\tagSENT_CONTENT	of\tagSENT_CONTENT	such\tagSENT_CONTENT	problems\tagSENT_CONTENT	is\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	Winograd\tagSENT_CONTENT	Schema\tagSENT_CONTENT	Challenge\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	labeled\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	typically\tagSENT_CONTENT	very\tagSENT_CONTENT	small\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	hundreds\tagSENT_CONTENT	of\tagSENT_CONTENT	examples\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	it\tagSENT_CONTENT	is\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	for\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	choose\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	"\tagSENT_CONTENT	the\tagSENT_CONTENT	trophy\tagSENT_CONTENT	"\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	answering\tagSENT_CONTENT	this\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	great\tagSENT_CONTENT	challenge\tagSENT_CONTENT	for\tagSENT_CONTENT	machines\tagSENT_CONTENT	because\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	very\tagSENT_CONTENT	little\tagSENT_CONTENT	of\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	surprisingly\tagSENT_CONTENT	simple\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	with\tagSENT_CONTENT	Winograd\tagSENT_CONTENT	schema\tagSENT_CONTENT	multiple\tagSENT_CONTENT	choice\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	a\tagSENT_CONTENT	Pronoun\tagSENT_CONTENT	Disambiguation\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	PDP-60\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	achieves\tagSENT_CONTENT	70.0\tagmetric	%\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	66.7\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	a\tagSENT_CONTENT	Winograd\tagSENT_CONTENT	Schema\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	WSC-273\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	achieves\tagSENT_CONTENT	63.7\tagmetric	%\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	11\tagSENT_CONTENT	%\tagSENT_CONTENT	above\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	result\tagSENT_CONTENT	(\tagSENT_CONTENT	52.8\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_END	Although\tagSENT_START	detecting\tagSENT_CONTENT	this\tagSENT_CONTENT	feature\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	challenge\tagSENT_CONTENT	,\tagSENT_CONTENT	further\tagSENT_CONTENT	analysis\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	successfully\tagSENT_CONTENT	discovers\tagSENT_CONTENT	this\tagSENT_CONTENT	special\tagSENT_CONTENT	word\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	its\tagSENT_CONTENT	decisions\tagSENT_CONTENT	in\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	grasp\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Our\tagSENT_START	work\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	intuition\tagSENT_CONTENT	that\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	can\tagSENT_CONTENT	naturally\tagSENT_CONTENT	capture\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Using\tagSENT_START	language\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	reading\tagSENT_CONTENT	common_sense\tagtask	also\tagSENT_CONTENT	produced\tagSENT_CONTENT	many\tagSENT_CONTENT	great\tagSENT_CONTENT	successes\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	LMs\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	features\tagSENT_CONTENT	fora\tagSENT_CONTENT	classifier\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Store\tagSENT_CONTENT	Close\tagSENT_CONTENT	Test\tagSENT_CONTENT	2017\tagSENT_CONTENT	,\tagSENT_CONTENT	giving\tagSENT_CONTENT	best\tagmetric	accuracy\tagmetric	against\tagSENT_CONTENT	other\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Methods\tagSECTITLE_END	Experimental\tagSECTITLE_START	settings\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	tests\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	LMs\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSENT_START	on\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	We\tagSENT_START	conduct\tagSENT_CONTENT	experiments\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	methods\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	Pronoun\tagSENT_CONTENT	Disambiguation\tagSENT_CONTENT	Problems\tagSENT_CONTENT	and\tagSENT_CONTENT	Winograd\tagdataset	Schema\tagdataset	Challenge\tagdataset	.\tagSENT_END	These\tagSENT_START	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	as\tagSENT_CONTENT	potential\tagSENT_CONTENT	alternatives\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Turing\tagSENT_CONTENT	Test\tagSENT_CONTENT	,\tagSENT_CONTENT	specifically\tagSENT_CONTENT	targeting\tagSENT_CONTENT	its\tagSENT_CONTENT	potential\tagSENT_CONTENT	weaknesses\tagSENT_CONTENT	and\tagSENT_CONTENT	inadequacy\tagmetric	.\tagSENT_END	Its\tagSENT_START	recent\tagSENT_CONTENT	best\tagSENT_CONTENT	reported\tagSENT_CONTENT	result\tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	3\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	above\tagSENT_CONTENT	random\tagSENT_CONTENT	guess\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	task\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	273\tagSENT_CONTENT	questions\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	work\tagSENT_CONTENT	against\tagSENT_CONTENT	techniques\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	traditional\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	restrictions\tagSENT_CONTENT	,\tagSENT_CONTENT	common_sense\tagtask	or\tagSENT_CONTENT	simple\tagSENT_CONTENT	statistical\tagSENT_CONTENT	test\tagSENT_CONTENT	over\tagSENT_CONTENT	text\tagSENT_CONTENT	corpora\tagSENT_CONTENT	(\tagSENT_CONTENT	"\tagSENT_CONTENT	Google\tagSENT_CONTENT	-\tagSENT_CONTENT	proof\tagSENT_CONTENT	")\tagSENT_CONTENT	.\tagSENT_END	Main\tagSECTITLE_START	results\tagSECTITLE_END	The\tagSECTITLE_START	first\tagSECTITLE_CONTENT	challenge\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	2016\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	PDP-60\tagSECTITLE_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	70.0\tagmetric	%\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	recent\tagSENT_CONTENT	reported\tagSENT_CONTENT	results\tagSENT_CONTENT	from\tagSENT_CONTENT	Quan\tagSENT_CONTENT	Liu\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	(\tagSENT_CONTENT	66.7\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	bases\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Winograd\tagSECTITLE_START	Schema\tagSECTITLE_CONTENT	Challenge\tagSECTITLE_END	Namely\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	resolver\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	56.4\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	training\tagSENT_CONTENT	another\tagSENT_CONTENT	4\tagSENT_CONTENT	LMs\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	on\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	4\tagSENT_CONTENT	text\tagSENT_CONTENT	corpora\tagSENT_CONTENT	LM-1-Billion\tagSENT_CONTENT	,\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	Gutenberg\tagSENT_CONTENT	Books\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	add\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	reach\tagSENT_CONTENT	61.5\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	nearly\tagSENT_CONTENT	10\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	above\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	result\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	drastic\tagSENT_CONTENT	improvement\tagSENT_CONTENT	considering\tagSENT_CONTENT	this\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	system\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	random\tagSENT_CONTENT	guess\tagSENT_CONTENT	by\tagSENT_CONTENT	only\tagmetric	3\tagmetric	%\tagmetric	inaccuracy\tagmetric	.\tagSENT_END	Customized\tagSECTITLE_START	training\tagSECTITLE_CONTENT	data\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Winograd\tagSECTITLE_CONTENT	Schema\tagSECTITLE_CONTENT	Challenge\tagSECTITLE_END	Namely\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	build\tagSENT_CONTENT	a\tagSENT_CONTENT	customized\tagSENT_CONTENT	text\tagSENT_CONTENT	corpus\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	questions\tagSENT_CONTENT	in\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	aggregate\tagSENT_CONTENT	documents\tagSENT_CONTENT	from\tagSENT_CONTENT	common_sense\tagtask	that\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	overlapping\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	name\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	STORIES\tagSENT_CONTENT	since\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	constituent\tagSENT_CONTENT	documents\tagSENT_CONTENT	take\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	story\tagSENT_CONTENT	with\tagSENT_CONTENT	long\tagSENT_CONTENT	chain\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	We\tagSENT_START	train\tagSENT_CONTENT	four\tagSENT_CONTENT	different\tagSENT_CONTENT	LMs\tagSENT_CONTENT	on\tagSENT_CONTENT	STORIES\tagSENT_CONTENT	and\tagSENT_CONTENT	add\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	10\tagSENT_CONTENT	LMs\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	again\tagSENT_CONTENT	of\tagSENT_CONTENT	2\tagmetric	%\tagmetric	accuracy\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	system\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Remarkably\tagSENT_START	,\tagSENT_CONTENT	single\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	corpus\tagSENT_CONTENT	are\tagSENT_CONTENT	already\tagSENT_CONTENT	extremely\tagSENT_CONTENT	strong\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	LM\tagSENT_CONTENT	achieving\tagSENT_CONTENT	62.6\tagmetric	%\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	even\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	10\tagSENT_CONTENT	models\tagSENT_CONTENT	previously\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	4\tagSENT_CONTENT	other\tagSENT_CONTENT	text\tagSENT_CONTENT	corpora\tagSENT_CONTENT	(\tagSENT_CONTENT	61.5\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	ensemble\tagSENT_CONTENT	also\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	system\tagSENT_CONTENT	on\tagSENT_CONTENT	WSC-273\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagmetric	remarkable\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	58.2\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	strongly\tagSENT_CONTENT	indicates\tagSENT_CONTENT	a\tagSENT_CONTENT	correct\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	grasp\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	resolver\tagSENT_CONTENT	's\tagSENT_CONTENT	decision\tagSENT_CONTENT	process\tagSENT_CONTENT	.\tagSENT_END	Importance\tagSECTITLE_START	of\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	corpus\tagSECTITLE_END	Namely\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	both\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	and\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	LMs\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	five\tagSENT_CONTENT	corpora\tagSENT_CONTENT	:\tagSENT_CONTENT	LM-1-Billion\tagSENT_CONTENT	,\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	Gutenberg\tagSENT_CONTENT	Books\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	STORIES\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	is\tagSENT_CONTENT	optionally\tagSENT_CONTENT	transferred\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	architectures\tagSENT_CONTENT	on\tagSENT_CONTENT	common_sense\tagtask	,\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	and\tagSENT_CONTENT	Gutenberg\tagSENT_CONTENT	Books\tagSENT_CONTENT	.\tagSENT_END	Figure\tagSENT_START	5-left\tagSENT_CONTENT	and\tagSENT_CONTENT	middle\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	STORIES\tagSENT_CONTENT	always\tagSENT_CONTENT	yield\tagSENT_CONTENT	the\tagmetric	highest\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	both\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	highlights\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	of\tagSENT_CONTENT	diversity\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	The\tagSENT_START	resulting\tagSENT_CONTENT	systems\tagSENT_CONTENT	outperform\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	systems\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	Pronoun\tagSENT_CONTENT	Disambiguation\tagSENT_CONTENT	Problems\tagSENT_CONTENT	and\tagSENT_CONTENT	Winograd\tagdataset	Schema\tagdataset	Challenge\tagdataset	.\tagSENT_END	Remarkably\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	later\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	63.7\tagmetric	%\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	comparing\tagSENT_CONTENT	to\tagSENT_CONTENT	52.8\tagmetric	%\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	expensively\tagSENT_CONTENT	annotated\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	bases\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	analyze\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	's\tagSENT_CONTENT	answers\tagSENT_CONTENT	and\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	discovers\tagSENT_CONTENT	key\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	that\tagSENT_CONTENT	decides\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	good\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	We\tagSENT_START	anticipate\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	simple\tagSENT_CONTENT	technique\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	building\tagSENT_CONTENT	block\tagSENT_CONTENT	for\tagSENT_CONTENT	future\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	utilize\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	ability\tagSENT_CONTENT	on\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	A\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	language\tagSECTITLE_CONTENT	models\tagSECTITLE_END	This\tagSENT_START	tensor\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	processed\tagSENT_CONTENT	by\tagSENT_CONTENT	eight\tagSENT_CONTENT	different\tagSENT_CONTENT	1-D\tagSENT_CONTENT	convolution\tagSENT_CONTENT	common_sense\tagtask	of\tagSENT_CONTENT	different\tagSENT_CONTENT	sizes\tagSENT_CONTENT	and\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	output\tagSENT_CONTENT	channels\tagSENT_CONTENT	,\tagSENT_CONTENT	listed\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	acitvation\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	Data\tagSECTITLE_CONTENT	contamination\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	CommonCrawl\tagSECTITLE_END	Training\tagSENT_START	LMs\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	on\tagSENT_CONTENT	full\tagSENT_CONTENT	CommonCrawl\tagSENT_CONTENT	,\tagSENT_CONTENT	therefore\tagSENT_CONTENT	,\tagSENT_CONTENT	might\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	ideal\tagSENT_CONTENT	.\tagSENT_END	
D18-1274	title\tagSECTITLE_END	Neural\tagSENT_START	Quality\tagSENT_CONTENT	Estimation\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	abstract\tagSECTITLE_END	grammatical_error_correction\tagtask	deployed\tagSENT_CONTENT	in\tagSENT_CONTENT	language\tagSENT_CONTENT	learning\tagSENT_CONTENT	environments\tagSENT_CONTENT	are\tagSENT_CONTENT	expected\tagSENT_CONTENT	to\tagSENT_CONTENT	accurately\tagSENT_CONTENT	correct\tagSENT_CONTENT	errors\tagSENT_CONTENT	in\tagSENT_CONTENT	learners\tagSENT_CONTENT	'\tagSENT_CONTENT	writing\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	practice\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	often\tagSENT_CONTENT	produce\tagSENT_CONTENT	grammatical_error_correction\tagtask	and\tagSENT_CONTENT	fail\tagSENT_CONTENT	to\tagSENT_CONTENT	correct\tagSENT_CONTENT	many\tagSENT_CONTENT	errors\tagSENT_CONTENT	,\tagSENT_CONTENT	thereby\tagSENT_CONTENT	misleading\tagSENT_CONTENT	learners\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	correcting\tagSENT_CONTENT	various\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	errors\tagSENT_CONTENT	in\tagSENT_CONTENT	written\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	termed\tagSENT_CONTENT	as\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	primarily\tagSENT_CONTENT	aimed\tagSENT_CONTENT	at\tagSENT_CONTENT	assisting\tagSENT_CONTENT	language\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	providing\tagSENT_CONTENT	corrective\tagSENT_CONTENT	feedback\tagSENT_CONTENT	to\tagSENT_CONTENT	second\tagSENT_CONTENT	-\tagSENT_CONTENT	language\tagSENT_CONTENT	learners\tagSENT_CONTENT	.\tagSENT_END	GEC\tagSENT_START	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	expected\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	grammatical_error_correction\tagtask	and\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	correct\tagSENT_CONTENT	most\tagSENT_CONTENT	learner\tagSENT_CONTENT	mistakes\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	prevent\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	instructor\tagSENT_CONTENT	can\tagSENT_CONTENT	intervene\tagSENT_CONTENT	and\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	correct\tagSENT_CONTENT	grammatical_error_correction\tagtask	when\tagSENT_CONTENT	necessary\tagSENT_CONTENT	,\tagSENT_CONTENT	before\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	provided\tagSENT_CONTENT	as\tagSENT_CONTENT	feedback\tagSENT_CONTENT	to\tagSENT_CONTENT	learners\tagSENT_CONTENT	.\tagSENT_END	Having\tagSENT_START	quality\tagSENT_CONTENT	estimates\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	's\tagSENT_CONTENT	output\tagSENT_CONTENT	sentences\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	instructors\tagSENT_CONTENT	to\tagSENT_CONTENT	decide\tagSENT_CONTENT	whether\tagSENT_CONTENT	to\tagSENT_CONTENT	check\tagSENT_CONTENT	and\tagSENT_CONTENT	fix\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	)\tagSENT_CONTENT	or\tagSENT_CONTENT	to\tagSENT_CONTENT	ignore\tagSENT_CONTENT	grammatical_error_correction\tagtask	altogether\tagSENT_CONTENT	and\tagSENT_CONTENT	recorrect\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	learner\tagSENT_CONTENT	-\tagSENT_CONTENT	written\tagSENT_CONTENT	sentences\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	lower\tagSENT_CONTENT	quality\tagSENT_CONTENT	ones\tagSENT_CONTENT	)\tagSENT_CONTENT	instead\tagSENT_CONTENT	.\tagSENT_END	-the\tagSENT_START	language\tagSENT_CONTENT	learners\tagSENT_CONTENT	-to\tagSENT_CONTENT	decide\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	extent\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	grammatical_error_correction\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	trusted\tagSENT_CONTENT	and\tagSENT_CONTENT	seek\tagSENT_CONTENT	assistance\tagSENT_CONTENT	from\tagSENT_CONTENT	instructors\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	sources\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_CONTENT	better\tagSENT_CONTENT	corrective\tagSENT_CONTENT	feedback\tagSENT_CONTENT	if\tagSENT_CONTENT	needed\tagSENT_CONTENT	.\tagSENT_END	Quality\tagSENT_START	of\tagSENT_CONTENT	language\tagSENT_CONTENT	output\tagSENT_CONTENT	applications\tagSENT_CONTENT	can\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	several\tagSENT_CONTENT	aspects\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	fluency\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	adequacy\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	editing\tagSENT_CONTENT	effort\tagSENT_CONTENT	.\tagSENT_END	a\tagSENT_START	few\tagSENT_CONTENT	reference\tagSENT_CONTENT	-\tagSENT_CONTENT	less\tagSENT_CONTENT	GEC\tagSENT_CONTENT	metrics\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	fluency\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	adequacy\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	GEC\tagSENT_CONTENT	,\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	grammatical_error_correction\tagtask	of\tagSENT_CONTENT	learner\tagSENT_CONTENT	sentences\tagSENT_CONTENT	using\tagSENT_CONTENT	regression\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	features\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	misspellings\tagSENT_CONTENT	,\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	learner\tagSENT_CONTENT	sentences\tagSENT_CONTENT	manually\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	subjective\tagSENT_CONTENT	scores\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	To\tagSENT_START	evaluate\tagSENT_CONTENT	GEC\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	developed\tagSENT_CONTENT	reference\tagSENT_CONTENT	-\tagSENT_CONTENT	less\tagSENT_CONTENT	metrics\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	grammatical_error_correction\tagtask	or\tagSENT_CONTENT	GBMs\tagSENT_CONTENT	.\tagSENT_END	GBM\tagSENT_START	scores\tagSENT_CONTENT	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	errors\tagSENT_CONTENT	detected\tagSENT_CONTENT	using\tagSENT_CONTENT	third\tagSENT_CONTENT	-\tagSENT_CONTENT	party\tagSENT_CONTENT	tools\tagSENT_CONTENT	or\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	grammatical_error_correction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Their\tagSENT_START	method\tagSENT_CONTENT	ignores\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	completely\tagSENT_CONTENT	and\tagSENT_CONTENT	judges\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	1\tagSENT_CONTENT	https://github.com/nusnlp/neuqe\tagSENT_CONTENT	outputs\tagSENT_CONTENT	independently\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	Contrary\tagSENT_START	to\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	GEC\tagSENT_CONTENT	reference\tagSENT_CONTENT	-\tagSENT_CONTENT	less\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	aimed\tagSENT_CONTENT	at\tagSENT_CONTENT	estimating\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	editing\tagSENT_CONTENT	effort\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	automatic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	approach\tagSENT_CONTENT	.\tagSENT_END	Quality\tagSECTITLE_START	Estimation\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	GEC\tagSECTITLE_END	HTER\tagSECTITLE_START	=\tagSECTITLE_END	Neural\tagSECTITLE_START	Quality\tagSECTITLE_CONTENT	Estimation\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Predictor\tagSECTITLE_START	Network\tagSECTITLE_END	Estimator\tagSECTITLE_START	Network\tagSECTITLE_END	The\tagSENT_START	input\tagSENT_CONTENT	vectors\tagSENT_CONTENT	are\tagSENT_CONTENT	added\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	vectors\tagSENT_CONTENT	as\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	CNNbased\tagSENT_CONTENT	predictor\tagSENT_CONTENT	and\tagSENT_CONTENT	estimator\tagSENT_CONTENT	,\tagSENT_CONTENT	learning\tagSENT_CONTENT	is\tagSENT_CONTENT	stabilized\tagSENT_CONTENT	using\tagSENT_CONTENT	strategies\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	initialization\tagSENT_CONTENT	and\tagSENT_CONTENT	weight\tagSENT_CONTENT	normalization\tagSENT_CONTENT	of\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	and\tagSENT_CONTENT	controlling\tagSENT_CONTENT	the\tagSENT_CONTENT	variance\tagSENT_CONTENT	of\tagSENT_CONTENT	activations\tagSENT_CONTENT	after\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	GEC\tagSECTITLE_START	System\tagSECTITLE_END	Datasets\tagSECTITLE_END	NQE\tagSECTITLE_START	Models\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	Baselines\tagSECTITLE_END	Evaluation\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Estimating\tagSECTITLE_START	Post\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Editing\tagSECTITLE_CONTENT	Effort\tagSECTITLE_END	Estimating\tagSECTITLE_START	M\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	Score\tagSECTITLE_END	Improving\tagSECTITLE_START	GEC\tagSECTITLE_CONTENT	Performance\tagSECTITLE_END	When\tagSENT_START	we\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	+\tagSENT_CONTENT	SpellCheck\tagSENT_CONTENT	)\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	G&J\tagSENT_CONTENT	and\tagSENT_CONTENT	C&N\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	reported\tagSENT_CONTENT	F\tagSENT_CONTENT	0.5\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL-2014\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	(\tagSENT_CONTENT	56.43\tagSENT_CONTENT	)\tagSENT_CONTENT	when\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	public\tagSENT_CONTENT	corpora\tagSENT_CONTENT	alone\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	we\tagSENT_CONTENT	add\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	reach\tagSENT_CONTENT	48.70\tagSENT_CONTENT	F\tagSENT_CONTENT	0.5\tagSENT_CONTENT	score\tagSENT_CONTENT	on\tagSENT_CONTENT	FCE\tagSENT_CONTENT	and\tagSENT_CONTENT	56.52\tagSENT_CONTENT	F\tagSENT_CONTENT	0.5\tagSENT_CONTENT	score\tagSENT_CONTENT	on\tagSENT_CONTENT	CoNLL-2014\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	grammatical_error_correction\tagtask	'\tagSENT_CONTENT	to\tagSENT_CONTENT	'\tagSENT_CONTENT	gets\tagSENT_CONTENT	a\tagSENT_CONTENT	higher\tagSENT_CONTENT	probability\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	impractical\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	references\tagSENT_CONTENT	that\tagSENT_CONTENT	coverall\tagSENT_CONTENT	grammatical_error_correction\tagtask	for\tagSENT_CONTENT	all\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
E17-1010	title\tagSECTITLE_END	word_sense_disambiguation\tagtask	:\tagSENT_END	abstract\tagSECTITLE_END	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	standing\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	,\tagSENT_CONTENT	lying\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	core\tagSENT_CONTENT	of\tagSENT_CONTENT	human\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	a\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	standing\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	offers\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	State\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Art\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	associating\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	context\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	suitable\tagSENT_CONTENT	entry\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	defined\tagSENT_CONTENT	sense\tagSENT_CONTENT	inventory\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	WSD\tagSECTITLE_END	Knowledge\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	WSD\tagSECTITLE_END	Instead\tagSENT_START	,\tagSENT_CONTENT	these\tagSENT_CONTENT	approaches\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	or\tagSENT_CONTENT	content\tagSENT_CONTENT	of\tagSENT_CONTENT	manually\tagSENT_CONTENT	-\tagSENT_CONTENT	curated\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	resources\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	Standardization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	WSD\tagSECTITLE_CONTENT	datasets\tagSECTITLE_END	Once\tagSENT_START	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	converted\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	unified\tagSENT_CONTENT	format\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	map\tagSENT_CONTENT	word_sense_disambiguation\tagtask	from\tagSENT_CONTENT	its\tagSENT_CONTENT	original\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	version\tagSENT_CONTENT	to\tagSENT_CONTENT	3.0\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	latest\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	final\tagSENT_CONTENT	verification\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	ensured\tagSENT_CONTENT	that\tagSENT_CONTENT	word_sense_disambiguation\tagtask	match\tagSENT_CONTENT	the\tagSENT_CONTENT	lemma\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	PoS\tagSENT_CONTENT	tag\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	CoreNLP\tagSENT_CONTENT	by\tagSENT_CONTENT	automatically\tagSENT_CONTENT	fixing\tagSENT_CONTENT	all\tagSENT_CONTENT	divergences\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_END	WSD\tagSECTITLE_START	evaluation\tagSECTITLE_CONTENT	datasets\tagSECTITLE_END	For\tagSENT_START	our\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	framework\tagSENT_CONTENT	we\tagSENT_CONTENT	considered\tagSENT_CONTENT	five\tagSENT_CONTENT	standard\tagSENT_CONTENT	all\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	WSD\tagSENT_CONTENT	datasets\tagSENT_CONTENT	from\tagSENT_CONTENT	word_sense_disambiguation\tagtask	:\tagSENT_END	After\tagSENT_START	standardization\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	nouns\tagSENT_CONTENT	,\tagSENT_CONTENT	verbs\tagSENT_CONTENT	,\tagSENT_CONTENT	adverbs\tagSENT_CONTENT	and\tagSENT_CONTENT	adjectives\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	smallest\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	five\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	containing\tagSENT_CONTENT	word_sense_disambiguation\tagtask	for\tagSENT_CONTENT	nouns\tagSENT_CONTENT	and\tagSENT_CONTENT	verbs\tagSENT_CONTENT	only\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	number\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	1644\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	only\tagSENT_CONTENT	nouns\tagSENT_CONTENT	are\tagSENT_CONTENT	considered\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	in\tagSENT_CONTENT	four\tagSENT_CONTENT	documents\tagSENT_CONTENT	coming\tagSENT_CONTENT	from\tagSENT_CONTENT	three\tagSENT_CONTENT	heterogeneous\tagSENT_CONTENT	domains\tagSENT_CONTENT	:\tagSENT_END	Sense\tagSECTITLE_START	-\tagSECTITLE_CONTENT	annotated\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	corpora\tagSECTITLE_END	As\tagSENT_START	regards\tagSENT_CONTENT	sense\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	corpora\tagSENT_CONTENT	,\tagSENT_CONTENT	OMSTI\tagSENT_CONTENT	is\tagSENT_CONTENT	made\tagSENT_CONTENT	up\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	considerable\tagSENT_CONTENT	increase\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sense\tagSENT_CONTENT	annotations\tagSENT_CONTENT	of\tagSENT_CONTENT	SemCor\tagSENT_CONTENT	.\tagSENT_END	Statistics\tagSECTITLE_END	Evaluation\tagSECTITLE_END	Comparison\tagSECTITLE_START	systems\tagSECTITLE_END	Supervised\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	word_sense_disambiguation\tagtask	in\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	made\tagSENT_CONTENT	up\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	billion\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	web\tagSENT_CONTENT	.\tagSENT_END	Then\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	learned\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Knowledge\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_END	We\tagSENT_START	used\tagSENT_CONTENT	both\tagSENT_CONTENT	default\tagSENT_CONTENT	configurations\tagSENT_CONTENT	from\tagSENT_CONTENT	UKB\tagSENT_CONTENT	:\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	graph\tagSENT_CONTENT	(\tagSENT_CONTENT	UKB\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	graph\tagSENT_CONTENT	including\tagSENT_CONTENT	word_sense_disambiguation\tagtask	as\tagSENT_CONTENT	connections\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	(\tagSENT_CONTENT	UKB\tagSENT_CONTENT	gloss\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Babelfy\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	word_sense_disambiguation\tagtask	which\tagSENT_CONTENT	exploits\tagSENT_CONTENT	random\tagSENT_CONTENT	walks\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	connections\tagSENT_CONTENT	between\tagSENT_CONTENT	synsets\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Tr\tagSECTITLE_START	.\tagSECTITLE_CONTENT	Corpus\tagSECTITLE_END	System\tagSECTITLE_END	Supervised\tagSECTITLE_END	Analysis\tagSECTITLE_END	This\tagSENT_START	maybe\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	cases\tagSENT_CONTENT	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	immediate\tagSENT_CONTENT	local\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_END	word_sense_disambiguation\tagtask	seems\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	its\tagSENT_CONTENT	previous\tagSENT_CONTENT	and\tagSENT_CONTENT	immediate\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	federal\tagSENT_CONTENT	and\tagSENT_CONTENT	government\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	occur\tagSENT_CONTENT	with\tagSENT_CONTENT	this\tagSENT_CONTENT	particular\tagSENT_CONTENT	sense\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	global\tagSENT_CONTENT	error\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	PoS\tagSENT_CONTENT	tagger\tagSENT_CONTENT	in\tagSENT_CONTENT	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	3.9\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	were\tagSENT_CONTENT	fixed\tagSENT_CONTENT	as\tagSENT_CONTENT	explained\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	This\tagSENT_START	framework\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	datasets\tagSENT_CONTENT	taken\tagSENT_CONTENT	from\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	manually\tagSENT_CONTENT	and\tagSENT_CONTENT	automatically\tagSENT_CONTENT	sense\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	word_sense_disambiguation\tagtask	.\tagSENT_END	Satanjeev\tagSECTITLE_START	Banerjee\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Ted\tagSECTITLE_CONTENT	Pedersen\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	2003\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Extended\tagSECTITLE_END	
D16-1065	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Experiments\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	public\tagSENT_CONTENT	datasets\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	pipelined\tagSENT_CONTENT	counterparts\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	achieves\tagSENT_CONTENT	better\tagSENT_CONTENT	or\tagSENT_CONTENT	comparable\tagSENT_CONTENT	performance\tagSENT_CONTENT	than\tagSENT_CONTENT	other\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	without\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	external\tagSENT_CONTENT	semantic\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	presented\tagSENT_START	a\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answering\tagSENT_CONTENT	system\tagSENT_CONTENT	by\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	good\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	is\tagSENT_CONTENT	still\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	nascent\tagSENT_CONTENT	stage\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	address\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	reformulate\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	by\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	an\tagSENT_CONTENT	incremental\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	joint\tagSENT_CONTENT	framework\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	pipelined\tagSENT_CONTENT	counterparts\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	achieves\tagSENT_CONTENT	better\tagSENT_CONTENT	or\tagSENT_CONTENT	comparable\tagSENT_CONTENT	performance\tagSENT_CONTENT	than\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	even\tagSENT_CONTENT	without\tagSENT_CONTENT	employing\tagSENT_CONTENT	external\tagSENT_CONTENT	semantic\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	AMR\tagSECTITLE_START	Parsing\tagSECTITLE_CONTENT	Task\tagSECTITLE_END	The\tagSECTITLE_START	Pipelined\tagSECTITLE_CONTENT	Models\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	AMR\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	amr_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	stage\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	that\tagSENT_CONTENT	first\tagSENT_CONTENT	identifies\tagSENT_CONTENT	concepts\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	identifies\tagSENT_CONTENT	the\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	obtain\tagSENT_CONTENT	between\tagSENT_CONTENT	these\tagSENT_CONTENT	.\tagSENT_END	Algorithms\tagSECTITLE_END	To\tagSENT_START	this\tagSENT_CONTENT	end\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	an\tagSENT_CONTENT	incremental\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	An\tagSECTITLE_START	Incremental\tagSECTITLE_CONTENT	Decoding\tagSECTITLE_CONTENT	Algorithm\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	Identification\tagSECTITLE_END	Obviously\tagSENT_START	,\tagSENT_CONTENT	finding\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	maximum\tagSENT_CONTENT	spanning\tagSENT_CONTENT	graph\tagSENT_CONTENT	in\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	in\tagSENT_CONTENT	fact\tagSENT_CONTENT	carries\tagSENT_CONTENT	more\tagSENT_CONTENT	complexities\tagSENT_CONTENT	than\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	maximum\tagSENT_CONTENT	spanning\tagSENT_CONTENT	tree\tagSENT_CONTENT	(\tagSENT_CONTENT	MST\tagSENT_CONTENT	)\tagSENT_CONTENT	decoding\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Unlike\tagSENT_START	the\tagSENT_CONTENT	beam\tagSENT_CONTENT	-\tagSENT_CONTENT	search\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	greatly\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	by\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	the\tagSENT_CONTENT	projectivity\tagSENT_CONTENT	property\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	tree\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	naive\tagSENT_CONTENT	search\tagSENT_CONTENT	process\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	context\tagSENT_CONTENT	inevitably\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	huge\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	furthermore\tagSENT_CONTENT	is\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	guarantee\tagSENT_CONTENT	the\tagSENT_CONTENT	connectivity\tagSENT_CONTENT	of\tagSENT_CONTENT	output\tagSENT_CONTENT	graph\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	do\tagmetric	buf\tagmetric	←\tagmetric	N\tagmetric	U\tagmetric	9\tagSECTITLE_START	:\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	determinism\tagSENT_CONTENT	constraint\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	section\tagSENT_CONTENT	2.2\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	satisfied\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Joint\tagSECTITLE_START	Decoding\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Concept\tagSECTITLE_CONTENT	Identifica\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	tion\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	Identification\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	beam\tagSENT_CONTENT	-\tagSENT_CONTENT	search\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	incremental\tagSENT_CONTENT	decoder\tagSENT_CONTENT	for\tagSENT_CONTENT	approximate\tagSENT_CONTENT	joint\tagSENT_CONTENT	inference\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	7\tagSECTITLE_START	:\tagSECTITLE_END	19\tagSECTITLE_START	:\tagSECTITLE_END	Violation\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Fixing\tagSECTITLE_CONTENT	Perceptron\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	Since\tagSENT_START	our\tagSENT_CONTENT	incremental\tagSENT_CONTENT	decoding\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	approximate\tagSENT_CONTENT	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	natural\tagSENT_CONTENT	to\tagSENT_CONTENT	employ\tagSENT_CONTENT	violation\tagSENT_CONTENT	-\tagSENT_CONTENT	fixing\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	here\tagSENT_CONTENT	for\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	reduce\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	averaged\tagSENT_CONTENT	parameters\tagSENT_CONTENT	after\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	decode\tagSENT_CONTENT	test\tagSENT_CONTENT	instances\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metric\tagSECTITLE_END	Following\tagSENT_START	previous\tagSENT_CONTENT	studies\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	were\tagSENT_CONTENT	performed\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	newswire\tagSENT_CONTENT	sections\tagSENT_CONTENT	of\tagSENT_CONTENT	LDC2013E117\tagSENT_CONTENT	and\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	split\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Development\tagSECTITLE_START	Results\tagSECTITLE_END	Incremental\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Identification\tagSECTITLE_CONTENT	Performance\tagSECTITLE_END	amr_parsing\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	component\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	search\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	effective\tagSENT_CONTENT	incremental\tagSENT_CONTENT	search\tagSENT_CONTENT	scheme\tagSENT_CONTENT	.\tagSENT_END	Joint\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	vs.\tagSECTITLE_CONTENT	Pipelined\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	To\tagSENT_START	give\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	implemented\tagSENT_CONTENT	system\tagSENT_CONTENT	1\tagSENT_CONTENT	only\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	features\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	4\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	for\tagSENT_CONTENT	concept\tagSENT_CONTENT	fragments\tagSENT_CONTENT	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	these\tagSENT_CONTENT	lexical\tagSENT_CONTENT	contextual\tagSENT_CONTENT	features\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	helpful\tagSENT_CONTENT	in\tagSENT_CONTENT	identifying\tagSENT_CONTENT	concepts\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Dataset\tagSECTITLE_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	State\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	art\tagSECTITLE_END	We\tagSENT_START	give\tagSENT_CONTENT	amr_parsing\tagtask	between\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsers\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	CCGbased\tagSENT_CONTENT	parser\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	dependencybased\tagSENT_CONTENT	parser\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	From\tagSENT_START	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	achieves\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	than\tagSENT_CONTENT	other\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	without\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	any\tagSENT_CONTENT	external\tagSENT_CONTENT	semantic\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	/\tagSENT_CONTENT	development\tagSENT_CONTENT	/\tagSENT_CONTENT	test\tagSENT_CONTENT	split\tagSENT_CONTENT	recommended\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	release\tagSENT_CONTENT	:\tagSENT_CONTENT	10,312\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	1,368\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	1,371\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	introduces\tagSENT_START	anew\tagSENT_CONTENT	CCG\tagSENT_CONTENT	grammar\tagSENT_CONTENT	induction\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	factor\tagSENT_CONTENT	graph\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	compositional\tagSENT_CONTENT	phenomena\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
1806.05516	title\tagSECTITLE_END	text_classification\tagtask	as\tagSENT_CONTENT	Additional\tagSENT_CONTENT	Contexts\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	abstract\tagSECTITLE_END	In\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	additional\tagSENT_CONTENT	contexts\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	neighboring\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	may\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	classifier\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	One\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	primary\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	review\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	tasked\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	it\tagSENT_CONTENT	into\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	classes\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	into\tagSENT_CONTENT	positive\tagSENT_CONTENT	or\tagSENT_CONTENT	negative\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	task\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	almost\tagSENT_CONTENT	all\tagSENT_CONTENT	subareas\tagSENT_CONTENT	of\tagSENT_CONTENT	NLP\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	text_classification\tagtask	for\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	type\tagSENT_CONTENT	classification\tagSENT_CONTENT	for\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	name\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	overcome\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	recent\tagSENT_CONTENT	works\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	augment\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	neighboring\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	topics\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	one\tagSENT_CONTENT	thing\tagSENT_CONTENT	,\tagSENT_CONTENT	neighboring\tagSENT_CONTENT	sentences\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	available\tagSENT_CONTENT	in\tagSENT_CONTENT	some\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	topics\tagSENT_CONTENT	inferred\tagSENT_CONTENT	using\tagSENT_CONTENT	topic\tagSENT_CONTENT	models\tagSENT_CONTENT	may\tagSENT_CONTENT	produce\tagSENT_CONTENT	less\tagSENT_CONTENT	useful\tagSENT_CONTENT	topics\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	usage\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	as\tagSENT_CONTENT	compelling\tagSENT_CONTENT	and\tagSENT_CONTENT	effective\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	free\tagSENT_CONTENT	contexts\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	contexts\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	always\tagSENT_CONTENT	available\tagSENT_CONTENT	no\tagSENT_CONTENT	matter\tagSENT_CONTENT	what\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	domain\tagSENT_CONTENT	is\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	observe\tagSENT_CONTENT	two\tagSENT_CONTENT	opportunities\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	each\tagSENT_CONTENT	language\tagSENT_CONTENT	has\tagSENT_CONTENT	its\tagSENT_CONTENT	own\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	and\tagSENT_CONTENT	cultural\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	that\tagSENT_CONTENT	may\tagSENT_CONTENT	contain\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	effectively\tagSENT_CONTENT	classify\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	contrasts\tagSENT_START	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	English\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	Arabictranslated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	A\tagSENT_START	yellow\tagSENT_CONTENT	circle\tagSENT_CONTENT	signifies\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	sentences\tagSENT_CONTENT	may\tagSENT_CONTENT	include\tagSENT_CONTENT	languagespecific\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	maybe\tagSENT_CONTENT	resolved\tagSENT_CONTENT	when\tagSENT_CONTENT	presented\tagSENT_CONTENT	with\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Consider\tagSENT_START	the\tagSENT_CONTENT	example\tagSENT_CONTENT	English\tagSENT_CONTENT	sentence\tagSENT_CONTENT	"\tagSENT_CONTENT	The\tagSENT_CONTENT	movie\tagSENT_CONTENT	is\tagSENT_CONTENT	terribly\tagSENT_CONTENT	amazing\tagSENT_CONTENT	"\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSENT_START	above\tagSENT_CONTENT	two\tagSENT_CONTENT	observations\tagSENT_CONTENT	hold\tagSENT_CONTENT	only\tagSENT_CONTENT	when\tagSENT_CONTENT	text_classification\tagtask	are\tagSENT_CONTENT	supported\tagSENT_CONTENT	for\tagSENT_CONTENT	(\tagSENT_CONTENT	nearly\tagSENT_CONTENT	)\tagSENT_CONTENT	arbitrary\tagSENT_CONTENT	language\tagSENT_CONTENT	pairs\tagSENT_CONTENT	with\tagSENT_CONTENT	sufficiently\tagSENT_CONTENT	high\tagSENT_CONTENT	quality\tagSENT_CONTENT	.\tagSENT_END	dis\tagSENT_START	the\tagSENT_CONTENT	Mahalanobis\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	MCFA\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	the\tagSENT_CONTENT	maturity\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	naively\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	their\tagSENT_CONTENT	vectors\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vector\tagSENT_CONTENT	may\tagSENT_CONTENT	introduce\tagSENT_CONTENT	more\tagSENT_CONTENT	noise\tagSENT_CONTENT	than\tagSENT_CONTENT	signals\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	unaltered\tagSENT_CONTENT	translation\tagSENT_CONTENT	space\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	of\tagSENT_CONTENT	shows\tagSENT_CONTENT	an\tagSENT_CONTENT	example\tagSENT_CONTENT	where\tagSENT_CONTENT	translation\tagSENT_CONTENT	noises\tagSENT_CONTENT	make\tagSENT_CONTENT	text_classification\tagtask	indistinguishable\tagSENT_CONTENT	.\tagSENT_END	Suppose\tagSENT_START	there\tagSENT_CONTENT	are\tagSENT_CONTENT	two\tagSENT_CONTENT	translated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	a\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	with\tagSENT_CONTENT	slight\tagmetric	errors\tagmetric	.\tagSENT_END	Revisiting\tagSENT_START	the\tagSENT_CONTENT	example\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	fix\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	sentence\tagSENT_CONTENT	"\tagSENT_CONTENT	The\tagSENT_CONTENT	movie\tagSENT_CONTENT	is\tagSENT_CONTENT	terribly\tagSENT_CONTENT	amazing\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Korean\tagSENT_CONTENT	translation\tagSENT_CONTENT	to\tagSENT_CONTENT	move\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	towards\tagSENT_CONTENT	text_classification\tagtask	where\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	"\tagSENT_CONTENT	The\tagSENT_CONTENT	movie\tagSENT_CONTENT	is\tagSENT_CONTENT	greatly\tagSENT_CONTENT	magnificent\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	.\tagSENT_END	Fixing\tagSENT_START	the\tagSENT_CONTENT	vectors\tagSENT_CONTENT	is\tagSENT_CONTENT	done\tagSENT_CONTENT	by\tagSENT_CONTENT	selectively\tagSENT_CONTENT	moving\tagSENT_CONTENT	the\tagSENT_CONTENT	vectors\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	vector\tagSENT_CONTENT	space\tagSENT_CONTENT	that\tagSENT_CONTENT	better\tagSENT_CONTENT	separates\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Noises\tagSENT_START	from\tagSENT_CONTENT	text_classification\tagtask	may\tagSENT_CONTENT	cause\tagSENT_CONTENT	adverse\tagSENT_CONTENT	effects\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	itself\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	when\tagSENT_CONTENT	a\tagSENT_CONTENT	noisy\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	directly\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	relatively\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	when\tagSENT_CONTENT	a\tagSENT_CONTENT	noisy\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	fix\tagSENT_CONTENT	another\tagSENT_CONTENT	noisy\tagSENT_CONTENT	vector\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	MCFA\tagSENT_START	is\tagSENT_CONTENT	extensible\tagSENT_CONTENT	and\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	as\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	translated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	increases\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	3\tagSENT_CONTENT	)\tagSENT_CONTENT	MCFA\tagSENT_CONTENT	moves\tagSENT_CONTENT	the\tagSENT_CONTENT	vectors\tagSENT_CONTENT	inside\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	preserves\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Results\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	attached\tagSENT_CONTENT	with\tagSENT_CONTENT	MCFA\tagSENT_CONTENT	significantly\tagSENT_CONTENT	improves\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	2\tagSENT_CONTENT	Preliminaries\tagSENT_END	Problem\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Translated\tagSECTITLE_CONTENT	Sentences\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	Context\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	ultimate\tagSENT_CONTENT	task\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	solve\tagSENT_CONTENT	is\tagSENT_CONTENT	text_classification\tagtask	where\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	classes\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	is\tagSENT_CONTENT	task\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	which\tagSENT_CONTENT	class\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	challenge\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	tackle\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	on\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	utilize\tagSENT_CONTENT	translated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	context\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSENT_START	base\tagSENT_CONTENT	model\tagSENT_CONTENT	used\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	variation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	CNN\tagSENT_CONTENT	for\tagSENT_CONTENT	texts\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	i\tagSENT_START	using\tagSENT_CONTENT	text_classification\tagtask	We\tagSENT_START	can\tagSENT_CONTENT	then\tagSENT_CONTENT	use\tagSENT_CONTENT	this\tagSENT_CONTENT	vector\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	text_classification\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	.\tagSENT_END	From\tagSENT_START	hereon\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	these\tagSENT_CONTENT	vectors\tagSENT_CONTENT	as\tagSENT_CONTENT	v\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	v\tagSENT_CONTENT	t1\tagSENT_CONTENT	,\tagSENT_CONTENT	v\tagSENT_CONTENT	t2\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	,\tagSENT_CONTENT	v\tagSENT_CONTENT	tn\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	[\tagSENT_START	v\tagSENT_CONTENT	s\tagSENT_CONTENT	;\tagSENT_CONTENT	v\tagSENT_CONTENT	t1\tagSENT_CONTENT	;\tagSENT_CONTENT	...\tagSENT_CONTENT	;\tagSENT_CONTENT	v\tagSENT_CONTENT	tn\tagSENT_CONTENT	]\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	this\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	sentiment_analysis\tagtask	translated\tagSENT_CONTENT	using\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	models\tagSENT_CONTENT	usually\tagSENT_CONTENT	contain\tagSENT_CONTENT	incorrect\tagSENT_CONTENT	translation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	effect\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	method\tagSENT_CONTENT	will\tagSENT_CONTENT	have\tagSENT_CONTENT	adverse\tagSENT_CONTENT	effects\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Model\tagSECTITLE_END	Self\tagSECTITLE_START	Usability\tagSECTITLE_CONTENT	Module\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	other\tagSENT_CONTENT	vectors\tagSENT_CONTENT	might\tagSENT_CONTENT	also\tagSENT_CONTENT	contain\tagSENT_CONTENT	errors\tagmetric	which\tagSENT_CONTENT	may\tagSENT_CONTENT	reflect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fixing\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	,\tagSENT_CONTENT	denoted\tagSENT_CONTENT	as\tagSENT_CONTENT	ρ\tagSENT_CONTENT	i\tagSENT_CONTENT	(\tagSENT_CONTENT	v\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	text_classification\tagtask	Relative\tagSECTITLE_START	Usability\tagSECTITLE_CONTENT	Module\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	text_classification\tagtask	Vector\tagSECTITLE_START	Fixing\tagSECTITLE_CONTENT	Module\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	approach\tagSENT_CONTENT	makes\tagSENT_CONTENT	text_classification\tagtask	not\tagSENT_CONTENT	interpretable\tagSENT_CONTENT	;\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	hard\tagSENT_CONTENT	to\tagSENT_CONTENT	explain\tagSENT_CONTENT	what\tagSENT_CONTENT	does\tagSENT_CONTENT	adding\tagSENT_CONTENT	a\tagSENT_CONTENT	value\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	dimension\tagSENT_CONTENT	mean\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	major\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	MCFA\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	vectors\tagSENT_CONTENT	are\tagSENT_CONTENT	interpretable\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	gate\tagSENT_CONTENT	vector\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	dimension\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setting\tagSECTITLE_END	text_classification\tagtask	is\tagSENT_CONTENT	done\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	polyglot\tagSENT_CONTENT	library\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	N\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	text_classification\tagtask	for\tagSENT_CONTENT	conciseness\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	do\tagSENT_CONTENT	not\tagSENT_CONTENT	show\tagSENT_CONTENT	results\tagSENT_CONTENT	from\tagSENT_CONTENT	RNN\tagSENT_CONTENT	models\tagSENT_CONTENT	because\tagSENT_CONTENT	they\tagSENT_CONTENT	were\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	less\tagSENT_CONTENT	effective\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	our\tagSENT_CONTENT	prior\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	models\tagSENT_CONTENT	with\tagSENT_CONTENT	additional\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	further\tagSENT_CONTENT	use\tagSENT_CONTENT	text_classification\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	method\tagSENT_CONTENT	by\tagSENT_CONTENT	averaging\tagSENT_CONTENT	text_classification\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	multiple\tagSENT_CONTENT	variants\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	N\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	N\tagSENT_CONTENT	=\tagSENT_CONTENT	10\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	competing\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	MCFA\tagSENT_CONTENT	is\tagSENT_CONTENT	successful\tagSENT_CONTENT	in\tagSENT_CONTENT	effectively\tagSENT_CONTENT	using\tagSENT_CONTENT	text_classification\tagtask	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	context\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagmetric	accuracies\tagmetric	of\tagSENT_CONTENT	text_classification\tagtask	when\tagSENT_CONTENT	N\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	all\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	except\tagSENT_CONTENT	SUBJ\tagdataset	,\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	CNN+B1\tagSENT_CONTENT	decreases\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagmetric	base\tagmetric	CNN\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	always\tagSENT_CONTENT	improves\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagmetric	base\tagmetric	CNN\tagmetric	accuracy\tagmetric	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	additional\tagSENT_CONTENT	context\tagSENT_CONTENT	:\tagSENT_CONTENT	topics\tagSENT_CONTENT	(\tagSENT_CONTENT	TopCNN\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	CNN+B1\tagSENT_CONTENT	,\tagSENT_CONTENT	CNN+B2\tagSENT_CONTENT	,\tagSENT_CONTENT	CNN+MCFA\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conclude\tagSENT_CONTENT	that\tagSENT_CONTENT	text_classification\tagtask	are\tagSENT_CONTENT	better\tagSENT_CONTENT	additional\tagSENT_CONTENT	contexts\tagSENT_CONTENT	than\tagSENT_CONTENT	topics\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	using\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	context\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	TopCNN\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	TopCNN\tagSENT_CONTENT	sent\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	when\tagSENT_CONTENT	N\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	text_classification\tagtask	always\tagSENT_CONTENT	outperform\tagSENT_CONTENT	topics\tagSENT_CONTENT	even\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	topics\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	context\tagSENT_CONTENT	also\tagSENT_CONTENT	decreases\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	on\tagSENT_CONTENT	most\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	giving\tagSENT_CONTENT	an\tagSENT_CONTENT	adverse\tagSENT_CONTENT	effect\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Model\tagSECTITLE_START	Interpretation\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	provide\tagSENT_CONTENT	examples\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	on\tagSENT_CONTENT	how\tagSENT_CONTENT	the\tagSENT_CONTENT	self\tagSENT_CONTENT	usability\tagSENT_CONTENT	module\tagSENT_CONTENT	determines\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	second\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	contains\tagSENT_CONTENT	mistranslations\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	are\tagSENT_CONTENT	minimal\tagSENT_CONTENT	and\tagSENT_CONTENT	may\tagSENT_CONTENT	actually\tagSENT_CONTENT	help\tagSENT_CONTENT	text_classification\tagtask	by\tagSENT_CONTENT	telling\tagSENT_CONTENT	it\tagSENT_CONTENT	that\tagSENT_CONTENT	thirst\tagSENT_CONTENT	for\tagSENT_CONTENT	violence\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	a\tagSENT_CONTENT	í\tagSENT_CONTENT	µí±\tagSENT_CONTENT	¡\tagSENT_CONTENT	í\tagSENT_CONTENT	µí±í\tagSENT_CONTENT	µí±\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	negative\tagSENT_CONTENT	sentence\tagSENT_CONTENT	)\tagSENT_END	NN\tagSECTITLE_START	(\tagSECTITLE_CONTENT	altered\tagSECTITLE_CONTENT	)\tagSECTITLE_END	NN\tagSECTITLE_START	(\tagSECTITLE_CONTENT	Unaltered\tagSECTITLE_CONTENT	)\tagSECTITLE_END	NN\tagSECTITLE_START	(\tagSECTITLE_CONTENT	altered\tagSECTITLE_CONTENT	)\tagSECTITLE_END	shows\tagSENT_START	text_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	unaltered\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	altered\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	four\tagSENT_CONTENT	different\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	After\tagSENT_START	the\tagSENT_CONTENT	fix\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vectors\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	middle\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	are\tagSENT_CONTENT	moved\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	text_classification\tagtask	more\tagSENT_CONTENT	obvious\tagSENT_CONTENT	and\tagSENT_CONTENT	clearer\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	provide\tagSENT_CONTENT	quantitative\tagSENT_CONTENT	evidence\tagSENT_CONTENT	by\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	Mahalanobis\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	altered\tagSENT_CONTENT	vectors\tagSENT_CONTENT	are\tagSENT_CONTENT	significantly\tagSENT_CONTENT	farther\tagSENT_CONTENT	than\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	unaltered\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	unaltered\tagSENT_CONTENT	vector\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	"\tagSENT_CONTENT	wasted\tagSENT_CONTENT	yours\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	puts\tagSENT_CONTENT	it\tagSENT_CONTENT	near\tagSENT_CONTENT	sentiment_analysis\tagtask	regarding\tagSENT_CONTENT	wasted\tagSENT_CONTENT	time\tagSENT_CONTENT	or\tagSENT_CONTENT	money\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	One\tagSENT_START	way\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	new\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	trained\tagSENT_CONTENT	from\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	NMT\tagSENT_CONTENT	)\tagSENT_CONTENT	systems\tagSENT_CONTENT	were\tagSENT_CONTENT	also\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	demonstrated\tagSENT_START	that\tagSENT_CONTENT	altered\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	NMT\tagSENT_CONTENT	encoders\tagSENT_CONTENT	outperform\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	encoders\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Increasing\tagSENT_START	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	data\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	has\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	investigates\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	as\tagSENT_CONTENT	better\tagSENT_CONTENT	additional\tagSENT_CONTENT	contexts\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	improves\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	multiple\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	
1603.01547	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	anew\tagSENT_CONTENT	,\tagSENT_CONTENT	simple\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	uses\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	pick\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	computing\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	blended\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	as\tagSENT_CONTENT	is\tagSENT_CONTENT	usual\tagSENT_CONTENT	in\tagSENT_CONTENT	similar\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	One\tagSENT_START	way\tagSENT_CONTENT	of\tagSENT_CONTENT	testing\tagSENT_CONTENT	the\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	understanding\tagSENT_CONTENT	is\tagSENT_CONTENT	simply\tagSENT_CONTENT	to\tagSENT_CONTENT	ask\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	questions\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	inferred\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Cloze\tagSENT_START	-\tagSENT_CONTENT	style\tagSENT_CONTENT	questions\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	formed\tagSENT_CONTENT	by\tagSENT_CONTENT	removing\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	an\tagSENT_CONTENT	appealing\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	such\tagSENT_CONTENT	questions\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	example\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	answer\tagSENT_CONTENT	cadidates\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Also\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	selecting\tagSENT_CONTENT	a\tagSENT_CONTENT	random\tagSENT_CONTENT	sentence\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	formed\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	summary\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	important\tagSENT_CONTENT	property\tagSENT_CONTENT	of\tagSENT_CONTENT	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	questions\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	automatically\tagSENT_CONTENT	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	real\tagSENT_CONTENT	world\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	Task\tagSECTITLE_START	and\tagSECTITLE_CONTENT	datasets\tagSECTITLE_END	Formal\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	Description\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	answering\tagSENT_CONTENT	a\tagSENT_CONTENT	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	which\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	document\tagSENT_CONTENT	provided\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	training\tagSENT_CONTENT	data\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	tuples\tagSENT_CONTENT	(\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	d\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	q\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	dis\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	that\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	to\tagSENT_CONTENT	question\tagSENT_CONTENT	q\tagSENT_END	Datasets\tagSECTITLE_END	News\tagSECTITLE_START	Articles\tagSECTITLE_CONTENT	-CNN\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	created\tagSENT_CONTENT	by\tagSENT_CONTENT	replacing\tagSENT_CONTENT	a\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	"\tagSENT_CONTENT	Producer\tagSENT_CONTENT	X\tagSENT_CONTENT	will\tagSENT_CONTENT	not\tagSENT_CONTENT	press\tagSENT_CONTENT	charges\tagSENT_CONTENT	against\tagSENT_CONTENT	Jeremy\tagSENT_CONTENT	Clarkson\tagSENT_CONTENT	,\tagSENT_CONTENT	his\tagSENT_CONTENT	lawyer\tagSENT_CONTENT	says\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	the\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	dataset\tagSENT_CONTENT	were\tagSENT_CONTENT	replaced\tagSENT_CONTENT	by\tagSENT_CONTENT	anonymous\tagSENT_CONTENT	tokens\tagSENT_CONTENT	which\tagSENT_CONTENT	were\tagSENT_CONTENT	further\tagSENT_CONTENT	shuffled\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	example\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	buildup\tagSENT_CONTENT	any\tagSENT_CONTENT	world\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	genuinely\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	document\tagSENT_CONTENT	to\tagSENT_CONTENT	search\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSENT_START	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	patterns\tagSENT_CONTENT	needed\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	dataset\tagSENT_CONTENT	together\tagSENT_CONTENT	with\tagSENT_CONTENT	human\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	are\tagSENT_CONTENT	provided\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Children\tagSECTITLE_START	's\tagSECTITLE_CONTENT	Book\tagSECTITLE_CONTENT	Test\tagSECTITLE_END	Our\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	-Attention\tagSECTITLE_CONTENT	Sum\tagSECTITLE_CONTENT	Reader\tagSECTITLE_END	4\tagSENT_START	is\tagSENT_CONTENT	tailor\tagSENT_CONTENT	-\tagSENT_CONTENT	made\tagSENT_CONTENT	to\tagSENT_CONTENT	leverage\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	a\tagSENT_CONTENT	dot\tagSENT_CONTENT	product\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	occurrence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	candidate\tagSENT_CONTENT	answer\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	likely\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Formal\tagSECTITLE_START	Description\tagSECTITLE_END	For\tagSENT_START	convenience\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	ind\tagSENT_CONTENT	as\tagSENT_CONTENT	f\tagmetric	i\tagSENT_CONTENT	(\tagSENT_CONTENT	d\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	s\tagSENT_START	i\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	query\tagSENT_CONTENT	q\tagSENT_CONTENT	appears\tagSENT_CONTENT	at\tagSENT_CONTENT	position\tagSENT_END	Finally\tagSENT_START	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	that\tagSENT_CONTENT	word\tagSENT_CONTENT	w\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	:\tagSENT_END	Model\tagSECTITLE_START	instance\tagSECTITLE_CONTENT	details\tagSECTITLE_END	Embeddings\tagSECTITLE_END	The\tagSENT_START	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	function\tagSENT_CONTENT	e\tagmetric	is\tagSENT_CONTENT	implemented\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	usual\tagSENT_CONTENT	way\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	table\tagSENT_CONTENT	V.\tagSENT_CONTENT	V\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	whose\tagSENT_CONTENT	rows\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	indexed\tagSENT_CONTENT	by\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	e(w\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	All\tagSENT_START	of\tagSENT_CONTENT	these\tagSENT_CONTENT	architectures\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	that\tagSENT_CONTENT	allows\tagSENT_CONTENT	them\tagmetric	to\tagSENT_CONTENT	highlight\tagSENT_CONTENT	places\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	that\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Attentive\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Impatient\tagSECTITLE_CONTENT	Readers\tagSECTITLE_END	In\tagSENT_START	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Attentive\tagSENT_CONTENT	Reader\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	select\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	directly\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	computed\tagSENT_CONTENT	attention\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	using\tagSENT_CONTENT	such\tagSENT_CONTENT	attention\tagSENT_CONTENT	fora\tagSENT_CONTENT	weighted\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	individual\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	blending\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	described\tagSENT_CONTENT	above\tagSENT_CONTENT	would\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	two\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	closest\tagSENT_CONTENT	word\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	-this\tagSENT_CONTENT	may\tagSENT_CONTENT	well\tagSENT_CONTENT	happen\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	February\tagSENT_END	Chen\tagSECTITLE_START	et\tagSECTITLE_CONTENT	al\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	2016\tagSECTITLE_END	One\tagSENT_START	difference\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	computed\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	bilinear\tagSENT_CONTENT	term\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	simple\tagSENT_CONTENT	dot\tagSENT_CONTENT	-\tagSENT_CONTENT	product\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	s\tagSENT_CONTENT	i\tagSENT_CONTENT	∝\tagSENT_CONTENT	exp\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Memory\tagSECTITLE_START	Networks\tagSECTITLE_END	Dynamic\tagSECTITLE_START	Entity\tagSECTITLE_CONTENT	Representation\tagSECTITLE_END	Pointer\tagSECTITLE_START	Networks\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	was\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	PtrNets\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	to\tagSENT_CONTENT	blend\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	into\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	Summary\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	use\tagSENT_CONTENT	summation\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	away\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	Training\tagSECTITLE_START	Details\tagSECTITLE_END	To\tagSENT_START	speedup\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	always\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	fetched\tagSENT_CONTENT	10\tagSENT_CONTENT	batches\tagSENT_CONTENT	worth\tagSENT_CONTENT	of\tagSENT_CONTENT	examples\tagSENT_CONTENT	and\tagSENT_CONTENT	sorted\tagSENT_CONTENT	them\tagmetric	according\tagSENT_CONTENT	to\tagSENT_CONTENT	document\tagSENT_CONTENT	length\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	forced\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	truly\tagSENT_CONTENT	deduce\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	single\tagSENT_CONTENT	context\tagSENT_CONTENT	document\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Method\tagSECTITLE_END	Although\tagSENT_START	the\tagSENT_CONTENT	model\tagSENT_CONTENT	computes\tagSENT_CONTENT	attention\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	we\tagSENT_CONTENT	restrict\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	candidate\tagSENT_CONTENT	answers\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	then\tagSENT_START	measures\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	test\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	was\tagSENT_CONTENT	among\tagSENT_CONTENT	question_answering\tagtask	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	greedy\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	model\tagSENT_CONTENT	fork\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	5\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	common\tagSENT_CONTENT	noun\tagSENT_CONTENT	prediction\tagSENT_CONTENT	our\tagSENT_CONTENT	single\tagSENT_CONTENT	models\tagSENT_CONTENT	is\tagSENT_CONTENT	0.4\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	Analysis\tagSECTITLE_END	Finally\tagSENT_START	the\tagSENT_CONTENT	context\tagSENT_CONTENT	length\tagSENT_CONTENT	is\tagSENT_CONTENT	correlated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	itself\tagSENT_CONTENT	negatively\tagSENT_CONTENT	correlated\tagSENT_CONTENT	with\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	An\tagSENT_START	analysis\tagSENT_CONTENT	by\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	on\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	datasets\tagSENT_CONTENT	a\tagSENT_CONTENT	significant\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	or\tagSENT_CONTENT	too\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	even\tagSENT_CONTENT	for\tagSENT_CONTENT	humans\tagSENT_CONTENT	(\tagSENT_CONTENT	partly\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	entity\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	)\tagSENT_END	Dataset\tagSECTITLE_END	Appendix\tagSECTITLE_START	B\tagSECTITLE_CONTENT	Dependence\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	accuracy\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	frequency\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	correct\tagSECTITLE_CONTENT	answer\tagSECTITLE_END	
P17-1044	title\tagSECTITLE_END	semantic_role_labeling\tagtask	:\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	anew\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	semantic_role_labeling\tagtask	(\tagSENT_CONTENT	SRL\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	significantly\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	detailed\tagSENT_CONTENT	analyses\tagSENT_CONTENT	to\tagSENT_CONTENT	reveal\tagSENT_CONTENT	its\tagSENT_CONTENT	strengths\tagSENT_CONTENT	and\tagSENT_CONTENT	limitations\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	semantic_role_labeling\tagtask	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	recover\tagSENT_CONTENT	the\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	essentially\tagSENT_CONTENT	"\tagSENT_CONTENT	who\tagSENT_CONTENT	did\tagSENT_CONTENT	what\tagSENT_CONTENT	to\tagSENT_CONTENT	whom\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	when\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	where\tagSENT_CONTENT	.\tagSENT_CONTENT	"\tagSENT_END	Recently\tagSENT_START	breakthroughs\tagSENT_CONTENT	involving\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	deep\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	SRL\tagSENT_CONTENT	without\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	input\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	seem\tagSENT_CONTENT	to\tagSENT_CONTENT	overturn\tagSENT_CONTENT	the\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	held\tagSENT_CONTENT	belief\tagSENT_CONTENT	that\tagSENT_CONTENT	semantic_role_labeling\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	prerequisite\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Deep\tagSECTITLE_START	BiLSTM\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	The\tagSENT_START	input\tagSENT_CONTENT	vector\tagSENT_CONTENT	x\tagSENT_CONTENT	1,t\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	token\tagSENT_CONTENT	wt\tagSENT_CONTENT	's\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic_role_labeling\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	binary\tagSENT_CONTENT	feature\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	=\tagSENT_CONTENT	v\tagSENT_CONTENT	)\tagSENT_CONTENT	indicating\tagSENT_CONTENT	whether\tagSENT_CONTENT	wt\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	predicate\tagSENT_CONTENT	.\tagSENT_END	Constrained\tagSECTITLE_START	A\tagSECTITLE_CONTENT	*\tagSECTITLE_CONTENT	Decoding\tagSECTITLE_END	Exploration\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	prefixes\tagSENT_CONTENT	is\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	agenda\tagSENT_CONTENT	A\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	sorted\tagSENT_CONTENT	by\tagSENT_CONTENT	f\tagmetric	(\tagSENT_CONTENT	w\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	+\tagSENT_CONTENT	g(w\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	SRL\tagSECTITLE_START	Constraints\tagSECTITLE_END	Predicate\tagSECTITLE_START	Detection\tagSECTITLE_END	We\tagSENT_START	independently\tagSENT_CONTENT	predict\tagSENT_CONTENT	whether\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	predicate\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	softmax\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	outputs\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	Model\tagSECTITLE_START	Setup\tagSECTITLE_END	Results\tagSECTITLE_END	Without\tagSENT_START	dropout\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	overfits\tagSENT_CONTENT	at\tagSENT_CONTENT	around\tagSENT_CONTENT	300\tagSENT_CONTENT	epochs\tagSENT_CONTENT	at\tagSENT_CONTENT	78\tagmetric	F1\tagmetric	.\tagSENT_END	Ablations\tagSECTITLE_END	End\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	end\tagSECTITLE_CONTENT	SRL\tagSECTITLE_END	On\tagSENT_START	CoNLL\tagSENT_CONTENT	2005\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	predicate\tagSENT_CONTENT	detector\tagSENT_CONTENT	achieved\tagSENT_CONTENT	over\tagSENT_CONTENT	96\tagmetric	F1\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	SRL\tagSENT_CONTENT	results\tagSENT_CONTENT	only\tagSENT_CONTENT	drop\tagSENT_CONTENT	1.2\tagSENT_CONTENT	-\tagSENT_CONTENT	3.5\tagSENT_CONTENT	F1\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	predicates\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Error\tagSECTITLE_START	Types\tagSECTITLE_CONTENT	Breakdown\tagSECTITLE_END	shows\tagSENT_START	a\tagSENT_CONTENT	confusion\tagSENT_CONTENT	matrix\tagSENT_CONTENT	for\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	These\tagSENT_START	confusions\tagSENT_CONTENT	can\tagSENT_CONTENT	arise\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	ARG2\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	verb\tagSENT_CONTENT	frames\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	semantic_role_labeling\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	direction\tagSENT_CONTENT	or\tagSENT_CONTENT	location\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	the\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	involved\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	attachment\tagSENT_CONTENT	mistake\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	62\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	spans\tagSENT_CONTENT	are\tagSENT_CONTENT	prepositional\tagSENT_CONTENT	phrases\tagSENT_CONTENT	.\tagSENT_END	Fix\tagSECTITLE_START	Labels\tagSECTITLE_END	29.3\tagSECTITLE_END	Merge\tagSECTITLE_START	Spans\tagSECTITLE_END	Long\tagSECTITLE_START	-\tagSECTITLE_CONTENT	range\tagSECTITLE_CONTENT	Dependencies\tagSECTITLE_END	Structural\tagSECTITLE_START	Consistency\tagSECTITLE_END	BIO\tagSECTITLE_START	Violations\tagSECTITLE_END	+\tagSECTITLE_START	SRL\tagSECTITLE_END	SRL\tagSECTITLE_START	Structure\tagSECTITLE_CONTENT	Violations\tagSECTITLE_END	Can\tagSECTITLE_START	Syntax\tagSECTITLE_CONTENT	Still\tagSECTITLE_CONTENT	Help\tagSECTITLE_CONTENT	SRL\tagSECTITLE_CONTENT	?\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Traditional\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	semantic_role_labeling\tagtask	have\tagSENT_CONTENT	used\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parsers\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	constituents\tagSENT_CONTENT	and\tagSENT_CONTENT	model\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	enforced\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	gold\tagSENT_CONTENT	syntax\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	offthe\tagSENT_CONTENT	-\tagSENT_CONTENT	shelf\tagSENT_CONTENT	neural\tagSENT_CONTENT	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	semantic_role_labeling\tagtask	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	,\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	constituency\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	global\tagSENT_CONTENT	constraints\tagSENT_CONTENT	without\tagSENT_CONTENT	coding\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	for\tagSENT_CONTENT	doing\tagSENT_CONTENT	so\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	alternative\tagSENT_CONTENT	line\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	on\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	input\tagSENT_CONTENT	for\tagSENT_CONTENT	semantic_role_labeling\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	anew\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	semantic_role_labeling\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	10\tagSENT_CONTENT	%\tagSENT_CONTENT	relative\tagSENT_CONTENT	error\tagSENT_CONTENT	reduction\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	
K16-1028	title\tagSECTITLE_END	summarization\tagtask	using\tagSENT_CONTENT	Sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	and\tagSENT_CONTENT	Beyond\tagSENT_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	model\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	Attentional\tagSENT_CONTENT	Encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	Decoder\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	achieve\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	generating\tagSENT_CONTENT	a\tagSENT_CONTENT	headline\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	summary\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	sentences\tagSENT_CONTENT	that\tagSENT_CONTENT	captures\tagSENT_CONTENT	the\tagSENT_CONTENT	salient\tagSENT_CONTENT	ideas\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	article\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Despite\tagSENT_START	the\tagSENT_CONTENT	similarities\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	different\tagSENT_CONTENT	problem\tagSENT_CONTENT	from\tagSENT_CONTENT	MT\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	make\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	main\tagSENT_CONTENT	contributions\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	We\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	off\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	shelf\tagSENT_CONTENT	attentional\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	RNN\tagSENT_CONTENT	that\tagSENT_CONTENT	was\tagSENT_CONTENT	originally\tagSENT_CONTENT	developed\tagSENT_CONTENT	for\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	already\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	stateof\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	English\tagSENT_CONTENT	corpora\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	each\tagSENT_CONTENT	specific\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	addresses\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	encoderdecoder\tagSENT_CONTENT	RNN\tagSENT_CONTENT	that\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	propose\tagSENT_CONTENT	several\tagSENT_CONTENT	novel\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	addressing\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	weakness\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	Encoder\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_CONTENT	RNN\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Large\tagSECTITLE_CONTENT	Vocabulary\tagSECTITLE_CONTENT	Trick\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	adapted\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	summarization\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	'\tagSENT_CONTENT	trick\tagSENT_CONTENT	'\tagSENT_CONTENT	(\tagSENT_CONTENT	LVT\tagSENT_CONTENT	)\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Capturing\tagSECTITLE_START	Keywords\tagSECTITLE_CONTENT	using\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	rich\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	challenges\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	concepts\tagSENT_CONTENT	and\tagSENT_CONTENT	key\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	around\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	story\tagSENT_CONTENT	revolves\tagSENT_CONTENT	.\tagSENT_END	Modeling\tagSECTITLE_START	Rare\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Unseen\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	using\tagSECTITLE_CONTENT	Switching\tagSECTITLE_CONTENT	Generator\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Pointer\tagSECTITLE_END	Often\tagSENT_START	-\tagSENT_CONTENT	times\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	keywords\tagSENT_CONTENT	or\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	test\tagSENT_CONTENT	document\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	central\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	may\tagSENT_CONTENT	actually\tagSENT_CONTENT	be\tagSENT_CONTENT	unseen\tagSENT_CONTENT	or\tagSENT_CONTENT	rare\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	an\tagSENT_CONTENT	intuitive\tagSENT_CONTENT	way\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	such\tagSENT_CONTENT	OOV\tagSENT_CONTENT	words\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	simply\tagSENT_CONTENT	point\tagSENT_CONTENT	to\tagSENT_CONTENT	their\tagSENT_CONTENT	location\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	document\tagSENT_CONTENT	instead\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	Nd\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	Pa\tagSENT_CONTENT	i\tagSENT_CONTENT	(\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	th\tagSENT_CONTENT	time\tagmetric	-\tagmetric	step\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	pointing\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	j\tagSENT_CONTENT	th\tagSENT_CONTENT	position\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	h\tagSENT_CONTENT	d\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	's\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	at\tagSENT_CONTENT	position\tagSENT_CONTENT	j.\tagSENT_END	When\tagSENT_START	the\tagSENT_CONTENT	OOV\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	occurs\tagSENT_CONTENT	in\tagSENT_CONTENT	multiple\tagSENT_CONTENT	document\tagSENT_CONTENT	positions\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	break\tagSENT_CONTENT	the\tagSENT_CONTENT	tie\tagSENT_CONTENT	in\tagSENT_CONTENT	favor\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	first\tagSENT_CONTENT	occurrence\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	y\tagSENT_CONTENT	and\tagSENT_CONTENT	x\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	and\tagSENT_CONTENT	document\tagSENT_CONTENT	words\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	g\tagSENT_CONTENT	i\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	indicator\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	0\tagSENT_CONTENT	whenever\tagSENT_CONTENT	the\tagmetric	word\tagmetric	at\tagSENT_CONTENT	summarization\tagtask	i\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	is\tagSENT_CONTENT	OOV\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	word\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	accurately\tagSENT_CONTENT	point\tagSENT_CONTENT	to\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	although\tagSENT_CONTENT	they\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	.\tagSENT_END	Capturing\tagSECTITLE_START	Hierarchical\tagSECTITLE_CONTENT	Document\tagSECTITLE_CONTENT	Structure\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Hierarchical\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	In\tagSENT_START	datasets\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	document\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	long\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	keywords\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	drawn\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	A\tagSENT_START	vast\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	past\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	extractive\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	key\tagSENT_CONTENT	sentences\tagSENT_CONTENT	or\tagSENT_CONTENT	passages\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	reproducing\tagSENT_CONTENT	them\tagSENT_CONTENT	as\tagSENT_CONTENT	summary\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	work\tagSENT_CONTENT	starts\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	framework\tagSENT_CONTENT	as\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	go\tagSENT_CONTENT	beyond\tagSENT_CONTENT	the\tagSENT_CONTENT	stan\tagSENT_CONTENT	-\tagSENT_CONTENT	dard\tagSENT_CONTENT	architecture\tagSENT_CONTENT	and\tagSENT_CONTENT	propose\tagSENT_CONTENT	novel\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	address\tagSENT_CONTENT	critical\tagSENT_CONTENT	problems\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Gigaword\tagSECTITLE_START	Corpus\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	made\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	script\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	tokenized\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	systemgenerated\tagSENT_CONTENT	parts\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Rush\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	authors\tagSENT_CONTENT	used\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	Rouge\tagmetric	recall\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	their\tagSENT_CONTENT	systems\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	lvt2k-2sent\tagSENT_START	-\tagSENT_CONTENT	ptr\tagSENT_CONTENT	:\tagSENT_CONTENT	This\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	switching\tagSENT_CONTENT	generator\tagSENT_CONTENT	/\tagSENT_CONTENT	pointer\tagSENT_CONTENT	model\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	2.3\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	use\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	rich\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	side\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	with\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	Rush\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	reported\tagSENT_CONTENT	recall\tagSENT_CONTENT	-\tagSENT_CONTENT	only\tagSENT_CONTENT	from\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	Rouge\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	authors\tagSENT_CONTENT	kindly\tagSENT_CONTENT	provided\tagSENT_CONTENT	us\tagSENT_CONTENT	with\tagSENT_CONTENT	their\tagSENT_CONTENT	F1\tagSENT_CONTENT	numbers\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	their\tagSENT_CONTENT	test\tagSENT_CONTENT	sample\tagSENT_CONTENT	.\tagSENT_END	Further\tagSENT_START	,\tagSENT_CONTENT	explicit\tagSENT_CONTENT	modeling\tagSENT_CONTENT	of\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	multiple\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	switch\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	point\tagSENT_CONTENT	to\tagSENT_CONTENT	source\tagSENT_CONTENT	words\tagSENT_CONTENT	when\tagSENT_CONTENT	needed\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	solve\tagSENT_CONTENT	specific\tagSENT_CONTENT	problems\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	boosting\tagSENT_CONTENT	performance\tagSENT_CONTENT	incrementally\tagSENT_CONTENT	.\tagSENT_END	#\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	name\tagSECTITLE_END	DUC\tagSECTITLE_START	Corpus\tagSECTITLE_END	The\tagSENT_START	DUC\tagSENT_CONTENT	corpus\tagSENT_CONTENT	8\tagSENT_CONTENT	comes\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	2003\tagSENT_CONTENT	corpus\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	624\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	2004\tagSENT_CONTENT	corpus\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	500\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	note\tagSENT_CONTENT	that\tagSENT_CONTENT	although\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	8\tagSENT_CONTENT	http://duc.nist.gov/duc2004/tasks.html\tagSENT_CONTENT	consistently\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	ABS+\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	three\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	Rouge\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	differences\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	CNN\tagSECTITLE_START	/\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	Corpus\tagSECTITLE_END	The\tagSENT_START	existing\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	text\tagSENT_CONTENT	summarization\tagSENT_CONTENT	corpora\tagSENT_CONTENT	including\tagSENT_CONTENT	Gigaword\tagdataset	and\tagSENT_CONTENT	DUC\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	only\tagSENT_CONTENT	one\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Convergence\tagSENT_START	of\tagSENT_CONTENT	all\tagSENT_CONTENT	models\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	slower\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	Gigaword\tagdataset	,\tagSENT_CONTENT	taking\tagSENT_CONTENT	nearly\tagSENT_CONTENT	35\tagSENT_CONTENT	epochs\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	We\tagSENT_START	believe\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	 \tagSENT_CONTENT	can\tagSENT_CONTENT	fix\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	by\tagSENT_CONTENT	encouraging\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	'\tagSENT_CONTENT	remember\tagSENT_CONTENT	'\tagSENT_CONTENT	the\tagmetric	words\tagmetric	it\tagSENT_CONTENT	has\tagSENT_CONTENT	already\tagSENT_CONTENT	produced\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	attentional\tagSENT_CONTENT	encoderdecoder\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	very\tagSENT_CONTENT	promising\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	stateof\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	significantly\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	
P08-1076	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	provides\tagSENT_CONTENT	evidence\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	more\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	in\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	traditional\tagSENT_CONTENT	and\tagSENT_CONTENT	important\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	reported\tagSENT_START	a\tagSENT_CONTENT	substantial\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvement\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL'00\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	data\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL'03\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	PTB\tagSENT_START	)\tagSENT_CONTENT	III\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	CoNLL'00\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	CoNLL'03\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Conditional\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	SSL\tagSECTITLE_END	Conventional\tagSECTITLE_START	Supervised\tagSECTITLE_CONTENT	CRFs\tagSECTITLE_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	Extension\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	CRFs\tagSECTITLE_END	Scalability\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Efficient\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Algorithm\tagSECTITLE_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Hybrid\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Experiments\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	performance\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	1G\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Set\tagSECTITLE_END	Design\tagSECTITLE_START	of\tagSECTITLE_CONTENT	JESS\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	CM\tagSECTITLE_END	ys\tagSECTITLE_START	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	y\tagSECTITLE_CONTENT	s−1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	{\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	ys\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	pf\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	N\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	ys\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	sf\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Ns\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	}\tagSECTITLE_CONTENT	9\tagSECTITLE_CONTENT	N\tagSECTITLE_CONTENT	=\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	{\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	ys\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	wdu\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	ys\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	wtp\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	y\tagSECTITLE_CONTENT	s−1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	wtp\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	}\tagSECTITLE_CONTENT	s+2\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	=\tagSECTITLE_CONTENT	s−2\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	{\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	ys\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	wd\tagSECTITLE_CONTENT	u−1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	ys\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	wtp\tagSECTITLE_CONTENT	u−1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	[\tagSECTITLE_CONTENT	y\tagSECTITLE_CONTENT	s−1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	wtp\tagSECTITLE_CONTENT	u−1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	]\tagSECTITLE_CONTENT	}\tagSECTITLE_END	Design\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Joint\tagSECTITLE_CONTENT	PMs\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	HMMs\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Tunable\tagSECTITLE_START	Parameters\tagSECTITLE_END	Our\tagSENT_START	method\tagSENT_CONTENT	can\tagSENT_CONTENT	greatly\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	effort\tagSENT_CONTENT	needed\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	performance\tagSENT_CONTENT	tagger\tagSENT_CONTENT	or\tagSENT_CONTENT	chunking\tagtask	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Unlabeled\tagSECTITLE_CONTENT	Data\tagSECTITLE_CONTENT	Size\tagSECTITLE_END	Expected\tagSECTITLE_START	Performance\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Unseen\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	These\tagSENT_START	improvements\tagSENT_CONTENT	are\tagSENT_CONTENT	essentially\tagSENT_CONTENT	very\tagSENT_CONTENT	important\tagSENT_CONTENT	;\tagSENT_CONTENT	when\tagSENT_CONTENT	a\tagSENT_CONTENT	tagger\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	are\tagSENT_CONTENT	actually\tagSENT_CONTENT	used\tagSENT_CONTENT	,\tagSENT_CONTENT	input\tagSENT_CONTENT	data\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	anywhere\tagSENT_CONTENT	and\tagSENT_CONTENT	this\tagSENT_CONTENT	may\tagSENT_CONTENT	mostly\tagSENT_CONTENT	include\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	labeled\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	labeled\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	limited\tagSENT_CONTENT	and\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	strongly\tagSENT_CONTENT	encourages\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	SSL\tagSENT_CONTENT	approach\tagSENT_CONTENT	that\tagSENT_CONTENT	includes\tagSENT_CONTENT	JESS\tagSENT_CONTENT	-\tagSENT_CONTENT	CM\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	a\tagSENT_CONTENT	general\tagSENT_CONTENT	tagger\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	for\tagSENT_CONTENT	actual\tagSENT_CONTENT	use\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Previous\tagSECTITLE_CONTENT	Top\tagSECTITLE_CONTENT	Systems\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Related\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	was\tagSENT_CONTENT	reported\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	'\tagSENT_CONTENT	ASO\tagSENT_CONTENT	-\tagSENT_CONTENT	semi\tagSENT_CONTENT	'\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	regards\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	JESS\tagSENT_CONTENT	-\tagSENT_CONTENT	CM\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	ASO\tagSENT_CONTENT	-\tagSENT_CONTENT	semi\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	15M\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	size\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	in\tagSENT_CONTENT	1991\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Experimental\tagSENT_START	results\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	JESS\tagSENT_CONTENT	-\tagSENT_CONTENT	CM\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	1G\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	have\tagSENT_CONTENT	provided\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	as\tagSENT_CONTENT	regards\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	for\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	large\tagSENT_CONTENT	test\tagSENT_CONTENT	collections\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	PTB\tagSENT_CONTENT	III\tagSENT_CONTENT	,\tagSENT_CONTENT	CoNLL'00\tagSENT_CONTENT	and\tagSENT_CONTENT	'\tagSENT_CONTENT	03\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	
P18-1013	title\tagSECTITLE_END	A\tagSENT_START	Unified\tagSENT_CONTENT	Model\tagSENT_CONTENT	for\tagSENT_CONTENT	Extractive\tagSENT_CONTENT	and\tagSENT_CONTENT	Abstractive\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	Inconsistency\tagSENT_CONTENT	Loss\tagSENT_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	condensing\tagSENT_CONTENT	apiece\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	points\tagSENT_CONTENT	.\tagSENT_END	Jessica\tagSENT_START	Foust\tagSENT_CONTENT	,\tagSENT_CONTENT	director\tagmetric	of\tagSENT_CONTENT	summarization\tagtask	at\tagSENT_CONTENT	McDonald\tagSENT_CONTENT	's\tagSENT_CONTENT	,\tagSENT_CONTENT	said\tagSENT_CONTENT	the\tagSENT_CONTENT	changes\tagSENT_CONTENT	were\tagSENT_CONTENT	made\tagSENT_CONTENT	because\tagSENT_CONTENT	customers\tagSENT_CONTENT	said\tagSENT_CONTENT	they\tagSENT_CONTENT	want\tagSENT_CONTENT	'\tagSENT_CONTENT	simple\tagSENT_CONTENT	,\tagSENT_CONTENT	clean\tagSENT_CONTENT	ingredients\tagSENT_CONTENT	'\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	familiar\tagSENT_CONTENT	with\tagSENT_CONTENT	......\tagSENT_END	Extractive\tagSECTITLE_START	Approach\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	The\tagSECTITLE_CONTENT	company\tagSECTITLE_CONTENT	says\tagSECTITLE_CONTENT	it\tagSECTITLE_CONTENT	expects\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	new\tagSECTITLE_CONTENT	'\tagSECTITLE_CONTENT	Artisan\tagSECTITLE_END	Many\tagSENT_START	earlier\tagSENT_CONTENT	works\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	mostly\tagSENT_CONTENT	benefits\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	by\tagSENT_CONTENT	mitigating\tagSENT_CONTENT	spurious\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	unified\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	inconsistency\tagSENT_CONTENT	loss\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	recent\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	informativity\tagSENT_CONTENT	and\tagSENT_CONTENT	readability\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	studied\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Unified\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	define\tagSENT_CONTENT	the\tagSENT_CONTENT	novel\tagSENT_CONTENT	inconsistency\tagSENT_CONTENT	loss\tagSENT_CONTENT	that\tagSENT_CONTENT	ensures\tagSENT_CONTENT	extractor\tagmetric	and\tagSENT_CONTENT	abstracter\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	mutually\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	in\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	3.2\tagSENT_CONTENT	.\tagSENT_END	Combining\tagSECTITLE_START	Attentions\tagSECTITLE_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	β\tagSENT_CONTENT	n\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	α\tagSENT_CONTENT	t\tagSENT_CONTENT	m\tagSENT_CONTENT	attentions\tagSENT_CONTENT	by\tagSENT_CONTENT	simple\tagSENT_CONTENT	scalar\tagSENT_CONTENT	multiplication\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	an\tagSENT_CONTENT	updated\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	is\tagSENT_CONTENT	our\tagSENT_CONTENT	key\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Inconsistency\tagSECTITLE_START	Loss\tagSECTITLE_END	Extractor\tagSECTITLE_END	When\tagSENT_START	g\tagSENT_CONTENT	n\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	then\tagSENT_CONTENT	th\tagSENT_CONTENT	sentence\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	attended\tagSENT_CONTENT	to\tagSENT_CONTENT	facilitate\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Abstracter\tagSECTITLE_END	The\tagSENT_START	second\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	abstracter\tagSENT_CONTENT	that\tagSENT_CONTENT	reads\tagSENT_CONTENT	the\tagSENT_CONTENT	article\tagSENT_CONTENT	;\tagSENT_CONTENT	then\tagSENT_CONTENT	,\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	:\tagSENT_CONTENT	Decoding\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	abstracter\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	first\tagSENT_CONTENT	define\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	Procedure\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	view\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	β\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	extractor\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Due\tagSENT_START	to\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	to\tagSENT_CONTENT	8\tagSENT_CONTENT	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	smaller\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	0.01\tagSENT_CONTENT	for\tagSENT_CONTENT	stability\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Our\tagmetric	goal\tagmetric	is\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	outputs\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	people\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	and\tagSENT_CONTENT	understand\tagSENT_CONTENT	an\tagSENT_CONTENT	article\tagSENT_CONTENT	faster\tagSENT_CONTENT	.\tagSENT_END	5.3\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summary\tagSENT_CONTENT	than\tagSENT_CONTENT	other\tagSENT_CONTENT	baselines\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Extracted\tagSECTITLE_CONTENT	Sentences\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	ground\tagSENT_CONTENT	-\tagSENT_CONTENT	truth\tagSENT_CONTENT	labels\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	-\tagSENT_CONTENT	bound\tagSENT_CONTENT	performance\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	to\tagSENT_CONTENT	calculate\tagSENT_CONTENT	ROUGE\tagmetric	-\tagmetric	recall\tagmetric	is\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	.\tagSENT_END	Method\tagSECTITLE_END	Results\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Abstractive\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	full\tagmetric	-\tagmetric	length\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagmetric	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	F-1\tagSENT_CONTENT	scores\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Without\tagSECTITLE_START	inconsistency\tagSECTITLE_CONTENT	loss\tagSECTITLE_CONTENT	:\tagSECTITLE_END	It\tagSENT_START	would\tagSENT_CONTENT	n't\tagSENT_CONTENT	bean\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	say\tagSENT_CONTENT	it\tagSENT_CONTENT	looked\tagSENT_CONTENT	half\tagSENT_CONTENT	a\tagSENT_CONTENT	mile\tagSENT_CONTENT	wide\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	would\tagSENT_CONTENT	n't\tagSENT_CONTENT	bean\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	say\tagSENT_CONTENT	it\tagSENT_CONTENT	looked\tagSENT_CONTENT	half\tagSENT_CONTENT	a\tagSENT_CONTENT	mile\tagSENT_CONTENT	wide\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluation\tagSECTITLE_END	We\tagSENT_START	perform\tagSENT_CONTENT	summarization\tagtask	on\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	Mechanical\tagSENT_CONTENT	Turk\tagSENT_CONTENT	(\tagSENT_CONTENT	MTurk\tagSENT_CONTENT	)\tagSENT_CONTENT	2\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	informativity\tagSENT_CONTENT	,\tagSENT_CONTENT	conciseness\tagSENT_CONTENT	and\tagSENT_CONTENT	readability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	the\tagSENT_CONTENT	article\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	4\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	random\tagSENT_CONTENT	summary\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluator\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	the\tagmetric	work\tagmetric	of\tagSENT_CONTENT	Italian\tagSENT_CONTENT	artist\tagSENT_CONTENT	Johannes\tagSENT_CONTENT	Stoetter\tagSENT_CONTENT	.\tagSENT_END	Stoetter\tagmetric	daubed\tagSENT_CONTENT	water\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	body\tagSENT_CONTENT	paint\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	naked\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	the\tagSENT_CONTENT	multicoloured\tagSENT_CONTENT	effect\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	intertwined\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	the\tagSENT_CONTENT	shape\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	chameleon\tagSENT_CONTENT	.\tagSENT_END	Stoetter\tagmetric	can\tagSENT_CONTENT	take\tagSENT_CONTENT	weeks\tagSENT_CONTENT	to\tagSENT_CONTENT	plan\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	his\tagSENT_CONTENT	pieces\tagSENT_CONTENT	and\tagSENT_CONTENT	hours\tagSENT_CONTENT	to\tagSENT_CONTENT	paint\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	are\tagSENT_CONTENT	nature\tagSENT_CONTENT	,\tagSENT_CONTENT	my\tagSENT_CONTENT	personal\tagSENT_CONTENT	life\tagSENT_CONTENT	-\tagSENT_CONTENT	philosophy\tagSENT_CONTENT	,\tagSENT_CONTENT	every\tagSENT_CONTENT	-\tagSENT_CONTENT	day\tagSENT_CONTENT	-\tagSENT_CONTENT	life\tagSENT_CONTENT	and\tagSENT_CONTENT	people\tagSENT_CONTENT	themselves\tagSENT_CONTENT	.\tagSENT_CONTENT	'\tagSENT_END	DeepRL\tagSECTITLE_START	:\tagSECTITLE_END	GAN\tagSECTITLE_START	:\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	the\tagmetric	work\tagmetric	of\tagSENT_CONTENT	Italian\tagSENT_CONTENT	artist\tagSENT_CONTENT	Johannes\tagSENT_CONTENT	Stoetter\tagSENT_CONTENT	.\tagSENT_END	Stoetter\tagmetric	daubed\tagSENT_CONTENT	water\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	body\tagSENT_CONTENT	paint\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	naked\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	the\tagSENT_CONTENT	multicoloured\tagSENT_CONTENT	effect\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	intertwined\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	the\tagSENT_CONTENT	shape\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	chameleon\tagSENT_CONTENT	.\tagSENT_END	Stoetter\tagmetric	daubed\tagSENT_CONTENT	water\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	body\tagSENT_CONTENT	paint\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	naked\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	the\tagSENT_CONTENT	multicoloured\tagSENT_CONTENT	effect\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	intertwined\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	the\tagSENT_CONTENT	shape\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	chameleon\tagSENT_CONTENT	.\tagSENT_CONTENT	:\tagSENT_END	Conclusion\tagSECTITLE_END	By\tagSENT_START	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	recall\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagmetric	while\tagSENT_CONTENT	being\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	informative\tagSENT_CONTENT	and\tagSENT_CONTENT	readable\tagSENT_CONTENT	summarization\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	solid\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	
D12-1042	title\tagSECTITLE_END	Multi\tagSENT_START	-\tagSENT_CONTENT	instance\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	Learning\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	abstract\tagSECTITLE_END	Distant\tagSENT_START	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	RE)-gathering\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	by\tagSENT_CONTENT	aligning\tagSENT_CONTENT	a\tagSENT_CONTENT	database\tagSENT_CONTENT	of\tagSENT_CONTENT	facts\tagSENT_CONTENT	with\tagSENT_CONTENT	text\tagSENT_CONTENT	-\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	efficient\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	scale\tagSENT_CONTENT	RE\tagSENT_CONTENT	to\tagSENT_CONTENT	thousands\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	(\tagSENT_CONTENT	IE\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	extracting\tagSENT_CONTENT	structured\tagSENT_CONTENT	information\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_CONTENT	binary\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	RE\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	subproblem\tagSENT_CONTENT	of\tagSENT_CONTENT	IE\tagSENT_CONTENT	that\tagSENT_CONTENT	addresses\tagSENT_CONTENT	the\tagSENT_CONTENT	extraction\tagSENT_CONTENT	of\tagSENT_CONTENT	labeled\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	graphical\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	called\tagSENT_CONTENT	MIML\tagSENT_CONTENT	-\tagSENT_CONTENT	RE\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	targets\tagSENT_CONTENT	MIML\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Distant\tagSENT_START	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	IE\tagSENT_CONTENT	was\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	binary\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	proteins\tagSENT_CONTENT	and\tagSENT_CONTENT	cells\tagSENT_CONTENT	/\tagSENT_CONTENT	tissues\tagSENT_CONTENT	/\tagSENT_CONTENT	diseases\tagSENT_CONTENT	/\tagSENT_CONTENT	drugs\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Yeast\tagSENT_CONTENT	Protein\tagSENT_CONTENT	Database\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	of\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	.\tagSENT_END	Distant\tagSECTITLE_START	Supervision\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Here\tagSENT_START	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	define\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	takes\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	collection\tagSENT_CONTENT	(\tagSENT_CONTENT	C\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	C\tagSENT_CONTENT	(\tagSENT_CONTENT	E\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	known\tagSENT_CONTENT	relation\tagSENT_CONTENT	labels\tagSENT_CONTENT	(\tagSENT_CONTENT	L\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	extraction\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	outputs\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	)\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	relations\tagSENT_CONTENT	extracted\tagSENT_CONTENT	is\tagSENT_CONTENT	supported\tagSENT_CONTENT	by\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	one\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	C.\tagSENT_CONTENT	To\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	extraction\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	database\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	(\tagSENT_CONTENT	D\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	instantiated\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	once\tagSENT_CONTENT	in\tagSENT_CONTENT	C.\tagSENT_CONTENT	Using\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_END	Model\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	assumes\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	involving\tagSENT_CONTENT	an\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	has\tagSENT_CONTENT	exactly\tagSENT_CONTENT	one\tagSENT_CONTENT	label\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	allows\tagSENT_CONTENT	the\tagSENT_CONTENT	pair\tagSENT_CONTENT	to\tagSENT_CONTENT	exhibit\tagSENT_CONTENT	multiple\tagSENT_CONTENT	labels\tagSENT_CONTENT	across\tagSENT_CONTENT	different\tagSENT_CONTENT	mentions\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	z\tagSENT_CONTENT	classifier\tagSENT_CONTENT	assigns\tagSENT_CONTENT	latent\tagSENT_CONTENT	labels\tagSENT_CONTENT	from\tagSENT_CONTENT	L\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	or\tagSENT_CONTENT	NIL\tagSENT_CONTENT	if\tagSENT_CONTENT	no\tagSENT_CONTENT	relation\tagSENT_CONTENT	is\tagSENT_CONTENT	expressed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	mention\tagSENT_CONTENT	.\tagSENT_END	x\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	z\tagSENT_CONTENT	is\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	that\tagSENT_CONTENT	sentence\tagSENT_CONTENT	;\tagSENT_END	•\tagSENT_START	y\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	classification\tagSENT_CONTENT	decision\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	whether\tagSENT_CONTENT	relationship_extraction\tagtask	holds\tagSENT_CONTENT	;\tagSENT_END	•\tagSENT_START	w\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	weight\tagSENT_CONTENT	vector\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	binary\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	classifier\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	That\tagSENT_START	is\tagSENT_CONTENT	,\tagSENT_CONTENT	entity\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	a\tagSENT_CONTENT	negative\tagSENT_CONTENT	example\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	Training\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	)\tagSENT_CONTENT	step\tagSENT_CONTENT	we\tagSENT_CONTENT	assign\tagSENT_CONTENT	latent\tagSENT_CONTENT	mention\tagSENT_CONTENT	labels\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	mention\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	level\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	it\tagSENT_CONTENT	is\tagSENT_CONTENT	computationally\tagSENT_CONTENT	intractable\tagSENT_CONTENT	to\tagSENT_CONTENT	consider\tagSENT_CONTENT	all\tagSENT_CONTENT	vectors\tagSENT_CONTENT	z\tagSENT_CONTENT	as\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	exponential\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	assignments\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	approximate\tagSENT_CONTENT	and\tagSENT_CONTENT	consider\tagSENT_CONTENT	relationship_extraction\tagtask	separately\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	z\tagSENT_CONTENT	i\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	previously\tagSENT_CONTENT	inferred\tagSENT_CONTENT	mention\tagSENT_CONTENT	labels\tagSENT_CONTENT	for\tagSENT_CONTENT	group\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	component\tagSENT_CONTENT	m\tagSENT_CONTENT	whose\tagSENT_CONTENT	label\tagSENT_CONTENT	is\tagSENT_CONTENT	replaced\tagSENT_CONTENT	by\tagSENT_CONTENT	z\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	obtained\tagSENT_CONTENT	these\tagSENT_CONTENT	weights\tagSENT_CONTENT	using\tagSENT_CONTENT	k\tagSENT_CONTENT	+\tagSENT_CONTENT	1\tagSENT_CONTENT	logistic\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	:\tagSENT_CONTENT	one\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	classifier\tagSENT_CONTENT	for\tagSENT_CONTENT	w\tagSENT_CONTENT	z\tagSENT_CONTENT	and\tagSENT_CONTENT	k\tagSENT_CONTENT	binary\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	label\tagSENT_CONTENT	r\tagSENT_CONTENT	∈\tagSENT_END	Inference\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Initialization\tagSECTITLE_START	:\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	initial\tagSENT_CONTENT	values\tagSENT_CONTENT	are\tagSENT_CONTENT	labels\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	z\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	equation\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	z\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Avoiding\tagSENT_START	overfitting\tagSENT_CONTENT	:\tagSENT_CONTENT	A\tagSENT_CONTENT	na¨ıvena¨ıve\tagSENT_CONTENT	implementation\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	unrealistic\tagSENT_CONTENT	training\tagSENT_CONTENT	scenario\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	z\tagSENT_CONTENT	classifier\tagSENT_CONTENT	generates\tagSENT_CONTENT	predictions\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	equation\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	datums\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	seen\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	At\tagSECTITLE_START	testing\tagSECTITLE_CONTENT	time\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	we\tagSECTITLE_CONTENT	compute\tagSECTITLE_CONTENT	p(z|x\tagSECTITLE_END	We\tagSENT_START	found\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	simple\tagSENT_CONTENT	bagging\tagSENT_CONTENT	model\tagSENT_CONTENT	performs\tagSENT_CONTENT	slightly\tagSENT_CONTENT	better\tagSENT_CONTENT	in\tagSENT_CONTENT	practice\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	couple\tagSENT_CONTENT	of\tagSENT_CONTENT	tenths\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	percent\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	mention\tagSENT_CONTENT	classifier\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	mention\tagSENT_CONTENT	labels\tagSENT_CONTENT	generated\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	z\tagSENT_CONTENT	i\tagSENT_CONTENT	changes\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	progresses\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	may\tagSENT_CONTENT	impact\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	that\tagSENT_CONTENT	group\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	Data\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	was\tagSENT_CONTENT	developed\tagSENT_CONTENT	by\tagSENT_CONTENT	by\tagSENT_CONTENT	aligning\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	New\tagSENT_CONTENT	York\tagSENT_CONTENT	Times\tagSENT_CONTENT	(\tagSENT_CONTENT	NYT\tagSENT_CONTENT	)\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	generated\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	organizers\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	infoboxes\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	2008\tagSENT_CONTENT	snapshot\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	KBP\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	requires\tagSENT_CONTENT	the\tagSENT_CONTENT	extraction\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	relations\tagSENT_CONTENT	r(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	query\tagSENT_CONTENT	that\tagSENT_CONTENT	contains\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	entity\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	subsampled\tagSENT_START	them\tagSENT_CONTENT	randomly\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	retention\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	10\tagmetric	%\tagmetric	.\tagSENT_END	Features\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	requires\tagSENT_CONTENT	two\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	:\tagSENT_CONTENT	one\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	mention\tagSENT_CONTENT	classifier\tagSENT_CONTENT	(\tagSENT_CONTENT	z\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	one\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Baselines\tagSECTITLE_END	we\tagSENT_START	model\tagSENT_CONTENT	relationship_extraction\tagtask	mention\tagSENT_CONTENT	independently\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	Mintz\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	collapsed\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	mentions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	entity\tagSENT_CONTENT	tuple\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	datum\tagSENT_CONTENT	;\tagSENT_CONTENT	(\tagSENT_CONTENT	b\tagSENT_CONTENT	)\tagSENT_CONTENT	we\tagSENT_CONTENT	allow\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	outputs\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	entity\tagSENT_CONTENT	tuple\tagSENT_CONTENT	at\tagSENT_CONTENT	prediction\tagSENT_CONTENT	time\tagSENT_CONTENT	by\tagSENT_CONTENT	OR\tagSENT_CONTENT	-\tagSENT_CONTENT	ing\tagSENT_CONTENT	the\tagSENT_CONTENT	predictions\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	individual\tagSENT_CONTENT	relation\tagSENT_CONTENT	mentions\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	tuple\tagSENT_CONTENT	(\tagSENT_CONTENT	similarly\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	Hoffmann\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_END	This\tagSENT_START	models\tagSENT_CONTENT	RE\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	MIML\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	learns\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	Perceptron\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	and\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	"\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	one\tagSENT_CONTENT	"\tagSENT_CONTENT	decision\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	KBP\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	KBP\tagSENT_CONTENT	scorer\tagSENT_CONTENT	,\tagSENT_CONTENT	10\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	changes\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_CONTENT	we\tagSENT_CONTENT	score\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	parameter\tagSENT_CONTENT	anydoc\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	true\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	configures\tagSENT_CONTENT	the\tagSENT_CONTENT	scorer\tagSENT_CONTENT	to\tagSENT_CONTENT	accept\tagSENT_CONTENT	relationship_extraction\tagtask	as\tagSENT_CONTENT	correct\tagSENT_CONTENT	regardless\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	supporting\tagSENT_CONTENT	document\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	b\tagSENT_CONTENT	)\tagSENT_CONTENT	we\tagSENT_CONTENT	score\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	gold\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	one\tagSENT_CONTENT	mention\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	ranking\tagSENT_CONTENT	score\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	include\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	equation\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	MIML\tagSENT_CONTENT	-\tagSENT_CONTENT	RE\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	indeed\tagSENT_CONTENT	,\tagSENT_CONTENT	MIML\tagSENT_CONTENT	-\tagSENT_CONTENT	RE\tagSENT_CONTENT	successfully\tagSENT_CONTENT	eliminates\tagSENT_CONTENT	undesired\tagSENT_CONTENT	labels\tagSENT_CONTENT	when\tagSENT_CONTENT	two\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	)\tagSENT_CONTENT	incompatible\tagSENT_CONTENT	labels\tagSENT_CONTENT	are\tagSENT_CONTENT	jointly\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	tuple\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	modeled\tagSENT_CONTENT	typically\tagSENT_CONTENT	has\tagSENT_CONTENT	multiple\tagSENT_CONTENT	instances\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	may\tagSENT_CONTENT	have\tagSENT_CONTENT	multiple\tagSENT_CONTENT	labels\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	database\tagSENT_CONTENT	.\tagSENT_END	
E17-1051	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	further\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	test\tagSENT_CONTENT	-\tagSENT_CONTENT	suite\tagSENT_CONTENT	that\tagSENT_CONTENT	assesses\tagSENT_CONTENT	specific\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	tasks\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	helpful\tagSENT_CONTENT	in\tagSENT_CONTENT	comparing\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	competitive\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	LDC2015E86\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	outper\tagSENT_CONTENT	-\tagSENT_CONTENT	forms\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	parsers\tagSENT_CONTENT	for\tagSENT_CONTENT	recovering\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	handling\tagSENT_CONTENT	polarity\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	amr_parsing\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	canonicalizing\tagSENT_CONTENT	language\tagSENT_CONTENT	and\tagSENT_CONTENT	representing\tagSENT_CONTENT	its\tagSENT_CONTENT	meaning\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	a\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	that\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	line\tagSENT_CONTENT	of\tagSENT_CONTENT	research\tagmetric	is\tagSENT_CONTENT	new\tagSENT_CONTENT	and\tagSENT_CONTENT	current\tagSENT_CONTENT	results\tagSENT_CONTENT	suggest\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	room\tagSENT_CONTENT	for\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	Greedy\tagSENT_START	transitionbased\tagSENT_CONTENT	methods\tagSENT_CONTENT	are\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	popular\tagSENT_CONTENT	choices\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	good\tagSENT_CONTENT	balance\tagSENT_CONTENT	between\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	scanned\tagSENT_CONTENT	left\tagSENT_CONTENT	to\tagSENT_CONTENT	right\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	linear\tagSENT_CONTENT	time\tagSENT_CONTENT	complexity\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	amr_parsing\tagtask	for\tagSENT_CONTENT	AMR\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	ARCEAGER\tagSENT_CONTENT	dependency\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	of\tagSENT_CONTENT	Nivre\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	brings\tagSENT_CONTENT	closer\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	by\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	some\tagSENT_CONTENT	mod\tagSENT_CONTENT	-\tagSENT_CONTENT	ifications\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	AMR\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	of\tagSENT_CONTENT	,\tagSENT_CONTENT	called\tagSENT_CONTENT	CAMR\tagSENT_CONTENT	,\tagSENT_CONTENT	also\tagSENT_CONTENT	defines\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	More\tagSENT_START	recently\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	greedy\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	ARC\tagSENT_CONTENT	-\tagSENT_CONTENT	STANDARD\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	also\tagSENT_CONTENT	address\tagSENT_CONTENT	amr_parsing\tagtask	by\tagSENT_CONTENT	means\tagSENT_CONTENT	of\tagSENT_CONTENT	transition\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	such\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	transition\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	traditional\tagSENT_CONTENT	transition\tagSENT_CONTENT	systems\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	In\tagSENT_START	§\tagSENT_CONTENT	3\tagSENT_CONTENT	we\tagSENT_CONTENT	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	,\tagSENT_CONTENT	linear\tagSENT_CONTENT	-\tagSENT_CONTENT	time\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	ARCEAGER\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency\tagSENT_CONTENT	tree\tagSENT_CONTENT	parsing\tagSENT_CONTENT	;\tagSENT_END	In\tagSENT_START	§\tagSENT_CONTENT	5\tagSENT_CONTENT	we\tagSENT_CONTENT	claim\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	is\tagSENT_CONTENT	not\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	metrics\tagSENT_CONTENT	to\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	and\tagSENT_CONTENT	better\tagSENT_CONTENT	compare\tagSENT_CONTENT	alternative\tagSENT_CONTENT	parsers\tagSENT_CONTENT	;\tagSENT_END	Background\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Notation\tagSECTITLE_END	both\tagSENT_START	in\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Transition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	AMR\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	Similarly\tagSENT_START	to\tagSENT_CONTENT	dependency\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	partially\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	predicateargument\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	Because\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	of\tagSENT_CONTENT	AMR\tagSENT_CONTENT	structures\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency\tagSENT_CONTENT	structures\tagSENT_CONTENT	,\tagSENT_CONTENT	transition\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	helpful\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	three\tagSENT_CONTENT	key\tagSENT_CONTENT	differences\tagSENT_CONTENT	between\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	trees\tagSENT_CONTENT	that\tagSENT_CONTENT	require\tagSENT_CONTENT	further\tagSENT_CONTENT	adjustments\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsers\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	inline\tagSENT_CONTENT	with\tagSENT_CONTENT	current\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	projectivity\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	generalized\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	projective\tagSENT_CONTENT	edges\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	§\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	Another\tagSENT_START	main\tagSENT_CONTENT	difference\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	AMR\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	mapping\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	anode\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	:\tagSENT_END	teach-01\tagSENT_START	and\tagSENT_CONTENT	person\tagSENT_CONTENT	,\tagSENT_CONTENT	connected\tagSENT_CONTENT	through\tagSENT_CONTENT	an\tagSENT_CONTENT	:\tagSENT_CONTENT	ARG0\tagSENT_CONTENT	edge\tagSENT_CONTENT	,\tagSENT_CONTENT	expressing\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagmetric	teacher\tagmetric	is\tagSENT_CONTENT	amr_parsing\tagtask	who\tagSENT_CONTENT	teaches\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	obtain\tagSENT_CONTENT	alignments\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	nodes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graph\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	run\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Transition\tagSECTITLE_START	system\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	AMR\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	A\tagSENT_START	configuration\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	triple\tagSENT_CONTENT	(\tagSENT_CONTENT	σ\tagSENT_CONTENT	,\tagSENT_CONTENT	β\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	A\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	AMR\tagSENT_CONTENT	edges\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	constructed\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagSENT_CONTENT	point\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	transition\tagSENT_CONTENT	actions\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	we\tagSENT_CONTENT	need\tagSENT_CONTENT	some\tagSENT_CONTENT	additional\tagSENT_CONTENT	notation\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	push\tagSENT_CONTENT	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	the\tagSENT_CONTENT	node\tagSENT_CONTENT	root(a(β\tagSENT_CONTENT	0\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	With\tagSENT_START	this\tagSENT_CONTENT	operation\tagSENT_CONTENT	the\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	projective\tagSENT_CONTENT	patterns\tagSENT_CONTENT	,\tagSENT_CONTENT	8\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	definition\tagSENT_CONTENT	given\tagSENT_CONTENT	in\tagSENT_CONTENT	§\tagSENT_CONTENT	2.1\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	formed\tagSENT_CONTENT	by\tagSENT_CONTENT	arcs\tagSENT_CONTENT	between\tagSENT_CONTENT	nodes\tagSENT_CONTENT	that\tagSENT_CONTENT	share\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	now\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	greedy\tagSENT_CONTENT	transitionbased\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	linear\tagSENT_CONTENT	-\tagSENT_CONTENT	time\tagSENT_CONTENT	inn\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_END	Since\tagSENT_START	each\tagSENT_CONTENT	transition\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	carried\tagSENT_CONTENT	out\tagSENT_CONTENT	inconstant\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conclude\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	runs\tagSENT_CONTENT	in\tagSENT_CONTENT	linear\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	System\tagSECTITLE_END	Oracle\tagSECTITLE_END	Informally\tagSENT_START	,\tagSENT_CONTENT	static\tagSENT_CONTENT	means\tagSENT_CONTENT	that\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	actual\tagSENT_CONTENT	configuration\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	has\tagSENT_CONTENT	no\tagSENT_CONTENT	mistakes\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	provides\tagSENT_CONTENT	amr_parsing\tagtask	that\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	introduce\tagSENT_CONTENT	any\tagSENT_CONTENT	mistake\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	the\tagSENT_CONTENT	current\tagSENT_CONTENT	configuration\tagSENT_CONTENT	(\tagSENT_CONTENT	σ\tagSENT_CONTENT	,\tagSENT_CONTENT	β\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	goldstandard\tagSENT_CONTENT	graph\tagSENT_CONTENT	G\tagSENT_CONTENT	=\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	test\tagSENT_CONTENT	the\tagSENT_CONTENT	conditions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	order\tagSENT_CONTENT	and\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	action\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagmetric	first\tagmetric	match\tagmetric	:\tagSENT_END	Transition\tagSECTITLE_START	Classifier\tagSECTITLE_END	Like\tagSENT_START	all\tagSENT_CONTENT	other\tagSENT_CONTENT	transition\tagSENT_CONTENT	systems\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	kind\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	controller\tagSENT_CONTENT	"\tagSENT_CONTENT	that\tagSENT_CONTENT	predicts\tagSENT_CONTENT	amr_parsing\tagtask	given\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	configuration\tagSENT_CONTENT	(\tagSENT_CONTENT	among\tagSENT_CONTENT	Shift\tagSENT_CONTENT	,\tagSENT_CONTENT	LArc\tagSENT_CONTENT	,\tagSENT_CONTENT	RArc\tagSENT_CONTENT	and\tagSENT_CONTENT	Reduce\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	a\tagSENT_CONTENT	classifier\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	200\tagSENT_CONTENT	tanh\tagSENT_CONTENT	units\tagSENT_CONTENT	and\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	0.1\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Concept\tagSECTITLE_START	Identification\tagSECTITLE_END	This\tagSENT_START	component\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	learned\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	manner\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	were\tagSENT_CONTENT	notable\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	works\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	Shift\tagSENT_CONTENT	decided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	store\tagSENT_CONTENT	the\tagSENT_CONTENT	pair\tagSENT_CONTENT	(\tagSENT_CONTENT	β\tagSENT_CONTENT	0\tagSENT_CONTENT	,\tagSENT_END	Edge\tagSECTITLE_START	Labeling\tagSECTITLE_END	The\tagSENT_START	function\tagSENT_CONTENT	p\tagSENT_CONTENT	gives\tagSENT_CONTENT	the\tagSENT_CONTENT	leftmost\tagSENT_CONTENT	(\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	alignment\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	element\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	function\tagSENT_CONTENT	c\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	function\tagSENT_CONTENT	maps\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	symbols\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	label\tagSENT_CONTENT	embedding\tagSENT_CONTENT	,\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	edge\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	lack\tagSENT_CONTENT	of\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	tree\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	words\tagSENT_CONTENT	these\tagSENT_CONTENT	symbols\tagSENT_CONTENT	are\tagSENT_CONTENT	mapped\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	Fine\tagSECTITLE_START	-\tagSECTITLE_CONTENT	grained\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	Until\tagSENT_START	now\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	were\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	.\tagSENT_END	Given\tagSENT_START	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	graphs\tagSENT_CONTENT	and\tagSENT_CONTENT	Since\tagSENT_CONTENT	Smatch\tagmetric	is\tagSENT_CONTENT	an\tagSENT_CONTENT	approximate\tagSENT_CONTENT	randomized\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	,\tagSENT_CONTENT	decimal\tagSENT_CONTENT	points\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	vary\tagSENT_CONTENT	between\tagSENT_CONTENT	different\tagSENT_CONTENT	runs\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	reported\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	approach\tagSENT_CONTENT	was\tagSENT_CONTENT	also\tagSENT_CONTENT	taken\tagSENT_CONTENT	by\tagSENT_CONTENT	 \tagSENT_CONTENT	feature\tagSENT_CONTENT	template\tagSENT_CONTENT	depth\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	graphs\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	At\tagSENT_START	the\tagSENT_CONTENT	top\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	Parse\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	notable\tagSENT_CONTENT	to\tagSENT_CONTENT	deal\tagSENT_CONTENT	with\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	the\tagSENT_CONTENT	bottom\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	Parse\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_END	The\tagmetric	Smatch\tagmetric	scores\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	parses\tagSENT_CONTENT	are\tagSENT_CONTENT	56\tagSENT_CONTENT	and\tagSENT_CONTENT	78\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Unlabeled\tagSENT_START	is\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	computed\tagSENT_CONTENT	on\tagSENT_CONTENT	(\tagSENT_CONTENT	2015b\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	others\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	compute\tagSENT_CONTENT	this\tagSENT_CONTENT	score\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	simply\tagSENT_CONTENT	strip\tagSENT_CONTENT	off\tagSENT_CONTENT	the\tagSENT_CONTENT	suffixes\tagSENT_CONTENT	from\tagSENT_CONTENT	all\tagSENT_CONTENT	Propbank\tagSENT_CONTENT	frames\tagSENT_CONTENT	and\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	parsers\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	on\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrases\tagSENT_CONTENT	only\tagSENT_CONTENT	(\tagSENT_CONTENT	NP\tagSENT_CONTENT	-\tagSENT_CONTENT	only\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	extracting\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	dataset\tagSENT_CONTENT	all\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrases\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	include\tagSENT_CONTENT	further\tagSENT_CONTENT	NPs\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	previously\tagSENT_CONTENT	discussed\tagSENT_CONTENT	,\tagSENT_CONTENT	reentrancy\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	important\tagSENT_CONTENT	characteristic\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	trivial\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	therefore\tagSENT_CONTENT	implement\tagSENT_CONTENT	a\tagSENT_CONTENT	test\tagSENT_CONTENT	for\tagSENT_CONTENT	it\tagSENT_CONTENT	(\tagSENT_CONTENT	Reentrancy\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	only\tagSENT_CONTENT	on\tagSENT_CONTENT	reentrant\tagSENT_CONTENT	edges\tagSENT_CONTENT	.\tagSENT_END	Concept\tagSENT_START	identification\tagSENT_CONTENT	is\tagSENT_CONTENT	another\tagSENT_CONTENT	critical\tagSENT_CONTENT	component\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	we\tagSENT_CONTENT	therefore\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	predicted\tagSENT_CONTENT	concepts\tagSENT_CONTENT	(\tagSENT_CONTENT	Concepts\tagSENT_CONTENT	)\tagSENT_CONTENT	too\tagSENT_CONTENT	.\tagSENT_END	Metric\tagSECTITLE_END	The\tagSENT_START	reason\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	Smatch\tagmetric	for\tagSENT_CONTENT	these\tagSENT_CONTENT	metrics\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	no\tagSENT_CONTENT	variable\tagSENT_CONTENT	names\tagSENT_CONTENT	involved\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagmetric	Smatch\tagmetric	score\tagmetric	on\tagSENT_CONTENT	:\tagSENT_CONTENT	ARG\tagSENT_CONTENT	edges\tagSENT_CONTENT	only\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeling\tagSENT_CONTENT	(\tagSENT_CONTENT	SRL\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	another\tagSENT_CONTENT	extremely\tagSENT_CONTENT	important\tagSENT_CONTENT	subtask\tagSENT_CONTENT	of\tagSENT_CONTENT	AMR\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	this\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	suite\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	metrics\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	us\tagSENT_CONTENT	find\tagSENT_CONTENT	strengths\tagSENT_CONTENT	and\tagSENT_CONTENT	weakness\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	speeding\tagSENT_CONTENT	up\tagSENT_CONTENT	the\tagSENT_CONTENT	research\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	area\tagSENT_CONTENT	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	additional\tagSENT_CONTENT	observations\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	2\tagSENT_CONTENT	is\tagSENT_CONTENT	optimal\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	score\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	Parse\tagSENT_CONTENT	1\tagSENT_CONTENT	recovers\tagSENT_CONTENT	more\tagSENT_CONTENT	reentrancies\tagSENT_CONTENT	.\tagSENT_END	labeled\tagSENT_START	case\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	has\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	in\tagSENT_CONTENT	labeling\tagSENT_CONTENT	the\tagSENT_CONTENT	arcs\tagSENT_CONTENT	.\tagSENT_END	State\tagSENT_START	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	choosing\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	frequent\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	token\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	table\tagSENT_CONTENT	constructed\tagSENT_CONTENT	from\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Advantages\tagSENT_START	of\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	the\tagSENT_CONTENT	worst\tagSENT_CONTENT	-\tagSENT_CONTENT	case\tagSENT_CONTENT	linear\tagSENT_CONTENT	complexity\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	both\tagSENT_CONTENT	helpful\tagSENT_CONTENT	for\tagSENT_CONTENT	realtime\tagSENT_CONTENT	applications\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	how\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	English\tagSENT_CONTENT	sentences\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	built\tagSENT_CONTENT	incrementally\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	that\tagSENT_CONTENT	builds\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	linear\tagSENT_CONTENT	time\tagSENT_CONTENT	by\tagSENT_CONTENT	processing\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	parser\tagSENT_CONTENT	demonstrates\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	amr_parsing\tagtask	using\tagSENT_CONTENT	techniques\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	techniques\tagSENT_CONTENT	from\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	noted\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	informative\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	parsing\tagSENT_CONTENT	process\tagSENT_CONTENT	with\tagSENT_CONTENT	Smatch\tagmetric	than\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	metrics\tagSENT_CONTENT	aimed\tagSENT_CONTENT	at\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	the\tagSENT_CONTENT	various\tagSENT_CONTENT	subproblems\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Although\tagSENT_START	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	outperform\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	baseline\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	Smatch\tagmetric	score\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	on\tagSENT_CONTENT	par\tagSENT_CONTENT	or\tagSENT_CONTENT	better\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	several\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	metrics\tagSENT_CONTENT	proposed\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	hope\tagSENT_CONTENT	that\tagSENT_CONTENT	moving\tagSENT_CONTENT	away\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	metric\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	will\tagSENT_CONTENT	further\tagSENT_CONTENT	speedup\tagSENT_CONTENT	progress\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	544\tagSECTITLE_END	
S18-1116	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	system\tagSENT_CONTENT	exploits\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	taxonomy_learning\tagtask	and\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	pattern\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	discovery\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Pattern\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Hypernym\tagSECTITLE_CONTENT	Discovery\tagSECTITLE_END	Learning\tagSECTITLE_START	Projections\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Hypernym\tagSECTITLE_CONTENT	Discovery\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	projections\tagSENT_CONTENT	for\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	discovery\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	differs\tagSENT_CONTENT	from\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	ways\tagSENT_CONTENT	:\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	performs\tagSENT_CONTENT	taxonomy_learning\tagtask	of\tagSENT_CONTENT	query\tagSENT_CONTENT	-\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	pairs\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	a\tagSENT_CONTENT	hard\tagSENT_CONTENT	clustering\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	modified\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	ways\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Model\tagSECTITLE_END	The\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	Algorithm\tagSECTITLE_END	The\tagSECTITLE_START	Word\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_END	Data\tagSECTITLE_START	Augmentation\tagSECTITLE_END	Hybrid\tagSECTITLE_START	Hypernym\tagSECTITLE_CONTENT	Discovery\tagSECTITLE_END	Our\tagSENT_START	hybrid\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	discovery\tagSENT_CONTENT	combines\tagSENT_CONTENT	taxonomy_learning\tagtask	and\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	pattern\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	discovery\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	This\tagSENT_START	table\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	average\tagSENT_CONTENT	precision\tagSENT_CONTENT	(\tagSENT_CONTENT	MAP\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	mean\tagSENT_CONTENT	reciprocal\tagSENT_CONTENT	rank\tagSENT_CONTENT	(\tagSENT_CONTENT	MRR\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	precision\tagSENT_CONTENT	at\tagSENT_CONTENT	rank\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	P@1\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	and\tagSENT_CONTENT	those\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	2\tagSENT_CONTENT	strongest\tagSENT_CONTENT	baselines\tagSENT_CONTENT	which\tagSENT_CONTENT	were\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	organizers\tagSENT_CONTENT	.\tagSENT_END	also\tagSENT_START	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	scores\tagSENT_CONTENT	we\tagSENT_CONTENT	would\tagSENT_CONTENT	have\tagSENT_CONTENT	obtained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	had\tagSENT_CONTENT	used\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	(\tagSENT_CONTENT	pattern\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	supervised\tagSENT_CONTENT	taxonomy_learning\tagtask	)\tagSENT_END	Ablation\tagSECTITLE_START	Tests\tagSECTITLE_END	No\tagSENT_START	MTL\tagSENT_CONTENT	:\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	taxonomy_learning\tagtask	(\tagSENT_CONTENT	MTL\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	classifier\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	concepts\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	2\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	techniques\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	subsampling\tagSENT_CONTENT	and\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	actually\tagSENT_CONTENT	harmed\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	's\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	1A\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	trial\tagSENT_CONTENT	set\tagSENT_CONTENT	suggested\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	.\tagSENT_END	MAP\tagSECTITLE_START	MRR\tagSECTITLE_CONTENT	P@1\tagSECTITLE_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	Concluding\tagSECTITLE_START	Remarks\tagSECTITLE_END	
P16-1223	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	approach\tagSENT_CONTENT	this\tagSENT_CONTENT	from\tagSENT_CONTENT	one\tagSENT_CONTENT	side\tagSENT_CONTENT	by\tagSENT_CONTENT	doing\tagSENT_CONTENT	a\tagSENT_CONTENT	careful\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	problems\tagSENT_CONTENT	and\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	by\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	simple\tagSENT_CONTENT	,\tagSENT_CONTENT	carefully\tagSENT_CONTENT	designed\tagSENT_CONTENT	systems\tagSENT_CONTENT	can\tagSENT_CONTENT	obtain\tagSENT_CONTENT	accuracies\tagmetric	of\tagSENT_CONTENT	72.4\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	75.8\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	two\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	exceeding\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	by\tagSENT_CONTENT	over\tagSENT_CONTENT	5\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	approaching\tagSENT_CONTENT	what\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	ceiling\tagSENT_CONTENT	for\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	task.1\tagSENT_END	Introduction\tagSECTITLE_END	Human\tagSENT_START	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	tested\tagSENT_CONTENT	by\tagSENT_CONTENT	asking\tagSENT_CONTENT	question_answering\tagtask	that\tagSENT_CONTENT	require\tagSENT_CONTENT	interpretive\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	approach\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	suggested\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	computers\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	several\tagSENT_CONTENT	strands\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	which\tagSENT_CONTENT	attempt\tagSENT_CONTENT	to\tagSENT_CONTENT	collect\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	-in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	triples\tagSENT_CONTENT	-and\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	directly\tagSENT_CONTENT	from\tagSENT_CONTENT	it\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	researchers\tagSENT_CONTENT	at\tagSENT_CONTENT	DeepMind\tagSENT_CONTENT	(\tagSENT_CONTENT	had\tagSENT_CONTENT	the\tagSENT_CONTENT	appealing\tagSENT_CONTENT	,\tagSENT_CONTENT	original\tagSENT_CONTENT	idea\tagSENT_CONTENT	of\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	abundant\tagSENT_CONTENT	news\tagSENT_CONTENT	articles\tagSENT_CONTENT	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	are\tagSENT_CONTENT	accompanied\tagSENT_CONTENT	by\tagSENT_CONTENT	bullet\tagSENT_CONTENT	point\tagSENT_CONTENT	summaries\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	heuristically\tagSENT_CONTENT	create\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	supervised\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	simple\tagSENT_CONTENT	,\tagSENT_CONTENT	carefully\tagSENT_CONTENT	designed\tagSENT_CONTENT	systems\tagSENT_CONTENT	can\tagSENT_CONTENT	obtain\tagSENT_CONTENT	high\tagSENT_CONTENT	,\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	of\tagSENT_CONTENT	72.4\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	75.8\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	respectively\tagSENT_CONTENT	.\tagSENT_END	this\tagSENT_START	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	easier\tagSENT_CONTENT	than\tagSENT_CONTENT	previously\tagSENT_CONTENT	realized\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	,\tagSENT_CONTENT	conventional\tagSENT_CONTENT	NLP\tagSENT_CONTENT	systems\tagSENT_CONTENT	can\tagSENT_CONTENT	do\tagSENT_CONTENT	much\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	it\tagSENT_CONTENT	than\tagSENT_CONTENT	previously\tagSENT_CONTENT	suggested\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	iii\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	distributed\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	very\tagSENT_CONTENT	effective\tagSENT_CONTENT	at\tagSENT_CONTENT	recognizing\tagSENT_CONTENT	paraphrases\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	iv\tagSENT_CONTENT	)\tagSENT_CONTENT	partly\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	current\tagSENT_CONTENT	systems\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	relation\tagSENT_CONTENT	extraction\tagSENT_CONTENT	systems\tagSENT_CONTENT	than\tagSENT_CONTENT	larger\tagSENT_CONTENT	-\tagSENT_CONTENT	discoursecontext\tagSENT_CONTENT	text\tagSENT_CONTENT	understanding\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	v\tagSENT_CONTENT	)\tagSENT_END	Passage\tagSECTITLE_END	The\tagSECTITLE_START	Reading\tagSECTITLE_CONTENT	Comprehension\tagSECTITLE_CONTENT	Task\tagSECTITLE_END	The\tagSENT_START	RC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	an\tagSENT_CONTENT	example4\tagSENT_CONTENT	:\tagSENT_CONTENT	it\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	p\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	q\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	a\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	news\tagSENT_CONTENT	article\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	article\tagSENT_CONTENT	's\tagSENT_CONTENT	bullet\tagSENT_CONTENT	points\tagSENT_CONTENT	has\tagSENT_CONTENT	had\tagSENT_CONTENT	one\tagSENT_CONTENT	entity\tagSENT_CONTENT	replaced\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	placeholder\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	is\tagSENT_CONTENT	this\tagSENT_CONTENT	questioned\tagSENT_CONTENT	entity\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	coreference\tagSENT_CONTENT	chain\tagSENT_CONTENT	containing\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	one\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	all\tagSENT_CONTENT	items\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	chain\tagSENT_CONTENT	are\tagSENT_CONTENT	replaced\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	@entityn\tagSENT_CONTENT	marker\tagSENT_CONTENT	,\tagSENT_CONTENT	fora\tagSENT_CONTENT	distinct\tagSENT_CONTENT	index\tagSENT_CONTENT	n.\tagSENT_CONTENT	argue\tagSENT_CONTENT	convincingly\tagSENT_CONTENT	that\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	strategy\tagSENT_CONTENT	is\tagSENT_CONTENT	necessary\tagSENT_CONTENT	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	that\tagSENT_CONTENT	systems\tagSENT_CONTENT	approach\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	by\tagSENT_CONTENT	understanding\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	in\tagSENT_CONTENT	front\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	,\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	world\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	without\tagSENT_CONTENT	needing\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	there\tagSENT_CONTENT	are\tagSENT_CONTENT	380k\tagSENT_CONTENT	and\tagSENT_CONTENT	879k\tagSENT_CONTENT	training\tagSENT_CONTENT	examples\tagSENT_CONTENT	for\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	respectively\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	passages\tagSENT_CONTENT	are\tagSENT_CONTENT	around\tagSENT_CONTENT	30\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	800\tagSENT_CONTENT	tokens\tagSENT_CONTENT	on\tagSENT_CONTENT	average\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	question_answering\tagtask	contains\tagSENT_CONTENT	around\tagSENT_CONTENT	12\tagSENT_CONTENT	-\tagSENT_CONTENT	14\tagSENT_CONTENT	tokens\tagSENT_CONTENT	.\tagSENT_END	CNN\tagSECTITLE_START	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_END	Our\tagSECTITLE_START	Systems\tagSECTITLE_END	Its\tagSENT_START	success\tagSENT_CONTENT	again\tagSENT_CONTENT	raises\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	true\tagSENT_CONTENT	nature\tagSENT_CONTENT	and\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	RC\tagSENT_CONTENT	task\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	seek\tagSENT_CONTENT	to\tagSENT_CONTENT	clarify\tagSENT_CONTENT	by\tagSENT_CONTENT	building\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	net\tagSENT_CONTENT	classifier\tagSENT_CONTENT	.\tagSENT_END	Entity\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Centric\tagSECTITLE_CONTENT	Classifier\tagSECTITLE_END	Whether\tagSENT_START	entity\tagSENT_CONTENT	e\tagSENT_CONTENT	occurs\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Sentence\tagSENT_START	co\tagSENT_CONTENT	-\tagSENT_CONTENT	occurrence\tagSENT_CONTENT	:\tagSENT_CONTENT	whether\tagSENT_CONTENT	entity\tagSENT_CONTENT	e\tagSENT_CONTENT	cooccurs\tagSENT_CONTENT	with\tagSENT_CONTENT	another\tagSENT_CONTENT	entity\tagSENT_CONTENT	or\tagSENT_CONTENT	verb\tagSENT_CONTENT	that\tagSENT_CONTENT	appears\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	in\tagSENT_CONTENT	some\tagSENT_CONTENT	sentence\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	End\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	end\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Passage\tagSECTITLE_END	h.\tagSENT_START	Meanwhile\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	another\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	question_answering\tagtask	q\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	l\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	embedding\tagSENT_CONTENT	q\tagSENT_CONTENT	∈\tagSENT_CONTENT	Rh\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSENT_START	:\tagSENT_CONTENT	In\tagSENT_CONTENT	this\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	pieces\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	the\tagSENT_CONTENT	output\tagSENT_CONTENT	vector\tagSENT_CONTENT	o\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	outputs\tagSENT_CONTENT	question_answering\tagtask	using\tagSENT_CONTENT	:\tagSENT_END	In\tagSENT_START	contrast\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	combined\tagSENT_CONTENT	o\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	embedding\tagSENT_CONTENT	q\tagSENT_CONTENT	via\tagSENT_CONTENT	another\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	layer\tagSENT_CONTENT	before\tagSENT_CONTENT	making\tagSENT_CONTENT	final\tagSENT_CONTENT	predictions\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	5-word\tagSENT_CONTENT	window\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	the\tagSENT_CONTENT	placeholder\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	way\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	other\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	ignored\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Training\tagSECTITLE_START	Details\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	's\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parser\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	parse\tagSENT_CONTENT	all\tagSENT_CONTENT	our\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	text\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	other\tagSENT_CONTENT	features\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	extracted\tagSENT_CONTENT	without\tagSENT_CONTENT	additional\tagSENT_CONTENT	tools\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	h\tagSENT_CONTENT	=\tagSENT_CONTENT	128\tagSENT_CONTENT	for\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	256\tagSENT_CONTENT	for\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	.\tagSENT_END	All\tagSENT_START	of\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	run\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	GPU\tagSENT_CONTENT	(\tagSENT_CONTENT	GeForce\tagSENT_CONTENT	GTX\tagSENT_CONTENT	TITAN\tagSENT_CONTENT	X\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	roughly\tagSENT_CONTENT	a\tagSENT_CONTENT	runtime\tagSENT_CONTENT	of\tagSENT_CONTENT	6\tagSENT_CONTENT	hours\tagSENT_CONTENT	per\tagSENT_CONTENT	epoch\tagSENT_CONTENT	for\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	15\tagSENT_CONTENT	hours\tagSENT_CONTENT	per\tagSENT_CONTENT	epoch\tagSENT_CONTENT	for\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	.\tagSENT_END	The\tagSENT_START	conventional\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	classifier\tagSENT_CONTENT	obtains\tagSENT_CONTENT	67.9\tagmetric	%\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Main\tagSECTITLE_START	Results\tagSECTITLE_END	The\tagSENT_START	numbers\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	after\tagSENT_CONTENT	we\tagSENT_CONTENT	exclude\tagSENT_CONTENT	each\tagSENT_CONTENT	feature\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	a\tagSENT_CONTENT	low\tagSENT_CONTENT	number\tagSENT_CONTENT	indicates\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	feature\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Analysis\tagSECTITLE_END	dataset\tagSENT_START	was\tagSENT_CONTENT	created\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	automatic\tagSENT_CONTENT	and\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	how\tagSENT_CONTENT	many\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	trivial\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	how\tagSENT_CONTENT	many\tagSENT_CONTENT	are\tagSENT_CONTENT	noisy\tagSENT_CONTENT	and\tagSENT_CONTENT	not\tagSENT_CONTENT	answerable\tagSENT_CONTENT	?\tagSENT_END	Breakdown\tagSECTITLE_START	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Examples\tagSECTITLE_END	The\tagSENT_START	nearest\tagSENT_CONTENT	words\tagSENT_CONTENT	around\tagSENT_CONTENT	the\tagSENT_CONTENT	placeholder\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	an\tagSENT_CONTENT	entity\tagSENT_CONTENT	marker\tagSENT_CONTENT	;\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	evident\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSENT_START	-\tagSENT_CONTENT	level\tagSENT_CONTENT	paraphrasing\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	entailed\tagSENT_CONTENT	/\tagSENT_END	In\tagSENT_START	many\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	though\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	complete\tagSENT_CONTENT	semantic\tagSENT_CONTENT	match\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	some\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	still\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	through\tagSENT_CONTENT	partial\tagSENT_CONTENT	clues\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	some\tagSENT_CONTENT	word\tagSENT_CONTENT	/\tagSENT_CONTENT	concept\tagSENT_CONTENT	overlap\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	category\tagSENT_CONTENT	includes\tagSENT_CONTENT	those\tagSENT_CONTENT	examples\tagSENT_CONTENT	with\tagSENT_CONTENT	critical\tagSENT_CONTENT	coreference\tagSENT_CONTENT	errors\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	or\tagSENT_CONTENT	key\tagSENT_CONTENT	entities\tagSENT_CONTENT	appearing\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Category\tagSECTITLE_START	Question\tagSECTITLE_END	Coref\tagSECTITLE_START	.\tagSECTITLE_END	"\tagSENT_START	coreference\tagSENT_CONTENT	errors\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	/\tagSENT_CONTENT	hard\tagSENT_CONTENT	"\tagSENT_CONTENT	cases\tagSENT_CONTENT	account\tagSENT_CONTENT	for\tagSENT_CONTENT	25\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	sample\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	our\tagSENT_CONTENT	manual\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	this\tagSENT_CONTENT	certainly\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	barrier\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	much\tagSENT_CONTENT	above\tagSENT_CONTENT	75\tagSENT_CONTENT	%\tagSENT_CONTENT	(\tagSENT_CONTENT	although\tagSENT_CONTENT	,\tagSENT_CONTENT	of\tagSENT_CONTENT	course\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	make\tagSENT_CONTENT	a\tagSENT_CONTENT	lucky\tagSENT_CONTENT	guess\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	hypothesize\tagSENT_CONTENT	that\tagSENT_CONTENT	inmost\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	answerable\tagSENT_CONTENT	"\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	 \tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	relevant\tagSENT_CONTENT	(\tagSENT_CONTENT	single\tagSENT_CONTENT	)\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	question_answering\tagtask	based\tagSENT_CONTENT	upon\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Per\tagSECTITLE_START	-\tagSECTITLE_CONTENT	category\tagSECTITLE_CONTENT	Performance\tagSECTITLE_END	Related\tagSECTITLE_START	Tasks\tagSECTITLE_END	On\tagSENT_START	the\tagSENT_CONTENT	one\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	demand\tagSENT_CONTENT	on\tagSENT_CONTENT	various\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	capacities\tagSENT_CONTENT	:\tagSENT_CONTENT	over\tagSENT_CONTENT	50\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	require\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	the\tagSENT_CONTENT	questions\tagSENT_CONTENT	come\tagSENT_CONTENT	in\tagSENT_CONTENT	assorted\tagSENT_CONTENT	categories\tagSENT_CONTENT	(\tagSENT_CONTENT	what\tagSENT_CONTENT	,\tagSENT_CONTENT	why\tagSENT_CONTENT	,\tagSENT_CONTENT	how\tagSENT_CONTENT	,\tagSENT_CONTENT	whose\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	takes\tagSENT_CONTENT	any\tagSENT_CONTENT	consecutive\tagSENT_CONTENT	21\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	children\tagSENT_CONTENT	's\tagSENT_CONTENT	book\tagSENT_CONTENT	-the\tagSENT_CONTENT	first\tagSENT_CONTENT	20\tagSENT_CONTENT	sentences\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	a\tagSENT_CONTENT	missing\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	21st\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	encourages\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	chain\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	,\tagSENT_CONTENT	induction\tagSENT_CONTENT	/\tagSENT_CONTENT	deduction\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	like\tagSENT_CONTENT	"\tagSENT_CONTENT	The\tagSENT_CONTENT	football\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	playground\tagSENT_CONTENT	"\tagSENT_CONTENT	after\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	"\tagSENT_CONTENT	John\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	playground\tagSENT_CONTENT	;\tagSENT_CONTENT	Bob\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	office\tagSENT_CONTENT	;\tagSENT_CONTENT	John\tagSENT_CONTENT	picked\tagSENT_CONTENT	up\tagSENT_CONTENT	the\tagSENT_CONTENT	football\tagSENT_CONTENT	;\tagSENT_CONTENT	Bob\tagSENT_CONTENT	went\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	kitchen\tagSENT_CONTENT	.\tagSENT_CONTENT	"\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	carefully\tagSENT_CONTENT	examined\tagSENT_CONTENT	the\tagmetric	recent\tagmetric	CNN\tagmetric	/\tagmetric	Daily\tagmetric	Mail\tagmetric	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Category\tagSECTITLE_END	Sample\tagSECTITLE_START	IDs\tagSECTITLE_END	
N15-1067	title\tagSECTITLE_END	dependency_parsing\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	that\tagSENT_CONTENT	reuses\tagSENT_CONTENT	existing\tagSENT_CONTENT	supervised\tagSENT_CONTENT	and\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	parsing\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	called\tagSENT_CONTENT	'\tagSENT_CONTENT	iterated\tagSENT_CONTENT	rerank\tagSENT_CONTENT	-\tagSENT_CONTENT	ing\tagSENT_CONTENT	'\tagSENT_CONTENT	(\tagSENT_CONTENT	IR\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	starts\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	iteratively\tagSENT_CONTENT	improves\tagSENT_CONTENT	these\tagSENT_CONTENT	trees\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	richer\tagSENT_CONTENT	probability\tagSENT_CONTENT	models\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	that\tagSENT_CONTENT	are\tagSENT_CONTENT	in\tagSENT_CONTENT	turn\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	trees\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	dependency_parsing\tagtask	and\tagSENT_CONTENT	its\tagSENT_CONTENT	supervised\tagSENT_CONTENT	counterpart\tagSENT_CONTENT	have\tagSENT_CONTENT	many\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	in\tagSENT_CONTENT	common\tagSENT_CONTENT	:\tagSENT_CONTENT	they\tagSENT_CONTENT	take\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	produce\tagSENT_CONTENT	dependency_parsing\tagtask	as\tagSENT_CONTENT	output\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	often\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	(\tagSENT_CONTENT	DDA\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	UAS\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	percentage\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	predicts\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	head\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Unsurprisingly\tagSENT_START	,\tagSENT_CONTENT	there\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	research\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	parsing\tagSENT_CONTENT	-producing\tagSENT_CONTENT	a\tagSENT_CONTENT	wealth\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	datasets\tagSENT_CONTENT	and\tagSENT_CONTENT	training\tagSENT_CONTENT	techniques\tagSENT_CONTENT	-than\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	difficult\tagSENT_CONTENT	,\tagSENT_CONTENT	much\tagSENT_CONTENT	less\tagSENT_CONTENT	accurate\tagSENT_CONTENT	and\tagSENT_CONTENT	generally\tagSENT_CONTENT	uses\tagSENT_CONTENT	very\tagSENT_CONTENT	simple\tagSENT_CONTENT	probability\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	would\tagSENT_CONTENT	like\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	information\tagSENT_CONTENT	available\tagSENT_CONTENT	from\tagSENT_CONTENT	lexical\tagSENT_CONTENT	semantics\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	parser\tagSENT_CONTENT	can\tagSENT_CONTENT	identify\tagSENT_CONTENT	that\tagSENT_CONTENT	"\tagSENT_CONTENT	he\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	"\tagSENT_CONTENT	walks\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	parser\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	"\tagSENT_CONTENT	sauce\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	John\tagSENT_CONTENT	"\tagSENT_CONTENT	have\tagSENT_CONTENT	very\tagSENT_CONTENT	different\tagSENT_CONTENT	meanings\tagSENT_CONTENT	to\tagSENT_CONTENT	decide\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	have\tagSENT_CONTENT	different\tagSENT_CONTENT	heads\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	phrases\tagSENT_CONTENT	"\tagSENT_CONTENT	ate\tagSENT_CONTENT	spaghetti\tagSENT_CONTENT	with\tagSENT_CONTENT	sauce\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	ate\tagSENT_CONTENT	spaghetti\tagSENT_CONTENT	with\tagSENT_CONTENT	John\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	applying\tagSENT_CONTENT	existing\tagSENT_CONTENT	supervised\tagSENT_CONTENT	parsing\tagSENT_CONTENT	techniques\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	,\tagSENT_CONTENT	unfortunately\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	trivial\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	overcome\tagSENT_CONTENT	these\tagSENT_CONTENT	difficulties\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	iterated\tagSENT_CONTENT	reranking\tagSENT_CONTENT	(\tagSENT_CONTENT	IR\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	existing\tagSENT_CONTENT	supervised\tagSENT_CONTENT	parsers\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	of\tagSENT_CONTENT	manually\tagSENT_CONTENT	annotated\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	starting\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	existing\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	parser\tagSENT_CONTENT	as\tagSENT_CONTENT	initialiser\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	lexical\tagSENT_CONTENT	semantics\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	abridge\tagSENT_CONTENT	connecting\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	research\tagSENT_CONTENT	areas\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	its\tagSENT_CONTENT	supervised\tagSENT_CONTENT	counterpart\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Unsupervised\tagSECTITLE_START	Dependency\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	breakthrough\tagSENT_CONTENT	was\tagSENT_CONTENT	set\tagSENT_CONTENT	by\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	with\tagSENT_CONTENT	valence\tagSENT_CONTENT	(\tagSENT_CONTENT	DMV\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	outperform\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	branching\tagSENT_CONTENT	baseline\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DDA\tagSENT_CONTENT	metric\tagSENT_CONTENT	:\tagSENT_CONTENT	43.2\tagSENT_CONTENT	%\tagSENT_CONTENT	vs\tagSENT_CONTENT	33.6\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	sentences\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	length\tagSENT_CONTENT	10\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	make\tagSENT_START	use\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	raw\tagSENT_CONTENT	text\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	estimate\tagSENT_CONTENT	stop\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	reducibility\tagSENT_CONTENT	principle\tagSENT_CONTENT	.\tagSENT_END	Reranking\tagSECTITLE_END	Our\tagSENT_START	work\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	reranking\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	technique\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	semi-)supervised\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Reranking\tagSENT_START	was\tagSENT_CONTENT	first\tagSENT_CONTENT	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	It\tagSENT_START	was\tagSENT_CONTENT	then\tagSENT_CONTENT	employed\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	Closest\tagSENT_START	to\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	work\tagSENT_CONTENT	series\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	McClosky\tagSENT_CONTENT	and\tagSENT_CONTENT	colleagues\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	selftraining\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	from\tagSENT_CONTENT	their\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	without\tagSENT_CONTENT	manually\tagSENT_CONTENT	annotated\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	uses\tagSENT_CONTENT	iterated\tagSENT_CONTENT	reranking\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	single\tagSENT_CONTENT	reranking\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	IR\tagSECTITLE_CONTENT	Framework\tagSECTITLE_END	Existing\tagSENT_START	training\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	-\tagSENT_CONTENT	oriented\tagSENT_CONTENT	search\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	EM\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	or\tagSENT_CONTENT	its\tagSENT_CONTENT	variants\tagSENT_CONTENT	:\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	move\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	point\tagSENT_CONTENT	which\tagSENT_CONTENT	represents\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	to\tagSENT_CONTENT	another\tagSENT_CONTENT	point\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	feasible\tagSENT_CONTENT	for\tagSENT_CONTENT	optimising\tagSENT_CONTENT	models\tagSENT_CONTENT	using\tagSENT_CONTENT	simple\tagSENT_CONTENT	features\tagSENT_CONTENT	since\tagSENT_CONTENT	existing\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	programming\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	can\tagSENT_CONTENT	compute\tagSENT_CONTENT	expectations\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	sums\tagmetric	overall\tagSENT_CONTENT	possible\tagSENT_CONTENT	parses\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	parse\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	parse\tagSENT_CONTENT	space\tagSENT_CONTENT	with\tagSENT_CONTENT	low\tagSENT_CONTENT	complexities\tagSENT_CONTENT	.\tagSENT_END	Treebank\tagSECTITLE_START	-\tagSECTITLE_CONTENT	oriented\tagSECTITLE_CONTENT	Greedy\tagSECTITLE_CONTENT	Search\tagSECTITLE_END	Given\tagSENT_START	S\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	possible\tagSENT_CONTENT	treebanks\tagSENT_CONTENT	D\tagSENT_CONTENT	=\tagSENT_CONTENT	{\tagSENT_CONTENT	d(s)|s\tagSENT_CONTENT	∈\tagSENT_CONTENT	S\tagSENT_CONTENT	}\tagSENT_CONTENT	where\tagSENT_CONTENT	d(s\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	s.\tagSENT_END	dependency_parsing\tagtask	using\tagSENT_CONTENT	reranking\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Iterated\tagSECTITLE_START	Reranking\tagSECTITLE_END	Reranking\tagSENT_START	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	brings\tagSENT_CONTENT	us\tagmetric	two\tagSENT_CONTENT	benefits\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	allows\tagSENT_CONTENT	us\tagmetric	to\tagSENT_CONTENT	employ\tagSENT_CONTENT	very\tagSENT_CONTENT	expressive\tagSENT_CONTENT	models\tagSENT_CONTENT	like\tagSENT_CONTENT	the\tagSENT_CONTENT	∞-order\tagSENT_CONTENT	generative\tagSENT_CONTENT	model\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	phase\tagSECTITLE_CONTENT	Iterated\tagSECTITLE_CONTENT	Reranking\tagSECTITLE_END	In\tagSENT_START	dependency_parsing\tagtask	,\tagSENT_CONTENT	starting\tagSENT_CONTENT	small\tagSENT_CONTENT	is\tagSENT_CONTENT	intuitive\tagSENT_CONTENT	.\tagSENT_END	Le\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Zuidema\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2014\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	's\tagSECTITLE_CONTENT	Reranker\tagSECTITLE_END	The\tagSECTITLE_START	∞-order\tagSECTITLE_CONTENT	Generative\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	We\tagSENT_START	then\tagSENT_CONTENT	generate\tagSENT_CONTENT	dependency_parsing\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	ROOT\tagSENT_CONTENT	's\tagSENT_CONTENT	dependent\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	H\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	head\tagSENT_CONTENT	,\tagSENT_CONTENT	d(N\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	fragment\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	rooted\tagSENT_CONTENT	at\tagSENT_CONTENT	N\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	C(N\tagSENT_CONTENT	)\tagSENT_END	H\tagSENT_START	L\tagSENT_CONTENT	,\tagSENT_CONTENT	HR\tagSENT_CONTENT	are\tagSENT_CONTENT	respectively\tagSENT_CONTENT	H\tagSENT_CONTENT	's\tagSENT_CONTENT	left\tagSENT_CONTENT	dependents\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	plus\tagSENT_CONTENT	EOC\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	d(ROOT\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	generating\tagSENT_CONTENT	dependency_parsing\tagtask	structured\tagSENT_CONTENT	.\tagSENT_END	Estimation\tagSECTITLE_START	with\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	IORNN\tagSECTITLE_END	The\tagSENT_START	inner\tagSENT_CONTENT	representation\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	node\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	turn\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagmetric	case\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	are\tagSENT_CONTENT	initially\tagSENT_CONTENT	borrowed\tagSENT_CONTENT	from\tagSENT_CONTENT	Collobert\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	-\tagSENT_CONTENT	tag\tagSENT_CONTENT	and\tagSENT_CONTENT	capitalisation\tagSENT_CONTENT	feature\tagSENT_CONTENT	.\tagSENT_END	Without\tagSENT_START	loss\tagSENT_CONTENT	of\tagSENT_CONTENT	generality\tagSENT_CONTENT	and\tagSENT_CONTENT	ignoring\tagSENT_CONTENT	directions\tagSENT_CONTENT	for\tagSENT_CONTENT	simplicity\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	generating\tagSENT_CONTENT	dependency_parsing\tagtask	for\tagSENT_CONTENT	node\tagSENT_CONTENT	h\tagSENT_CONTENT	conditioning\tagSENT_CONTENT	on\tagSENT_CONTENT	context\tagSENT_CONTENT	C\tagSENT_CONTENT	∞\tagSENT_CONTENT	(\tagSENT_CONTENT	u\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	contains\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	u\tagSENT_CONTENT	's\tagSENT_CONTENT	ancestors\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	h\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	theirs\tagSENT_CONTENT	siblings\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	previously\tagSENT_CONTENT	generated\tagSENT_CONTENT	u\tagSENT_CONTENT	's\tagSENT_CONTENT	sisters\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	are\tagSENT_CONTENT	being\tagSENT_CONTENT	generated\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	contexts\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	nodes\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	C\tagSENT_CONTENT	∞\tagSENT_CONTENT	(\tagSENT_CONTENT	u\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Reranker\tagSECTITLE_END	Complete\tagSECTITLE_START	System\tagSECTITLE_END	In\tagSENT_START	general\tagSENT_CONTENT	,\tagSENT_CONTENT	any\tagSENT_CONTENT	third\tagSENT_CONTENT	-\tagSENT_CONTENT	party\tagSENT_CONTENT	parser\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	phase\tagSENT_CONTENT	0\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	any\tagSENT_CONTENT	thirdparty\tagSENT_CONTENT	parser\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	generate\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	lists\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	phases\tagSENT_CONTENT	.\tagSENT_END	Tuning\tagSECTITLE_START	Parser\tagSECTITLE_CONTENT	P\tagSECTITLE_END	Tuning\tagSECTITLE_START	Reranker\tagSECTITLE_CONTENT	R\tagSECTITLE_END	Tuning\tagSECTITLE_START	multi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	phase\tagSECTITLE_CONTENT	IR\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	force\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	search\tagSENT_CONTENT	in\tagSENT_CONTENT	phase\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	run\tagSENT_CONTENT	intensively\tagSENT_CONTENT	because\tagSENT_CONTENT	we\tagSENT_CONTENT	hypothesise\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	patterns\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	found\tagSENT_CONTENT	within\tagSENT_CONTENT	short\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Setting\tagSECTITLE_END	We\tagSENT_START	then\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	5\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	)\tagSENT_CONTENT	:\tagSENT_CONTENT	we\tagSENT_CONTENT	strip\tagSENT_CONTENT	off\tagSENT_CONTENT	all\tagSENT_CONTENT	empty\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	trees\tagSENT_CONTENT	,\tagSENT_CONTENT	punctuation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	terminals\tagSENT_CONTENT	(\tagSENT_CONTENT	tagged\tagSENT_CONTENT	#\tagSENT_CONTENT	and\tagSENT_CONTENT	$\tagSENT_CONTENT	)\tagSENT_END	not\tagSENT_START	pronounced\tagSENT_CONTENT	where\tagSENT_CONTENT	they\tagSENT_CONTENT	appear\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	then\tagSENT_CONTENT	convert\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	trees\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	using\tagSENT_CONTENT	Collins\tagSENT_CONTENT	's\tagSENT_CONTENT	head\tagSENT_CONTENT	rules\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Analysis\tagSECTITLE_END	The\tagSECTITLE_START	role\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	lexical\tagSECTITLE_CONTENT	semantics\tagSECTITLE_END	shows\tagSENT_START	DDAs\tagmetric	on\tagSENT_CONTENT	training\tagSENT_CONTENT	sentences\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	length\tagSENT_CONTENT	15\tagSENT_END	It\tagSENT_START	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	phase\tagSENT_CONTENT	1\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	discovering\tagSENT_CONTENT	dependency_parsing\tagtask	that\tagSENT_CONTENT	are\tagSENT_CONTENT	invisible\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	in\tagSENT_CONTENT	phase\tagSENT_CONTENT	0\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	importance\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	starting\tagSECTITLE_CONTENT	point\tagSECTITLE_END	shows\tagSENT_START	DDAs\tagmetric	of\tagSENT_CONTENT	phase\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	MaxEnc\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	training\tagSENT_CONTENT	sentences\tagSENT_CONTENT	up\tagSENT_END	The\tagSECTITLE_START	contribution\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Iterated\tagSECTITLE_CONTENT	Reranking\tagSECTITLE_END	We\tagSENT_START	attribute\tagSENT_CONTENT	this\tagSENT_CONTENT	improvement\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	∞-order\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	uses\tagSENT_CONTENT	very\tagSENT_CONTENT	large\tagSENT_CONTENT	fragments\tagSENT_CONTENT	as\tagSENT_CONTENT	contexts\tagSENT_CONTENT	thus\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	treebank\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	initializer\tagSENT_CONTENT	,\tagSENT_CONTENT	almost\tagSENT_CONTENT	all\tagSENT_CONTENT	modal\tagSENT_CONTENT	auxilaries\tagSENT_CONTENT	are\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	their\tagSENT_CONTENT	verbs\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	way\tagSENT_CONTENT	around\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Although\tagSENT_START	their\tagSENT_CONTENT	approach\tagSENT_CONTENT	can\tagSENT_CONTENT	distinguish\tagSENT_CONTENT	polysemes\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	'\tagSENT_CONTENT	cool\tagSENT_CONTENT	'\tagSENT_CONTENT	in\tagSENT_CONTENT	'\tagSENT_CONTENT	to\tagSENT_CONTENT	cool\tagSENT_CONTENT	the\tagSENT_CONTENT	selling\tagSENT_CONTENT	panic\tagSENT_CONTENT	'\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	'\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	cool\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	notable\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	word\tagSENT_CONTENT	meaning\tagSENT_CONTENT	similarities\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	a\tagSENT_CONTENT	generative\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	parser\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	reranker\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	But\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	innovation\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	making\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	existing\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	
clin27.paper	title\tagSECTITLE_END	Modeling\tagSENT_START	Noise\tagSENT_CONTENT	Using\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	MoNoise\tagSENT_CONTENT	:\tagSENT_CONTENT	lexical_normalization\tagtask	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	generalizability\tagSENT_CONTENT	and\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	aims\tagSENT_CONTENT	at\tagSENT_CONTENT	being\tagSENT_CONTENT	easily\tagSENT_CONTENT	reusable\tagSENT_CONTENT	and\tagSENT_CONTENT	adaptable\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	added\tagSENT_CONTENT	data\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagmetric	high\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	so\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	too\tagSENT_CONTENT	distant\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	should\tagSENT_CONTENT	add\tagSENT_CONTENT	lexical_normalization\tagtask	inherent\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	task\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	because\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	domain\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	'\tagSENT_CONTENT	normal\tagSENT_CONTENT	'\tagSENT_CONTENT	source\tagSENT_CONTENT	domain\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	already\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	Because\tagSENT_START	lexical_normalization\tagtask	comprises\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	normalization\tagSENT_CONTENT	actions\tagSENT_CONTENT	required\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	anomalies\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	modular\tagSENT_CONTENT	way\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conclude\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagmetric	6\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	They\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	Hidden\tagSENT_CONTENT	Markov\tagSENT_CONTENT	Model\tagSENT_CONTENT	encoding\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	characters\tagSENT_CONTENT	and\tagSENT_CONTENT	phonemic\tagSENT_CONTENT	transcriptions\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	lexical_normalization\tagtask	in\tagSENT_CONTENT	SMS\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Later\tagSENT_START	,\tagSENT_CONTENT	focus\tagSENT_CONTENT	shifted\tagSENT_CONTENT	towards\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	,\tagSENT_CONTENT	more\tagSENT_CONTENT	specifically\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	use\tagSENT_START	random\tagSENT_CONTENT	walks\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	bipartite\tagSENT_CONTENT	graph\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	contexts\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	they\tagSENT_CONTENT	rank\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	reported\tagSENT_CONTENT	the\tagmetric	highest\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	LexNorm\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	rerank\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	spellchecker\tagSENT_CONTENT	.\tagSENT_END	More\tagSENT_START	recently\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	2015\tagSENT_CONTENT	Workshop\tagSENT_CONTENT	on\tagSENT_CONTENT	Noisy\tagSENT_CONTENT	User\tagSENT_CONTENT	-\tagSENT_CONTENT	generated\tagSENT_CONTENT	Text\tagSENT_CONTENT	hosted\tagSENT_CONTENT	a\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	also\tagSENT_START	tests\tagSENT_CONTENT	if\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	similar\tagSENT_CONTENT	candidates\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Aspell\tagSENT_CONTENT	dictionary\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	concludes\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	We\tagSENT_START	will\tagSENT_CONTENT	consider\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	Dutch\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	if\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	other\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	main\tagSENT_CONTENT	differences\tagSENT_CONTENT	are\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	and\tagSENT_CONTENT	include\tagSENT_CONTENT	N\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	ranking\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	easily\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_END	The\tagSENT_START	data\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	divided\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	data\tagSENT_CONTENT	annotated\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Normalization\tagSECTITLE_START	Corpora\tagSECTITLE_END	lexical_normalization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	rather\tagSENT_CONTENT	subjective\tagSENT_CONTENT	task\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	annotators\tagSENT_CONTENT	are\tagSENT_CONTENT	asked\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	noisy\tagSENT_CONTENT	texts\tagSENT_CONTENT	to\tagSENT_CONTENT	'\tagSENT_CONTENT	normal\tagSENT_CONTENT	'\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	report\tagSENT_START	a\tagSENT_CONTENT	Cohen\tagSENT_CONTENT	's\tagSENT_CONTENT	κ\tagSENT_CONTENT	of\tagSENT_CONTENT	0.5854\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	lot\tagSENT_CONTENT	lower\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	give\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	idea\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	discuss\tagSENT_CONTENT	some\tagSENT_CONTENT	example\tagSENT_CONTENT	sentences\tagSENT_CONTENT	below\tagSENT_CONTENT	.\tagSENT_END	Other\tagSECTITLE_START	Data\tagSECTITLE_END	We\tagSENT_START	used\tagSENT_CONTENT	some\tagmetric	preprocessing\tagmetric	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	types\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	smaller\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	faster\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	Method\tagSECTITLE_END	lexical_normalization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	split\tagSENT_CONTENT	into\tagSENT_CONTENT	two\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_END	•\tagSENT_START	Candidate\tagSENT_CONTENT	generation\tagSENT_CONTENT	:\tagSENT_CONTENT	generate\tagSENT_CONTENT	lexical_normalization\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	step\tagSENT_CONTENT	is\tagSENT_CONTENT	responsible\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	uppperbound\tagSENT_CONTENT	on\tagSENT_CONTENT	recall\tagmetric	;\tagSENT_CONTENT	but\tagSENT_CONTENT	care\tagSENT_CONTENT	should\tagSENT_CONTENT	also\tagSENT_CONTENT	betaken\tagSENT_CONTENT	to\tagSENT_CONTENT	not\tagSENT_CONTENT	generate\tagSENT_CONTENT	too\tagSENT_CONTENT	many\tagSENT_CONTENT	candidates\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	this\tagSENT_CONTENT	could\tagSENT_CONTENT	complicate\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	includes\tagSENT_CONTENT	error\tagSENT_CONTENT	detection\tagSENT_CONTENT	as\tagSENT_CONTENT	first\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	only\tagSENT_CONTENT	explores\tagSENT_CONTENT	the\tagSENT_CONTENT	possibilities\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	words\tagSENT_CONTENT	detected\tagSENT_CONTENT	as\tagSENT_CONTENT	anomaly\tagSENT_CONTENT	.\tagSENT_END	Candidate\tagSECTITLE_START	Generation\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	domain\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Tweets\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagmetric	3.2\tagSENT_CONTENT	.\tagSENT_END	Aspell\tagSENT_START	uses\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	character\tagSENT_CONTENT	edit\tagSENT_CONTENT	distance\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	distance\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	similar\tagSENT_CONTENT	looking\tagSENT_CONTENT	and\tagSENT_CONTENT	similar\tagSENT_CONTENT	sounding\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	a\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	space\tagmetric	restrictions\tagmetric	and\tagSENT_CONTENT	input\tagSENT_CONTENT	devices\tagSENT_CONTENT	native\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagSENT_CONTENT	domain\tagSENT_CONTENT	,\tagSENT_CONTENT	users\tagSENT_CONTENT	often\tagSENT_CONTENT	use\tagSENT_CONTENT	abbreviated\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	modules\tagSENT_CONTENT	are\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	separately\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagmetric	5.1\tagSENT_END	Candidate\tagSECTITLE_START	Ranking\tagSECTITLE_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	internal\tagSENT_CONTENT	calculated\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	word\tagSENT_CONTENT	;\tagSENT_CONTENT	this\tagSENT_CONTENT	distance\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	include\tagSENT_CONTENT	counts\tagSENT_CONTENT	for\tagSENT_CONTENT	unchanged\tagSENT_CONTENT	pairs\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	;\tagSENT_CONTENT	this\tagSENT_CONTENT	strengthens\tagSENT_CONTENT	the\tagmetric	decision\tagmetric	whether\tagSENT_CONTENT	to\tagSENT_CONTENT	keep\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	N\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	data\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	N\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	more\tagSENT_CONTENT	canonical\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	data\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagmetric	3.2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Whereas\tagSENT_START	the\tagSENT_CONTENT	classifier\tagSENT_CONTENT	might\tagSENT_CONTENT	classify\tagSENT_CONTENT	multiple\tagSENT_CONTENT	or\tagSENT_CONTENT	zero\tagSENT_CONTENT	candidates\tagSENT_CONTENT	per\tagSENT_CONTENT	position\tagmetric	as\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	choose\tagSENT_CONTENT	this\tagSENT_CONTENT	classifier\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	divided\tagSENT_CONTENT	in\tagSENT_CONTENT	multiple\tagSENT_CONTENT	normalization\tagSENT_CONTENT	actions\tagSENT_CONTENT	which\tagSENT_CONTENT	behave\tagSENT_CONTENT	differently\tagSENT_CONTENT	feature\tagSENT_CONTENT	wise\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	setup\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	all\tagSENT_CONTENT	classified\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	for\tagSENT_START	testing\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	LexNorm\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	2,000\tagSENT_CONTENT	Tweets\tagSENT_CONTENT	from\tagSENT_CONTENT	LiLiu\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagmetric	3.1\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	577\tagSENT_CONTENT	Tweets\tagSENT_CONTENT	as\tagSENT_CONTENT	development\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_CONTENT	   \tagSENT_END	•\tagSENT_START	GhentNorm\tagSENT_CONTENT	:\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	previous\tagmetric	lexical_normalization\tagtask	in\tagSENT_CONTENT	this\tagSENT_CONTENT	section\tagSENT_CONTENT	is\tagSENT_CONTENT	done\tagSENT_CONTENT	with\tagSENT_CONTENT	all\tagSENT_CONTENT	words\tagSENT_CONTENT	lowercased\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	inline\tagSENT_CONTENT	with\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	and\tagSENT_CONTENT	capitalization\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	consistently\tagSENT_CONTENT	annotated\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	available\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Candidate\tagSECTITLE_START	Generation\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	first\tagSENT_CONTENT	compare\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	modules\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	contribute\tagSENT_CONTENT	less\tagSENT_CONTENT	unique\tagSENT_CONTENT	candidates\tagSENT_CONTENT	;\tagSENT_CONTENT	presumably\tagSENT_CONTENT	because\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	overlap\tagSENT_CONTENT	:\tagSENT_CONTENT	Recall\tagmetric	achieved\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	N\tagSENT_CONTENT	candidates\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	different\tagSENT_CONTENT	development\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	also\tagSENT_START	words\tagSENT_CONTENT	not\tagSENT_CONTENT	needing\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Candidate\tagSECTITLE_START	Ranking\tagSECTITLE_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	test\tagSENT_CONTENT	our\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	LexNorm2015\tagdataset	,\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	2015\tagSENT_CONTENT	workshop\tagSENT_CONTENT	on\tagSENT_CONTENT	Noisy\tagSENT_CONTENT	User\tagSENT_CONTENT	-\tagSENT_CONTENT	generated\tagSENT_CONTENT	Text\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Additional\tagSECTITLE_START	Experiments\tagSECTITLE_END	We\tagSENT_START	test\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	largest\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	LiLiu\tagSENT_CONTENT	and\tagSENT_CONTENT	LexNorm2015\tagdataset	.\tagSENT_END	As\tagSENT_START	explained\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagmetric	4\tagSENT_CONTENT	we\tagSENT_CONTENT	included\tagSENT_CONTENT	two\tagSENT_CONTENT	options\tagSENT_CONTENT	to\tagSENT_CONTENT	tune\tagSENT_CONTENT	the\tagSENT_CONTENT	speed\tagSENT_CONTENT	-\tagSENT_CONTENT	performance\tagSENT_CONTENT	ratio\tagSENT_CONTENT	.\tagSENT_END	Aspell\tagSECTITLE_START	mode\tagSECTITLE_CONTENT	Filter\tagSECTITLE_END	Test\tagSECTITLE_START	Data\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	different\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	with\tagSENT_CONTENT	previous\tagmetric	work\tagmetric	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	LexNorm1.2\tagSENT_CONTENT	corpus\tagSENT_CONTENT	we\tagSENT_CONTENT	assume\tagSENT_CONTENT	gold\tagSENT_CONTENT	error\tagSENT_CONTENT	detection\tagSENT_CONTENT	,\tagSENT_CONTENT	inline\tagSENT_CONTENT	with\tagSENT_CONTENT	previous\tagmetric	work\tagmetric	;\tagSENT_CONTENT	for\tagSENT_CONTENT	more\tagSENT_CONTENT	details\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	metrics\tagSENT_CONTENT	we\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	papers\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	not\tagSENT_CONTENT	directly\tagSENT_CONTENT	comparable\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	different\tagSENT_CONTENT	random\tagSENT_CONTENT	splits\tagSENT_CONTENT	.\tagSENT_END	Recall+P\tagSECTITLE_START	recision\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	;\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	scores\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	precision\tagmetric	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	recall\tagSENT_CONTENT	.\tagSENT_END	Arguably\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	desirable\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	want\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Extrinsic\tagSECTITLE_START	Evaluation\tagSECTITLE_END	To\tagSENT_START	test\tagSENT_CONTENT	if\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	setup\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	step\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	Berkeley\tagSENT_CONTENT	parser\tagSENT_END	We\tagSENT_START	observed\tagSENT_CONTENT	an\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	0.68\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	treebank\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	lexical_normalization\tagtask	and\tagSENT_CONTENT	a\tagSENT_CONTENT	grammar\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	more\tagSENT_CONTENT	canonical\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	model\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagmetric	3.2\tagSENT_CONTENT	to\tagSENT_CONTENT	initialize\tagSENT_CONTENT	Bilty\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	character\tagSENT_CONTENT	level\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	proposed\tagSENT_CONTENT	MoNoise\tagSENT_CONTENT	;\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	beats\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	normalization\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	Future\tagSENT_START	work\tagSENT_CONTENT	includes\tagSENT_CONTENT	lexical_normalization\tagtask	concerning\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	normalizations\tagSENT_CONTENT	,\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	domains\tagSENT_CONTENT	and\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	depth\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	replacements\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	usefulness\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	normalization\tagSENT_CONTENT	as\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	.\tagSENT_END	
1808.08644	title\tagSECTITLE_END	Predicting\tagSENT_START	relation_prediction\tagtask	using\tagSENT_CONTENT	Global\tagSENT_CONTENT	Graph\tagSENT_CONTENT	Properties\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	demonstrate\tagSENT_CONTENT	how\tagSENT_CONTENT	such\tagSENT_CONTENT	global\tagSENT_CONTENT	modeling\tagSENT_CONTENT	improves\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	relation_prediction\tagtask	between\tagSENT_CONTENT	synsets\tagSENT_CONTENT	,\tagSENT_CONTENT	yielding\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WN18RR\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	challenging\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	link\tagSENT_CONTENT	prediction\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	"\tagSENT_CONTENT	easy\tagSENT_CONTENT	"\tagSENT_CONTENT	reciprocal\tagSENT_CONTENT	cases\tagSENT_CONTENT	are\tagSENT_CONTENT	removed\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Semantic\tagSENT_START	graphs\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	,\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	qualities\tagSENT_CONTENT	of\tagSENT_CONTENT	language\tagSENT_CONTENT	as\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	human\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	contrast\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	regularity\tagSENT_CONTENT	and\tagSENT_CONTENT	significance\tagSENT_CONTENT	of\tagSENT_CONTENT	global\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic\tagSENT_CONTENT	graphs\tagSENT_CONTENT	is\tagSENT_CONTENT	wellattested\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	global\tagSENT_CONTENT	properties\tagSENT_CONTENT	have\tagSENT_CONTENT	rarely\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	While\tagSENT_START	relation_prediction\tagtask	might\tagSENT_CONTENT	mistake\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	between\tagSENT_CONTENT	'\tagSENT_CONTENT	cat\tagSENT_CONTENT	'\tagSENT_CONTENT	and\tagSENT_CONTENT	'\tagSENT_CONTENT	boat\tagSENT_CONTENT	'\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	plausible\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	whatever\tagSENT_CONTENT	reason\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	graphstructure\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	model\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	discard\tagSENT_CONTENT	it\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	synset\tagSENT_CONTENT	should\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	one\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	examine\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	global\tagSENT_CONTENT	graph\tagSENT_CONTENT	properties\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	link\tagSENT_CONTENT	structure\tagSENT_CONTENT	via\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	replace\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	objective\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	margin\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	objective\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	compares\tagSENT_CONTENT	the\tagSENT_CONTENT	observed\tagSENT_CONTENT	network\tagSENT_CONTENT	against\tagSENT_CONTENT	alternative\tagSENT_CONTENT	networks\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	call\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	MaxMargin\tagSENT_CONTENT	Markov\tagSENT_CONTENT	Graph\tagSENT_CONTENT	Model\tagSENT_CONTENT	(\tagSENT_CONTENT	M3GM\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	drawing\tagSENT_CONTENT	on\tagSENT_CONTENT	ideas\tagSENT_CONTENT	from\tagSENT_CONTENT	relation_prediction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	relation_prediction\tagtask	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	M3GM\tagSENT_CONTENT	assigns\tagSENT_CONTENT	importance\tagSENT_CONTENT	to\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	all\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	captures\tagSENT_CONTENT	some\tagSENT_CONTENT	interesting\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	relational\tagSENT_CONTENT	properties\tagSENT_CONTENT	that\tagSENT_CONTENT	lend\tagSENT_CONTENT	insight\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	relation_prediction\tagtask	in\tagSENT_CONTENT	semantic\tagSENT_CONTENT	graphs\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	recent\tagSENT_CONTENT	works\tagSENT_CONTENT	compose\tagSENT_CONTENT	single\tagSENT_CONTENT	edges\tagSENT_CONTENT	into\tagSENT_CONTENT	more\tagSENT_CONTENT	intricate\tagSENT_CONTENT	motifs\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	define\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	and\tagSENT_CONTENT	compose\tagSENT_CONTENT	various\tagSENT_CONTENT	functions\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	introduces\tagSENT_CONTENT	interaction\tagSENT_CONTENT	features\tagSENT_CONTENT	between\tagSENT_CONTENT	relation_prediction\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	hypernyms\tagSENT_CONTENT	and\tagSENT_CONTENT	meronyms\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	relation\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	Monte\tagSENT_START	Carlo\tagSENT_CONTENT	Maximum\tagSENT_CONTENT	Likelihood\tagSENT_CONTENT	Estimation\tagSENT_CONTENT	(\tagSENT_CONTENT	MCMLE\tagSENT_CONTENT	;\tagSENT_CONTENT	)\tagSENT_CONTENT	follows\tagSENT_CONTENT	a\tagSENT_CONTENT	sampling\tagSENT_CONTENT	logic\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	graphs\tagSENT_CONTENT	is\tagSENT_CONTENT	randomly\tagSENT_CONTENT	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	space\tagSENT_CONTENT	under\tagSENT_CONTENT	the\tagSENT_CONTENT	intuition\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	scores\tagSENT_CONTENT	would\tagSENT_CONTENT	give\tagSENT_CONTENT	relation_prediction\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	score\tagSENT_CONTENT	mass\tagSENT_CONTENT	.\tagSENT_END	Max\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Margin\tagSECTITLE_CONTENT	Markov\tagSECTITLE_CONTENT	Graph\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	where\tagSENT_START	f\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	from\tagSENT_CONTENT	graphs\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	of\tagSENT_CONTENT	feature\tagSENT_CONTENT	counts\tagSENT_CONTENT	.\tagSENT_END	Graph\tagSECTITLE_START	Motifs\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Based\tagSENT_START	on\tagSENT_CONTENT	common\tagSENT_CONTENT	practice\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	graph\tagSENT_CONTENT	features\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	basis\tagSENT_CONTENT	:\tagSENT_END	For\tagSENT_START	relation_prediction\tagtask	r\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	inventory\tagSENT_CONTENT	R\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	denote\tagSENT_CONTENT	its\tagSENT_CONTENT	edge\tagSENT_CONTENT	set\tagSENT_CONTENT	as\tagSENT_CONTENT	Er\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	redefine\tagSENT_CONTENT	E\tagSENT_END	u\tagSENT_START	•\tagSENT_CONTENT	A\tagSENT_CONTENT	combinatory\tagSENT_CONTENT	'\tagSENT_CONTENT	2-outgoing\tagSENT_CONTENT	'\tagSENT_CONTENT	feature\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	extracted\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	nodes\tagSENT_CONTENT	with\tagSENT_CONTENT	relation_prediction\tagtask	and\tagSENT_CONTENT	one\tagSENT_CONTENT	has\tagSENT_CONTENT	part\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	number\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	thus\tagSENT_CONTENT	scales\tagSENT_CONTENT	in\tagSENT_CONTENT	O(|R|\tagSENT_CONTENT	K\tagSENT_CONTENT	)\tagSENT_CONTENT	fora\tagSENT_CONTENT	feature\tagSENT_CONTENT	basis\tagSENT_CONTENT	which\tagSENT_CONTENT	involves\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	K\tagSENT_CONTENT	edges\tagSENT_CONTENT	in\tagSENT_CONTENT	any\tagSENT_CONTENT	feature\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	so\tagSENT_CONTENT	our\tagSENT_CONTENT	17\tagSENT_CONTENT	basis\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	K\tagSENT_CONTENT	=\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	combinatory\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	with\tagSENT_CONTENT	roughly\tagSENT_CONTENT	3,000\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Local\tagSECTITLE_START	Score\tagSECTITLE_CONTENT	Component\tagSECTITLE_END	In\tagSENT_START	classical\tagSENT_CONTENT	ERGM\tagSENT_CONTENT	application\tagSENT_CONTENT	domains\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	or\tagSENT_CONTENT	biological\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	nodes\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	or\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	little\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	intrinsic\tagSENT_CONTENT	information\tagSENT_CONTENT	that\tagSENT_CONTENT	maybe\tagSENT_CONTENT	extracted\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	applying\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	relation_prediction\tagtask	generalizes\tagSENT_CONTENT	various\tagSENT_CONTENT	models\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	prediction\tagSENT_CONTENT	literature\tagSENT_CONTENT	:\tagSENT_END	(\tagSENT_START	Bordes\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2013\tagSENT_CONTENT	)\tagSENT_CONTENT	embeds\tagSENT_CONTENT	relation_prediction\tagtask	r\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	shared\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	representing\tagSENT_CONTENT	a\tagSENT_CONTENT	'\tagSENT_CONTENT	difference\tagSENT_CONTENT	'\tagSENT_CONTENT	between\tagSENT_CONTENT	sources\tagSENT_CONTENT	and\tagSENT_CONTENT	targets\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	association\tagSENT_CONTENT	score\tagSENT_CONTENT	under\tagSENT_CONTENT	a\tagSENT_CONTENT	translational\tagSENT_CONTENT	objective\tagSENT_CONTENT	,\tagSENT_END	BiLin\tagSENT_START	(\tagSENT_CONTENT	Nickel\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	embeds\tagSENT_CONTENT	relation_prediction\tagtask	into\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	rank\tagSENT_CONTENT	matrices\tagSENT_CONTENT	,\tagSENT_CONTENT	computing\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	bilinear\tagSENT_CONTENT	multiplication\tagSENT_CONTENT	,\tagSENT_END	DistMult\tagSENT_START	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	BiLin\tagSENT_CONTENT	where\tagSENT_CONTENT	relation_prediction\tagtask	are\tagSENT_CONTENT	diagonal\tagSENT_CONTENT	,\tagSENT_CONTENT	reducing\tagSENT_CONTENT	the\tagSENT_CONTENT	computation\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	ternary\tagSENT_CONTENT	dot\tagSENT_CONTENT	product\tagSENT_CONTENT	,\tagSENT_END	Parameter\tagSECTITLE_START	Estimation\tagSECTITLE_END	where\tagSENT_START	M\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	networks˜Gnetworks˜\tagSENT_CONTENT	networks˜G\tagSENT_CONTENT	sampled\tagSENT_CONTENT	from\tagSENT_CONTENT	G\tagSENT_CONTENT	|V\tagSENT_CONTENT	|\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	relation_prediction\tagtask	sets\tagSENT_CONTENT	on\tagSENT_CONTENT	nodes\tagSENT_CONTENT	V\tagSENT_CONTENT	.\tagSENT_END	Relation\tagSECTITLE_START	Prediction\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	M3GM\tagSENT_CONTENT	on\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	WN18RR\tagSECTITLE_START	Dataset\tagSECTITLE_END	relation_prediction\tagtask	dataset\tagSENT_CONTENT	for\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	subset\tagSENT_CONTENT	curated\tagSENT_CONTENT	as\tagSENT_CONTENT	WN18\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	containing\tagSENT_CONTENT	18\tagSENT_CONTENT	relations\tagSENT_CONTENT	for\tagSENT_CONTENT	about\tagSENT_CONTENT	41,000\tagSENT_CONTENT	synsets\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	3.0\tagSENT_CONTENT	.\tagSENT_END	Metrics\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	common\tagSENT_CONTENT	in\tagSENT_CONTENT	ranking\tagSENT_CONTENT	tasks\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	in\tagSENT_CONTENT	particular\tagSENT_CONTENT	:\tagSENT_CONTENT	MR\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Rank\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	desired\tagSENT_CONTENT	entity\tagSENT_CONTENT	;\tagSENT_CONTENT	MRR\tagSENT_CONTENT	,\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Reciprocal\tagSENT_CONTENT	Rank\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	H@k\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	Hits\tagSENT_CONTENT	(\tagSENT_CONTENT	true\tagSENT_CONTENT	entities\tagSENT_CONTENT	)\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	k\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	lists\tagSENT_CONTENT	,\tagSENT_CONTENT	fork\tagSENT_CONTENT	∈\tagSENT_CONTENT	{\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	10\tagSENT_CONTENT	}\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	some\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	type\tagSENT_CONTENT	-\tagSENT_CONTENT	restrict\tagSENT_CONTENT	relation_prediction\tagtask	Systems\tagSECTITLE_END	RULE\tagSECTITLE_END	We\tagSENT_START	include\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	rule\tagSENT_CONTENT	baseline\tagSENT_CONTENT	that\tagSENT_CONTENT	predicts\tagSENT_CONTENT	relation_prediction\tagtask	between\tagSENT_CONTENT	sand\tagSENT_CONTENT	tin\tagSENT_END	Association\tagSECTITLE_START	Models\tagSECTITLE_END	The\tagSENT_START	next\tagSENT_CONTENT	group\tagSENT_CONTENT	of\tagSENT_CONTENT	systems\tagSENT_CONTENT	compute\tagSENT_CONTENT	local\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Max\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Margin\tagSECTITLE_CONTENT	Markov\tagSECTITLE_CONTENT	Graph\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	For\tagSENT_START	relation_prediction\tagtask	and\tagSENT_CONTENT	source\tagSENT_CONTENT	(\tagSENT_CONTENT	target\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	K\tagSENT_CONTENT	candidate\tagSENT_CONTENT	targets\tagSENT_CONTENT	(\tagSENT_CONTENT	sources\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	association\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	tune\tagSENT_CONTENT	a\tagSENT_CONTENT	separate\tagSENT_CONTENT	α\tagSENT_CONTENT	r\tagSENT_CONTENT	for\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	's\tagSENT_CONTENT	mean\tagSENT_CONTENT	reciprocal\tagSENT_CONTENT	rank\tagSENT_CONTENT	(\tagSENT_CONTENT	MRR\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Synset\tagSECTITLE_START	Embeddings\tagSECTITLE_END	We\tagSENT_START	apply\tagSENT_CONTENT	this\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	FastText\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	averaging\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	wordforms\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	lemmas\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	synset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	performing\tagSENT_CONTENT	a\tagSENT_CONTENT	caseinsensitive\tagSENT_CONTENT	query\tagSENT_CONTENT	on\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	These\tagSENT_START	proved\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	substantially\tagSENT_CONTENT	weaker\tagSENT_CONTENT	than\tagSENT_CONTENT	distributionally\tagSENT_CONTENT	-\tagSENT_CONTENT	informed\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	report\tagSENT_CONTENT	their\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Setup\tagSECTITLE_END	Following\tagSENT_START	tuning\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	association\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	synset\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	with\tagSENT_CONTENT	d\tagSENT_CONTENT	=\tagSENT_CONTENT	300\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	negative\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	over\tagSENT_CONTENT	10\tagSENT_CONTENT	negative\tagSENT_CONTENT	samples\tagSENT_CONTENT	and\tagSENT_CONTENT	iterating\tagSENT_CONTENT	over\tagSENT_CONTENT	relation_prediction\tagtask	once\tagSENT_CONTENT	every\tagSENT_CONTENT	five\tagSENT_CONTENT	epochs\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Graph\tagSECTITLE_START	Analysis\tagSECTITLE_END	Lines\tagSENT_START	1\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	prefers\tagSENT_CONTENT	abroad\tagSENT_CONTENT	scattering\tagSENT_CONTENT	of\tagSENT_CONTENT	targets\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	member\tagSENT_CONTENT	meronym\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	relation_prediction\tagtask	6\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	flat\tagSENT_CONTENT	and\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	downwards\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	line\tagSENT_CONTENT	4\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	multitude\tagSENT_CONTENT	of\tagSENT_CONTENT	unique\tagSENT_CONTENT	hypernyms\tagSENT_CONTENT	is\tagSENT_CONTENT	undesired\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	expected\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	upwards\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	relation\tagSENT_CONTENT	.\tagSENT_END	in\tagSENT_START	features\tagSENT_CONTENT	3\tagSENT_CONTENT	and\tagSENT_CONTENT	7\tagSENT_CONTENT	we\tagSENT_CONTENT	seethe\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	(\tagSENT_CONTENT	here\tagSENT_CONTENT	derivationally\tagSENT_CONTENT	related\tagSENT_CONTENT	form\tagSENT_CONTENT	and\tagSENT_CONTENT	verb\tagSENT_CONTENT	group\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	manage\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	represented\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	model\tagSENT_CONTENT	despite\tagSENT_CONTENT	not\tagSENT_CONTENT	being\tagSENT_CONTENT	directly\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	α\tagSENT_CONTENT	r\tagSENT_CONTENT	values\tagSENT_CONTENT	weighing\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	M3GM\tagSENT_CONTENT	scores\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_CONTENT	found\tagSENT_CONTENT	per\tagSENT_CONTENT	relation_prediction\tagtask	through\tagSENT_CONTENT	grid\tagSENT_CONTENT	search\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	
1611.05774	title\tagSECTITLE_END	abstract\tagSECTITLE_END	By\tagSENT_START	training\tagSENT_CONTENT	grammars\tagSENT_CONTENT	without\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	phrasal\tagSENT_CONTENT	representations\tagSENT_CONTENT	depend\tagSENT_CONTENT	minimally\tagSENT_CONTENT	on\tagSENT_CONTENT	nonterminals\tagSENT_CONTENT	,\tagSENT_CONTENT	providing\tagSENT_CONTENT	support\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	We\tagSENT_START	talk\tagSENT_CONTENT	about\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	assumptions\tagSENT_CONTENT	and\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	explore\tagSENT_CONTENT	its\tagSENT_CONTENT	parameters\tagSENT_CONTENT	or\tagSENT_CONTENT	posteriors\tagSENT_CONTENT	over\tagSENT_CONTENT	its\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	gain\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	what\tagSENT_CONTENT	it\tagSENT_CONTENT	"\tagSENT_CONTENT	discovers\tagSENT_CONTENT	"\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Their\tagSENT_START	relative\tagSENT_CONTENT	lack\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	while\tagSENT_CONTENT	still\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	a\tagSENT_CONTENT	degree\tagSENT_CONTENT	of\tagSENT_CONTENT	linguistically\tagSENT_CONTENT	-\tagSENT_CONTENT	motivated\tagSENT_CONTENT	prior\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	affords\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	considerable\tagSENT_CONTENT	freedom\tagSENT_CONTENT	to\tagSENT_CONTENT	derive\tagSENT_CONTENT	its\tagSENT_CONTENT	own\tagSENT_CONTENT	insights\tagSENT_CONTENT	about\tagSENT_CONTENT	syntax\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	key\tagSENT_CONTENT	findings\tagSENT_CONTENT	are\tagSENT_CONTENT	that\tagSENT_CONTENT	lexical\tagSENT_CONTENT	heads\tagSENT_CONTENT	play\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	representing\tagSENT_CONTENT	most\tagSENT_CONTENT	phrase\tagSENT_CONTENT	types\tagSENT_CONTENT	(\tagSENT_CONTENT	although\tagSENT_CONTENT	compositions\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	salient\tagSENT_CONTENT	heads\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	infrequent\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	have\tagSENT_CONTENT	less\tagSENT_CONTENT	inductive\tagSENT_CONTENT	bias\tagSENT_CONTENT	relative\tagSENT_CONTENT	to\tagSENT_CONTENT	traditional\tagSENT_CONTENT	unlexicalized\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	free\tagSENT_CONTENT	grammars\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	parse\tagSENT_CONTENT	by\tagSENT_CONTENT	transducing\tagSENT_CONTENT	word\tagSENT_CONTENT	sequences\tagSENT_CONTENT	to\tagSENT_CONTENT	linearized\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	represented\tagSENT_CONTENT	as\tagSENT_CONTENT	strings\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	a\tagSENT_CONTENT	by\tagSENT_CONTENT	-\tagSENT_CONTENT	product\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	investigation\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	without\tagSENT_CONTENT	ensembling\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	reported\tagSENT_CONTENT	supervised\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	structure\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	93.6\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	;\tagSENT_CONTENT	English\tagSENT_CONTENT	PTB\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	through\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	95.8\tagSENT_CONTENT	UAS\tagSENT_CONTENT	,\tagSENT_CONTENT	94.6\tagmetric	LAS\tagmetric	;\tagSENT_CONTENT	PTB\tagSENT_CONTENT	SD\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Recurrent\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	Grammars\tagSECTITLE_END	Unlike\tagSENT_START	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	that\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	rules\tagSENT_CONTENT	to\tagSENT_CONTENT	compose\tagSENT_CONTENT	more\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	phrase\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	implicitly\tagSENT_CONTENT	parameterizes\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	passed\tagSENT_CONTENT	through\tagSENT_CONTENT	compositions\tagSENT_CONTENT	of\tagSENT_CONTENT	phrases\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	Θ\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	weakening\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	classical\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	free\tagSENT_CONTENT	grammars\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	RNNG\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	an\tagSENT_CONTENT	abstract\tagSENT_CONTENT	state\tagSENT_CONTENT	machine\tagSENT_CONTENT	like\tagSENT_CONTENT	those\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	with\tagSENT_CONTENT	its\tagSENT_CONTENT	algorithmic\tagSENT_CONTENT	state\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	partially\tagSENT_CONTENT	completed\tagSENT_CONTENT	constituents\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	buffer\tagSENT_CONTENT	of\tagSENT_CONTENT	already\tagSENT_CONTENT	-\tagSENT_CONTENT	generated\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbols\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	past\tagSENT_CONTENT	actions\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	NT(X\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	X\tagSENT_CONTENT	∈\tagSENT_CONTENT	N\tagSENT_CONTENT	,\tagSENT_CONTENT	introduces\tagSENT_CONTENT	an\tagSENT_CONTENT	open\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	symbol\tagSENT_CONTENT	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	(\tagSENT_CONTENT	NP\tagSENT_CONTENT	"\tagSENT_CONTENT	;\tagSENT_CONTENT	•\tagSENT_CONTENT	GEN(x\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	x\tagSENT_CONTENT	∈\tagSENT_CONTENT	Σ\tagSENT_CONTENT	,\tagSENT_CONTENT	generates\tagSENT_CONTENT	a\tagSENT_CONTENT	terminal\tagSENT_CONTENT	symbol\tagSENT_CONTENT	and\tagSENT_CONTENT	places\tagSENT_CONTENT	it\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	and\tagSENT_CONTENT	buffer\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	•\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	indicates\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	now\tagSENT_CONTENT	complete\tagSENT_CONTENT	.\tagSENT_END	master\tagSENT_START	/\tagSENT_CONTENT	interpreting\tagSENT_CONTENT	-\tagSENT_CONTENT	rnng\tagSENT_CONTENT	3\tagSENT_CONTENT	also\tagSENT_CONTENT	defined\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	only\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	;\tagSENT_CONTENT	here\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	generative\tagSENT_CONTENT	version\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	flexible\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	rather\tagSENT_CONTENT	surprisingly\tagSENT_CONTENT	)\tagSENT_END	This\tagSENT_START	function\tagSENT_CONTENT	computes\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	;\tagSENT_CONTENT	it\tagSENT_CONTENT	also\tagSENT_CONTENT	uses\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	here\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	one\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	can\tagSENT_START	be\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	finding\tagSENT_CONTENT	arg\tagSENT_CONTENT	max\tagSENT_CONTENT	y\tagSENT_CONTENT	p(y\tagSENT_CONTENT	|\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	(\tagSENT_CONTENT	finding\tagSENT_CONTENT	p(x\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	marginalizing\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	for\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Composition\tagSECTITLE_START	is\tagSECTITLE_CONTENT	Key\tagSECTITLE_END	Model\tagSECTITLE_END	Ablated\tagSECTITLE_START	RNNGs\tagSECTITLE_END	We\tagSENT_START	conjecture\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	component\tagSENT_CONTENT	that\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	-\tagSENT_CONTENT	is\tagSENT_CONTENT	critical\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	's\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	buffer\tagSENT_CONTENT	and\tagSENT_CONTENT	action\tagSENT_CONTENT	history\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	trained\tagSENT_CONTENT	each\tagSENT_CONTENT	ablation\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	compared\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	labeled\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	;\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	converting\tagSENT_CONTENT	parse\tagSENT_CONTENT	output\tagSENT_CONTENT	to\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	tool\tagSENT_CONTENT	by\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	This\tagSENT_START	strongly\tagSENT_CONTENT	supports\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	proper\tagSENT_CONTENT	REDUCE\tagSENT_CONTENT	operation\tagSENT_CONTENT	that\tagSENT_CONTENT	transforms\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	label\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	explicit\tagSENT_CONTENT	(\tagSENT_CONTENT	vector\tagSENT_CONTENT	)\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	helpful\tagSENT_CONTENT	to\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	UAS\tagSECTITLE_START	LAS\tagSECTITLE_END	Model\tagSECTITLE_END	Gated\tagSECTITLE_START	Attention\tagSECTITLE_CONTENT	RNNG\tagSECTITLE_END	Linguistic\tagSECTITLE_START	Hypotheses\tagSECTITLE_END	Proposals\tagSENT_START	for\tagSENT_CONTENT	multiple\tagSENT_CONTENT	headed\tagSENT_CONTENT	phrases\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	deal\tagSENT_CONTENT	with\tagSENT_CONTENT	tricky\tagSENT_CONTENT	cases\tagSENT_CONTENT	like\tagSENT_CONTENT	constituency_parsing\tagtask	)\tagSENT_CONTENT	likewise\tagSENT_CONTENT	exist\tagSENT_CONTENT	.\tagSENT_END	Related\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	role\tagSENT_CONTENT	of\tagSENT_CONTENT	heads\tagSENT_CONTENT	in\tagSENT_CONTENT	phrasal\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	of\tagSENT_CONTENT	whether\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	internal\tagSENT_CONTENT	material\tagSENT_CONTENT	wholly\tagSENT_CONTENT	determines\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	(\tagSENT_CONTENT	dependency_parsing\tagtask	)\tagSENT_CONTENT	or\tagSENT_CONTENT	whether\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	relabeling\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	constitutent\tagSENT_CONTENT	introduces\tagSENT_CONTENT	new\tagSENT_CONTENT	information\tagSENT_CONTENT	(\tagSENT_CONTENT	exocentric\tagSENT_CONTENT	representations\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Gated\tagSECTITLE_START	Attention\tagSECTITLE_CONTENT	Composition\tagSECTITLE_END	To\tagSENT_START	investigate\tagSENT_CONTENT	what\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	-\tagSENT_CONTENT	only\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	learns\tagSENT_CONTENT	about\tagSENT_CONTENT	headedness\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	later\tagSENT_CONTENT	endocentricity\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	an\tagSENT_CONTENT	explicit\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	sigmoid\tagSENT_CONTENT	gate\tagSENT_CONTENT	with\tagSENT_CONTENT	multiplicative\tagSENT_CONTENT	interactions\tagSENT_CONTENT	,\tagSENT_CONTENT	henceforth\tagSENT_CONTENT	called\tagSENT_CONTENT	GA\tagSENT_CONTENT	-\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	weighted\tagSENT_CONTENT	sum\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	expressive\tagSENT_CONTENT	than\tagSENT_CONTENT	traditional\tagSENT_CONTENT	head\tagSENT_CONTENT	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	it\tagSENT_CONTENT	allows\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	divided\tagSENT_CONTENT	among\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Head\tagSENT_START	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	conversely\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	analogous\tagSENT_CONTENT	to\tagSENT_CONTENT	giving\tagSENT_CONTENT	all\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	containing\tagSENT_CONTENT	the\tagSENT_CONTENT	lexical\tagSENT_CONTENT	head\tagSENT_CONTENT	.\tagSENT_END	denote\tagSENT_START	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	vector\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	phrase\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	vector\tagSENT_CONTENT	sums\tagSENT_CONTENT	to\tagSENT_CONTENT	one\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	softmax\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	divides\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	unit\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	among\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	constituency_parsing\tagtask	m\tagSENT_CONTENT	=\tagSENT_CONTENT	[\tagSENT_CONTENT	c\tagSENT_CONTENT	1\tagSENT_CONTENT	;\tagSENT_CONTENT	c\tagSENT_CONTENT	2\tagSENT_CONTENT	;\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	]\tagSENT_CONTENT	a\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	convex\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	weighted\tagSENT_CONTENT	by\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	intuition\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	composed\tagSENT_CONTENT	representation\tagSENT_CONTENT	should\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	both\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	through\tagSENT_CONTENT	weighted\tagSENT_CONTENT	sum\tagSENT_CONTENT	and\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	results\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	We\tagSECTITLE_CONTENT	include\tagSECTITLE_CONTENT	this\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	's\tagSECTITLE_CONTENT	performance\tagSECTITLE_CONTENT	in\tagSECTITLE_END	Headedness\tagSECTITLE_START	in\tagSECTITLE_CONTENT	Phrases\tagSECTITLE_END	The\tagSECTITLE_START	Heads\tagSECTITLE_CONTENT	that\tagSECTITLE_CONTENT	GA\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	RNNG\tagSECTITLE_CONTENT	Learns\tagSECTITLE_END	The\tagSENT_START	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	vectors\tagSENT_CONTENT	tell\tagSENT_CONTENT	us\tagmetric	which\tagSENT_CONTENT	constituency_parsing\tagtask	are\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	's\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	comparison\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	uniform\tagSENT_CONTENT	distribution\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	categories\tagSENT_CONTENT	;\tagSENT_CONTENT	this\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	entropy\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	headedness\tagSENT_CONTENT	at\tagSENT_CONTENT	all\tagSENT_CONTENT	by\tagSENT_CONTENT	assigning\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	to\tagSENT_CONTENT	constituency_parsing\tagtask	The\tagSENT_START	syntax\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	standing\tagSENT_CONTENT	source\tagSENT_CONTENT	of\tagSENT_CONTENT	controversy\tagSENT_CONTENT	in\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	attends\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	conjunction\tagSENT_CONTENT	terminal\tagSENT_CONTENT	in\tagSENT_CONTENT	conjunctions\tagSENT_CONTENT	of\tagSENT_CONTENT	verb\tagSENT_CONTENT	phrases\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	VP\tagSENT_CONTENT	→\tagSENT_CONTENT	VP\tagSENT_CONTENT	and\tagSENT_CONTENT	VP\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	10\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	reinforcing\tagSENT_CONTENT	the\tagSENT_CONTENT	similar\tagSENT_CONTENT	finding\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrases\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Existing\tagSECTITLE_CONTENT	Head\tagSECTITLE_CONTENT	Rules\tagSECTITLE_END	To\tagSENT_START	better\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	overlap\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	vectors\tagSENT_CONTENT	and\tagSENT_CONTENT	existing\tagSENT_CONTENT	head\tagSENT_CONTENT	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	converted\tagSENT_CONTENT	the\tagSENT_CONTENT	trees\tagSENT_CONTENT	in\tagSENT_CONTENT	PTB\tagSENT_CONTENT	§\tagSENT_CONTENT	23\tagSENT_CONTENT	into\tagSENT_CONTENT	dependency_parsing\tagtask	using\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	weights\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	higher\tagSENT_CONTENT	overlap\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	conversion\tagSENT_CONTENT	using\tagSENT_CONTENT	Collins\tagSENT_CONTENT	head\tagSENT_CONTENT	rules\tagSENT_CONTENT	(\tagSENT_CONTENT	49.8\tagmetric	UAS\tagmetric	)\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	head\tagSENT_CONTENT	rules\tagSENT_CONTENT	(\tagSENT_CONTENT	40.4\tagmetric	UAS\tagmetric	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	general\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	tree\tagSENT_CONTENT	output\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	error\tagSENT_CONTENT	rate\tagSENT_CONTENT	(\tagSENT_CONTENT	≈\tagSENT_CONTENT	90\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	when\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	verb\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	constituent\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	verb\tagSENT_CONTENT	phrase\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	the\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrase\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	verb\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	discussed\tagSENT_CONTENT	above\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	leave\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	this\tagSENT_CONTENT	noun\tagSENT_CONTENT	-\tagSENT_CONTENT	centered\tagSENT_CONTENT	verb\tagSENT_CONTENT	phrase\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	to\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Role\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Nonterminal\tagSECTITLE_CONTENT	Labels\tagSECTITLE_END	We\tagSENT_START	therefore\tagSENT_CONTENT	expect\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	that\tagSENT_CONTENT	the\tagSENT_CONTENT	U\tagSENT_CONTENT	-\tagSENT_CONTENT	GA\tagSENT_CONTENT	-\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	correctly\tagSENT_CONTENT	recovers\tagSENT_CONTENT	(\tagSENT_CONTENT	on\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	)\tagSENT_CONTENT	will\tagSENT_CONTENT	capture\tagSENT_CONTENT	categories\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	those\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Our\tagSENT_START	experiment\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	was\tagSENT_CONTENT	motivated\tagSENT_CONTENT	by\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	achieved\tagSENT_CONTENT	constituency_parsing\tagtask	without\tagSENT_CONTENT	explicit\tagSENT_CONTENT	composition\tagSENT_CONTENT	.\tagSENT_END	Extensive\tagSENT_START	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency_parsing\tagtask	typically\tagSENT_CONTENT	employs\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	free\tagSENT_CONTENT	grammar\tagSENT_CONTENT	formalism\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	lexicalized\tagSENT_CONTENT	(\tagSENT_CONTENT	Collins\tagSENT_CONTENT	,\tagSENT_CONTENT	1997\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	augmentations\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	GA\tagSENT_CONTENT	-\tagSENT_CONTENT	RNNG\tagSENT_CONTENT	allows\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	divided\tagSENT_CONTENT	among\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	essentially\tagSENT_CONTENT	propagating\tagSENT_CONTENT	(\tagSENT_CONTENT	weighted\tagSENT_CONTENT	)\tagSENT_CONTENT	headedness\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	multiple\tagSENT_CONTENT	components\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	
1806.00187	title\tagSECTITLE_END	Scaling\tagSENT_START	machine_translation\tagtask	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	reduced\tagSENT_CONTENT	precision\tagSENT_CONTENT	and\tagSENT_CONTENT	machine_translation\tagtask	can\tagSENT_CONTENT	speedup\tagSENT_CONTENT	training\tagSENT_CONTENT	by\tagSENT_CONTENT	nearly\tagSENT_CONTENT	5x\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	8-GPU\tagSENT_CONTENT	machine\tagSENT_CONTENT	with\tagSENT_CONTENT	careful\tagSENT_CONTENT	tuning\tagSENT_CONTENT	and\tagSENT_CONTENT	implementation\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	machine_translation\tagtask	(\tagSENT_CONTENT	NMT\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	seen\tagSENT_CONTENT	impressive\tagSENT_CONTENT	progress\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	introduction\tagSENT_CONTENT	of\tagSENT_CONTENT	evermore\tagSENT_CONTENT	efficient\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	stragglers\tagSENT_CONTENT	primarily\tagSENT_CONTENT	affect\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	questions\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	large\tagSENT_CONTENT	batch\tagSENT_CONTENT	training\tagSENT_CONTENT	are\tagSENT_CONTENT	relevant\tagSENT_CONTENT	even\tagSENT_CONTENT	for\tagSENT_CONTENT	users\tagSENT_CONTENT	of\tagSENT_CONTENT	commodity\tagSENT_CONTENT	hardware\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	machine\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	as\tagSENT_CONTENT	such\tagSENT_CONTENT	hardware\tagSENT_CONTENT	continues\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	,\tagSENT_CONTENT	enabling\tagSENT_CONTENT	bigger\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	batch\tagSENT_CONTENT	sizes\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	assess\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	dramatically\tagSENT_CONTENT	increasing\tagSENT_CONTENT	the\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	from\tagSENT_CONTENT	25k\tagSENT_CONTENT	to\tagSENT_CONTENT	over\tagSENT_CONTENT	400k\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	necessary\tagSENT_CONTENT	condition\tagSENT_CONTENT	for\tagSENT_CONTENT	machine_translation\tagtask	with\tagSENT_CONTENT	synchronous\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Distributed\tagSENT_START	training\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	follows\tagSENT_CONTENT	machine_translation\tagtask	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	model\tagSENT_CONTENT	parallel\tagSENT_CONTENT	evaluates\tagSENT_CONTENT	different\tagSENT_CONTENT	model\tagSENT_CONTENT	layers\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	workers\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	data\tagSENT_CONTENT	parallel\tagSENT_CONTENT	keeps\tagSENT_CONTENT	a\tagSENT_CONTENT	copy\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	worker\tagSENT_CONTENT	but\tagSENT_CONTENT	distributes\tagSENT_CONTENT	different\tagSENT_CONTENT	batches\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	machines\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Compared\tagSENT_START	to\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	LM\tagSENT_CONTENT	training\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	face\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	challenges\tagSENT_CONTENT	of\tagSENT_CONTENT	variable\tagSENT_CONTENT	batch\tagSENT_CONTENT	sizes\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	discard\tagSENT_CONTENT	any\tagSENT_CONTENT	computation\tagSENT_CONTENT	done\tagSENT_CONTENT	by\tagSENT_CONTENT	workers\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Datasets\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	of\tagSENT_CONTENT	32\tagSENT_CONTENT	K\tagSENT_CONTENT	symbols\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	source\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	byte\tagSENT_CONTENT	pair\tagSENT_CONTENT	encoding\tagSENT_CONTENT	(\tagSENT_CONTENT	BPE\tagmetric	;\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	beyond\tagSENT_CONTENT	36\tagSENT_CONTENT	M\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Paracrawl\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Hyperparameters\tagSECTITLE_END	We\tagSENT_START	include\tagSENT_CONTENT	residual\tagSENT_CONTENT	connections\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	after\tagSENT_CONTENT	machine_translation\tagtask	and\tagSENT_CONTENT	after\tagSENT_CONTENT	the\tagSENT_CONTENT	combined\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	apply\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	after\tagSENT_CONTENT	each\tagSENT_CONTENT	residual\tagSENT_CONTENT	connection\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	we\tagSENT_CONTENT	present\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	improving\tagSENT_CONTENT	training\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	via\tagSENT_CONTENT	reduced\tagSENT_CONTENT	precision\tagSENT_CONTENT	floating\tagSENT_CONTENT	point\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	larger\tagSENT_CONTENT	batches\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.2\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	multiple\tagSENT_CONTENT	nodes\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	distributed\tagSENT_CONTENT	setting\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Half\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Precision\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	weights\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	available\tagSENT_CONTENT	in\tagSENT_CONTENT	full\tagSENT_CONTENT	precision\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	and\tagSENT_CONTENT	optimization\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	momentum\tagSENT_CONTENT	,\tagSENT_CONTENT	weight\tagSENT_CONTENT	updates\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	FP32\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Larger\tagSECTITLE_CONTENT	Batches\tagSECTITLE_END	shows\tagSENT_START	that\tagSENT_CONTENT	bigger\tagSENT_CONTENT	batches\tagSENT_CONTENT	result\tagSENT_CONTENT	in\tagSENT_CONTENT	slower\tagSENT_CONTENT	initial\tagSENT_CONTENT	convergence\tagSENT_CONTENT	when\tagSENT_CONTENT	measured\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	epochs\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	passes\tagSENT_CONTENT	over\tagSENT_CONTENT	machine_translation\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	results\tagSENT_CONTENT	support\tagSENT_CONTENT	machine_translation\tagtask	since\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	steps\tagSENT_CONTENT	define\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	synchronization\tagSENT_CONTENT	points\tagSENT_CONTENT	for\tagSENT_CONTENT	synchronous\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Parallel\tagSECTITLE_START	Training\tagSECTITLE_END	While\tagSENT_START	machine_translation\tagtask	improves\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	even\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	node\tagSENT_CONTENT	,\tagSENT_CONTENT	another\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	large\tagSENT_CONTENT	batches\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	easily\tagSENT_CONTENT	parallelized\tagSENT_CONTENT	across\tagSENT_CONTENT	multiple\tagSENT_CONTENT	nodes\tagSENT_CONTENT	(\tagSENT_CONTENT	machines\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	En\tagSECTITLE_START	-\tagSECTITLE_CONTENT	De\tagSECTITLE_END	Results\tagSECTITLE_START	with\tagSECTITLE_CONTENT	WMT\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	Table\tagmetric	2\tagSENT_CONTENT	reports\tagSENT_CONTENT	29.3\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	for\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	De\tagSENT_CONTENT	in\tagSENT_CONTENT	1h\tagSENT_CONTENT	25min\tagSENT_CONTENT	and\tagSENT_CONTENT	43.2\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	for\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	Fr\tagSENT_CONTENT	in\tagSENT_CONTENT	8h\tagSENT_CONTENT	32min\tagSENT_CONTENT	.\tagSENT_END	Train\tagSECTITLE_START	set\tagSECTITLE_END	Results\tagSECTITLE_START	with\tagSECTITLE_CONTENT	WMT\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	Paracrawl\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	Paracrawl\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	recent\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	4B\tagSENT_CONTENT	parallel\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	language\tagSENT_CONTENT	pair\tagSENT_CONTENT	(\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	De\tagSENT_CONTENT	and\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	Fr\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	machine_translation\tagtask	for\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	De\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	sampling\tagSENT_CONTENT	ratios\tagSENT_CONTENT	of\tagSENT_CONTENT	WMT\tagSENT_CONTENT	and\tagSENT_CONTENT	filtered\tagSENT_CONTENT	Paracrawl\tagSENT_CONTENT	data\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	Paracrawl\tagSENT_CONTENT	improves\tagSENT_CONTENT	BLEU\tagmetric	on\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	De\tagSENT_CONTENT	to\tagSENT_CONTENT	29.8\tagSENT_CONTENT	but\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	for\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	Fr\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	just\tagSENT_CONTENT	42.1\tagSENT_CONTENT	vs.\tagSENT_CONTENT	43.2\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Stragglers\tagSECTITLE_END	In\tagSENT_START	Section\tagSENT_CONTENT	4.2\tagSENT_CONTENT	we\tagSENT_CONTENT	observed\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	could\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	variance\tagSENT_CONTENT	between\tagSENT_CONTENT	workers\tagSENT_CONTENT	by\tagSENT_CONTENT	accumulating\tagSENT_CONTENT	the\tagSENT_CONTENT	gradients\tagSENT_CONTENT	over\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	worker\tagSENT_CONTENT	before\tagSENT_CONTENT	updating\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	machine_translation\tagtask	in\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	one\tagSENT_CONTENT	takes\tagSENT_CONTENT	approximately\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	processing\tagSENT_CONTENT	time\tagSENT_CONTENT	across\tagSENT_CONTENT	all\tagSENT_CONTENT	workers\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	Our\tagSENT_START	careful\tagSENT_CONTENT	implementation\tagSENT_CONTENT	speeds\tagSENT_CONTENT	up\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	big\tagSENT_CONTENT	transformer\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	by\tagSENT_CONTENT	nearly\tagSENT_CONTENT	5x\tagSENT_CONTENT	on\tagSENT_CONTENT	one\tagSENT_CONTENT	machine\tagSENT_CONTENT	with\tagSENT_CONTENT	8\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	WMT'14\tagSENT_CONTENT	En\tagSENT_CONTENT	-\tagSENT_CONTENT	De\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	29.3\tagmetric	BLEU\tagmetric	vs.\tagSENT_CONTENT	29.2\tagSENT_CONTENT	for\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	setup\tagSENT_CONTENT	,\tagSENT_CONTENT	training\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	85\tagSENT_CONTENT	minutes\tagSENT_CONTENT	on\tagSENT_CONTENT	128\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	note\tagSENT_CONTENT	that\tagSENT_CONTENT	machine_translation\tagtask	still\tagSENT_CONTENT	incurs\tagSENT_CONTENT	a\tagSENT_CONTENT	significant\tagSENT_CONTENT	overhead\tagSENT_CONTENT	:\tagSENT_CONTENT	16-node\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	∼10x\tagSENT_CONTENT	faster\tagSENT_CONTENT	than\tagSENT_CONTENT	1-node\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	
S18-1147	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	A\tagSENT_START	hypernym\tagSENT_CONTENT	detection\tagSENT_CONTENT	system\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	taxonomy_learning\tagtask	and\tagSENT_CONTENT	lexical\tagSENT_CONTENT	semantics\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	pattern\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	Hyponym\tagSECTITLE_END	System\tagSECTITLE_START	Overview\tagSECTITLE_END	Embedding\tagSECTITLE_END	Hypernym\tagSECTITLE_START	Learning\tagSECTITLE_END	Previous\tagSENT_START	work\tagSENT_CONTENT	like\tagSENT_CONTENT	TAXOEMBED\tagSENT_CONTENT	(\tagSENT_CONTENT	EspinosaAnke\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2016a\tagSENT_CONTENT	)\tagSENT_CONTENT	uses\tagSENT_CONTENT	transformation\tagSENT_CONTENT	matrix\tagSENT_CONTENT	for\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	not\tagSENT_CONTENT	optimal\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	lack\tagSENT_CONTENT	of\tagSENT_CONTENT	deeper\tagSENT_CONTENT	nonlinear\tagSENT_CONTENT	feature\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	discriminative\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	maxmargin\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	taxonomy_learning\tagtask	(\tagSENT_CONTENT	or\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	)\tagSENT_END	Experiment\tagSECTITLE_END	Setting\tagSECTITLE_END	Mean\tagSENT_START	Average\tagSENT_CONTENT	Precision\tagSENT_CONTENT	(\tagmetric	MAP\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Reciprocal\tagSENT_CONTENT	Rank\tagSENT_CONTENT	(\tagmetric	MRR\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Precision\tagSENT_CONTENT	at\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	P@1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Precision\tagSENT_CONTENT	at\tagSENT_CONTENT	3\tagSENT_CONTENT	(\tagmetric	P@3\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Precision\tagSENT_CONTENT	at\tagSENT_CONTENT	5\tagSENT_CONTENT	(\tagmetric	P@5\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Precision\tagSENT_CONTENT	at\tagSENT_CONTENT	15\tagSENT_CONTENT	(\tagSENT_CONTENT	P@15\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Result\tagSECTITLE_START	and\tagSECTITLE_CONTENT	analysis\tagSECTITLE_END	Conclusion\tagSECTITLE_END	References\tagSECTITLE_END	
1808.10792	title\tagSECTITLE_END	summarization\tagtask	abstract\tagSECTITLE_END	This\tagSENT_START	two\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	process\tagSENT_CONTENT	is\tagSENT_CONTENT	both\tagSENT_CONTENT	simpler\tagSENT_CONTENT	and\tagSENT_CONTENT	higher\tagSENT_CONTENT	performing\tagSENT_CONTENT	than\tagSENT_CONTENT	other\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	on\tagSENT_CONTENT	ROUGE\tagmetric	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	DM\tagSENT_CONTENT	and\tagSENT_CONTENT	NYT\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	summaries\tagSENT_CONTENT	that\tagSENT_CONTENT	compress\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	longer\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	is\tagSENT_CONTENT	an\tagSENT_CONTENT	appeal\tagSENT_CONTENT	to\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	models\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	modeling\tagSENT_CONTENT	perspective\tagSENT_CONTENT	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	evidence\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	summarization\tagtask	follow\tagSENT_CONTENT	a\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_END	Source\tagSECTITLE_START	Document\tagSECTITLE_END	the\tagSENT_START	chancellor\tagSENT_CONTENT	and\tagSENT_CONTENT	her\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	spending\tagSENT_CONTENT	easter\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	small\tagSENT_CONTENT	island\tagSENT_CONTENT	of\tagSENT_CONTENT	ischia\tagSENT_CONTENT	,\tagSENT_CONTENT	near\tagSENT_CONTENT	naples\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	mediterranean\tagSENT_CONTENT	for\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	[\tagSENT_CONTENT	not\tagSENT_CONTENT	so\tagSENT_CONTENT	sunny\tagSENT_CONTENT	:\tagSENT_CONTENT	]\tagSENT_END	Reference\tagSECTITLE_END	Baseline\tagSECTITLE_START	Approach\tagSECTITLE_END	Bottom\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Up\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	Motivated\tagSENT_START	by\tagSENT_CONTENT	this\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	attention\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	To\tagSENT_START	incorporate\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	attention\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	masking\tagSENT_CONTENT	to\tagSENT_CONTENT	constrain\tagSENT_CONTENT	copying\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	selected\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	produces\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	outputs\tagSENT_CONTENT	.\tagSENT_END	Compared\tagSENT_START	to\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	attention\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE\tagmetric	-\tagmetric	L\tagmetric	score\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	DM\tagSENT_CONTENT	)\tagSENT_CONTENT	corpus\tagSENT_CONTENT	from\tagSENT_CONTENT	36.4\tagSENT_CONTENT	to\tagSENT_CONTENT	38.3\tagSENT_CONTENT	while\tagSENT_CONTENT	being\tagSENT_CONTENT	simpler\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	There\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	tension\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	between\tagSENT_CONTENT	staying\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	allowing\tagSENT_CONTENT	compressive\tagSENT_CONTENT	or\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	modification\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	methods\tagSENT_CONTENT	often\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	extract\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	summarization\tagtask	at\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	level\tagSENT_CONTENT	requires\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	grammatically\tagSENT_CONTENT	correct\tagSENT_CONTENT	output\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	difficult\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	third\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	recently\tagSENT_CONTENT	,\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	(\tagSENT_CONTENT	RL\tagSENT_CONTENT	)\tagSENT_CONTENT	approaches\tagSENT_CONTENT	that\tagSENT_CONTENT	optimize\tagSENT_CONTENT	objectives\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	other\tagSENT_CONTENT	than\tagSENT_CONTENT	maximum\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	relevant\tagSENT_CONTENT	sections\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	keywords\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	guide\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Pasunuru\tagSENT_CONTENT	and\tagSENT_CONTENT	Bansal\tagSENT_CONTENT	(\tagSENT_CONTENT	2018\tagSENT_CONTENT	)\tagSENT_CONTENT	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	loss\tagSENT_CONTENT	-\tagSENT_CONTENT	function\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	whether\tagSENT_CONTENT	salient\tagSENT_CONTENT	keywords\tagSENT_CONTENT	are\tagSENT_CONTENT	included\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	Y\tagSENT_START	to\tagSENT_CONTENT	summarization\tagtask	Following\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	model\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	an\tagSENT_CONTENT	attentional\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Bottom\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Up\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	We\tagSENT_START	next\tagSENT_CONTENT	consider\tagSENT_CONTENT	techniques\tagSENT_CONTENT	for\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	a\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Content\tagSECTITLE_START	Selection\tagSECTITLE_END	While\tagSENT_START	there\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	significant\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	see\tagSENT_CONTENT	related\tagSENT_CONTENT	work\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	a\tagSENT_CONTENT	simplifying\tagSENT_CONTENT	assumption\tagSENT_CONTENT	and\tagSENT_CONTENT	treat\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	can\tagSENT_CONTENT	then\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	q\tagSENT_CONTENT	i\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagmetric	word\tagmetric	is\tagSENT_CONTENT	selected\tagSENT_CONTENT	as\tagSENT_CONTENT	σ(W\tagSENT_CONTENT	sh\tagSENT_CONTENT	i\tagSENT_CONTENT	+\tagSENT_CONTENT	b\tagSENT_CONTENT	s\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	trainable\tagSENT_CONTENT	parameters\tagSENT_CONTENT	W\tagSENT_CONTENT	sand\tagSENT_CONTENT	b\tagSENT_CONTENT	s\tagSENT_CONTENT	.\tagSENT_END	Bottom\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Up\tagSECTITLE_CONTENT	Copy\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	While\tagSENT_START	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	attention\tagSENT_CONTENT	could\tagSENT_CONTENT	also\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	modify\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	encoder\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	standard\tagSENT_CONTENT	encoder\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	text\tagSENT_CONTENT	was\tagSENT_CONTENT	effective\tagSENT_CONTENT	at\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	limit\tagSENT_CONTENT	the\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	step\tagSENT_CONTENT	to\tagSENT_CONTENT	attention\tagSENT_CONTENT	masking\tagSENT_CONTENT	.\tagSENT_END	End\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	End\tagSECTITLE_CONTENT	Alternatives\tagSECTITLE_END	In\tagSENT_START	theory\tagmetric	,\tagSENT_CONTENT	though\tagSENT_CONTENT	,\tagSENT_CONTENT	standard\tagSENT_CONTENT	copy\tagSENT_CONTENT	attention\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Method\tagSENT_START	1\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	MASK\tagSENT_CONTENT	ONLY\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_CONTENT	We\tagSENT_CONTENT	first\tagSENT_CONTENT	consider\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	alignment\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	bottom\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	approach\tagSENT_CONTENT	could\tagSENT_CONTENT	help\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Method\tagmetric	3\tagSENT_CONTENT	(\tagSENT_CONTENT	DIFFMASK\tagSENT_CONTENT	)\tagSENT_END	Inference\tagSECTITLE_END	Length\tagSENT_START	:\tagSENT_CONTENT	To\tagSENT_CONTENT	encourage\tagSENT_CONTENT	the\tagSENT_CONTENT	generation\tagSENT_CONTENT	of\tagSENT_CONTENT	longer\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	summarization\tagtask	during\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	selecting\tagSENT_CONTENT	a\tagSENT_CONTENT	sufficiently\tagSENT_CONTENT	high\tagSENT_CONTENT	β\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	penalty\tagSENT_CONTENT	blocks\tagSENT_CONTENT	summarization\tagtask	whenever\tagSENT_CONTENT	they\tagSENT_CONTENT	would\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	repetitions\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	DM\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	NYT\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	both\tagSENT_CONTENT	standard\tagSENT_CONTENT	corpora\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	We\tagSENT_START	limit\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	examples\tagSENT_CONTENT	to\tagSENT_CONTENT	100,000\tagSENT_CONTENT	on\tagSENT_CONTENT	either\tagmetric	corpus\tagmetric	,\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	impact\tagSENT_CONTENT	on\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	have\tagSENT_CONTENT	a\tagSENT_CONTENT	comparable\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagmetric	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	with\tagSENT_CONTENT	256\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	directions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	512\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	decoder\tagSENT_CONTENT	.\tagSENT_END	2017\tagSENT_START	)\tagSENT_CONTENT	can\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	slightly\tagSENT_CONTENT	improved\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	increased\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	parameters\tagmetric	.\tagSENT_END	All\tagSENT_START	inference\tagSENT_CONTENT	parameters\tagSENT_CONTENT	are\tagSENT_CONTENT	tuned\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	200\tagSENT_CONTENT	example\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	While\tagSENT_START	we\tagSENT_CONTENT	would\tagSENT_CONTENT	expect\tagSENT_CONTENT	better\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	to\tagSENT_CONTENT	primarily\tagSENT_CONTENT	improve\tagSENT_CONTENT	ROUGE-1\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	all\tagSENT_CONTENT	three\tagSENT_CONTENT	increase\tagSENT_CONTENT	hints\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	fluency\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	being\tagSENT_CONTENT	hurt\tagSENT_CONTENT	specifically\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	main\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	seems\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	reduction\tagSENT_CONTENT	of\tagSENT_CONTENT	mistakenly\tagSENT_CONTENT	copied\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	further\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	domain\tagSENT_CONTENT	transfer\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	The\tagSENT_START	LEAD-3\tagSENT_CONTENT	baseline\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	baseline\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	extracts\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	three\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	an\tagSENT_CONTENT	  \tagSENT_CONTENT	article\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	Pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	Generator\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	abstract\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	copy\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	causes\tagSENT_CONTENT	the\tagSENT_CONTENT	summaries\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	mostly\tagSENT_CONTENT	extractive\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	further\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	unmodified\tagSENT_CONTENT	Pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	Generator\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	already\tagSENT_CONTENT	learned\tagSENT_CONTENT	an\tagSENT_CONTENT	appropriate\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	is\tagSENT_CONTENT	limited\tagSENT_CONTENT	by\tagSENT_CONTENT	its\tagSENT_CONTENT	ineffective\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	and\tagSENT_CONTENT	inference\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_END	Conclusion\tagSECTITLE_END	This\tagSENT_START	work\tagSENT_CONTENT	presents\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	but\tagSENT_CONTENT	accurate\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	identifies\tagSENT_CONTENT	phrases\tagSENT_CONTENT	within\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	likely\tagSENT_CONTENT	included\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Examples\tagSECTITLE_END	Generated\tagSECTITLE_START	summary\tagSECTITLE_END	A\tagSECTITLE_START	Domain\tagSECTITLE_CONTENT	Transfer\tagSECTITLE_CONTENT	Examples\tagSECTITLE_END	S2S\tagSENT_START	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	Pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	Generator\tagSENT_CONTENT	with\tagSENT_CONTENT	Coverage\tagSENT_CONTENT	Penalty\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	DM\tagSENT_CONTENT	that\tagSENT_CONTENT	scores\tagSENT_CONTENT	20.6\tagmetric	ROUGE\tagmetric	-\tagmetric	L\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	NYT\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	
P15-2047	title\tagSECTITLE_END	A\tagSENT_START	Dependency\tagSENT_CONTENT	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	abstract\tagSECTITLE_END	Previous\tagSENT_START	research\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	has\tagSENT_CONTENT	verified\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	dependency\tagSENT_CONTENT	shortest\tagSENT_CONTENT	paths\tagSENT_CONTENT	or\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	vital\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	unstructured\tagSENT_CONTENT	texts\tagSENT_CONTENT	and\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	step\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	dependency\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	previous\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	carefully\tagSENT_CONTENT	selected\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	extended\tagSENT_CONTENT	some\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	high\tagSENT_CONTENT	order\tagSENT_CONTENT	features\tagSENT_CONTENT	*\tagSENT_CONTENT	Contribution\tagSENT_CONTENT	during\tagSENT_CONTENT	internship\tagSENT_CONTENT	at\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	ways\tagSENT_CONTENT	.\tagSENT_END	designed\tagSENT_START	a\tagSENT_CONTENT	dependency\tagSENT_CONTENT	tree\tagSENT_CONTENT	kernel\tagSENT_CONTENT	and\tagSENT_CONTENT	attached\tagSENT_CONTENT	relationship_extraction\tagtask	including\tagSENT_CONTENT	Part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	Speech\tagSENT_CONTENT	tag\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagSENT_CONTENT	tag\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	node\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	tree\tagSENT_CONTENT	.\tagSENT_END	Interestingly\tagSENT_START	,\tagSENT_CONTENT	provided\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	insight\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	path\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	dependency\tagSENT_CONTENT	graph\tagSENT_CONTENT	concentrates\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	identifying\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSENT_START	work\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	useful\tagSENT_CONTENT	dependency\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	includes\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	two\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	serve\tagSENT_CONTENT	different\tagSENT_CONTENT	functions\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	collaboration\tagSENT_CONTENT	can\tagSENT_CONTENT	boost\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	for\tagSENT_CONTENT	detailed\tagSENT_CONTENT	examples\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	techniques\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	exploring\tagSENT_CONTENT	relationship_extraction\tagtask	behind\tagSENT_CONTENT	complex\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RN\tagSENT_CONTENT	-\tagSENT_CONTENT	N\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	extracting\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	RNN\tagSENT_CONTENT	is\tagSENT_CONTENT	good\tagSENT_CONTENT	at\tagSENT_CONTENT	modeling\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	path\tagSENT_START	is\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	its\tagSENT_CONTENT	subtree\tagSENT_CONTENT	,\tagSENT_CONTENT	strengthening\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	path\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	augmented\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	is\tagSENT_CONTENT	represented\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	continuous\tagSENT_CONTENT	semantic\tagSENT_CONTENT	vector\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	further\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Problem\tagSECTITLE_START	Definition\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Motivation\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	first\tagSENT_START	used\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	paths\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	sequences\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	thief←broke→screwdriver\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	provide\tagSENT_CONTENT	strong\tagSENT_CONTENT	evidence\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	paths\tagSENT_CONTENT	contain\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	attached\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	node\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	path\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	exploited\tagSENT_CONTENT	enough\tagSENT_CONTENT	.\tagSENT_END	Based\tagSENT_START	on\tagSENT_CONTENT	many\tagSENT_CONTENT	observations\tagSENT_CONTENT	like\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	idea\tagSENT_CONTENT	that\tagSENT_CONTENT	combines\tagSENT_CONTENT	the\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	path\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	precise\tagSENT_CONTENT	structure\tagSENT_CONTENT	for\tagSENT_CONTENT	classifying\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Dependency\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	introduce\tagSENT_CONTENT	how\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	techniques\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	word\tagSENT_CONTENT	won\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	develop\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	from\tagSENT_CONTENT	its\tagSENT_CONTENT	leaf\tagSENT_CONTENT	words\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	root\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	subtree\tagSENT_CONTENT	embedding\tagSENT_CONTENT	cw\tagSENT_CONTENT	and\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	cw\tagSENT_CONTENT	with\tagSENT_CONTENT	x\tagSENT_CONTENT	w\tagSENT_CONTENT	to\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	w.\tagSENT_CONTENT	Next\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	is\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Finally\tagSENT_START	our\tagSENT_CONTENT	framework\tagSENT_CONTENT	can\tagSENT_CONTENT	efficiently\tagSENT_CONTENT	represent\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	more\tagSENT_CONTENT	comprehensive\tagSENT_CONTENT	dependency\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Modeling\tagSECTITLE_START	Dependency\tagSECTITLE_CONTENT	Subtree\tagSECTITLE_END	Modeling\tagSECTITLE_START	Shortest\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Path\tagSECTITLE_END	A\tagSENT_START	CNN\tagSENT_CONTENT	contains\tagSENT_CONTENT	relationship_extraction\tagtask	over\tagSENT_CONTENT	a\tagSENT_CONTENT	window\tagSENT_CONTENT	of\tagSENT_CONTENT	object\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	concatenate\tagSENT_CONTENT	k\tagSENT_CONTENT	neighboring\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	dependency\tagSENT_CONTENT	relations\tagSENT_CONTENT	)\tagSENT_CONTENT	relationship_extraction\tagtask	into\tagSENT_CONTENT	anew\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	involves\tagSENT_CONTENT	a\tagSENT_CONTENT	filter\tagSENT_CONTENT	W\tagSENT_CONTENT	1\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	l×(dim·k+dimc·nw\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	operates\tagSENT_CONTENT	on\tagSENT_CONTENT	X\tagSENT_CONTENT	i\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	anew\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	Li\tagSENT_CONTENT	with\tagSENT_CONTENT	l\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	,\tagSENT_END	Learning\tagSECTITLE_END	We\tagSENT_START	then\tagSENT_CONTENT	pass\tagSENT_CONTENT	M\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	fully\tagSENT_CONTENT	connected\tagSENT_CONTENT	sof\tagSENT_CONTENT	tmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	whose\tagSENT_CONTENT	output\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	y\tagSENT_CONTENT	over\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	There\tagSENT_START	are\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	each\tagSENT_CONTENT	type\tagSENT_CONTENT	has\tagSENT_CONTENT	two\tagSENT_CONTENT	directions\tagSENT_CONTENT	.\tagSENT_END	Contributions\tagSECTITLE_START	of\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	components\tagSECTITLE_END	The\tagSENT_START	results\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	parts\tagSENT_CONTENT	are\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Model\tagSECTITLE_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Baselines\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	DepNN\tagSENT_CONTENT	with\tagSENT_CONTENT	several\tagSENT_CONTENT	baseline\tagSENT_CONTENT	relation\tagSENT_CONTENT	classification\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	had\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	larger\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	tags\tagSENT_CONTENT	may\tagSENT_CONTENT	cause\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	,\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	paths\tagSENT_CONTENT	and\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	play\tagSENT_CONTENT	different\tagSENT_CONTENT	roles\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	by\tagSENT_CONTENT	modeling\tagSENT_CONTENT	the\tagSENT_CONTENT	augmented\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	290\tagSECTITLE_END	
N18-1064	title\tagSECTITLE_END	Entity\tagSENT_START	Commonsense\tagSENT_CONTENT	Representation\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	and\tagSENT_CONTENT	concise\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	while\tagSENT_CONTENT	preserving\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	entities\tagSENT_CONTENT	found\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	miti\tagSENT_CONTENT	-\tagSENT_CONTENT	gating\tagSENT_CONTENT	the\tagSENT_CONTENT	aforementioned\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	experiment\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	Gigaword\tagdataset	and\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	varying\tagSENT_CONTENT	lengths\tagSENT_CONTENT	.\tagSENT_END	Usefulness\tagSECTITLE_START	of\tagSECTITLE_CONTENT	linked\tagSECTITLE_CONTENT	entities\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	summarization\tagSECTITLE_END	Observations\tagSECTITLE_END	As\tagSENT_START	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	three\tagSENT_CONTENT	observations\tagSENT_CONTENT	that\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	usefulness\tagSENT_CONTENT	of\tagSENT_CONTENT	linked\tagSENT_CONTENT	entities\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Possible\tagSECTITLE_START	issues\tagSECTITLE_END	Also\tagSENT_START	,\tagSENT_CONTENT	"\tagSENT_CONTENT	swap\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	irrelevant\tagSENT_CONTENT	because\tagSENT_CONTENT	although\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	linked\tagSENT_CONTENT	correctly\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	"\tagSENT_CONTENT	Trade\tagSENT_CONTENT	(\tagSENT_CONTENT	Sports\tagSENT_CONTENT	)\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	too\tagSENT_CONTENT	common\tagSENT_CONTENT	and\tagSENT_CONTENT	irrelevant\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Our\tagSECTITLE_START	model\tagSECTITLE_END	Base\tagSECTITLE_START	model\tagSECTITLE_END	As\tagSENT_START	our\tagSENT_CONTENT	base\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	a\tagSENT_CONTENT	basic\tagSENT_CONTENT	encoderdecoder\tagSENT_CONTENT	RNN\tagSENT_CONTENT	used\tagSENT_CONTENT	inmost\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Input\tagSECTITLE_START	Text\tagSECTITLE_END	Entity\tagSECTITLE_START	List\tagSECTITLE_END	①\tagSECTITLE_START	/wiki\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Los_Angeles_Dodgers\tagSECTITLE_END	Entity\tagSECTITLE_START	encoding\tagSECTITLE_CONTENT	submodule\tagSECTITLE_END	The\tagSENT_START	RNN\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	good\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	smartly\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	it\tagSENT_CONTENT	may\tagSENT_CONTENT	perform\tagSENT_CONTENT	bad\tagSENT_CONTENT	when\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	many\tagSENT_CONTENT	entities\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	introduces\tagSENT_CONTENT	noise\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	afar\tagSENT_CONTENT	entity\tagSENT_CONTENT	during\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	When\tagSENT_START	a\tagSENT_CONTENT	correctly\tagSENT_CONTENT	linked\tagSENT_CONTENT	and\tagSENT_CONTENT	already\tagSENT_CONTENT	adequately\tagSENT_CONTENT	disambiguated\tagSENT_CONTENT	entity\tagSENT_CONTENT	is\tagSENT_CONTENT	disambiguated\tagSENT_CONTENT	again\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	would\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	very\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	and\tagSENT_CONTENT	might\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Pooling\tagSECTITLE_START	submodule\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	not\tagSENT_CONTENT	all\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	important\tagSENT_CONTENT	and\tagSENT_CONTENT	necessary\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	The\tagSENT_START	value\tagSENT_CONTENT	k\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	lengths\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Extending\tagSECTITLE_START	from\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	base\tagSECTITLE_CONTENT	model\tagSECTITLE_END	,\tagSENT_START	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	with\tagSENT_CONTENT	competitive\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	The\tagSENT_START	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	is\tagSENT_CONTENT	achieved\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	attentional\tagSENT_CONTENT	neural\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	considering\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	factors\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	saliency\tagSENT_CONTENT	,\tagSENT_CONTENT	fluency\tagSENT_CONTENT	and\tagSENT_CONTENT	novelty\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Gigaword\tagSENT_START	Previous\tagSENT_CONTENT	studies\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	have\tagSENT_CONTENT	only\tagSENT_CONTENT	used\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	stage\tagSENT_CONTENT	to\tagSENT_CONTENT	anonymize\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	mitigate\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	problems\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	settings\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	test\tagSENT_CONTENT	dataset\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	summarization\tagtask	For\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_END	Lead-3\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	baseline\tagSENT_CONTENT	that\tagSENT_CONTENT	extracts\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	three\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	LexRank\tagSENT_CONTENT	extracts\tagSENT_CONTENT	texts\tagSENT_CONTENT	using\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	GRU\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	Distraction\tagSENT_CONTENT	-\tagSENT_CONTENT	M3\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	competing\tagSENT_CONTENT	models\tagSENT_CONTENT	using\tagSENT_CONTENT	ROUGE\tagmetric	F1\tagmetric	scores\tagmetric	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Gigaword\tagdataset	dataset\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	texts\tagSENT_CONTENT	are\tagSENT_CONTENT	short\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	a\tagSENT_CONTENT	comparable\tagSENT_CONTENT	performance\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	break\tagSENT_CONTENT	the\tagSENT_CONTENT	tie\tagSENT_CONTENT	between\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	conduct\tagSENT_CONTENT	summarization\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Entities\tagSENT_START	as\tagSENT_CONTENT	summarization\tagtask	Gigaword\tagSECTITLE_START	Dataset\tagSECTITLE_CONTENT	Example\tagSECTITLE_END	Original\tagSENT_START	western\tagSENT_CONTENT	mexico\tagSENT_CONTENT	@state\tagSENT_CONTENT	@jalisco\tagSENT_CONTENT	will\tagSENT_CONTENT	host\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	edition\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	@UNK\tagSENT_CONTENT	dollar\tagSENT_CONTENT	@lorena\tagSENT_CONTENT	ochoa\tagSENT_CONTENT	summarization\tagtask	@golf\tagSENT_CONTENT	tournament\tagSENT_CONTENT	on\tagSENT_CONTENT	nov\tagSENT_CONTENT	.\tagSENT_CONTENT	#\tagSENT_CONTENT	#\tagSENT_CONTENT	-\tagSENT_CONTENT	#\tagSENT_CONTENT	#\tagSENT_CONTENT	#\tagSENT_CONTENT	#\tagSENT_CONTENT	#\tagSENT_CONTENT	#\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	@guadalajara\tagSENT_CONTENT	@country\tagSENT_CONTENT	club\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	@lorena\tagSENT_CONTENT	ochoa\tagSENT_CONTENT	foundation\tagSENT_CONTENT	said\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	statement\tagSENT_CONTENT	on\tagSENT_CONTENT	wednesday\tagSENT_CONTENT	.\tagSENT_END	0.719\tagSECTITLE_END	0.086\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	leverage\tagSENT_CONTENT	on\tagSENT_CONTENT	linked\tagSENT_CONTENT	entities\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
D13-1090	title\tagSECTITLE_END	Discriminative\tagSENT_START	Improvements\tagSENT_CONTENT	to\tagSENT_CONTENT	semantic_textual_similarity\tagtask	abstract\tagSECTITLE_END	Matrix\tagmetric	and\tagmetric	tensor\tagmetric	factorization\tagmetric	have\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_textual_similarity\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	identification\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Measuring\tagSENT_START	semantic_textual_similarity\tagtask	of\tagSENT_CONTENT	short\tagSENT_CONTENT	units\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	is\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	to\tagSENT_CONTENT	many\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	grouping\tagSENT_CONTENT	redundant\tagSENT_CONTENT	event\tagSENT_CONTENT	mentions\tagSENT_CONTENT	in\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	accomplished\tagSENT_CONTENT	by\tagSENT_CONTENT	factoring\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	or\tagSENT_CONTENT	tensor\tagSENT_CONTENT	of\tagSENT_CONTENT	term\tagSENT_CONTENT	-\tagSENT_CONTENT	context\tagSENT_CONTENT	counts\tagSENT_CONTENT	;\tagSENT_CONTENT	proximity\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	induced\tagSENT_CONTENT	latent\tagSENT_CONTENT	space\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	correlate\tagSENT_CONTENT	with\tagSENT_CONTENT	semantic_textual_similarity\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	can\tagSENT_CONTENT	considerably\tagSENT_CONTENT	improve\tagSENT_CONTENT	distributional\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	measuring\tagSENT_CONTENT	semantic_textual_similarity\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Without\tagSENT_START	attempting\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	justice\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	literature\tagSENT_CONTENT	on\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	identification\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	note\tagSENT_CONTENT	three\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	approaches\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	string\tagSENT_CONTENT	similarity\tagSENT_CONTENT	metrics\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	overlap\tagSENT_CONTENT	and\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	score\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	string\tagSENT_CONTENT	kernels\tagSENT_CONTENT	(;\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	operations\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	parse\tagSENT_CONTENT	structure\tagSENT_CONTENT	(;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	distributional\tagSENT_CONTENT	methods\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	semantic_textual_similarity\tagtask	(\tagSENT_CONTENT	LSA\tagSENT_CONTENT	;\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	most\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	take\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	approach\tagSENT_CONTENT	:\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	meanings\tagSENT_CONTENT	of\tagSENT_CONTENT	individual\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	directly\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagmetric	distributional\tagmetric	representation\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	treat\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	pseudo\tagSENT_CONTENT	-\tagSENT_CONTENT	documents\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	LSA\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	identify\tagSENT_CONTENT	paraphrases\tagSENT_CONTENT	using\tagSENT_CONTENT	semantic_textual_similarity\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	space\tagSENT_CONTENT	.\tagSENT_END	Discriminative\tagSECTITLE_START	feature\tagSECTITLE_CONTENT	weighting\tagSECTITLE_END	By\tagSENT_START	decomposing\tagSENT_CONTENT	the\tagSENT_CONTENT	matrix\tagSENT_CONTENT	W\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	hope\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagmetric	latent\tagmetric	representation\tagmetric	in\tagSENT_CONTENT	which\tagSENT_CONTENT	semantically\tagSENT_CONTENT	-\tagSENT_CONTENT	related\tagSENT_CONTENT	sentences\tagSENT_CONTENT	are\tagSENT_CONTENT	similar\tagSENT_CONTENT	.\tagSENT_END	Singular\tagSENT_START	value\tagSENT_CONTENT	decomposition\tagSENT_CONTENT	(\tagSENT_CONTENT	SVD\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	traditionally\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	this\tagmetric	factorization\tagmetric	.\tagSENT_END	(;\tagSENT_START	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	from\tagSENT_CONTENT	SVD\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	addition\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	negativity\tagSENT_CONTENT	constraint\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	latent\tagmetric	representation\tagmetric	based\tagSENT_CONTENT	on\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	orthogonal\tagSENT_CONTENT	basis\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	anew\tagSENT_CONTENT	weighting\tagSENT_CONTENT	scheme\tagSENT_CONTENT	,\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	KLD\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagmetric	information\tagmetric	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	this\tagSENT_CONTENT	divergence\tagSENT_CONTENT	to\tagSENT_CONTENT	reweight\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	W\tagSENT_CONTENT	before\tagSENT_CONTENT	performing\tagSENT_CONTENT	the\tagmetric	matrix\tagmetric	factorization\tagmetric	.\tagSENT_END	This\tagSENT_START	has\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	increasing\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	whose\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	appearing\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	is\tagSENT_CONTENT	strongly\tagSENT_CONTENT	influenced\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagmetric	paraphrase\tagmetric	relationship\tagmetric	between\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	pk\tagSENT_CONTENT	=\tagSENT_CONTENT	q\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	the\tagSENT_CONTENT	KL\tagSENT_CONTENT	-\tagSENT_CONTENT	divergence\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	zero\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	ignored\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	matrix\tagmetric	factorization\tagmetric	.\tagSENT_END	:\tagSENT_START	Fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	paraphrase\tagmetric	classification\tagmetric	,\tagSENT_CONTENT	selected\tagSENT_CONTENT	from\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	unigram\tagSECTITLE_START	recall\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	unigram\tagSECTITLE_CONTENT	precision\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	bigram\tagSECTITLE_CONTENT	recall\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	bigram\tagSECTITLE_CONTENT	precision\tagSECTITLE_CONTENT	5\tagSECTITLE_CONTENT	dependency\tagSECTITLE_CONTENT	relation\tagSECTITLE_CONTENT	recall\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	dependency\tagSECTITLE_CONTENT	relation\tagSECTITLE_CONTENT	precision\tagSECTITLE_CONTENT	7\tagSECTITLE_CONTENT	BLEU\tagSECTITLE_CONTENT	recall\tagSECTITLE_CONTENT	8\tagSECTITLE_CONTENT	BLEU\tagSECTITLE_CONTENT	precision\tagSECTITLE_CONTENT	9\tagSECTITLE_CONTENT	Difference\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	sentence\tagSECTITLE_CONTENT	length\tagSECTITLE_CONTENT	10\tagSECTITLE_CONTENT	Tree\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	editing\tagSECTITLE_CONTENT	distance\tagSECTITLE_END	Supervised\tagSECTITLE_START	classification\tagSECTITLE_END	While\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	performed\tagSENT_CONTENT	paraphrase\tagmetric	classification\tagmetric	using\tagSENT_CONTENT	distance\tagSENT_CONTENT	or\tagSENT_CONTENT	semantic_textual_similarity\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	space\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	more\tagSENT_CONTENT	direct\tagSENT_CONTENT	supervision\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	this\tagmetric	representation\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	any\tagSENT_CONTENT	supervised\tagSENT_CONTENT	classification\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	further\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	treating\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	apply\tagSENT_CONTENT	additional\tagSENT_CONTENT	features\tagSENT_CONTENT	besides\tagSENT_CONTENT	the\tagmetric	latent\tagmetric	representation\tagmetric	.\tagSENT_END	These\tagSENT_START	features\tagSENT_CONTENT	mainly\tagSENT_CONTENT	capture\tagSENT_CONTENT	semantic_textual_similarity\tagtask	between\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	by\tagSENT_CONTENT	counting\tagSENT_CONTENT	specific\tagSENT_CONTENT	unigram\tagSENT_CONTENT	and\tagSENT_CONTENT	bigram\tagSENT_CONTENT	overlap\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	test\tagSENT_CONTENT	the\tagSENT_CONTENT	utility\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	KLD\tagSENT_CONTENT	weighting\tagSENT_CONTENT	towards\tagSENT_CONTENT	paraphrase\tagmetric	classification\tagmetric	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Microsoft\tagSENT_CONTENT	Research\tagSENT_CONTENT	Paraphrase\tagSENT_CONTENT	Corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	KLD\tagSENT_CONTENT	weights\tagSENT_CONTENT	are\tagSENT_CONTENT	constructed\tagSENT_CONTENT	from\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	matrix\tagmetric	factorizations\tagmetric	are\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	formed\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Matrix\tagmetric	factorization\tagmetric	on\tagSENT_CONTENT	both\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	)\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	transductive\tagSENT_CONTENT	learning\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	assume\tagSENT_CONTENT	access\tagSENT_CONTENT	to\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	instances\tagSENT_CONTENT	.\tagSENT_END	Similarity\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	classification\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	experiment\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	predict\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	by\tagSENT_CONTENT	measuring\tagSENT_CONTENT	semantic_textual_similarity\tagtask	in\tagSENT_CONTENT	latent\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	threshold\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	classification\tagSENT_CONTENT	boundary\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	classification\tagSECTITLE_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	supervised\tagmetric	classification\tagmetric	,\tagSENT_CONTENT	constructing\tagSENT_CONTENT	sample\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagmetric	latent\tagmetric	representation\tagmetric	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Equation\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	best\tagSENT_CONTENT	result\tagSENT_CONTENT	is\tagSENT_CONTENT	from\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	KLD\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	distributional\tagSENT_CONTENT	features\tagSENT_CONTENT	FEAT\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	79.76\tagmetric	%\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	85.87\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	we\tagSENT_CONTENT	induce\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	basis\tagSENT_CONTENT	from\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	get\tagSENT_CONTENT	78.55\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	84.59\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	,\tagSENT_CONTENT	also\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	augment\tagSENT_CONTENT	the\tagSENT_CONTENT	distributional\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	the\tagSENT_CONTENT	ten\tagSENT_CONTENT	"\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	"\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	   \tagSENT_CONTENT	racy\tagmetric	now\tagSENT_CONTENT	improves\tagSENT_CONTENT	to\tagSENT_CONTENT	80.41\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	85.96\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	the\tagmetric	latent\tagmetric	representation\tagmetric	is\tagSENT_CONTENT	induced\tagSENT_CONTENT	from\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	79.94\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	85.36\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	,\tagSENT_CONTENT	again\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagmetric	information\tagmetric	captured\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	distributional\tagSENT_CONTENT	representation\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	be\tagSENT_CONTENT	augmented\tagSENT_CONTENT	by\tagSENT_CONTENT	more\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	traditional\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	three\tagSENT_CONTENT	ways\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	distributional\tagSENT_CONTENT	measures\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_textual_similarity\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	.\tagSENT_END	
1810.04805	title\tagSECTITLE_END	abstract\tagSECTITLE_END	As\tagSENT_START	a\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	BERT\tagSENT_CONTENT	representations\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuned\tagSENT_CONTENT	with\tagSENT_CONTENT	just\tagSENT_CONTENT	one\tagSENT_CONTENT	additional\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	fora\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	without\tagSENT_CONTENT	substantial\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	architecture\tagSENT_CONTENT	modifications\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	These\tagSENT_START	tasks\tagSENT_CONTENT	include\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	paraphrasing\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	relationships\tagSENT_CONTENT	between\tagSENT_CONTENT	sentences\tagSENT_CONTENT	by\tagSENT_CONTENT	analyzing\tagSENT_CONTENT	them\tagmetric	holistically\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	token\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	and\tagSENT_END	The\tagSENT_START	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ELMo\tagmetric	(\tagSENT_CONTENT	,\tagSENT_CONTENT	uses\tagSENT_CONTENT	tasks\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	architectures\tagSENT_CONTENT	that\tagSENT_CONTENT	include\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	representations\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	approaches\tagSENT_CONTENT	share\tagSENT_CONTENT	named_entity_recognition\tagtask	during\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	they\tagSENT_CONTENT	use\tagSENT_CONTENT	unidirectional\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	general\tagSENT_CONTENT	language\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Such\tagSENT_START	restrictions\tagSENT_CONTENT	are\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	optimal\tagSENT_CONTENT	for\tagSENT_CONTENT	sentencelevel\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	devastating\tagSENT_CONTENT	when\tagSENT_CONTENT	applying\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	token\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	to\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	context\tagmetric	from\tagSENT_CONTENT	both\tagSENT_CONTENT	directions\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Feature\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Approaches\tagSECTITLE_END	When\tagSENT_START	integrating\tagSENT_CONTENT	contextual\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	with\tagSENT_CONTENT	existing\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	architectures\tagSENT_CONTENT	,\tagSENT_CONTENT	ELMo\tagmetric	advances\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	several\tagSENT_CONTENT	major\tagSENT_CONTENT	NLP\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Fine\tagSECTITLE_START	-\tagSECTITLE_CONTENT	tuning\tagSECTITLE_CONTENT	Approaches\tagSECTITLE_END	Transfer\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	from\tagSECTITLE_CONTENT	Supervised\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	BERT\tagSECTITLE_END	Model\tagSECTITLE_START	Architecture\tagSECTITLE_END	We\tagSENT_START	primarily\tagSENT_CONTENT	report\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	common_sense\tagtask	:\tagSENT_END	•\tagSENT_START	BERT\tagSENT_CONTENT	BASE\tagSENT_CONTENT	was\tagSENT_CONTENT	chosen\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	an\tagSENT_CONTENT	identical\tagSENT_CONTENT	model\tagSENT_CONTENT	size\tagSENT_CONTENT	as\tagSENT_CONTENT	OpenAI\tagSENT_CONTENT	GPT\tagSENT_CONTENT	for\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Input\tagSECTITLE_START	Representation\tagSECTITLE_END	Our\tagSENT_START	input\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	unambiguously\tagSENT_CONTENT	represent\tagSENT_CONTENT	both\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	text\tagSENT_CONTENT	sentence\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	sentences\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Position\tagSECTITLE_START	Embeddings\tagSECTITLE_END	The\tagSENT_START	input\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	separate\tagSENT_CONTENT	them\tagmetric	with\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	token\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	a\tagSENT_CONTENT	learned\tagSENT_CONTENT	sentence\tagSENT_CONTENT	A\tagSENT_CONTENT	embedding\tagSENT_CONTENT	to\tagSENT_CONTENT	every\tagSENT_CONTENT	token\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	B\tagSENT_CONTENT	embedding\tagSENT_CONTENT	to\tagSENT_CONTENT	every\tagSENT_CONTENT	token\tagSENT_CONTENT	of\tagSENT_CONTENT	common_sense\tagtask	.\tagSENT_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	Task\tagSECTITLE_START	#\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Masked\tagSECTITLE_CONTENT	LM\tagSECTITLE_END	Unfortunately\tagSENT_START	,\tagSENT_CONTENT	standard\tagSENT_CONTENT	conditional\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	only\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	or\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	left\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	named_entity_recognition\tagtask	would\tagSENT_CONTENT	allow\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	to\tagSENT_CONTENT	indirectly\tagSENT_CONTENT	"\tagSENT_CONTENT	see\tagSENT_CONTENT	itself\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagmetric	multi\tagmetric	-\tagmetric	layered\tagmetric	context\tagmetric	.\tagSENT_END	Task\tagSECTITLE_START	#\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Next\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Prediction\tagSECTITLE_END	Many\tagSENT_START	important\tagSENT_CONTENT	downstream\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Inference\tagSENT_CONTENT	(\tagSENT_CONTENT	NLI\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	understanding\tagSENT_CONTENT	the\tagSENT_CONTENT	relationship\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	text\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	directly\tagSENT_CONTENT	captured\tagSENT_CONTENT	by\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	choose\tagSENT_CONTENT	the\tagSENT_CONTENT	NotNext\tagSENT_CONTENT	sentences\tagSENT_CONTENT	completely\tagSENT_CONTENT	at\tagSENT_CONTENT	random\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	97%-98\tagmetric	%\tagmetric	accuracy\tagmetric	at\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	Procedure\tagSECTITLE_END	The\tagSENT_START	LM\tagSENT_CONTENT	masking\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	after\tagSENT_CONTENT	WordPiece\tagSENT_CONTENT	tokenization\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	uniform\tagSENT_CONTENT	masking\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	15\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	given\tagSENT_CONTENT	to\tagSENT_CONTENT	partial\tagSENT_CONTENT	word\tagSENT_CONTENT	pieces\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	training\tagSENT_CONTENT	loss\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	masked\tagSENT_CONTENT	LM\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	and\tagSENT_CONTENT	mean\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Fine\tagSECTITLE_START	-\tagSECTITLE_CONTENT	tuning\tagSECTITLE_CONTENT	Procedure\tagSECTITLE_END	Comparison\tagSECTITLE_START	of\tagSECTITLE_CONTENT	BERT\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	OpenAI\tagSECTITLE_CONTENT	GPT\tagSECTITLE_END	Experiments\tagSECTITLE_END	GLUE\tagSECTITLE_START	Datasets\tagSECTITLE_END	Most\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	GLUE\tagSENT_CONTENT	datasets\tagSENT_CONTENT	have\tagSENT_CONTENT	already\tagSENT_CONTENT	existed\tagSENT_CONTENT	fora\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	purpose\tagSENT_CONTENT	of\tagSENT_CONTENT	GLUE\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	distribute\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	with\tagSENT_CONTENT	canonical\tagSENT_CONTENT	Train\tagSENT_CONTENT	,\tagSENT_CONTENT	Dev\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Test\tagSENT_CONTENT	splits\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	setup\tagSENT_CONTENT	an\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	server\tagSENT_CONTENT	to\tagSENT_CONTENT	mitigate\tagSENT_CONTENT	issues\tagSENT_CONTENT	with\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	inconsistencies\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Given\tagSENT_START	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	whether\tagSENT_CONTENT	common_sense\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	contradiction\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	neutral\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	one\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	if\tagSENT_CONTENT	two\tagSENT_CONTENT	questions\tagSENT_CONTENT	asked\tagSENT_CONTENT	on\tagSENT_CONTENT	Quora\tagSENT_CONTENT	are\tagSENT_CONTENT	semantically\tagSENT_CONTENT	equivalent\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	were\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	score\tagSENT_CONTENT	from\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	denoting\tagSENT_CONTENT	how\tagSENT_CONTENT	similar\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sentences\tagSENT_CONTENT	are\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	System\tagSECTITLE_END	MNLI-(m\tagSECTITLE_START	/\tagSECTITLE_CONTENT	mm\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	QQP\tagSECTITLE_CONTENT	QNLI\tagSECTITLE_CONTENT	SST-2\tagSECTITLE_CONTENT	CoLA\tagSECTITLE_CONTENT	STS\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	B\tagSECTITLE_CONTENT	MRPC\tagSECTITLE_CONTENT	RTE\tagSECTITLE_CONTENT	Average\tagSECTITLE_END	GLUE\tagSECTITLE_START	Results\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	BERT\tagSENT_CONTENT	BASE\tagSENT_CONTENT	and\tagSENT_CONTENT	OpenAI\tagSENT_CONTENT	GPT\tagSENT_CONTENT	are\tagSENT_CONTENT	nearly\tagSENT_CONTENT	identical\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	outside\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	masking\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagSECTITLE_START	v1.1\tagSECTITLE_END	question_answering\tagtask	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	collection\tagSENT_CONTENT	of\tagSENT_CONTENT	100k\tagSENT_CONTENT	crowdsourced\tagSENT_CONTENT	question\tagSENT_CONTENT	/\tagSENT_CONTENT	answer\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	•\tagSECTITLE_START	Output\tagSECTITLE_CONTENT	Answer\tagSECTITLE_CONTENT	:\tagSECTITLE_END	within\tagSENT_START	a\tagSENT_CONTENT	cloud\tagSENT_CONTENT	This\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	span\tagSENT_CONTENT	prediction\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	quite\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	classification\tagSENT_CONTENT	tasks\tagSENT_CONTENT	of\tagSENT_CONTENT	GLUE\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	adapt\tagSENT_CONTENT	BERT\tagSENT_CONTENT	to\tagSENT_CONTENT	run\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	in\tagSENT_CONTENT	a\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	manner\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	same\tagSENT_CONTENT	formula\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	scoring\tagSENT_CONTENT	span\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	At\tagSENT_START	inference\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	not\tagSENT_CONTENT	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	the\tagSENT_CONTENT	constraint\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	must\tagSENT_CONTENT	come\tagSENT_CONTENT	after\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	no\tagSENT_CONTENT	other\tagSENT_CONTENT	heuristics\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagdataset	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	highly\tagSENT_CONTENT	rigorous\tagSENT_CONTENT	testing\tagSENT_CONTENT	procedure\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	submitter\tagSENT_CONTENT	must\tagSENT_CONTENT	manually\tagSENT_CONTENT	contact\tagSENT_CONTENT	the\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	organizers\tagSENT_CONTENT	to\tagSENT_CONTENT	run\tagSENT_CONTENT	their\tagSENT_CONTENT	system\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	hidden\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	submitted\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_END	We\tagSENT_START	therefore\tagSENT_CONTENT	use\tagSENT_CONTENT	very\tagSENT_CONTENT	modest\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	submitted\tagSENT_CONTENT	system\tagSENT_CONTENT	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	training\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	and\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Named\tagSECTITLE_START	Entity\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_END	Named\tagSENT_START	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	LARGE\tagSENT_START	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	existing\tagSENT_CONTENT	SOTA\tagSENT_CONTENT	,\tagSENT_CONTENT	Cross\tagSENT_CONTENT	-\tagSENT_CONTENT	View\tagSENT_CONTENT	Training\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	by\tagSENT_CONTENT	+0.2\tagSENT_CONTENT	on\tagSENT_CONTENT	CoNLL-2003\tagSENT_CONTENT	NER\tagSENT_CONTENT	Test\tagSENT_CONTENT	.\tagSENT_END	SWAG\tagSECTITLE_END	The\tagSENT_START	Situations\tagSENT_CONTENT	With\tagSENT_CONTENT	Adversarial\tagSENT_CONTENT	Generations\tagSENT_CONTENT	(\tagSENT_CONTENT	SWAG\tagdataset	)\tagSENT_CONTENT	dataset\tagSENT_CONTENT	contains\tagSENT_CONTENT	113k\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	pair\tagSENT_CONTENT	completion\tagSENT_CONTENT	examples\tagSENT_CONTENT	that\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	grounded\tagSENT_CONTENT	commonsense\tagSENT_CONTENT	inference\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	four\tagSENT_CONTENT	input\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	each\tagSENT_CONTENT	contain\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	sentence\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	sentence\tagSENT_CONTENT	B\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Studies\tagSECTITLE_END	Although\tagSENT_START	we\tagSENT_CONTENT	have\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	extremely\tagSENT_CONTENT	strong\tagSENT_CONTENT	empirical\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	presented\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	have\tagSENT_CONTENT	not\tagSENT_CONTENT	isolated\tagSENT_CONTENT	named_entity_recognition\tagtask	from\tagSENT_CONTENT	each\tagSENT_CONTENT	aspect\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	BERT\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Pre\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	We\tagSENT_START	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	removing\tagSENT_CONTENT	NSP\tagSENT_CONTENT	hurts\tagSENT_CONTENT	performance\tagSENT_CONTENT	significantly\tagSENT_CONTENT	on\tagSENT_CONTENT	QNLI\tagSENT_CONTENT	,\tagSENT_CONTENT	MNLI\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	SQuAD\tagdataset	.\tagSENT_END	The\tagSENT_START	LTR\tagSENT_CONTENT	model\tagSENT_CONTENT	performs\tagSENT_CONTENT	worse\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	MLM\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	extremely\tagSENT_CONTENT	large\tagSENT_CONTENT	drops\tagSENT_CONTENT	on\tagSENT_CONTENT	MRPC\tagSENT_CONTENT	and\tagSENT_CONTENT	SQuAD\tagdataset	.\tagSENT_END	This\tagSENT_START	does\tagSENT_CONTENT	significantly\tagSENT_CONTENT	improve\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	still\tagSENT_CONTENT	far\tagSENT_CONTENT	worse\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	 \tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Size\tagSECTITLE_END	We\tagSENT_START	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	larger\tagSENT_CONTENT	models\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagmetric	strict\tagmetric	accuracy\tagmetric	improvement\tagmetric	across\tagSENT_CONTENT	all\tagSENT_CONTENT	four\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	for\tagSENT_CONTENT	MRPC\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	has\tagSENT_CONTENT	3,600\tagSENT_CONTENT	labeled\tagSENT_CONTENT	training\tagSENT_CONTENT	examples\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	substantially\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Number\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Steps\tagSECTITLE_END	question_answering\tagtask	:\tagSENT_CONTENT	Does\tagSENT_CONTENT	BERT\tagSENT_CONTENT	really\tagSENT_CONTENT	need\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	128,000\tagSENT_CONTENT	words\tagSENT_CONTENT	/\tagSENT_CONTENT	batch\tagSENT_CONTENT	*\tagSENT_CONTENT	1,000,000\tagSENT_CONTENT	steps\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	high\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	?\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	absolute\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	the\tagSENT_CONTENT	MLM\tagSENT_CONTENT	model\tagSENT_CONTENT	begins\tagSENT_CONTENT	to\tagSENT_CONTENT	outperform\tagSENT_CONTENT	the\tagSENT_CONTENT	LTR\tagSENT_CONTENT	model\tagSENT_CONTENT	almost\tagSENT_CONTENT	immediately\tagSENT_CONTENT	.\tagSENT_END	Feature\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Approach\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	BERT\tagSECTITLE_END	Second\tagSENT_START	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	major\tagSENT_CONTENT	computational\tagSENT_CONTENT	benefits\tagSENT_CONTENT	to\tagSENT_CONTENT	being\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	compute\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	once\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	run\tagSENT_CONTENT	many\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	less\tagSENT_CONTENT	expensive\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	how\tagSENT_CONTENT	well\tagSENT_CONTENT	BERT\tagSENT_CONTENT	performs\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	by\tagSENT_CONTENT	generating\tagSENT_CONTENT	ELMo\tagmetric	-\tagSENT_CONTENT	like\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	contextual\tagSENT_CONTENT	representations\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL-2003\tagSENT_CONTENT	NER\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	do\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	named_entity_recognition\tagtask	as\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.3\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	activations\tagSENT_CONTENT	from\tagSENT_CONTENT	one\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	layers\tagSENT_CONTENT	without\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	any\tagSENT_CONTENT	parameters\tagSENT_CONTENT	of\tagSENT_CONTENT	BERT\tagSENT_CONTENT	.\tagSENT_END	Layers\tagSECTITLE_END	While\tagSENT_START	the\tagSENT_CONTENT	empirical\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	strong\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	common_sense\tagtask	surpassing\tagSENT_CONTENT	human\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	important\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	phenomena\tagSENT_CONTENT	that\tagSENT_CONTENT	mayor\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	captured\tagSENT_CONTENT	by\tagSENT_CONTENT	BERT\tagSENT_CONTENT	.\tagSENT_END	
S17-2157	title\tagSECTITLE_END	abstract\tagSECTITLE_END	amr_parsing\tagtask	obtained\tagSENT_CONTENT	59\tagmetric	%\tagmetric	Smatch\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Consequently\tagSENT_START	amr_parsing\tagtask	are\tagSENT_CONTENT	pipelines\tagSENT_CONTENT	that\tagSENT_CONTENT	make\tagSENT_CONTENT	extensive\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	additional\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSENT_START	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoders\tagSENT_CONTENT	have\tagSENT_CONTENT	previously\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	reported\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	are\tagSENT_CONTENT	well\tagSENT_CONTENT	below\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	with\tagSENT_CONTENT	sophisticated\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	and\tagSENT_CONTENT	categorization\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	extensions\tagSENT_CONTENT	increase\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	over\tagSENT_CONTENT	a\tagSENT_CONTENT	standard\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Graph\tagSECTITLE_START	Linearization\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Lemmatization\tagSECTITLE_END	We\tagSENT_START	start\tagSENT_CONTENT	by\tagSENT_CONTENT	discussing\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	linearize\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	enable\tagSENT_CONTENT	sequential\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	amr_parsing\tagtask	,\tagSENT_CONTENT	graphs\tagSENT_CONTENT	are\tagSENT_CONTENT	represented\tagSENT_CONTENT	as\tagSENT_CONTENT	spanning\tagSENT_CONTENT	trees\tagSENT_CONTENT	with\tagSENT_CONTENT	designated\tagSENT_CONTENT	root\tagSENT_CONTENT	nodes\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	predicates\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	PropBank\tagSENT_CONTENT	framesets\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	represented\tagSENT_CONTENT	as\tagSENT_CONTENT	sense\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	lemmas\tagSENT_CONTENT	.\tagSENT_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	processing\tagSECTITLE_END	This\tagSENT_START	tokenization\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	more\tagSENT_CONTENT	closely\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	constants\tagSENT_CONTENT	than\tagSENT_CONTENT	other\tagSENT_CONTENT	tokenizers\tagSENT_CONTENT	we\tagSENT_CONTENT	experimented\tagSENT_CONTENT	with\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	handling\tagSENT_CONTENT	of\tagSENT_CONTENT	hyphenation\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	biomedical\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	predict\tagSENT_CONTENT	constant\tagSENT_CONTENT	strings\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	unseen\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	forms\tagSENT_CONTENT	predicted\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	NE\tagSENT_CONTENT	tagger\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	broadly\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	conventions\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	SUTime\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	normalized\tagSENT_CONTENT	forms\tagSENT_CONTENT	of\tagSENT_CONTENT	dates\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	(\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	)\tagSENT_CONTENT	oracle\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	is\tagSENT_CONTENT	98.7\tagmetric	%\tagmetric	Smatch\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	96.16\tagSENT_CONTENT	%\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	aligned\tagSENT_CONTENT	lexicalized\tagSENT_CONTENT	representation\tagSENT_CONTENT	and\tagSENT_CONTENT	93.48\tagSENT_CONTENT	%\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	unlexicalized\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	Pointer\tagSECTITLE_START	-\tagSECTITLE_CONTENT	augmented\tagSECTITLE_CONTENT	neural\tagSECTITLE_CONTENT	attention\tagSECTITLE_END	:\tagSENT_START	Resources\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	candidate\tagSENT_CONTENT	lemmas\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	left\tagSENT_CONTENT	-\tagSENT_CONTENT	most\tagSENT_CONTENT	resource\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	amr_parsing\tagtask	available\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Experiments\tagSECTITLE_END	When\tagSENT_START	training\tagSENT_CONTENT	amr_parsing\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	biomedical\tagSENT_CONTENT	domain\tagSENT_CONTENT	with\tagSENT_CONTENT	minibatch\tagmetric	SGD\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	sample\tagSENT_END	Singleton\tagSENT_START	tokens\tagSENT_CONTENT	are\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	unknown\tagSENT_CONTENT	word\tagSENT_CONTENT	symbol\tagSENT_CONTENT	with\tagSENT_CONTENT	probability\tagSENT_CONTENT	0.5\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Metric\tagSECTITLE_END	amr_parsing\tagtask	are\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	with\tagSENT_CONTENT	Smatch\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	further\tagSENT_CONTENT	analysis\tagSENT_CONTENT	is\tagSENT_CONTENT	done\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	metrics\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	enable\tagSENT_CONTENT	future\tagSENT_CONTENT	comparison\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Bio\tagSENT_CONTENT	AMR\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	newswire\tagSENT_CONTENT	and\tagSENT_CONTENT	discussion\tagSENT_CONTENT	forum\tagSENT_CONTENT	data\tagSENT_CONTENT	(\tagSENT_CONTENT	LDC2016E25\tagSENT_CONTENT	)\tagSENT_CONTENT	only\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Results\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	neural\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	obtain\tagSENT_CONTENT	strong\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	by\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	modelling\tagSENT_CONTENT	structure\tagSENT_CONTENT	implicit\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	
P16-2038	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	experiments\tagSENT_CONTENT	in\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	CCG\tagSENT_CONTENT	supertag\tagSENT_CONTENT	-\tagSENT_CONTENT	ging\tagSENT_CONTENT	,\tagSENT_CONTENT	coupled\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	additional\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	consistently\tagSENT_CONTENT	better\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	ccg_supertagging\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	innermost\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	outermost\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	in\tagSENT_CONTENT	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	deep\tagSENT_CONTENT	MTL\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	ccg_supertagging\tagtask	for\tagSENT_CONTENT	all\tagSENT_CONTENT	tasks\tagSENT_CONTENT	happen\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	(\tagSENT_CONTENT	outermost\tagSENT_CONTENT	)\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	natural\tagSENT_CONTENT	to\tagSENT_CONTENT	think\tagSENT_CONTENT	of\tagSENT_CONTENT	some\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	analysis\tagSENT_CONTENT	as\tagSENT_CONTENT	feeding\tagSENT_CONTENT	into\tagSENT_CONTENT	others\tagSENT_CONTENT	,\tagSENT_CONTENT	typically\tagSENT_CONTENT	with\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	feeding\tagSENT_CONTENT	into\tagSENT_CONTENT	highlevel\tagSENT_CONTENT	ones\tagSENT_CONTENT	;\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagtask	)\tagSENT_CONTENT	or\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	improved\tagSENT_CONTENT	deep\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	chunking\tagtask	by\tagSENT_CONTENT	also\tagSENT_CONTENT	having\tagSENT_CONTENT	task\tagSENT_CONTENT	supervision\tagSENT_CONTENT	from\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	outermost\tagSENT_CONTENT	level\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	also\tagSENT_CONTENT	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	NER\tagSENT_CONTENT	and\tagSENT_CONTENT	SRL\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	only\tagSENT_CONTENT	obtain\tagSENT_CONTENT	improvements\tagSENT_CONTENT	from\tagSENT_CONTENT	MTL\tagSENT_CONTENT	with\tagSENT_CONTENT	POS\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	.\tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	MTL\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	with\tagSENT_CONTENT	deep\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	;\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_END	Sequence\tagSECTITLE_START	tagging\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	deep\tagSECTITLE_CONTENT	bi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	RNNs\tagSECTITLE_END	We\tagSENT_START	write\tagSENT_CONTENT	FL\tagSENT_CONTENT	(\tagSENT_CONTENT	·\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	shortcut\tagSENT_CONTENT	to\tagSENT_CONTENT	F\tagSENT_CONTENT	θ\tagSENT_CONTENT	L\tagSENT_CONTENT	-an\tagSENT_CONTENT	instantiation\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagmetric	with\tagSENT_CONTENT	a\tagSENT_CONTENT	spe\tagSENT_CONTENT	-\tagSENT_CONTENT	cific\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θ\tagSENT_CONTENT	L\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	)\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	a\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ith\tagSENT_CONTENT	item\tagSENT_CONTENT	in\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	n\tagSENT_CONTENT	,\tagSENT_CONTENT	taking\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	both\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	history\tagSENT_END	where\tagSENT_START	L\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	label\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	interest\tagSENT_CONTENT	;\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	L\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	below\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	other\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	using\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	produce\tagSENT_CONTENT	competitive\tagSENT_CONTENT	tagging\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	richness\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	vi\tagSENT_CONTENT	that\tagSENT_CONTENT	takes\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	maybe\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	tasks\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	POS\tagSENT_CONTENT	-\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	CCG\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	although\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	ccg_supertagging\tagtask	are\tagSENT_CONTENT	different\tagSENT_CONTENT	than\tagSENT_CONTENT	each\tagSENT_CONTENT	other\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	also\tagSENT_CONTENT	share\tagSENT_CONTENT	lot\tagSENT_CONTENT	of\tagSENT_CONTENT	substructure\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	knowing\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	verb\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	in\tagSENT_CONTENT	determining\tagSENT_CONTENT	ccg_supertagging\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	chunk\tagSENT_CONTENT	it\tagSENT_CONTENT	participate\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Supervising\tagSECTITLE_START	different\tagSECTITLE_CONTENT	tasks\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	layers\tagSECTITLE_END	This\tagSENT_START	enables\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	a\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	cascaded\tagSENT_CONTENT	predictions\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	deep\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	We\tagSENT_START	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	POS\tagSENT_CONTENT	-\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	CCG\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	these\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagtask	and\tagSENT_CONTENT	CCG\tagSENT_CONTENT	data\tagSENT_CONTENT	are\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	.\tagSENT_END	ccg_supertagging\tagtask	are\tagSENT_CONTENT	also\tagSENT_CONTENT	slighly\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	a\tagSENT_CONTENT	recently\tagSENT_CONTENT	reported\tagSENT_CONTENT	result\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	93.00\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	significantly\tagSENT_CONTENT	better\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.05\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ccg_supertagging\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	lower\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	consistently\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	standard\tagSENT_CONTENT	MTL\tagSENT_CONTENT	.\tagSENT_END	LAYERS\tagSECTITLE_END	DOMAINS\tagSECTITLE_START	CHUNKS\tagSECTITLE_CONTENT	POS\tagSECTITLE_CONTENT	BROADCAST\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	BC\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	NEWS\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	8)\tagSECTITLE_CONTENT	MAGAZINES\tagSECTITLE_END	Domain\tagSENT_START	adaptation\tagSENT_CONTENT	We\tagSENT_CONTENT	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	OntoNotes\tagSENT_CONTENT	4.0\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	assume\tagSENT_CONTENT	main\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	chunking\tagtask	)\tagSENT_CONTENT	ccg_supertagging\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	domain\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	lower\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	POS\tagSENT_CONTENT	supervision\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	in\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	when\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	ccg_supertagging\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	domain\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	believe\tagSENT_CONTENT	this\tagSENT_CONTENT	result\tagSENT_CONTENT	is\tagSENT_CONTENT	worth\tagSENT_CONTENT	exploring\tagSENT_CONTENT	further\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	scenario\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	interested\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	common\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	MTL\tagSENT_START	and\tagSENT_CONTENT	chunking\tagtask	of\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	allowing\tagSENT_CONTENT	supervision\tagSENT_CONTENT	signals\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	tasks\tagSENT_CONTENT	to\tagSENT_CONTENT	benefit\tagSENT_CONTENT	each\tagSENT_CONTENT	other\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	appealing\tagSENT_CONTENT	idea\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	case\tagSENT_CONTENT	we\tagSENT_CONTENT	suspect\tagSENT_CONTENT	the\tagSENT_CONTENT	existence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	hierarchy\tagmetric	between\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	worthwhile\tagSENT_CONTENT	to\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	this\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	MTL\tagSENT_CONTENT	architecture\tagSENT_CONTENT	's\tagSENT_CONTENT	design\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	making\tagSENT_CONTENT	lower\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	affect\tagSENT_CONTENT	the\tagSENT_CONTENT	lower\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	
1804.00079	title\tagSECTITLE_END	TENCE\tagmetric	REPRESENTATIONS\tagmetric	VIA\tagSENT_CONTENT	LARGE\tagSENT_CONTENT	SCALE\tagSENT_CONTENT	MULTI-\tagSENT_CONTENT	TASK\tagSENT_CONTENT	LEARNING\tagSENT_END	abstract\tagSECTITLE_END	A\tagSENT_START	lot\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	recent\tagSENT_CONTENT	success\tagSENT_CONTENT	in\tagSENT_CONTENT	natural_language_inference\tagtask	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	driven\tagSENT_CONTENT	by\tagSENT_CONTENT	distributed\tagSENT_CONTENT	vector\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	large\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	manner\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Computer\tagSENT_START	vision\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	image\tagSENT_CONTENT	captioning\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	visual\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	typically\tagSENT_CONTENT	use\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	on\tagSENT_CONTENT	ImageNet\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	representations\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	image\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	natural_language_inference\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	and\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	benefited\tagSENT_CONTENT	from\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_END	Many\tagSENT_START	neural\tagSENT_CONTENT	NLP\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	initialized\tagSENT_CONTENT	with\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	but\tagSENT_CONTENT	learn\tagSENT_CONTENT	their\tagmetric	representations\tagmetric	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	context\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagmetric	,\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	manner\tagSENT_CONTENT	from\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	signals\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	generalize\tagSENT_CONTENT	across\tagSENT_CONTENT	a\tagSENT_CONTENT	diverse\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	representations\tagmetric	that\tagSENT_CONTENT	encode\tagSENT_CONTENT	several\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thoughts\tagSENT_CONTENT	,\tagSENT_CONTENT	machine\tagmetric	translation\tagmetric	,\tagSENT_CONTENT	natural_language_inference\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	likely\tagSENT_CONTENT	have\tagSENT_CONTENT	different\tagSENT_CONTENT	inductive\tagSENT_CONTENT	biases\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	primary\tagmetric	contribution\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	benefits\tagSENT_CONTENT	of\tagSENT_CONTENT	diverse\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	representation\tagSENT_CONTENT	learning\tagSENT_CONTENT	objectives\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	reusable\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	model\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	objectives\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	diversity\tagSENT_CONTENT	explored\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	lingual\tagSENT_CONTENT	NMT\tagSENT_CONTENT	,\tagSENT_CONTENT	natural_language_inference\tagtask	,\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	and\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thought\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	A\tagmetric	network\tagmetric	's\tagmetric	representation\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	element\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	composition\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	inputs\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	typically\tagSENT_CONTENT	assumed\tagSENT_CONTENT	to\tagSENT_CONTENT	contain\tagSENT_CONTENT	a\tagSENT_CONTENT	squashed\tagSENT_CONTENT	"\tagSENT_CONTENT	summary\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Notably\tagSENT_START	,\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thought\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagmetric	extension\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	learn\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	usable\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representations\tagSENT_CONTENT	from\tagSENT_CONTENT	weakly\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	More\tagSENT_START	recently\tagSENT_CONTENT	,\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	completely\tagSENT_CONTENT	supervised\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	learning\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	from\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	data\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	all\tagSENT_CONTENT	previous\tagSENT_CONTENT	approaches\tagSENT_CONTENT	on\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	terms\tagSENT_CONTENT	"\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	performance\tagSENT_CONTENT	"\tagSENT_CONTENT	on\tagSENT_CONTENT	"\tagSENT_CONTENT	transfer\tagSENT_CONTENT	tasks\tagSENT_CONTENT	"\tagSENT_CONTENT	to\tagSENT_CONTENT	mean\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	tasks\tagSENT_CONTENT	unseen\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	demonstrated\tagSENT_START	that\tagSENT_CONTENT	representations\tagmetric	learned\tagSENT_CONTENT	by\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	NMT\tagSENT_CONTENT	systems\tagSENT_CONTENT	also\tagSENT_CONTENT	generalize\tagSENT_CONTENT	well\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	a\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	attentive\tagSENT_CONTENT	classification\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	composes\tagSENT_CONTENT	information\tagmetric	present\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagmetric	.\tagSENT_END	Our\tagSENT_START	work\tagSENT_CONTENT	is\tagSENT_CONTENT	most\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	train\tagSENT_CONTENT	a\tagSENT_CONTENT	many\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	many\tagSENT_CONTENT	sequenceto\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	diverse\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	weakly\tagSENT_CONTENT	related\tagSENT_CONTENT	tasks\tagSENT_CONTENT	that\tagSENT_CONTENT	includes\tagSENT_CONTENT	machine\tagmetric	translation\tagmetric	,\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	image\tagSENT_CONTENT	captioning\tagSENT_CONTENT	,\tagSENT_CONTENT	sequence\tagSENT_CONTENT	autoencoding\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thoughts\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	natural_language_inference\tagtask	between\tagSENT_CONTENT	that\tagSENT_CONTENT	work\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	own\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	further\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	how\tagSENT_CONTENT	different\tagSENT_CONTENT	tasks\tagSENT_CONTENT	contribute\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	information\tagSENT_CONTENT	signals\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagmetric	representations\tagmetric	following\tagSENT_CONTENT	work\tagSENT_CONTENT	by\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	SEQUENCE\tagSECTITLE_START	-\tagSECTITLE_CONTENT	TO\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	SEQUENCE\tagSECTITLE_CONTENT	LEARNING\tagSECTITLE_END	The\tagSENT_START	encoder\tagSENT_CONTENT	representation\tagSENT_CONTENT	h\tagSENT_CONTENT	x\tagSENT_CONTENT	is\tagSENT_CONTENT	provided\tagSENT_CONTENT	as\tagSENT_CONTENT	conditioning\tagSENT_CONTENT	information\tagmetric	to\tagSENT_CONTENT	the\tagSENT_CONTENT	reset\tagSENT_CONTENT	gate\tagSENT_CONTENT	,\tagSENT_CONTENT	update\tagSENT_CONTENT	gate\tagSENT_CONTENT	and\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	computation\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	GRU\tagSENT_CONTENT	via\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	Cr\tagSENT_CONTENT	,\tagSENT_CONTENT	C\tagSENT_CONTENT	z\tagSENT_CONTENT	and\tagSENT_CONTENT	Cd\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	attenuation\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagmetric	from\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	TRAINING\tagSECTITLE_START	OBJECTIVES\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	EVALUATION\tagSECTITLE_END	Our\tagSENT_START	desiderata\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagmetric	task\tagmetric	collection\tagmetric	were\tagSENT_CONTENT	:\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	diversity\tagSENT_CONTENT	,\tagSENT_CONTENT	existence\tagSENT_CONTENT	of\tagSENT_CONTENT	fairly\tagSENT_CONTENT	large\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	success\tagSENT_CONTENT	as\tagSENT_CONTENT	standalone\tagSENT_CONTENT	training\tagSENT_CONTENT	objectives\tagSENT_CONTENT	for\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	.\tagSENT_END	Skip\tagSENT_START	-\tagSENT_CONTENT	thought\tagSENT_CONTENT	vectors\tagSENT_CONTENT	Skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thought\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	are\tagSENT_CONTENT	an\tagmetric	extension\tagmetric	of\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	 \tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	that\tagSENT_CONTENT	NMT\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	formulated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	learning\tagSENT_CONTENT	problem\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	natural_language_inference\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	is\tagSENT_CONTENT	its\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	translation\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	natural_language_inference\tagtask	(\tagSENT_CONTENT	NLI\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	3-way\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	EVALUATION\tagSECTITLE_START	STRATEGIES\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	EXPERIMENTAL\tagSECTITLE_CONTENT	RESULTS\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	DISCUSSION\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagmetric	quality\tagmetric	of\tagSENT_CONTENT	our\tagmetric	learned\tagmetric	representations\tagmetric	,\tagSENT_CONTENT	present\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagmetric	evaluation\tagmetric	and\tagSENT_CONTENT	discuss\tagSENT_CONTENT	our\tagSENT_CONTENT	findings\tagSENT_CONTENT	.\tagSENT_END	EVALUATION\tagSECTITLE_START	STRATEGY\tagSECTITLE_END	We\tagSENT_START	follow\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	protocol\tagSENT_CONTENT	to\tagSENT_CONTENT	those\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	;\tagSENT_CONTENT	;\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	our\tagmetric	learned\tagmetric	representations\tagmetric	as\tagSENT_CONTENT	features\tagSENT_CONTENT	fora\tagSENT_CONTENT	low\tagSENT_CONTENT	complexity\tagSENT_CONTENT	classifier\tagSENT_CONTENT	(\tagSENT_CONTENT	typically\tagSENT_CONTENT	linear\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	supervised\tagSENT_CONTENT	task\tagSENT_CONTENT	/\tagSENT_CONTENT	domain\tagSENT_CONTENT	unseen\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	without\tagSENT_CONTENT	updating\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagmetric	quality\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	learned\tagSENT_CONTENT	individual\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	using\tagSENT_CONTENT	standard\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSENT_START	approaches\tagSENT_CONTENT	trained\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagmetric	on\tagSENT_CONTENT	some\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	presented\tagSENT_CONTENT	for\tagSENT_CONTENT	comparison\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTAL\tagSECTITLE_START	RESULTS\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	DISCUSSION\tagSECTITLE_END	Increasing\tagSENT_START	the\tagmetric	capacity\tagmetric	our\tagSENT_CONTENT	sentence\tagSENT_CONTENT	encoder\tagSENT_CONTENT	with\tagSENT_CONTENT	more\tagSENT_CONTENT	hidden\tagSENT_CONTENT	units\tagSENT_CONTENT	(\tagSENT_CONTENT	+\tagSENT_CONTENT	L\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	layer\tagSENT_CONTENT	(\tagSENT_CONTENT	+2L\tagSENT_CONTENT	)\tagSENT_CONTENT	also\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	improved\tagSENT_CONTENT	transfer\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	,\tagSENT_CONTENT	who\tagSENT_CONTENT	use\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	learn\tagSENT_CONTENT	our\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagmetric	.\tagSENT_END	In\tagSENT_START	Appendix\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagmetric	sentence\tagmetric	representations\tagmetric	outperform\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thoughts\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	on\tagSENT_CONTENT	par\tagSENT_CONTENT	with\tagSENT_CONTENT	Infersent\tagSENT_CONTENT	for\tagSENT_CONTENT	image\tagSENT_CONTENT	-\tagSENT_CONTENT	caption\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	MRPC\tagSENT_CONTENT	and\tagSENT_CONTENT	STSB\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	only\tagmetric	the\tagmetric	F1\tagmetric	score\tagmetric	and\tagmetric	Spearman\tagmetric	correlations\tagmetric	respectively\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	multiply\tagSENT_CONTENT	the\tagSENT_CONTENT	SICK\tagSENT_CONTENT	-\tagSENT_CONTENT	R\tagSENT_CONTENT	scores\tagSENT_CONTENT	by\tagSENT_CONTENT	100\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	natural_language_inference\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	scale\tagSENT_CONTENT	.\tagSENT_END	semantic_textual_similarity\tagtask	correlates\tagSENT_CONTENT	reasonably\tagSENT_CONTENT	well\tagSENT_CONTENT	with\tagSENT_CONTENT	their\tagSENT_CONTENT	relatedness\tagSENT_CONTENT	on\tagSENT_CONTENT	semantic\tagSENT_CONTENT	textual\tagSENT_CONTENT	similarity\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	(\tagSENT_CONTENT	Appendix\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	present\tagSENT_CONTENT	qualitative\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagmetric	learned\tagmetric	representations\tagmetric	by\tagSENT_CONTENT	visualizations\tagSENT_CONTENT	using\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	reduction\tagSENT_CONTENT	techniques\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	nearest\tagmetric	neighbor\tagmetric	exploration\tagmetric	(\tagSENT_CONTENT	Appendix\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_START	&\tagSECTITLE_CONTENT	FUTURE\tagSECTITLE_CONTENT	WORK\tagSECTITLE_END	Our\tagSENT_START	primary\tagSENT_CONTENT	motivation\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	encapsulate\tagSENT_CONTENT	the\tagSENT_CONTENT	inductive\tagSENT_CONTENT	biases\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	diverse\tagSENT_CONTENT	training\tagSENT_CONTENT	signals\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	framework\tagSENT_CONTENT	includes\tagSENT_CONTENT	a\tagmetric	combination\tagmetric	of\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	lingual\tagSENT_CONTENT	NMT\tagSENT_CONTENT	,\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	and\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thought\tagSENT_CONTENT	vectors\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	One\tagSENT_START	could\tagSENT_CONTENT	also\tagSENT_CONTENT	consider\tagSENT_CONTENT	controllable\tagSENT_CONTENT	text\tagSENT_CONTENT	generation\tagSENT_CONTENT	by\tagSENT_CONTENT	directly\tagSENT_CONTENT	manipulating\tagSENT_CONTENT	the\tagmetric	sentence\tagmetric	representations\tagmetric	and\tagSENT_CONTENT	realizing\tagSENT_CONTENT	it\tagSENT_CONTENT	by\tagSENT_CONTENT	decoding\tagSENT_CONTENT	with\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	semantic_textual_similarity\tagtask	and\tagSENT_CONTENT	training\tagSENT_CONTENT	details\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	did\tagSENT_CONTENT	not\tagSENT_CONTENT	tune\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	architectural\tagSENT_CONTENT	details\tagSENT_CONTENT	and\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	owing\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	were\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	any\tagmetric	clear\tagmetric	criterion\tagmetric	on\tagSENT_CONTENT	which\tagSENT_CONTENT	to\tagSENT_CONTENT	tune\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	VOCABULARY\tagSECTITLE_START	EXPANSION\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	REPRESENTATION\tagSECTITLE_CONTENT	POOLING\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	performing\tagSENT_CONTENT	10-fold\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	validation\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	L2\tagSENT_CONTENT	regularization\tagSENT_CONTENT	penalty\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	tune\tagSENT_CONTENT	the\tagmetric	way\tagmetric	in\tagSENT_CONTENT	which\tagSENT_CONTENT	our\tagmetric	sentence\tagmetric	representations\tagmetric	are\tagSENT_CONTENT	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	employ\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	expansion\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	tasks\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	by\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagmetric	linear\tagmetric	regression\tagmetric	to\tagSENT_CONTENT	map\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	MULTI\tagSECTITLE_START	-\tagSECTITLE_CONTENT	TASK\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_CONTENT	DETAILS\tagSECTITLE_END	We\tagSENT_START	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	thought\tagSENT_CONTENT	next\tagSENT_CONTENT	as\tagSENT_CONTENT	STN\tagSENT_CONTENT	,\tagSENT_CONTENT	French\tagSENT_CONTENT	and\tagSENT_CONTENT	German\tagSENT_CONTENT	NMT\tagSENT_CONTENT	as\tagSENT_CONTENT	natural_language_inference\tagtask	as\tagSENT_CONTENT	NLI\tagSENT_CONTENT	,\tagSENT_END	The\tagSENT_START	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	h\tagSENT_CONTENT	x\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagmetric	concatenation\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	hidden\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	forward\tagSENT_CONTENT	GRU\tagSENT_CONTENT	with\tagSENT_CONTENT	1500-dimensional\tagSENT_CONTENT	hidden\tagSENT_CONTENT	vectors\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	GRU\tagSENT_CONTENT	,\tagSENT_CONTENT	also\tagSENT_CONTENT	with\tagSENT_CONTENT	1500-dimensional\tagSENT_CONTENT	hidden\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	tables\tagSENT_CONTENT	3\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	the\tagmetric	representations\tagmetric	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	detailed\tagSENT_CONTENT	description\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	typically\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	.\tagSENT_END	DESCRIPTION\tagSECTITLE_START	OF\tagSECTITLE_CONTENT	EVALUATION\tagSECTITLE_CONTENT	TASKS\tagSECTITLE_END	TEXT\tagSECTITLE_START	CLASSIFICATION\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	text\tagSENT_CONTENT	classification\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	-sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	on\tagSENT_CONTENT	movie\tagSENT_CONTENT	reviews\tagSENT_CONTENT	(\tagSENT_CONTENT	MR\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	product\tagSENT_CONTENT	reviews\tagSENT_CONTENT	(\tagSENT_CONTENT	CR\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	(\tagSENT_CONTENT	SST\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagmetric	type\tagmetric	classification\tagmetric	(\tagSENT_CONTENT	TREC\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	subjectivity\tagSENT_CONTENT	/\tagSENT_CONTENT	objectivity\tagSENT_CONTENT	classification\tagSENT_CONTENT	(\tagSENT_CONTENT	SUBJ\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	opinion\tagSENT_CONTENT	polarity\tagSENT_CONTENT	(\tagSENT_CONTENT	MPQA\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Representations\tagmetric	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	a\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	classifier\tagSENT_CONTENT	with\tagSENT_CONTENT	10-fold\tagSENT_CONTENT	cross\tagSENT_CONTENT	validation\tagSENT_CONTENT	to\tagSENT_CONTENT	tune\tagSENT_CONTENT	the\tagSENT_CONTENT	L2\tagSENT_CONTENT	weight\tagSENT_CONTENT	penalty\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	evaluation\tagmetric	metric\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	is\tagSENT_CONTENT	classification\tagmetric	accuracy\tagmetric	.\tagSENT_END	PARAPHRASE\tagSECTITLE_START	IDENTIFICATION\tagSECTITLE_END	The\tagSENT_START	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	is\tagSENT_CONTENT	classification\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	.\tagSENT_END	ENTAILMENT\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	SEMANTIC\tagSECTITLE_CONTENT	RELATEDNESS\tagSECTITLE_END	To\tagSENT_START	test\tagSENT_CONTENT	if\tagSENT_CONTENT	similar\tagSENT_CONTENT	sentences\tagSENT_CONTENT	share\tagSENT_CONTENT	similar\tagmetric	representations\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SICK\tagSENT_CONTENT	relatedness\tagSENT_CONTENT	(\tagSENT_CONTENT	SICK\tagSENT_CONTENT	-\tagSENT_CONTENT	R\tagSENT_CONTENT	)\tagSENT_CONTENT	task\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	output\tagSENT_CONTENT	a\tagSENT_CONTENT	score\tagSENT_CONTENT	from\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	indicating\tagSENT_CONTENT	the\tagSENT_CONTENT	relatedness\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	for\tagSENT_CONTENT	SICK\tagdataset	-\tagdataset	R\tagdataset	is\tagSENT_CONTENT	Pearson\tagmetric	correlation\tagmetric	and\tagSENT_CONTENT	classification\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	SICK\tagSENT_CONTENT	-\tagSENT_CONTENT	E.\tagSENT_END	SEMANTIC\tagSECTITLE_START	TEXTUAL\tagSECTITLE_CONTENT	SIMILARITY\tagSECTITLE_END	In\tagSENT_START	this\tagmetric	evaluation\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	relatedness\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	sentences\tagSENT_CONTENT	using\tagSENT_CONTENT	semantic_textual_similarity\tagtask	between\tagSENT_CONTENT	their\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	IMAGE\tagSECTITLE_START	-\tagSECTITLE_CONTENT	CAPTION\tagSECTITLE_CONTENT	RETRIEVAL\tagSECTITLE_END	Image\tagSENT_START	-\tagSENT_CONTENT	caption\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	is\tagSENT_CONTENT	typically\tagSENT_CONTENT	formulated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	ranking\tagSENT_CONTENT	task\tagSENT_CONTENT	wherein\tagSENT_CONTENT	images\tagSENT_CONTENT	are\tagSENT_CONTENT	retrieved\tagSENT_CONTENT	and\tagSENT_CONTENT	ranked\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	semantic_textual_similarity\tagtask	and\tagSENT_CONTENT	vice\tagSENT_CONTENT	-\tagSENT_CONTENT	versa\tagSENT_CONTENT	.\tagSENT_END	QUORA\tagSECTITLE_START	DUPLICATE\tagSECTITLE_CONTENT	QUESTION\tagSECTITLE_CONTENT	CLASSIFICATION\tagSECTITLE_END	Given\tagSENT_START	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	expressive\tagSENT_CONTENT	classifier\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	representations\tagmetric	of\tagSENT_CONTENT	both\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	evaluation\tagmetric	criterion\tagmetric	is\tagSENT_CONTENT	classification\tagmetric	accuracy\tagmetric	.\tagSENT_END	SENTENCE\tagSECTITLE_START	CHARACTERISTICS\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	SYNTAX\tagSECTITLE_END	In\tagSENT_START	an\tagSENT_CONTENT	attempt\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	what\tagmetric	information\tagmetric	is\tagSENT_CONTENT	encoded\tagSENT_CONTENT	in\tagSENT_CONTENT	by\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	six\tagSENT_CONTENT	different\tagSENT_CONTENT	classification\tagSENT_CONTENT	tasks\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	sentence\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	length\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	content\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	order\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	properties\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	active\tagSENT_CONTENT	/\tagSENT_CONTENT	passive\tagSENT_CONTENT	,\tagSENT_CONTENT	tense\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	TSS\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	content\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	formulated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	that\tagSENT_CONTENT	takes\tagSENT_CONTENT	a\tagmetric	concatenation\tagmetric	of\tagSENT_CONTENT	a\tagmetric	sentence\tagmetric	representation\tagmetric	u\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	k\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagmetric	word\tagmetric	The\tagSENT_START	passive\tagSENT_CONTENT	and\tagSENT_CONTENT	tense\tagSENT_CONTENT	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	characterized\tagSENT_CONTENT	as\tagSENT_CONTENT	binary\tagSENT_CONTENT	classification\tagSENT_CONTENT	problems\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagmetric	sentence\tagmetric	's\tagmetric	representation\tagmetric	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dataset\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagmetric	authors\tagmetric	but\tagSENT_CONTENT	different\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	validation\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	splits\tagSENT_CONTENT	.\tagSENT_END	:\tagmetric	Evaluation\tagmetric	of\tagSENT_CONTENT	sentence\tagmetric	representations\tagmetric	on\tagSENT_CONTENT	semantic_textual_similarity\tagtask	.\tagSENT_END	Caption\tagSECTITLE_START	Retrieval\tagSECTITLE_END	
S16-1186	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	improvements\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	as\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	2016\tagSENT_CONTENT	Shared\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	New\tagSECTITLE_START	Concept\tagSECTITLE_CONTENT	Fragment\tagSECTITLE_CONTENT	Sources\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	In\tagSENT_START	that\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	clex\tagSENT_CONTENT	has\tagSENT_CONTENT	three\tagSENT_CONTENT	sources\tagSENT_CONTENT	of\tagSENT_CONTENT	concept\tagSENT_CONTENT	fragments\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	lexicon\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	rules\tagSENT_CONTENT	for\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	identified\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	tagger\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	rules\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	First\tagmetric	match\tagmetric	:\tagSENT_CONTENT	1\tagSENT_CONTENT	if\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	place\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	that\tagSENT_CONTENT	matches\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	.\tagSENT_END	•\tagmetric	Sentence\tagmetric	match\tagmetric	:\tagSENT_CONTENT	1\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	matches\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	have\tagSENT_CONTENT	occurred\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	10\tagSENT_CONTENT	times\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	with\tagSENT_CONTENT	no\tagSENT_CONTENT	gaps\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Concept\tagSENT_CONTENT	fragment\tagSENT_CONTENT	source\tagSENT_CONTENT	:\tagSENT_CONTENT	indicator\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	concept\tagSENT_CONTENT	fragment\tagSENT_CONTENT	(\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	NER\tagSENT_CONTENT	tagger\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	frame\tagSENT_CONTENT	files\tagSENT_CONTENT	,\tagSENT_CONTENT	lemma\tagSENT_CONTENT	,\tagSENT_CONTENT	verb\tagSENT_CONTENT	-\tagSENT_CONTENT	pass\tagSENT_CONTENT	through\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	NE\tagSENT_CONTENT	pass\tagSENT_CONTENT	-\tagSENT_CONTENT	through\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	No\tagmetric	match\tagmetric	from\tagSENT_CONTENT	corpus\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	if\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	matching\tagSENT_CONTENT	concept\tagSENT_CONTENT	fragment\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	span\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	rules\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	balance\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	lexicon\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	sources\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	validation\tagSENT_CONTENT	.\tagSENT_END	During\tagSENT_START	amr_parsing\tagtask	,\tagSENT_CONTENT	when\tagSENT_CONTENT	processing\tagSENT_CONTENT	a\tagSENT_CONTENT	training\tagSENT_CONTENT	example\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	exclude\tagSENT_CONTENT	concept\tagSENT_CONTENT	fragments\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	section\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	can\tagSENT_CONTENT	cause\tagSENT_CONTENT	problems\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Infinite\tagSECTITLE_START	Ramp\tagSECTITLE_CONTENT	Loss\tagSECTITLE_END	and\tagSENT_START	the\tagSENT_CONTENT	structured\tagSENT_CONTENT	SVM\tagSENT_CONTENT	loss\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	incorporates\tagSENT_CONTENT	amr_parsing\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	cost\tagSENT_CONTENT	function\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_END	It\tagSENT_START	also\tagSENT_CONTENT	occurs\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	second\tagSENT_CONTENT	max\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	usual\tagSENT_CONTENT	cost\tagSENT_CONTENT	augmented\tagSENT_CONTENT	decoding\tagSENT_CONTENT	that\tagSENT_CONTENT	gives\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	SVM\tagSENT_CONTENT	loss\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	what\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	updates\tagSENT_CONTENT	away\tagSENT_CONTENT	from\tagSENT_CONTENT	in\tagSENT_CONTENT	subgradient\tagSENT_CONTENT	descent\tagSENT_CONTENT	,\tagSENT_CONTENT	called\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	fear\tagSENT_CONTENT	derivation\tagSENT_CONTENT	"\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_END	Experiments\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	using\tagSENT_CONTENT	Smatch\tagmetric	.\tagSENT_END	Following\tagSENT_START	the\tagSENT_CONTENT	recommended\tagSENT_CONTENT	train\tagSENT_CONTENT	/\tagSENT_CONTENT	dev./test\tagSENT_CONTENT	split\tagSENT_CONTENT	of\tagSENT_CONTENT	LDC2015E86\tagdataset	,\tagSENT_CONTENT	amr_parsing\tagtask	achieves\tagSENT_CONTENT	70\tagSENT_CONTENT	%\tagSENT_CONTENT	precision\tagSENT_CONTENT	,\tagSENT_CONTENT	65\tagSENT_CONTENT	%\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	67\tagmetric	%\tagmetric	F\tagmetric	1\tagmetric	Smatch\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	LDC2015E86\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	is\tagSENT_START	55\tagmetric	%\tagmetric	F\tagmetric	1\tagmetric	Smatch\tagmetric	,\tagSENT_CONTENT	so\tagSENT_CONTENT	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	are\tagSENT_CONTENT	quite\tagSENT_CONTENT	substantial\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	2016\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	improved\tagSENT_CONTENT	parser\tagSENT_CONTENT	achieves\tagSENT_CONTENT	56\tagmetric	%\tagmetric	F\tagmetric	1\tagmetric	Smatch\tagmetric	.\tagSENT_END	Because\tagSENT_START	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	were\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	boosting\tagSENT_CONTENT	recall\tagSENT_CONTENT	in\tagSENT_CONTENT	concept\tagSENT_CONTENT	identification\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	frame\tagSENT_CONTENT	files\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	advantage\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	show\tagSENT_CONTENT	as\tagSENT_CONTENT	large\tagSENT_CONTENT	improvements\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	as\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	LDC2015E86\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	improvements\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	as\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	2016\tagSENT_CONTENT	Shared\tagSENT_CONTENT	Task\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	substantial\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	parser\tagSENT_CONTENT	.\tagSENT_END	
1611.01578	title\tagSECTITLE_END	abstract\tagSECTITLE_END	On\tagSENT_START	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	can\tagSENT_CONTENT	compose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	cell\tagSENT_CONTENT	that\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	performs\tagSENT_CONTENT	the\tagSENT_CONTENT	widely\tagSENT_CONTENT	-\tagSENT_CONTENT	used\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	cell\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	baselines\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Neural\tagSENT_START	Architecture\tagSENT_CONTENT	Search\tagSENT_CONTENT	has\tagSENT_CONTENT	some\tagmetric	parallels\tagmetric	to\tagSENT_CONTENT	program\tagSENT_CONTENT	synthesis\tagSENT_CONTENT	and\tagSENT_CONTENT	inductive\tagSENT_CONTENT	programming\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	idea\tagSENT_CONTENT	of\tagSENT_CONTENT	searching\tagSENT_CONTENT	a\tagSENT_CONTENT	program\tagSENT_CONTENT	from\tagSENT_CONTENT	examples\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	program\tagSENT_CONTENT	induction\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	successfully\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	settings\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	simple\tagSENT_CONTENT	Q&A\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	sorta\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	numbers\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	very\tagSENT_CONTENT	few\tagSENT_CONTENT	examples\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	controller\tagSENT_CONTENT	in\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Architecture\tagSENT_CONTENT	Search\tagSENT_CONTENT	is\tagSENT_CONTENT	auto\tagSENT_CONTENT	-\tagSENT_CONTENT	regressive\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	means\tagSENT_CONTENT	it\tagSENT_CONTENT	predicts\tagSENT_CONTENT	hyperparameters\tagmetric	one\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	previous\tagSENT_CONTENT	predictions\tagSENT_CONTENT	.\tagSENT_END	METHODS\tagSECTITLE_END	GENERATE\tagSECTITLE_START	MODEL\tagSECTITLE_CONTENT	DESCRIPTIONS\tagSECTITLE_CONTENT	WITH\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	CONTROLLER\tagSECTITLE_CONTENT	RECURRENT\tagSECTITLE_CONTENT	NEURAL\tagSECTITLE_CONTENT	NETWORK\tagSECTITLE_END	It\tagSENT_START	predicts\tagSENT_CONTENT	filter\tagSENT_CONTENT	height\tagSENT_CONTENT	,\tagSENT_CONTENT	filter\tagSENT_CONTENT	width\tagSENT_CONTENT	,\tagSENT_CONTENT	stride\tagSENT_CONTENT	height\tagSENT_CONTENT	,\tagSENT_CONTENT	stride\tagSENT_CONTENT	width\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	number\tagmetric	of\tagSENT_CONTENT	filters\tagSENT_CONTENT	for\tagSENT_CONTENT	one\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	repeats\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	parameters\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	controller\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	θ\tagSENT_CONTENT	c\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	optimized\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	expected\tagSENT_CONTENT	validation\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	next\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	describe\tagSENT_CONTENT	a\tagSENT_CONTENT	policy\tagSENT_CONTENT	gradient\tagSENT_CONTENT	method\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	to\tagSENT_CONTENT	update\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θ\tagSENT_CONTENT	c\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	controller\tagSENT_CONTENT	RNN\tagSENT_CONTENT	generates\tagSENT_CONTENT	better\tagmetric	architectures\tagmetric	overtime\tagSENT_CONTENT	.\tagSENT_END	TRAINING\tagSECTITLE_START	WITH\tagSECTITLE_CONTENT	REINFORCE\tagSECTITLE_END	Where\tagSENT_START	m\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	architectures\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	controller\tagSENT_CONTENT	samples\tagSENT_CONTENT	in\tagSENT_CONTENT	one\tagSENT_CONTENT	batch\tagSENT_CONTENT	and\tagSENT_CONTENT	T\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	hyperparameters\tagmetric	our\tagSENT_CONTENT	controller\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	to\tagSENT_CONTENT	design\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	INCREASE\tagSECTITLE_START	ARCHITECTURE\tagSECTITLE_CONTENT	COMPLEXITY\tagSECTITLE_CONTENT	WITH\tagSECTITLE_CONTENT	SKIP\tagSECTITLE_CONTENT	CONNECTIONS\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	OTHER\tagSECTITLE_CONTENT	LAYER\tagSECTITLE_CONTENT	TYPES\tagSECTITLE_END	The\tagSENT_START	matrices\tagSENT_CONTENT	W\tagSENT_CONTENT	prev\tagSENT_CONTENT	,\tagSENT_CONTENT	W\tagSENT_CONTENT	curr\tagSENT_CONTENT	and\tagSENT_CONTENT	v\tagSENT_CONTENT	are\tagSENT_CONTENT	trainable\tagmetric	parameters\tagmetric	.\tagSENT_END	GENERATE\tagSECTITLE_START	RECURRENT\tagSECTITLE_CONTENT	CELL\tagSECTITLE_CONTENT	ARCHITECTURES\tagSECTITLE_END	EXPERIMENTS\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	RESULTS\tagSECTITLE_END	We\tagSENT_START	apply\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	image\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	CIFAR-10\tagSENT_CONTENT	and\tagSENT_CONTENT	language_modeling\tagtask	with\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	,\tagSENT_CONTENT	two\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	benchmarked\tagSENT_CONTENT	datasets\tagSENT_CONTENT	in\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	LEARNING\tagSECTITLE_START	CONVOLUTIONAL\tagSECTITLE_CONTENT	ARCHITECTURES\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	CIFAR-10\tagSECTITLE_END	The\tagSENT_START	best\tagSENT_CONTENT	model\tagSENT_CONTENT	from\tagSENT_CONTENT	this\tagSENT_CONTENT	grid\tagSENT_CONTENT	search\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	run\tagSENT_CONTENT	until\tagSENT_CONTENT	convergence\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	then\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	summarize\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	First\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	ask\tagSENT_CONTENT	the\tagSENT_CONTENT	controller\tagSENT_CONTENT	to\tagSENT_CONTENT	not\tagSENT_CONTENT	predict\tagSENT_CONTENT	stride\tagSENT_CONTENT	or\tagSENT_CONTENT	pooling\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	design\tagSENT_CONTENT	a\tagSENT_CONTENT	15-layer\tagSENT_CONTENT	architecture\tagSENT_CONTENT	that\tagSENT_CONTENT	achieves\tagSENT_CONTENT	5.50\tagSENT_CONTENT	%\tagSENT_CONTENT	error\tagSENT_CONTENT	rate\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	limit\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	complexity\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	language_modeling\tagtask	predict\tagSENT_CONTENT	13\tagSENT_CONTENT	layers\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	layer\tagSENT_CONTENT	prediction\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	fully\tagSENT_CONTENT	connected\tagSENT_CONTENT	block\tagSENT_CONTENT	of\tagSENT_CONTENT	3\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	LEARNING\tagSECTITLE_START	RECURRENT\tagSECTITLE_CONTENT	CELLS\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	PENN\tagSECTITLE_CONTENT	TREEBANK\tagSECTITLE_END	We\tagSENT_START	apply\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Architecture\tagSENT_CONTENT	Search\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	known\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	The\tagSENT_START	number\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagmetric	pairs\tagmetric	to\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	cell\tagSENT_CONTENT	is\tagSENT_CONTENT	called\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	base\tagSENT_CONTENT	number\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	8\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Every\tagSENT_START	child\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	two\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	hidden\tagSENT_CONTENT	units\tagSENT_CONTENT	adjusted\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	learnable\tagmetric	parameters\tagmetric	approximately\tagSENT_CONTENT	match\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	medium\tagSENT_CONTENT	"\tagSENT_CONTENT	baselines\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	table\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	found\tagSENT_CONTENT	by\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Architecture\tagSENT_CONTENT	Search\tagSENT_CONTENT	outperform\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	models\tagSENT_CONTENT	achieves\tagSENT_CONTENT	again\tagSENT_CONTENT	of\tagSENT_CONTENT	almost\tagSENT_CONTENT	3.6\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	:\tagSECTITLE_CONTENT	In\tagSECTITLE_END	Model\tagSECTITLE_END	To\tagSENT_START	understand\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	cell\tagSENT_CONTENT	can\tagSENT_CONTENT	generalize\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	carryout\tagSENT_CONTENT	a\tagSENT_CONTENT	larger\tagSENT_CONTENT	experiment\tagSENT_CONTENT	where\tagSENT_CONTENT	language_modeling\tagtask	has\tagSENT_CONTENT	16.28\tagSENT_CONTENT	M\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	cell\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	no\tagSENT_CONTENT	change\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	settings\tagSENT_CONTENT	except\tagSENT_CONTENT	for\tagSENT_CONTENT	dropping\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	cell\tagSENT_CONTENT	and\tagSENT_CONTENT	adjusting\tagSENT_CONTENT	the\tagmetric	hyperparameters\tagmetric	so\tagSENT_CONTENT	that\tagSENT_CONTENT	language_modeling\tagtask	should\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	computational\tagSENT_CONTENT	complexity\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	base\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	even\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	bigger\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	somewhat\tagSENT_CONTENT	comparable\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	The\tagSENT_START	code\tagSENT_CONTENT	for\tagSENT_CONTENT	running\tagSENT_CONTENT	language_modeling\tagtask	found\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	controller\tagSENT_CONTENT	on\tagSENT_CONTENT	CIFAR-10\tagSENT_CONTENT	and\tagSENT_CONTENT	PTB\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	released\tagSENT_CONTENT	at\tagSENT_CONTENT	https://github.com/tensorflow/models\tagSENT_CONTENT	.\tagSENT_END	FH\tagSENT_START	is\tagSENT_CONTENT	filter\tagSENT_CONTENT	height\tagSENT_CONTENT	,\tagSENT_CONTENT	FW\tagSENT_CONTENT	is\tagSENT_CONTENT	filter\tagSENT_CONTENT	width\tagSENT_CONTENT	and\tagSENT_CONTENT	N\tagSENT_CONTENT	is\tagSENT_CONTENT	number\tagmetric	of\tagSENT_CONTENT	filters\tagSENT_CONTENT	.\tagSENT_END	
1710.10504	title\tagSECTITLE_END	abstract\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	PhaseCond\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	architecture\tagSENT_CONTENT	of\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layered\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	phases\tagSENT_CONTENT	each\tagSENT_CONTENT	implementing\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	producing\tagSENT_CONTENT	passage\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	inner\tagSENT_CONTENT	or\tagSENT_CONTENT	outer\tagSENT_CONTENT	fusion\tagSENT_CONTENT	layers\tagSENT_CONTENT	regulating\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	flow\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Benefiting\tagSENT_START	from\tagSENT_CONTENT	the\tagSENT_CONTENT	availability\tagSENT_CONTENT	of\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	SQuAD\tagdataset	(\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	has\tagSENT_CONTENT	spread\tagSENT_CONTENT	to\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	tasks\tagSENT_CONTENT	to\tagSENT_CONTENT	allow\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	over\tagSENT_CONTENT	past\tagSENT_CONTENT	output\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	previous\tagSENT_CONTENT	research\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	purely\tagSENT_CONTENT	capture\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	distance\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	hops\tagSENT_CONTENT	architecture\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	alternatively\tagSENT_CONTENT	captures\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	refines\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	unlike\tagSENT_CONTENT	the\tagSENT_CONTENT	domains\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	jointly\tagSENT_CONTENT	align\tagSENT_CONTENT	and\tagSENT_CONTENT	translate\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	passage\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagSENT_CONTENT	alignment\tagSENT_CONTENT	matrix\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	contributions\tagSENT_CONTENT	are\tagSENT_CONTENT	threefold\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	we\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	phase\tagSENT_CONTENT	conductor\tagSENT_CONTENT	for\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	containing\tagSENT_CONTENT	multiple\tagSENT_CONTENT	phases\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	producing\tagSENT_CONTENT	passage\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	inner\tagSENT_CONTENT	or\tagSENT_CONTENT	outer\tagSENT_CONTENT	fusion\tagSENT_CONTENT	layers\tagSENT_CONTENT	regulating\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	flow\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_END	MODEL\tagSECTITLE_START	ARCHITECTURE\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	F\tagSENT_CONTENT	can\tagSENT_CONTENT	bean\tagSENT_CONTENT	inner\tagSENT_CONTENT	fusion\tagSENT_CONTENT	layer\tagSENT_CONTENT	F\tagSENT_CONTENT	inner\tagSENT_CONTENT	inside\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	an\tagSENT_CONTENT	outer\tagSENT_CONTENT	fusion\tagSENT_CONTENT	layer\tagSENT_CONTENT	F\tagSENT_CONTENT	outer\tagSENT_CONTENT	immediately\tagSENT_CONTENT	following\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	ENCODER\tagSECTITLE_START	LAYERS\tagSECTITLE_END	The\tagSENT_START	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	raw\tagSENT_CONTENT	features\tagSENT_CONTENT	as\tagSENT_CONTENT	inputs\tagSENT_CONTENT	are\tagSENT_CONTENT	processed\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	encoder\tagSENT_CONTENT	layers\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	more\tagSENT_CONTENT	abstract\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	from\tagSENT_CONTENT	the\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	approaches\tagSENT_CONTENT	that\tagSENT_CONTENT	every\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	exactly\tagSENT_CONTENT	one\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	passage\tagSENT_CONTENT	encoder\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	encoder\tagSENT_CONTENT	layers\tagSENT_CONTENT	simultaneously\tagSENT_CONTENT	calculate\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	purpose\tagSENT_CONTENT	of\tagSENT_CONTENT	serving\tagSENT_CONTENT	different\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	functions\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	phases\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	v\tagSENT_CONTENT	Q\tagSENT_CONTENT	j\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	2d\tagSENT_CONTENT	are\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	independent\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	dis\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	terms\tagmetric	of\tagSENT_CONTENT	shared\tagSENT_CONTENT	encoder\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	jointly\tagSENT_CONTENT	produce\tagSENT_CONTENT	new\tagSENT_CONTENT	representation\tagSENT_CONTENT	h\tagSENT_CONTENT	P\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	u\tagSENT_CONTENT	Q\tagSENT_CONTENT	m\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	via\tagSENT_CONTENT	a\tagSENT_CONTENT	shared\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	,\tagSENT_END	∈\tagSENT_START	R\tagSENT_CONTENT	2d\tagSENT_CONTENT	and\tagSENT_CONTENT	u\tagSENT_CONTENT	Q\tagSENT_CONTENT	j\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	2d\tagSENT_CONTENT	are\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	sharing\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	trainable\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	QUESTION\tagSECTITLE_START	-\tagSECTITLE_CONTENT	PASSAGE\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	LAYERS\tagSECTITLE_END	The\tagSENT_START	process\tagSENT_CONTENT	of\tagSENT_CONTENT	representing\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	essentially\tagSENT_CONTENT	includes\tagSENT_CONTENT	two\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	calculating\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	part\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	question\tagSENT_CONTENT	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	how\tagSENT_CONTENT	similar\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	i\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	scalar\tagSENT_CONTENT	,\tagSENT_CONTENT	denoting\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	using\tagSENT_CONTENT	dot\tagSENT_CONTENT	product\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	vector\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	word\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	the\tagSENT_CONTENT	independent\tagSENT_CONTENT	representation\tagSENT_CONTENT	v\tagSENT_CONTENT	Q\tagSENT_CONTENT	k\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	different\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	shared\tagSENT_CONTENT	weight\tagSENT_CONTENT	question\tagSENT_CONTENT	representation\tagSENT_CONTENT	u\tagSENT_CONTENT	Q\tagSENT_CONTENT	k\tagSENT_CONTENT	.\tagSENT_END	OUTER\tagSECTITLE_START	FUSION\tagSECTITLE_CONTENT	LAYERS\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	regulate\tagSENT_CONTENT	the\tagSENT_CONTENT	flow\tagSENT_CONTENT	of\tagSENT_CONTENT	N\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	passage\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	prevent\tagSENT_CONTENT	the\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	fitting\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	highway\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	of\tagSENT_CONTENT	GRUlike\tagSENT_CONTENT	gating\tagSENT_CONTENT	units\tagSENT_CONTENT	and\tagSENT_CONTENT	taking\tagSENT_CONTENT	C\tagSENT_CONTENT	0\tagSENT_END	where\tagSENT_START	t\tagSENT_CONTENT	∈\tagSENT_CONTENT	K\tagSENT_CONTENT	,\tagSENT_CONTENT	K\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	W\tagSENT_CONTENT	t\tagSENT_CONTENT	C\tagSENT_CONTENT	,\tagSENT_CONTENT	W\tagSENT_CONTENT	t\tagSENT_CONTENT	z\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	,\tagSENT_CONTENT	b\tagSENT_CONTENT	t\tagSENT_CONTENT	C\tagSENT_CONTENT	,\tagSENT_END	SELF\tagSECTITLE_START	-\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	LAYERS\tagSECTITLE_END	More\tagSENT_START	generally\tagSENT_CONTENT	,\tagSENT_CONTENT	propagating\tagSENT_CONTENT	evidence\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	words\tagSENT_CONTENT	allows\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	have\tagSENT_CONTENT	better\tagSENT_CONTENT	evidence\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	h\tagSENT_CONTENT	t−1\tagSENT_CONTENT	k\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	t\tagSENT_CONTENT	−\tagSENT_CONTENT	1\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	B\tagSENT_CONTENT	ti\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	2N\tagSENT_CONTENT	dis\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	the\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	sent\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	section\tagSENT_CONTENT	2.3.1\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	t\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	layer\tagSENT_CONTENT	passage\tagSENT_CONTENT	representation\tagSENT_CONTENT	ht\tagSENT_CONTENT	i\tagSENT_CONTENT	.\tagSENT_END	INNER\tagSECTITLE_START	FUSION\tagSECTITLE_CONTENT	LAYERS\tagSECTITLE_END	b\tagSENT_START	t\tagSENT_CONTENT	fare\tagSENT_CONTENT	the\tagSENT_CONTENT	bias\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ft\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	activation\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	OUTPUT\tagSECTITLE_START	LAYERS\tagSECTITLE_END	We\tagSENT_START	directly\tagSENT_CONTENT	follow\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	memory\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	answer\tagSENT_CONTENT	pointer\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	boundary\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	TRAINING\tagSECTITLE_START	DETAILS\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	100-dimensional\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	parts\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tag\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	tag\tagSENT_CONTENT	feature\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	binary\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	exact\tagSENT_CONTENT	matching\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	indicate\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	word\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	exactly\tagSENT_CONTENT	matched\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	vice\tagSENT_CONTENT	versa\tagSENT_CONTENT	.\tagSENT_END	MAIN\tagSECTITLE_START	RESULTS\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_CONTENT	COMPARISON\tagSECTITLE_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	Iterative\tagSENT_CONTENT	Aligner\tagSENT_CONTENT	builds\tagSENT_CONTENT	path\tagSENT_CONTENT	in\tagSENT_CONTENT	turn\tagSENT_CONTENT	through\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	:\tagSENT_CONTENT	:\tagSENT_CONTENT	The\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	published\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	competing\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	Single\tagSECTITLE_START	Model\tagSECTITLE_END	ANALYSIS\tagSECTITLE_START	ON\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	LAYERS\tagSECTITLE_END	The\tagSENT_START	model\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	which\tagSENT_CONTENT	has\tagSENT_CONTENT	two\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	passage\tagSENT_CONTENT	layers\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	T\tagSECTITLE_START	h\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	m\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	ic\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	tb\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	ll\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	fe\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	h\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	m\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	io\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	D\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	v\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	B\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	fe\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	te\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	N\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	ti\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	l\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	tb\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	ll\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	fe\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	N\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	h\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	m\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	io\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	li\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	P\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	..\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	0\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	ir\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	ir\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	S\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	B\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	w\tagSECTITLE_CONTENT	l\tagSECTITLE_CONTENT	ti\tagSECTITLE_CONTENT	tl\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	.\tagSECTITLE_END	T\tagSECTITLE_START	h\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	m\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	ic\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	tb\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	ll\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	fe\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	h\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	m\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	io\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	D\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	v\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	B\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	fe\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	te\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	N\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	ti\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	l\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	tb\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	ll\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	fe\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	N\tagSECTITLE_CONTENT	F\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	h\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	m\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	io\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	li\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	P\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	..\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	0\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	n\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	ir\tagSECTITLE_CONTENT	th\tagSECTITLE_CONTENT	ir\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	S\tagSECTITLE_CONTENT	u\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_CONTENT	B\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	w\tagSECTITLE_CONTENT	l\tagSECTITLE_CONTENT	ti\tagSECTITLE_CONTENT	tl\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	.\tagSECTITLE_END	CONCLUSION\tagSECTITLE_END	The\tagSENT_START	question\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	passage\tagSENT_CONTENT	representation\tagSENT_CONTENT	phase\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	stack\tagSENT_CONTENT	of\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	passage\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	question_answering\tagtask	that\tagSENT_CONTENT	regularize\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	passage\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	
1711.04434	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Unlike\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	fuse\tagSENT_CONTENT	different\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	inclines\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	fake\tagSENT_CONTENT	facts\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	This\tagSENT_START	task\tagSENT_CONTENT	is\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	summarization\tagtask	since\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	hard\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	common\tagSENT_CONTENT	extractive\tagSENT_CONTENT	techniques\tagSENT_CONTENT	.\tagSENT_END	bosnian\tagSENT_START	moslems\tagSENT_CONTENT	postponed\tagSENT_CONTENT	after\tagSENT_CONTENT	unhcr\tagSENT_CONTENT	pulled\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	bosnia\tagSENT_CONTENT	:\tagSENT_CONTENT	An\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	s2s\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	know\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	inevitably\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	fuse\tagSENT_CONTENT	different\tagSENT_CONTENT	parts\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	fabrication\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	serious\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	intuitively\tagSENT_CONTENT	,\tagSENT_CONTENT	encoding\tagSENT_CONTENT	existing\tagSENT_CONTENT	facts\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	should\tagSENT_CONTENT	bean\tagSENT_CONTENT	ideal\tagSENT_CONTENT	solution\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	fake\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	faithfulness\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Fact\tagSECTITLE_START	Description\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Based\tagSENT_START	on\tagSENT_CONTENT	our\tagSENT_CONTENT	observation\tagSENT_CONTENT	,\tagSENT_CONTENT	30\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	s2s\tagSENT_CONTENT	models\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	fact\tagSENT_CONTENT	fabrication\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	mismatch\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	predicate\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	subject\tagSENT_CONTENT	or\tagSENT_CONTENT	object\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	from\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	on\tagSENT_CONTENT	average\tagSENT_CONTENT	one\tagSENT_CONTENT	key\tagSENT_CONTENT	source\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	missing\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	.\tagSENT_END	18.2\tagSENT_START	Count\tagSENT_CONTENT	1\tagSENT_CONTENT	2.7\tagSENT_CONTENT	Copy%\tagSENT_CONTENT	0.12\tagSENT_CONTENT	0.17\tagSENT_CONTENT	:\tagSENT_CONTENT	Comparisons\tagSENT_CONTENT	between\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Fact\tagSECTITLE_START	Aware\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_END	Model\tagSECTITLE_START	Framework\tagSECTITLE_END	The\tagSENT_START	decoder\tagSENT_CONTENT	produces\tagSENT_CONTENT	summarization\tagtask	=\tagSENT_END	Encoders\tagSECTITLE_END	Dual\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_END	Learning\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Metric\tagSECTITLE_END	We\tagSENT_START	adopt\tagSENT_CONTENT	ROUGE\tagmetric	(\tagSENT_CONTENT	Lin\tagSENT_CONTENT	2004\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	automatic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	With\tagSENT_START	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	6\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	restrict\tagSENT_CONTENT	the\tagSENT_CONTENT	maximal\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	20\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Baselines\tagSECTITLE_END	Model\tagSECTITLE_END	Informativeness\tagSECTITLE_START	Evaluation\tagSECTITLE_END	,\tagSENT_START	the\tagmetric	ROUGE\tagmetric	scores\tagSENT_CONTENT	it\tagSENT_CONTENT	receives\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	much\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Faithfulness\tagSECTITLE_START	Evaluation\tagSECTITLE_END	s2s\tagSENT_START	-\tagSENT_CONTENT	att\tagSENT_CONTENT	outputs\tagSENT_CONTENT	gives\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	two\tagSENT_CONTENT	long\tagSENT_CONTENT	fact\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	in\tagSENT_CONTENT	Example\tagSENT_CONTENT	3\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	only\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	one\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Gate\tagSECTITLE_START	Analysis\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	gates\tagSENT_CONTENT	.\tagSENT_END	That\tagSENT_START	is\tagSENT_CONTENT	why\tagSENT_CONTENT	fact\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	are\tagSENT_CONTENT	particularly\tagSENT_CONTENT	preferred\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	sentence\tagSENT_CONTENT	while\tagSENT_CONTENT	preserving\tagSENT_CONTENT	its\tagSENT_CONTENT	meaning\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	direct\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	general\tagSENT_CONTENT	s2s\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	researchers\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	import\tagSENT_CONTENT	various\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	Notably\tagSENT_START	,\tagSENT_CONTENT	previous\tagSENT_CONTENT	researches\tagSENT_CONTENT	usually\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	investigates\tagSENT_CONTENT	the\tagSENT_CONTENT	faithfulness\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	one\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	our\tagSENT_CONTENT	decoder\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	copying\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	and\tagSENT_CONTENT	coverage\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	further\tagSENT_CONTENT	adapted\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
5635-grammar-as-a-foreign-language	title\tagSECTITLE_END	abstract\tagSECTITLE_END	constituency_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	the\tagSENT_CONTENT	subject\tagSENT_CONTENT	of\tagSENT_CONTENT	intensive\tagSENT_CONTENT	research\tagSENT_CONTENT	and\tagSENT_CONTENT	engineering\tagSENT_CONTENT	for\tagSENT_CONTENT	decades\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	domain\tagSENT_CONTENT	agnostic\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	enhanced\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	when\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	corpus\tagSENT_CONTENT	that\tagSENT_CONTENT	was\tagSENT_CONTENT	annotated\tagSENT_CONTENT	using\tagSENT_CONTENT	existing\tagSENT_CONTENT	parsers\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	constituency_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	linguistics\tagSENT_CONTENT	and\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	computational\tagSENT_CONTENT	requirements\tagSENT_CONTENT	of\tagSENT_CONTENT	traditional\tagSENT_CONTENT	parsers\tagSENT_CONTENT	are\tagSENT_CONTENT	cubic\tagSENT_CONTENT	in\tagSENT_CONTENT	sentence\tagSENT_CONTENT	length\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	while\tagSENT_CONTENT	constituency_parsing\tagtask	improved\tagSENT_CONTENT	inaccuracy\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	never\tagSENT_CONTENT	matched\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	constituency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	formulated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	problem\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	linearize\tagSENT_CONTENT	the\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	(\tagSENT_CONTENT	cf\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	apply\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	parsing\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	Go\tagSECTITLE_END	LSTM+A\tagSECTITLE_START	Parsing\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Attention\tagSECTITLE_START	Mechanism\tagSECTITLE_END	Linearizing\tagSECTITLE_START	Parsing\tagSECTITLE_CONTENT	Trees\tagSECTITLE_END	Parameters\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Initialization\tagSECTITLE_END	Experiments\tagSECTITLE_END	Training\tagSECTITLE_START	Data\tagSECTITLE_END	In\tagSENT_START	earlier\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	used\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	reimplementation\tagSENT_CONTENT	of\tagSENT_CONTENT	BerkeleyParser\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	a\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	parsed\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	Analysis\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	has\tagSENT_CONTENT	received\tagSENT_CONTENT	a\tagSENT_CONTENT	tremendous\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	20\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Traditional\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	constituency_parsing\tagtask	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	free\tagSENT_CONTENT	grammars\tagSENT_CONTENT	(\tagSENT_CONTENT	CFGs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	introduced\tagSENT_START	Incremental\tagSENT_CONTENT	Sigmoid\tagSENT_CONTENT	Belief\tagSENT_CONTENT	Networks\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	already\tagSENT_CONTENT	in\tagSENT_CONTENT	1990\tagSENT_CONTENT	experimented\tagSENT_CONTENT	with\tagSENT_CONTENT	applying\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Conclusions\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	generic\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	approaches\tagSENT_CONTENT	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	excellent\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	constituency_parsing\tagtask	parsing\tagSENT_CONTENT	with\tagSENT_CONTENT	relatively\tagSENT_CONTENT	little\tagSENT_CONTENT	effort\tagSENT_CONTENT	or\tagSENT_CONTENT	tuning\tagSENT_CONTENT	.\tagSENT_END	
sentic-lstm	title\tagSECTITLE_END	sentiment_analysis\tagtask	via\tagSENT_CONTENT	Embedding\tagSENT_CONTENT	Commonsense\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	into\tagSENT_CONTENT	an\tagSENT_CONTENT	Attentive\tagSENT_CONTENT	LSTM\tagSENT_END	abstract\tagSECTITLE_END	Analyzing\tagSENT_START	people\tagSENT_CONTENT	's\tagSENT_CONTENT	opinions\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	towards\tagSENT_CONTENT	certain\tagSENT_CONTENT	aspects\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	become\tagSENT_CONTENT	increasingly\tagSENT_CONTENT	popular\tagSENT_CONTENT	for\tagSENT_CONTENT	processing\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	data\tagSENT_CONTENT	on\tagSENT_CONTENT	online\tagSENT_CONTENT	communities\tagSENT_CONTENT	,\tagSENT_CONTENT	blogs\tagSENT_CONTENT	,\tagSENT_CONTENT	wikis\tagSENT_CONTENT	,\tagSENT_CONTENT	microblogging\tagSENT_CONTENT	platforms\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	online\tagSENT_CONTENT	collaborative\tagSENT_CONTENT	media\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	most\tagSENT_CONTENT	works\tagSENT_CONTENT	approach\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	categorization\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	is\tagSENT_CONTENT	actually\tagSENT_CONTENT	a\tagSENT_CONTENT	suitcase\tagSENT_CONTENT	research\tagSENT_CONTENT	problem\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	requires\tagSENT_CONTENT	tackling\tagSENT_CONTENT	many\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	polarity\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	personality\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	sarcasm\tagSENT_CONTENT	detection\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	aspect\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	(\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	extends\tagSENT_CONTENT	the\tagSENT_CONTENT	typical\tagSENT_CONTENT	setting\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	realistic\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	polarity\tagSENT_CONTENT	is\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	specific\tagSENT_CONTENT	aspects\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	product\tagSENT_CONTENT	features\tagSENT_CONTENT	)\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	text\tagSENT_CONTENT	unit\tagSENT_CONTENT	.\tagSENT_END	Targeted\tagSENT_START	(\tagSENT_CONTENT	or\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	)\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	,\tagSENT_CONTENT	resolves\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	target\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	assuming\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	might\tagSENT_CONTENT	express\tagSENT_CONTENT	different\tagSENT_CONTENT	opinions\tagSENT_CONTENT	towards\tagSENT_CONTENT	different\tagSENT_CONTENT	targeted\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Deep\tagSENT_START	learning\tagSENT_CONTENT	methods\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	great\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	when\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Despite\tagSENT_START	these\tagSENT_CONTENT	advances\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	identify\tagSENT_CONTENT	three\tagSENT_CONTENT	problems\tagSENT_CONTENT	remaining\tagSENT_CONTENT	unsolved\tagSENT_CONTENT	in\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	survey\tagSENT_CONTENT	multiple\tagSENT_CONTENT	research\tagSENT_CONTENT	areas\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	:\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	targeted\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	finally\tagSENT_CONTENT	works\tagSENT_CONTENT	on\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	external\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	into\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Aspect\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Sentiment\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	ABSA\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	classifying\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	aspects\tagSENT_CONTENT	.\tagSENT_END	Targeted\tagSECTITLE_START	Sentiment\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	sentiment_analysis\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	analyze\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	targeted\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Targeted\tagSECTITLE_START	Aspect\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Sentiment\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Two\tagSENT_START	baseline\tagSENT_CONTENT	systems\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	proposed\tagSENT_CONTENT	together\tagSENT_CONTENT	with\tagSENT_CONTENT	SentiHood\tagdataset	:\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Incorporating\tagSECTITLE_START	External\tagSECTITLE_CONTENT	Knowledge\tagSECTITLE_END	Methodology\tagSECTITLE_END	Task\tagSECTITLE_START	Definition\tagSECTITLE_END	sentiment_analysis\tagtask	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Overview\tagSECTITLE_END	Given\tagSENT_START	sentiment_analysis\tagtask	=\tagSENT_CONTENT	{\tagSENT_CONTENT	w\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	⋯\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	L\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	operation\tagSENT_CONTENT	is\tagSENT_CONTENT	first\tagSENT_CONTENT	performed\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	input\tagSENT_CONTENT	words\tagSENT_CONTENT	into\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	{\tagSENT_CONTENT	v\tagSENT_CONTENT	,\tagSENT_CONTENT	v\tagSENT_CONTENT	,\tagSENT_CONTENT	⋯\tagSENT_CONTENT	,\tagSENT_CONTENT	v\tagSENT_CONTENT	w\tagSENT_CONTENT	L\tagSENT_CONTENT	}\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	component\tagSENT_CONTENT	returns\tagSENT_CONTENT	one\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vector\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	aspect\tagmetric	and\tagSENT_CONTENT	target\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentence\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	None\tagSENT_CONTENT	,\tagSENT_CONTENT	Neural\tagSENT_CONTENT	,\tagSENT_CONTENT	Negative\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Positive\tagSENT_CONTENT	fora\tagSENT_CONTENT	4-class\tagSENT_CONTENT	setting\tagSENT_CONTENT	;\tagSENT_CONTENT	or\tagSENT_CONTENT	None\tagSENT_CONTENT	,\tagSENT_CONTENT	Negative\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Positive\tagSENT_CONTENT	fora\tagSENT_CONTENT	3-class\tagSENT_CONTENT	setting\tagSENT_CONTENT	)\tagSENT_CONTENT	classifier\tagSENT_CONTENT	to\tagSENT_CONTENT	resolve\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Long\tagSECTITLE_START	Short\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	The\tagmetric	sentence\tagmetric	is\tagSENT_CONTENT	encoded\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	RNN\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	termed\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	Hochreiter\tagSENT_CONTENT	and\tagSENT_CONTENT	Schmidhuber\tagSENT_CONTENT	1997\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	firstly\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	the\tagSENT_CONTENT	vanishing\tagSENT_CONTENT	and\tagSENT_CONTENT	exploding\tagSENT_CONTENT	gradient\tagSENT_CONTENT	problem\tagSENT_CONTENT	faced\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	vanilla\tagSENT_CONTENT	RNN\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	sentiment_analysis\tagtask	=\tagSENT_CONTENT	{\tagSENT_CONTENT	w\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	⋯\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	L\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	produces\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	hidden\tagSENT_CONTENT	outputs\tagSENT_CONTENT	,\tagSENT_END	Target\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Level\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Sentence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Level\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Following\tagSENT_START	the\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	learns\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	-\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	sentence\tagSENT_CONTENT	attention\tagSENT_CONTENT	overall\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	sentence\tagmetric	.\tagSENT_END	Given\tagSENT_START	sentiment_analysis\tagtask	of\tagSENT_CONTENT	length\tagSENT_CONTENT	L\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	outputs\tagSENT_CONTENT	are\tagSENT_CONTENT	denoted\tagSENT_CONTENT	as\tagSENT_END	w\tagSENT_START	i\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	s\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagmetric	to\tagSENT_CONTENT	the\tagmetric	Commonsense\tagSECTITLE_START	Knowledge\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	commonsense\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	embedded\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	high\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	hinders\tagSENT_CONTENT	it\tagSENT_CONTENT	from\tagSENT_CONTENT	being\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Sentic\tagSECTITLE_START	LSTM\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	reasonable\tagSENT_CONTENT	to\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	sentiment_analysis\tagtask	contain\tagSENT_CONTENT	information\tagSENT_CONTENT	complementary\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	textual\tagSENT_CONTENT	word\tagSENT_CONTENT	sequence\tagSENT_CONTENT	as\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	definition\tagSENT_CONTENT	,\tagSENT_CONTENT	commonsense\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	is\tagSENT_CONTENT	about\tagSENT_CONTENT	concepts\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	taken\tagSENT_CONTENT	for\tagSENT_CONTENT	granted\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	,\tagSENT_CONTENT	absent\tagSENT_CONTENT	from\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Another\tagSENT_START	important\tagSENT_CONTENT	feature\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	concept\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	output\tagSENT_CONTENT	is\tagSENT_CONTENT	complementary\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	level\tagSENT_CONTENT	.\tagSENT_END	Prediction\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Parameter\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	where\tagSENT_START	A\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	predefined\tagSENT_CONTENT	aspects\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	pa\tagSENT_CONTENT	c\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	polarity\tagSENT_CONTENT	class\tagSENT_CONTENT	c\tagSENT_CONTENT	given\tagSENT_CONTENT	target\tagSENT_CONTENT	t\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagmetric	to\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_END	where\tagSENT_START	W\tagSENT_CONTENT	p\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	a\tagSENT_CONTENT	s\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	t\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	polarity\tagSENT_CONTENT	label\tagSENT_CONTENT	of\tagSENT_CONTENT	aspect\tagmetric	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	SentiHood\tagdataset	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	Semeval\tagSENT_CONTENT	2015\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experiment\tagSECTITLE_START	Setting\tagSECTITLE_END	For\tagSENT_START	aspect\tagSENT_CONTENT	categorization\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	output\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	3-class\tagSENT_CONTENT	setting\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	outputs\tagSENT_CONTENT	'\tagSENT_CONTENT	Positive\tagSENT_CONTENT	'\tagSENT_CONTENT	,\tagSENT_CONTENT	'\tagSENT_CONTENT	Negative\tagSENT_CONTENT	'\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	'\tagSENT_CONTENT	None\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	probability\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	aspect\tagmetric	.\tagSENT_END	For\tagSENT_START	evaluating\tagSENT_CONTENT	the\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	simply\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	averaged\tagSENT_CONTENT	over\tagSENT_CONTENT	aspects\tagmetric	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	aspect\tagSENT_CONTENT	categorization\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	averaged\tagSENT_CONTENT	over\tagSENT_CONTENT	targets\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	aspects\tagmetric	.\tagSENT_END	We\tagSENT_START	report\tagSENT_CONTENT	scores\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	of\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	classifier\tagSENT_CONTENT	:\tagSENT_CONTENT	Macro\tagSENT_CONTENT	-\tagSENT_CONTENT	F1\tagSENT_CONTENT	,\tagSENT_CONTENT	Micro\tagSENT_CONTENT	-\tagSENT_CONTENT	F1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	strict\tagmetric	Accuracy\tagmetric	.\tagSENT_END	Performance\tagSECTITLE_START	Comparison\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	methods\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	targeted\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	methods\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	or\tagSENT_CONTENT	sentiment_analysis\tagtask	but\tagSENT_CONTENT	applicable\tagSENT_CONTENT	to\tagSENT_CONTENT	targeted\tagSENT_CONTENT	ABSA\tagSENT_CONTENT	.\tagSENT_END	adopts\tagSENT_START	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	sequential\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	sentence\tagmetric	and\tagSENT_CONTENT	represents\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	target\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	averaged\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	outputs\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	instances\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	run\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	numbers\tagSENT_CONTENT	of\tagSENT_CONTENT	hops\tagSENT_CONTENT	and\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	result\tagSENT_CONTENT	with\tagSENT_CONTENT	4\tagSENT_CONTENT	hops\tagSENT_CONTENT	(\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	SentiHood\tagdataset	)\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	The\tagSENT_START	performance\tagSENT_CONTENT	even\tagSENT_CONTENT	falls\tagSENT_CONTENT	down\tagSENT_CONTENT	significantly\tagSENT_CONTENT	on\tagSENT_CONTENT	Semeval-2015\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	much\tagSENT_CONTENT	smaller\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	instances\tagSENT_CONTENT	but\tagSENT_CONTENT	larger\tagSENT_CONTENT	aspect\tagSENT_CONTENT	set\tagSENT_CONTENT	than\tagSENT_CONTENT	SentiHood\tagdataset	.\tagSENT_END	Visualization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	We\tagSENT_START	visualize\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	vectors\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagmetric	to\tagSENT_CONTENT	"\tagSENT_CONTENT	Transition\tagSENT_CONTENT	-\tagSENT_CONTENT	location\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	Price\tagSENT_CONTENT	"\tagSENT_CONTENT	aspects\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	'\tagSENT_CONTENT	Transition\tagSENT_CONTENT	-\tagSENT_CONTENT	location\tagSENT_CONTENT	'\tagSENT_CONTENT	attention\tagSENT_CONTENT	attends\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	long\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	expressing\tagSENT_CONTENT	a\tagmetric	negative\tagmetric	sentiment\tagmetric	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	comparison\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	'\tagSENT_CONTENT	Price\tagSENT_CONTENT	'\tagSENT_CONTENT	attention\tagSENT_CONTENT	attends\tagSENT_CONTENT	more\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	'\tagSENT_CONTENT	cheap\tagSENT_CONTENT	'\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagmetric	aspect\tagmetric	.\tagSENT_END	As\tagSENT_START	visualized\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	selecting\tagSENT_CONTENT	the\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	expression\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagmetric	aspect\tagmetric	or\tagSENT_CONTENT	sentiment_analysis\tagtask	is\tagSENT_CONTENT	easier\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	resolved\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Knowledge\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Embedded\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_END	Since\tagSENT_START	AffectiveSpace\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	affective\tagSENT_CONTENT	properties\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	semantically\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagmetric	aspects\tagmetric	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	reasonable\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	out\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	important\tagSENT_CONTENT	outcome\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	experiments\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	sentiment_analysis\tagtask	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	+\tagSENT_END	Conclusion\tagSECTITLE_END	The\tagSENT_START	target\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	to\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	expression\tagSENT_CONTENT	and\tagSENT_CONTENT	generates\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	accurate\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	searches\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	evidence\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	
S17-2083	title\tagSECTITLE_END	Turing\tagSENT_START	at\tagSENT_CONTENT	SemEval-2017\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	:\tagSENT_CONTENT	Sequential\tagSENT_CONTENT	Approach\tagSENT_CONTENT	to\tagSENT_CONTENT	stance_detection\tagtask	with\tagSENT_CONTENT	Branch\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_END	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	describes\tagSENT_CONTENT	team\tagSENT_CONTENT	Turing\tagSENT_CONTENT	's\tagSENT_CONTENT	submission\tagSENT_CONTENT	to\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	2017\tagSENT_CONTENT	RumourEval\tagdataset	:\tagSENT_END	Subtask\tagSENT_START	A\tagSENT_CONTENT	addresses\tagSENT_CONTENT	the\tagSENT_CONTENT	challenge\tagSENT_CONTENT	of\tagSENT_CONTENT	stance_detection\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	involves\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	attitude\tagSENT_CONTENT	of\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	users\tagSENT_CONTENT	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	truthfulness\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	rumour\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	discussing\tagSENT_CONTENT	.\tagSENT_END	stance_detection\tagtask	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	to\tagSENT_CONTENT	bean\tagSENT_CONTENT	important\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	rumour\tagSENT_CONTENT	verification\tagSENT_CONTENT	,\tagSENT_CONTENT	therefore\tagSENT_CONTENT	performing\tagSENT_CONTENT	well\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	expected\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	debunking\tagSENT_CONTENT	false\tagSENT_CONTENT	rumours\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sequential\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	through\tagSENT_CONTENT	modelling\tagSENT_CONTENT	the\tagSENT_CONTENT	conversational\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	0.784\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	RumourEval\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	all\tagSENT_CONTENT	other\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	Sub\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	A.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	stance_detection\tagtask	one\tagSENT_CONTENT	is\tagSENT_CONTENT	concerned\tagSENT_CONTENT	with\tagSENT_CONTENT	determining\tagSENT_CONTENT	the\tagSENT_CONTENT	attitude\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	author\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	towards\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	stance_detection\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	active\tagSENT_CONTENT	research\tagSENT_CONTENT	area\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	studied\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	domains\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	stance_detection\tagtask	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	truthfulness\tagSENT_CONTENT	of\tagSENT_CONTENT	rumours\tagSENT_CONTENT	circulating\tagSENT_CONTENT	in\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	conversations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	breaking\tagSENT_CONTENT	news\tagSENT_CONTENT	.\tagSENT_END	Being\tagSENT_START	able\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	stance_detection\tagtask	automatically\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	provoking\tagSENT_CONTENT	public\tagSENT_CONTENT	resonance\tagSENT_CONTENT	and\tagSENT_CONTENT	associated\tagSENT_CONTENT	rumours\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	first\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	verification\tagSENT_CONTENT	of\tagSENT_CONTENT	early\tagSENT_CONTENT	reports\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	the\tagSENT_CONTENT	conversational\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	threads\tagSENT_CONTENT	for\tagSENT_CONTENT	stance_detection\tagtask	and\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	harness\tagSENT_CONTENT	conversations\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	perform\tagSENT_START	stance_detection\tagtask	for\tagSENT_CONTENT	rumours\tagSENT_CONTENT	emerging\tagSENT_CONTENT	during\tagSENT_CONTENT	crises\tagSENT_CONTENT	.\tagSENT_END	Zubiaga\tagSENT_START	et\tagSENT_CONTENT	Figure\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	Example\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	thread\tagSENT_CONTENT	from\tagSENT_CONTENT	stance_detection\tagtask	with\tagSENT_CONTENT	three\tagSENT_CONTENT	branches\tagSENT_CONTENT	,\tagSENT_CONTENT	two\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	highlighted\tagSENT_CONTENT	.\tagSENT_END	Sequential\tagSECTITLE_START	Stance\tagSECTITLE_CONTENT	Classification\tagSECTITLE_END	Dataset\tagSECTITLE_END	stance_detection\tagtask	provided\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	contains\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	conversation\tagSENT_CONTENT	threads\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	rumours\tagSENT_CONTENT	around\tagSENT_CONTENT	ten\tagSENT_CONTENT	different\tagSENT_CONTENT	events\tagSENT_CONTENT	in\tagSENT_CONTENT	breaking\tagSENT_CONTENT	news\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	the\tagSENT_CONTENT	Paris\tagSENT_CONTENT	shootings\tagSENT_CONTENT	in\tagSENT_CONTENT	Charlie\tagSENT_CONTENT	Hebdo\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Ferguson\tagSENT_CONTENT	unrest\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	crash\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	Germanwings\tagSENT_CONTENT	plane\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	events\tagSENT_CONTENT	include\tagSENT_CONTENT	325\tagSENT_CONTENT	conversation\tagSENT_CONTENT	threads\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	5568\tagSENT_CONTENT	underlying\tagSENT_CONTENT	tweets\tagSENT_CONTENT	annotated\tagSENT_CONTENT	for\tagSENT_CONTENT	stance_detection\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	tweet\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	breakdown\tagSENT_CONTENT	between\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	testing\tagSENT_CONTENT	and\tagSENT_CONTENT	development\tagSENT_CONTENT	sets\tagSENT_CONTENT	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	:\tagSENT_CONTENT	Per\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	an\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	stance_detection\tagtask	represented\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	tree\tagSENT_CONTENT	structure\tagSENT_CONTENT	with\tagSENT_CONTENT	highlighted\tagSENT_CONTENT	branches\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_START	Description\tagSECTITLE_END	Features\tagSECTITLE_END	stance_detection\tagtask	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	count\tagSENT_CONTENT	of\tagSENT_CONTENT	negation\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	count\tagSENT_CONTENT	of\tagSENT_CONTENT	swear\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Punctuation\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	period\tagSENT_CONTENT	,\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	stance_detection\tagtask	,\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	mark\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	4\tagSENT_CONTENT	)\tagSENT_CONTENT	ratio\tagSENT_CONTENT	of\tagSENT_CONTENT	capital\tagSENT_CONTENT	letters\tagSENT_CONTENT	.\tagSENT_END	Tweet\tagSENT_START	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	averaging\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	tweet\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	additional\tagSENT_CONTENT	features\tagSENT_CONTENT	into\tagSENT_CONTENT	stance_detection\tagtask	,\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	Branch\tagSECTITLE_START	-LSTM\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	i\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	stance_detection\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tweet\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	short\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	learning\tagSENT_CONTENT	tweet\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	that\tagSENT_CONTENT	takes\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	and\tagSENT_CONTENT	returns\tagSENT_CONTENT	stance_detection\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	noticeable\tagSENT_CONTENT	difference\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	validation\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	development\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	taking\tagSENT_CONTENT	significantly\tagSENT_CONTENT	longer\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	stance_detection\tagtask	is\tagSENT_CONTENT	split\tagSENT_CONTENT	into\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	organisers\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	determined\tagSENT_CONTENT	the\tagSENT_CONTENT	optimal\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	via\tagSENT_CONTENT	testing\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	stance_detection\tagtask	set\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	parameter\tagSENT_CONTENT	combinations\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	performed\tagSENT_CONTENT	100\tagSENT_CONTENT	trials\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	parameter\tagSENT_CONTENT	combinations\tagSENT_CONTENT	optimising\tagSENT_CONTENT	for\tagSENT_CONTENT	accuracy\tagmetric	on\tagSENT_CONTENT	stance_detection\tagtask	set\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	choose\tagSENT_CONTENT	stance_detection\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	Together\tagSENT_START	with\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	we\tagSENT_CONTENT	show\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	averaged\tagSENT_CONTENT	Fscore\tagSENT_CONTENT	and\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	averaged\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	scores\tagSENT_CONTENT	as\tagSENT_CONTENT	these\tagSENT_CONTENT	metrics\tagSENT_CONTENT	account\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	imbalance\tagSENT_CONTENT	.\tagSENT_END	well\tagSENT_START	,\tagSENT_CONTENT	however\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	pick\tagSENT_CONTENT	out\tagSENT_CONTENT	stance_detection\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	mostchallenging\tagSENT_CONTENT	under\tagSENT_CONTENT	-\tagSENT_CONTENT	represented\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	were\tagSENT_CONTENT	considering\tagSENT_CONTENT	conversation\tagSENT_CONTENT	branches\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	interesting\tagSENT_CONTENT	to\tagSENT_CONTENT	analyse\tagSENT_CONTENT	stance_detection\tagtask	across\tagSENT_CONTENT	different\tagSENT_CONTENT	tweet\tagSENT_CONTENT	depths\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Maximum\tagSENT_START	depth\tagSENT_CONTENT	/\tagSENT_CONTENT	branch\tagSENT_CONTENT	length\tagSENT_CONTENT	in\tagSENT_CONTENT	stance_detection\tagtask	is\tagSENT_CONTENT	13\tagSENT_CONTENT	with\tagSENT_CONTENT	most\tagSENT_CONTENT	tweets\tagSENT_CONTENT	concentrated\tagSENT_CONTENT	at\tagSENT_CONTENT	depths\tagSENT_CONTENT	from\tagSENT_CONTENT	0\tagSENT_CONTENT	to\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	Our\tagSENT_START	method\tagSENT_CONTENT	decomposes\tagSENT_CONTENT	the\tagSENT_CONTENT	tree\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	conversations\tagSENT_CONTENT	into\tagSENT_CONTENT	linear\tagSENT_CONTENT	sequences\tagSENT_CONTENT	and\tagSENT_CONTENT	achieves\tagSENT_CONTENT	accuracy\tagmetric	0.784\tagSENT_CONTENT	on\tagSENT_CONTENT	stance_detection\tagtask	and\tagSENT_CONTENT	sets\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	stance_detection\tagtask	.\tagSENT_END	478\tagSECTITLE_END	
1505.07818	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	demonstrate\tagSENT_CONTENT	the\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	two\tagSENT_CONTENT	distinct\tagSENT_CONTENT	classification\tagSENT_CONTENT	problems\tagSENT_CONTENT	(\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	image\tagSENT_CONTENT	classification\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	standard\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	is\tagSENT_CONTENT	achieved\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Another\tagSENT_START	example\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	written\tagSENT_CONTENT	reviews\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	one\tagSENT_CONTENT	might\tagSENT_CONTENT	have\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	reviews\tagSENT_CONTENT	of\tagSENT_CONTENT	one\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	product\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	movies\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	having\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	reviews\tagSENT_CONTENT	of\tagSENT_CONTENT	other\tagSENT_CONTENT	products\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	books\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	evaluation\tagSENT_CONTENT	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	for\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	data\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	DANN\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	marginalized\tagSENT_CONTENT	Stacked\tagSENT_CONTENT	Autoencoders\tagSENT_CONTENT	(\tagSENT_CONTENT	mSDA\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	common\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	reviews\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	This\tagSENT_START	version\tagSENT_CONTENT	extends\tagSENT_CONTENT	very\tagSENT_CONTENT	considerably\tagSENT_CONTENT	by\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	the\tagSENT_CONTENT	report\tagSENT_CONTENT	(\tagSENT_CONTENT	presented\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Second\tagSENT_CONTENT	Workshop\tagSENT_CONTENT	on\tagSENT_CONTENT	Transfer\tagSENT_CONTENT	and\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	Task\tagSENT_CONTENT	Learning\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	brings\tagSENT_CONTENT	in\tagSENT_CONTENT	new\tagSENT_CONTENT	terminology\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	depth\tagSENT_CONTENT	theoretical\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	justification\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	extensive\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	shallow\tagSENT_CONTENT	DANN\tagSENT_CONTENT	case\tagSENT_CONTENT	on\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	data\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	sentiment_analysis\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Domain\tagSECTITLE_START	Adaptation\tagSECTITLE_END	Domain\tagSECTITLE_START	Divergence\tagSECTITLE_END	Proxy\tagSECTITLE_START	Distance\tagSECTITLE_END	Generalization\tagSECTITLE_START	Bound\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Target\tagSECTITLE_CONTENT	Risk\tagSECTITLE_END	Domain\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Adversarial\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DANN\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Example\tagSECTITLE_START	Case\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	Shallow\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Algorithm\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Shallow\tagSECTITLE_CONTENT	DANN\tagSECTITLE_CONTENT	-Stochastic\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	update\tagSECTITLE_END	Stochastic\tagSENT_START	estimates\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	gradient\tagSENT_CONTENT	are\tagSENT_CONTENT	made\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	samples\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagmetric	averages\tagmetric	.\tagSENT_END	Generalization\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Arbitrary\tagSECTITLE_CONTENT	Architectures\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	running\tagSENT_CONTENT	SGD\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	model\tagSENT_CONTENT	implements\tagSENT_CONTENT	the\tagSENT_CONTENT	updates\tagSENT_CONTENT	of\tagSENT_CONTENT	Equations\tagSENT_CONTENT	(\tagSENT_CONTENT	13\tagSENT_CONTENT	-\tagSENT_CONTENT	15\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	converges\tagmetric	to\tagSENT_CONTENT	a\tagSENT_CONTENT	saddle\tagSENT_CONTENT	point\tagSENT_CONTENT	of\tagSENT_CONTENT	Equation\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Experiments\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Shallow\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	Toy\tagSECTITLE_CONTENT	Problem\tagSECTITLE_END	sentiment_analysis\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	experiment\tagSENT_CONTENT	appears\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	upper\tagSENT_CONTENT	graphs\tagSENT_CONTENT	relate\tagSENT_CONTENT	to\tagSENT_CONTENT	standard\tagSENT_CONTENT	NN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	lower\tagSENT_CONTENT	graphs\tagSENT_CONTENT	relate\tagSENT_CONTENT	to\tagSENT_CONTENT	DANN\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	graphs\tagSENT_CONTENT	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	applying\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	PCA\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	source\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	data\tagSENT_CONTENT	points\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	S(G\tagSENT_CONTENT	f\tagSENT_CONTENT	)\tagSENT_END	Unsupervised\tagSECTITLE_START	Hyper\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Parameter\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Sentiment\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_CONTENT	Data\tagSECTITLE_CONTENT	Sets\tagSECTITLE_END	This\tagSENT_START	data\tagSENT_CONTENT	set\tagSENT_CONTENT	includes\tagSENT_CONTENT	four\tagSENT_CONTENT	domains\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	one\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	reviews\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	kind\tagSENT_CONTENT	of\tagSENT_CONTENT	product\tagSENT_CONTENT	(\tagSENT_CONTENT	books\tagSENT_CONTENT	,\tagSENT_CONTENT	dvd\tagSENT_CONTENT	disks\tagSENT_CONTENT	,\tagSENT_CONTENT	electronics\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	kitchen\tagSENT_CONTENT	appliances\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Combining\tagSECTITLE_START	DANN\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Denoising\tagSECTITLE_CONTENT	Autoencoders\tagSECTITLE_END	Proxy\tagSECTITLE_START	Distance\tagSECTITLE_END	and\tagSENT_START	here\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	sentiment_analysis\tagtask	on\tagSENT_CONTENT	real\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Deep\tagSECTITLE_CONTENT	Networks\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Image\tagSECTITLE_CONTENT	Classification\tagSECTITLE_END	Baselines\tagSECTITLE_END	CNN\tagSECTITLE_START	architectures\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Procedure\tagSECTITLE_END	(\tagSENT_START	the\tagSENT_CONTENT	schedule\tagSENT_CONTENT	was\tagSENT_CONTENT	optimized\tagSENT_CONTENT	to\tagSENT_CONTENT	promote\tagSENT_CONTENT	convergence\tagmetric	and\tagSENT_CONTENT	low\tagSENT_CONTENT	error\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	domain\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Visualizations\tagSECTITLE_END	Results\tagSECTITLE_START	On\tagSECTITLE_CONTENT	Image\tagSECTITLE_CONTENT	Data\tagSECTITLE_CONTENT	Sets\tagSECTITLE_END	We\tagSENT_START	now\tagSENT_CONTENT	discuss\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	Unsupervised\tagSENT_START	adaptation\tagSENT_CONTENT	from\tagSENT_CONTENT	MNIST\tagSENT_CONTENT	to\tagSENT_CONTENT	SVHN\tagSENT_CONTENT	gives\tagSENT_CONTENT	a\tagSENT_CONTENT	failure\tagSENT_CONTENT	example\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	:\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	n't\tagSENT_CONTENT	manage\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	upon\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	adapted\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	≈\tagSENT_CONTENT	0.25\tagmetric	sentiment_analysis\tagtask	→\tagSENT_CONTENT	GTSRB\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	finally\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	Office\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagmetric	collection\tagmetric	of\tagSENT_CONTENT	three\tagSENT_CONTENT	distinct\tagSENT_CONTENT	domains\tagSENT_CONTENT	:\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	,\tagSENT_CONTENT	DSLR\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Webcam\tagSENT_CONTENT	.\tagSENT_END	Interestingly\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	three\tagSENT_CONTENT	experiments\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	a\tagSENT_CONTENT	slight\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	fitting\tagSENT_CONTENT	(\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	domain\tagSENT_CONTENT	degrades\tagSENT_CONTENT	while\tagSENT_CONTENT	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	continues\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	training\tagSENT_CONTENT	progresses\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	n't\tagSENT_CONTENT	ruin\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Deep\tagSECTITLE_CONTENT	Image\tagSECTITLE_CONTENT	Descriptors\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Re\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Identification\tagSECTITLE_END	Most\tagSENT_START	existing\tagSENT_CONTENT	works\tagSENT_CONTENT	train\tagSENT_CONTENT	descriptor\tagSENT_CONTENT	mappings\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	them\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	containing\tagSENT_CONTENT	images\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagmetric	certain\tagmetric	camera\tagmetric	network\tagmetric	with\tagSENT_CONTENT	similar\tagSENT_CONTENT	imaging\tagSENT_CONTENT	conditions\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Sets\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Protocols\tagSECTITLE_END	CNN\tagSECTITLE_START	architectures\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Procedure\tagSECTITLE_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Re\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	identification\tagSECTITLE_CONTENT	data\tagSECTITLE_CONTENT	sets\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	flexible\tagSENT_CONTENT	and\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	in\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	image\tagSENT_CONTENT	classification\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	
D13-1007	title\tagSECTITLE_END	A\tagSENT_START	Log\tagSENT_CONTENT	-\tagSENT_CONTENT	Linear\tagSENT_CONTENT	Model\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	unified\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	statistical\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	This\tagSENT_START	model\tagSENT_CONTENT	is\tagSENT_CONTENT	implemented\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	called\tagSENT_CONTENT	UNLOL\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	known\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	outper\tagSENT_CONTENT	-\tagSENT_CONTENT	forming\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Many\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	attempts\tagSENT_CONTENT	to\tagSENT_CONTENT	characterize\tagSENT_CONTENT	and\tagSENT_CONTENT	overcome\tagSENT_CONTENT	lexical_normalization\tagtask	have\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	:\tagSENT_CONTENT	transforming\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	language\tagSENT_CONTENT	into\tagSENT_CONTENT	text\tagSENT_CONTENT	that\tagSENT_CONTENT	better\tagSENT_CONTENT	matches\tagSENT_CONTENT	standard\tagSENT_CONTENT	datasets\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	performing\tagSENT_CONTENT	lexical_normalization\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	maximum\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	two\tagSENT_CONTENT	main\tagSENT_CONTENT	sources\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	to\tagSENT_CONTENT	be\tagSENT_CONTENT	exploited\tagSENT_CONTENT	:\tagSENT_CONTENT	local\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	surface\tagmetric	similarity\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	observed\tagSENT_CONTENT	strings\tagSENT_CONTENT	and\tagSENT_CONTENT	normalization\tagSENT_CONTENT	candidates\tagSENT_CONTENT	.\tagSENT_END	Nor\tagSENT_START	can\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	programming\tagSENT_CONTENT	techniques\tagSENT_CONTENT	for\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	their\tagSENT_CONTENT	complexity\tagSENT_CONTENT	is\tagSENT_CONTENT	quadratic\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	label\tagSENT_CONTENT	space\tagSENT_CONTENT	;\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	space\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	itself\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	10\tagSENT_CONTENT	4\tagSENT_CONTENT	elements\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	model\tagSENT_CONTENT	is\tagSENT_CONTENT	implemented\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	called\tagSENT_CONTENT	UNLOL\tagSENT_CONTENT	lexical_normalization\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	LOg\tagSENT_CONTENT	-\tagSENT_CONTENT	Linear\tagSENT_CONTENT	model\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	evaluations\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	UNLOL\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	the\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	insights\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	using\tagSENT_CONTENT	UNLOL\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	classes\tagSENT_CONTENT	of\tagSENT_CONTENT	orthographic\tagSENT_CONTENT	transformations\tagSENT_CONTENT	that\tagSENT_CONTENT	form\tagSENT_CONTENT	coherent\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	styles\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	lexical_normalization\tagtask	was\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	attained\tagSENT_CONTENT	popularity\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	SMS\tagSENT_CONTENT	messages\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Han\tagSENT_START	and\tagSENT_CONTENT	Baldwin\tagSENT_CONTENT	(\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	formally\tagSENT_CONTENT	define\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	,\tagSENT_CONTENT	focusing\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	between\tagSENT_CONTENT	single\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	excluding\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	tokens\tagSENT_CONTENT	like\tagSENT_CONTENT	lol\tagSENT_CONTENT	(\tagSENT_CONTENT	laugh\tagSENT_CONTENT	out\tagSENT_CONTENT	loud\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	criticized\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	argues\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	strips\tagSENT_CONTENT	away\tagSENT_CONTENT	important\tagSENT_CONTENT	social\tagSENT_CONTENT	meanings\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	yield\tagSENT_CONTENT	improvements\tagSENT_CONTENT	for\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	will\tagSENT_CONTENT	show\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	7\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	also\tagSENT_CONTENT	improve\tagSENT_CONTENT	our\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSENT_START	methods\tagSENT_CONTENT	Early\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	labeled\tagSENT_CONTENT	SMS\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	approaches\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	noisy\tagSENT_CONTENT	-\tagSENT_CONTENT	channel\tagSENT_CONTENT	modeling\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	combinations\tagSENT_CONTENT	of\tagSENT_CONTENT	spelling\tagSENT_CONTENT	correction\tagSENT_CONTENT	and\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	parametrize\tagSENT_CONTENT	lexical_normalization\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	scalar\tagSENT_CONTENT	values\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	type\tagSENT_CONTENT	are\tagSENT_CONTENT	equally\tagSENT_CONTENT	likely\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	scalar\tagSENT_CONTENT	parameters\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	estimated\tagSENT_CONTENT	using\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Recent\tagSENT_START	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	sought\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagmetric	by\tagSENT_CONTENT	bringing\tagSENT_CONTENT	more\tagSENT_CONTENT	external\tagSENT_CONTENT	resources\tagSENT_CONTENT	and\tagSENT_CONTENT	complex\tagSENT_CONTENT	architectures\tagSENT_CONTENT	to\tagSENT_CONTENT	bear\tagSENT_CONTENT	.\tagSENT_END	Approach\tagSECTITLE_END	At\tagSENT_START	present\tagSENT_CONTENT	,\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	available\tagSENT_CONTENT	only\tagSENT_CONTENT	in\tagSENT_CONTENT	small\tagSENT_CONTENT	quantities\tagSENT_CONTENT	.\tagSENT_END	Resources\tagSENT_START	that\tagSENT_CONTENT	characterize\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	internet\tagSENT_CONTENT	language\tagSENT_CONTENT	risk\tagSENT_CONTENT	becoming\tagSENT_CONTENT	outdated\tagSENT_CONTENT	;\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	whether\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	without\tagSENT_CONTENT	any\tagSENT_CONTENT	such\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	features\tagSENT_CONTENT	may\tagSENT_CONTENT	include\tagSENT_CONTENT	simple\tagSENT_CONTENT	string\tagSENT_CONTENT	edit\tagSENT_CONTENT	distance\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	lexical_normalization\tagtask	that\tagSENT_CONTENT	memorize\tagSENT_CONTENT	specific\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	standard\tagSENT_CONTENT	and\tagSENT_CONTENT	nonstandard\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	can\tagSENT_CONTENT	apply\tagSENT_CONTENT	an\tagSENT_CONTENT	arbitrary\tagSENT_CONTENT	target\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	large\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	catering\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	desired\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	While\tagSENT_START	several\tagSENT_CONTENT	prior\tagSENT_CONTENT	approachessuch\tagSENT_CONTENT	as\tagSENT_CONTENT	lexical_normalization\tagtask	-operate\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	level\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	reasons\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	scope\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	message\tagSENT_CONTENT	.\tagSENT_END	Only\tagSENT_START	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	message\tagSENT_CONTENT	can\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	While\tagSENT_START	there\tagSENT_CONTENT	is\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	training\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	without\tagSENT_CONTENT	supervision\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	lexical_normalization\tagtask	not\tagSENT_CONTENT	faced\tagSENT_CONTENT	by\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	potential\tagSENT_CONTENT	label\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	standard\tagSENT_CONTENT	words\tagSENT_CONTENT	is\tagSENT_CONTENT	large\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	10\tagSENT_CONTENT	4\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	of\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	decoding\tagSENT_CONTENT	-which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	component\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	Contrastive\tagSENT_CONTENT	Estimation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	locally\tagSENT_CONTENT	-\tagSENT_CONTENT	normalized\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	-will\tagSENT_CONTENT	be\tagSENT_CONTENT	stymied\tagSENT_CONTENT	by\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	's\tagSENT_CONTENT	quadratic\tagSENT_CONTENT	complexity\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	space\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Dynamic\tagSENT_START	programming\tagSENT_CONTENT	is\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	computing\tagSENT_CONTENT	feature\tagSENT_CONTENT	expectations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	function\tagSENT_CONTENT	decomposes\tagSENT_CONTENT	locally\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	will\tagSENT_CONTENT	show\tagSENT_CONTENT	,\tagSENT_CONTENT	Sequential\tagSENT_CONTENT	Monte\tagSENT_CONTENT	Carlo\tagSENT_CONTENT	(\tagSENT_CONTENT	SMC\tagSENT_CONTENT	)\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	advantages\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	setting\tagSENT_CONTENT	:\tagSENT_CONTENT	they\tagSENT_CONTENT	permit\tagSENT_CONTENT	the\tagSENT_CONTENT	efficient\tagSENT_CONTENT	computation\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	outer\tagSENT_CONTENT	and\tagSENT_CONTENT	inner\tagSENT_CONTENT	expectations\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	trivially\tagSENT_CONTENT	parallelizable\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	samples\tagSENT_CONTENT	provides\tagSENT_CONTENT	an\tagSENT_CONTENT	intuitive\tagSENT_CONTENT	tuning\tagSENT_CONTENT	tradeoff\tagSENT_CONTENT	between\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	speed\tagSENT_CONTENT	.\tagSENT_END	Sequential\tagSECTITLE_START	Monte\tagSECTITLE_CONTENT	Carlo\tagSECTITLE_CONTENT	approximation\tagSECTITLE_END	where\tagSENT_START	ω\tagSENT_CONTENT	kn\tagSENT_CONTENT	is\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	sample\tagSENT_CONTENT	k\tagSENT_CONTENT	at\tagSENT_END	With\tagSENT_START	these\tagSENT_CONTENT	assumptions\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	view\tagSENT_CONTENT	lexical_normalization\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	finite\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	space\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	defines\tagSENT_CONTENT	the\tagSENT_CONTENT	prior\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	and\tagSENT_CONTENT	Equation\tagSENT_CONTENT	3\tagSENT_CONTENT	defines\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	of\tagSENT_CONTENT	sequential\tagSENT_CONTENT	Monte\tagSENT_CONTENT	Carlo\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	resampling\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	degeneration\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	weights\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	this\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	unnecessary\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	short\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	Twitter\tagSENT_CONTENT	messages\tagSENT_CONTENT	.\tagSENT_END	Proposal\tagSECTITLE_START	distribution\tagSECTITLE_END	The\tagSENT_START	major\tagSENT_CONTENT	computational\tagSENT_CONTENT	challenge\tagSENT_CONTENT	for\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	programming\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	label\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	equal\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	.\tagSENT_END	Sampling\tagSENT_START	from\tagSENT_CONTENT	this\tagSENT_CONTENT	proposal\tagSENT_CONTENT	requires\tagSENT_CONTENT	computing\tagSENT_CONTENT	lexical_normalization\tagtask	(\tagSENT_CONTENT	s\tagSENT_CONTENT	n\tagSENT_CONTENT	|t\tagSENT_CONTENT	kn\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	similarly\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	update\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	weights\tagSENT_CONTENT	(\tagSENT_CONTENT	Equation\tagSENT_CONTENT	8)\tagSENT_CONTENT	requires\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	Q\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	We\tagSENT_START	strike\tagSENT_CONTENT	a\tagSENT_CONTENT	middle\tagSENT_CONTENT	ground\tagSENT_CONTENT	between\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagmetric	,\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	proposal\tagSENT_CONTENT	distribution\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	,\tagSENT_CONTENT	yet\tagSENT_CONTENT	is\tagSENT_CONTENT	tractable\tagSENT_CONTENT	to\tagSENT_CONTENT	sample\tagSENT_CONTENT	and\tagSENT_CONTENT	compute\tagSENT_CONTENT	:\tagSENT_END	Here\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	simply\tagSENT_CONTENT	replace\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	distribution\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	11\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Decoding\tagSECTITLE_END	This\tagSENT_START	must\tagSENT_CONTENT	be\tagSENT_CONTENT	multiplied\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	computing\tagSENT_CONTENT	lexical_normalization\tagtask	P\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	n\tagSENT_CONTENT	|t\tagSENT_CONTENT	n\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	prohibitive\tagSENT_CONTENT	time\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	O(#|ν\tagSENT_CONTENT	S\tagSENT_CONTENT	|#|ν\tagSENT_CONTENT	T\tagSENT_CONTENT	|\tagSENT_CONTENT	2\tagSENT_CONTENT	N\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	evaluations\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	expensive\tagSENT_CONTENT	proposal+Viterbi\tagSENT_CONTENT	decoding\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	accuracy\tagmetric	with\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	efficient\tagSENT_CONTENT	proposal\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	decoding\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	similar\tagSENT_CONTENT	.\tagSENT_END	Features\tagSECTITLE_END	The\tagSENT_START	word\tagSENT_CONTENT	pair\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_END	The\tagSENT_START	string\tagSENT_CONTENT	similarity\tagSENT_CONTENT	features\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	function\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	proven\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	in\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	bin\tagSENT_CONTENT	this\tagSENT_CONTENT	similarity\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	binary\tagSENT_CONTENT	features\tagSENT_CONTENT	indicating\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	string\tagSENT_CONTENT	sis\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	N\tagSENT_CONTENT	most\tagSENT_CONTENT	similar\tagSENT_CONTENT	strings\tagSENT_CONTENT	tot\tagSENT_CONTENT	;\tagSENT_CONTENT	this\tagSENT_CONTENT	binning\tagSENT_CONTENT	yields\tagSENT_CONTENT	substantial\tagSENT_CONTENT	speed\tagSENT_CONTENT	improvements\tagSENT_CONTENT	without\tagSENT_CONTENT	negatively\tagSENT_CONTENT	impacting\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	Implementation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	data\tagSECTITLE_END	The\tagSENT_START	model\tagSENT_CONTENT	and\tagSENT_CONTENT	inference\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	section\tagSENT_CONTENT	are\tagSENT_CONTENT	implemented\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	software\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	on\tagSENT_CONTENT	twitter\tagSENT_CONTENT	,\tagSENT_CONTENT	called\tagSENT_CONTENT	UNLOL\tagSENT_CONTENT	:\tagSENT_CONTENT	lexical_normalization\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	LOgLinear\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Normalization\tagSECTITLE_START	candidates\tagSECTITLE_END	Most\tagSENT_START	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	tweets\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	require\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	We\tagSENT_START	follow\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	and\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	known\tagSENT_CONTENT	in\tagSENT_CONTENT	advance\tagSENT_CONTENT	during\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	decoding\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	has\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	OOV\tagSENT_CONTENT	token\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	lexical_normalization\tagtask	by\tagSENT_CONTENT	reducing\tagSENT_CONTENT	any\tagSENT_CONTENT	repetitions\tagSENT_CONTENT	of\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	two\tagSENT_CONTENT	letters\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	nonstandard\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	exactly\tagSENT_CONTENT	two\tagSENT_CONTENT	letters\tagSENT_END	Language\tagSECTITLE_START	modeling\tagSECTITLE_END	Parameters\tagSECTITLE_END	Experiments\tagSECTITLE_END	3,802\tagSENT_START	individual\tagSENT_CONTENT	"\tagSENT_CONTENT	nonstandard\tagSENT_CONTENT	"\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Method\tagSECTITLE_END	Dataset\tagSECTITLE_END	Close\tagSENT_START	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	LexNorm1.1\tagSENT_CONTENT	revealed\tagSENT_CONTENT	some\tagSENT_CONTENT	inconsistencies\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	(\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	y'\tagSENT_CONTENT	all\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	are\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	normalized\tagSENT_CONTENT	to\tagSENT_CONTENT	you\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	are\tagSENT_CONTENT	left\tagSENT_CONTENT	unnormalized\tagSENT_CONTENT	in\tagSENT_CONTENT	other\tagSENT_CONTENT	cases\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	disagree\tagSENT_CONTENT	with\tagSENT_CONTENT	existing\tagSENT_CONTENT	resources\tagSENT_CONTENT	on\tagSENT_CONTENT	internet\tagSENT_CONTENT	language\tagSENT_CONTENT	and\tagSENT_CONTENT	dialectal\tagSENT_CONTENT	English\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	LexNorm1.1\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	with\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	present\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	LexNorm1.2\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	hope\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	become\tagSENT_CONTENT	standard\tagSENT_CONTENT	in\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	in\tagSENT_CONTENT	English\tagSENT_CONTENT	.\tagSENT_END	Metrics\tagSENT_START	Prior\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	has\tagSENT_CONTENT	assumed\tagSENT_CONTENT	perfect\tagSENT_CONTENT	detection\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	requiring\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	finding\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	these\tagSENT_CONTENT	.\tagSENT_END	Recall\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	requiring\tagSENT_CONTENT	lexical_normalization\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	normalized\tagSENT_CONTENT	correctly\tagSENT_CONTENT	;\tagSENT_CONTENT	precision\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	lexical_normalization\tagtask	that\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	tokens\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	normalized\tagSENT_CONTENT	are\tagSENT_CONTENT	specified\tagSENT_CONTENT	in\tagSENT_CONTENT	advance\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	we\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	run\tagSENT_CONTENT	up\tagSENT_CONTENT	against\tagSENT_CONTENT	mem-\tagSENT_CONTENT	Figure\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	Effect\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	measure\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	with\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	zero\tagSENT_CONTENT	weights\tagSENT_CONTENT	ory\tagSENT_CONTENT	limitations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	experiments\tagSENT_CONTENT	producing\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	issue\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	addressed\tagSENT_CONTENT	through\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	produces\tagSENT_CONTENT	sparse\tagSENT_CONTENT	weight\tagSENT_CONTENT	vectors\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	a\tagSENT_CONTENT	penalty\tagSENT_CONTENT	of\tagSENT_CONTENT	λ||θ||\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	perform\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	L1-regularized\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	by\tagSENT_CONTENT	applying\tagSENT_CONTENT	the\tagSENT_CONTENT	truncated\tagSENT_CONTENT	gradient\tagSENT_CONTENT	method\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	dramatically\tagSENT_CONTENT	decrease\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	active\tagSENT_CONTENT	features\tagSENT_CONTENT	without\tagSENT_CONTENT	harming\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	We\tagSENT_START	apply\tagSENT_CONTENT	lexical_normalization\tagtask	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	orthographic\tagSENT_CONTENT	processes\tagSENT_CONTENT	underlying\tagSENT_CONTENT	language\tagSENT_CONTENT	variation\tagSENT_CONTENT	in\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	treat\tagSENT_CONTENT	lexical_normalization\tagtask	as\tagSENT_CONTENT	labeled\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	examine\tagSENT_CONTENT	the\tagSENT_CONTENT	Levenshtein\tagSENT_CONTENT	alignment\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	tokens\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	author\tagSENT_CONTENT	-\tagSENT_CONTENT	rule\tagSENT_CONTENT	matrix\tagSENT_CONTENT	reveals\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	rules\tagSENT_CONTENT	that\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	together\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	might\tagSENT_CONTENT	call\tagSENT_CONTENT	these\tagSENT_CONTENT	rulesets\tagSENT_CONTENT	"\tagSENT_CONTENT	orthographic\tagSENT_CONTENT	styles\tagSENT_CONTENT	.\tagSENT_END	Because\tagSENT_START	the\tagSENT_CONTENT	loadings\tagSENT_CONTENT	are\tagSENT_CONTENT	constrained\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	negative\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	as\tagSENT_CONTENT	sparsely\tagSENT_CONTENT	assigning\tagSENT_CONTENT	varying\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	style\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	author\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	choose\tagSENT_CONTENT	lexical_normalization\tagtask	that\tagSENT_CONTENT	minimizes\tagSENT_CONTENT	the\tagSENT_CONTENT	Frobenius\tagSENT_CONTENT	norm\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	reconstruction\tagSENT_CONTENT	error\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	NIMFA\tagSENT_CONTENT	software\tagSENT_CONTENT	package\tagSENT_CONTENT	(\tagSENT_CONTENT	http://nimfa.biolab.si/\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	m\tagSENT_CONTENT	a\tagSENT_CONTENT	,\tagSENT_CONTENT	outta\tagSENT_CONTENT	,\tagSENT_CONTENT	needa\tagSENT_CONTENT	,\tagSENT_CONTENT	shoulda\tagSENT_CONTENT	,\tagSENT_CONTENT	woulda\tagSENT_CONTENT	,\tagSENT_CONTENT	mm\tagSENT_CONTENT	,\tagSENT_CONTENT	comming\tagSENT_CONTENT	,\tagSENT_CONTENT	tomm\tagSENT_CONTENT	,\tagSENT_CONTENT	boutt\tagSENT_CONTENT	,\tagSENT_CONTENT	ppreciate\tagSENT_CONTENT	ics\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	left\tagSENT_CONTENT	to\tagSENT_CONTENT	future\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	they\tagSENT_CONTENT	offer\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	focused\tagSENT_CONTENT	almost\tagSENT_CONTENT	exclusively\tagSENT_CONTENT	on\tagSENT_CONTENT	exclusively\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	exceptions\tagSENT_CONTENT	for\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	style\tagSENT_CONTENT	10\tagSENT_CONTENT	is\tagSENT_CONTENT	largely\tagSENT_CONTENT	the\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	all\tagSENT_START	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	expressions\tagSENT_CONTENT	in\tagSENT_CONTENT	standard\tagSENT_CONTENT	English\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	thus\tagSENT_CONTENT	outside\tagSENT_CONTENT	the\tagSENT_CONTENT	scope\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	as\tagSENT_CONTENT	defined\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	UNLOL\tagSENT_START	has\tagSENT_CONTENT	produced\tagSENT_CONTENT	lexical_normalization\tagtask	for\tagSENT_CONTENT	these\tagSENT_CONTENT	terms\tagSENT_CONTENT	:\tagSENT_CONTENT	i\tagSENT_CONTENT	/\tagSENT_CONTENT	ima\tagSENT_CONTENT	,\tagSENT_CONTENT	out\tagSENT_CONTENT	/\tagSENT_CONTENT	outta\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	need\tagSENT_CONTENT	/\tagSENT_CONTENT	needa\tagSENT_CONTENT	.\tagSENT_END	But\tagSENT_START	while\tagSENT_CONTENT	lexical_normalization\tagtask	are\tagSENT_CONTENT	wrong\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	style\tagSENT_CONTENT	nonetheless\tagSENT_CONTENT	captures\tagSENT_CONTENT	a\tagSENT_CONTENT	coherent\tagSENT_CONTENT	orthographic\tagSENT_CONTENT	phenomenon\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	unified\tagSENT_CONTENT	,\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	statistical\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	normalizing\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	attaining\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	reported\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	The\tagSENT_START	power\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	relationships\tagSENT_CONTENT	through\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	contextual\tagSENT_CONTENT	regularity\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	feature\tagSENT_CONTENT	weights\tagSENT_CONTENT	without\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	primary\tagSENT_CONTENT	technical\tagSENT_CONTENT	challenge\tagSENT_CONTENT	was\tagSENT_CONTENT	overcoming\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	label\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	;\tagSENT_CONTENT	we\tagSENT_CONTENT	accomplish\tagSENT_CONTENT	this\tagSENT_CONTENT	using\tagSENT_CONTENT	sequential\tagSENT_CONTENT	Monte\tagSENT_CONTENT	Carlo\tagSENT_CONTENT	.\tagSENT_END	
C18-1121	title\tagSECTITLE_END	Ensure\tagSENT_START	the\tagSENT_CONTENT	Correctness\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Summary\tagSENT_CONTENT	:\tagSENT_CONTENT	Incorporate\tagSENT_CONTENT	Entailment\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	produces\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	studied\tagSENT_CONTENT	task\tagSENT_CONTENT	that\tagSENT_CONTENT	creates\tagSENT_CONTENT	a\tagSENT_CONTENT	condensed\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	along\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	true\tagSENT_CONTENT	winner\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	women\tagSENT_CONTENT	's\tagSENT_CONTENT	epee\tagSENT_CONTENT	team\tagSENT_CONTENT	event\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	"\tagSENT_CONTENT	france\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	summarization\tagtask	wrongly\tagSENT_CONTENT	generates\tagSENT_CONTENT	"\tagSENT_CONTENT	canada\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	probably\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	similar\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	country\tagSENT_CONTENT	names\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	argue\tagSENT_CONTENT	that\tagSENT_CONTENT	correctness\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	essential\tagSENT_CONTENT	requirement\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	while\tagSENT_CONTENT	most\tagSENT_CONTENT	existing\tagSENT_CONTENT	systems\tagSENT_CONTENT	ignore\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	incorporate\tagSENT_CONTENT	entailment\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	an\tagSENT_CONTENT	entailment\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	entailment\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	decoder\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	are\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	•\tagSENT_START	We\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	entailment\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	producing\tagSENT_CONTENT	unrelated\tagSENT_CONTENT	information\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	entailment\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	encoder\tagSENT_CONTENT	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	modeling\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Seq2seq\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	Overview\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	generating\tagSENT_CONTENT	unrelated\tagSENT_CONTENT	summary\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	two\tagSENT_CONTENT	strategies\tagSENT_CONTENT	to\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	entailment\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Entailment\tagSECTITLE_START	-\tagSECTITLE_CONTENT	aware\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	sharing\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	entailment\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	Shared\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	Attention\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Summarization\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_END	where\tagSENT_START	each\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	weighted\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	α\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	calculated\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	10\tagSENT_CONTENT	and\tagSENT_CONTENT	11\tagSENT_CONTENT	:\tagSENT_END	summarization\tagtask	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	by\tagSENT_CONTENT	minimizing\tagSENT_CONTENT	negative\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	loss\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	Equation\tagSENT_CONTENT	4\tagSENT_CONTENT	.\tagSENT_END	Matching\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_CONTENT	Inference\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	Learning\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	MTL\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Traditional\tagSENT_START	MTL\tagSENT_CONTENT	considers\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	all\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Entailment\tagSECTITLE_START	-\tagSECTITLE_CONTENT	aware\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	encourage\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	summary\tagSENT_CONTENT	entailed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	an\tagSENT_CONTENT	entailment\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	decoder\tagSENT_CONTENT	by\tagSENT_CONTENT	entailment\tagSENT_CONTENT	RAML\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	Norouzi\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Reward\tagSECTITLE_START	Augmented\tagSECTITLE_CONTENT	Maximum\tagSECTITLE_CONTENT	Likelihood\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	RAML\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	RAML\tagSENT_CONTENT	to\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	entailment\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	reward\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Optimizing\tagSECTITLE_START	by\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Sampling\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	weight\tagSENT_CONTENT	the\tagSENT_CONTENT	counts\tagSENT_CONTENT	by\tagSENT_CONTENT	exp{−d\tagSENT_CONTENT	/\tagSENT_CONTENT	τ\tagSENT_CONTENT	}\tagSENT_CONTENT	and\tagSENT_CONTENT	perform\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Our\tagmetric	goal\tagmetric	is\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	entailment\tagSENT_CONTENT	reward\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	summarization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	categorized\tagSENT_CONTENT	into\tagSENT_CONTENT	extraction\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	(\tagSENT_CONTENT	solve\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	fake\tagSENT_CONTENT	facts\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	8\tagSENT_CONTENT	,\tagSENT_CONTENT	000\tagSENT_CONTENT	pairs\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	samples\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	and\tagSENT_CONTENT	 \tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Experiment\tagSECTITLE_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	We\tagSENT_START	test\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	performance\tagSENT_CONTENT	(\tagSENT_CONTENT	ROUGE-2\tagmetric	F1\tagmetric	score\tagmetric	)\tagSENT_CONTENT	on\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	2,000\tagSENT_CONTENT	batches\tagSENT_CONTENT	.\tagSENT_END	Comparative\tagSECTITLE_START	Methods\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Gigaword\tagSECTITLE_CONTENT	Corpus\tagSECTITLE_END	Our\tagSENT_START	final\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	Seq2seq\tagSENT_CONTENT	+\tagSENT_CONTENT	selective\tagSENT_CONTENT	+\tagSENT_CONTENT	MTL\tagSENT_CONTENT	+\tagSENT_CONTENT	ERAML\tagSENT_CONTENT	,\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	improves\tagSENT_CONTENT	2.52\tagmetric	(\tagmetric	%\tagmetric	)\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	2.32\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	and\tagSENT_CONTENT	2.33\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	over\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	DUC\tagSECTITLE_CONTENT	2004\tagSECTITLE_CONTENT	Test\tagSECTITLE_CONTENT	Corpus\tagSECTITLE_END	(\tagSENT_START	Nallapati\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	0.98\tagmetric	%\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	0.78\tagSENT_CONTENT	%\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	and\tagSENT_CONTENT	0.65\tagSENT_CONTENT	%\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_END	Manual\tagSECTITLE_START	Evaluation\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	60.6\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	correct\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	rises\tagSENT_CONTENT	to\tagSENT_CONTENT	69.4\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	74.2\tagSENT_CONTENT	%\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	selective\tagSENT_CONTENT	encoding\tagSENT_CONTENT	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	strategies\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	correct\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Further\tagSECTITLE_START	Analysis\tagSECTITLE_END	Does\tagSECTITLE_START	our\tagSECTITLE_CONTENT	summarization\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	learn\tagSECTITLE_CONTENT	entailment\tagSECTITLE_CONTENT	knowledge\tagSECTITLE_CONTENT	?\tagSECTITLE_END	summarization\tagtask	of\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	encourage\tagSENT_CONTENT	summarization\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summaries\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	entailed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Is\tagSECTITLE_START	it\tagSECTITLE_CONTENT	less\tagSECTITLE_CONTENT	abstractive\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	our\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	?\tagSECTITLE_END	shows\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	produces\tagSENT_CONTENT	more\tagSENT_CONTENT	novel\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	article\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	a\tagSENT_CONTENT	lower\tagSENT_CONTENT	degree\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Case\tagSECTITLE_START	Study\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	table\tagSENT_CONTENT	,\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	generates\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	obtains\tagSENT_CONTENT	higher\tagSENT_CONTENT	entailment\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	of\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	investigates\tagSENT_CONTENT	the\tagSENT_CONTENT	correctness\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
P16-2034	title\tagSECTITLE_END	Attention\tagSENT_START	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Bidirectional\tagSENT_CONTENT	Long\tagSENT_CONTENT	Short\tagSENT_CONTENT	-\tagSENT_CONTENT	Term\tagSENT_CONTENT	Memory\tagSENT_CONTENT	Networks\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	abstract\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	semantic\tagSENT_CONTENT	processing\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	finding\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	nominals\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	NLP\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	proposes\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	Att\tagSENT_CONTENT	-\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	review\tagSENT_CONTENT	related\tagSENT_CONTENT	work\tagSENT_CONTENT	about\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Over\tagSENT_START	the\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	various\tagSENT_CONTENT	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Most\tagSENT_START	representative\tagSENT_CONTENT	progress\tagSENT_CONTENT	was\tagSENT_CONTENT	made\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	utilized\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks(CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	One\tagSENT_START	related\tagSENT_CONTENT	work\tagSENT_CONTENT	was\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	employed\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	RN\tagSENT_CONTENT	-\tagSENT_CONTENT	N\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	patterns\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	text\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	Att\tagSENT_CONTENT	-\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	finally\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	These\tagSENT_START	components\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	Bidirectional\tagSECTITLE_START	Network\tagSECTITLE_END	Attention\tagSECTITLE_END	Attentive\tagSENT_START	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	recently\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	success\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	ranging\tagSENT_CONTENT	from\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	image\tagSENT_CONTENT	captioning\tagSENT_CONTENT	(\tagSENT_CONTENT	Hermann\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2015\tagSENT_CONTENT	;\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Model\tagSECTITLE_END	Classifying\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	labeî\tagSENT_CONTENT	y\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	discrete\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	classes\tagSENT_END	Regularization\tagSECTITLE_END	relationship_extraction\tagtask	are\tagSENT_CONTENT	further\tagSENT_CONTENT	introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.1\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Experimental\tagSECTITLE_CONTENT	Setup\tagSECTITLE_END	This\tagSENT_START	dataset\tagSENT_CONTENT	contains\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	directions\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	undirected\tagSENT_CONTENT	Other\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	for\tagSENT_START	the\tagSENT_CONTENT	nine\tagSENT_CONTENT	actual\tagSENT_CONTENT	relations\tagSENT_CONTENT	(\tagSENT_CONTENT	excluding\tagSENT_CONTENT	the\tagSENT_CONTENT	Other\tagSENT_CONTENT	relation\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	takes\tagSENT_CONTENT	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	compares\tagSENT_START	our\tagSENT_CONTENT	Att\tagSENT_CONTENT	-\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	methods\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	Zhang\tagSENT_START	and\tagSENT_CONTENT	Wang\tagSENT_CONTENT	(\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	employed\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	RNN\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	dimension\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	Att\tagSENT_CONTENT	-\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	
D12-1110	title\tagSECTITLE_END	abstract\tagSECTITLE_END	The\tagSENT_START	model\tagSENT_CONTENT	obtains\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	different\tagSENT_CONTENT	experiments\tagSENT_CONTENT	:\tagSENT_CONTENT	predicting\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	distributions\tagSENT_CONTENT	of\tagSENT_CONTENT	adverb\tagSENT_CONTENT	-\tagSENT_CONTENT	adjective\tagSENT_CONTENT	pairs\tagSENT_CONTENT	;\tagSENT_CONTENT	classifying\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	labels\tagSENT_CONTENT	of\tagSENT_CONTENT	movie\tagSENT_CONTENT	reviews\tagSENT_CONTENT	and\tagSENT_CONTENT	classifying\tagSENT_CONTENT	relationship_extraction\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	cause\tagSENT_CONTENT	-\tagSENT_CONTENT	effect\tagSENT_CONTENT	or\tagSENT_CONTENT	topic\tagSENT_CONTENT	-\tagSENT_CONTENT	message\tagSENT_CONTENT	between\tagSENT_CONTENT	nouns\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	path\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Semantic\tagSENT_START	word\tagSENT_CONTENT	vector\tagSENT_CONTENT	spaces\tagSENT_CONTENT	are\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	core\tagSENT_CONTENT	of\tagSENT_CONTENT	many\tagSENT_CONTENT	useful\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	applications\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	search\tagSENT_CONTENT	query\tagSENT_CONTENT	expansions\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	text\tagSENT_CONTENT	with\tagSENT_CONTENT	disambiguated\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	links\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	among\tagSENT_CONTENT	many\tagSENT_CONTENT	others\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	extend\tagSENT_CONTENT	these\tagSENT_CONTENT	approaches\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	general\tagSENT_CONTENT	and\tagSENT_CONTENT	powerful\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	shows\tagSENT_START	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	each\tagSENT_CONTENT	constituent\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	or\tagSENT_CONTENT	longer\tagSENT_CONTENT	phrase\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	-\tagSENT_CONTENT	vector\tagSENT_CONTENT	(\tagSENT_CONTENT	MV\tagSENT_CONTENT	)\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	last\tagSENT_CONTENT	experiment\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	MV\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	can\tagSENT_CONTENT	also\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	words\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	learned\tagSENT_CONTENT	phrase\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	between\tagSENT_CONTENT	words\tagSENT_CONTENT	is\tagSENT_CONTENT	recursively\tagSENT_CONTENT	constructed\tagSENT_CONTENT	and\tagSENT_CONTENT	composed\tagSENT_CONTENT	by\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	arbitrary\tagSENT_CONTENT	type\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	variable\tagSENT_CONTENT	length\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	path\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	MV\tagSECTITLE_START	-\tagSECTITLE_CONTENT	RNN\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	Recursive\tagSECTITLE_CONTENT	Matrix\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Vector\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	These\tagSENT_START	approaches\tagSENT_CONTENT	are\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	lines\tagSENT_CONTENT	but\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	restricted\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	whereas\tagSENT_CONTENT	we\tagSENT_CONTENT	would\tagSENT_CONTENT	like\tagSENT_CONTENT	nonlinear\tagSENT_CONTENT	functions\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	compositional\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	phrases\tagSENT_CONTENT	or\tagSENT_CONTENT	full\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	relationship_extraction\tagtask	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	initial\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	details\tagSENT_CONTENT	of\tagSENT_CONTENT	combining\tagSENT_CONTENT	two\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	extensions\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	our\tagSENT_CONTENT	training\tagSENT_CONTENT	procedure\tagSENT_CONTENT	.\tagSENT_END	Matrix\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Vector\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Representation\tagSECTITLE_END	Composition\tagSECTITLE_START	Models\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Two\tagSECTITLE_CONTENT	Words\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	parent\tagSENT_CONTENT	vector\tagSENT_CONTENT	p\tagSENT_CONTENT	from\tagSENT_CONTENT	two\tagSENT_CONTENT	consecutive\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	respective\tagSENT_CONTENT	vectors\tagSENT_CONTENT	a\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	,\tagSENT_CONTENT	give\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	:\tagSENT_CONTENT	p\tagSENT_END	For\tagSENT_START	our\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	relationship_extraction\tagtask	on\tagSENT_CONTENT	p\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	as\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	latter\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	requirement\tagSENT_CONTENT	that\tagSENT_CONTENT	will\tagSENT_CONTENT	become\tagSENT_CONTENT	clear\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	will\tagSENT_CONTENT	explore\tagSENT_CONTENT	methods\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	require\tagSENT_CONTENT	any\tagSENT_CONTENT	manually\tagSENT_CONTENT	designed\tagSENT_CONTENT	semantic\tagSENT_CONTENT	resources\tagSENT_CONTENT	as\tagSENT_CONTENT	background\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	K.\tagSENT_CONTENT	No\tagSENT_CONTENT	explicit\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	R\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	Such\tagSENT_START	a\tagSENT_CONTENT	nonlinearity\tagSENT_CONTENT	will\tagSENT_CONTENT	allow\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	approximate\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	functions\tagSENT_CONTENT	beyond\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	…\tagSECTITLE_START	very\tagSECTITLE_CONTENT	good\tagSECTITLE_CONTENT	movie\tagSECTITLE_CONTENT	…\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	b\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	B\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Recursive\tagSECTITLE_START	Compositions\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Multiple\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Phrases\tagSECTITLE_END	relationship_extraction\tagtask	describes\tagSENT_CONTENT	how\tagSENT_CONTENT	we\tagSENT_CONTENT	extend\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	pair\tagSENT_CONTENT	matrix\tagSENT_CONTENT	-\tagSENT_CONTENT	vector\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	compositional\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	vectors\tagSENT_CONTENT	and\tagSENT_CONTENT	matrices\tagSENT_CONTENT	for\tagSENT_CONTENT	longer\tagSENT_CONTENT	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	function\tagSENT_CONTENT	f\tagmetric	can\tagSENT_CONTENT	be\tagSENT_CONTENT	readily\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	phrase\tagSENT_CONTENT	vectors\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	recursively\tagSENT_CONTENT	compatible\tagSENT_END	Objective\tagSECTITLE_START	Functions\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	these\tagSENT_CONTENT	representations\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	parent\tagSENT_CONTENT	node\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	a\tagSENT_CONTENT	class\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	or\tagSENT_CONTENT	relationship_extraction\tagtask	classes\tagSENT_CONTENT	:\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	both\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	distributions\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Learning\tagSECTITLE_END	be\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	and\tagSENT_CONTENT	λ\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	all\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	relationship_extraction\tagtask	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Low\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Rank\tagSECTITLE_CONTENT	Matrix\tagSECTITLE_CONTENT	Approximations\tagSECTITLE_END	Discussion\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Generality\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	even\tagSENT_CONTENT	with\tagSENT_CONTENT	good\tagSENT_CONTENT	correlation\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	remains\tagSENT_CONTENT	how\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	would\tagSENT_CONTENT	perform\tagSENT_CONTENT	on\tagSENT_CONTENT	downstream\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	high\tagSENT_CONTENT	prediction\tagSENT_CONTENT	performance\tagSENT_CONTENT	came\tagSENT_CONTENT	from\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	meaning\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Analysis\tagSECTITLE_END	relationship_extraction\tagtask	analyzes\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	proof\tagSENT_CONTENT	-\tagSENT_CONTENT	ofconcept\tagSENT_CONTENT	studies\tagSENT_CONTENT	.\tagSENT_END	Predicting\tagSECTITLE_START	Sentiment\tagSECTITLE_CONTENT	Distributions\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Adverb\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Adjective\tagSECTITLE_CONTENT	Pairs\tagSECTITLE_END	Logic\tagSECTITLE_START	-\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Vector\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Compositionality\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	necessary\tagSENT_CONTENT	(\tagSENT_CONTENT	though\tagSENT_CONTENT	not\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	)\tagSENT_CONTENT	condition\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	pickup\tagSENT_CONTENT	these\tagSENT_CONTENT	phenomena\tagSENT_CONTENT	in\tagSENT_CONTENT	real\tagSENT_CONTENT	datasets\tagSENT_CONTENT	and\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	which\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	sections\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	T\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	(\tagSENT_CONTENT	f\tagSENT_CONTENT	,\tagSENT_CONTENT	F\tagSENT_CONTENT	)\tagSENT_END	Predicting\tagSECTITLE_START	Movie\tagSECTITLE_CONTENT	Review\tagSECTITLE_CONTENT	Ratings\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	full\tagSENT_CONTENT	length\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	exact\tagSENT_CONTENT	same\tagSENT_CONTENT	setup\tagSENT_CONTENT	and\tagSENT_CONTENT	parameters\tagSENT_CONTENT	(\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	word\tagSENT_CONTENT	vector\tagSENT_CONTENT	size\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	Method\tagSECTITLE_END	Classification\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Semantic\tagSECTITLE_CONTENT	Relationships\tagSECTITLE_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	finding\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	nominals\tagSENT_CONTENT	.\tagSENT_END	Predicting\tagSENT_START	such\tagSENT_CONTENT	 \tagSENT_CONTENT	semantic\tagSENT_CONTENT	relations\tagSENT_CONTENT	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	thesaurus\tagSENT_CONTENT	construction\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	explains\tagSENT_START	our\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	classifying\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	node\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	path\tagSENT_CONTENT	and\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	that\tagSENT_CONTENT	node\tagSENT_CONTENT	's\tagSENT_CONTENT	vector\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	directions\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	undirected\tagSENT_CONTENT	other\tagSENT_CONTENT	class\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	19\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	Among\tagSENT_START	relationship_extraction\tagtask	are\tagSENT_CONTENT	:\tagSENT_CONTENT	messagetopic\tagSENT_CONTENT	,\tagSENT_CONTENT	cause\tagSENT_CONTENT	-\tagSENT_CONTENT	effect\tagSENT_CONTENT	,\tagSENT_CONTENT	instrument\tagSENT_CONTENT	-\tagSENT_CONTENT	agency\tagSENT_CONTENT	(\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	pair\tagSENT_CONTENT	is\tagSENT_CONTENT	counted\tagSENT_CONTENT	as\tagSENT_CONTENT	correct\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	These\tagSENT_START	representations\tagSENT_CONTENT	have\tagSENT_CONTENT	proven\tagSENT_CONTENT	very\tagSENT_CONTENT	effective\tagSENT_CONTENT	in\tagSENT_CONTENT	sense\tagSENT_CONTENT	discrimination\tagSENT_CONTENT	and\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	and\tagSENT_CONTENT	selectional\tagSENT_CONTENT	preferences\tagSENT_CONTENT	.\tagSENT_END	present\tagSENT_START	an\tagSENT_CONTENT	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	compositional\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	component\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	multiplication\tagSENT_CONTENT	to\tagSENT_CONTENT	tensor\tagSENT_CONTENT	products\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	convolution\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	It\tagSENT_START	generalizes\tagSENT_CONTENT	several\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	learn\tagSENT_CONTENT	propositional\tagSENT_CONTENT	logic\tagSENT_CONTENT	,\tagSENT_CONTENT	accurately\tagSENT_CONTENT	predicts\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	nouns\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	
P17-1099	title\tagSECTITLE_END	summarization\tagtask	with\tagSENT_CONTENT	Pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	Generator\tagSENT_CONTENT	Networks\tagSENT_END	abstract\tagSECTITLE_END	Neural\tagSENT_START	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	provided\tagSENT_CONTENT	a\tagSENT_CONTENT	viable\tagSENT_CONTENT	new\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	meaning\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	restricted\tagSENT_CONTENT	to\tagSENT_CONTENT	simply\tagSENT_CONTENT	selecting\tagSENT_CONTENT	and\tagSENT_CONTENT	rearranging\tagSENT_CONTENT	passages\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	condensing\tagSENT_CONTENT	apiece\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	that\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	.\tagSENT_END	Baseline\tagSENT_START	Seq2Seq\tagSENT_CONTENT	+\tagSENT_CONTENT	Attention\tagSENT_CONTENT	:\tagSENT_CONTENT	UNK\tagSENT_CONTENT	UNK\tagSENT_CONTENT	says\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	confident\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	destabilize\tagSENT_CONTENT	nigeria\tagSENT_CONTENT	's\tagSENT_CONTENT	economy\tagSENT_CONTENT	.\tagSENT_END	he\tagSENT_START	says\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	confident\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	thwart\tagSENT_CONTENT	criminals\tagSENT_CONTENT	.\tagSENT_END	he\tagSENT_START	says\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	confident\tagSENT_CONTENT	it\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	thwart\tagSENT_CONTENT	criminals\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	great\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	past\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	extractive\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	et\tagSENT_START	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	both\tagSENT_CONTENT	read\tagSENT_CONTENT	and\tagSENT_CONTENT	freely\tagSENT_CONTENT	generate\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	has\tagSENT_CONTENT	made\tagSENT_CONTENT	summarization\tagtask	viable\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	most\tagSENT_CONTENT	recent\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	headline\tagSENT_CONTENT	generation\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	reducing\tagSENT_CONTENT	one\tagSENT_CONTENT	or\tagSENT_CONTENT	two\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	headline\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	both\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	(\tagSENT_CONTENT	requiring\tagSENT_CONTENT	higher\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	abstraction\tagSENT_CONTENT	while\tagSENT_CONTENT	avoiding\tagSENT_CONTENT	repetition\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	ultimately\tagSENT_CONTENT	more\tagSENT_CONTENT	useful\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	network\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	balance\tagSENT_CONTENT	between\tagSENT_CONTENT	extractive\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	Forced\tagSENT_CONTENT	-\tagSENT_CONTENT	Attention\tagSENT_CONTENT	Sentence\tagSENT_CONTENT	Compression\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	were\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Our\tagSECTITLE_START	Models\tagSECTITLE_END	Sequence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	sequence\tagSECTITLE_CONTENT	attentional\tagSECTITLE_CONTENT	model\tagSECTITLE_END	For\tagSENT_START	each\tagSENT_CONTENT	decoder\tagSENT_CONTENT	timestep\tagmetric	a\tagSENT_CONTENT	generation\tagSENT_CONTENT	probability\tagSENT_CONTENT	p\tagSENT_CONTENT	gen\tagSENT_CONTENT	∈\tagSENT_END	The\tagSENT_START	vocabulary\tagSENT_CONTENT	distribution\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	distribution\tagSENT_CONTENT	are\tagSENT_CONTENT	weighted\tagSENT_CONTENT	and\tagSENT_CONTENT	summed\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	distribution\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Pointer\tagSECTITLE_START	-\tagSECTITLE_CONTENT	generator\tagSECTITLE_CONTENT	network\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	generation\tagSENT_CONTENT	probability\tagSENT_CONTENT	p\tagSENT_CONTENT	gen\tagSENT_CONTENT	∈\tagSENT_CONTENT	[\tagSENT_CONTENT	0\tagSENT_CONTENT	,\tagSENT_CONTENT	1\tagSENT_CONTENT	]\tagSENT_CONTENT	for\tagSENT_CONTENT	timestep\tagSENT_CONTENT	t\tagSENT_CONTENT	is\tagSENT_CONTENT	calculated\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	h\tagSENT_CONTENT	*\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	state\tagSENT_CONTENT	st\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	input\tagSENT_CONTENT	x\tagSENT_CONTENT	t\tagSENT_CONTENT	:\tagSENT_END	The\tagSENT_START	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	is\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	modified\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	P(w\tagSENT_CONTENT	)\tagSENT_CONTENT	given\tagSENT_CONTENT	in\tagSENT_CONTENT	equation\tagSENT_CONTENT	(\tagSENT_CONTENT	9\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Coverage\tagSECTITLE_START	mechanism\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	common\tagSENT_CONTENT	problem\tagSENT_CONTENT	for\tagSENT_CONTENT	sequenceto\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	especially\tagSENT_CONTENT	pronounced\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	text\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	coverage\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	extra\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	,\tagSENT_CONTENT	changing\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	:\tagSENT_END	This\tagSENT_START	ensures\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	's\tagSENT_CONTENT	current\tagSENT_CONTENT	decision\tagSENT_CONTENT	(\tagSENT_CONTENT	choosing\tagSENT_CONTENT	whereto\tagSENT_CONTENT	attend\tagSENT_CONTENT	next\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	informed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	reminder\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	previous\tagSENT_CONTENT	decisions\tagSENT_CONTENT	(\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	(\tagSENT_CONTENT	12\tagSENT_CONTENT	)\tagSENT_CONTENT	differs\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	coverage\tagSENT_CONTENT	loss\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	flexible\tagSENT_CONTENT	:\tagSENT_CONTENT	because\tagSENT_CONTENT	summarization\tagtask	should\tagSENT_CONTENT	not\tagSENT_CONTENT	require\tagSENT_CONTENT	uniform\tagSENT_CONTENT	coverage\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	penalize\tagSENT_CONTENT	the\tagSENT_CONTENT	overlap\tagSENT_CONTENT	between\tagSENT_CONTENT	each\tagSENT_CONTENT	attention\tagSENT_CONTENT	distribution\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	coverage\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	-preventing\tagSENT_CONTENT	repeated\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	were\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	modern\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	DUC-2004\tagSENT_CONTENT	and\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	,\tagSENT_CONTENT	two\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	summarization\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	longer\tagSENT_CONTENT	text\tagSENT_CONTENT	are\tagSENT_CONTENT	rare\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Prior\tagSENT_START	to\tagSENT_CONTENT	modern\tagSENT_CONTENT	neural\tagSENT_CONTENT	methods\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	received\tagSENT_CONTENT	less\tagSENT_CONTENT	attention\tagSENT_CONTENT	than\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	Jing\tagSENT_CONTENT	(\tagSENT_CONTENT	2000\tagSENT_CONTENT	)\tagSENT_CONTENT	explored\tagSENT_CONTENT	cutting\tagSENT_CONTENT	unimportant\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Cheung\tagSENT_CONTENT	and\tagSENT_CONTENT	Penn\tagSENT_CONTENT	(\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_CONTENT	explore\tagSENT_CONTENT	sentence\tagSENT_CONTENT	fusion\tagSENT_CONTENT	using\tagSENT_CONTENT	dependency\tagSENT_CONTENT	trees\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	pointer\tagSENT_CONTENT	network\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	approaches\tagSENT_CONTENT	for\tagSENT_CONTENT	NMT\tagSENT_CONTENT	,\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	believe\tagSENT_CONTENT	the\tagSENT_CONTENT	mixture\tagSENT_CONTENT	approach\tagSENT_CONTENT	described\tagSENT_CONTENT	here\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	-in\tagSENT_CONTENT	section\tagSENT_CONTENT	6\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	respect\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	coverage\tagSENT_CONTENT	-\tagSENT_CONTENT	like\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	image\tagSENT_CONTENT	captioning\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	also\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	a\tagSENT_CONTENT	coverage\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	they\tagSENT_CONTENT	call\tagSENT_CONTENT	'\tagSENT_CONTENT	distraction\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	into\tagSENT_CONTENT	neural\tagSENT_CONTENT	summarization\tagSENT_CONTENT	of\tagSENT_CONTENT	longer\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Temporal\tagSENT_START	attention\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	related\tagSENT_CONTENT	technique\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	NMT\tagSENT_CONTENT	 \tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Experiments\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	gradient\tagSENT_CONTENT	clipping\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	maximum\tagSENT_CONTENT	gradient\tagSENT_CONTENT	norm\tagSENT_CONTENT	of\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	use\tagSENT_CONTENT	any\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	At\tagSENT_START	test\tagSENT_CONTENT	time\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	produced\tagSENT_CONTENT	using\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	with\tagSENT_CONTENT	beam\tagSENT_CONTENT	size\tagSENT_CONTENT	4\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	13\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	trained\tagSENT_CONTENT	fora\tagSENT_CONTENT	further\tagSENT_CONTENT	3000\tagSENT_CONTENT	iterations\tagSENT_CONTENT	(\tagSENT_CONTENT	about\tagSENT_CONTENT	2\tagSENT_CONTENT	hours\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	tried\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	coverage\tagSENT_CONTENT	model\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_CONTENT	hoping\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	may\tagSENT_CONTENT	learn\tagSENT_CONTENT	by\tagSENT_CONTENT	itself\tagSENT_CONTENT	not\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	repeatedly\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	locations\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	this\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	ineffective\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	no\tagSENT_CONTENT	discernible\tagSENT_CONTENT	reduction\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	Preliminaries\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	metric\tagSENT_CONTENT	,\tagSENT_CONTENT	reporting\tagSENT_CONTENT	the\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	respectively\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	overlap\tagSENT_CONTENT	,\tagSENT_CONTENT	bigram\tagSENT_CONTENT	-\tagSENT_CONTENT	overlap\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	longest\tagSENT_CONTENT	common\tagSENT_CONTENT	sequence\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Observations\tagSECTITLE_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	perform\tagSENT_CONTENT	poorly\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	ROUGE\tagmetric	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	fact\tagSENT_CONTENT	the\tagSENT_CONTENT	larger\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	(\tagSENT_CONTENT	150k\tagSENT_CONTENT	)\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	seem\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	much\tagSENT_CONTENT	better\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	and\tagSENT_CONTENT	METEOR\tagmetric	scores\tagmetric	than\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	many\tagSENT_CONTENT	fewer\tagSENT_CONTENT	training\tagSENT_CONTENT	epochs\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	difference\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	also\tagSENT_CONTENT	marked\tagSENT_CONTENT	:\tagSENT_CONTENT	outof\tagSENT_CONTENT	-\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	handled\tagSENT_CONTENT	easily\tagSENT_CONTENT	,\tagSENT_CONTENT	factual\tagSENT_CONTENT	details\tagSENT_CONTENT	are\tagSENT_CONTENT	almost\tagSENT_CONTENT	always\tagSENT_CONTENT	copied\tagSENT_CONTENT	correctly\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	no\tagSENT_CONTENT	fabrications\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	coverage\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagmetric	ROUGE\tagmetric	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	scores\tagSENT_CONTENT	further\tagSENT_CONTENT	,\tagSENT_CONTENT	convincingly\tagSENT_CONTENT	surpassing\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	model\tagSENT_CONTENT	Article\tagSENT_END	Discussion\tagSECTITLE_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	extractive\tagSECTITLE_CONTENT	systems\tagSECTITLE_END	summarization\tagtask	introduces\tagSENT_CONTENT	even\tagSENT_CONTENT	more\tagSENT_CONTENT	options\tagSENT_CONTENT	(\tagSENT_CONTENT	choice\tagSENT_CONTENT	of\tagSENT_CONTENT	phrasing\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	further\tagSENT_CONTENT	decreasing\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	matching\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	subjectivity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	the\tagSENT_CONTENT	diversity\tagSENT_CONTENT	of\tagSENT_CONTENT	valid\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	seems\tagSENT_CONTENT	that\tagSENT_CONTENT	ROUGE\tagmetric	rewards\tagSENT_CONTENT	safe\tagSENT_CONTENT	strategies\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	selecting\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	-\tagSENT_CONTENT	appearing\tagSENT_CONTENT	content\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	preserving\tagSENT_CONTENT	original\tagSENT_CONTENT	phrasing\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	explore\tagSENT_CONTENT	this\tagSENT_CONTENT	issue\tagSENT_CONTENT	further\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	systems\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagmetric	METEOR\tagmetric	metric\tagmetric	,\tagSENT_CONTENT	which\tagSENT_CONTENT	rewards\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	exact\tagSENT_CONTENT	word\tagSENT_CONTENT	matches\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	matching\tagSENT_CONTENT	stems\tagSENT_CONTENT	,\tagSENT_CONTENT	synonyms\tagSENT_CONTENT	and\tagSENT_CONTENT	paraphrases\tagSENT_CONTENT	(\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	predefined\tagSENT_CONTENT	list\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	boost\tagSENT_START	by\tagSENT_CONTENT	the\tagSENT_CONTENT	inclusion\tagSENT_CONTENT	of\tagSENT_CONTENT	stem\tagSENT_CONTENT	,\tagSENT_CONTENT	synonym\tagSENT_CONTENT	and\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	matching\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	maybe\tagSENT_CONTENT	performing\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	How\tagSECTITLE_START	abstractive\tagSECTITLE_CONTENT	is\tagSECTITLE_CONTENT	our\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	?\tagSECTITLE_END	shows\tagSENT_START	that\tagSENT_CONTENT	our\tagSENT_CONTENT	final\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	summaries\tagSENT_CONTENT	contain\tagSENT_CONTENT	a\tagSENT_CONTENT	much\tagSENT_CONTENT	lower\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	novel\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	those\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	n't\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	article\tagSENT_CONTENT	)\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	a\tagSENT_CONTENT	lower\tagSENT_CONTENT	degree\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	final\tagSENT_CONTENT	model\tagSENT_CONTENT	copies\tagSENT_CONTENT	whole\tagSENT_CONTENT	article\tagSENT_CONTENT	sentences\tagSENT_CONTENT	35\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	;\tagSENT_CONTENT	by\tagSENT_CONTENT	summarization\tagtask	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summaries\tagSENT_CONTENT	do\tagSENT_CONTENT	so\tagSENT_CONTENT	only\tagSENT_CONTENT	1.3\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	disparity\tagSENT_CONTENT	is\tagSENT_CONTENT	likely\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	receives\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	by\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	supervision\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	form\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	attest\tagSENT_CONTENT	time\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	like\tagSENT_CONTENT	stitching\tagSENT_CONTENT	and\tagSENT_CONTENT	truncation\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	performed\tagSENT_CONTENT	with\tagSENT_CONTENT	grammaticality\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	pointergenerator\tagSENT_CONTENT	architecture\tagSENT_CONTENT	with\tagSENT_CONTENT	coverage\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	reduces\tagSENT_CONTENT	inaccuracies\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
1704.00051	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	proposes\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	using\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	unique\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	:\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	any\tagSENT_CONTENT	factoid\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	span\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	article\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	considers\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	an\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	setting\tagSENT_CONTENT	using\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	unique\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	one\tagSENT_CONTENT	does\tagSENT_CONTENT	when\tagSENT_CONTENT	looking\tagSENT_CONTENT	for\tagSENT_CONTENT	answers\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	encyclopedia\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	causes\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	challenges\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	QA\tagSENT_CONTENT	and\tagSENT_CONTENT	of\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Having\tagSENT_START	a\tagSENT_CONTENT	single\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	forces\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	very\tagSENT_CONTENT	precise\tagSENT_CONTENT	while\tagSENT_CONTENT	searching\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	evidence\tagSENT_CONTENT	might\tagSENT_CONTENT	appear\tagSENT_CONTENT	only\tagSENT_CONTENT	once\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	multiple\tagSENT_CONTENT	existing\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	MRS\tagSENT_CONTENT	by\tagSENT_CONTENT	requiring\tagSENT_CONTENT	an\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	at\tagSENT_CONTENT	once\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	develop\tagSENT_CONTENT	DrQA\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Document\tagSENT_CONTENT	Retriever\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	module\tagSENT_CONTENT	using\tagSENT_CONTENT	bigram\tagSENT_CONTENT	hashing\tagSENT_CONTENT	and\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	matching\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	efficiently\tagSENT_CONTENT	return\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	relevant\tagSENT_CONTENT	articles\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	answer\tagSENT_CONTENT	spans\tagSENT_CONTENT	in\tagSENT_CONTENT	those\tagSENT_CONTENT	few\tagSENT_CONTENT	returned\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	performance\tagSENT_CONTENT	is\tagSENT_CONTENT	improved\tagSENT_CONTENT	across\tagSENT_CONTENT	all\tagSENT_CONTENT	datasets\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	single\tagSENT_CONTENT	task\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	A\tagSENT_START	second\tagSENT_CONTENT	motivation\tagSENT_CONTENT	to\tagSENT_CONTENT	cast\tagSENT_CONTENT	afresh\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	after\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	text\tagSENT_CONTENT	or\tagSENT_CONTENT	story\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	of\tagSENT_CONTENT	using\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	resource\tagSENT_CONTENT	for\tagSENT_CONTENT	seeking\tagSENT_CONTENT	answers\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	they\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	validating\tagSENT_CONTENT	answers\tagSENT_CONTENT	returned\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	categories\tagSENT_CONTENT	for\tagSENT_CONTENT	determining\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	patterns\tagSENT_CONTENT	that\tagSENT_CONTENT	should\tagSENT_CONTENT	fit\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	expected\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	AskMSR\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	search\tagSENT_CONTENT	-\tagSENT_CONTENT	engine\tagSENT_CONTENT	based\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	that\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	"\tagSENT_CONTENT	data\tagSENT_CONTENT	redundancy\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	sophisticated\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	analyses\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	or\tagSENT_CONTENT	candidate\tagSENT_CONTENT	answers\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	.\tagSENT_END	Document\tagSECTITLE_START	Reader\tagSECTITLE_END	833,500\tagSECTITLE_END	Document\tagSECTITLE_START	Retriever\tagSECTITLE_END	SQuAD\tagSECTITLE_START	,\tagSECTITLE_CONTENT	TREC\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	WebQuestions\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	WikiMovies\tagSECTITLE_END	An\tagSENT_START	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	system\tagSENT_CONTENT	DrQA\tagSENT_CONTENT	.\tagSENT_END	Several\tagSENT_START	works\tagSENT_CONTENT	have\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	combine\tagSENT_CONTENT	multiple\tagSENT_CONTENT	QA\tagSENT_CONTENT	training\tagSENT_CONTENT	datasets\tagSENT_CONTENT	via\tagSENT_CONTENT	multitask\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	achieve\tagSENT_CONTENT	improvement\tagSENT_CONTENT	across\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	via\tagSENT_CONTENT	task\tagSENT_CONTENT	transfer\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	general\tagSENT_CONTENT	system\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	asking\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	inevitably\tagSENT_CONTENT	different\tagSENT_CONTENT	data\tagSENT_CONTENT	distributions\tagSENT_CONTENT	across\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	System\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	DrQA\tagSECTITLE_END	Document\tagSECTITLE_START	Retriever\tagSECTITLE_END	A\tagSENT_START	simple\tagSENT_CONTENT	inverted\tagSENT_CONTENT	index\tagSENT_CONTENT	lookup\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	term\tagSENT_CONTENT	vector\tagSENT_CONTENT	model\tagSENT_CONTENT	scoring\tagSENT_CONTENT	performs\tagSENT_CONTENT	quite\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	built\tagSENT_CONTENT	-\tagSENT_CONTENT	in\tagSENT_CONTENT	ElasticSearch\tagSENT_CONTENT	based\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	Search\tagSENT_CONTENT	API\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	Document\tagSENT_CONTENT	Retriever\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	full\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	setting\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	return\tagSENT_CONTENT	5\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	given\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Document\tagSECTITLE_START	Reader\tagSECTITLE_END	Given\tagSENT_START	question_answering\tagtask	q\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	l\tagSENT_CONTENT	tokens\tagSENT_CONTENT	{\tagSENT_CONTENT	q\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	l\tagSENT_CONTENT	}\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	documents\tagSENT_CONTENT	of\tagSENT_CONTENT	n\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	where\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	p\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	m\tagSENT_CONTENT	tokens\tagSENT_CONTENT	{\tagSENT_CONTENT	p\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	pm\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	develop\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	in\tagSENT_CONTENT	turn\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	finally\tagSENT_CONTENT	aggregate\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	answers\tagSENT_CONTENT	.\tagSENT_END	Rd\tagSENT_START	and\tagSENT_CONTENT	pass\tagSENT_CONTENT	them\tagmetric	as\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	obtain\tagSENT_CONTENT	:\tagSENT_END	f\tagmetric	emb\tagmetric	(\tagSENT_CONTENT	p\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	three\tagSENT_CONTENT	simple\tagSENT_CONTENT	binary\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	whether\tagSENT_CONTENT	pi\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	exactly\tagSENT_CONTENT	matched\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	either\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	original\tagSENT_CONTENT	,\tagSENT_CONTENT	lowercase\tagSENT_CONTENT	or\tagSENT_CONTENT	lemma\tagSENT_CONTENT	form\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	:\tagSENT_END	question_answering\tagtask	encoding\tagSENT_CONTENT	The\tagSENT_CONTENT	question\tagSENT_CONTENT	encoding\tagSENT_CONTENT	is\tagSENT_CONTENT	simpler\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	apply\tagSENT_CONTENT	another\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	q\tagSENT_CONTENT	i\tagSENT_CONTENT	and\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	hidden\tagSENT_CONTENT	units\tagSENT_CONTENT	into\tagSENT_CONTENT	one\tagSENT_CONTENT	single\tagSENT_CONTENT	vector\tagSENT_CONTENT	:\tagSENT_CONTENT	{\tagSENT_CONTENT	q\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	l\tagSENT_CONTENT	}\tagSENT_END	Data\tagSECTITLE_END	Our\tagSENT_START	work\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	data\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	that\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	for\tagSENT_CONTENT	finding\tagSENT_CONTENT	answers\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	dataset\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	our\tagSENT_CONTENT	main\tagSENT_CONTENT	resource\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	three\tagSENT_CONTENT	more\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	(\tagSENT_CONTENT	CuratedTREC\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	WikiMovies\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	the\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	QA\tagSENT_CONTENT	abilities\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	full\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	from\tagSENT_CONTENT	multitask\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	.\tagSENT_END	Wikipedia\tagSECTITLE_START	(\tagSECTITLE_CONTENT	Knowledge\tagSECTITLE_CONTENT	Source\tagSECTITLE_CONTENT	)\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	2016\tagSENT_CONTENT	-\tagSENT_CONTENT	12\tagSENT_CONTENT	-\tagSENT_CONTENT	21\tagSENT_CONTENT	dump\tagSENT_CONTENT	2\tagSENT_CONTENT	of\tagSENT_CONTENT	English\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	experiments\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	source\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	SQuAD\tagSECTITLE_END	question_answering\tagtask	is\tagSENT_CONTENT	always\tagSENT_CONTENT	a\tagSENT_CONTENT	span\tagSENT_CONTENT	from\tagSENT_CONTENT	this\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	and\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	SQuAD\tagdataset	for\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	our\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	task\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	rel-2\tagSENT_CONTENT	https://dumps.wikimedia.org/enwiki/\tagSENT_END	Open\tagSECTITLE_START	-\tagSECTITLE_CONTENT	domain\tagSECTITLE_CONTENT	QA\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	SQuAD\tagdataset	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	largest\tagSENT_CONTENT	general\tagSENT_CONTENT	purpose\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	currently\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	version\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	contains\tagSENT_CONTENT	a\tagSENT_CONTENT	total\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	from\tagSENT_CONTENT	WebQuestions\tagSENT_CONTENT	Introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	built\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	questions\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	KB\tagSENT_CONTENT	.\tagSENT_END	WikiMovies\tagSENT_START	This\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	contains\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	domain\tagSENT_CONTENT	of\tagSENT_CONTENT	movies\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Example\tagSECTITLE_END	Distantly\tagSECTITLE_START	Supervised\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	All\tagSENT_START	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	presented\tagSENT_CONTENT	above\tagSENT_CONTENT	contain\tagSENT_CONTENT	training\tagSENT_CONTENT	portions\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	CuratedTREC\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	WikiMovies\tagSENT_CONTENT	only\tagSENT_CONTENT	contain\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answer\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	not\tagSENT_CONTENT	an\tagSENT_CONTENT	associated\tagSENT_CONTENT	document\tagSENT_CONTENT	or\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	directly\tagSENT_CONTENT	.\tagSENT_END	run\tagSENT_START	Document\tagSENT_CONTENT	Retriever\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	retrieve\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	5\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	also\tagSENT_CONTENT	generate\tagSENT_CONTENT	additional\tagSENT_CONTENT	DS\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	SQuAD\tagdataset	by\tagSENT_CONTENT	trying\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	mentions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	answers\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	provided\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	from\tagSENT_CONTENT	other\tagSENT_CONTENT	pages\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	page\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	was\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Finding\tagSECTITLE_START	Relevant\tagSECTITLE_CONTENT	Articles\tagSECTITLE_END	Table\tagSENT_START	3\tagSENT_CONTENT	compares\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	approaches\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.1\tagSENT_CONTENT	with\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	Search\tagSENT_CONTENT	Engine\tagSENT_CONTENT	5\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	finding\tagSENT_CONTENT	articles\tagSENT_CONTENT	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	question_answering\tagtask	given\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Reader\tagSECTITLE_START	Evaluation\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	SQuAD\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	3-layer\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	with\tagSENT_CONTENT	h\tagSENT_CONTENT	=\tagSENT_CONTENT	128\tagSENT_CONTENT	hidden\tagSENT_CONTENT	units\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	encoding\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagdataset	has\tagSENT_CONTENT	been\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	competitive\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	since\tagSENT_CONTENT	its\tagSENT_CONTENT	creation\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	list\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	-\tagSENT_CONTENT	performing\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	table\tagSENT_CONTENT	.\tagSENT_END	Result\tagSECTITLE_START	and\tagSECTITLE_CONTENT	analysis\tagSECTITLE_END	Full\tagSECTITLE_START	Wikipedia\tagSECTITLE_CONTENT	Question\tagSECTITLE_CONTENT	Answering\tagSECTITLE_END	•\tagSENT_START	Fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tune\tagSENT_CONTENT	(\tagSENT_CONTENT	DS\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_CONTENT	A\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	and\tagSENT_CONTENT	then\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuned\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	dataset\tagSENT_CONTENT	independently\tagSENT_CONTENT	using\tagSENT_CONTENT	its\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervision\tagSENT_CONTENT	(\tagSENT_CONTENT	DS\tagSENT_CONTENT	)\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Method\tagSECTITLE_END	Dev\tagSECTITLE_END	n\tagSENT_START	/\tagSENT_CONTENT	a\tagSENT_CONTENT	n\tagSENT_CONTENT	/\tagSENT_CONTENT	a\tagSENT_CONTENT	71.3\tagSENT_CONTENT	79.7\tagSENT_CONTENT	DrQA\tagSENT_CONTENT	(\tagSENT_CONTENT	Our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	Only\tagSENT_CONTENT	)\tagSENT_CONTENT	69.5\tagSENT_CONTENT	78.8\tagSENT_CONTENT	70.0\tagSENT_CONTENT	79.0\tagSENT_CONTENT	 \tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	while\tagSENT_CONTENT	these\tagSENT_CONTENT	help\tagSENT_CONTENT	for\tagSENT_CONTENT	more\tagSENT_CONTENT	exact\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	reading\tagSENT_CONTENT	in\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	they\tagSENT_CONTENT	do\tagSENT_CONTENT	n't\tagSENT_CONTENT	improve\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	setting\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	are\tagSENT_CONTENT	interested\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	,\tagSENT_CONTENT	full\tagSENT_CONTENT	system\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	using\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	compare\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	unconstrained\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	using\tagSENT_CONTENT	redundant\tagSENT_CONTENT	resources\tagSENT_CONTENT	(\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	YodaQA\tagSENT_CONTENT	,\tagSENT_CONTENT	giving\tagSENT_CONTENT	results\tagSENT_CONTENT	which\tagSENT_CONTENT	were\tagSENT_CONTENT	previously\tagSENT_CONTENT	reported\tagSENT_CONTENT	on\tagSENT_CONTENT	CuratedTREC\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	DrQA\tagSENT_START	's\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	component\tagSENT_CONTENT	on\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	in\tagSENT_CONTENT	shows\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	drop\tagSENT_CONTENT	(\tagSENT_CONTENT	from\tagSENT_CONTENT	69.5\tagSENT_CONTENT	to\tagSENT_CONTENT	27.1\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	now\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Dataset\tagSECTITLE_END	YodaQA\tagSECTITLE_END	Two\tagSENT_START	obvious\tagSENT_CONTENT	angles\tagSENT_CONTENT	of\tagSENT_CONTENT	attack\tagSENT_CONTENT	are\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	aggregates\tagSENT_CONTENT	over\tagSENT_CONTENT	multiple\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	and\tagSENT_CONTENT	documents\tagSENT_CONTENT	directly\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	currently\tagSENT_CONTENT	trains\tagSENT_CONTENT	on\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	independently\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	perform\tagSENT_CONTENT	question_answering\tagtask	across\tagSENT_CONTENT	the\tagSENT_CONTENT	Document\tagSENT_CONTENT	Retriever\tagSENT_CONTENT	and\tagSENT_CONTENT	Document\tagSENT_CONTENT	Reader\tagSENT_CONTENT	pipeline\tagSENT_CONTENT	,\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	independent\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	
43852	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	To\tagSENT_START	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	competitive\tagSENT_CONTENT	compression\tagSENT_CONTENT	system\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	which\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	require\tagSENT_CONTENT	any\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	but\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	While\tagSENT_START	phenomena\tagSENT_CONTENT	like\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	distance\tagSENT_CONTENT	relations\tagSENT_CONTENT	may\tagSENT_CONTENT	seem\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	grammatically\tagSENT_CONTENT	correct\tagSENT_CONTENT	compressions\tagSENT_CONTENT	impossible\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	going\tagSENT_CONTENT	to\tagSENT_CONTENT	present\tagSENT_CONTENT	an\tagSENT_CONTENT	evidence\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	contrary\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Baseline\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	equivalent\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	Quadratic\tagSENT_CONTENT	Programming\tagSENT_CONTENT	problem\tagSENT_CONTENT	if\tagSENT_CONTENT	K\tagSENT_CONTENT	>\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	costly\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	not\tagSENT_CONTENT	adequate\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	data\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Ultimately\tagSENT_START	,\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	McDonald\tagSENT_CONTENT	's\tagSENT_CONTENT	model\tagSENT_CONTENT	contained\tagSENT_CONTENT	463,614\tagSENT_CONTENT	individual\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	summarized\tagSENT_CONTENT	in\tagSENT_CONTENT	three\tagSENT_CONTENT	categories\tagSENT_CONTENT	:\tagSENT_END	We\tagSENT_START	can\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	chain\tagSENT_CONTENT	rule\tagSENT_CONTENT	to\tagSENT_CONTENT	decompose\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	Evaluation\tagSECTITLE_END	Data\tagSECTITLE_END	Experiments\tagSECTITLE_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	two\tagSENT_CONTENT	metrics\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	:\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	how\tagSENT_CONTENT	many\tagSENT_CONTENT	compressions\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	fully\tagSENT_CONTENT	reproduced\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	three\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	*\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	(\tagSENT_CONTENT	MIRA\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	comparable\tagSENT_CONTENT	compression\tagSENT_CONTENT	ratios\tagSENT_CONTENT	(\tagSENT_CONTENT	CR\tagmetric	)\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	compression\tagSENT_CONTENT	in\tagSENT_CONTENT	characters\tagSENT_CONTENT	divided\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	length\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	:\tagSENT_CONTENT	A\tagSENT_CONTENT	total\tagSENT_CONTENT	of\tagSENT_CONTENT	1,000\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	were\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	automatic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	with\tagSENT_CONTENT	humans\tagSENT_CONTENT	:\tagSENT_CONTENT	The\tagSENT_CONTENT	first\tagSENT_CONTENT	200\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	1,000\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	automatic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	were\tagSENT_CONTENT	compressed\tagSENT_CONTENT	by\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	four\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Whatever\tagSENT_START	the\tagSENT_CONTENT	crisis\tagSENT_CONTENT	or\tagSENT_CONTENT	embarrassment\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	Pres\tagSENT_CONTENT	.\tagSENT_END	Medha\tagSECTITLE_START	Patkar\tagSECTITLE_CONTENT	extended\tagSECTITLE_CONTENT	her\tagSECTITLE_CONTENT	support\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	Aam\tagSECTITLE_CONTENT	Aadmi\tagSECTITLE_CONTENT	Party\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	State\tagSECTITLE_CONTENT	Sen.\tagSECTITLE_CONTENT	Stewart\tagSECTITLE_CONTENT	Greenleaf\tagSECTITLE_CONTENT	discusses\tagSECTITLE_CONTENT	his\tagSECTITLE_CONTENT	proposed\tagSECTITLE_CONTENT	human\tagSECTITLE_CONTENT	trafficking\tagSECTITLE_CONTENT	bill\tagSECTITLE_CONTENT	at\tagSECTITLE_CONTENT	Calvery\tagSECTITLE_CONTENT	Baptist\tagSECTITLE_CONTENT	Church\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Willow\tagSECTITLE_CONTENT	Grove\tagSECTITLE_CONTENT	Thursday\tagSECTITLE_CONTENT	night\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	Stewart\tagSECTITLE_CONTENT	Greenleaf\tagSECTITLE_CONTENT	discusses\tagSECTITLE_CONTENT	his\tagSECTITLE_CONTENT	human\tagSECTITLE_CONTENT	trafficking\tagSECTITLE_CONTENT	bill\tagSECTITLE_CONTENT	.\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	one\tagSENT_CONTENT	removes\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	the\tagSENT_CONTENT	age\tagSENT_CONTENT	modifiers\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	preceding\tagSENT_CONTENT	commas\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	not\tagSENT_CONTENT	dropped\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	compression\tagSENT_CONTENT	is\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	,\tagSENT_CONTENT	preserving\tagSENT_CONTENT	both\tagSENT_CONTENT	conjoined\tagSENT_CONTENT	elements\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	automatic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	penalized\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	single\tagSENT_CONTENT	golden\tagSENT_CONTENT	variant\tagSENT_CONTENT	,\tagSENT_CONTENT	inhuman\tagSENT_CONTENT	evals\tagSENT_CONTENT	there\tagSENT_CONTENT	was\tagSENT_CONTENT	no\tagSENT_CONTENT	penalty\tagSENT_CONTENT	for\tagSENT_CONTENT	readable\tagSENT_CONTENT	alternatives\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	
P16-1085	title\tagSECTITLE_END	Embeddings\tagSENT_START	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	:\tagSENT_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	how\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	oldest\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	and\tagSENT_CONTENT	Artificial\tagSENT_CONTENT	Intelligence\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	exploited\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	Sentiment\tagSENT_CONTENT	Analysis\tagSENT_CONTENT	(\tagSENT_CONTENT	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	and\tagSENT_CONTENT	Language\tagSENT_CONTENT	Understanding\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	One\tagSENT_START	way\tagSENT_CONTENT	to\tagSENT_CONTENT	enhance\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	more\tagSENT_CONTENT	finegrained\tagSENT_CONTENT	semantic\tagSENT_CONTENT	items\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	word_sense_disambiguation\tagtask	or\tagSENT_CONTENT	concepts\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	that\tagSENT_CONTENT	conventional\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	conflate\tagSENT_CONTENT	different\tagSENT_CONTENT	meanings\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Sense\tagSECTITLE_CONTENT	Disambiguation\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	assigning\tagSENT_CONTENT	predefined\tagSENT_CONTENT	meanings\tagSENT_CONTENT	to\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	contexts\tagSENT_CONTENT	,\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	computational\tagSENT_CONTENT	lexical\tagSENT_CONTENT	semantics\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	methods\tagSECTITLE_END	They\tagSENT_START	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	's\tagSENT_CONTENT	context\tagSENT_CONTENT	can\tagSENT_CONTENT	provide\tagSENT_CONTENT	enough\tagSENT_CONTENT	evidence\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	Unsupervised\tagSECTITLE_START	methods\tagSECTITLE_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	methods\tagSECTITLE_END	Knowledge\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	methods\tagSECTITLE_END	Standard\tagSECTITLE_START	WSD\tagSECTITLE_CONTENT	features\tagSECTITLE_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	WSD\tagSECTITLE_CONTENT	features\tagSECTITLE_END	Several\tagSENT_START	studies\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	investigated\tagSENT_CONTENT	their\tagSENT_CONTENT	integration\tagSENT_CONTENT	into\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	Concatenation\tagSECTITLE_END	Average\tagSECTITLE_END	Fractional\tagSECTITLE_START	decay\tagSECTITLE_END	Here\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	assumed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	inversely\tagSENT_CONTENT	proportional\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	distance\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	Exponential\tagSECTITLE_START	decay\tagSECTITLE_END	Framework\tagSECTITLE_END	WSD\tagSECTITLE_START	System\tagSECTITLE_END	Embedding\tagSECTITLE_START	Features\tagSECTITLE_END	Experiments\tagSECTITLE_END	Lexical\tagSECTITLE_START	Sample\tagSECTITLE_CONTENT	WSD\tagSECTITLE_CONTENT	Experiment\tagSECTITLE_END	Lexical\tagSECTITLE_START	sample\tagSECTITLE_CONTENT	WSD\tagSECTITLE_CONTENT	results\tagSECTITLE_END	All\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	WSD\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	Since\tagSENT_START	all\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	tasks\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	usually\tagSENT_CONTENT	provide\tagSENT_CONTENT	any\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	challenge\tagSENT_CONTENT	here\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	word_sense_disambiguation\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	casein\tagSENT_CONTENT	the\tagSENT_CONTENT	lexical\tagSENT_CONTENT	sample\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	to\tagSENT_CONTENT	gather\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	coverage\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	as\tagSENT_CONTENT	many\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	possible\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	One\tagSENT_CONTENT	Million\tagSENT_CONTENT	Sense\tagSENT_CONTENT	-\tagSENT_CONTENT	Tagged\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	and\tagSENT_CONTENT	Induction\tagSENT_CONTENT	)\tagSENT_CONTENT	was\tagSENT_CONTENT	constructed\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DSO\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	provides\tagSENT_CONTENT	annotations\tagSENT_CONTENT	for\tagSENT_CONTENT	around\tagSENT_CONTENT	42\tagSENT_CONTENT	K\tagSENT_CONTENT	different\tagSENT_CONTENT	nouns\tagSENT_CONTENT	,\tagSENT_CONTENT	verbs\tagSENT_CONTENT	,\tagSENT_CONTENT	adjectives\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	adverbs\tagSENT_CONTENT	.\tagSENT_END	also\tagSENT_START	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	system\tagSENT_CONTENT	that\tagSENT_CONTENT	averages\tagSENT_CONTENT	word_sense_disambiguation\tagtask	of\tagSENT_CONTENT	IMS\tagSENT_CONTENT	with\tagSENT_CONTENT	theirs\tagSENT_CONTENT	(\tagSENT_CONTENT	shown\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	Muffin\tagSENT_CONTENT	+\tagSENT_CONTENT	IMS\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	tables\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	All\tagSECTITLE_START	-\tagSECTITLE_CONTENT	words\tagSECTITLE_CONTENT	WSD\tagSECTITLE_CONTENT	results\tagSECTITLE_END	Analysis\tagSECTITLE_END	All\tagSENT_START	the\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	experiment\tagSENT_CONTENT	were\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	unless\tagSENT_CONTENT	specified\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	word_sense_disambiguation\tagtask	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.2\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	effect\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	parameters\tagSECTITLE_END	Comparison\tagSECTITLE_START	of\tagSECTITLE_CONTENT	embedding\tagSECTITLE_CONTENT	types\tagSECTITLE_END	Conclusions\tagSECTITLE_END	As\tagSENT_START	future\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	possibility\tagSENT_CONTENT	of\tagSENT_CONTENT	designing\tagSENT_CONTENT	word_sense_disambiguation\tagtask	that\tagSENT_CONTENT	best\tagSENT_CONTENT	suit\tagSENT_CONTENT	the\tagSENT_CONTENT	WSD\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	
P18-1063	title\tagSECTITLE_END	summarization\tagtask	with\tagSENT_CONTENT	Reinforce\tagSENT_CONTENT	-\tagSENT_CONTENT	Selected\tagSENT_CONTENT	Sentence\tagSENT_CONTENT	Rewriting\tagSENT_END	abstract\tagSECTITLE_END	Empirically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	significantly\tagSENT_CONTENT	higher\tagSENT_CONTENT	abstractiveness\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	has\tagSENT_CONTENT	two\tagSENT_CONTENT	main\tagSENT_CONTENT	paradigms\tagSENT_CONTENT	:\tagSENT_CONTENT	extractive\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	takes\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	hierarchy\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	better\tagSENT_CONTENT	models\tagSENT_CONTENT	the\tagSENT_CONTENT	language\tagSENT_CONTENT	structure\tagSENT_CONTENT	and\tagSENT_CONTENT	makes\tagSENT_CONTENT	summarization\tagtask	possible\tagSENT_CONTENT	.\tagSENT_END	Empirically\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	metrics\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	on\tagSENT_CONTENT	METEOR\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	previous\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	use\tagSENT_CONTENT	complex\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	encoder\tagSENT_CONTENT	,\tagSENT_CONTENT	copy\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	coverage\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	surpass\tagSENT_CONTENT	the\tagSENT_CONTENT	popular\tagSENT_CONTENT	lead-3\tagSENT_CONTENT	baseline\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	scores\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	contribution\tagSENT_CONTENT	is\tagSENT_CONTENT	three\tagSENT_CONTENT	fold\tagSENT_CONTENT	:\tagSENT_CONTENT	First\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	RL\tagSENT_CONTENT	technique\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	known\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	effectively\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	then\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	structure\tagSENT_CONTENT	without\tagSENT_CONTENT	annotated\tagSENT_CONTENT	matching\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	pairs\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	,\tagSENT_START	our\tagmetric	goal\tagmetric	is\tagSENT_CONTENT	to\tagSENT_CONTENT	approximate\tagSENT_CONTENT	the\tagSENT_CONTENT	function\tagSENT_CONTENT	h\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	Si\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	xi\tagSENT_CONTENT	and\tagSENT_CONTENT	Di\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	y\tagSENT_CONTENT	i\tagSENT_CONTENT	.\tagSENT_END	Extractor\tagSECTITLE_START	Agent\tagSECTITLE_END	Convolutional\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	Hierarchical\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Representation\tagSECTITLE_END	Sentence\tagSECTITLE_START	Selection\tagSECTITLE_END	summarization\tagtask	(\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	)\tagSENT_END	Generated\tagSECTITLE_START	Sentence\tagSECTITLE_END	Reward\tagSECTITLE_END	RL\tagSECTITLE_START	Agent\tagSECTITLE_END	Document\tagSECTITLE_START	Sentences\tagSECTITLE_END	summarization\tagtask	(\tagSENT_CONTENT	extract\tagSENT_CONTENT	sent\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	Abstractor\tagSECTITLE_START	Network\tagSECTITLE_END	Learning\tagSECTITLE_END	Maximum\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Likelihood\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Submodules\tagSECTITLE_END	2.1.2\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	formulated\tagSENT_CONTENT	our\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Reinforce\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Guided\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	(\tagSENT_START	D\tagSENT_CONTENT	,\tagSENT_CONTENT	d\tagSENT_CONTENT	j\tagSENT_CONTENT	t−1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	samples\tagSENT_CONTENT	summarization\tagtask	j\tagSENT_CONTENT	t\tagSENT_CONTENT	∼\tagSENT_CONTENT	π\tagSENT_CONTENT	θa\tagSENT_CONTENT	,\tagSENT_CONTENT	ω\tagSENT_CONTENT	(\tagSENT_CONTENT	c\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	In\tagSENT_START	Eqn\tagSENT_CONTENT	.\tagSENT_CONTENT	6\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	ROUGE\tagmetric	-\tagmetric	recall\tagmetric	because\tagSENT_CONTENT	we\tagSENT_CONTENT	want\tagSENT_CONTENT	the\tagSENT_CONTENT	extracted\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	contain\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	information\tagSENT_CONTENT	as\tagSENT_CONTENT	possible\tagSENT_CONTENT	for\tagSENT_CONTENT	rewriting\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	RL\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	agent\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	attempt\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	agent\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	know\tagSENT_CONTENT	in\tagSENT_CONTENT	advance\tagSENT_CONTENT	how\tagSENT_CONTENT	many\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	article\tagSENT_CONTENT	(\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	desired\tagSENT_CONTENT	length\tagSENT_CONTENT	varies\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	downstream\tagSENT_CONTENT	applications\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	summarization\tagtask	allows\tagSENT_CONTENT	dy-7\tagSENT_CONTENT	During\tagSENT_CONTENT	this\tagSENT_CONTENT	RL\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	extractor\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	keep\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractor\tagSENT_CONTENT	parameters\tagSENT_CONTENT	fixed\tagSENT_CONTENT	.\tagSENT_END	8\tagSENT_START	We\tagSENT_CONTENT	use\tagSENT_CONTENT	ROUGE-1\tagmetric	for\tagSENT_CONTENT	terminal\tagSENT_CONTENT	reward\tagSENT_CONTENT	because\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	measure\tagSENT_CONTENT	of\tagSENT_CONTENT	bag\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	information\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	has\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	namic\tagSENT_CONTENT	decisions\tagSENT_CONTENT	of\tagSENT_CONTENT	number\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	sentences\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	eliminates\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	for\tagSENT_CONTENT	tuning\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	steps\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	enables\tagSENT_CONTENT	a\tagSENT_CONTENT	data\tagSENT_CONTENT	-\tagSENT_CONTENT	driven\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	for\tagSENT_CONTENT	any\tagSENT_CONTENT	specific\tagSENT_CONTENT	dataset\tagSENT_CONTENT	/\tagSENT_CONTENT	application\tagSENT_CONTENT	.\tagSENT_END	Repetition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Avoiding\tagSECTITLE_CONTENT	Reranking\tagSECTITLE_END	summarization\tagtask	are\tagSENT_CONTENT	reranked\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	repeated\tagSENT_CONTENT	N\tagSENT_CONTENT	-grams\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	smaller\tagSENT_CONTENT	the\tagSENT_CONTENT	better\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	some\tagSENT_CONTENT	loosely\tagSENT_CONTENT	-\tagSENT_CONTENT	related\tagSENT_CONTENT	recent\tagSENT_CONTENT	works\tagSENT_CONTENT	:\tagSENT_CONTENT	 \tagSENT_CONTENT	proposed\tagSENT_CONTENT	selective\tagSENT_CONTENT	gate\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Please\tagSENT_START	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	supplementary\tagSENT_CONTENT	for\tagSENT_CONTENT	full\tagSENT_CONTENT	training\tagSENT_CONTENT	details\tagSENT_CONTENT	(\tagSENT_CONTENT	all\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	tuning\tagSENT_CONTENT	was\tagSENT_CONTENT	performed\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Metrics\tagSECTITLE_END	For\tagSENT_START	all\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	standard\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	Lin\tagSENT_CONTENT	,\tagSENT_CONTENT	2004\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	fulllength\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	stemming\tagSENT_CONTENT	)\tagSENT_CONTENT	following\tagSENT_CONTENT	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Modular\tagSECTITLE_START	Extractive\tagSECTITLE_CONTENT	vs.\tagSECTITLE_CONTENT	Abstractive\tagSECTITLE_END	The\tagSENT_START	extractor\tagSENT_CONTENT	alone\tagSENT_CONTENT	performs\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Benefiting\tagSENT_START	from\tagSENT_CONTENT	the\tagSENT_CONTENT	high\tagSENT_CONTENT	modularity\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	summarization\tagtask	abstractive\tagSENT_CONTENT	by\tagSENT_CONTENT	simply\tagSENT_CONTENT	applying\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractor\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	extracted\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	shows\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	our\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	ofdomain\tagSENT_CONTENT	test\tagSENT_CONTENT	-\tagSENT_CONTENT	only\tagSENT_CONTENT	setup\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	better\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	See\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_END	Extractive\tagSECTITLE_START	Summarization\tagSECTITLE_END	Abstractive\tagSECTITLE_START	Summarization\tagSECTITLE_END	Both\tagSENT_START	combined\tagSENT_CONTENT	models\tagSENT_CONTENT	exceed\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	generator\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	without\tagSENT_CONTENT	coverage\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	margin\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	2-step\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	approach\tagSENT_CONTENT	:\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	naturally\tagSENT_CONTENT	avoids\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	extracting\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	keypoints\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	best\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	A\tagSENT_CONTENT	trivial\tagSENT_CONTENT	lead-3\tagSENT_CONTENT	+\tagSENT_CONTENT	abs\tagSENT_CONTENT	baseline\tagSENT_CONTENT	obtains\tagSENT_CONTENT	ROUGE\tagmetric	of\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	again\tagSENT_CONTENT	confirms\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	reinforce\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	.\tagSENT_END	Relevance\tagSECTITLE_START	Readability\tagSECTITLE_CONTENT	Total\tagSECTITLE_END	Several\tagSENT_START	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	have\tagSENT_CONTENT	pointed\tagSENT_CONTENT	out\tagSENT_CONTENT	that\tagSENT_CONTENT	extractive\tagSENT_CONTENT	baselines\tagSENT_CONTENT	are\tagSENT_CONTENT	very\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	beat\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	ROUGE\tagmetric	)\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	system\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluation\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	conduct\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	robustness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	training\tagSENT_CONTENT	procedure\tagSENT_CONTENT	.\tagSENT_END	Speed\tagSECTITLE_START	Comparison\tagSECTITLE_END	Our\tagSENT_START	full\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	extremely\tagSENT_CONTENT	fast\tagSENT_CONTENT	extractor\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	parallelizable\tagSENT_CONTENT	abstractor\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	computation\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	is\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractor\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Abstractiveness\tagSECTITLE_END	A\tagSENT_START	potential\tagSENT_CONTENT	reason\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	individual\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractor\tagSENT_CONTENT	learns\tagSENT_CONTENT	to\tagSENT_CONTENT	drop\tagSENT_CONTENT	more\tagSENT_CONTENT	document\tagSENT_CONTENT	words\tagSENT_CONTENT	so\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	write\tagSENT_CONTENT	individual\tagSENT_CONTENT	summary\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	concise\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	;\tagSENT_CONTENT	thus\tagSENT_CONTENT	the\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	novelty\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Output\tagSECTITLE_CONTENT	Examples\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	RL\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	hierarchy\tagSENT_CONTENT	.\tagSENT_END	
1601.03651	title\tagSECTITLE_END	relationship_extraction\tagtask	by\tagSENT_CONTENT	Deep\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_CONTENT	with\tagSENT_CONTENT	Data\tagSENT_CONTENT	Augmentation\tagSENT_END	abstract\tagSECTITLE_END	Nowadays\tagSENT_START	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	play\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	existing\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	of\tagSENT_CONTENT	shallow\tagSENT_CONTENT	architectures\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	or\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	networks\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	deep\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	DRNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	this\tagSENT_CONTENT	challenge\tagSENT_CONTENT	.\tagSENT_END	Further\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	method\tagSENT_CONTENT	by\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Classifying\tagSENT_START	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	context\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	marked\tagSENT_CONTENT	entities\tagSENT_CONTENT	valuables\tagSENT_CONTENT	and\tagSENT_CONTENT	safe\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	-\tagSENT_CONTENT	Container(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	become\tagSENT_CONTENT	a\tagSENT_CONTENT	hot\tagSENT_CONTENT	research\tagSENT_CONTENT	topic\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Nowadays\tagSENT_START	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	made\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	traditional\tagSENT_CONTENT	methods\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	either\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	designed\tagSENT_CONTENT	features\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	kernels\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	utilize\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	have\tagSENT_CONTENT	noticed\tagSENT_CONTENT	that\tagSENT_CONTENT	these\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	typically\tagSENT_CONTENT	designed\tagSENT_CONTENT	in\tagSENT_CONTENT	shallow\tagSENT_CONTENT	architectures\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	or\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	evidence\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	community\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	deep\tagSENT_CONTENT	architectures\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	natural\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	whether\tagSENT_CONTENT	such\tagSENT_CONTENT	deep\tagSENT_CONTENT	architectures\tagSENT_CONTENT	are\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	deep\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	DRNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	deep\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	can\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	space\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	granularity\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	visualizing\tagSENT_CONTENT	how\tagSENT_CONTENT	RNN\tagSENT_CONTENT	units\tagSENT_CONTENT	are\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	ultimate\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	different\tagSENT_CONTENT	layers\tagSENT_CONTENT	indeed\tagSENT_CONTENT	learn\tagSENT_CONTENT	different\tagSENT_CONTENT	representations\tagSENT_CONTENT	:\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	layers\tagSENT_CONTENT	enable\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	information\tagSENT_CONTENT	mix\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	highlevel\tagSENT_CONTENT	layers\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	precisely\tagSENT_CONTENT	locating\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	*\tagSENT_END	We\tagSENT_START	further\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	directed\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	our\tagSENT_CONTENT	deep\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	strategy\tagSENT_CONTENT	have\tagSENT_CONTENT	contributed\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	coupled\tagSENT_CONTENT	well\tagSENT_CONTENT	together\tagSENT_CONTENT	for\tagSENT_CONTENT	further\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Traditional\tagSENT_START	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	mainly\tagSENT_CONTENT	fall\tagSENT_CONTENT	into\tagSENT_CONTENT	two\tagSENT_CONTENT	groups\tagSENT_CONTENT	:\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	or\tagSENT_CONTENT	kernel\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	.\tagSENT_END	design\tagSENT_START	a\tagSENT_CONTENT	kernel\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	(\tagSENT_CONTENT	SDP\tagSENT_CONTENT	)\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	by\tagSENT_CONTENT	observing\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	strongly\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	SDPs\tagSENT_CONTENT	.\tagSENT_END	combine\tagSENT_START	structural\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	tree\tagSENT_CONTENT	kernel\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	previous\tagSENT_CONTENT	study\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	SDP\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	Methodology\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	methodology\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	Overview\tagSECTITLE_END	Different\tagSENT_START	from\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	design\tagSENT_CONTENT	deep\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	with\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	four\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	so\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Then\tagSENT_START	all\tagSENT_CONTENT	pooling\tagSENT_CONTENT	layers\tagSENT_CONTENT	are\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	and\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Recurrent\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Shortest\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Path\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	RNN\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	SDP\tagSENT_CONTENT	,\tagSENT_CONTENT	serving\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	building\tagSENT_CONTENT	block\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	deep\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	reduces\tagSENT_CONTENT	relationship_extraction\tagtask	;\tagSENT_CONTENT	second\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	words\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	agents\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	naturally\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	simplicity\tagSENT_CONTENT	and\tagSENT_CONTENT	without\tagSENT_CONTENT	loss\tagSENT_CONTENT	of\tagSENT_CONTENT	generality\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	vanilla\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	is\tagSENT_CONTENT	linearly\tagSENT_CONTENT	transformed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	weight\tagSENT_CONTENT	matrix\tagSENT_CONTENT	and\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linearly\tagSENT_CONTENT	squashed\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	activation\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_END	b\tagSENT_START	h\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	bias\tagSENT_CONTENT	term\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	activation\tagSENT_CONTENT	function\tagSENT_CONTENT	(\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiment\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Deep\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	Although\tagSENT_START	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	picking\tagSENT_CONTENT	information\tagSENT_CONTENT	along\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	subpath\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	task\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	its\tagSENT_CONTENT	iterative\tagSENT_CONTENT	nature\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	community\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	deep\tagSENT_CONTENT	architectures\tagSENT_CONTENT	maybe\tagSENT_CONTENT	more\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	capture\tagSENT_CONTENT	different\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Softmax\tagSECTITLE_END	Word\tagSECTITLE_START	/\tagSECTITLE_CONTENT	GR\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	POS\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	WordNet\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_END	Hidden\tagSECTITLE_START	layer\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	words\tagSENT_CONTENT	along\tagSENT_CONTENT	SDPs\tagSENT_CONTENT	provide\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	different\tagSENT_CONTENT	perspectives\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	enhance\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	cross\tagSENT_CONTENT	"\tagSENT_CONTENT	connection\tagSENT_CONTENT	for\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	≥\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	lower\tagSENT_CONTENT	layer\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	W\tagSENT_END	Data\tagSECTITLE_START	Augmentation\tagSECTITLE_END	To\tagSENT_START	mitigate\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	technique\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	by\tagSENT_CONTENT	making\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	two\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	paths\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	mapped\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	subject\tagSENT_CONTENT	-\tagSENT_CONTENT	predicate\tagSENT_CONTENT	and\tagSENT_CONTENT	object\tagSENT_CONTENT	-\tagSENT_CONTENT	predicate\tagSENT_CONTENT	components\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	-\tagSENT_CONTENT	Container(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Then\tagSENT_START	relationship_extraction\tagtask	becomes\tagSENT_CONTENT	Container\tagSENT_CONTENT	-\tagSENT_CONTENT	Content(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	exactly\tagSENT_CONTENT	the\tagSENT_CONTENT	inverse\tagSENT_CONTENT	of\tagSENT_CONTENT	Content\tagSENT_CONTENT	-\tagSENT_CONTENT	Container(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Objective\tagSECTITLE_END	In\tagSENT_START	total\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	40\tagSENT_CONTENT	pools\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	and\tagSENT_CONTENT	fed\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	outputs\tagSENT_CONTENT	the\tagSENT_CONTENT	estimated\tagSENT_CONTENT	probability\tagSENT_CONTENT	that\tagSENT_CONTENT	two\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	paths\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	s\tagSENT_CONTENT	right\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	where\tagSENT_START	r\tagSENT_CONTENT	−1\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	inverse\tagSENT_CONTENT	of\tagSENT_CONTENT	Experiments\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	DRNNs\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	established\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Other\tagSENT_CONTENT	class\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	taken\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	when\tagSENT_CONTENT	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	measures\tagSENT_CONTENT	.\tagSENT_END	Hyperparameter\tagSECTITLE_START	Settings\tagSECTITLE_END	relationship_extraction\tagtask	presents\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Variant\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Data\tagSECTITLE_CONTENT	augmentation\tagSECTITLE_END	Data\tagSECTITLE_START	Augmentation\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	The\tagSENT_START	result\tagSENT_CONTENT	verifies\tagSENT_CONTENT	our\tagSENT_CONTENT	conjecture\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	obtained\tagSENT_CONTENT	an\tagSENT_CONTENT	even\tagSENT_CONTENT	larger\tagSENT_CONTENT	degradation\tagSENT_CONTENT	of\tagSENT_CONTENT	1.1\tagSENT_CONTENT	%\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	pilot\tagSENT_CONTENT	experiments\tagSENT_CONTENT	suggest\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	should\tagSENT_CONTENT	take\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	unfavorable\tagSENT_CONTENT	noise\tagSENT_CONTENT	when\tagSENT_CONTENT	performing\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	would\tagSENT_CONTENT	like\tagSENT_CONTENT	to\tagSENT_CONTENT	point\tagSENT_CONTENT	out\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	general\tagSENT_CONTENT	technique\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	ad\tagSENT_CONTENT	hoc\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	dataset\tagSENT_CONTENT	;\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	methodology\tagSENT_CONTENT	for\tagSENT_CONTENT	dealing\tagSENT_CONTENT	with\tagSENT_CONTENT	noise\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	potentially\tagSENT_CONTENT	applicable\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	RNNs\tagSECTITLE_START	vs.\tagSECTITLE_CONTENT	CNNs\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	convolution\tagSENT_CONTENT	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	are\tagSENT_CONTENT	typically\tagSENT_CONTENT	padded\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	symbol\tagSENT_CONTENT	or\tagSENT_CONTENT	simply\tagSENT_CONTENT	zero\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSECTITLE_START	Performance\tagSECTITLE_END	They\tagSENT_START	extend\tagSENT_CONTENT	their\tagSENT_CONTENT	recursive\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	elevate\tagSENT_CONTENT	the\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	-score\tagSENT_CONTENT	to\tagSENT_CONTENT	82.4\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_START	of\tagSECTITLE_CONTENT	DRNNs\tagSECTITLE_CONTENT	'\tagSECTITLE_CONTENT	Depth\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	depth\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	DRNNs\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	think\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	considering\tagSENT_CONTENT	relationship_extraction\tagtask	-\tagSENT_CONTENT	Agency(e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	informative\tagSENT_CONTENT	with\tagSENT_CONTENT	only\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	vessels\tagSENT_CONTENT	and\tagSENT_CONTENT	badge\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	adding\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	of\tagSENT_CONTENT	verb\tagSENT_CONTENT	phrase\tagSENT_CONTENT	defaced\tagSENT_CONTENT	with\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	probably\tagSENT_CONTENT	because\tagSENT_CONTENT	had\tagSENT_CONTENT	links\tagSENT_CONTENT	two\tagSENT_CONTENT	ends\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	Message\tagSENT_CONTENT	and\tagSENT_CONTENT	Topic\tagSENT_CONTENT	.\tagSENT_END	Figure\tagSENT_START	4\tagSENT_CONTENT	:\tagSENT_CONTENT	Visualization\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	along\tagSENT_CONTENT	multiple\tagSENT_CONTENT	RNN\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	a\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	pays\tagSENT_CONTENT	more\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	those\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	whether\tagSENT_CONTENT	entities\tagSENT_CONTENT	or\tagSENT_CONTENT	their\tagSENT_CONTENT	common\tagSENT_CONTENT	ancestor\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	relevant\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	consistent\tagSENT_CONTENT	among\tagSENT_CONTENT	different\tagSENT_CONTENT	data\tagSENT_CONTENT	samples\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	proposed\tagSENT_CONTENT	deep\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	DRNNs\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	By\tagSENT_START	visualizing\tagSENT_CONTENT	DRNNs\tagSENT_CONTENT	'\tagSENT_CONTENT	units\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	that\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	layers\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	integrating\tagSENT_CONTENT	information\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	target\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	designed\tagSENT_CONTENT	a\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	strategy\tagSENT_CONTENT	by\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	the\tagSENT_CONTENT	directionality\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	
S17-2094	title\tagSECTITLE_END	sentiment_analysis\tagtask	with\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	and\tagSENT_CONTENT	LSTMs\tagSENT_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Determining\tagSENT_START	sentiment_analysis\tagtask	of\tagSENT_CONTENT	tweets\tagSENT_CONTENT	has\tagSENT_CONTENT	become\tagSENT_CONTENT	a\tagSENT_CONTENT	landmark\tagSENT_CONTENT	homework\tagSENT_CONTENT	exercise\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	data\tagSENT_CONTENT	science\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	last\tagSENT_CONTENT	few\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	techniques\tagSENT_CONTENT	have\tagSENT_CONTENT	significantly\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	performed\tagSENT_CONTENT	traditional\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	is\tagSENT_CONTENT	no\tagSENT_CONTENT	exception\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagSENT_CONTENT	trend\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	previous\tagSENT_CONTENT	iterations\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	have\tagSENT_CONTENT	already\tagSENT_CONTENT	established\tagSENT_CONTENT	their\tagSENT_CONTENT	power\tagSENT_CONTENT	over\tagSENT_CONTENT	other\tagSENT_CONTENT	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Two\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	popular\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	techniques\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	are\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	and\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_START	description\tagSECTITLE_CONTENT	2.1\tagSECTITLE_CONTENT	CNN\tagSECTITLE_END	LSTM\tagSECTITLE_END	Training\tagSECTITLE_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	processing\tagSECTITLE_END	Unsupervised\tagSECTITLE_START	training\tagSECTITLE_END	Distant\tagSECTITLE_START	training\tagSECTITLE_END	The\tagSENT_START	embeddings\tagSENT_CONTENT	learned\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	phase\tagSENT_CONTENT	contain\tagSENT_CONTENT	very\tagSENT_CONTENT	little\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	fora\tagSENT_CONTENT	positive\tagSENT_CONTENT	word\tagSENT_CONTENT	(\tagSENT_CONTENT	ex\tagSENT_CONTENT	.\tagSENT_CONTENT	"\tagSENT_END	Supervised\tagSECTITLE_START	training\tagSECTITLE_END	Subtask\tagSECTITLE_START	specific\tagSECTITLE_CONTENT	tricks\tagSECTITLE_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	quantification\tagSENT_CONTENT	subtasks\tagSENT_CONTENT	(\tagSENT_CONTENT	D\tagSENT_CONTENT	and\tagSENT_CONTENT	E\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	average\tagSENT_CONTENT	approach\tagSENT_CONTENT	of\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	into\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	average\tagSENT_CONTENT	recall\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	2017\tagSENT_CONTENT	edition\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	this\tagSENT_CONTENT	should\tagSENT_CONTENT	not\tagSENT_CONTENT	affect\tagSENT_CONTENT	the\tagSENT_CONTENT	conclusions\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	significantly\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	metrics\tagSENT_CONTENT	were\tagSENT_CONTENT	highly\tagSENT_CONTENT	correlated\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	absence\tagSENT_CONTENT	of\tagSENT_CONTENT	class\tagSENT_CONTENT	weights\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	absence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	distant\tagSENT_CONTENT	training\tagSENT_CONTENT	stage\tagSENT_CONTENT	lowers\tagSENT_CONTENT	the\tagmetric	scores\tagmetric	significantly\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	demonstrates\tagSENT_CONTENT	that\tagSENT_CONTENT	these\tagSENT_CONTENT	are\tagSENT_CONTENT	sound\tagSENT_CONTENT	additions\tagSENT_CONTENT	.\tagSENT_END	Indeed\tagSENT_START	,\tagSENT_CONTENT	while\tagSENT_CONTENT	these\tagSENT_CONTENT	individual\tagSENT_CONTENT	models\tagSENT_CONTENT	give\tagSENT_CONTENT	similar\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	outputs\tagSENT_CONTENT	are\tagSENT_CONTENT	sufficiently\tagSENT_CONTENT	uncorrelated\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	ensembling\tagSENT_CONTENT	them\tagSENT_CONTENT	gives\tagSENT_CONTENT	the\tagmetric	score\tagmetric	a\tagSENT_CONTENT	small\tagSENT_CONTENT	boost\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	subtask\tagSENT_CONTENT	A\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	actually\tagSENT_CONTENT	a\tagSENT_CONTENT	tie\tagSENT_CONTENT	between\tagSENT_CONTENT	our\tagSENT_CONTENT	submission\tagSENT_CONTENT	and\tagSENT_CONTENT	another\tagSENT_CONTENT	team\tagSENT_CONTENT	(\tagSENT_CONTENT	DataStories\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagmetric	P\tagmetric	N\tagmetric	1\tagmetric	score\tagmetric	)\tagSENT_CONTENT	our\tagSENT_CONTENT	submission\tagSENT_CONTENT	ranks\tagSENT_CONTENT	higher\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	presented\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	compete\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2017\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	System\tagSECTITLE_START	/\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	System\tagSECTITLE_CONTENT	5\tagSECTITLE_CONTENT	System\tagSECTITLE_END	
S16-1181	title\tagSECTITLE_END	abstract\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	description\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	additional\tagSENT_CONTENT	sources\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	further\tagSENT_CONTENT	boost\tagSENT_CONTENT	its\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	achieves\tagSENT_CONTENT	a\tagmetric	Smatch\tagmetric	F\tagmetric	-\tagmetric	score\tagmetric	of\tagSENT_CONTENT	62\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	blind\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	amr_parsing\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	taking\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	producing\tagSENT_CONTENT	as\tagSENT_CONTENT	output\tagSENT_CONTENT	an\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representation\tagSENT_CONTENT	(\tagSENT_CONTENT	AMR\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	rooted\tagSENT_CONTENT	,\tagSENT_CONTENT	directed\tagSENT_CONTENT	,\tagSENT_CONTENT	edge\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	and\tagSENT_CONTENT	leaf\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	graph\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	has\tagSENT_CONTENT	drawn\tagSENT_CONTENT	an\tagSENT_CONTENT	increasing\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	recently\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	relation\tagSENT_CONTENT	identification\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	adopt\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	techniques\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	those\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	growing\tagSENT_CONTENT	and\tagSENT_CONTENT	several\tagSENT_CONTENT	systems\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	substantially\tagSENT_CONTENT	advanced\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	far\tagSENT_CONTENT	less\tagSENT_CONTENT	accurate\tagSENT_CONTENT	than\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parsers\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	boost\tagSENT_CONTENT	amr_parsing\tagtask	by\tagSENT_CONTENT	introducing\tagSENT_CONTENT	additional\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	CAMR\tagSECTITLE_START	Overview\tagSECTITLE_END	Basic\tagSECTITLE_START	Configuration\tagSECTITLE_END	CAMR\tagSECTITLE_START	Extensions\tagSECTITLE_END	Feature\tagSECTITLE_START	Enrichment\tagSECTITLE_END	Rich\tagSENT_START	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	tags\tagSENT_CONTENT	Since\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	types\tagSENT_CONTENT	in\tagSENT_CONTENT	AMR\tagSENT_CONTENT	are\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	types\tagSENT_CONTENT	defined\tagSENT_CONTENT	in\tagSENT_CONTENT	atypical\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	tagging\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	richer\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	tagger\tagSENT_CONTENT	could\tagSENT_CONTENT	improve\tagSENT_CONTENT	concept\tagSENT_CONTENT	identification\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	The\tagSENT_START	ISI\tagSENT_CONTENT	verbalization\tagSENT_CONTENT	list\tagSENT_CONTENT	A\tagSENT_CONTENT	large\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	"\tagSENT_CONTENT	normalized\tagSENT_CONTENT	"\tagSENT_CONTENT	English\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	any\tagSENT_CONTENT	alignment\tagSENT_CONTENT	is\tagSENT_CONTENT	missed\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	left\tagSENT_CONTENT	un\tagSENT_CONTENT	-\tagSENT_CONTENT	aligned\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	simply\tagSENT_CONTENT	add\tagSENT_CONTENT	an\tagSENT_CONTENT	alignment\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	the\tagSENT_CONTENT	unaligned\tagSENT_CONTENT	concept\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	word\tagSENT_CONTENT	token\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	token\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	verbalization\tagSENT_CONTENT	list\tagSENT_CONTENT	.\tagSENT_END	Wikification\tagSECTITLE_END	Given\tagSENT_START	an\tagSENT_CONTENT	entity\tagSENT_CONTENT	mention\tagSENT_CONTENT	m\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	system\tagSENT_CONTENT	first\tagSENT_CONTENT	constructs\tagSENT_CONTENT	a\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	Graph\tagSENT_CONTENT	g(m\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	mat\tagmetric	the\tagSENT_CONTENT	hub\tagSENT_CONTENT	and\tagSENT_CONTENT	leaf\tagSENT_CONTENT	nodes\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	reachable\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	from\tagSENT_END	Data\tagSECTITLE_END	Research\tagmetric	on\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	has\tagSENT_CONTENT	reported\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	releases\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	annotated\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	the\tagmetric	Smatch\tagmetric	scorer\tagmetric	uses\tagSENT_CONTENT	this\tagSENT_CONTENT	information\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	scoring\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	make\tagSENT_CONTENT	amr_parsing\tagtask	between\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	release\tagSENT_CONTENT	and\tagSENT_CONTENT	results\tagSENT_CONTENT	previously\tagSENT_CONTENT	reported\tagSENT_CONTENT	by\tagSENT_CONTENT	other\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	a.\tagSENT_START	LDC2013E117-This\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	public\tagSENT_CONTENT	release\tagSENT_CONTENT	that\tagSENT_CONTENT	was\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	very\tagSENT_CONTENT	first\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	with\tagSENT_CONTENT	Smatch\tagmetric	v2.0\tagmetric	.\tagSENT_CONTENT	)\tagSENT_END	SemEval\tagSECTITLE_START	Development\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	As\tagSENT_START	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parser\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	stage\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	impact\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	SemEval\tagSECTITLE_START	Test\tagSECTITLE_CONTENT	Set\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Blind\tagSECTITLE_CONTENT	Test\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	result\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	blind\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	configuration\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	§\tagSENT_CONTENT	5.1\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	we\tagSENT_START	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	remain\tagSENT_CONTENT	relatively\tagSENT_CONTENT	stable\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	indicating\tagSENT_START	the\tagSENT_CONTENT	blind\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	harder\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	further\tagSENT_CONTENT	error\tagSENT_CONTENT	analysis\tagSENT_CONTENT	to\tagSENT_CONTENT	gain\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSECTITLE_START	Release\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	LDC2014T12\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	/\tagSENT_CONTENT	development\tagSENT_CONTENT	/\tagSENT_CONTENT	test\tagSENT_CONTENT	split\tagSENT_CONTENT	recommended\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	release\tagSENT_CONTENT	:\tagSENT_CONTENT	10,312\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	1,368\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	1,371\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	amr_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	the\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	features\tagSENT_CONTENT	yield\tagSENT_CONTENT	a\tagSENT_CONTENT	modest\tagSENT_CONTENT	improvement\tagSENT_CONTENT	over\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	release\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Our\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	additional\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	helpful\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	a\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	designed\tagSENT_CONTENT	wikifier\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	helpful\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	step\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	
D17-1206	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	The\tagSECTITLE_START	Joint\tagSECTITLE_CONTENT	Many\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	The\tagSENT_START	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Representations\tagSECTITLE_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Level\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	POS\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Level\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Chunking\tagSECTITLE_END	chunking\tagtask	is\tagSENT_CONTENT	also\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	which\tagSENT_CONTENT	assigns\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	I\tagSENT_CONTENT	-\tagSENT_CONTENT	VP\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	chunking\tagtask	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layer\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	predicting\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	strategy\tagSENT_CONTENT	as\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	h\tagSENT_END	t\tagSENT_START	]\tagSENT_CONTENT	in\tagSENT_CONTENT	chunking\tagtask	.\tagSENT_END	Syntactic\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	,\tagSENT_START	where\tagSENT_CONTENT	we\tagSENT_CONTENT	computed\tagSENT_CONTENT	chunking\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	fashion\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	vector\tagSENT_CONTENT	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_END	Semantic\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Semantic\tagSECTITLE_CONTENT	relatedness\tagSECTITLE_END	Semantic\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	Textual\tagSECTITLE_CONTENT	entailment\tagSECTITLE_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	JMT\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Pre\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Representations\tagSECTITLE_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	POS\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	Chunking\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	Relatedness\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Training\tagSECTITLE_START	the\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	For\tagSENT_START	handling\tagSENT_CONTENT	multiple\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	recently\tagSENT_CONTENT	have\tagSENT_CONTENT	suggested\tagSENT_CONTENT	that\tagSENT_CONTENT	using\tagSENT_CONTENT	different\tagSENT_CONTENT	layers\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	tasks\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	effective\tagSENT_CONTENT	than\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	layer\tagSENT_CONTENT	in\tagSENT_CONTENT	jointly\tagSENT_CONTENT	learning\tagSENT_CONTENT	closely\tagSENT_CONTENT	-\tagSENT_CONTENT	related\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	Datasets\tagSECTITLE_END	To\tagSENT_START	train\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	(\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	)\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	Penn\tagdataset	Treebank\tagdataset	,\tagSENT_CONTENT	and\tagSENT_CONTENT	followed\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	split\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	0\tagSENT_CONTENT	-\tagSENT_CONTENT	18\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	development\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	19\tagSENT_CONTENT	-\tagSENT_CONTENT	21\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	22\tagSENT_CONTENT	-\tagSENT_CONTENT	24\tagSENT_CONTENT	)\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Details\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	handling\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	are\tagSENT_CONTENT	not\tagSENT_CONTENT	used\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Published\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	POS\tagSECTITLE_START	tagging\tagSECTITLE_END	chunking\tagtask	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	chunking\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	JMT\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	result\tagSENT_CONTENT	.\tagSENT_END	Dependency\tagSECTITLE_START	parsing\tagSECTITLE_END	chunking\tagtask	95.02\tagSENT_CONTENT	n\tagSENT_CONTENT	/\tagSENT_CONTENT	a\tagSENT_CONTENT	95.77\tagSENT_CONTENT	n\tagSENT_CONTENT	/\tagSENT_CONTENT	a\tagSENT_END	Method\tagSECTITLE_END	Analysis\tagSECTITLE_START	on\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Architectures\tagSECTITLE_END	Output\tagSECTITLE_START	label\tagSECTITLE_CONTENT	embeddings\tagSECTITLE_END	chunking\tagtask	used\tagSENT_CONTENT	here\tagSENT_CONTENT	is\tagSENT_CONTENT	relatively\tagSENT_CONTENT	small\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	effective\tagSENT_CONTENT	;\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	POS\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	drops\tagSENT_CONTENT	from\tagSENT_CONTENT	97.52\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	97.38\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagtask	drops\tagSENT_CONTENT	from\tagSENT_CONTENT	95.65\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	95.14\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
pdf_id_HkAClQgA-	title\tagSECTITLE_END	A\tagSENT_START	DEEP\tagSENT_CONTENT	REINFORCED\tagSENT_CONTENT	MODEL\tagSENT_CONTENT	FOR\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	Attentional\tagSENT_START	,\tagSENT_CONTENT	RNN\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	good\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	short\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	sequences\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	automatically\tagSENT_CONTENT	generating\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	summaries\tagSENT_CONTENT	from\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	while\tagSENT_CONTENT	retaining\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	points\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	two\tagSENT_CONTENT	prominent\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DUC-2004\tagSENT_CONTENT	dataset\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	system\tagSENT_CONTENT	by\tagSENT_CONTENT	are\tagSENT_CONTENT	limited\tagSENT_CONTENT	to\tagSENT_CONTENT	75\tagSENT_CONTENT	characters\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	and\tagSENT_CONTENT	similarly\tagSENT_CONTENT	good\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	New\tagSENT_CONTENT	York\tagSENT_CONTENT	Times\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	NYT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	41.16\tagmetric	ROUGE-1\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	NEURAL\tagSECTITLE_START	INTRA\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_END	INTRA\tagSECTITLE_START	-\tagSECTITLE_CONTENT	TEMPORAL\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	INPUT\tagSECTITLE_CONTENT	SEQUENCE\tagSECTITLE_END	At\tagSENT_START	each\tagSENT_CONTENT	decoding\tagSENT_CONTENT	step\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	temporal\tagSENT_CONTENT	attention\tagSENT_CONTENT	function\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	over\tagSENT_CONTENT	specific\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	encoded\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	's\tagSENT_CONTENT	own\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	previouslygenerated\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	INTRA\tagSECTITLE_START	-\tagSECTITLE_CONTENT	DECODER\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_END	To\tagSENT_START	prevent\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	summarization\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	previously\tagSENT_CONTENT	decoded\tagSENT_CONTENT	sequence\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	set\tagSENT_CONTENT	c\tagSENT_CONTENT	d\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagmetric	vector\tagmetric	of\tagSENT_CONTENT	zeros\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	sequence\tagSENT_CONTENT	is\tagSENT_CONTENT	empty\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	decoding\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	t\tagSENT_CONTENT	>\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	equations\tagSENT_CONTENT	:\tagSENT_CONTENT	illustrates\tagSENT_CONTENT	the\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	computation\tagSENT_CONTENT	c\tagSENT_CONTENT	d\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	temporal\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	use\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	difference\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	summarization\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	decoder\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	simple\tagSENT_CONTENT	and\tagSENT_CONTENT	widely\tagSENT_CONTENT	applicable\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	TOKEN\tagSECTITLE_START	GENERATION\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	POINTER\tagSECTITLE_END	Putting\tagSENT_START	summarization\tagtask	9\tagSENT_CONTENT	,\tagSENT_CONTENT	10\tagSENT_CONTENT	and\tagSENT_CONTENT	11\tagSENT_CONTENT	together\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	our\tagSENT_CONTENT	final\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	token\tagSENT_CONTENT	y\tagSENT_CONTENT	t\tagSENT_CONTENT	:\tagSENT_END	SHARING\tagSECTITLE_START	DECODER\tagSECTITLE_CONTENT	WEIGHTS\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	embedding\tagSENT_CONTENT	matrix\tagSENT_CONTENT	W\tagSENT_CONTENT	emb\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	some\tagSENT_CONTENT	weight\tagSENT_CONTENT	-\tagSENT_CONTENT	sharing\tagSENT_CONTENT	between\tagSENT_CONTENT	this\tagSENT_CONTENT	embedding\tagSENT_CONTENT	matrix\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	W\tagSENT_CONTENT	out\tagSENT_CONTENT	matrix\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tokengeneration\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	similarly\tagSENT_CONTENT	to\tagSENT_CONTENT	Inan\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_END	HYBRID\tagSECTITLE_START	LEARNING\tagSECTITLE_CONTENT	OBJECTIVE\tagSECTITLE_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	application\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	SUPERVISED\tagSECTITLE_START	LEARNING\tagSECTITLE_CONTENT	WITH\tagSECTITLE_CONTENT	TEACHER\tagSECTITLE_CONTENT	FORCING\tagSECTITLE_END	The\tagSENT_START	maximum\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	training\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	loss\tagSENT_CONTENT	:\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	minimizing\tagSENT_CONTENT	L\tagSENT_CONTENT	ml\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	always\tagSENT_CONTENT	produce\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	discrete\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ROUGE\tagmetric	)\tagSENT_CONTENT	.\tagSENT_END	POLICY\tagSECTITLE_START	LEARNING\tagSECTITLE_END	MIXED\tagSECTITLE_START	TRAINING\tagSECTITLE_CONTENT	OBJECTIVE\tagSECTITLE_CONTENT	FUNCTION\tagSECTITLE_END	One\tagSENT_START	potential\tagSENT_CONTENT	issue\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	training\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	fora\tagSENT_CONTENT	specific\tagSENT_CONTENT	discrete\tagSENT_CONTENT	metric\tagSENT_CONTENT	like\tagSENT_CONTENT	ROUGE\tagmetric	does\tagSENT_CONTENT	not\tagSENT_CONTENT	guarantee\tagSENT_CONTENT	an\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	quality\tagSENT_CONTENT	and\tagSENT_CONTENT	readability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	motivates\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	define\tagSENT_CONTENT	a\tagSENT_CONTENT	mixed\tagSENT_CONTENT	learning\tagSENT_CONTENT	objective\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	combines\tagSENT_CONTENT	summarization\tagtask	14\tagSENT_CONTENT	and\tagSENT_CONTENT	15\tagSENT_CONTENT	:\tagSENT_END	A\tagSENT_START	similar\tagSENT_CONTENT	mixed\tagSENT_CONTENT	-\tagSENT_CONTENT	objective\tagSENT_CONTENT	learning\tagSENT_CONTENT	function\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	 \tagSENT_CONTENT	for\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	on\tagSENT_CONTENT	short\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	its\tagSENT_CONTENT	first\tagSENT_CONTENT	use\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	critical\tagSENT_CONTENT	policy\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	long\tagSENT_CONTENT	summarization\tagSENT_CONTENT	to\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	improve\tagSENT_CONTENT	readability\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	NEURAL\tagSECTITLE_START	ENCODER\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	DECODER\tagSECTITLE_CONTENT	SEQUENCE\tagSECTITLE_CONTENT	MODELS\tagSECTITLE_END	Neural\tagSENT_START	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	applications\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	apply\tagSENT_CONTENT	this\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	language\tagSENT_CONTENT	tokens\tagSENT_CONTENT	to\tagSENT_CONTENT	vectors\tagmetric	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	inputs\tagSENT_CONTENT	for\tagSENT_CONTENT	these\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	REINFORCEMENT\tagSECTITLE_START	LEARNING\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	SEQUENCE\tagSECTITLE_CONTENT	GENERATION\tagSECTITLE_END	This\tagSENT_START	is\tagSENT_CONTENT	applicable\tagSENT_CONTENT	to\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	many\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	metrics\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	like\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	,\tagSENT_CONTENT	ROUGE\tagmetric	or\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	.\tagSENT_END	TEXT\tagSECTITLE_START	SUMMARIZATION\tagSECTITLE_END	summarization\tagtask	studied\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	are\tagSENT_CONTENT	extractive\tagSENT_CONTENT	in\tagSENT_CONTENT	nature\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	usually\tagSENT_CONTENT	work\tagSENT_CONTENT	by\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	phrases\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	arranging\tagSENT_CONTENT	them\tagSENT_CONTENT	into\tagSENT_CONTENT	anew\tagSENT_CONTENT	summary\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	RESULTS\tagSECTITLE_END	EXPERIMENTS\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	run\tagSENT_CONTENT	maximum\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	(\tagSENT_CONTENT	ML\tagSENT_CONTENT	)\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	and\tagSENT_CONTENT	without\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	removing\tagSENT_CONTENT	c\tagSENT_CONTENT	d\tagSENT_CONTENT	t\tagSENT_CONTENT	from\tagSENT_CONTENT	summarization\tagtask	9\tagSENT_CONTENT	and\tagSENT_CONTENT	11\tagSENT_CONTENT	to\tagSENT_CONTENT	disable\tagSENT_CONTENT	intraattention\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	performing\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	ROUGE\tagSECTITLE_START	metrics\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	options\tagSECTITLE_CONTENT	:\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	F-1\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	metrics\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	Porter\tagSENT_CONTENT	stemmer\tagSENT_CONTENT	option\tagSENT_CONTENT	.\tagSENT_END	QUANTITATIVE\tagSECTITLE_START	ANALYSIS\tagSECTITLE_END	Further\tagSENT_START	analysis\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	increases\tagSENT_CONTENT	the\tagmetric	ROUGE-1\tagmetric	score\tagmetric	of\tagSENT_CONTENT	examples\tagSENT_CONTENT	with\tagSENT_CONTENT	along\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	decreasing\tagSENT_CONTENT	the\tagmetric	score\tagmetric	of\tagSENT_CONTENT	shorter\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	confirms\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	improves\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	longer\tagSENT_CONTENT	output\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	explains\tagSENT_CONTENT	why\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	does\tagSENT_CONTENT	nt\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	NYT\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	shorter\tagSENT_CONTENT	summaries\tagSENT_CONTENT	on\tagSENT_CONTENT	average\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	RL\tagSENT_CONTENT	and\tagSENT_CONTENT	ML+RL\tagSENT_CONTENT	models\tagSENT_CONTENT	obtain\tagSENT_CONTENT	much\tagSENT_CONTENT	higher\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	ML\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	against\tagSENT_CONTENT	extractive\tagSENT_CONTENT	baselines\tagSENT_CONTENT	(\tagSENT_CONTENT	either\tagSENT_CONTENT	lead\tagSENT_CONTENT	sentences\tagSENT_CONTENT	or\tagSENT_CONTENT	lead\tagSENT_CONTENT	words\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	built\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	trained\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	smaller\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	NYT\tagSENT_CONTENT	dataset\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	6\tagSENT_CONTENT	times\tagSENT_CONTENT	smaller\tagSENT_CONTENT	than\tagSENT_CONTENT	ours\tagSENT_CONTENT	but\tagSENT_CONTENT	contains\tagSENT_CONTENT	longer\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	QUALITATIVE\tagSECTITLE_START	ANALYSIS\tagSECTITLE_END	We\tagSENT_START	perform\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	scores\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	increase\tagSENT_CONTENT	inhuman\tagSENT_CONTENT	readability\tagSENT_CONTENT	and\tagSENT_CONTENT	quality\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	article\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	summary\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	different\tagSENT_CONTENT	models\tagSENT_CONTENT	side\tagSENT_CONTENT	by\tagSENT_CONTENT	side\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluator\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	confirms\tagSENT_CONTENT	that\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	for\tagSENT_CONTENT	single\tagSENT_CONTENT	discrete\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ROUGE\tagmetric	with\tagSENT_CONTENT	RL\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	detrimental\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	quality\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	anew\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	training\tagSENT_CONTENT	procedure\tagSENT_CONTENT	that\tagSENT_CONTENT	obtains\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	,\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	readability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	suited\tagSENT_CONTENT	to\tagSENT_CONTENT	long\tagSENT_CONTENT	output\tagSENT_CONTENT	sequences\tagSENT_CONTENT	.\tagSENT_END	A.1\tagSECTITLE_START	PREPROCESSING\tagSECTITLE_END	Since\tagSENT_START	the\tagSENT_CONTENT	NYT\tagSENT_CONTENT	abstracts\tagSENT_CONTENT	almost\tagSENT_CONTENT	never\tagSENT_CONTENT	contain\tagSENT_CONTENT	periods\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	them\tagSENT_CONTENT	multisentence\tagSENT_CONTENT	summarization\tagtask	if\tagSENT_CONTENT	we\tagSENT_CONTENT	split\tagSENT_CONTENT	sentences\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	semicolons\tagSENT_CONTENT	.\tagSENT_END	A.2\tagSECTITLE_START	DATASET\tagSECTITLE_CONTENT	SPLITS\tagSECTITLE_END	We\tagSENT_START	created\tagSENT_CONTENT	our\tagSENT_CONTENT	own\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	splits\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	A.3\tagSECTITLE_START	POINTER\tagSECTITLE_CONTENT	SUPERVISION\tagSECTITLE_END	For\tagSENT_START	all\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	abstract\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	"\tagSENT_CONTENT	PERSON\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	LOCATION\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	"\tagSENT_CONTENT	or\tagSENT_CONTENT	"\tagSENT_CONTENT	MISC\tagSENT_CONTENT	"\tagSENT_END	B\tagSECTITLE_START	HYPERPARAMETERS\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	IMPLEMENTATION\tagSECTITLE_CONTENT	DETAILS\tagSECTITLE_END	
P18-1014	title\tagSECTITLE_END	summarization\tagtask	with\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	:\tagSENT_CONTENT	Sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	Words\tagSENT_CONTENT	from\tagSENT_CONTENT	Alternating\tagSENT_CONTENT	Pointer\tagSENT_CONTENT	Networks\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	anew\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	called\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	(\tagSENT_CONTENT	Sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	Words\tagSENT_CONTENT	from\tagSENT_CONTENT	Alternating\tagSENT_CONTENT	Pointer\tagSENT_CONTENT	Networks\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	shorten\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	document\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	the\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	broadly\tagSENT_CONTENT	classified\tagSENT_CONTENT	into\tagSENT_CONTENT	two\tagSENT_CONTENT	categories\tagSENT_CONTENT	:\tagSENT_CONTENT	extractive\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	.\tagSENT_END	Classical\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	have\tagSENT_CONTENT	relied\tagSENT_CONTENT	on\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	score\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	highestscoring\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	of\tagSENT_CONTENT	these\tagSENT_CONTENT	methods\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	multiple\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	Deep\tagSENT_START	models\tagSENT_CONTENT	with\tagSENT_CONTENT	thousands\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagmetric	require\tagSENT_CONTENT	large\tagSENT_CONTENT	,\tagSENT_CONTENT	labeled\tagSENT_CONTENT	datasets\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	this\tagSENT_CONTENT	hurdle\tagSENT_CONTENT	of\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	was\tagSENT_CONTENT	surmounted\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagSENT_CONTENT	creation\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	labeled\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	news\tagSENT_CONTENT	stories\tagSENT_CONTENT	from\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	around\tagSENT_CONTENT	280,000\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	design\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	anew\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Problem\tagSECTITLE_START	Formulation\tagSECTITLE_END	SWAP\tagSENT_START	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	predicts\tagSENT_CONTENT	both\tagSENT_CONTENT	key\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	salient\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	subsequently\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Background\tagSECTITLE_END	The\tagSENT_START	softmax\tagSENT_CONTENT	normalizes\tagSENT_CONTENT	vector\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	to\tagSENT_CONTENT	bean\tagSENT_CONTENT	attention\tagSENT_CONTENT	mask\tagSENT_CONTENT	over\tagSENT_CONTENT	inputs\tagSENT_CONTENT	.\tagSENT_END	SWAP\tagSECTITLE_START	-\tagSECTITLE_CONTENT	NET\tagSECTITLE_END	A\tagSENT_START	switch\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	either\tagmetric	a\tagmetric	word\tagmetric	or\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	decoding\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	Encoder\tagSECTITLE_END	The\tagmetric	word\tagmetric	embedding\tagSENT_CONTENT	xi\tagSENT_CONTENT	is\tagSENT_CONTENT	encoded\tagSENT_CONTENT	as\tagSENT_CONTENT	e\tagSENT_END	Decoder\tagSECTITLE_END	Network\tagSECTITLE_START	Details\tagSECTITLE_END	=\tagSENT_START	1\tagSENT_CONTENT	to\tagSENT_CONTENT	denote\tagmetric	word\tagmetric	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	probabilities\tagSENT_CONTENT	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	vectors\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagmetric	word\tagmetric	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	levels\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	switch\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	:\tagSENT_END	Parameters\tagmetric	v\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_END	Summary\tagSECTITLE_START	Generation\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Traditional\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	term\tagSENT_CONTENT	frequency\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	level\tagSENT_CONTENT	decoder\tagSENT_CONTENT	predicts\tagSENT_CONTENT	salient\tagSENT_CONTENT	sentences\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summary\tagSENT_CONTENT	and\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	output\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	step\tagSENT_CONTENT	predicts\tagSENT_CONTENT	keywords\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	method\tagSENT_CONTENT	developed\tagSENT_CONTENT	by\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	architecture\tagSENT_CONTENT	but\tagSENT_CONTENT	only\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	aim\tagSENT_CONTENT	of\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summary\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	sentence\tagmetric	-\tagmetric	word\tagmetric	,\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	studied\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	symbols\tagSENT_CONTENT	<\tagSENT_CONTENT	GO\tagSENT_CONTENT	>\tagSENT_CONTENT	and\tagSENT_CONTENT	<\tagSENT_CONTENT	EOS\tagSENT_CONTENT	>\tagSENT_CONTENT	to\tagSENT_CONTENT	indicate\tagSENT_CONTENT	start\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	decoders\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	speedup\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	the\tagmetric	Baselines\tagSECTITLE_END	Two\tagSENT_START	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	NN\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	summarizer\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	Benchmark\tagSECTITLE_START	Datasets\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Metrics\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	toolkit\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	in\tagSENT_CONTENT	comparison\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Benchmark\tagSECTITLE_END	Discussion\tagSECTITLE_END	Statistics\tagSECTITLE_END	the\tagSENT_START	@entity1\tagSENT_CONTENT	@entity21\tagSENT_CONTENT	denied\tagSENT_CONTENT	his\tagSENT_CONTENT	request\tagSENT_CONTENT	,\tagSENT_CONTENT	citing\tagSENT_CONTENT	summarization\tagtask	prohibiting\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	0\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	indecent\tagSENT_CONTENT	connotations\tagSENT_CONTENT	.\tagSENT_END	Sample\tagSENT_START	gold\tagSENT_CONTENT	summary\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	and\tagSENT_CONTENT	Lead-3\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	Lead-3\tagSENT_CONTENT	has\tagSENT_CONTENT	only\tagSENT_CONTENT	about\tagSENT_CONTENT	62\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Gold\tagSENT_START	summary\tagSENT_CONTENT	Lead-3\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	0.81\tagSENT_CONTENT	0.553\tagSENT_CONTENT	0.8\tagSENT_CONTENT	:\tagSENT_CONTENT	Average\tagSENT_CONTENT	pairwise\tagSENT_CONTENT	cosine\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	vector\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	shows\tagSENT_START	the\tagSENT_CONTENT	average\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	from\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	and\tagSENT_CONTENT	Lead-3\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	a\tagSENT_CONTENT	sample\tagSENT_CONTENT	gold\tagSENT_CONTENT	summary\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summary\tagSENT_CONTENT	from\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	from\tagSENT_CONTENT	Lead-3\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	SWAP\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	tosequence\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summarizers\tagSENT_CONTENT	SummaRuNNer\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	
D15-1044	title\tagSECTITLE_END	A\tagSENT_START	Neural\tagSENT_CONTENT	Attention\tagSENT_CONTENT	Model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	summarization\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	text\tagSENT_CONTENT	extraction\tagSENT_CONTENT	is\tagSENT_CONTENT	inherently\tagSENT_CONTENT	limited\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	generation\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	ab\tagSENT_CONTENT	-\tagSENT_CONTENT	stractive\tagSENT_CONTENT	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	proven\tagSENT_CONTENT	challenging\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	challenge\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Crucially\tagSENT_START	both\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	jointly\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	This\tagSENT_START	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	call\tagSENT_CONTENT	Attention\tagSENT_CONTENT	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Summarization\tagSENT_CONTENT	(\tagSENT_CONTENT	ABS\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	incorporates\tagSENT_CONTENT	less\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	structure\tagSENT_CONTENT	than\tagSENT_CONTENT	comparable\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	can\tagSENT_CONTENT	easily\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	generated\tagSENT_CONTENT	is\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	it\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	generalize\tagSENT_CONTENT	(\tagSENT_CONTENT	russian\tagSENT_CONTENT	defense\tagSENT_CONTENT	minister\tagSENT_CONTENT	to\tagSENT_CONTENT	russia\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	paraphrase\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	combating\tagSENT_CONTENT	to\tagSENT_CONTENT	against\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	compressing\tagSENT_CONTENT	(\tagSENT_CONTENT	dropping\tagSENT_CONTENT	the\tagSENT_CONTENT	creation\tagSENT_CONTENT	of\tagSENT_CONTENT	)\tagSENT_END	Since\tagSENT_START	our\tagSENT_CONTENT	system\tagSENT_CONTENT	makes\tagSENT_CONTENT	summarization\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summary\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	directly\tagSENT_CONTENT	on\tagSENT_CONTENT	any\tagSENT_CONTENT	document\tagSENT_CONTENT	-\tagSENT_CONTENT	summary\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	We\tagSENT_START	begin\tagSENT_CONTENT	by\tagSENT_CONTENT	defining\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	summarization\tagtask	takes\tagSENT_CONTENT	x\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	outputs\tagSENT_CONTENT	a\tagSENT_CONTENT	shortened\tagSENT_CONTENT	sentence\tagSENT_CONTENT	y\tagSENT_CONTENT	of\tagSENT_CONTENT	length\tagSENT_CONTENT	N\tagSENT_END	While\tagSENT_START	summarization\tagtask	poses\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	difficult\tagSENT_CONTENT	generation\tagSENT_CONTENT	challenge\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	lack\tagSENT_CONTENT	of\tagSENT_CONTENT	hard\tagSENT_CONTENT	constraints\tagSENT_CONTENT	gives\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	more\tagSENT_CONTENT	freedom\tagSENT_CONTENT	in\tagSENT_CONTENT	generation\tagSENT_CONTENT	and\tagSENT_CONTENT	allows\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	fit\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	conditional\tagSENT_CONTENT	logprobability\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	given\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	,\tagSENT_CONTENT	s(x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	The\tagSENT_START	next\tagSENT_CONTENT	section\tagSENT_CONTENT	defines\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	this\tagSENT_CONTENT	distribution\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	return\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	of\tagSENT_CONTENT	generation\tagSENT_CONTENT	for\tagSENT_CONTENT	factored\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	5\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	modified\tagSENT_CONTENT	factored\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	The\tagSENT_START	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	interest\tagSENT_CONTENT	,\tagSENT_CONTENT	p(y\tagSENT_CONTENT	i+1\tagSENT_CONTENT	|x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	c\tagSENT_CONTENT	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	conditional\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	x.\tagSENT_CONTENT	Past\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	compression\tagSENT_CONTENT	has\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	noisy\tagSENT_CONTENT	-\tagSENT_CONTENT	channel\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	split\tagSENT_CONTENT	and\tagSENT_CONTENT	independently\tagSENT_CONTENT	estimate\tagSENT_CONTENT	a\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	conditional\tagSENT_CONTENT	summarization\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	arg\tagSENT_CONTENT	max\tagSENT_CONTENT	y\tagSENT_CONTENT	log\tagSENT_END	Neural\tagSECTITLE_START	Language\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	The\tagSENT_START	core\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	estimating\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	Encoders\tagSECTITLE_END	By\tagSENT_START	incorporating\tagSENT_CONTENT	in\tagSENT_CONTENT	enc\tagSENT_CONTENT	and\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	elements\tagSENT_CONTENT	jointly\tagSENT_CONTENT	we\tagSENT_CONTENT	crucially\tagSENT_CONTENT	can\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	text\tagSENT_CONTENT	into\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	For\tagSENT_START	summarization\tagtask	this\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	distinguish\tagSENT_CONTENT	content\tagSENT_CONTENT	words\tagSENT_CONTENT	from\tagSENT_CONTENT	stop\tagSENT_CONTENT	words\tagSENT_CONTENT	or\tagSENT_CONTENT	embellishments\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	an\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	distribution\tagSENT_CONTENT	p\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	generated\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_END	Once\tagSENT_START	we\tagSENT_CONTENT	have\tagSENT_CONTENT	defined\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	conditional\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	p(y\tagSENT_CONTENT	i+1\tagSENT_CONTENT	|x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	c\tagSENT_CONTENT	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	estimate\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	to\tagSENT_CONTENT	minimize\tagSENT_CONTENT	the\tagSENT_CONTENT	negative\tagSENT_CONTENT	loglikelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Generating\tagSECTITLE_START	Summaries\tagSECTITLE_END	Recall\tagSENT_START	from\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	4\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagmetric	goal\tagmetric	is\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	,\tagSENT_END	Extension\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Extractive\tagSECTITLE_CONTENT	Tuning\tagSECTITLE_END	We\tagSENT_START	do\tagSENT_CONTENT	this\tagSENT_CONTENT	by\tagSENT_CONTENT	modifying\tagSENT_CONTENT	our\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	estimate\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	is\tagSENT_CONTENT	standard\tagSENT_CONTENT	in\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	:\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	traditionally\tagSENT_CONTENT	connected\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	headline\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	They\tagSENT_START	extract\tagSENT_CONTENT	tree\tagSENT_CONTENT	transduction\tagSENT_CONTENT	rules\tagSENT_CONTENT	from\tagSENT_CONTENT	aligned\tagSENT_CONTENT	,\tagSENT_CONTENT	parsed\tagSENT_CONTENT	texts\tagSENT_CONTENT	and\tagSENT_CONTENT	learn\tagSENT_CONTENT	weights\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	margin\tagSENT_CONTENT	learning\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	there\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	some\tagSENT_CONTENT	work\tagSENT_CONTENT	using\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	directly\tagSENT_CONTENT	for\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	of\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	utilize\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Data\tagSECTITLE_START	Set\tagSECTITLE_END	This\tagSENT_START	data\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	summarization\tagtask	-\tagSENT_CONTENT	only\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	the\tagSENT_CONTENT	similarly\tagSENT_CONTENT	sized\tagSENT_CONTENT	DUC-2003\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	was\tagSENT_CONTENT	made\tagSENT_CONTENT	available\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	BLEU\tagSENT_CONTENT	which\tagSENT_CONTENT	interpolates\tagSENT_CONTENT	various\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	matches\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	several\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	ROUGE\tagmetric	for\tagSENT_CONTENT	different\tagSENT_CONTENT	match\tagSENT_CONTENT	lengths\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	DUC-2014\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	on\tagSENT_CONTENT	single\tagSENT_CONTENT	reference\tagSENT_CONTENT	headline\tagSENT_CONTENT	-\tagSENT_CONTENT	generation\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	randomly\tagSENT_CONTENT	heldout\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	only\tagSENT_CONTENT	uses\tagSENT_CONTENT	annotations\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	separation\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	several\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	baselines\tagSENT_CONTENT	use\tagSENT_CONTENT	parsing\tagSENT_CONTENT	and\tagSENT_CONTENT	tagging\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	model\tagSENT_CONTENT	could\tagSENT_CONTENT	in\tagSENT_CONTENT	theory\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	any\tagSENT_CONTENT	pair\tagSENT_CONTENT	,\tagSENT_CONTENT	Gigaword\tagdataset	contains\tagSENT_CONTENT	many\tagSENT_CONTENT	spurious\tagSENT_CONTENT	headline\tagSENT_CONTENT	-\tagSENT_CONTENT	article\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Baselines\tagSECTITLE_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	abroad\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	headline\tagSENT_CONTENT	-\tagSENT_CONTENT	generation\tagSENT_CONTENT	baselines\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	DUC\tagSENT_CONTENT	task\tagSENT_CONTENT	also\tagSENT_CONTENT	includes\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	manual\tagSENT_CONTENT	summaries\tagSENT_CONTENT	performed\tagSENT_CONTENT	by\tagSENT_CONTENT	8\tagSENT_CONTENT	human\tagSENT_CONTENT	summarizers\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	sentences\tagSENT_CONTENT	(\tagSENT_CONTENT	yielding\tagSENT_CONTENT	4\tagSENT_CONTENT	references\tagSENT_CONTENT	per\tagSENT_CONTENT	sentence\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	system\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	Gigaword\tagdataset	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	summaries\tagSENT_CONTENT	,\tagSENT_CONTENT	MOSES+\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_END	summarization\tagtask	uses\tagSENT_CONTENT	the\tagSENT_CONTENT	Torch\tagSENT_CONTENT	numerical\tagSENT_CONTENT	framework\tagSENT_CONTENT	(\tagSENT_CONTENT	http://torch.ch/\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	openly\tagSENT_CONTENT	available\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	pipeline\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	The\tagSENT_START	PREFIX\tagSENT_CONTENT	baseline\tagSENT_CONTENT	actually\tagSENT_CONTENT	performs\tagSENT_CONTENT	surprisingly\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	ROUGE-1\tagmetric	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	sense\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	earlier\tagSENT_CONTENT	observed\tagSENT_CONTENT	overlap\tagSENT_CONTENT	between\tagSENT_CONTENT	article\tagSENT_CONTENT	and\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	ABS\tagSENT_CONTENT	and\tagSENT_CONTENT	MOSES+\tagSENT_CONTENT	perform\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	TOPIARY\tagSENT_CONTENT	,\tagSENT_CONTENT	particularly\tagSENT_CONTENT	on\tagSENT_CONTENT	ROUGE-2\tagmetric	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	in\tagSENT_CONTENT	DUC\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	structure\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	recent\tagSENT_CONTENT	developments\tagSENT_CONTENT	in\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	.\tagSENT_END	
1711.03953	title\tagSECTITLE_END	language_modeling\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	formulate\tagSENT_CONTENT	language_modeling\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	factorization\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	expressiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	the\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	neu\tagSENT_CONTENT	-\tagSENT_CONTENT	ral\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	limited\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	As\tagSENT_START	a\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	statistical\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	has\tagSENT_CONTENT	gone\tagSENT_CONTENT	through\tagSENT_CONTENT	significant\tagSENT_CONTENT	development\tagSENT_CONTENT	from\tagSENT_CONTENT	traditional\tagSENT_CONTENT	Ngram\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	neural\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	decade\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	further\tagSENT_CONTENT	implies\tagSENT_CONTENT	that\tagSENT_CONTENT	language_modeling\tagtask	with\tagSENT_CONTENT	distributed\tagSENT_CONTENT	(\tagSENT_CONTENT	output\tagSENT_CONTENT	)\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	enough\tagSENT_CONTENT	capacity\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	discrete\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	into\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	formulate\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	-\tagSENT_CONTENT	token\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	Mixture\tagSENT_CONTENT	of\tagSENT_CONTENT	Softmaxes\tagSENT_CONTENT	(\tagSENT_CONTENT	MoS\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Let\tagSENT_START	{\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	M\tagSENT_CONTENT	}\tagSENT_CONTENT	denote\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	M\tagSENT_CONTENT	possible\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	In\tagSENT_START	other\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	asking\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	question\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	does\tagSENT_CONTENT	there\tagSENT_CONTENT	exist\tagSENT_END	SOFTMAX\tagSECTITLE_END	The\tagmetric	majority\tagmetric	of\tagSENT_CONTENT	parametric\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	function\tagSENT_CONTENT	operating\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	)\tagSENT_END	Property\tagmetric	1\tagSENT_CONTENT	.\tagSENT_END	Property\tagmetric	2\tagSENT_CONTENT	.\tagSENT_END	Based\tagSENT_START	on\tagSENT_CONTENT	the\tagmetric	Property\tagmetric	1\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagSENT_CONTENT	(\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	immediately\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	Lemma\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	want\tagSENT_CONTENT	language_modeling\tagtask	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	matrices\tagSENT_CONTENT	H\tagSENT_CONTENT	θ\tagSENT_CONTENT	and\tagSENT_CONTENT	W\tagSENT_CONTENT	θ\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	factorize\tagSENT_CONTENT	some\tagSENT_CONTENT	matrix\tagSENT_CONTENT	A\tagSENT_CONTENT	∈\tagSENT_CONTENT	F\tagSENT_CONTENT	(\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Combining\tagSENT_START	Proposition\tagSENT_CONTENT	1\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagmetric	Property\tagmetric	2\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagSENT_CONTENT	(\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	now\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	state\tagSENT_CONTENT	the\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	Bottleneck\tagSENT_CONTENT	problem\tagSENT_CONTENT	formally\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	above\tagSENT_CONTENT	corollary\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	dimension\tagSENT_CONTENT	dis\tagSENT_CONTENT	too\tagSENT_CONTENT	small\tagSENT_CONTENT	,\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagmetric	capacity\tagmetric	to\tagSENT_CONTENT	express\tagSENT_CONTENT	the\tagSENT_CONTENT	true\tagSENT_CONTENT	data\tagSENT_CONTENT	distribution\tagSENT_CONTENT	.\tagSENT_END	HYPOTHESIS\tagSECTITLE_START	:\tagSECTITLE_CONTENT	NATURAL\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	IS\tagSECTITLE_CONTENT	HIGH\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	RANK\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	"\tagSENT_CONTENT	north\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	"\tagSENT_CONTENT	korea\tagSENT_CONTENT	"\tagSENT_CONTENT	or\tagSENT_CONTENT	"\tagSENT_CONTENT	korean\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	news\tagSENT_CONTENT	article\tagSENT_CONTENT	on\tagSENT_CONTENT	international\tagmetric	politics\tagmetric	,\tagSENT_CONTENT	which\tagSENT_CONTENT	however\tagSENT_CONTENT	is\tagSENT_CONTENT	unlikely\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	textbook\tagSENT_CONTENT	on\tagSENT_CONTENT	U.S.\tagSENT_CONTENT	domestic\tagSENT_CONTENT	history\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	semantic\tagSENT_CONTENT	meanings\tagSENT_CONTENT	might\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	those\tagSENT_CONTENT	bases\tagSENT_CONTENT	since\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	hundred\tagSENT_CONTENT	meanings\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	enough\tagSENT_CONTENT	to\tagSENT_CONTENT	cover\tagSENT_CONTENT	everyday\tagSENT_CONTENT	meanings\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	to\tagSENT_CONTENT	mention\tagSENT_CONTENT	language_modeling\tagtask	in\tagSENT_CONTENT	specialized\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	provide\tagSENT_CONTENT	evidences\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.3\tagSENT_CONTENT	to\tagSENT_CONTENT	support\tagSENT_CONTENT	our\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	learning\tagSENT_CONTENT	language_modeling\tagtask	is\tagSENT_CONTENT	important\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	the\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	is\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	rank\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	clear\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	limits\tagSENT_CONTENT	the\tagSENT_CONTENT	expressiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	EASY\tagSECTITLE_START	FIXES\tagSECTITLE_CONTENT	?\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	considered\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	lot\tagSENT_CONTENT	of\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	can\tagSENT_CONTENT	employ\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	an\tagSENT_CONTENT	Ngram\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Increasing\tagSENT_START	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	model\tagmetric	parameters\tagmetric	easily\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	.\tagSENT_END	Clearly\tagSENT_START	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	tradeoff\tagSENT_CONTENT	between\tagSENT_CONTENT	expressiveness\tagSENT_CONTENT	and\tagSENT_CONTENT	generalization\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	MIXTURE\tagSECTITLE_START	OF\tagSECTITLE_CONTENT	SOFTMAXES\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	HIGH\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	RANK\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	language_modeling\tagtask	called\tagSENT_CONTENT	Mixture\tagSENT_CONTENT	of\tagSENT_CONTENT	Softmaxes\tagSENT_CONTENT	(\tagSENT_CONTENT	MoS\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	the\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	issue\tagSENT_CONTENT	.\tagSENT_END	Similar\tagSENT_START	to\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	where\tagSENT_START	w\tagSENT_CONTENT	π\tagSENT_CONTENT	,\tagSENT_CONTENT	k\tagSENT_CONTENT	and\tagSENT_CONTENT	W\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	k\tagSENT_CONTENT	are\tagSENT_CONTENT	model\tagmetric	parameters\tagmetric	.\tagSENT_END	language_modeling\tagtask	and\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	Softmax\tagSENT_END	MIXTURE\tagSECTITLE_START	OF\tagSECTITLE_CONTENT	CONTEXTS\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	LOW\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	RANK\tagSECTITLE_CONTENT	BASELINE\tagSECTITLE_END	EXPERIMENTS\tagSECTITLE_END	MAIN\tagSECTITLE_START	RESULTS\tagSECTITLE_END	Following\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	MoS\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	(\tagSENT_CONTENT	PTB\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	WikiText-2\tagSENT_CONTENT	(\tagSENT_CONTENT	WT2\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	investigate\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	MoS\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	extended\tagSENT_CONTENT	to\tagSENT_CONTENT	even\tagSENT_CONTENT	larger\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	1B\tagSENT_CONTENT	Word\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	evaluation\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	precision\tagSENT_CONTENT	/\tagSENT_CONTENT	recall\tagSENT_CONTENT	of\tagSENT_CONTENT	Smoothed\tagSENT_CONTENT	Sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	suggested\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	language_modeling\tagtask	on\tagSENT_CONTENT	PTB\tagSENT_CONTENT	and\tagSENT_CONTENT	WT2\tagSENT_CONTENT	are\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	  \tagSENT_END	ABLATION\tagSECTITLE_START	STUDY\tagSECTITLE_END	To\tagSENT_START	further\tagSENT_CONTENT	verify\tagSENT_CONTENT	the\tagSENT_CONTENT	improvement\tagSENT_CONTENT	shown\tagSENT_CONTENT	above\tagSENT_CONTENT	does\tagSENT_CONTENT	come\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	MoS\tagSENT_CONTENT	structure\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	adding\tagSENT_CONTENT	another\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	or\tagSENT_CONTENT	finding\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	an\tagmetric	ablation\tagmetric	study\tagmetric	on\tagSENT_CONTENT	both\tagSENT_CONTENT	PTB\tagSENT_CONTENT	and\tagSENT_CONTENT	WT2\tagSENT_CONTENT	.\tagSENT_END	VERIFY\tagSECTITLE_START	THE\tagSECTITLE_CONTENT	ROLE\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	RANK\tagSECTITLE_END	While\tagSENT_START	the\tagSENT_CONTENT	study\tagSENT_CONTENT	above\tagSENT_CONTENT	verifies\tagSENT_CONTENT	that\tagSENT_CONTENT	MoS\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	to\tagSENT_CONTENT	achieving\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	not\tagSENT_CONTENT	clear\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagmetric	superiority\tagmetric	of\tagSENT_CONTENT	MoS\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	its\tagSENT_CONTENT	potential\tagSENT_CONTENT	high\tagSENT_CONTENT	rank\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	suggested\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	theoretical\tagSENT_CONTENT	analysis\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagmetric	validation\tagmetric	or\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	PTB\tagSENT_CONTENT	with\tagSENT_CONTENT	tokens\tagSENT_END	Then\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	stack\tagSENT_CONTENT	all\tagSENT_CONTENT	T\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	probability\tagSENT_CONTENT	vectors\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	T\tagSENT_CONTENT	×\tagSENT_CONTENT	M\tagSENT_CONTENT	matrix\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	inˆA\tagSENT_CONTENT	inˆ\tagSENT_CONTENT	inˆA\tagSENT_CONTENT	MoS\tagSENT_CONTENT	,\tagSENT_CONTENT	ˆ\tagSENT_END	Model\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	MoS\tagSENT_CONTENT	and\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	achieve\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	generalization\tagSENT_CONTENT	gap\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	gap\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagmetric	test\tagmetric	set\tagmetric	and\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Empirically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	rank\tagSENT_CONTENT	limitation\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	using\tagSENT_CONTENT	MoS\tagSENT_CONTENT	will\tagSENT_CONTENT	not\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	ADDITIONAL\tagSECTITLE_START	ANALYSIS\tagSECTITLE_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	In\tagSENT_START	language_modeling\tagtask	,\tagSENT_CONTENT	have\tagSENT_CONTENT	previously\tagSENT_CONTENT	considered\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	rank\tagSENT_CONTENT	perspective\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	several\tagSENT_CONTENT	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	have\tagSENT_CONTENT	tried\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	into\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	CONCLUSIONS\tagSECTITLE_END	Under\tagSENT_START	the\tagSENT_CONTENT	matrix\tagSENT_CONTENT	factorization\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	expressiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	is\tagSENT_CONTENT	limited\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	termed\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	PROOFS\tagSECTITLE_END	Proof\tagSENT_START	of\tagSENT_CONTENT	Property\tagmetric	1\tagSENT_END	Proof\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Property\tagSECTITLE_CONTENT	2\tagSECTITLE_END	B\tagSECTITLE_START	EXPERIMENT\tagSECTITLE_CONTENT	SETTING\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	HYPER\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	PARAMETERS\tagSECTITLE_END	B.1\tagSECTITLE_START	PTB\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	WT2\tagSECTITLE_END	The\tagmetric	hyper\tagmetric	-\tagmetric	parameters\tagmetric	used\tagSENT_CONTENT	for\tagSENT_CONTENT	MoS\tagSENT_CONTENT	in\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	experiment\tagSENT_CONTENT	is\tagSENT_CONTENT	summarized\tagSENT_CONTENT	below\tagSENT_CONTENT	.\tagSENT_END	Practically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	sample\tagSENT_CONTENT	c\tagSENT_CONTENT	,\tagSENT_CONTENT	c\tagSENT_CONTENT	from\tagSENT_CONTENT	validation\tagmetric	or\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	of\tagSENT_CONTENT	PTB\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_CONTENT	the\tagSENT_CONTENT	empirical\tagSENT_CONTENT	estimations\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	half\tagSENT_CONTENT	of\tagSENT_CONTENT	:\tagSENT_CONTENT	BPC\tagSENT_CONTENT	comparison\tagSENT_CONTENT	on\tagSENT_CONTENT	text8\tagSENT_CONTENT	.\tagSENT_END	Notice\tagSENT_START	that\tagSENT_CONTENT	language_modeling\tagtask	(\tagSENT_CONTENT	CharLM\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	exactly\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	rank\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	matrix\tagSENT_CONTENT	is\tagSENT_CONTENT	upper\tagSENT_CONTENT	bounded\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	CharLM\tagSENT_CONTENT	usually\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	limited\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	(\tagSENT_CONTENT	tens\tagSENT_CONTENT	of\tagSENT_CONTENT	characters\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	follow\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	90\tagSENT_CONTENT	M\tagSENT_CONTENT	characters\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	for\tagSENT_CONTENT	validation\tagmetric	and\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	C.3\tagSECTITLE_START	MOS\tagSECTITLE_CONTENT	COMPUTATIONAL\tagSECTITLE_CONTENT	TIME\tagSECTITLE_END	"\tagSENT_START	best-1\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	best-3\tagSENT_CONTENT	"\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	settings\tagSENT_CONTENT	where\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	and\tagSENT_CONTENT	MoS\tagSENT_CONTENT	obtain\tagSENT_CONTENT	their\tagmetric	own\tagmetric	best\tagmetric	perplexity\tagmetric	,\tagSENT_CONTENT	with\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	3\tagSENT_CONTENT	GPUs\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	second\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	methods\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	settings\tagSENT_CONTENT	that\tagSENT_CONTENT	achieve\tagSENT_CONTENT	the\tagmetric	best\tagmetric	performance\tagmetric	for\tagSENT_CONTENT	each\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	settings\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	best-1\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	best-3\tagSENT_CONTENT	"\tagSENT_CONTENT	settings\tagSENT_CONTENT	well\tagSENT_CONTENT	reflect\tagSENT_CONTENT	the\tagSENT_CONTENT	actual\tagSENT_CONTENT	computational\tagSENT_CONTENT	cost\tagSENT_CONTENT	brought\tagSENT_CONTENT	by\tagSENT_CONTENT	MoS\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	C.4\tagSECTITLE_START	QUALITATIVE\tagSECTITLE_CONTENT	ANALYSIS\tagSECTITLE_END	Comparing\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	two\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	preceding\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	N\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	MoS\tagSENT_CONTENT	flexibly\tagSENT_CONTENT	adjusts\tagSENT_CONTENT	its\tagmetric	top\tagmetric	predictions\tagmetric	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	topic\tagSENT_CONTENT	quantities\tagSENT_CONTENT	being\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	3rd\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	is\tagSENT_CONTENT	about\tagSENT_CONTENT	international\tagmetric	politics\tagmetric	,\tagSENT_CONTENT	where\tagSENT_CONTENT	country\tagSENT_CONTENT	/\tagSENT_CONTENT	region\tagSENT_CONTENT	names\tagSENT_CONTENT	are\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	appear\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	5th\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagmetric	6th\tagmetric	example\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	MoS\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	exploit\tagSENT_CONTENT	less\tagSENT_CONTENT	common\tagSENT_CONTENT	words\tagSENT_CONTENT	accurately\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	MoC\tagSENT_CONTENT	fails\tagSENT_CONTENT	to\tagSENT_CONTENT	yield\tagSENT_CONTENT	such\tagSENT_CONTENT	choices\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	continued\tagSENT_CONTENT	banning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	anc\tagSENT_CONTENT	and\tagSENT_CONTENT	enforcement\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	emergency\tagSENT_CONTENT	<\tagSENT_CONTENT	eos\tagSENT_CONTENT	>\tagSENT_CONTENT	#\tagSENT_CONTENT	4\tagSENT_CONTENT	Context\tagSENT_CONTENT	shares\tagSENT_CONTENT	of\tagSENT_CONTENT	ual\tagSENT_CONTENT	the\tagmetric	parent\tagmetric	of\tagSENT_CONTENT	united\tagSENT_CONTENT	airlines\tagSENT_CONTENT	were\tagSENT_CONTENT	extremely\tagSENT_CONTENT	active\tagSENT_CONTENT	all\tagSENT_CONTENT	day\tagSENT_CONTENT	friday\tagSENT_CONTENT	reacting\tagSENT_CONTENT	to\tagSENT_CONTENT	news\tagSENT_CONTENT	and\tagSENT_CONTENT	rumors\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	$\tagSENT_CONTENT	N\tagSENT_CONTENT	billion\tagSENT_CONTENT	buy\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	airline\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	<\tagSENT_CONTENT	unk\tagSENT_CONTENT	>\tagSENT_CONTENT	group\tagSENT_END	
C14-1220	title\tagSECTITLE_END	relationship_extraction\tagtask	via\tagSENT_CONTENT	Convolutional\tagSENT_CONTENT	Deep\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_END	abstract\tagSECTITLE_END	The\tagSENT_START	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	methods\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	are\tagSENT_CONTENT	primarily\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	performance\tagSENT_CONTENT	strongly\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	extracted\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	marked\tagSENT_CONTENT	nouns\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	nominals\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	S\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	annotated\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	nominals\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	is\tagSENT_CONTENT	considerable\tagSENT_CONTENT	interest\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	both\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	in\tagSENT_CONTENT	itself\tagSENT_CONTENT	and\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	step\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	NLP\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	most\tagSENT_CONTENT	representative\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	supervised\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	;\tagSENT_CONTENT	such\tagSENT_CONTENT	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	and\tagSENT_CONTENT	yield\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	exploit\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	DNN\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	lexical\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	feed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	marked\tagSENT_CONTENT	nouns\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	task\tagSENT_CONTENT	relationship_extraction\tagtask	"\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	considered\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	objective\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	assigning\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	thus\tagSENT_CONTENT	necessary\tagSENT_CONTENT	to\tagSENT_CONTENT	specify\tagSENT_CONTENT	which\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	to\tagSENT_CONTENT	assign\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	DNN\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	feasibility\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	without\tagSENT_CONTENT	complicated\tagSENT_CONTENT	NLP\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	specify\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	relationship_extraction\tagtask	should\tagSENT_CONTENT	be\tagSENT_CONTENT	assigned\tagSENT_CONTENT	,\tagSENT_CONTENT	position\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	distances\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	noun\tagSENT_CONTENT	pairs\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	DNN\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	position\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	critical\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	extracted\tagSENT_CONTENT	lexical\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	topics\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	.\tagSENT_END	Many\tagSENT_START	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	relation\tagSENT_CONTENT	discovery\tagSENT_CONTENT	and\tagSENT_CONTENT	supervised\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	2004\tagSENT_CONTENT	)\tagSENT_CONTENT	adopted\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	clustering\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	cluster\tagSENT_CONTENT	the\tagSENT_CONTENT	contexts\tagSENT_CONTENT	of\tagSENT_CONTENT	nominals\tagSENT_CONTENT	and\tagSENT_CONTENT	simply\tagSENT_CONTENT	selected\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	frequent\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	contexts\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	nominals\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	supervised\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	researchers\tagSENT_CONTENT	concentrate\tagSENT_CONTENT	on\tagSENT_CONTENT	extracting\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Kernel\tagSENT_START	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	natural\tagSENT_CONTENT	alternative\tagSENT_CONTENT	to\tagSENT_CONTENT	exploit\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	classification\tagSENT_CONTENT	clues\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	supervised\tagSENT_CONTENT	method\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	yields\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	present\tagSENT_START	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	that\tagSENT_CONTENT	learns\tagSENT_CONTENT	vectors\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	tree\tagSENT_CONTENT	path\tagSENT_CONTENT	that\tagSENT_CONTENT	connects\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	their\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relationship\tagSENT_CONTENT	.\tagSENT_END	also\tagSENT_START	use\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	;\tagSENT_CONTENT	their\tagSENT_CONTENT	method\tagSENT_CONTENT	allows\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	explicit\tagSENT_CONTENT	weighting\tagSENT_CONTENT	of\tagSENT_CONTENT	important\tagSENT_CONTENT	phrases\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	DNN\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	lexical\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	;\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	effectively\tagSENT_CONTENT	alleviates\tagSENT_CONTENT	the\tagSENT_CONTENT	shortcomings\tagSENT_CONTENT	of\tagSENT_CONTENT	traditional\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	describes\tagSENT_START	the\tagSENT_CONTENT	architecture\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	network\tagSENT_CONTENT	takes\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	discovers\tagSENT_CONTENT	multiple\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	higher\tagSENT_CONTENT	levels\tagSENT_CONTENT	represent\tagSENT_CONTENT	more\tagSENT_CONTENT	abstract\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	inputs\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	primarily\tagSENT_CONTENT	includes\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	three\tagSENT_CONTENT	components\tagSENT_CONTENT	:\tagSENT_CONTENT	Word\tagSENT_CONTENT	Representation\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	Output\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	confidence\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	.\tagSENT_END	Methodology\tagSECTITLE_END	The\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	Features\tagSECTITLE_START	Remark\tagSECTITLE_CONTENT	L1\tagSECTITLE_CONTENT	Noun\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	L2\tagSECTITLE_CONTENT	Noun\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	L3\tagSECTITLE_END	Word\tagSECTITLE_START	Representation\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	should\tagSENT_CONTENT	first\tagSENT_CONTENT	concentrate\tagSENT_CONTENT	on\tagSENT_CONTENT	learning\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	carry\tagSENT_CONTENT	more\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	significant\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Lexical\tagSECTITLE_START	Level\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Lexical\tagSENT_START	level\tagSENT_CONTENT	features\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	important\tagSENT_CONTENT	cues\tagSENT_CONTENT	for\tagSENT_CONTENT	deciding\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Sentence\tagSECTITLE_START	Level\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	pooled\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	offer\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	and\tagSENT_CONTENT	automatically\tagSENT_CONTENT	extract\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	the\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Word\tagSECTITLE_START	Features\tagSECTITLE_END	Position\tagSECTITLE_START	Features\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	complex\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	this\tagSENT_CONTENT	purpose\tagSENT_CONTENT	,\tagSENT_CONTENT	PF\tagSENT_CONTENT	are\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Convolution\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	marked\tagSENT_CONTENT	with\tagSENT_CONTENT	target\tagSENT_CONTENT	nouns\tagSENT_CONTENT	only\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	predicting\tagSENT_CONTENT	label\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	Level\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	Vector\tagSECTITLE_END	To\tagSENT_START	learn\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	designed\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	selected\tagSENT_CONTENT	hyperbolic\tagSENT_CONTENT	tanh\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Output\tagSECTITLE_END	To\tagSENT_START	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	confidence\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	vector\tagSENT_CONTENT	f\tagSENT_CONTENT	∈\tagSENT_END	4\tagSENT_START	×1\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	n\tagSENT_CONTENT	4\tagSENT_CONTENT	is\tagSENT_CONTENT	equal\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	This\tagSENT_START	score\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	conditional\tagSENT_CONTENT	probability\tagSENT_CONTENT	by\tagSENT_CONTENT	applying\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	see\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.6\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Backpropagation\tagSECTITLE_START	Training\tagSECTITLE_END	Given\tagSENT_START	an\tagSENT_CONTENT	input\tagSENT_CONTENT	example\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	parameter\tagSENT_CONTENT	θ\tagSENT_CONTENT	outputs\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	o\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	component\tagSENT_CONTENT	oi\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metrics\tagSECTITLE_END	There\tagSENT_START	are\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	directions\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	undirected\tagSENT_CONTENT	Other\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	pair\tagSENT_CONTENT	is\tagSENT_CONTENT	counted\tagSENT_CONTENT	as\tagSENT_CONTENT	correct\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	instances\tagSENT_CONTENT	S\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	S\tagSENT_CONTENT	2\tagSENT_CONTENT	have\tagSENT_CONTENT	relationship_extraction\tagtask	Component\tagSENT_CONTENT	-\tagSENT_CONTENT	Whole\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Whole(e\tagSENT_START	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	three\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Parameter\tagSECTITLE_START	Settings\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	experimentally\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	effects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	parameters\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	window\tagSENT_CONTENT	size\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	component\tagSENT_CONTENT	w\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Comparison\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	To\tagSENT_START	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	automatically\tagSENT_CONTENT	learned\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	select\tagSENT_CONTENT	seven\tagSENT_CONTENT	approaches\tagSENT_CONTENT	as\tagSENT_CONTENT	competitors\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	:\tagSENT_CONTENT	Classifier\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	feature\tagSENT_CONTENT	sets\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	This\tagSENT_START	improvement\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	explained\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	training\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	learned\tagSENT_CONTENT	lexical\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSECTITLE_START	Effect\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Learned\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	exploit\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	DNN\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	lexical\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	position\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	PF\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	successfully\tagSENT_CONTENT	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	specify\tagSENT_CONTENT	the\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	nominals\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	to\tagSENT_CONTENT	assign\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	
P10-4014	title\tagSECTITLE_END	A\tagSENT_START	Wide\tagSENT_CONTENT	-\tagSENT_CONTENT	Coverage\tagSENT_CONTENT	word_sense_disambiguation\tagtask	Disambiguation\tagSENT_CONTENT	System\tagSENT_CONTENT	for\tagSENT_CONTENT	Free\tagSENT_CONTENT	Text\tagSENT_END	abstract\tagSECTITLE_END	word_sense_disambiguation\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	SensE\tagSENT_CONTENT	-\tagSENT_CONTENT	val\tagSENT_CONTENT	and\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	workshops\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	sense\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	word_sense_disambiguation\tagtask	achieves\tagSENT_CONTENT	competitive\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	on\tagSENT_CONTENT	several\tagSENT_CONTENT	SensEval\tagSENT_CONTENT	/\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	English\tagSENT_CONTENT	lexical\tagSENT_CONTENT	-\tagSENT_CONTENT	sample\tagSENT_CONTENT	and\tagSENT_CONTENT	all\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Section\tagSENT_START	2\tagSENT_CONTENT	gives\tagSENT_CONTENT	word_sense_disambiguation\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	introduces\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	framework\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	details\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	implementation\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_START	Description\tagSECTITLE_END	The\tagSENT_START	sense\tagSENT_CONTENT	inventory\tagSENT_CONTENT	used\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	word_sense_disambiguation\tagtask	1.7.1\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_START	Architecture\tagSECTITLE_END	Preprocessing\tagSECTITLE_END	Feature\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Instance\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Classification\tagSECTITLE_END	The\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	Data\tagSECTITLE_CONTENT	Set\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	All\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	•\tagSENT_START	Perform\tagSENT_CONTENT	word_sense_disambiguation\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	texts\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	word\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	method\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	POS\tagSECTITLE_END	11,445\tagSENT_START	4,705\tagSENT_CONTENT	5,129\tagSENT_CONTENT	28\tagSENT_CONTENT	:\tagSENT_CONTENT	Statistics\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	types\tagSENT_CONTENT	which\tagSENT_CONTENT	have\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	The\tagSENT_START	frequencies\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	types\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	training\tagSENT_CONTENT	instances\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	1.7.1\tagSENT_CONTENT	are\tagSENT_CONTENT	listed\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	English\tagSECTITLE_START	Lexical\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Sample\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	English\tagSECTITLE_START	All\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	Conclusion\tagSECTITLE_END	word_sense_disambiguation\tagtask	on\tagSENT_CONTENT	English\tagSENT_CONTENT	lexicalsample\tagSENT_CONTENT	tasks\tagSENT_CONTENT	proves\tagSENT_CONTENT	the\tagSENT_CONTENT	strength\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	82.6\tagSECTITLE_START	%\tagSECTITLE_CONTENT	Rank\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	System\tagSECTITLE_END	
D15-1063	title\tagSECTITLE_END	abstract\tagSECTITLE_END	timex_normalisation\tagtask	shows\tagSENT_CONTENT	promising\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	particular\tagSENT_CONTENT	considering\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	neither\tagSENT_CONTENT	requires\tagSENT_CONTENT	language\tagSENT_CONTENT	skills\tagSENT_CONTENT	nor\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	tagger\tagSENT_CONTENT	for\tagSENT_CONTENT	200\tagSENT_CONTENT	+\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_START	&\tagSECTITLE_CONTENT	Related\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	timex_normalisation\tagtask	(\tagSENT_CONTENT	the\tagSENT_CONTENT	extraction\tagSENT_CONTENT	and\tagSENT_CONTENT	normalization\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal\tagSENT_CONTENT	expressions\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	crucial\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	many\tagSENT_CONTENT	applications\tagSENT_CONTENT	can\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	temporal\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	and\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	there\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	earlier\tagSENT_CONTENT	approaches\tagSENT_CONTENT	for\tagSENT_CONTENT	automatic\tagSENT_CONTENT	extensions\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal\tagSENT_CONTENT	taggers\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	languages\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	were\tagSENT_CONTENT	limited\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	languages\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	were\tagSENT_CONTENT	considered\tagSENT_CONTENT	less\tagSENT_CONTENT	successful\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	particular\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	subtask\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	address\tagSENT_CONTENT	both\tagSENT_CONTENT	subtasks\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	extraction\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	limit\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	selected\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	at\tagSENT_CONTENT	extending\tagSENT_CONTENT	HeidelTime\tagSENT_CONTENT	to\tagSENT_CONTENT	coverall\tagSENT_CONTENT	languages\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	world\tagSENT_CONTENT	.\tagSENT_END	HeidelTime\tagSECTITLE_END	Input\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Output\tagSECTITLE_CONTENT	Format\tagSECTITLE_END	timex_normalisation\tagtask	are\tagSENT_CONTENT	annotated\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	markup\tagSENT_CONTENT	language\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	TIMEX3\tagSENT_CONTENT	tags\tagSENT_CONTENT	with\tagSENT_CONTENT	normalization\tagSENT_CONTENT	attributes\tagSENT_CONTENT	,\tagSENT_CONTENT	most\tagSENT_CONTENT	importantly\tagSENT_CONTENT	type\tagSENT_CONTENT	(\tagSENT_CONTENT	date\tagSENT_CONTENT	,\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	duration\tagSENT_CONTENT	,\tagSENT_CONTENT	set\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	value\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	expressions\tagSENT_CONTENT	in\tagSENT_CONTENT	standard\tagSENT_CONTENT	format\tagSENT_CONTENT	.\tagSENT_END	Language\tagSECTITLE_START	-\tagSECTITLE_CONTENT	dependent\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	Each\tagSENT_START	language\tagSENT_CONTENT	requires\tagSENT_CONTENT	its\tagSENT_CONTENT	own\tagSENT_CONTENT	language\tagSENT_CONTENT	resources\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	patterns\tagSENT_CONTENT	,\tagSENT_CONTENT	timex_normalisation\tagtask	and\tagSENT_CONTENT	rules\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	contain\tagSENT_CONTENT	normalized\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	patterns\tagSENT_CONTENT	defined\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	pattern\tagSENT_CONTENT	files\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	value\tagSENT_CONTENT	of\tagSENT_CONTENT	"\tagSENT_CONTENT	January\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	"\tagSENT_CONTENT	01\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	"\tagSENT_CONTENT	3\tagSENT_CONTENT	"\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	normalized\tagSENT_CONTENT	to\tagSENT_CONTENT	"\tagSENT_CONTENT	03\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	case\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	four\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	(\tagSENT_CONTENT	date\tagSENT_CONTENT	,\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	duration\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	set\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	rule\tagSENT_CONTENT	file\tagSENT_CONTENT	contains\tagSENT_CONTENT	all\tagSENT_CONTENT	rules\tagSENT_CONTENT	for\tagSENT_CONTENT	respective\tagSENT_CONTENT	expressions\tagSENT_CONTENT	.\tagSENT_END	Manual\tagSECTITLE_START	Extension\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	New\tagSECTITLE_CONTENT	Language\tagSECTITLE_END	all\tagSENT_START	patterns\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	manually\tagSENT_CONTENT	translated\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_END	Automatic\tagSECTITLE_START	Extension\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	All\tagSECTITLE_CONTENT	Languages\tagSECTITLE_END	In\tagSENT_START	timex_normalisation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	the\tagSENT_CONTENT	steps\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	automatic\tagSENT_CONTENT	extension\tagSENT_CONTENT	approach\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	Linguistic\tagSECTITLE_START	Preprocessing\tagSECTITLE_END	the\tagSENT_START	only\tagSENT_CONTENT	obligatory\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	steps\tagSENT_CONTENT	are\tagSENT_CONTENT	sentence\tagSENT_CONTENT	splitting\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Language\tagSECTITLE_START	-\tagSECTITLE_CONTENT	independent\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	Some\tagSENT_START	patterns\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	are\tagSENT_CONTENT	valid\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	(\tagSENT_CONTENT	many\tagSENT_CONTENT	)\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	numbers\tagSENT_CONTENT	for\tagSENT_CONTENT	days\tagSENT_CONTENT	and\tagSENT_CONTENT	months\tagSENT_CONTENT	.\tagSENT_END	Simplified\tagSECTITLE_START	English\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	simplified\tagSENT_CONTENT	English\tagSENT_CONTENT	resources\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	HeidelTime\tagSENT_CONTENT	's\tagSENT_CONTENT	original\tagSENT_CONTENT	English\tagSENT_CONTENT	resources\tagSENT_CONTENT	amenable\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Language\tagSECTITLE_START	-\tagSECTITLE_CONTENT	independent\tagSECTITLE_CONTENT	Rules\tagSECTITLE_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	just\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	month\tagSENT_CONTENT	day\tagSENT_CONTENT	"\tagSENT_CONTENT	pattern\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	match\tagSENT_CONTENT	"\tagSENT_CONTENT	January\tagSENT_CONTENT	13\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	"\tagSENT_CONTENT	day\tagSENT_CONTENT	month\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	day\tagSENT_CONTENT	X\tagSENT_CONTENT	month\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	month\tagSENT_CONTENT	X\tagSENT_CONTENT	day\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	"\tagSENT_CONTENT	X\tagSENT_CONTENT	"\tagSENT_CONTENT	matching\tagSENT_CONTENT	any\tagSENT_CONTENT	token\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	"\tagSENT_CONTENT	13\tagSENT_CONTENT	de\tagSENT_CONTENT	enero\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	timex_normalisation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	names\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	languageindependent\tagSENT_CONTENT	and\tagSENT_CONTENT	simplified\tagSENT_CONTENT	English\tagSENT_CONTENT	pattern\tagSENT_CONTENT	and\tagSENT_CONTENT	normalization\tagSENT_CONTENT	files\tagSENT_CONTENT	.\tagSENT_END	Creating\tagSECTITLE_START	Resources\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	All\tagSECTITLE_CONTENT	Languages\tagSECTITLE_END	For\tagSENT_START	timex_normalisation\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	respective\tagSENT_CONTENT	pattern\tagSENT_CONTENT	and\tagSENT_CONTENT	normalization\tagSENT_CONTENT	files\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	language\tagSENT_CONTENT	in\tagSENT_CONTENT	Wiktionary\tagSENT_CONTENT	are\tagSENT_CONTENT	created\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Unfortunately\tagSENT_START	,\tagSENT_CONTENT	Wiktionary\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	course\tagSENT_CONTENT	not\tagSENT_CONTENT	complete\tagSENT_CONTENT	and\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	contain\tagSENT_CONTENT	timex_normalisation\tagtask	to\tagSENT_CONTENT	all\tagSENT_CONTENT	languages\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	English\tagSENT_CONTENT	patterns\tagSENT_CONTENT	.\tagSENT_END	Improving\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Finalizing\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	Evaluation\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	estimation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	for\tagSENT_CONTENT	languages\tagSENT_CONTENT	without\tagSENT_CONTENT	temporally\tagSENT_CONTENT	annotated\tagSENT_CONTENT	corpora\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	completeness\tagSENT_CONTENT	statistics\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	544\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Measures\tagSECTITLE_END	Since\tagSENT_START	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	fold\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	precision\tagSENT_CONTENT	,\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	extraction\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	relaxed\tagSENT_CONTENT	extraction\tagSENT_CONTENT	plus\tagSENT_CONTENT	value\tagSENT_CONTENT	normalization\tagSENT_CONTENT	)\tagSENT_CONTENT	value\tagSENT_CONTENT	F1\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	For\tagSENT_START	Spanish\tagSENT_CONTENT	,\tagSENT_CONTENT	German\tagSENT_CONTENT	,\tagSENT_CONTENT	French\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Portuguese\tagSENT_CONTENT	,\tagSENT_CONTENT	high\tagSENT_CONTENT	precision\tagSENT_CONTENT	,\tagSENT_CONTENT	moderate\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	are\tagSENT_CONTENT	achieved\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	recall\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	worse\tagSENT_CONTENT	than\tagSENT_CONTENT	precision\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	languages\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	extracted\tagSENT_CONTENT	expressions\tagSENT_CONTENT	works\tagSENT_CONTENT	quite\tagSENT_CONTENT	well\tagSENT_CONTENT	(\tagSENT_CONTENT	value\tagSENT_CONTENT	acc\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Completeness\tagSECTITLE_START	Statistics\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	timex_normalisation\tagtask	exist\tagSENT_CONTENT	for\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	75\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	50\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	patterns\tagSENT_CONTENT	for\tagSENT_CONTENT	34\tagSENT_CONTENT	and\tagSENT_CONTENT	83\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	even\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	languages\tagSENT_CONTENT	with\tagSENT_CONTENT	low\tagSENT_CONTENT	overall\tagSENT_CONTENT	coverage\tagSENT_CONTENT	,\tagSENT_CONTENT	important\tagSENT_CONTENT	patterns\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	month\tagSENT_CONTENT	names\tagSENT_CONTENT	and\tagSENT_CONTENT	date\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	covered\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Ongoing\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	Currently\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	improving\tagSENT_CONTENT	the\tagSENT_CONTENT	simplified\tagSENT_CONTENT	English\tagSENT_CONTENT	resources\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	by\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	further\tagSENT_CONTENT	resources\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	
S18-1012	title\tagSECTITLE_END	abstract\tagSECTITLE_END	timex_normalisation\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	challenging\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	Chrono\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	system\tagSENT_CONTENT	that\tagSENT_CONTENT	identifies\tagSENT_CONTENT	timex_normalisation\tagtask	in\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	normalizes\tagSENT_CONTENT	them\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	.\tagSENT_END	Parsing\tagSENT_START	timex_normalisation\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Understanding\tagSENT_START	and\tagSENT_CONTENT	processing\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	vital\tagSENT_CONTENT	for\tagSENT_CONTENT	navigating\tagSENT_CONTENT	life\tagSENT_CONTENT	.\tagSENT_END	Identifying\tagSENT_START	,\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	timex_normalisation\tagtask	requires\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	and\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	syntax\tagSENT_CONTENT	,\tagSENT_CONTENT	semantics\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	context\tagSENT_CONTENT	to\tagSENT_CONTENT	link\tagSENT_CONTENT	timex_normalisation\tagtask	to\tagSENT_CONTENT	related\tagSENT_CONTENT	events\tagSENT_CONTENT	and\tagSENT_CONTENT	order\tagSENT_CONTENT	them\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	line\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	standard\tagSENT_START	by\tagSENT_CONTENT	representing\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	allowing\tagSENT_CONTENT	for\tagSENT_CONTENT	events\tagSENT_CONTENT	to\tagSENT_CONTENT	act\tagSENT_CONTENT	as\tagSENT_CONTENT	anchors\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	using\tagSENT_CONTENT	mathematical\tagSENT_CONTENT	operations\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	timeline\tagSENT_CONTENT	to\tagSENT_CONTENT	define\tagSENT_CONTENT	the\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	(\tagSENT_START	ML\tagSENT_CONTENT	)\tagSENT_CONTENT	Python\tagSENT_CONTENT	package\tagSENT_CONTENT	that\tagSENT_CONTENT	normalizes\tagSENT_CONTENT	timex_normalisation\tagtask	into\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	.\tagSENT_END	https://github.com/AmyOlex/Chrono\tagSECTITLE_END	The\tagSECTITLE_START	Chrono\tagSECTITLE_CONTENT	System\tagSECTITLE_END	Our\tagSENT_START	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	building\tagSENT_CONTENT	this\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	system\tagSENT_CONTENT	includes\tagSENT_CONTENT	four\tagSENT_CONTENT	processing\tagSENT_CONTENT	phases\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	text\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	flagging\tagSENT_CONTENT	numeric\tagSENT_CONTENT	and\tagSENT_CONTENT	temporal\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	temporal\tagSENT_CONTENT	expression\tagSENT_CONTENT	identification\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	2\tagSENT_START	)\tagSENT_CONTENT	Flagging\tagSENT_CONTENT	Numeric\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	timex_normalisation\tagtask	of\tagSENT_CONTENT	numeric\tagSENT_CONTENT	expressions\tagSENT_CONTENT	are\tagSENT_CONTENT	converted\tagSENT_CONTENT	to\tagSENT_CONTENT	numerics\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	Word2Number\tagSENT_CONTENT	2\tagSENT_CONTENT	Python\tagSENT_CONTENT	module\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	is\tagSENT_CONTENT	done\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	parsing\tagSENT_CONTENT	textual\tagSENT_CONTENT	numerics\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	are\tagSENT_CONTENT	flagged\tagSENT_CONTENT	through\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsing\tagSENT_CONTENT	using\tagSENT_CONTENT	lists\tagSENT_CONTENT	of\tagSENT_CONTENT	key\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	regular\tagSENT_CONTENT	expressions\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	phase\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	liberal\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	timex_normalisation\tagtask	than\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	so\tagSENT_CONTENT	it\tagSENT_CONTENT	identifies\tagSENT_CONTENT	a\tagSENT_CONTENT	broader\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	potential\tagSENT_CONTENT	temporal\tagSENT_CONTENT	tokens\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	refined\tagSENT_CONTENT	in\tagSENT_CONTENT	future\tagSENT_CONTENT	steps\tagSENT_CONTENT	.\tagSENT_END	4\tagSECTITLE_START	)\tagSECTITLE_CONTENT	SCATE\tagSECTITLE_CONTENT	Normalization\tagSECTITLE_CONTENT	:\tagSECTITLE_END	Parsing\tagSENT_START	strategies\tagSENT_CONTENT	differ\tagSENT_CONTENT	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	temporal\tagSENT_CONTENT	phrase\tagSENT_CONTENT	being\tagSENT_CONTENT	parsed\tagSENT_CONTENT	.\tagSENT_END	Formatted\tagSECTITLE_START	Dates\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Times\tagSECTITLE_CONTENT	:\tagSECTITLE_END	To\tagSENT_START	identify\tagSENT_CONTENT	which\tagSENT_CONTENT	format\tagSENT_CONTENT	the\tagSENT_CONTENT	date\tagSENT_CONTENT	/\tagSENT_CONTENT	time\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	Chrono\tagSENT_CONTENT	looks\tagSENT_CONTENT	fora\tagSENT_CONTENT	2-digit\tagSENT_CONTENT	or\tagSENT_CONTENT	4-digit\tagSENT_CONTENT	year\tagSENT_CONTENT	first\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	uses\tagSENT_CONTENT	that\tagSENT_CONTENT	position\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	elements\tagSENT_CONTENT	.\tagSENT_END	Another\tagSENT_START	exception\tagSENT_CONTENT	to\tagSENT_CONTENT	RP\tagSENT_CONTENT	and\tagSENT_CONTENT	LC\tagSENT_CONTENT	is\tagSENT_CONTENT	identifying\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	AM\tagSENT_CONTENT	or\tagSENT_CONTENT	PM\tagSENT_CONTENT	where\tagSENT_CONTENT	periods\tagSENT_CONTENT	are\tagSENT_CONTENT	kept\tagSENT_CONTENT	and\tagSENT_CONTENT	text\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	converted\tagSENT_CONTENT	to\tagSENT_CONTENT	lowercase\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	variations\tagSENT_CONTENT	like\tagSENT_CONTENT	"\tagSENT_CONTENT	PM\tagSENT_CONTENT	"\tagSENT_CONTENT	or\tagSENT_CONTENT	"\tagSENT_CONTENT	p.m.\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Text\tagSENT_START	Year\tagSENT_CONTENT	:\tagSENT_CONTENT	Another\tagSENT_CONTENT	special\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	parsing\tagSENT_CONTENT	timex_normalisation\tagtask	are\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	years\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	nineteen\tagSENT_CONTENT	ninety\tagSENT_CONTENT	-\tagSENT_CONTENT	seven\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	can\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	either\tagSENT_CONTENT	a\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	"\tagSENT_CONTENT	Period\tagSENT_CONTENT	"\tagSENT_CONTENT	or\tagSENT_CONTENT	"\tagSENT_CONTENT	Calendar\tagSENT_CONTENT	-\tagSENT_CONTENT	Interval\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	language\tagSENT_CONTENT	intricacies\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	define\tagSENT_CONTENT	a\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	base\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	disambiguate\tagSENT_CONTENT	these\tagSENT_CONTENT	entities\tagSENT_CONTENT	as\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	contingent\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	topic\tagSENT_CONTENT	being\tagSENT_CONTENT	discussed\tagSENT_CONTENT	where\tagSENT_CONTENT	phrasing\tagSENT_CONTENT	around\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	different\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	instance\tagSENT_CONTENT	.\tagSENT_END	Four\tagSENT_START	ML\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	in\tagSENT_CONTENT	Chrono\tagSENT_CONTENT	to\tagSENT_CONTENT	differentiate\tagSENT_CONTENT	between\tagSENT_CONTENT	"\tagSENT_CONTENT	Period\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	Calendar\tagSENT_CONTENT	-\tagSENT_CONTENT	Interval\tagSENT_CONTENT	"\tagSENT_CONTENT	entities\tagSENT_CONTENT	using\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	NLTK\tagSENT_CONTENT	with\tagSENT_CONTENT	default\tagSENT_CONTENT	parameters\tagSENT_CONTENT	to\tagSENT_CONTENT	implement\tagSENT_CONTENT	NB\tagSENT_CONTENT	and\tagSENT_CONTENT	DT\tagSENT_CONTENT	,\tagSENT_CONTENT	NN\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	three\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	implemented\tagSENT_CONTENT	using\tagSENT_CONTENT	Python\tagSENT_CONTENT	's\tagSENT_CONTENT	Keras\tagSENT_CONTENT	package\tagSENT_CONTENT	3\tagSENT_CONTENT	with\tagSENT_CONTENT	epochs\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	and\tagSENT_CONTENT	batch\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	10\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	SVM\tagSENT_CONTENT	is\tagSENT_CONTENT	implemented\tagSENT_CONTENT	using\tagSENT_CONTENT	SciKitLearn\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	C\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	0.05\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	set\tagSENT_CONTENT	to\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	mentions\tagSENT_CONTENT	are\tagSENT_CONTENT	identified\tagSENT_CONTENT	by\tagSENT_CONTENT	normalizing\tagSENT_CONTENT	with\tagSENT_CONTENT	RP\tagSENT_CONTENT	and\tagSENT_CONTENT	LC\tagSENT_CONTENT	before\tagSENT_CONTENT	searching\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	numbers\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	31\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	timex_normalisation\tagtask	is\tagSENT_CONTENT	not\tagSENT_CONTENT	always\tagSENT_CONTENT	valid\tagSENT_CONTENT	and\tagSENT_END	more\tagSENT_START	complex\tagSENT_CONTENT	,\tagSENT_CONTENT	content\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsing\tagSENT_CONTENT	maybe\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	Training\tagSENT_START	and\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	Chrono\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	the\tagSENT_CONTENT	Newswire\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	81\tagSENT_CONTENT	documents\tagSENT_CONTENT	,\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	organizers\tagSENT_CONTENT	.\tagSENT_END	Scores\tagSENT_START	for\tagSENT_CONTENT	"\tagSENT_CONTENT	100\tagSENT_CONTENT	%\tagSENT_CONTENT	Correct\tagSENT_CONTENT	Entity\tagSENT_CONTENT	"\tagSENT_CONTENT	consider\tagSENT_CONTENT	timex_normalisation\tagtask	and\tagSENT_CONTENT	all\tagSENT_CONTENT	properties\tagSENT_CONTENT	(\tagSENT_CONTENT	like\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	intervals\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	"\tagSENT_CONTENT	Correct\tagSENT_CONTENT	Span\tagSENT_CONTENT	"\tagSENT_CONTENT	only\tagSENT_CONTENT	consider\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	ChronoNN\tagSENT_START	processed\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	consisted\tagSENT_CONTENT	of\tagSENT_CONTENT	20\tagSENT_CONTENT	previously\tagSENT_CONTENT	unseen\tagSENT_CONTENT	Newswire\tagSENT_CONTENT	articles\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	received\tagSENT_CONTENT	a\tagmetric	F1\tagmetric	of\tagSENT_CONTENT	.44\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	one\tagSENT_CONTENT	downfall\tagSENT_CONTENT	of\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	new\tagSENT_CONTENT	rules\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	developed\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	new\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	
D15-1176	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	This\tagSENT_START	model\tagSENT_CONTENT	assumes\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagmetric	character\tagmetric	type\tagmetric	is\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	parameters\tagSENT_CONTENT	encode\tagSENT_CONTENT	both\tagSENT_CONTENT	idiosyncratic\tagSENT_CONTENT	lexical\tagSENT_CONTENT	and\tagSENT_CONTENT	regular\tagSENT_CONTENT	morphological\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	.\tagSENT_END	our\tagSENT_START	characterbased\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	similar\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	semantically\tagSENT_CONTENT	and\tagSENT_CONTENT	syntactically\tagSENT_CONTENT	similar\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	for\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	orthographically\tagSENT_CONTENT	distant\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	October\tagSENT_CONTENT	and\tagSENT_CONTENT	January\tagmetric	)\tagSENT_CONTENT	;\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	word\tagSENT_CONTENT	lookup\tagSENT_CONTENT	tables\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	fraction\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	;\tagSENT_CONTENT	(\tagSENT_CONTENT	iii\tagSENT_CONTENT	)\tagSENT_END	our\tagSENT_START	model\tagSENT_CONTENT	obtains\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	including\tagSENT_CONTENT	establishing\tagSENT_CONTENT	anew\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	English\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	iv\tagSENT_CONTENT	)\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvements\tagSENT_CONTENT	are\tagSENT_CONTENT	especially\tagSENT_CONTENT	dramatic\tagSENT_CONTENT	in\tagSENT_CONTENT	morphologically\tagSENT_CONTENT	rich\tagSENT_CONTENT	languages\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSENT_START	on\tagSENT_CONTENT	Language\tagSENT_CONTENT	Modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	part-of-speech_tagging\tagtask	are\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Sections\tagSENT_CONTENT	4\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Vectors\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Wordless\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Vectors\tagSECTITLE_END	Problem\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Independent\tagSECTITLE_CONTENT	Parameters\tagSECTITLE_END	Solution\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Compositional\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	C2W\tagSECTITLE_START	Model\tagSECTITLE_END	Rd\tagSENT_START	C\tagSENT_CONTENT	×|C|\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	d\tagSENT_CONTENT	C\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	character\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	set\tagSENT_CONTENT	C.\tagSENT_CONTENT	This\tagSENT_CONTENT	of\tagSENT_CONTENT	course\tagSENT_CONTENT	just\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	lookup\tagSENT_CONTENT	table\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	similarities\tagSENT_CONTENT	between\tagSENT_CONTENT	characters\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	language\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	vowels\tagSENT_CONTENT	vs.\tagSENT_CONTENT	consonants\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Lookup\tagSECTITLE_CONTENT	Table\tagSECTITLE_END	Experiments\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Language\tagSECTITLE_CONTENT	Modeling\tagSECTITLE_END	Language\tagSECTITLE_START	Model\tagSECTITLE_END	Experiments\tagSECTITLE_END	Experiments\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Part\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	speech\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_END	As\tagSENT_START	a\tagSENT_CONTENT	second\tagSENT_CONTENT	illustration\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	utility\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	turn\tagSENT_CONTENT	to\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	Bi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Experiments\tagSECTITLE_END	The\tagSENT_START	best\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	row\tagSENT_CONTENT	"\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	97.29\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	surpassing\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	lookup\tagSENT_CONTENT	table\tagSENT_CONTENT	.\tagSENT_END	POS\tagmetric	accuracy\tagmetric	results\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	PTB\tagSENT_CONTENT	using\tagSENT_CONTENT	word\tagSENT_CONTENT	representation\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSENT_START	with\tagSENT_CONTENT	Benchmarks\tagSENT_CONTENT	Most\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	systems\tagSENT_CONTENT	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	either\tagSENT_CONTENT	learning\tagSENT_CONTENT	or\tagSENT_CONTENT	handcrafting\tagSENT_CONTENT	good\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	:\tagSENT_CONTENT	POS\tagmetric	accuracies\tagmetric	on\tagSENT_CONTENT	different\tagSENT_CONTENT	languages\tagSENT_CONTENT	ditional\tagSENT_CONTENT	raw\tagSENT_CONTENT	data\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	fashion\tagSENT_CONTENT	.\tagSENT_END	Accuracies\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	reported\tagSENT_CONTENT	on\tagSENT_CONTENT	column\tagSENT_CONTENT	"\tagSENT_CONTENT	acc\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	C2W\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	conjunction\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	adding\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linearity\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	C2W\tagSENT_CONTENT	model\tagSENT_CONTENT	e\tagSENT_CONTENT	C\tagSENT_CONTENT	w\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	over\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	linear\tagSENT_CONTENT	trans-\tagSENT_CONTENT	:\tagSENT_CONTENT	POS\tagmetric	accuracy\tagmetric	result\tagSENT_CONTENT	comparison\tagSENT_CONTENT	with\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	PTB\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Conclusion\tagSECTITLE_END	On\tagSENT_START	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	using\tagSENT_CONTENT	characters\tagSENT_CONTENT	alone\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	achieve\tagSENT_CONTENT	comparable\tagSENT_CONTENT	or\tagSENT_CONTENT	better\tagSENT_CONTENT	results\tagSENT_CONTENT	than\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	manually\tagSENT_CONTENT	engineer\tagSENT_CONTENT	such\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	
1607.03474	title\tagSECTITLE_END	abstract\tagSECTITLE_END	language_modeling\tagtask	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	architecture\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	powerful\tagSENT_CONTENT	and\tagSENT_CONTENT	efficient\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Unfortunately\tagSENT_START	,\tagSENT_CONTENT	increased\tagSENT_CONTENT	depth\tagSENT_CONTENT	represents\tagSENT_CONTENT	a\tagSENT_CONTENT	challenge\tagSENT_CONTENT	when\tagSENT_CONTENT	neural\tagmetric	network\tagmetric	parameters\tagmetric	are\tagSENT_CONTENT	optimized\tagSENT_CONTENT	by\tagSENT_CONTENT	means\tagSENT_CONTENT	of\tagSENT_CONTENT	error\tagSENT_CONTENT	backpropagation\tagSENT_CONTENT	.\tagSENT_END	Used\tagSENT_START	as\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	connections\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	layers\tagSENT_CONTENT	were\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	domains\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	language_modeling\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	variants\tagSENT_CONTENT	called\tagSENT_CONTENT	Residual\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	computer\tagSENT_CONTENT	vision\tagSENT_CONTENT	problems\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Deep\tagSECTITLE_CONTENT	Recurrent\tagSECTITLE_CONTENT	Transitions\tagSECTITLE_END	illustrates\tagSENT_START	that\tagSENT_CONTENT	stacking\tagSENT_CONTENT	d\tagSENT_CONTENT	RNN\tagSENT_CONTENT	layers\tagSENT_CONTENT	allows\tagSENT_CONTENT	a\tagSENT_CONTENT	maximum\tagSENT_CONTENT	credit\tagSENT_CONTENT	assignment\tagSENT_CONTENT	path\tagSENT_CONTENT	length\tagSENT_CONTENT	(\tagSENT_CONTENT	number\tagmetric	of\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	transformations\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	d\tagSENT_CONTENT	+\tagSENT_CONTENT	T\tagSENT_CONTENT	−\tagSENT_CONTENT	1\tagSENT_CONTENT	between\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	T\tagSENT_CONTENT	time\tagSENT_END	Revisiting\tagSECTITLE_START	Gradient\tagSECTITLE_CONTENT	Flow\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Recurrent\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	Recurrent\tagSECTITLE_START	Highway\tagSECTITLE_CONTENT	Networks\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	RHN\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Experiments\tagSECTITLE_END	It\tagSENT_START	reduces\tagSENT_CONTENT	model\tagSENT_CONTENT	size\tagSENT_CONTENT	fora\tagSENT_CONTENT	fixed\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	units\tagSENT_CONTENT	and\tagSENT_CONTENT	prevents\tagSENT_CONTENT	an\tagSENT_CONTENT	unbounded\tagSENT_CONTENT	blow\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	of\tagSENT_CONTENT	state\tagSENT_CONTENT	values\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	stable\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	imposes\tagSENT_CONTENT	language_modeling\tagtask	which\tagSENT_CONTENT	maybe\tagSENT_CONTENT	suboptimal\tagSENT_CONTENT	for\tagSENT_CONTENT	certain\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Optimization\tagSECTITLE_END	Network\tagSENT_START	sizes\tagSENT_CONTENT	are\tagSENT_CONTENT	chosen\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	network\tagmetric	parameters\tagmetric	increases\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	depth\tagSENT_CONTENT	increases\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	remains\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	across\tagSENT_CONTENT	architectures\tagSENT_CONTENT	.\tagSENT_END	Sequence\tagSECTITLE_START	Modeling\tagSECTITLE_END	PENN\tagSECTITLE_START	TREEBANK\tagSECTITLE_END	To\tagSENT_START	examine\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	depth\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	RHNs\tagSENT_CONTENT	with\tagSENT_CONTENT	fixed\tagmetric	total\tagmetric	parameters\tagmetric	(\tagSENT_CONTENT	32\tagSENT_CONTENT	M\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	depths\tagSENT_CONTENT	ranging\tagSENT_CONTENT	from\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	10\tagSENT_CONTENT	for\tagSENT_CONTENT	word\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	TreeBank\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	preprocessed\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	directly\tagSENT_CONTENT	comparable\tagSENT_CONTENT	baseline\tagSENT_CONTENT	is\tagSENT_CONTENT	Variational\tagSENT_CONTENT	LSTM+WT\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	differs\tagSENT_CONTENT	in\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	and\tagSENT_CONTENT	size\tagSENT_CONTENT	from\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	WIKIPEDIA\tagSECTITLE_END	Due\tagSENT_START	to\tagSENT_CONTENT	its\tagSENT_CONTENT	size\tagSENT_CONTENT	(\tagSENT_CONTENT	100\tagmetric	M\tagmetric	characters\tagmetric	in\tagSENT_CONTENT	total\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	complexity\tagSENT_CONTENT	(\tagSENT_CONTENT	inclusion\tagSENT_CONTENT	of\tagSENT_CONTENT	Latin\tagSENT_CONTENT	/\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	Latin\tagSENT_CONTENT	alphabets\tagSENT_CONTENT	,\tagSENT_CONTENT	XML\tagSENT_CONTENT	markup\tagSENT_CONTENT	and\tagSENT_CONTENT	various\tagSENT_CONTENT	special\tagSENT_CONTENT	characters\tagSENT_CONTENT	for\tagSENT_CONTENT	enwik8\tagSENT_CONTENT	)\tagSENT_END	Model\tagSECTITLE_END	Analysis\tagSECTITLE_END	Conclusion\tagSECTITLE_END	Experiments\tagSENT_START	confirmed\tagSENT_CONTENT	the\tagSENT_CONTENT	theoretical\tagSENT_CONTENT	optimization\tagSENT_CONTENT	advantages\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	improved\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Supplementary\tagSECTITLE_START	Material\tagSECTITLE_END	Details\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Experimental\tagSECTITLE_CONTENT	Setups\tagSECTITLE_END	Optimization\tagSECTITLE_END	Penn\tagSECTITLE_START	Treebank\tagSECTITLE_END	The\tagSENT_START	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	text\tagSENT_CONTENT	corpus\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	comparatively\tagSENT_CONTENT	small\tagSENT_CONTENT	standard\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Enwik8\tagSECTITLE_END	The\tagSENT_START	Wikipedia\tagSENT_CONTENT	enwik8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	,\tagSENT_CONTENT	2012\tagSENT_CONTENT	)\tagSENT_CONTENT	was\tagSENT_CONTENT	split\tagSENT_CONTENT	into\tagSENT_CONTENT	training\tagSENT_CONTENT	/\tagSENT_CONTENT	validation\tagSENT_CONTENT	/\tagSENT_CONTENT	test\tagSENT_CONTENT	splits\tagSENT_CONTENT	of\tagSENT_CONTENT	90\tagSENT_CONTENT	M\tagSENT_CONTENT	,\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	characters\tagmetric	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	Text8\tagSECTITLE_END	The\tagSENT_START	Wikipedia\tagSENT_CONTENT	text8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	)\tagSENT_CONTENT	was\tagSENT_CONTENT	split\tagSENT_CONTENT	into\tagSENT_CONTENT	training\tagSENT_CONTENT	/\tagSENT_CONTENT	validation\tagSENT_CONTENT	/\tagSENT_CONTENT	test\tagSENT_CONTENT	splits\tagSENT_CONTENT	of\tagSENT_CONTENT	90\tagSENT_CONTENT	M\tagSENT_CONTENT	,\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	characters\tagmetric	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	Lesioning\tagSECTITLE_START	Experiment\tagSECTITLE_END	Recurrent\tagSECTITLE_START	Highway\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	
reside_emnlp18	title\tagSECTITLE_END	Improving\tagSENT_START	relationship_extraction\tagtask	using\tagSENT_CONTENT	Side\tagSENT_CONTENT	Information\tagSENT_END	abstract\tagSECTITLE_END	Distantly\tagSENT_START	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	Relation\tagSENT_CONTENT	Extraction\tagSENT_CONTENT	(\tagSENT_CONTENT	RE\tagSENT_CONTENT	)\tagSENT_CONTENT	methods\tagSENT_CONTENT	train\tagSENT_CONTENT	relationship_extraction\tagtask	by\tagSENT_CONTENT	automatically\tagSENT_CONTENT	aligning\tagSENT_CONTENT	relation\tagSENT_CONTENT	instances\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	Base\tagSENT_CONTENT	(\tagSENT_CONTENT	KB\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	unstructured\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	of\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	Bases\tagSENT_CONTENT	(\tagSENT_CONTENT	KBs\tagSENT_CONTENT	)\tagSENT_CONTENT	like\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	has\tagSENT_CONTENT	proven\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	web\tagSENT_CONTENT	search\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	require\tagSENT_CONTENT	large\tagSENT_CONTENT	labeled\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	expensive\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	.\tagSENT_END	employ\tagSENT_START	Convolutional\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	instances\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	improving\tagSENT_CONTENT	RE\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	relationship_extraction\tagtask	"\tagSENT_CONTENT	was\tagSENT_CONTENT	started\tagSENT_CONTENT	by\tagSENT_CONTENT	"\tagSENT_CONTENT	extracted\tagSENT_CONTENT	using\tagSENT_CONTENT	Open\tagSENT_CONTENT	Information\tagSENT_CONTENT	Extraction\tagSENT_CONTENT	(\tagSENT_CONTENT	Open\tagSENT_CONTENT	IE\tagSENT_CONTENT	)\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	RESIDE\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	method\tagSENT_CONTENT	which\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	KB\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	principled\tagSENT_CONTENT	manner\tagSENT_CONTENT	for\tagSENT_CONTENT	improving\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervised\tagSENT_CONTENT	RE\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	relationship\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Dependency\tagSENT_START	tree\tagSENT_CONTENT	based\tagSENT_CONTENT	features\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	found\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	relevant\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	KBs\tagSENT_CONTENT	like\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	readily\tagSENT_CONTENT	provide\tagSENT_CONTENT	relationship_extraction\tagtask	which\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	directly\tagSENT_CONTENT	utilized\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_START	:\tagSECTITLE_CONTENT	Graph\tagSECTITLE_CONTENT	Convolution\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	brief\tagSENT_CONTENT	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	Graph\tagSENT_CONTENT	Convolution\tagSENT_CONTENT	Networks\tagSENT_CONTENT	(\tagSENT_CONTENT	GCN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	graphs\tagSENT_CONTENT	with\tagSENT_CONTENT	directed\tagSENT_CONTENT	and\tagSENT_CONTENT	labeled\tagSENT_CONTENT	edges\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	Marcheggiani\tagSENT_CONTENT	and\tagSENT_CONTENT	Titov\tagSENT_CONTENT	,\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	GCN\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Labeled\tagSECTITLE_CONTENT	Directed\tagSECTITLE_CONTENT	Graph\tagSECTITLE_END	Integrating\tagSECTITLE_START	Edge\tagSECTITLE_CONTENT	Importance\tagSECTITLE_END	s\tagSENT_START	n\tagSENT_CONTENT	}\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Side\tagSENT_START	Information\tagSENT_CONTENT	Acquisition\tagSENT_CONTENT	:\tagSENT_CONTENT	In\tagSENT_CONTENT	this\tagSENT_CONTENT	module\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	KBs\tagSENT_CONTENT	and\tagSENT_CONTENT	utilize\tagSENT_CONTENT	Open\tagSENT_CONTENT	IE\tagSENT_CONTENT	methods\tagSENT_CONTENT	forgetting\tagSENT_CONTENT	relevant\tagSENT_CONTENT	side\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	RESIDE\tagSECTITLE_START	Details\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	provide\tagSENT_CONTENT	the\tagSENT_CONTENT	detailed\tagSENT_CONTENT	description\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	components\tagSENT_CONTENT	of\tagSENT_CONTENT	RESIDE\tagSENT_CONTENT	.\tagSENT_END	Syntactic\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Encoding\tagSECTITLE_END	For\tagSENT_START	incorporating\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	p\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	position\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	,\tagSENT_CONTENT	not\tagSENT_CONTENT	all\tagSENT_CONTENT	tokens\tagSENT_CONTENT	are\tagSENT_CONTENT	equally\tagSENT_CONTENT	relevant\tagSENT_CONTENT	for\tagSENT_CONTENT	RE\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	calculate\tagSENT_CONTENT	the\tagSENT_CONTENT	degree\tagSENT_CONTENT	of\tagSENT_CONTENT	relevance\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	token\tagSENT_CONTENT	using\tagSENT_CONTENT	attention\tagSENT_CONTENT	as\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	 \tagSENT_CONTENT	Figure\tagSENT_CONTENT	2\tagSENT_CONTENT	:\tagSENT_CONTENT	relationship_extraction\tagtask	alias\tagSENT_CONTENT	side\tagSENT_CONTENT	information\tagSENT_CONTENT	extraction\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Side\tagSECTITLE_START	Information\tagSECTITLE_CONTENT	Acquisition\tagSECTITLE_END	relationship_extraction\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	found\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	several\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Relation\tagSECTITLE_START	Alias\tagSECTITLE_CONTENT	Side\tagSECTITLE_CONTENT	Information\tagSECTITLE_END	RESIDE\tagSENT_START	uses\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	Open\tagSENT_CONTENT	IE\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	extracting\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	denote\tagSENT_CONTENT	by\tagSENT_END	Entity\tagSECTITLE_START	Type\tagSECTITLE_CONTENT	Side\tagSECTITLE_CONTENT	Information\tagSECTITLE_END	Type\tagSENT_START	information\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	promising\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	concatenate\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	type\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	bag\tagSENT_CONTENT	representation\tagSENT_CONTENT	before\tagSENT_CONTENT	using\tagSENT_CONTENT	it\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Instance\tagSECTITLE_START	Set\tagSECTITLE_CONTENT	Aggregation\tagSECTITLE_END	For\tagSENT_START	utilizing\tagSENT_CONTENT	all\tagSENT_CONTENT	valid\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	attention\tagSENT_CONTENT	over\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	relationship_extraction\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	bag\tagSENT_CONTENT	.\tagSENT_END	Datasets\tagSECTITLE_END	Baselines\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Criteria\tagSECTITLE_END	Results\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	we\tagSENT_CONTENT	attempt\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	questions\tagSENT_CONTENT	:\tagSENT_END	How\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	affected\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	absence\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	alias\tagSENT_CONTENT	information\tagSENT_CONTENT	?\tagSENT_END	Performance\tagSECTITLE_START	Comparison\tagSECTITLE_END	Ablation\tagSECTITLE_START	Results\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	various\tagSENT_CONTENT	components\tagSENT_CONTENT	of\tagSENT_CONTENT	RESIDE\tagSENT_CONTENT	on\tagSENT_CONTENT	its\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	Alias\tagSECTITLE_CONTENT	Side\tagSECTITLE_CONTENT	Information\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	test\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	insetting\tagSENT_CONTENT	where\tagSENT_CONTENT	relation\tagSENT_CONTENT	alias\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	readily\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	are\tagSENT_CONTENT	not\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	extended\tagSENT_CONTENT	using\tagSENT_CONTENT	Paraphrase\tagSENT_CONTENT	Database\tagSENT_CONTENT	(\tagSENT_CONTENT	PPDB\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	from\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	Base\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	RESIDE\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	principled\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	entity\tagSENT_CONTENT	type\tagSENT_CONTENT	and\tagSENT_CONTENT	relation\tagSENT_CONTENT	alias\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	Knowledge\tagSENT_CONTENT	Base\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	improving\tagSENT_CONTENT	distant\tagSENT_CONTENT	supervised\tagSENT_CONTENT	relation\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	
1704.08381	title\tagSECTITLE_END	Neural\tagSENT_START	AMR\tagSENT_CONTENT	:\tagSENT_CONTENT	Sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	Sequence\tagSENT_CONTENT	Models\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	Generation\tagSENT_END	abstract\tagSECTITLE_END	Sequence\tagSENT_START	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	strong\tagSENT_CONTENT	performance\tagSENT_CONTENT	across\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	training\tagSENT_CONTENT	procedure\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	lift\tagSENT_CONTENT	this\tagSENT_CONTENT	limitation\tagSENT_CONTENT	using\tagSENT_CONTENT	millions\tagSENT_CONTENT	of\tagSENT_CONTENT	unla\tagSENT_CONTENT	-\tagSENT_CONTENT	beled\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graphs\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	amr_parsing\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	competitive\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	62.1\tagmetric	SMATCH\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	best\tagSENT_CONTENT	score\tagSENT_CONTENT	reported\tagSENT_CONTENT	without\tagSENT_CONTENT	significant\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	external\tagSENT_CONTENT	semantic\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	amr_parsing\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	establishes\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	33.8\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Obama\tagSECTITLE_START	was\tagSECTITLE_CONTENT	elected\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	his\tagSECTITLE_CONTENT	voters\tagSECTITLE_CONTENT	celebrated\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	their\tagSENT_CONTENT	application\tagSENT_CONTENT	to\tagSENT_CONTENT	AMR\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	limited\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	part\tagSENT_CONTENT	because\tagSENT_CONTENT	effective\tagSENT_CONTENT	linearization\tagSENT_CONTENT	(\tagSENT_CONTENT	encoding\tagSENT_CONTENT	graphs\tagSENT_CONTENT	as\tagSENT_CONTENT	linear\tagSENT_CONTENT	sequences\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	were\tagSENT_CONTENT	thought\tagSENT_CONTENT	to\tagSENT_CONTENT	pose\tagSENT_CONTENT	significant\tagSENT_CONTENT	challenges\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	these\tagSENT_CONTENT	challenges\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	easily\tagSENT_CONTENT	overcome\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	demonstrating\tagSENT_CONTENT	that\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	using\tagSENT_CONTENT	any\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	isomorphic\tagSENT_CONTENT	linearization\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	text\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	significantly\tagSENT_CONTENT	reduce\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	For\tagSENT_START	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	competitive\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	62.1\tagmetric	SMATCH\tagmetric	without\tagSENT_CONTENT	using\tagSENT_CONTENT	any\tagSENT_CONTENT	external\tagSENT_CONTENT	annotated\tagSENT_CONTENT	examples\tagSENT_CONTENT	other\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	NER\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	over\tagSENT_CONTENT	10\tagSENT_CONTENT	points\tagSENT_CONTENT	relative\tagSENT_CONTENT	to\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	comparable\tagSENT_CONTENT	setup\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	provide\tagSENT_CONTENT	extensive\tagSENT_CONTENT	ablative\tagSENT_CONTENT	and\tagSENT_CONTENT	qualitative\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	quantifying\tagSENT_CONTENT	the\tagSENT_CONTENT	contributions\tagSENT_CONTENT	that\tagSENT_CONTENT	come\tagSENT_CONTENT	from\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	paired\tagSENT_CONTENT	training\tagSENT_CONTENT	procedure\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	amr_parsing\tagtask	Flanigan\tagSENT_END	amr_parsing\tagtask	)\tagSENT_CONTENT	perform\tagSENT_CONTENT	a\tagSENT_CONTENT	series\tagSENT_CONTENT	of\tagSENT_CONTENT	shift\tagSENT_CONTENT	-\tagSENT_CONTENT	reduce\tagSENT_CONTENT	transformations\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	externally\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_END	AMR\tagSECTITLE_START	Generation\tagSECTITLE_END	Methods\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	provide\tagSENT_CONTENT	the\tagSENT_CONTENT	formal\tagSENT_CONTENT	definition\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	generation\tagSENT_CONTENT	(\tagSENT_CONTENT	section\tagSENT_CONTENT	3.1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Tasks\tagSECTITLE_END	We\tagSENT_START	study\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	finding\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θ\tagSENT_CONTENT	P\tagSENT_CONTENT	for\tagSENT_CONTENT	model\tagSENT_CONTENT	f\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	predicts\tagSENT_CONTENT	an\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graphâgraphˆgraphâ\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	s\tagSENT_CONTENT	:\tagSENT_END	Sequence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	sequence\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Linearization\tagSECTITLE_END	Paired\tagSECTITLE_START	Training\tagSECTITLE_END	Obtaining\tagSENT_START	a\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	jointly\tagSENT_CONTENT	annotated\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	expensive\tagSENT_CONTENT	and\tagSENT_CONTENT	current\tagSENT_CONTENT	datasets\tagSENT_CONTENT	only\tagSENT_CONTENT	extend\tagSENT_CONTENT	to\tagSENT_CONTENT	thousands\tagSENT_CONTENT	of\tagSENT_CONTENT	examples\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSENT_START	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	amr_parsing\tagtask	with\tagSENT_CONTENT	so\tagSENT_CONTENT	few\tagSENT_CONTENT	training\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	an\tagSENT_CONTENT	external\tagSENT_CONTENT	unannotated\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	Se\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	procedure\tagSENT_CONTENT	which\tagSENT_CONTENT	pairs\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	and\tagSENT_CONTENT	generator\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	procedure\tagSENT_CONTENT	is\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Algorithm\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	first\tagSENT_CONTENT	trains\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	D\tagSENT_CONTENT	of\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Algorithm\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Paired\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Procedure\tagSECTITLE_END	Training\tagSENT_START	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_END	Se\tagSENT_START	,\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	self\tagSENT_CONTENT	training\tagSENT_CONTENT	iterations\tagSENT_CONTENT	,\tagSENT_CONTENT	N\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	initial\tagSENT_CONTENT	sample\tagSENT_CONTENT	size\tagSENT_CONTENT	k.\tagSENT_CONTENT	Output\tagSENT_CONTENT	:\tagSENT_CONTENT	Model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	5\tagSECTITLE_START	:\tagSECTITLE_END	amr_parsing\tagtask	.\tagSENT_END	6\tagSECTITLE_START	:\tagSECTITLE_END	Ae\tagSENT_START	amr_parsing\tagtask	using\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θP\tagSENT_CONTENT	11\tagSENT_CONTENT	:\tagSENT_END	After\tagSENT_START	we\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	parser\tagSENT_CONTENT	from\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	label\tagSENT_CONTENT	amr_parsing\tagtask	for\tagSENT_CONTENT	Se\tagSENT_CONTENT	and\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	generator\tagSENT_CONTENT	.\tagSENT_END	AMR\tagSECTITLE_START	Preprocessing\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	series\tagSENT_CONTENT	of\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	steps\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	modifications\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	to\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	graph\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	two\tagSENT_CONTENT	goals\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	linearized\tagSENT_CONTENT	sequences\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	amr_parsing\tagtask	easier\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	enough\tagSENT_CONTENT	original\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	address\tagSENT_CONTENT	amr_parsing\tagtask	from\tagSENT_CONTENT	certain\tagSENT_CONTENT	open\tagSENT_CONTENT	class\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	entries\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	(\tagSENT_CONTENT	NEs\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	quantities\tagSENT_CONTENT	.\tagSENT_END	Anonymization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Named\tagSECTITLE_CONTENT	Entities\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	account\tagSENT_CONTENT	for\tagSENT_CONTENT	new\tagSENT_CONTENT	unseen\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	extensive\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	alignments\tagSENT_CONTENT	obtained\tagSENT_CONTENT	using\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	aligner\tagSENT_CONTENT	of\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	anonymized\tagSENT_CONTENT	subgraphs\tagSENT_CONTENT	to\tagSENT_CONTENT	spans\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	replace\tagSENT_CONTENT	mapped\tagSENT_CONTENT	text\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	anonymized\tagSENT_CONTENT	token\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	inserted\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graph\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	a\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	predicts\tagSENT_CONTENT	an\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	token\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	token\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graph\tagSENT_CONTENT	and\tagSENT_CONTENT	replace\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	output\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	frequent\tagSENT_CONTENT	mapping\tagSENT_CONTENT	observed\tagSENT_CONTENT	during\tagSENT_CONTENT	amr_parsing\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	name\tagSENT_CONTENT	.\tagSENT_END	Anonymizing\tagSENT_START	Dates\tagSENT_CONTENT	For\tagSENT_CONTENT	dates\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	separate\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	tokens\tagSENT_CONTENT	for\tagSENT_CONTENT	year\tagSENT_CONTENT	,\tagSENT_CONTENT	month\tagSENT_CONTENT	-\tagSENT_CONTENT	number\tagSENT_CONTENT	,\tagSENT_CONTENT	month\tagSENT_CONTENT	-\tagSENT_CONTENT	name\tagSENT_CONTENT	,\tagSENT_CONTENT	day\tagSENT_CONTENT	-\tagSENT_CONTENT	number\tagSENT_CONTENT	and\tagSENT_CONTENT	day\tagSENT_CONTENT	-\tagSENT_CONTENT	name\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	date\tagSENT_CONTENT	is\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	byword\tagSENT_CONTENT	or\tagSENT_CONTENT	by\tagSENT_CONTENT	number\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	:\tagSENT_CONTENT	ARG0-of\tagSENT_CONTENT	have\tagSENT_CONTENT	-\tagSENT_CONTENT	org\tagSENT_CONTENT	-\tagSENT_CONTENT	role\tagSENT_CONTENT	:\tagSENT_END	amr_parsing\tagtask	:\tagSENT_END	New\tagSENT_START	:\tagSENT_CONTENT	op2\tagSENT_CONTENT	York\tagSENT_CONTENT	hold\tagSENT_CONTENT	:\tagSENT_CONTENT	ARG0\tagSENT_CONTENT	amr_parsing\tagtask	:\tagSENT_END	:\tagSENT_START	ARG1\tagSENT_CONTENT	(\tagSENT_CONTENT	meet\tagSENT_CONTENT	:\tagSENT_CONTENT	ARG0\tagSENT_CONTENT	amr_parsing\tagtask	:\tagSENT_END	NER\tagSENT_START	for\tagSENT_CONTENT	Linearization\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	conduct\tagSENT_CONTENT	all\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	corpus\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	SemEval-2016\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	(\tagSENT_CONTENT	LDC2015E86\tagdataset	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	contains\tagSENT_CONTENT	16,833/1,368/1,371\tagSENT_CONTENT	train\tagSENT_CONTENT	/\tagSENT_CONTENT	dev\tagSENT_CONTENT	/\tagSENT_CONTENT	test\tagSENT_CONTENT	examples\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	subsampled\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	overlap\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	or\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_CONTENT	--69.0\tagSENT_END	During\tagSENT_START	prediction\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	decoding\tagSENT_CONTENT	using\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	and\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	beam\tagSENT_CONTENT	size\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	both\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Parsing\tagSENT_START	Results\tagSENT_CONTENT	21.1\tagSENT_CONTENT	22.4\tagSENT_CONTENT	TREETOSTR\tagSENT_CONTENT	23.0\tagSENT_CONTENT	23.0\tagSENT_CONTENT	:\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Our\tagSENT_START	full\tagSENT_CONTENT	models\tagSENT_CONTENT	outperform\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	but\tagSENT_CONTENT	still\tagSENT_CONTENT	lags\tagSENT_CONTENT	behind\tagSENT_CONTENT	other\tagSENT_CONTENT	parser\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	systems\tagSENT_CONTENT	(\tagSENT_CONTENT	CAMR\tagSENT_CONTENT	6\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	resource\tagSENT_CONTENT	heavy\tagSENT_CONTENT	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	SBMT\tagmetric	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	final\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	GIGA-20\tagSENT_CONTENT	M\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	TSP\tagSENT_CONTENT	and\tagSENT_CONTENT	TREETOSTR\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	LDC2015E86\tagdataset	,\tagSENT_CONTENT	by\tagSENT_CONTENT	over\tagSENT_CONTENT	9\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	points\tagSENT_CONTENT	.\tagSENT_END	Generation\tagSECTITLE_START	Results\tagSECTITLE_END	Sparsity\tagSENT_START	Reduction\tagSENT_CONTENT	Even\tagSENT_CONTENT	after\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	of\tagSENT_CONTENT	open\tagSENT_CONTENT	class\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	entries\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	still\tagSENT_CONTENT	encounter\tagSENT_CONTENT	a\tagSENT_CONTENT	great\tagSENT_CONTENT	deal\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	small\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Table\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	incorporating\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	amr_parsing\tagtask	dramatically\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	sampled\tagSENT_CONTENT	sentences\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	out\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	rate\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	threshold\tagSENT_CONTENT	of\tagSENT_CONTENT	5\tagSENT_CONTENT	reduces\tagSENT_CONTENT	almost\tagSENT_CONTENT	5\tagSENT_CONTENT	times\tagSENT_CONTENT	for\tagSENT_CONTENT	GIGA-20M.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	trained\tagSENT_CONTENT	our\tagSENT_CONTENT	generator\tagSENT_CONTENT	on\tagSENT_CONTENT	GIGA-2\tagSENT_CONTENT	M\tagSENT_CONTENT	and\tagSENT_CONTENT	finetuned\tagSENT_CONTENT	on\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	amr_parsing\tagtask	with\tagSENT_CONTENT	PBMT\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	achieved\tagSENT_CONTENT	a\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	29.7\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	2.8\tagSENT_CONTENT	points\tagSENT_CONTENT	of\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	BLEU\tagSECTITLE_START	FULL\tagSECTITLE_END	Model\tagSECTITLE_END	22.7\tagSENT_START	54.2\tagSENT_CONTENT	32.0\tagSENT_CONTENT	:\tagSENT_CONTENT	SMATCH\tagmetric	scores\tagmetric	for\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	(\tagSENT_CONTENT	DEV\tagSENT_CONTENT	set\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	contains\tagSENT_START	examples\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ablations\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Following\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	largely\tagSENT_CONTENT	ineffective\tagSENT_CONTENT	without\tagSENT_CONTENT	anonymization\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Linearization\tagSECTITLE_START	Evaluation\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	three\tagSENT_CONTENT	strategies\tagSENT_CONTENT	for\tagSENT_CONTENT	converting\tagSENT_CONTENT	amr_parsing\tagtask	into\tagSENT_CONTENT	sequences\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	largely\tagSENT_CONTENT	agnostic\tagSENT_CONTENT	to\tagSENT_CONTENT	linearization\tagSENT_CONTENT	orders\tagSENT_CONTENT	.\tagSENT_END	Linearization\tagSECTITLE_START	Orders\tagSECTITLE_END	Linearization\tagSECTITLE_START	Order\tagSECTITLE_CONTENT	BLEU\tagSECTITLE_CONTENT	HUMAN\tagSECTITLE_CONTENT	21.7\tagSECTITLE_CONTENT	GLOBAL\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	RANDOM\tagSECTITLE_END	20.8\tagSENT_START	RANDOM\tagSENT_CONTENT	20.3\tagSENT_CONTENT	:\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	for\tagSENT_CONTENT	different\tagSENT_CONTENT	linearization\tagSENT_CONTENT	orders\tagSENT_CONTENT	(\tagSENT_CONTENT	DEV\tagSENT_CONTENT	set\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	construct\tagSENT_CONTENT	a\tagSENT_CONTENT	random\tagSENT_CONTENT	global\tagSENT_CONTENT	ordering\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	edge\tagSENT_CONTENT	types\tagSENT_CONTENT	appearing\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	use\tagSENT_CONTENT	it\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	example\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Human\tagSECTITLE_START	-\tagSECTITLE_CONTENT	authored\tagSECTITLE_CONTENT	AMR\tagSECTITLE_CONTENT	leaks\tagSECTITLE_CONTENT	information\tagSECTITLE_END	To\tagSENT_START	further\tagSENT_CONTENT	investigate\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compared\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	ordering\tagSENT_CONTENT	of\tagSENT_CONTENT	edge\tagSENT_CONTENT	pairs\tagSENT_CONTENT	under\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	children\tagSENT_CONTENT	nodes\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	those\tagSENT_CONTENT	edges\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	reported\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Error\tagSENT_START	analysis\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	a\tagSENT_CONTENT	sample\tagSENT_CONTENT	of\tagSENT_CONTENT	50\tagSENT_CONTENT	examples\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	relative\tagSENT_CONTENT	ordering\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	AMR\tagSENT_CONTENT	edges\tagSENT_CONTENT	was\tagSENT_CONTENT	particularly\tagSENT_CONTENT	indicative\tagSENT_CONTENT	of\tagSENT_CONTENT	generation\tagSENT_CONTENT	order\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	any\tagSENT_CONTENT	practical\tagSENT_CONTENT	application\tagSENT_CONTENT	requiring\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	amr_parsing\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	intention\tagSENT_CONTENT	to\tagSENT_CONTENT	realize\tagSENT_CONTENT	it\tagSENT_CONTENT	later\tagSENT_CONTENT	on\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dialog\tagSENT_CONTENT	agent\tagSENT_CONTENT	,\tagSENT_CONTENT	will\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	either\tagSENT_CONTENT	using\tagSENT_CONTENT	consistent\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	randomderived\tagSENT_CONTENT	linearization\tagSENT_CONTENT	orders\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	second\tagSENT_CONTENT	example\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	branching\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	coordination\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	verbs\tagSENT_CONTENT	stabilize\tagSENT_CONTENT	and\tagSENT_CONTENT	push\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	subordinate\tagSENT_CONTENT	clause\tagSENT_CONTENT	headed\tagSENT_CONTENT	by\tagSENT_CONTENT	state\tagmetric	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	third\tagSENT_CONTENT	example\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	missing\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	graph\tagSENT_CONTENT	headed\tagSENT_CONTENT	by\tagSENT_CONTENT	expert\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Results\tagSECTITLE_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	applied\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	tasks\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	by\tagSENT_CONTENT	carefully\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	representation\tagSENT_CONTENT	and\tagSENT_CONTENT	scaling\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	via\tagSENT_CONTENT	pretraining\tagSENT_CONTENT	on\tagSENT_CONTENT	millions\tagSENT_CONTENT	of\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	sentences\tagSENT_CONTENT	sourced\tagSENT_CONTENT	from\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	achieve\tagSENT_CONTENT	competitive\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	SMATCH\tagmetric	62.1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	performance\tagSENT_CONTENT	for\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	limit\tagSECTITLE_END	disfluency\tagSENT_START	state\tagSENT_CONTENT	:\tagSENT_CONTENT	arg0\tagSENT_CONTENT	amr_parsing\tagtask	:\tagSENT_CONTENT	arg0-of\tagSENT_CONTENT	(\tagSENT_CONTENT	have\tagSENT_CONTENT	-\tagSENT_CONTENT	org\tagSENT_END	amr_parsing\tagtask	:\tagSENT_END	amr_parsing\tagtask	:\tagSENT_CONTENT	arg2\tagSENT_CONTENT	(\tagSENT_CONTENT	make\tagSENT_CONTENT	:\tagSENT_CONTENT	arg1\tagSENT_CONTENT	missile\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_END	:\tagSENT_START	mod\tagSENT_CONTENT	(\tagmetric	impeach\tagmetric	:\tagSENT_CONTENT	polarity\tagSENT_CONTENT	-:arg1\tagSENT_CONTENT	thing\tagSENT_CONTENT	)\tagSENT_END	a\tagSENT_START	technical\tagSENT_CONTENT	committee\tagSENT_CONTENT	of\tagSENT_CONTENT	Indian\tagSENT_CONTENT	missile\tagSENT_CONTENT	experts\tagSENT_CONTENT	stated\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	equipment\tagSENT_CONTENT	was\tagSENT_CONTENT	unimpeachable\tagSENT_CONTENT	and\tagSENT_CONTENT	irrefutable\tagSENT_CONTENT	evidence\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	transfer\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	missiles\tagSENT_CONTENT	but\tagSENT_CONTENT	missile\tagSENT_CONTENT	-\tagSENT_CONTENT	making\tagSENT_CONTENT	capability\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	COMMENT\tagSECTITLE_END	
wang13a	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Fast\tagSECTITLE_START	approximations\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	dropout\tagSECTITLE_END	The\tagSECTITLE_START	implied\tagSECTITLE_CONTENT	objective\tagSECTITLE_CONTENT	function\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	subsections\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Gaussian\tagSENT_CONTENT	assumption\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	several\tagSENT_CONTENT	approximations\tagSENT_CONTENT	at\tagSENT_CONTENT	different\tagSENT_CONTENT	tradeoff\tagSENT_CONTENT	points\tagSENT_CONTENT	between\tagSENT_CONTENT	speed\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	end\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	sentiment_analysis\tagtask	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	little\tagSENT_CONTENT	to\tagSENT_CONTENT	no\tagSENT_CONTENT	performance\tagSENT_CONTENT	loss\tagSENT_CONTENT	when\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	faster\tagSENT_CONTENT	,\tagSENT_CONTENT	less\tagSENT_CONTENT	accurate\tagSENT_CONTENT	approximations\tagSENT_CONTENT	.\tagSENT_END	Gradient\tagSECTITLE_START	computation\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	sampling\tagSECTITLE_CONTENT	from\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Gaussian\tagSECTITLE_END	A\tagSECTITLE_START	closed\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	form\tagSECTITLE_CONTENT	approximation\tagSECTITLE_END	Generalizations\tagSECTITLE_END	Least\tagSECTITLE_START	squares\tagSECTITLE_CONTENT	regression\tagSECTITLE_END	Hinge\tagSECTITLE_START	loss\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Maxout\tagSECTITLE_CONTENT	unit\tagSECTITLE_END	Softmax\tagSECTITLE_START	and\tagSECTITLE_CONTENT	general\tagSECTITLE_CONTENT	loss\tagSECTITLE_END	Transformation\tagSECTITLE_START	invariance\tagSECTITLE_CONTENT	as\tagSECTITLE_CONTENT	noise\tagSECTITLE_END	Other\tagSECTITLE_START	noise\tagSECTITLE_END	Fast\tagSECTITLE_START	dropout\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	neural\tagSECTITLE_CONTENT	networks\tagSECTITLE_END	The\tagSECTITLE_START	hidden\tagSECTITLE_CONTENT	layers\tagSECTITLE_END	Training\tagSECTITLE_START	with\tagSECTITLE_CONTENT	backpropagation\tagSECTITLE_END	Relation\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Bayesian\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	selection\tagSECTITLE_END	Experiments\tagSECTITLE_END	Evaluating\tagSECTITLE_START	the\tagSECTITLE_CONTENT	assumptions\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	speed\tagSECTITLE_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	document\tagSECTITLE_CONTENT	classification\tagSECTITLE_END	We\tagSENT_START	show\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	fast\tagSENT_CONTENT	dropout\tagSENT_CONTENT	LR\tagSENT_CONTENT	on\tagSENT_CONTENT	several\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	and\tagSENT_CONTENT	topic\tagSENT_CONTENT	document\tagSENT_CONTENT	classification\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	time\tagSENT_CONTENT	taken\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	half\tagSENT_CONTENT	of\tagSENT_CONTENT	table\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	MNIST\tagSECTITLE_END	sentiment_analysis\tagtask	on\tagSENT_CONTENT	MNIST\tagSENT_CONTENT	using\tagSENT_CONTENT	2-hidden\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	table\tagSENT_CONTENT	2\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	error\tagSENT_CONTENT	curves\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	slight\tagSENT_CONTENT	smaller\tagSENT_CONTENT	net\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Methods\\tagSECTITLE_START	Datasets\tagSECTITLE_END	Other\tagSECTITLE_START	experiments\tagSECTITLE_END	Conclusions\tagSECTITLE_END	Dataset\tagSECTITLE_END	
1705.09980	title\tagSECTITLE_END	amr_parsing\tagtask	by\tagSENT_CONTENT	Character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	Translation\tagSENT_CONTENT	:\tagSENT_CONTENT	Experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representations\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	translation\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representations\tagSENT_CONTENT	(\tagSENT_CONTENT	amr_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Using\tagSENT_START	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	some\tagSENT_CONTENT	trivial\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	and\tagSENT_CONTENT	postprocessing\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	53.1\tagSENT_END	We\tagSENT_START	examine\tagSENT_CONTENT	five\tagSENT_CONTENT	different\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	this\tagSENT_CONTENT	baseline\tagSENT_CONTENT	result\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	reordering\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	match\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	increases\tagSENT_CONTENT	performance\tagSENT_CONTENT	to\tagSENT_CONTENT	58.3\tagSENT_CONTENT	;\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_END	Combining\tagSENT_START	all\tagSENT_CONTENT	five\tagSENT_CONTENT	techniques\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	71.0\tagSENT_CONTENT	on\tagSENT_CONTENT	holdout\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	state\tagmetric	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Various\tagSENT_START	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Research\tagmetric	in\tagSENT_CONTENT	this\tagSENT_CONTENT	area\tagSENT_CONTENT	comprises\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	many\tagSENT_CONTENT	others\tagSENT_CONTENT	.\tagSENT_END	Efforts\tagSENT_START	to\tagSENT_CONTENT	create\tagSENT_CONTENT	datasets\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representations\tagSENT_CONTENT	have\tagSENT_CONTENT	stimulated\tagSENT_CONTENT	research\tagmetric	in\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	those\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	formalism\tagSENT_CONTENT	of\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representation\tagSENT_CONTENT	(\tagSENT_CONTENT	AMR\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	also\tagSENT_CONTENT	shared\tagSENT_CONTENT	tasks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	organized\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	article\tagSENT_CONTENT	,\tagSENT_CONTENT	therefore\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	concentrate\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	because\tagSENT_CONTENT	large\tagSENT_CONTENT	gold\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	datasets\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	and\tagSENT_CONTENT	various\tagSENT_CONTENT	different\tagSENT_CONTENT	approaches\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	compared\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	traditional\tagSENT_CONTENT	approaches\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	interesting\tagSENT_CONTENT	attempts\tagSENT_CONTENT	recently\tagSENT_CONTENT	to\tagSENT_CONTENT	view\tagSENT_CONTENT	amr_parsing\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	translation\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	mapping\tagSENT_CONTENT	English\tagSENT_CONTENT	expressions\tagSENT_CONTENT	to\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	under\tagSENT_CONTENT	supervision\tagSENT_CONTENT	of\tagSENT_CONTENT	some\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	method\tagSENT_CONTENT	.\tagSENT_END	used\tagSENT_START	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previously\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	neural\tagSENT_CONTENT	parser\tagSENT_CONTENT	was\tagSENT_CONTENT	still\tagSENT_CONTENT	far\tagSENT_CONTENT	below\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	But\tagSENT_START	,\tagSENT_CONTENT	even\tagSENT_CONTENT	though\tagSENT_CONTENT	they\tagSENT_CONTENT	got\tagSENT_CONTENT	substantial\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	systems\tagSENT_CONTENT	still\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	come\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	state\tagmetric	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	aim\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	article\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	out\tagSENT_CONTENT	how\tagSENT_CONTENT	far\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	push\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	neural\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	:\tagSENT_CONTENT	can\tagSENT_CONTENT	we\tagSENT_CONTENT	reach\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	scores\tagSENT_CONTENT	comparable\tagSENT_CONTENT	with\tagSENT_CONTENT	traditional\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	?\tagSENT_END	More\tagSENT_START	specifically\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	objectives\tagSENT_CONTENT	are\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	try\tagSENT_CONTENT	to\tagSENT_CONTENT	reproduce\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	;\tagSENT_CONTENT	improve\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	results\tagSENT_CONTENT	by\tagSENT_CONTENT	employing\tagSENT_CONTENT	several\tagSENT_CONTENT	novel\tagSENT_CONTENT	techniques\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	investigate\tagSENT_CONTENT	whether\tagSENT_CONTENT	injecting\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	novel\tagSENT_CONTENT	techniques\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	contribute\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Our\tagSENT_START	final\tagSENT_CONTENT	model\tagSENT_CONTENT	reaches\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	71.0\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Method\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	give\tagSENT_CONTENT	a\tagSENT_CONTENT	bit\tagSENT_CONTENT	of\tagSENT_CONTENT	background\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Then\tagSENT_START	we\tagSENT_CONTENT	outline\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	ideas\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	translation\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	English\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	as\tagSENT_CONTENT	output\tagSENT_CONTENT	.\tagSENT_END	Abstract\tagSECTITLE_START	Meaning\tagSECTITLE_CONTENT	Representations\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	utilizing\tagSENT_CONTENT	amr_parsing\tagtask	we\tagSENT_CONTENT	will\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	parsing\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representations\tagSENT_CONTENT	(\tagSENT_CONTENT	amr_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	were\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	acyclic\tagSENT_CONTENT	,\tagSENT_CONTENT	directed\tagSENT_CONTENT	graphs\tagSENT_CONTENT	that\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	also\tagSENT_CONTENT	allow\tagSENT_CONTENT	fora\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	occurrence\tagSENT_CONTENT	of\tagSENT_CONTENT	variables\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	concept\tagSENT_CONTENT	person\tagSENT_CONTENT	with\tagSENT_CONTENT	variable\tagSENT_CONTENT	p\tagSENT_CONTENT	stands\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	relation\tagSENT_CONTENT	with\tagSENT_CONTENT	affect-01\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	with\tagSENT_CONTENT	hunger-01\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	brackets\tagSENT_CONTENT	are\tagSENT_CONTENT	important\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	they\tagSENT_CONTENT	signal\tagSENT_CONTENT	which\tagSENT_CONTENT	relations\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	concepts\tagSENT_CONTENT	(\tagSENT_CONTENT	amr_parsing\tagtask	used\tagSENT_CONTENT	in\tagSENT_CONTENT	is\tagSENT_CONTENT	optional\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	readability\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	also\tagSENT_CONTENT	include\tagSENT_CONTENT	proper\tagSENT_CONTENT	name\tagSENT_CONTENT	reference\tagSENT_CONTENT	resolution\tagSENT_CONTENT	by\tagSENT_CONTENT	including\tagSENT_CONTENT	a\tagSENT_CONTENT	link\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	wikipedia\tagSENT_CONTENT	entry\tagSENT_CONTENT	(\tagSENT_CONTENT	wikification\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	evaluation\tagSENT_CONTENT	purposes\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	converted\tagSENT_CONTENT	into\tagSENT_CONTENT	triples\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	precision\tagSENT_CONTENT	and\tagSENT_CONTENT	recall\tagSENT_CONTENT	on\tagSENT_CONTENT	matching\tagSENT_CONTENT	triples\tagSENT_CONTENT	between\tagSENT_CONTENT	gold\tagSENT_CONTENT	standard\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	and\tagSENT_CONTENT	system\tagSENT_CONTENT	-\tagSENT_CONTENT	produced\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagmetric	SMATCH\tagmetric	system\tagmetric	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	from\tagSENT_CONTENT	LDC\tagSENT_CONTENT	release\tagSENT_CONTENT	LDC2016E25\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	36,521\tagSENT_CONTENT	training\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	,\tagSENT_CONTENT	1,368\tagSENT_CONTENT	development\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	and\tagSENT_CONTENT	1,371\tagSENT_CONTENT	test\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	development\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	designated\tagSENT_CONTENT	dev\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	from\tagSENT_CONTENT	LDC2016E25\tagdataset	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	exact\tagSENT_CONTENT	same\tagSENT_CONTENT	sets\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	LDC2015E89\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Basic\tagSECTITLE_CONTENT	Translation\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	If\tagSENT_START	we\tagSENT_CONTENT	improved\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	default\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	setting\tagSENT_CONTENT	was\tagSENT_CONTENT	kept\tagSENT_CONTENT	and\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	that\tagSENT_CONTENT	improved\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	is\tagSENT_CONTENT	stopped\tagSENT_CONTENT	3\tagSENT_CONTENT	epochs\tagSENT_CONTENT	after\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	improve\tagSENT_CONTENT	-\tagSENT_CONTENT	ment\tagSENT_CONTENT	in\tagSENT_CONTENT	validation\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	anymore\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	wikification\tagSENT_CONTENT	relations\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_END	Postprocessing\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Restoring\tagSECTITLE_CONTENT	Information\tagSECTITLE_END	Pruning\tagSECTITLE_END	The\tagSENT_START	second\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	careful\tagSENT_CONTENT	and\tagSENT_CONTENT	only\tagSENT_CONTENT	removes\tagSENT_CONTENT	duplicate\tagSENT_CONTENT	nodes\tagSENT_CONTENT	if\tagSENT_CONTENT	they\tagSENT_CONTENT	have\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	This\tagSENT_START	helps\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	only\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	All\tagSENT_START	re\tagSENT_CONTENT	-\tagSENT_CONTENT	occurrent\tagSENT_CONTENT	nodes\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	removed\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	nodes\tagSENT_CONTENT	occurring\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	twice\tagSENT_CONTENT	are\tagSENT_CONTENT	removed\tagSENT_CONTENT	.\tagSENT_END	Two\tagSENT_START	example\tagSENT_CONTENT	amr_parsing\tagtask	whose\tagSENT_CONTENT	branches\tagSENT_CONTENT	are\tagSENT_CONTENT	pruned\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	fourth\tagSENT_CONTENT	method\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	AMR\tagSENT_CONTENT	,\tagSENT_CONTENT	none\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	:\tagSENT_CONTENT	mod\tagSENT_CONTENT	(\tagSENT_CONTENT	raw\tagSENT_CONTENT	)\tagSENT_CONTENT	branches\tagSENT_CONTENT	share\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	so\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	third\tagSENT_CONTENT	occurrence\tagSENT_CONTENT	is\tagSENT_CONTENT	removed\tagSENT_CONTENT	.\tagSENT_END	Wikification\tagSECTITLE_END	Since\tagSENT_START	we\tagSENT_CONTENT	removed\tagSENT_CONTENT	wikification\tagSENT_CONTENT	relations\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	will\tagSENT_CONTENT	never\tagSENT_CONTENT	output\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	link\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	it\tagSENT_CONTENT	has\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	link\tagSENT_CONTENT	gets\tagSENT_CONTENT	added\tagSENT_CONTENT	;\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	remains\tagSENT_CONTENT	unaltered\tagSENT_CONTENT	.\tagSENT_END	Restoring\tagSECTITLE_START	co\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	referring\tagSECTITLE_CONTENT	nodes\tagSECTITLE_END	Baseline\tagSECTITLE_START	Results\tagSECTITLE_END	Improving\tagSECTITLE_START	the\tagSECTITLE_CONTENT	Basic\tagSECTITLE_CONTENT	Translation\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	outlined\tagSENT_CONTENT	our\tagSENT_CONTENT	basic\tagSENT_CONTENT	method\tagSENT_CONTENT	of\tagSENT_CONTENT	producing\tagSENT_CONTENT	amr_parsing\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	characters\tagSENT_CONTENT	.\tagSENT_END	AMR\tagSECTITLE_START	Re\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	ordering\tagSECTITLE_END	Although\tagSENT_START	amr_parsing\tagtask	are\tagSENT_CONTENT	unordered\tagSENT_CONTENT	by\tagSENT_CONTENT	definition\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	textual\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	branches\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	exponential\tagSENT_CONTENT	increase\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	often\tagSENT_CONTENT	have\tagSENT_CONTENT	thousands\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	orders\tagSENT_CONTENT	.\tagSENT_END	Introducing\tagSECTITLE_START	Super\tagSECTITLE_CONTENT	Characters\tagSECTITLE_END	AMR\tagSECTITLE_START	,\tagSECTITLE_CONTENT	chars\tagSECTITLE_CONTENT	:\tagSECTITLE_END	amr_parsing\tagtask	:\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	hi\tagSENT_CONTENT	n\tagSENT_CONTENT	g\tagSENT_END	:\tagSENT_START	polarity\tagSENT_CONTENT	+\tagSENT_CONTENT	-\tagSENT_CONTENT	)\tagSENT_CONTENT	 \tagSENT_CONTENT	differentiate\tagSENT_CONTENT	between\tagSENT_CONTENT	amr_parsing\tagtask	that\tagSENT_CONTENT	opens\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	AMR\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	that\tagSENT_CONTENT	opens\tagSENT_CONTENT	,\tagSENT_CONTENT	say\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	fifth\tagSENT_CONTENT	subtree\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	experiment\tagSENT_CONTENT	we\tagSENT_CONTENT	replaced\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	super\tagSENT_CONTENT	character\tagSENT_CONTENT	that\tagSENT_CONTENT	also\tagSENT_CONTENT	provides\tagSENT_CONTENT	the\tagSENT_CONTENT	subtree\tagSENT_CONTENT	information\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	opening\tagSENT_CONTENT	parenthesis\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	fifth\tagSENT_CONTENT	level\tagSENT_CONTENT	becomes\tagSENT_CONTENT	*\tagSENT_END	Adding\tagSECTITLE_START	Part\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Speech\tagSECTITLE_CONTENT	Information\tagSECTITLE_END	Adding\tagSECTITLE_START	Silver\tagSECTITLE_CONTENT	Standard\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	A\tagSENT_START	problem\tagSENT_CONTENT	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	parsing\tagSENT_CONTENT	approaches\tagSENT_CONTENT	is\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	since\tagSENT_CONTENT	a\tagSENT_CONTENT	lot\tagSENT_CONTENT	of\tagSENT_CONTENT	manual\tagSENT_CONTENT	effort\tagSENT_CONTENT	is\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	gold\tagSENT_CONTENT	standard\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Ultimately\tagSENT_START	,\tagSENT_CONTENT	their\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	20\tagSENT_CONTENT	million\tagSENT_CONTENT	additional\tagSENT_CONTENT	data\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	obtains\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	62.1\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	therefore\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagSENT_CONTENT	data\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	silver\tagSENT_CONTENT	standard\tagSENT_CONTENT	"\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	mean\tagSENT_CONTENT	something\tagmetric	in\tagSENT_CONTENT	between\tagSENT_CONTENT	unchecked\tagSENT_CONTENT	automatically\tagSENT_CONTENT	produced\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	gold\tagSENT_CONTENT	standard\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	of\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	off\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	shelf\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsers\tagSENT_CONTENT	CAMR\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	silver\tagSENT_CONTENT	standard\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	JAMR\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	published\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parser\tagSENT_CONTENT	and\tagSENT_CONTENT	does\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	two\tagSENT_CONTENT	stages\tagSENT_CONTENT	:\tagSENT_CONTENT	first\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	concepts\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	Markov\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	these\tagSENT_CONTENT	concepts\tagSENT_CONTENT	by\tagSENT_CONTENT	searching\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	spanning\tagSENT_CONTENT	connected\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	that\tagSENT_CONTENT	are\tagSENT_CONTENT	either\tagSENT_CONTENT	invalid\tagSENT_CONTENT	or\tagSENT_CONTENT	include\tagSENT_CONTENT	null\tagSENT_CONTENT	-\tagSENT_CONTENT	tag\tagSENT_CONTENT	or\tagSENT_CONTENT	null\tagSENT_CONTENT	-\tagSENT_CONTENT	edge\tagSENT_END	To\tagSENT_START	ensure\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	are\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	of\tagSENT_CONTENT	decent\tagSENT_CONTENT	quality\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	produced\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	other\tagSENT_CONTENT	using\tagSENT_CONTENT	SMATCH\tagmetric	.\tagSENT_END	This\tagSENT_START	value\tagSENT_CONTENT	was\tagSENT_CONTENT	picked\tagSENT_CONTENT	to\tagSENT_CONTENT	filter\tagSENT_CONTENT	out\tagSENT_CONTENT	amr_parsing\tagtask	that\tagSENT_CONTENT	would\tagSENT_CONTENT	only\tagSENT_CONTENT	hurt\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	process\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	to\tagSENT_CONTENT	also\tagSENT_CONTENT	still\tagSENT_CONTENT	include\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	CAMR\tagSENT_START	produces\tagSENT_CONTENT	higher\tagSENT_CONTENT	quality\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	in\tagSENT_CONTENT	general\tagSENT_CONTENT	(\tagSENT_CONTENT	64.0\tagSENT_CONTENT	vs\tagSENT_CONTENT	55.0\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	it\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	some\tagSENT_CONTENT	variety\tagSENT_CONTENT	by\tagSENT_CONTENT	also\tagSENT_CONTENT	adding\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	performed\tagSENT_CONTENT	five\tagSENT_CONTENT	experiments\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	added\tagSENT_CONTENT	100k\tagSENT_CONTENT	silver\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	,\tagSENT_CONTENT	either\tagSENT_CONTENT	containing\tagSENT_CONTENT	100\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	75\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	67\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	50\tagSENT_CONTENT	%\tagSENT_CONTENT	or\tagSENT_CONTENT	0\tagSENT_CONTENT	%\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	:\tagSENT_START	F\tagSENT_CONTENT	-\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dev\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	adding\tagSENT_CONTENT	different\tagSENT_CONTENT	ratios\tagSENT_CONTENT	of\tagSENT_CONTENT	CAMR\tagSENT_CONTENT	and\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	parsed\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	our\tagSENT_CONTENT	initial\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	As\tagSENT_START	would\tagSENT_CONTENT	be\tagSENT_CONTENT	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	only\tagSENT_CONTENT	adding\tagSENT_CONTENT	amr_parsing\tagtask	considerably\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	only\tagSENT_CONTENT	adding\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	.\tagSENT_END	Optimizing\tagSECTITLE_START	training\tagSECTITLE_END	Both\tagSENT_START	phases\tagSENT_CONTENT	use\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	learning\tagSENT_CONTENT	rates\tagSENT_CONTENT	resulted\tagSENT_CONTENT	in\tagSENT_CONTENT	lower\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	averaged\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	means\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	say\tagSENT_CONTENT	,\tagSENT_CONTENT	four\tagSENT_CONTENT	models\tagSENT_CONTENT	is\tagSENT_CONTENT	four\tagSENT_CONTENT	times\tagSENT_CONTENT	faster\tagSENT_CONTENT	than\tagSENT_CONTENT	ensembling\tagSENT_CONTENT	four\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	also\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	quarter\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	the\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	method\tagSENT_CONTENT	uses\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	tested\tagSENT_CONTENT	with\tagSENT_CONTENT	both\tagSENT_CONTENT	ensembling\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	obtained\tagSENT_CONTENT	similar\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	opting\tagSENT_CONTENT	to\tagSENT_CONTENT	only\tagSENT_CONTENT	use\tagSENT_CONTENT	averaging\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Even\tagSENT_START	after\tagSENT_CONTENT	adding\tagSENT_CONTENT	the\tagSENT_CONTENT	silver\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	addition\tagSENT_CONTENT	of\tagSENT_CONTENT	POS\tagSENT_CONTENT	-\tagSENT_CONTENT	tags\tagSENT_CONTENT	and\tagSENT_CONTENT	super\tagSENT_CONTENT	characters\tagSENT_CONTENT	still\tagSENT_CONTENT	increased\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	albeit\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Unfortunately\tagSENT_START	,\tagSENT_CONTENT	Foland\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	publish\tagSENT_CONTENT	these\tagSENT_CONTENT	specific\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	the\tagSENT_CONTENT	table\tagSENT_CONTENT	shows\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	scores\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	parsers\tagSENT_CONTENT	on\tagSENT_CONTENT	five\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	eight\tagSENT_CONTENT	metrics\tagSENT_CONTENT	other\tagSENT_CONTENT	than\tagSENT_CONTENT	Smatch\tagmetric	.\tagSENT_END	In\tagSENT_START	general\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	quite\tagSENT_CONTENT	conservative\tagSENT_CONTENT	,\tagSENT_CONTENT	obtaining\tagSENT_CONTENT	amr_parsing\tagtask	than\tagSENT_CONTENT	recall\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	metric\tagSENT_CONTENT	.\tagSENT_END	only\tagSENT_START	contains\tagSENT_CONTENT	16,833\tagSENT_CONTENT	instances\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	36,521\tagSENT_CONTENT	of\tagSENT_CONTENT	LDC2016E25\tagdataset	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	amr_parsing\tagtask	with\tagSENT_CONTENT	previous\tagSENT_CONTENT	parsers\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	script\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	Applying\tagSENT_START	re\tagSENT_CONTENT	-\tagSENT_CONTENT	ordering\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	introducing\tagSENT_CONTENT	super\tagSENT_CONTENT	characters\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	adding\tagSENT_CONTENT	POS\tagSENT_CONTENT	-\tagSENT_CONTENT	tags\tagSENT_CONTENT	are\tagSENT_CONTENT	techniques\tagSENT_CONTENT	that\tagSENT_CONTENT	substantially\tagSENT_CONTENT	improve\tagSENT_CONTENT	neural\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	best\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	71.0\tagSENT_CONTENT	,\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	any\tagSENT_CONTENT	known\tagSENT_CONTENT	previously\tagSENT_CONTENT	published\tagSENT_CONTENT	result\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	have\tagSENT_CONTENT	the\tagSENT_CONTENT	feeling\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	still\tagSENT_CONTENT	a\tagSENT_CONTENT	lot\tagSENT_CONTENT	of\tagSENT_CONTENT	techniques\tagSENT_CONTENT	that\tagSENT_CONTENT	one\tagSENT_CONTENT	could\tagSENT_CONTENT	try\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Another\tagSENT_START	possible\tagSENT_CONTENT	next\tagSENT_CONTENT	step\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	change\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	are\tagSENT_CONTENT	unscoped\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	have\tagSENT_CONTENT	no\tagSENT_CONTENT	quantifiers\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	would\tagSENT_CONTENT	be\tagSENT_CONTENT	challenging\tagSENT_CONTENT	to\tagSENT_CONTENT	transfer\tagSENT_CONTENT	the\tagSENT_CONTENT	techniques\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	scoped\tagSENT_CONTENT	meaning\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	those\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Groningen\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Bank\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	Parallel\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Bank\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	
P18-1015	title\tagSECTITLE_END	summarization\tagtask	abstract\tagSECTITLE_END	Most\tagSENT_START	previous\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	summarization\tagSENT_CONTENT	systems\tagSENT_CONTENT	purely\tagSENT_CONTENT	depend\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	tends\tagSENT_CONTENT	to\tagSENT_CONTENT	work\tagSENT_CONTENT	unstably\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Most\tagSENT_START	previous\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	purely\tagSENT_CONTENT	depend\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	summarization\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	traditional\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	call\tagSENT_CONTENT	these\tagSENT_CONTENT	existing\tagSENT_CONTENT	summaries\tagSENT_CONTENT	soft\tagSENT_CONTENT	templates\tagSENT_CONTENT	since\tagSENT_CONTENT	no\tagSENT_CONTENT	actual\tagSENT_CONTENT	rules\tagSENT_CONTENT	are\tagSENT_CONTENT	nee\tagSENT_CONTENT	-\tagSENT_CONTENT	ded\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	import\tagSENT_CONTENT	of\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	quality\tagSENT_CONTENT	external\tagSENT_CONTENT	summaries\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	stability\tagSENT_CONTENT	and\tagSENT_CONTENT	readability\tagSENT_CONTENT	of\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	We\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	soft\tagSENT_CONTENT	templates\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	readability\tagSENT_CONTENT	and\tagSENT_CONTENT	stability\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Method\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	modules\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	Retrieve\tagSENT_CONTENT	,\tagSENT_CONTENT	Rerank\tagSENT_CONTENT	and\tagSENT_CONTENT	Rewrite\tagSENT_CONTENT	.\tagSENT_END	Retrieve\tagSECTITLE_END	Jointly\tagSECTITLE_START	Rerank\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Rewrite\tagSECTITLE_END	Rerank\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	the\tagSENT_CONTENT	soft\tagSENT_CONTENT	template\tagSENT_CONTENT	r\tagSENT_CONTENT	resembles\tagSENT_CONTENT	the\tagSENT_CONTENT	actual\tagSENT_CONTENT	summary\tagSENT_CONTENT	y\tagSENT_END	Rewrite\tagSECTITLE_END	The\tagSENT_START	soft\tagSENT_CONTENT	template\tagSENT_CONTENT	r\tagSENT_CONTENT	selected\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	Rerank\tagSENT_CONTENT	module\tagSENT_CONTENT	has\tagSENT_CONTENT	already\tagSENT_CONTENT	competed\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	ROUGE\tagmetric	evaluation\tagmetric	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_END	To\tagSENT_START	make\tagSENT_CONTENT	full\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	both\tagSENT_CONTENT	sides\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	two\tagSENT_CONTENT	costs\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	:\tagSENT_END	To\tagSENT_START	enhance\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	dropout\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	probability\tagSENT_CONTENT	p\tagSENT_CONTENT	=\tagSENT_CONTENT	0.3\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	Dataset\tagSECTITLE_END	COPY\tagSENT_START	means\tagSENT_CONTENT	the\tagSENT_CONTENT	copy\tagSENT_CONTENT	ratio\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	without\tagSENT_CONTENT	stopwords\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Metrics\tagSECTITLE_END	We\tagSENT_START	adopt\tagSENT_CONTENT	ROUGE\tagmetric	)\tagSENT_CONTENT	for\tagSENT_CONTENT	automatic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	"\tagSENT_CONTENT	RG\tagSENT_CONTENT	"\tagSENT_CONTENT	stands\tagSENT_CONTENT	for\tagSENT_CONTENT	ROUGE\tagmetric	for\tagSENT_CONTENT	short\tagSENT_CONTENT	.\tagSENT_END	LESS\tagSECTITLE_START	3\tagSECTITLE_END	A\tagSENT_START	seriously\tagSENT_CONTENT	large\tagSENT_CONTENT	copy\tagSENT_CONTENT	ratio\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	summarization\tagtask	pays\tagSENT_CONTENT	more\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	compression\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	required\tagSENT_CONTENT	abstraction\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	During\tagSENT_START	test\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	5\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Baselines\tagSECTITLE_END	ABS+\tagSENT_START	further\tagSENT_CONTENT	tuned\tagSENT_CONTENT	the\tagSENT_CONTENT	ABS\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	additional\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	balance\tagSENT_CONTENT	between\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	Informativeness\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Model\tagSECTITLE_END	Linguistic\tagSECTITLE_START	Quality\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	The\tagSENT_START	soft\tagSENT_CONTENT	templates\tagSENT_CONTENT	indeed\tagSENT_CONTENT	well\tagSENT_CONTENT	guide\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Re\tagSENT_START	3\tagSENT_CONTENT	Sum\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	LEN\tagSENT_CONTENT	DF\tagSENT_CONTENT	is\tagSENT_CONTENT	0.7\tagSENT_CONTENT	times\tagSENT_CONTENT	larger\tagSENT_CONTENT	in\tagSENT_CONTENT	OpenNMT\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	that\tagSENT_CONTENT	Open\tagSENT_CONTENT	-\tagSENT_CONTENT	NMT\tagSENT_CONTENT	works\tagSENT_CONTENT	quite\tagSENT_CONTENT	unstably\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Templates\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	interesting\tagSENT_CONTENT	to\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagmetric	ROUGE-2\tagmetric	score\tagmetric	of\tagSENT_CONTENT	Random\tagSENT_CONTENT	templates\tagSENT_CONTENT	is\tagSENT_CONTENT	zero\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	generate\tagSENT_CONTENT	acceptable\tagSENT_CONTENT	summaries\tagSENT_CONTENT	with\tagSENT_CONTENT	Random\tagSENT_CONTENT	templates\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	manually\tagSENT_CONTENT	inspect\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	different\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	sake\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	present\tagSENT_CONTENT	the\tagSENT_CONTENT	2-best\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	OpenNMT\tagSENT_CONTENT	with\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	sentence\tagSENT_CONTENT	while\tagSENT_CONTENT	preserving\tagSENT_CONTENT	its\tagSENT_CONTENT	meaning\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	direct\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	general\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	framework\tagSENT_CONTENT	,\tagSENT_CONTENT	researchers\tagSENT_CONTENT	attempted\tagSENT_CONTENT	to\tagSENT_CONTENT	integrate\tagSENT_CONTENT	various\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	proposes\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	soft\tagSENT_CONTENT	templates\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	guide\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	one\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	templates\tagSENT_CONTENT	are\tagSENT_CONTENT	far\tagSENT_CONTENT	inferior\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	optimal\tagSENT_CONTENT	ones\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	intend\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	Retrieve\tagSENT_CONTENT	module\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	indexing\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	fields\tagSENT_CONTENT	.\tagSENT_END	
f2205c56378e715d8d12c521d045c0756a76	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	core\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	analysis\tagSENT_CONTENT	stack\tagSENT_CONTENT	:\tagSENT_CONTENT	coreference\tagSENT_CONTENT	resolution\tagSENT_CONTENT	(\tagSENT_CONTENT	within\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	clustering\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	coarse\tagSENT_CONTENT	semantic\tagSENT_CONTENT	typing\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	matching\tagSENT_CONTENT	to\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	entities\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	add\tagSENT_CONTENT	binary\tagSENT_CONTENT	and\tagSENT_CONTENT	ternary\tagSENT_CONTENT	factors\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	interactions\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	constraint\tagSENT_CONTENT	that\tagSENT_CONTENT	named_entity_recognition\tagtask	have\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	semantic\tagSENT_CONTENT	type\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	is\tagSENT_CONTENT	coreference\tagSENT_CONTENT	resolution\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	identifies\tagSENT_CONTENT	clusters\tagSENT_CONTENT	of\tagSENT_CONTENT	mentions\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	referring\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	A\tagSENT_START	separate\tagSENT_CONTENT	line\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	considered\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	or\tagSENT_CONTENT	"\tagSENT_CONTENT	Wikification\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	mentions\tagSENT_CONTENT	are\tagSENT_CONTENT	linked\tagSENT_CONTENT	to\tagSENT_CONTENT	entries\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	System\tagSENT_CONTENT	available\tagSENT_CONTENT	at\tagSENT_CONTENT	http://nlp.cs.berkeley.edu\tagSENT_CONTENT	base\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference\tagSENT_CONTENT	,\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	typing\tagSENT_CONTENT	(\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	field\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	named_entity_recognition\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	,\tagSENT_CONTENT	factors\tagSENT_CONTENT	capture\tagSENT_CONTENT	a\tagSENT_CONTENT	mapping\tagSENT_CONTENT	between\tagSENT_CONTENT	NER\tagSENT_CONTENT	's\tagSENT_CONTENT	semantic\tagSENT_CONTENT	types\tagSENT_CONTENT	and\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	's\tagSENT_CONTENT	semantics\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	by\tagSENT_CONTENT	infoboxes\tagSENT_CONTENT	,\tagSENT_CONTENT	categories\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	article\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	employed\tagSENT_CONTENT	for\tagSENT_CONTENT	coreference\tagSENT_CONTENT	resolution\tagSENT_CONTENT	and\tagSENT_CONTENT	coreference\tagSENT_CONTENT	for\tagSENT_CONTENT	entity\tagSENT_CONTENT	linking\tagSENT_CONTENT	 \tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	tighter\tagSENT_CONTENT	integration\tagSENT_CONTENT	of\tagSENT_CONTENT	coreference\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	promising\tagSENT_END	named_entity_recognition\tagtask	is\tagSENT_CONTENT	improved\tagSENT_CONTENT	by\tagSENT_CONTENT	simple\tagSENT_CONTENT	coreference\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	CRF\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	conceptually\tagSENT_CONTENT	no\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	than\tagSENT_CONTENT	its\tagSENT_CONTENT	component\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	behavior\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	understood\tagSENT_CONTENT	using\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Motivating\tagSECTITLE_START	Examples\tagSECTITLE_END	4\tagSENT_START	shows\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	coreference\tagSENT_CONTENT	is\tagSENT_CONTENT	now\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	but\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	transparent\tagSENT_CONTENT	.\tagSENT_END	ORGANIZATION\tagSECTITLE_START	PERSON\tagSECTITLE_END	Model\tagSECTITLE_END	,\tagSENT_START	indicating\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	mention\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	or\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	begins\tagSENT_CONTENT	anew\tagSENT_CONTENT	cluster\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	θ\tagSENT_CONTENT	is\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	x\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	automatic\tagSENT_CONTENT	parses\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	mention\tagSENT_CONTENT	boundaries\tagSENT_CONTENT	.\tagSENT_END	Independent\tagSECTITLE_START	Model\tagSECTITLE_END	Coreference\tagSECTITLE_END	Named\tagSECTITLE_START	Entity\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_END	Our\tagSENT_START	NER\tagSENT_CONTENT	model\tagSENT_CONTENT	places\tagSENT_CONTENT	named_entity_recognition\tagtask	over\tagSENT_CONTENT	possible\tagSENT_CONTENT	semantic\tagSENT_CONTENT	types\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	mention\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Entity\tagSECTITLE_START	Linking\tagSECTITLE_END	The\tagSENT_START	standard\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	doing\tagSENT_CONTENT	so\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	collect\tagSENT_CONTENT	all\tagSENT_CONTENT	hyperlinks\tagSENT_CONTENT	in\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	and\tagSENT_CONTENT	associate\tagSENT_CONTENT	each\tagSENT_CONTENT	hyperlinked\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	Michael\tagSENT_CONTENT	Jordan\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	named_entity_recognition\tagtask	over\tagSENT_CONTENT	titles\tagSENT_CONTENT	of\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	observed\tagSENT_CONTENT	to\tagSENT_CONTENT	link\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	Michael\tagSENT_CONTENT	Jordan\tagSENT_CONTENT	,\tagSENT_CONTENT	Michael\tagSENT_CONTENT	I.\tagSENT_CONTENT	Jordan\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	i\tagSENT_START	,\tagSENT_CONTENT	e\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	coherence\tagSENT_CONTENT	between\tagSENT_CONTENT	choices\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Cross\tagSECTITLE_START	-\tagSECTITLE_CONTENT	task\tagSECTITLE_CONTENT	Interaction\tagSECTITLE_CONTENT	Factors\tagSECTITLE_END	Entity\tagSECTITLE_START	Linking\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	NER\tagSECTITLE_END	Coreference\tagSECTITLE_START	and\tagSECTITLE_CONTENT	NER\tagSECTITLE_END	Coreference\tagSENT_START	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	NER\tagSENT_CONTENT	by\tagSENT_CONTENT	ensuring\tagSENT_CONTENT	named_entity_recognition\tagtask	across\tagSENT_CONTENT	named_entity_recognition\tagtask	;\tagSENT_CONTENT	likewise\tagSENT_CONTENT	,\tagSENT_CONTENT	NER\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	coreference\tagSENT_CONTENT	by\tagSENT_CONTENT	encouraging\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	linkup\tagSENT_CONTENT	mentions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	type\tagSENT_CONTENT	.\tagSENT_END	<\tagSENT_START	i.\tagSENT_CONTENT	When\tagSENT_CONTENT	scoring\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	variables\tagSENT_CONTENT	,\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	factors\tagSENT_CONTENT	is\tagSENT_CONTENT	active\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	during\tagSENT_CONTENT	inference\tagSENT_CONTENT	when\tagSENT_CONTENT	we\tagSENT_CONTENT	marginalize\tagSENT_CONTENT	overall\tagSENT_CONTENT	settings\tagSENT_CONTENT	of\tagSENT_CONTENT	variables\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	factors\tagSENT_CONTENT	comes\tagSENT_CONTENT	into\tagSENT_CONTENT	play\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	The\tagSENT_START	semantic\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	antecedent\tagSENT_CONTENT	and\tagSENT_CONTENT	head\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_END	Coreference\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Entity\tagSECTITLE_CONTENT	Linking\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	said\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	named_entity_recognition\tagtask	can\tagSENT_CONTENT	actually\tagSENT_CONTENT	have\tagSENT_CONTENT	different\tagSENT_CONTENT	entity\tagSENT_CONTENT	links\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	Dell\tagSENT_CONTENT	and\tagSENT_CONTENT	Company\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_END	Nevertheless\tagSENT_START	,\tagSENT_CONTENT	these\tagSENT_CONTENT	basic\tagSENT_CONTENT	features\tagSENT_CONTENT	still\tagSENT_CONTENT	promise\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	identify\tagSENT_CONTENT	related\tagSENT_CONTENT	articles\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	named_entity_recognition\tagtask	by\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	the\tagSENT_CONTENT	abundance\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	on\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_END	where\tagSENT_START	A(C\tagSENT_CONTENT	*\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	antecedent\tagSENT_CONTENT	structures\tagSENT_CONTENT	consistent\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	annotation\tagSENT_CONTENT	:\tagSENT_CONTENT	named_entity_recognition\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	cluster\tagSENT_CONTENT	must\tagSENT_CONTENT	pick\tagSENT_CONTENT	the\tagSENT_CONTENT	NEW\tagSENT_CONTENT	label\tagSENT_CONTENT	and\tagSENT_CONTENT	named_entity_recognition\tagtask	must\tagSENT_CONTENT	pick\tagSENT_CONTENT	an\tagSENT_CONTENT	antecedent\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	those\tagSENT_CONTENT	preceding\tagSENT_CONTENT	them\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	cluster\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	reason\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	that\tagSENT_CONTENT	has\tagSENT_CONTENT	fewer\tagSENT_CONTENT	than\tagSENT_CONTENT	two\tagSENT_CONTENT	antecedents\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	cluster\tagSENT_CONTENT	,\tagSENT_CONTENT	all\tagSENT_CONTENT	elements\tagSENT_CONTENT	of\tagSENT_CONTENT	A(C\tagSENT_CONTENT	*\tagSENT_CONTENT	)\tagSENT_CONTENT	only\tagSENT_CONTENT	contain\tagSENT_CONTENT	one\tagSENT_CONTENT	possibility\tagSENT_CONTENT	for\tagSENT_CONTENT	that\tagSENT_CONTENT	mention\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	even\tagSENT_CONTENT	for\tagSENT_CONTENT	mentions\tagSENT_CONTENT	with\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	ends\tagSENT_CONTENT	up\tagSENT_CONTENT	learning\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	place\tagSENT_CONTENT	almost\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	mass\tagSENT_CONTENT	consistently\tagSENT_CONTENT	on\tagSENT_CONTENT	one\tagSENT_CONTENT	antecedent\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	entity\tagSENT_CONTENT	linker\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	links\tagSENT_CONTENT	to\tagSENT_CONTENT	NIL\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	more\tagSENT_CONTENT	thoroughly\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Inference\tagSECTITLE_END	Experiments\tagSECTITLE_END	This\tagSENT_START	corpus\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	contain\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	this\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	though\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	still\tagSENT_CONTENT	exploits\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	coreference\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	ACE\tagSECTITLE_START	Evaluation\tagSECTITLE_END	We\tagSENT_START	both\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	overall\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	(\tagSENT_CONTENT	how\tagSENT_CONTENT	many\tagSENT_CONTENT	mentions\tagSENT_CONTENT	are\tagSENT_CONTENT	correctly\tagSENT_CONTENT	linked\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	two\tagSENT_CONTENT	more\tagSENT_CONTENT	specific\tagSENT_CONTENT	criteria\tagSENT_CONTENT	:\tagSENT_CONTENT	precision\tagSENT_CONTENT	/\tagSENT_CONTENT	recall\tagSENT_CONTENT	/\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	of\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	NIL\tagSENT_CONTENT	9\tagSENT_CONTENT	predictions\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	precision\tagSENT_CONTENT	/\tagSENT_CONTENT	recall\tagSENT_CONTENT	/\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Model\tagSECTITLE_START	Ablations\tagSECTITLE_END	These\tagSENT_START	joint\tagSENT_CONTENT	factors\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	strongest\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	any\tagSENT_CONTENT	considered\tagSENT_CONTENT	here\tagSENT_CONTENT	and\tagSENT_CONTENT	give\tagSENT_CONTENT	large\tagSENT_CONTENT	improvements\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	last\tagSENT_CONTENT	line\tagSENT_CONTENT	of\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	experiment\tagSENT_CONTENT	where\tagSENT_CONTENT	named_entity_recognition\tagtask	were\tagSENT_CONTENT	not\tagSENT_CONTENT	observed\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	they\tagSENT_CONTENT	were\tagSENT_CONTENT	left\tagSENT_CONTENT	latent\tagSENT_CONTENT	.\tagSENT_END	Unsurprisingly\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	good\tagSENT_CONTENT	at\tagSENT_CONTENT	named_entity_recognition\tagtask	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	or\tagSENT_CONTENT	even\tagSENT_CONTENT	slightly\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	coreference\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	.\tagSENT_END	OntoNotes\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Evaluating\tagSENT_START	on\tagSENT_CONTENT	OntoNotes\tagSENT_CONTENT	carries\tagSENT_CONTENT	with\tagSENT_CONTENT	it\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	named_entity_recognition\tagtask	are\tagSENT_CONTENT	not\tagSENT_CONTENT	available\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	handle\tagSENT_CONTENT	this\tagSENT_CONTENT	by\tagSENT_END	Divergent\tagSECTITLE_START	Coreference\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	NER\tagSECTITLE_END	The\tagSENT_START	unary\tagSENT_CONTENT	NER\tagSENT_CONTENT	features\tagSENT_CONTENT	developed\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.1.2\tagSENT_CONTENT	are\tagSENT_CONTENT	now\tagSENT_CONTENT	applied\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	conjoined\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	BIO\tagSENT_CONTENT	labels\tagSENT_CONTENT	at\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	with\tagSENT_CONTENT	factors\tagSENT_CONTENT	involving\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	2\tagSENT_CONTENT	touching\tagSENT_CONTENT	t\tagSENT_CONTENT	9\tagSENT_CONTENT	(\tagSENT_CONTENT	company\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	both\tagSENT_CONTENT	other\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	once\tagSENT_CONTENT	again\tagSENT_CONTENT	joint\tagSENT_CONTENT	modeling\tagSENT_CONTENT	gives\tagSENT_CONTENT	substantial\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	outperform\tagSENT_CONTENT	both\tagSENT_CONTENT	prior\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	,\tagSENT_CONTENT	though\tagSENT_CONTENT	the\tagSENT_CONTENT	ILLINOIS\tagSENT_CONTENT	system\tagSENT_CONTENT	features\tagSENT_CONTENT	higher\tagSENT_CONTENT	recall\tagSENT_CONTENT	while\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	features\tagSENT_CONTENT	higher\tagSENT_CONTENT	precision\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	build\tagSENT_START	coreference\tagSENT_CONTENT	clusters\tagSENT_CONTENT	greedily\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	and\tagSENT_CONTENT	maintain\tagSENT_CONTENT	named_entity_recognition\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	cluster\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	a\tagSENT_CONTENT	list\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	targets\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	current\tagSENT_CONTENT	best\tagSENT_CONTENT	link\tagSENT_CONTENT	target\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	though\tagSENT_CONTENT	that\tagSENT_CONTENT	might\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	chosen\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	inference\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	use\tagSENT_START	coreference\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	step\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	then\tagSENT_CONTENT	solve\tagSENT_CONTENT	an\tagSENT_CONTENT	ILP\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	optimal\tagSENT_CONTENT	entity\tagSENT_CONTENT	link\tagSENT_CONTENT	assignments\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	mention\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	surface\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	that\tagSENT_CONTENT	mention\tagSENT_CONTENT	,\tagSENT_CONTENT	other\tagSENT_CONTENT	mentions\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	cluster\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	mentions\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	could\tagSENT_CONTENT	strengthen\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	integrating\tagSENT_CONTENT	this\tagSENT_CONTENT	capability\tagSENT_CONTENT	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	primary\tagSENT_CONTENT	cause\tagSENT_CONTENT	of\tagSENT_CONTENT	errors\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	on\tagSENT_CONTENT	OntoNotes\tagSENT_CONTENT	is\tagSENT_CONTENT	parsing\tagSENT_CONTENT	ambiguities\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	ambiguities\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	unlikely\tagSENT_CONTENT	to\tagSENT_CONTENT	see\tagSENT_CONTENT	improvements\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	experiments\tagSENT_CONTENT	presented\tagSENT_CONTENT	here\tagSENT_CONTENT	.\tagSENT_END	Beyond\tagSENT_START	maintaining\tagSENT_CONTENT	uncertainty\tagSENT_CONTENT	over\tagSENT_CONTENT	mention\tagSENT_CONTENT	boundaries\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	might\tagSENT_CONTENT	also\tagSENT_CONTENT	consider\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	uncertainty\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	parse\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	consider\tagSENT_CONTENT	parsing\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	named_entity_recognition\tagtask	together\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	PCFG\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	named_entity_recognition\tagtask	is\tagSENT_CONTENT	available\tagSENT_CONTENT	at\tagSENT_CONTENT	http://nlp.cs.berkeley.edu\tagSENT_CONTENT	.\tagSENT_END	
1606.01549	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	enables\tagSENT_CONTENT	the\tagSENT_CONTENT	reader\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	query\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	A\tagSENT_START	recent\tagSENT_CONTENT	trend\tagSENT_CONTENT	to\tagSENT_CONTENT	measure\tagSENT_CONTENT	progress\tagSENT_CONTENT	towards\tagSENT_CONTENT	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	's\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	comprehend\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	success\tagSENT_CONTENT	of\tagSENT_CONTENT	many\tagSENT_CONTENT	recent\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	attributed\tagSENT_CONTENT	primarily\tagSENT_CONTENT	to\tagSENT_CONTENT	two\tagSENT_CONTENT	factors\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	hop\tagSENT_CONTENT	architectures\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	allow\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	scan\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	iteratively\tagSENT_CONTENT	for\tagSENT_CONTENT	multiple\tagSENT_CONTENT	passes\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	attentions\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	orthogonally\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	GA\tagSENT_CONTENT	reader\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	its\tagSENT_CONTENT	relative\tagSENT_CONTENT	simplicity\tagSENT_CONTENT	,\tagSENT_CONTENT	consis\tagSENT_CONTENT	-\tagSENT_CONTENT	tently\tagSENT_CONTENT	improves\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	three\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	The\tagSENT_START	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	QA\tagSENT_CONTENT	task\tagSENT_CONTENT	involves\tagSENT_CONTENT	tuples\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	(\tagSENT_CONTENT	d\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	,\tagSENT_CONTENT	C\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	dis\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	(\tagSENT_CONTENT	context\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	query\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	contents\tagSENT_CONTENT	of\tagSENT_CONTENT	d\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	is\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	placeholder\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	candidates\tagSENT_CONTENT	C.\tagSENT_END	Gated\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Reader\tagSECTITLE_END	In\tagSENT_START	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	ideally\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	carried\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	across\tagSENT_CONTENT	hops\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	design\tagSENT_CONTENT	of\tagSENT_CONTENT	gated\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	is\tagSENT_CONTENT	motivated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	multiplicative\tagSENT_CONTENT	interaction\tagSENT_CONTENT	among\tagSENT_CONTENT	vector\tagSENT_CONTENT	-\tagSENT_CONTENT	space\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	various\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	units\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Details\tagSECTITLE_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Hop\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	Gated\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Module\tagSECTITLE_END	Answer\tagSECTITLE_START	Prediction\tagSECTITLE_END	The\tagSENT_START	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	candidate\tagSENT_CONTENT	c\tagSENT_CONTENT	∈\tagSENT_CONTENT	C\tagSENT_CONTENT	as\tagSENT_CONTENT	being\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	then\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	aggregating\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	document\tagSENT_CONTENT	tokens\tagSENT_CONTENT	which\tagSENT_CONTENT	appear\tagSENT_CONTENT	inc\tagSENT_CONTENT	and\tagSENT_CONTENT	renormalizing\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	candidates\tagSENT_CONTENT	:\tagSENT_END	a\tagSENT_START	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	loss\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Further\tagSECTITLE_START	Enhancements\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Datasets\tagSECTITLE_END	question_answering\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	easily\tagSENT_CONTENT	answered\tagSENT_CONTENT	by\tagSENT_CONTENT	simple\tagSENT_CONTENT	baselines\tagSENT_CONTENT	are\tagSENT_CONTENT	filtered\tagSENT_CONTENT	out\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSECTITLE_START	Comparison\tagSECTITLE_END	Model\tagSECTITLE_START	Strict\tagSECTITLE_CONTENT	Relaxed\tagSECTITLE_END	Comparing\tagSENT_START	with\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WDW\tagSENT_CONTENT	dataset\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	GA\tagSENT_CONTENT	Reader\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	all\tagSENT_CONTENT	previously\tagSENT_CONTENT	published\tagSENT_CONTENT	models\tagSENT_CONTENT	when\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	GA\tagSECTITLE_START	Reader\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	This\tagSENT_START	model\tagSENT_CONTENT	ends\tagSENT_CONTENT	up\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	one\tagSENT_CONTENT	query\tagSENT_CONTENT	GRU\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	selecting\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	we\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	question_answering\tagtask	of\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	gate\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	document\tagSENT_CONTENT	reader\tagSENT_CONTENT	states\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	what\tagSENT_CONTENT	operation\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	in\tagSENT_CONTENT	equation\tagSENT_CONTENT	6\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Ablation\tagSECTITLE_START	Study\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Components\tagSECTITLE_END	Model\tagSECTITLE_START	Accuracy\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	WDW\tagSENT_CONTENT	,\tagSENT_CONTENT	NSE\tagSENT_CONTENT	,\tagSENT_CONTENT	also\tagSENT_CONTENT	uses\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	the\tagSENT_CONTENT	comparison\tagSENT_CONTENT	is\tagSENT_CONTENT	fair\tagSENT_CONTENT	in\tagSENT_CONTENT	that\tagSENT_CONTENT	respect\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSECTITLE_START	Visualization\tagSECTITLE_END	A\tagSENT_START	generic\tagSENT_CONTENT	pattern\tagSENT_CONTENT	observed\tagSENT_CONTENT	in\tagSENT_CONTENT	these\tagSENT_CONTENT	examples\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	candidates\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	(\tagSENT_CONTENT	shown\tagSENT_CONTENT	along\tagSENT_CONTENT	rows\tagSENT_CONTENT	)\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	pick\tagSENT_CONTENT	out\tagSENT_CONTENT	salient\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	which\tagSENT_CONTENT	provide\tagSENT_CONTENT	clues\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	cloze\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	layer\tagSENT_CONTENT	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	match\tagSENT_CONTENT	with\tagSENT_CONTENT	these\tagSENT_CONTENT	tokens\tagSENT_CONTENT	is\tagSENT_CONTENT	selected\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	Analysis\tagSENT_START	of\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	query\tagSENT_CONTENT	attentions\tagSENT_CONTENT	in\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	reader\tagSENT_CONTENT	further\tagSENT_CONTENT	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	iteratively\tagSENT_CONTENT	attends\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	to\tagSENT_CONTENT	arrive\tagSENT_CONTENT	at\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	
1707.09098	title\tagSECTITLE_END	MEMEN\tagmetric	:\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	Embedding\tagSENT_CONTENT	with\tagSENT_CONTENT	Memory\tagSENT_CONTENT	Networks\tagSENT_CONTENT	for\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Comprehension\tagSENT_END	abstract\tagSECTITLE_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	existing\tagSENT_CONTENT	attention\tagSENT_CONTENT	methods\tagSENT_CONTENT	represent\tagSENT_CONTENT	each\tagSENT_CONTENT	query\tagSENT_CONTENT	word\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	or\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	vector\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	query\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	neither\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	can\tagSENT_CONTENT	handle\tagSENT_CONTENT	the\tagSENT_CONTENT	proper\tagSENT_CONTENT	weight\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	query\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	memory\tagSENT_CONTENT	network\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	and\tagSENT_CONTENT	passage\tagSENT_CONTENT	to\tagSENT_CONTENT	catch\tagSENT_CONTENT	more\tagSENT_CONTENT	pivotal\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Its\tagSENT_START	task\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	teach\tagSENT_CONTENT	machine\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	content\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	related\tagSENT_CONTENT	to\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Many\tagSENT_START	significant\tagSENT_CONTENT	works\tagSENT_CONTENT	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	most\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	augmented\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	contrary\tagSENT_CONTENT	,\tagSENT_CONTENT	every\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	has\tagSENT_CONTENT	its\tagSENT_CONTENT	own\tagSENT_CONTENT	embedding\tagSENT_CONTENT	vector\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	situation\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	many\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	useless\tagSENT_CONTENT	even\tagSENT_CONTENT	if\tagSENT_CONTENT	disturbing\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	stopwords\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	three\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	useful\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	every\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	multilayer\tagSENT_CONTENT	memory\tagSENT_CONTENT	network\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	match\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	answer\tagSENT_CONTENT	boundary\tagSENT_CONTENT	prediction\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	get\tagSENT_CONTENT	the\tagSENT_CONTENT	location\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	analogy\tagSENT_CONTENT	inference\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	similar\tagSENT_CONTENT	attributes\tagSENT_CONTENT	close\tagSENT_CONTENT	in\tagSENT_CONTENT	their\tagSENT_CONTENT	embedding\tagSENT_CONTENT	space\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	more\tagSENT_CONTENT	adept\tagSENT_CONTENT	at\tagSENT_CONTENT	helping\tagSENT_CONTENT	find\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	To\tagSENT_START	combines\tagSENT_CONTENT	the\tagSENT_CONTENT	advantages\tagSENT_CONTENT	of\tagSENT_CONTENT	one\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	attention\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	novel\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	attention\tagSENT_CONTENT	vectors\tagSENT_CONTENT	contain\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	.\tagSENT_END	On\tagSENT_START	SQuAD\tagdataset	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	75.37\tagSENT_CONTENT	%\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	and\tagSENT_CONTENT	82.66\tagSENT_CONTENT	%\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Structure\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	several\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	contexts\tagSENT_CONTENT	and\tagSENT_CONTENT	pass\tagSENT_CONTENT	them\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	RNN\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Encoding\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Context\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Query\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	represent\tagSENT_CONTENT	all\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	pass\tagSENT_CONTENT	them\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Memory\tagSECTITLE_START	Network\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Full\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Orientation\tagSECTITLE_CONTENT	Matching\tagSECTITLE_END	Unlike\tagSENT_START	previous\tagSENT_CONTENT	methods\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	either\tagSENT_CONTENT	two\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	matching\tagSENT_CONTENT	or\tagSENT_CONTENT	one\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	matching\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	full\tagSENT_CONTENT	-\tagSENT_CONTENT	orientation\tagSENT_CONTENT	matching\tagSENT_CONTENT	layer\tagSENT_CONTENT	that\tagSENT_CONTENT	synthesizes\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	advantages\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	side\tagSENT_CONTENT	and\tagSENT_CONTENT	hedge\tagSENT_CONTENT	the\tagSENT_CONTENT	weakness\tagSENT_CONTENT	.\tagSENT_END	After\tagSENT_START	concatenating\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	pass\tagSENT_CONTENT	them\tagmetric	into\tagSENT_CONTENT	a\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	context\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	that\tagSENT_CONTENT	represents\tagSENT_CONTENT	how\tagSENT_CONTENT	much\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	every\tagSENT_CONTENT	query\tagSENT_CONTENT	word\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	f\tagmetric	is\tagSENT_CONTENT	an\tagSENT_CONTENT	simple\tagSENT_CONTENT	linear\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_CONTENT	M\tagmetric	1\tagSENT_CONTENT	and\tagSENT_CONTENT	M\tagmetric	3\tagSENT_CONTENT	are\tagSENT_CONTENT	matrixes\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	tiled\tagSENT_CONTENT	n\tagSENT_CONTENT	times\tagSENT_CONTENT	by\tagSENT_CONTENT	m\tagmetric	1\tagSENT_CONTENT	and\tagSENT_CONTENT	m\tagmetric	3\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	multiple\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	integrated\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	matching\tagSENT_CONTENT	module\tagSENT_CONTENT	M\tagmetric	can\tagSENT_CONTENT	be\tagSENT_CONTENT	regarded\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	{\tagSENT_CONTENT	r\tagSENT_CONTENT	Pt\tagSENT_CONTENT	}\tagSENT_CONTENT	n\tagSENT_CONTENT	t=1\tagSENT_CONTENT	of\tagSENT_CONTENT	next\tagSENT_CONTENT	layer\tagSENT_CONTENT	after\tagSENT_CONTENT	a\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	reduction\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	call\tagSENT_CONTENT	this\tagSENT_CONTENT	memory\tagSENT_CONTENT	networks\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Output\tagSECTITLE_START	layer\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	boundary\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	pointer\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	locate\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Then\tagSENT_START	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	representation\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	initialized\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	indices\tagSENT_CONTENT	that\tagSENT_CONTENT	represent\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	W\tagSENT_CONTENT	h\tagSENT_CONTENT	is\tagSENT_CONTENT	parameter\tagSENT_CONTENT	,\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	that\tagSENT_CONTENT	respectively\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	point\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	endpoint\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	O\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	that\tagSENT_CONTENT	represents\tagSENT_CONTENT	j\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Experiment\tagSECTITLE_END	Implementation\tagSECTITLE_START	Settings\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	use\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagger\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	tagger\tagSENT_CONTENT	in\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	CoreNLP\tagSENT_CONTENT	utilities\tagSENT_CONTENT	to\tagSENT_CONTENT	transform\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	TriviaQA\tagSECTITLE_START	Results\tagSECTITLE_END	TriviaQA\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	dataset\tagSENT_CONTENT	where\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	authored\tagSENT_CONTENT	by\tagSENT_CONTENT	trivia\tagSENT_CONTENT	enthusiasts\tagSENT_CONTENT	,\tagSENT_CONTENT	independently\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	evidence\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Because\tagSENT_START	the\tagSENT_CONTENT	evidence\tagSENT_CONTENT	is\tagSENT_CONTENT	gathered\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	automated\tagSENT_CONTENT	process\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	documents\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	guaranteed\tagSENT_CONTENT	to\tagSENT_CONTENT	contain\tagSENT_CONTENT	all\tagSENT_CONTENT	facts\tagSENT_CONTENT	needed\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	SQuAD\tagSECTITLE_START	Results\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	use\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	v1.1\tagSENT_CONTENT	to\tagSENT_CONTENT	conduct\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Ensemble\tagSECTITLE_START	Details\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	current\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	is\tagSENT_CONTENT	simply\tagSENT_CONTENT	choosing\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	confidence\tagSENT_CONTENT	scores\tagSENT_CONTENT	among\tagSENT_CONTENT	several\tagSENT_CONTENT	single\tagSENT_CONTENT	models\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	exactly\tagSENT_CONTENT	identical\tagSENT_CONTENT	except\tagSENT_CONTENT	the\tagSENT_CONTENT	random\tagSENT_CONTENT	initial\tagSENT_CONTENT	seed\tagSENT_CONTENT	.\tagSENT_END	Speed\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Efficiency\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	EM\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagmetric	score\tagSENT_CONTENT	increase\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	hops\tagSENT_CONTENT	enlarges\tagSENT_CONTENT	until\tagSENT_CONTENT	it\tagSENT_CONTENT	arrives\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	Hops\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Ablations\tagSECTITLE_END	For\tagSENT_START	context\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	similarity\tagSENT_CONTENT	matching\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	simply\tagSENT_CONTENT	took\tagSENT_CONTENT	out\tagSENT_CONTENT	the\tagmetric	M\tagmetric	3\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	linear\tagSENT_CONTENT	function\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	proved\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	contributory\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Recently\tagSENT_START	,\tagSENT_CONTENT	released\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	almost\tagSENT_CONTENT	two\tagSENT_CONTENT	orders\tagSENT_CONTENT	of\tagSENT_CONTENT	magnitude\tagSENT_CONTENT	larger\tagSENT_CONTENT	than\tagSENT_CONTENT	all\tagSENT_CONTENT	previous\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	annotated\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSECTITLE_START	Based\tagSECTITLE_CONTENT	Models\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Machine\tagSECTITLE_CONTENT	Reading\tagSECTITLE_END	present\tagSENT_START	a\tagSENT_CONTENT	coattention\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	locate\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	MEMEN\tagmetric	for\tagSENT_CONTENT	Machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	style\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	multilayer\tagSENT_CONTENT	embedding\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	network\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	interaction\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	query\tagSENT_CONTENT	.\tagSENT_END	
S18-1150	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Hypernymy\tagSENT_START	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	lexical\tagSENT_CONTENT	-\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relation\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	applications\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	soon\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Path\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_END	Approaches\tagSENT_START	based\tagSENT_CONTENT	on\tagSENT_CONTENT	taxonomy_learning\tagtask	of\tagSENT_CONTENT	patterns\tagSENT_CONTENT	achieve\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	precision\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	considerable\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	limitation\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	approaches\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sparsity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	space\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Distributional\tagSECTITLE_END	Combined\tagSECTITLE_START	Approaches\tagSECTITLE_END	System\tagSECTITLE_START	Description\tagSECTITLE_END	Candidate\tagSECTITLE_START	Hypernyms\tagSECTITLE_END	Feature\tagSECTITLE_START	Vector\tagSECTITLE_END	HR\tagSECTITLE_START	=\tagSECTITLE_END	Model\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Hypernym\tagSECTITLE_CONTENT	Discovery\tagSECTITLE_END	To\tagSENT_START	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	categories\tagSENT_CONTENT	(\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	and\tagSENT_CONTENT	not\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	improved\tagSENT_CONTENT	this\tagSENT_CONTENT	ratio\tagSENT_CONTENT	to\tagSENT_CONTENT	0.2\tagSENT_CONTENT	by\tagSENT_CONTENT	taxonomy_learning\tagtask	of\tagSENT_CONTENT	not\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	instances\tagSENT_CONTENT	(\tagSENT_CONTENT	20\tagSENT_CONTENT	%\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	instances\tagSENT_CONTENT	and\tagSENT_CONTENT	80\tagSENT_CONTENT	%\tagSENT_CONTENT	not\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	instances\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
C18-1146	title\tagSECTITLE_END	Structure\tagSENT_START	-\tagSENT_CONTENT	Infused\tagSENT_CONTENT	Copy\tagSENT_CONTENT	Mechanisms\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	Seq2seq\tagSENT_START	learning\tagSENT_CONTENT	has\tagSENT_CONTENT	produced\tagSENT_CONTENT	promising\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Recent\tagSENT_START	years\tagSENT_CONTENT	have\tagSENT_CONTENT	witnessed\tagSENT_CONTENT	increasing\tagSENT_CONTENT	interest\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	System\tagSENT_START	summaries\tagSENT_CONTENT	fail\tagSENT_CONTENT	to\tagSENT_CONTENT	preserve\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	main\tagSENT_CONTENT	verbs\tagSENT_CONTENT	)\tagSENT_CONTENT	despite\tagSENT_CONTENT	their\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	importance\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	learning\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	has\tagSENT_CONTENT	achieved\tagSENT_CONTENT	remarkable\tagSENT_CONTENT	success\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	seek\tagSENT_CONTENT	to\tagSENT_CONTENT	address\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	by\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	source\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	structure\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	help\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	identify\tagSENT_CONTENT	summary\tagSENT_CONTENT	-\tagSENT_CONTENT	worthy\tagSENT_CONTENT	content\tagSENT_CONTENT	and\tagSENT_CONTENT	compose\tagSENT_CONTENT	summaries\tagSENT_CONTENT	that\tagSENT_CONTENT	preserve\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	we\tagSENT_START	introduce\tagSENT_CONTENT	novel\tagSENT_CONTENT	neural\tagSENT_CONTENT	architectures\tagSENT_CONTENT	that\tagSENT_CONTENT	encourage\tagSENT_CONTENT	salient\tagSENT_CONTENT	source\tagSENT_CONTENT	words\tagSENT_CONTENT	/\tagSENT_CONTENT	relations\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	preserved\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	we\tagSENT_START	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	effective\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Prior\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	era\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	structure\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	utilized\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	an\tagSENT_CONTENT	"\tagSENT_CONTENT	extract\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	-\tagSENT_CONTENT	compress\tagSENT_CONTENT	"\tagSENT_CONTENT	framework\tagSENT_CONTENT	.\tagSENT_END	Natural\tagSENT_START	language\tagSENT_CONTENT	generation\tagSENT_CONTENT	(\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	also\tagSENT_CONTENT	makes\tagSENT_CONTENT	extensive\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	structural\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	/\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	,\tagSENT_CONTENT	discourse\tagSENT_CONTENT	structures\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	domainspecific\tagSENT_CONTENT	templates\tagSENT_CONTENT	built\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	planner\tagSENT_CONTENT	or\tagSENT_CONTENT	an\tagSENT_CONTENT	OpenIE\tagSENT_CONTENT	system\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Approach\tagSECTITLE_END	We\tagSENT_START	seek\tagSENT_CONTENT	to\tagSENT_CONTENT	transform\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	x\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	y\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	concise\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	preserves\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Basic\tagSECTITLE_CONTENT	Framework\tagSECTITLE_END	embeddings\tagSENT_START	of\tagSENT_CONTENT	system\tagSENT_CONTENT	predicted\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	teacher\tagSENT_CONTENT	forcing\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	expands\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	space\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	include\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	switch\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	layer\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Structure\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Infused\tagSECTITLE_CONTENT	Copy\tagSECTITLE_CONTENT	Mechanisms\tagSECTITLE_END	Inspired\tagSENT_START	by\tagSENT_CONTENT	summarization\tagtask	via\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	hypothesize\tagSENT_CONTENT	that\tagSENT_CONTENT	structural\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	incoming\tagSENT_CONTENT	dependency\tagSENT_CONTENT	arc\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	depth\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parse\tagSENT_CONTENT	tree\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	helpful\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	word\tagSENT_CONTENT	importance\tagSENT_CONTENT	.\tagSENT_END	Shallow\tagSECTITLE_START	Combination\tagSECTITLE_END	•\tagSENT_START	Struct+Input\tagSENT_CONTENT	concatenates\tagSENT_CONTENT	structural\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	i\tagSENT_CONTENT	(\tagSENT_CONTENT	flattened\tagSENT_CONTENT	into\tagSENT_CONTENT	one\tagSENT_CONTENT	vector\tagSENT_CONTENT	s\tagSENT_END	The\tagSENT_START	above\tagSENT_CONTENT	models\tagSENT_CONTENT	complement\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	semantic\tagSENT_CONTENT	and\tagSENT_CONTENT	structural\tagSENT_CONTENT	signals\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	2-Way\tagSECTITLE_START	Combination\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	+\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	)\tagSECTITLE_END	2-Way\tagSECTITLE_START	Combination\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	+\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Because\tagSENT_START	summarization\tagtask	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	assume\tagSENT_CONTENT	selecting\tagSENT_CONTENT	a\tagSENT_CONTENT	source\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	including\tagSENT_CONTENT	it\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	has\tagSENT_CONTENT	an\tagSENT_CONTENT	impact\tagSENT_CONTENT	on\tagSENT_CONTENT	its\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	source\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	the\tagSENT_CONTENT	reverse\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	calculation\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	probabilities\tagSENT_CONTENT	P\tagSENT_CONTENT	vocab\tagSENT_CONTENT	(\tagSENT_CONTENT	w\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	switch\tagSENT_CONTENT	value\tagSENT_CONTENT	p\tagSENT_CONTENT	gen\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	for\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	word\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	w\tagSENT_CONTENT	)\tagSENT_CONTENT	remains\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	as\tagSENT_CONTENT	previously\tagSENT_CONTENT	(\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_START	Objective\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Beam\tagSECTITLE_CONTENT	Search\tagSECTITLE_END	We\tagSENT_START	want\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	techniques\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	not\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	in\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	α\tagSENT_CONTENT	matrix\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	summary\tagSENT_CONTENT	sequences\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	structure\tagSENT_CONTENT	-\tagSENT_CONTENT	infused\tagSENT_CONTENT	copy\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	this\tagSENT_CONTENT	section\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Sets\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	dataset\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	input\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	frequent\tagSENT_CONTENT	70\tagSENT_CONTENT	K\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	texts\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Parameter\tagSENT_START	settings\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	ROUGE\tagmetric	results\tagSENT_CONTENT	on\tagSENT_CONTENT	valid\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	ROUGE\tagmetric	results\tagSENT_CONTENT	on\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	ABS\tagSENT_START	and\tagSENT_CONTENT	ABS+\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	work\tagSENT_CONTENT	introducing\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	To\tagSENT_START	further\tagSENT_CONTENT	gauge\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	quality\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	hire\tagSENT_CONTENT	human\tagSENT_CONTENT	workers\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	Mechanical\tagSENT_CONTENT	Turk\tagSENT_CONTENT	platform\tagSENT_CONTENT	to\tagSENT_CONTENT	rate\tagSENT_CONTENT	summarization\tagtask	on\tagSENT_CONTENT	a\tagSENT_CONTENT	Likert\tagSENT_CONTENT	scale\tagSENT_CONTENT	of\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	three\tagSENT_CONTENT	criteria\tagSENT_CONTENT	(\tagSENT_CONTENT	Zhang\tagSENT_CONTENT	and\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	,\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_END	We\tagSENT_START	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	dependency\tagSENT_CONTENT	relations\tagSENT_CONTENT	preserved\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	impact\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigated\tagSENT_CONTENT	structure\tagSENT_CONTENT	-\tagSENT_CONTENT	infused\tagSENT_CONTENT	copy\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	that\tagSENT_CONTENT	combine\tagSENT_CONTENT	source\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	structure\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	copy\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
1801.00102	title\tagSECTITLE_END	Compare\tagSENT_START	,\tagSENT_CONTENT	Compress\tagSENT_CONTENT	and\tagSENT_CONTENT	Propagate\tagSENT_CONTENT	:\tagSENT_CONTENT	Enhancing\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Architectures\tagSENT_CONTENT	with\tagSENT_CONTENT	Alignment\tagSENT_CONTENT	Factorization\tagSENT_CONTENT	for\tagSENT_CONTENT	natural_language_inference\tagtask	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	presents\tagSENT_CONTENT	anew\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	natural_language_inference\tagtask	(\tagSENT_CONTENT	NLI\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	conduct\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	popular\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	,\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	,\tagSENT_CONTENT	MultiNLI\tagSENT_CONTENT	and\tagSENT_CONTENT	SciTail\tagdataset	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	competitive\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	natural_language_inference\tagtask	(\tagSENT_CONTENT	NLI\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	pivotal\tagSENT_CONTENT	and\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	natural_language_inference\tagtask	and\tagSENT_CONTENT	artificial\tagSENT_CONTENT	intelligence\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	a\tagSENT_CONTENT	steep\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	NLI\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	largely\tagSENT_CONTENT	contributed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	release\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	largest\tagSENT_CONTENT	publicly\tagSENT_CONTENT	available\tagSENT_CONTENT	corpus\tagSENT_CONTENT	for\tagSENT_CONTENT	natural_language_inference\tagtask	)\tagSENT_CONTENT	which\tagSENT_CONTENT	comprises\tagSENT_CONTENT	570\tagSENT_CONTENT	K\tagSENT_CONTENT	hand\tagSENT_CONTENT	labeled\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	natural_language_inference\tagtask	here\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	ESIM\tagSENT_CONTENT	considers\tagSENT_CONTENT	a\tagSENT_CONTENT	nonparameterized\tagSENT_CONTENT	comparison\tagSENT_CONTENT	scheme\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	the\tagSENT_CONTENT	subtraction\tagSENT_CONTENT	and\tagSENT_CONTENT	element\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	product\tagSENT_CONTENT	of\tagSENT_CONTENT	aligned\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	original\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	comparison\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	natural_language_inference\tagtask	(\tagSENT_CONTENT	or\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	recognition\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	along\tagSENT_CONTENT	standing\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	research\tagSENT_CONTENT	,\tagSENT_CONTENT	typically\tagSENT_CONTENT	carried\tagSENT_CONTENT	out\tagSENT_CONTENT	on\tagSENT_CONTENT	smaller\tagSENT_CONTENT	datasets\tagSENT_CONTENT	using\tagSENT_CONTENT	traditional\tagSENT_CONTENT	methods\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	DGEM\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	based\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	proposed\tagSENT_CONTENT	together\tagSENT_CONTENT	with\tagSENT_CONTENT	anew\tagSENT_CONTENT	entailment\tagSENT_CONTENT	challenge\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	SciTail\tagdataset	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	contextualized\tagSENT_CONTENT	vectors\tagSENT_CONTENT	learned\tagSENT_CONTENT	from\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	natural_language_inference\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	ELMo\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	showned\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	performance\tagSENT_CONTENT	when\tagSENT_CONTENT	integrated\tagSENT_CONTENT	with\tagSENT_CONTENT	existing\tagSENT_CONTENT	NLI\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Input\tagSECTITLE_START	Encoding\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Soft\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Alignment\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Inter\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Alignment\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Alignment\tagSECTITLE_START	Factorization\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Factorization\tagSECTITLE_START	Operation\tagSECTITLE_END	Propagation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Augmentation\tagSECTITLE_END	Sequential\tagSECTITLE_START	Encoder\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Prediction\tagSECTITLE_START	Layer\tagSECTITLE_END	Experiments\tagSECTITLE_END	Model\tagSECTITLE_END	89.3\tagSECTITLE_START	External\tagSECTITLE_CONTENT	Resource\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	88.7\tagSECTITLE_START	200D\tagSECTITLE_CONTENT	CAFE\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	AVGMAX\tagSECTITLE_CONTENT	+\tagSECTITLE_CONTENT	200D\tagSECTITLE_CONTENT	MLP\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	+\tagSECTITLE_CONTENT	ELMo\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Notably\tagSENT_START	,\tagSENT_CONTENT	SciTail\tagdataset	is\tagSENT_CONTENT	known\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	difficult\tagSENT_CONTENT	dataset\tagSENT_CONTENT	for\tagSENT_CONTENT	NLI\tagSENT_CONTENT	,\tagSENT_CONTENT	made\tagSENT_CONTENT	evident\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagmetric	low\tagmetric	accuracy\tagmetric	scores\tagmetric	even\tagSENT_CONTENT	though\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	binary\tagSENT_CONTENT	in\tagSENT_CONTENT	nature\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagmetric	test\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	CAFE\tagSENT_CONTENT	at\tagSENT_CONTENT	different\tagSENT_CONTENT	extents\tagSENT_CONTENT	of\tagSENT_CONTENT	parameterization\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	varying\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	encoder\tagSENT_CONTENT	,\tagSENT_CONTENT	width\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	softmax\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	and\tagSENT_CONTENT	final\tagSENT_CONTENT	pooling\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	CAFE\tagSENT_START	obtains\tagSENT_CONTENT	88.5\tagmetric	%\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	an\tagSENT_CONTENT	extremely\tagSENT_CONTENT	competitive\tagSENT_CONTENT	score\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	extremely\tagSENT_CONTENT	popular\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	CAFE\tagSENT_CONTENT	also\tagSENT_CONTENT	achieves\tagSENT_CONTENT	88.3\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	88.1\tagmetric	%\tagmetric	test\tagmetric	accuracy\tagmetric	with\tagSENT_CONTENT	only\tagSENT_CONTENT	3.5\tagSENT_CONTENT	M\tagSENT_CONTENT	and\tagSENT_CONTENT	1.5\tagSENT_CONTENT	M\tagSENT_CONTENT	parameters\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	an\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	5\tagSENT_CONTENT	CAFE\tagSENT_CONTENT	models\tagSENT_CONTENT	achieves\tagSENT_CONTENT	89.3\tagmetric	%\tagmetric	test\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	test\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	to\tagSENT_CONTENT	date\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	SciTail\tagdataset	,\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	CAFE\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	performance\tagSENT_CONTENT	gain\tagSENT_CONTENT	over\tagSENT_CONTENT	strong\tagSENT_CONTENT	baselines\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	DecompAtt\tagSENT_CONTENT	and\tagSENT_CONTENT	ESIM\tagSENT_CONTENT	are\tagSENT_CONTENT	≈\tagSENT_CONTENT	10\tagSENT_CONTENT	%\tagSENT_CONTENT	−\tagSENT_CONTENT	13\tagSENT_CONTENT	%\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	MultiNLI\tagSECTITLE_END	Ablation\tagSECTITLE_START	Study\tagSECTITLE_END	Linguistic\tagSECTITLE_START	Error\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Interpreting\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Visualizing\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	CAFE\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
P16-1200	title\tagSECTITLE_END	relationship_extraction\tagtask	with\tagSENT_CONTENT	Selective\tagSENT_CONTENT	Attention\tagSENT_CONTENT	over\tagSENT_CONTENT	Instances\tagSENT_END	abstract\tagSECTITLE_END	relationship_extraction\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	novel\tagSENT_CONTENT	relational\tagSENT_CONTENT	facts\tagSENT_CONTENT	from\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	These\tagSENT_START	KBs\tagSENT_CONTENT	mostly\tagSENT_CONTENT	compose\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	triple\tagSENT_CONTENT	format\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	existing\tagSENT_CONTENT	supervised\tagSENT_CONTENT	RE\tagSENT_CONTENT	systems\tagSENT_CONTENT	require\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	time\tagSENT_CONTENT	consuming\tagSENT_CONTENT	and\tagSENT_CONTENT	labor\tagSENT_CONTENT	intensive\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	recent\tagSENT_CONTENT	works\tagSENT_CONTENT	)\tagSENT_CONTENT	attempt\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	without\tagSENT_CONTENT	handcrafted\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	As\tagSENT_START	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	full\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	informative\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	selective\tagSENT_CONTENT	attention\tagSENT_CONTENT	is\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	two\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	has\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	(\tagSENT_CONTENT	dos\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	these\tagSENT_CONTENT	methods\tagSENT_CONTENT	achieve\tagSENT_CONTENT	great\tagSENT_CONTENT	success\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	still\tagSENT_CONTENT	extract\tagSENT_CONTENT	relationship_extraction\tagtask	on\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	and\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	alack\tagSENT_CONTENT	of\tagSENT_CONTENT	sufficient\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	various\tagSENT_CONTENT	areas\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	image\tagSENT_CONTENT	classification\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Methodology\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	{\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	n\tagSENT_CONTENT	}\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	Sentence\tagSECTITLE_START	Encoder\tagSECTITLE_END	Input\tagSECTITLE_START	Representation\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	informative\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Convolution\tagSECTITLE_START	,\tagSECTITLE_CONTENT	Max\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	pooling\tagSECTITLE_CONTENT	and\tagSECTITLE_END	Non\tagSENT_START	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	Layers\tagSENT_CONTENT	In\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	challenges\tagSENT_CONTENT	are\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	is\tagSENT_CONTENT	variable\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	can\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	any\tagSENT_CONTENT	area\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	,\tagSENT_CONTENT	convolution\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	sequence\tagSENT_CONTENT	wand\tagSENT_CONTENT	a\tagSENT_CONTENT	convolution\tagSENT_CONTENT	matrix\tagSENT_CONTENT	W\tagSENT_CONTENT	∈\tagSENT_END	Further\tagSENT_START	,\tagSENT_CONTENT	PCNN\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	variation\tagSENT_CONTENT	of\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	adopts\tagSENT_CONTENT	piecewise\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Selective\tagSECTITLE_START	Attention\tagSECTITLE_CONTENT	over\tagSECTITLE_CONTENT	Instances\tagSECTITLE_END	To\tagSENT_START	exploit\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	S\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	real\tagSENT_CONTENT	-\tagSENT_CONTENT	valued\tagSENT_CONTENT	vector\tagSENT_CONTENT	s\tagSENT_CONTENT	when\tagSENT_CONTENT	predicting\tagSENT_CONTENT	relationship_extraction\tagtask	where\tagSENT_START	A\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	weighted\tagSENT_CONTENT	diagonal\tagSENT_CONTENT	matrix\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	r\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	vector\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	which\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	relation\tagSENT_END	where\tagSENT_START	n\tagSENT_CONTENT	r\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	o\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	which\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	scores\tagSENT_CONTENT	associated\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	d\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	nr\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	bias\tagSENT_CONTENT	vector\tagSENT_CONTENT	and\tagSENT_CONTENT	M\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	matrix\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	follows\tagSENT_CONTENT	the\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	will\tagSENT_CONTENT	reflect\tagSENT_CONTENT	their\tagSENT_CONTENT	relation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	only\tagSENT_CONTENT	uses\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	probability\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Optimization\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Implementation\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	dropout\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	prevent\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	the\tagSENT_CONTENT	scaled\tagSENT_CONTENT	set\tagSENT_CONTENT	vectorˆrvectorˆvectorˆr\tagSENT_CONTENT	i\tagSENT_CONTENT	is\tagSENT_CONTENT	finally\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	are\tagSENT_CONTENT	intended\tagSENT_CONTENT	to\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	selective\tagSENT_CONTENT	attention\tagSENT_CONTENT	can\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	the\tagSENT_CONTENT	wrong\tagSENT_CONTENT	labelling\tagSENT_CONTENT	problem\tagSENT_CONTENT	and\tagSENT_CONTENT	take\tagSENT_CONTENT	full\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	informative\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metrics\tagSECTITLE_END	This\tagSENT_START	dataset\tagSENT_CONTENT	was\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	aligning\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	New\tagSENT_CONTENT	York\tagSENT_CONTENT	Times\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	NYT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	evaluates\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	comparing\tagSENT_CONTENT	relationship_extraction\tagtask	discovered\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	articles\tagSENT_CONTENT	with\tagSENT_CONTENT	those\tagSENT_CONTENT	in\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Settings\tagSECTITLE_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	Parameter\tagSECTITLE_START	Settings\tagSECTITLE_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Selective\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	It\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	the\tagSENT_CONTENT	AVE\tagSENT_CONTENT	method\tagSENT_CONTENT	brings\tagSENT_CONTENT	in\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	more\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	regards\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	equally\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	also\tagSENT_CONTENT	brings\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	noise\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	wrong\tagSENT_CONTENT	labelling\tagSENT_CONTENT	sentences\tagSENT_CONTENT	which\tagSENT_CONTENT	may\tagSENT_CONTENT	hurt\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Number\tagSECTITLE_END	:\tagSENT_START	For\tagSENT_CONTENT	each\tagSENT_CONTENT	testing\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	randomly\tagSENT_CONTENT	select\tagSENT_CONTENT	one\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	this\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	•\tagSENT_START	Two\tagSENT_CONTENT	:\tagSENT_CONTENT	For\tagSENT_CONTENT	each\tagSENT_CONTENT	testing\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	randomly\tagSENT_CONTENT	select\tagSENT_CONTENT	two\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	proceed\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	All\tagSENT_START	:\tagSENT_CONTENT	We\tagSENT_CONTENT	use\tagSENT_CONTENT	all\tagSENT_CONTENT	sentences\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	pair\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	reason\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	regard\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	equally\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	noise\tagSENT_CONTENT	contained\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	express\tagSENT_CONTENT	relationship_extraction\tagtask	will\tagSENT_CONTENT	have\tagSENT_CONTENT	negative\tagSENT_CONTENT	influence\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	relation\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Approaches\tagSECTITLE_END	Case\tagSECTITLE_START	Study\tagSECTITLE_END	The\tagSENT_START	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	low\tagSENT_CONTENT	attention\tagSENT_CONTENT	weight\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	express\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	high\tagSENT_CONTENT	one\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	Mel\tagSENT_CONTENT	Karmazin\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	chief\tagSENT_CONTENT	executive\tagSENT_CONTENT	of\tagSENT_CONTENT	Sirius\tagSENT_CONTENT	Satellite\tagSENT_CONTENT	Radio\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Works\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	full\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	informative\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	the\tagSENT_CONTENT	wrong\tagSENT_CONTENT	labelling\tagSENT_CONTENT	problem\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	It\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	but\tagSENT_CONTENT	also\tagSENT_CONTENT	other\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	instance\tagSENT_CONTENT	learning\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	CNN\tagSENT_CONTENT	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	effective\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	
N09-1009	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	then\tagSENT_CONTENT	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	show\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvements\tagSENT_CONTENT	using\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	bilingual\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	parallel\tagSENT_CONTENT	,\tagSENT_CONTENT	multilingual\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	§\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	give\tagSENT_CONTENT	a\tagSENT_CONTENT	brief\tagSENT_CONTENT	explanation\tagSENT_CONTENT	of\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	grammars\tagSENT_CONTENT	and\tagSENT_CONTENT	introduce\tagSENT_CONTENT	some\tagSENT_CONTENT	notation\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	specific\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	used\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	Probabilistic\tagSECTITLE_START	Grammars\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Grammar\tagSECTITLE_CONTENT	Induction\tagSECTITLE_END	Dependency\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Valence\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	dependency_parsing\tagtask	with\tagSENT_CONTENT	valence\tagSENT_CONTENT	"\tagSENT_CONTENT	(\tagSENT_CONTENT	DMV\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	=\tagSENT_START	$\tagSENT_CONTENT	:\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	except\tagSENT_CONTENT	$\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	parent\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	no\tagSENT_CONTENT	cycles\tagSENT_CONTENT	or\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Learning\tagSECTITLE_START	DMV\tagSECTITLE_END	Parameter\tagSECTITLE_START	Tying\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Bayesian\tagSECTITLE_CONTENT	Setting\tagSECTITLE_END	Logistic\tagSECTITLE_START	Normal\tagSECTITLE_CONTENT	Distributions\tagSECTITLE_END	Generating\tagSENT_START	from\tagSENT_CONTENT	PLN\tagSENT_CONTENT	involves\tagSENT_CONTENT	drawing\tagSENT_CONTENT	a\tagSENT_CONTENT	random\tagSENT_CONTENT	vector\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	multivariate\tagSENT_CONTENT	normal\tagSENT_CONTENT	distribution\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	logistic\tagSENT_CONTENT	transformation\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	vector\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	sampled\tagSENT_CONTENT	multinomial\tagSENT_CONTENT	distributions\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	required\tagSENT_CONTENT	lengths\tagSENT_CONTENT	from\tagSENT_CONTENT	different\tagSENT_CONTENT	probability\tagSENT_CONTENT	simplices\tagSENT_CONTENT	.\tagSENT_END	Shared\tagSECTITLE_START	Logistic\tagSECTITLE_CONTENT	Normal\tagSECTITLE_CONTENT	Distributions\tagSECTITLE_END	Inference\tagSECTITLE_END	Exact\tagSENT_START	MAP\tagSENT_CONTENT	estimation\tagSENT_CONTENT	is\tagSENT_CONTENT	probably\tagSENT_CONTENT	not\tagSENT_CONTENT	feasible\tagSENT_CONTENT	;\tagSENT_CONTENT	a\tagSENT_CONTENT	variational\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	like\tagSENT_CONTENT	ours\tagmetric	might\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	,\tagSENT_CONTENT	though\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	is\tagSENT_CONTENT	expected\tagSENT_CONTENT	from\tagSENT_CONTENT	adjusting\tagSENT_CONTENT	the\tagSENT_CONTENT	SLN\tagSENT_CONTENT	to\tagSENT_CONTENT	fit\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	In\tagSENT_START	both\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	standard\tagSENT_CONTENT	practice\tagSENT_CONTENT	,\tagSENT_CONTENT	sentences\tagSENT_CONTENT	were\tagSENT_CONTENT	stripped\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	punctuation\tagSENT_CONTENT	,\tagSENT_CONTENT	leaving\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tags\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	induction\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	[\tagSENT_START	(\tagSENT_CONTENT	y\tagSENT_CONTENT	;\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	]\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSENT_START	with\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	consistently\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	its\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	counterpart\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	only\tagSENT_CONTENT	performance\tagSENT_CONTENT	with\tagSENT_CONTENT	MBR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	Nouns\tagSECTITLE_START	,\tagSECTITLE_CONTENT	Verbs\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Adjectives\tagSECTITLE_END	The\tagSENT_START	covariance\tagSENT_CONTENT	matrices\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	were\tagSENT_CONTENT	initialized\tagSENT_CONTENT	with\tagSENT_CONTENT	1\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	diagonal\tagSENT_CONTENT	,\tagSENT_CONTENT	0.5\tagSENT_CONTENT	between\tagSENT_CONTENT	tags\tagmetric	which\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	family\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	0\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	.\tagSENT_END	Monolingual\tagSECTITLE_START	Experiments\tagSECTITLE_END	Bilingual\tagSECTITLE_START	Experiments\tagSECTITLE_END	Future\tagSECTITLE_START	Work\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
C16-1007	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	CATENA\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	sieve\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	classification\tagSENT_CONTENT	from\tagSENT_CONTENT	English\tagSENT_CONTENT	texts\tagSENT_CONTENT	,\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	causal\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	causal\tagSENT_CONTENT	relations\tagSENT_CONTENT	are\tagSENT_CONTENT	much\tagSENT_CONTENT	sparser\tagSENT_CONTENT	than\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	architecture\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	selected\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	mostly\tagSENT_CONTENT	suitable\tagSENT_CONTENT	to\tagSENT_CONTENT	serve\tagSENT_CONTENT	both\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	effects\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	causal\tagSENT_CONTENT	components\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	limited\tagSENT_CONTENT	,\tagSENT_CONTENT	yield\tagSENT_CONTENT	promising\tagSENT_CONTENT	results\tagSENT_CONTENT	and\tagSENT_CONTENT	confirm\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	causal\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_START	architecture\tagSECTITLE_END	The\tagSENT_START	output\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	document\tagSENT_CONTENT	with\tagSENT_CONTENT	temporal\tagSENT_CONTENT	links\tagSENT_CONTENT	(\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	)\tagSENT_CONTENT	set\tagSENT_CONTENT	between\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	BEFORE\tagSENT_CONTENT	,\tagSENT_CONTENT	INCLUDES\tagSENT_CONTENT	or\tagSENT_CONTENT	SIMULTANEOUS\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	denotes\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	modules\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	rely\tagSENT_CONTENT	both\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	sieve\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	architecture\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	unlabelled\tagSENT_CONTENT	pairs\tagSENT_CONTENT	-after\tagSENT_END	Although\tagSENT_START	some\tagSENT_CONTENT	steps\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	run\tagSENT_CONTENT	in\tagSENT_CONTENT	parallel\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	modules\tagSENT_CONTENT	interact\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	causality\tagSENT_CONTENT	is\tagSENT_CONTENT	tightly\tagSENT_CONTENT	connected\tagSENT_CONTENT	with\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	that\tagSENT_CONTENT	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	one\tagSENT_CONTENT	module\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	or\tagSENT_CONTENT	check\tagSENT_CONTENT	the\tagSENT_CONTENT	consistency\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	TLINK\tagSENT_CONTENT	labels\tagSENT_CONTENT	for\tagSENT_CONTENT	event\tagSENT_CONTENT	-\tagSENT_CONTENT	event\tagSENT_CONTENT	(\tagSENT_CONTENT	E\tagSENT_CONTENT	-\tagSENT_CONTENT	E\tagSENT_CONTENT	)\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sieve\tagSENT_CONTENT	+\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	CLINK\tagSENT_CONTENT	classifier\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_END	This\tagSENT_START	step\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	rules\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	causality\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_END	The\tagSENT_START	modules\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	detailed\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Temporal\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_CONTENT	System\tagSECTITLE_END	The\tagSENT_START	module\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	contains\tagSENT_CONTENT	two\tagSENT_CONTENT	main\tagSENT_CONTENT	components\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	for\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	and\tagSENT_CONTENT	supervised\tagSENT_CONTENT	classification\tagSENT_CONTENT	modules\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	between\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	three\tagSENT_CONTENT	steps\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	ordered\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	individual\tagSENT_CONTENT	precisions\tagSENT_CONTENT	.\tagSENT_END	Temporal\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Identification\tagSECTITLE_END	All\tagSENT_START	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	satisfying\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	rules\tagSENT_CONTENT	,\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	TempEval-3\tagSENT_CONTENT	task\tagSENT_CONTENT	description\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	considered\tagSENT_CONTENT	as\tagSENT_CONTENT	having\tagSENT_CONTENT	temporal\tagSENT_CONTENT	links\tagSENT_CONTENT	(\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_END	Temporal\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Type\tagSECTITLE_CONTENT	Classification\tagSECTITLE_END	Instead\tagSENT_START	of\tagSENT_CONTENT	running\tagSENT_CONTENT	transitive\tagSENT_CONTENT	inference\tagSENT_CONTENT	after\tagSENT_CONTENT	each\tagSENT_CONTENT	classifier\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	run\tagSENT_CONTENT	temporal_information_extraction\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sieve\tagSENT_CONTENT	,\tagSENT_CONTENT	only\tagSENT_CONTENT	once\tagSENT_CONTENT	.\tagSENT_END	Temporal\tagSECTITLE_START	Rule\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Sieve\tagSECTITLE_END	The\tagSENT_START	temporal\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sieve\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	specific\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	rules\tagSENT_CONTENT	designed\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	takes\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	pairs\tagSENT_CONTENT	identified\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	we\tagSENT_CONTENT	take\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	types\tagSENT_CONTENT	DATE\tagSENT_CONTENT	and\tagSENT_CONTENT	TIME\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	normalized\tagSENT_CONTENT	values\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	we\tagSENT_CONTENT	assign\tagSENT_CONTENT	a\tagSENT_CONTENT	label\tagSENT_CONTENT	whenever\tagSENT_CONTENT	temporal_information_extraction\tagtask	establishes\tagSENT_CONTENT	a\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	between\tagSENT_CONTENT	an\tagSENT_CONTENT	event\tagSENT_CONTENT	(\tagSENT_CONTENT	E\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	timex\tagSENT_CONTENT	(\tagSENT_CONTENT	T\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	T\tagSENT_CONTENT	acts\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	modifier\tagSENT_CONTENT	of\tagSENT_CONTENT	E.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	T\tagSENT_CONTENT	is\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	temporal_information_extraction\tagtask	expressing\tagSENT_CONTENT	a\tagSENT_CONTENT	STARTTIME\tagSENT_CONTENT	sense\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	from\tagSENT_CONTENT	or\tagSENT_CONTENT	since\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	is\tagSENT_CONTENT	labelled\tagSENT_CONTENT	as\tagSENT_CONTENT	BEGUN\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	absence\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	T\tagSENT_CONTENT	might\tagSENT_CONTENT	simply\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	temporal\tagSENT_CONTENT	modifier\tagSENT_CONTENT	of\tagSENT_CONTENT	E\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	exemplified\tagSENT_CONTENT	in\tagSENT_CONTENT	"\tagSENT_CONTENT	Police\tagSENT_CONTENT	ET\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	body\tagSENT_CONTENT	was\tagSENT_CONTENT	found\tagSENT_CONTENT	...\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	events\tagSENT_CONTENT	are\tagSENT_CONTENT	modified\tagSENT_CONTENT	by\tagSENT_CONTENT	temporal_information_extraction\tagtask	marking\tagSENT_CONTENT	the\tagSENT_CONTENT	starting\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	ending\tagSENT_CONTENT	time\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	duration\tagSENT_CONTENT	pattern\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	'\tagSENT_CONTENT	between\tagSENT_CONTENT	TBEGIN\tagSENT_CONTENT	and\tagSENT_CONTENT	TEND\tagSENT_CONTENT	'\tagSENT_CONTENT	or\tagSENT_CONTENT	'\tagSENT_CONTENT	from\tagSENT_CONTENT	TBEGIN\tagSENT_CONTENT	to\tagSENT_CONTENT	/\tagSENT_CONTENT	until\tagSENT_CONTENT	TEND\tagSENT_CONTENT	'\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	possibly\tagSENT_CONTENT	existing\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	(\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	event\tagSENT_CONTENT	(\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	temporal_information_extraction\tagtask	encoded\tagSENT_CONTENT	in\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	other\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	rules\tagSENT_CONTENT	is\tagSENT_CONTENT	taken\tagSENT_CONTENT	from\tagSENT_CONTENT	CAEVO\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	rules\tagSENT_CONTENT	for\tagSENT_CONTENT	linking\tagSENT_CONTENT	a\tagSENT_CONTENT	reporting\tagSENT_CONTENT	event\tagSENT_CONTENT	and\tagSENT_CONTENT	another\tagSENT_CONTENT	event\tagSENT_CONTENT	syntactically\tagSENT_CONTENT	dominated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	tense\tagSENT_CONTENT	and\tagSENT_CONTENT	aspect\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	rules\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	role\tagSENT_CONTENT	played\tagSENT_CONTENT	by\tagSENT_CONTENT	various\tagSENT_CONTENT	tenses\tagSENT_CONTENT	of\tagSENT_CONTENT	English\tagSENT_CONTENT	verbs\tagSENT_CONTENT	in\tagSENT_CONTENT	conveying\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Temporal\tagSECTITLE_START	Reasoner\tagSECTITLE_END	Temporal\tagSECTITLE_START	Supervised\tagSECTITLE_CONTENT	Classifiers\tagSECTITLE_END	Several\tagSENT_START	external\tagSENT_CONTENT	tools\tagSENT_CONTENT	and\tagSENT_CONTENT	resources\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	:\tagSENT_END	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	Mirza\tagSENT_CONTENT	and\tagSENT_CONTENT	Tonelli\tagSENT_CONTENT	(\tagSENT_CONTENT	2014b\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	further\tagSENT_CONTENT	expanded\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Paraphrase\tagSENT_CONTENT	Database\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	manually\tagSENT_CONTENT	clustered\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	{\tagSENT_CONTENT	before\tagSENT_CONTENT	,\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	advance\tagSENT_CONTENT	of\tagSENT_CONTENT	}\tagSENT_CONTENT	.\tagSENT_END	Rep.\tagSECTITLE_START	Description\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	D\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	T\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	Morphosyntactic\tagSECTITLE_CONTENT	information\tagSECTITLE_END	We\tagSENT_START	exclude\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	token\tagSENT_CONTENT	/\tagSENT_CONTENT	lemma\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	'\tagSENT_CONTENT	robustness\tagSENT_CONTENT	in\tagSENT_CONTENT	dealing\tagSENT_CONTENT	with\tagSENT_CONTENT	completely\tagSENT_CONTENT	new\tagSENT_CONTENT	texts\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	vocabularies\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	similarity\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	event\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Causal\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_CONTENT	System\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	while\tagSENT_CONTENT	temporal_information_extraction\tagtask	has\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	NLP\tagSENT_CONTENT	community\tagSENT_CONTENT	,\tagSENT_CONTENT	capturing\tagSENT_CONTENT	causal\tagSENT_CONTENT	relationships\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	text\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	expressed\tagSENT_CONTENT	by\tagSENT_CONTENT	different\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	involve\tagSENT_CONTENT	both\tagSENT_CONTENT	situation\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	world\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	.\tagSENT_END	Causal\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Identification\tagSECTITLE_END	Similar\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	processing\tagSENT_CONTENT	module\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	temporal_information_extraction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	candidate\tagSENT_CONTENT	event\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	include\tagSENT_CONTENT	as\tagSENT_CONTENT	candidate\tagSENT_CONTENT	event\tagSENT_CONTENT	pairs\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	each\tagSENT_CONTENT	event\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	events\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	one\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	account\tagSENT_CONTENT	for\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	sentential\tagSENT_CONTENT	causality\tagSENT_CONTENT	,\tagSENT_CONTENT	under\tagSENT_CONTENT	temporal_information_extraction\tagtask	that\tagSENT_CONTENT	causality\tagSENT_CONTENT	maybe\tagSENT_CONTENT	expressed\tagSENT_CONTENT	also\tagSENT_CONTENT	between\tagSENT_CONTENT	events\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	consecutive\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Causal\tagSECTITLE_START	Rule\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Sieve\tagSECTITLE_END	Causal\tagSECTITLE_START	Supervised\tagSECTITLE_CONTENT	Classifier\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	recognize\tagSENT_CONTENT	and\tagSENT_CONTENT	determine\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	CLINKs\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	signalled\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	causal\tagSENT_CONTENT	signal\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopt\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	approach\tagSENT_CONTENT	.\tagSENT_END	Tools\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Resources\tagSECTITLE_END	The\tagSENT_START	same\tagSENT_CONTENT	external\tagSENT_CONTENT	tools\tagSENT_CONTENT	and\tagSENT_CONTENT	resources\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.2.3\tagSENT_CONTENT	for\tagSENT_CONTENT	building\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	each\tagSENT_CONTENT	event\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	manually\tagSENT_CONTENT	cluster\tagSENT_CONTENT	some\tagSENT_CONTENT	signals\tagSENT_CONTENT	together\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	{\tagSENT_CONTENT	therefore\tagSENT_CONTENT	,\tagSENT_CONTENT	thereby\tagSENT_CONTENT	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	,\tagSENT_CONTENT	consequently\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	did\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	event\tagSENT_CONTENT	-\tagSENT_CONTENT	event\tagSENT_CONTENT	labels\tagSENT_CONTENT	added\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sieve\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	reasoner\tagSENT_CONTENT	in\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	also\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	CLINK\tagSENT_CONTENT	classifier\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_END	The\tagSENT_START	purpose\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	is\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	fold\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	extracted\tagSENT_CONTENT	temporal\tagSENT_CONTENT	and\tagSENT_CONTENT	causal\tagSENT_CONTENT	links\tagSENT_CONTENT	separately\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	ii\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	integrated\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	Temporal\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Causal\tagSECTITLE_CONTENT	Relation\tagSECTITLE_CONTENT	evaluation\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	following\tagSENT_CONTENT	TempEval-3\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	released\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	8\tagSENT_END	The\tagSENT_START	resulting\tagSENT_CONTENT	corpus\tagSENT_CONTENT	contains\tagSENT_CONTENT	temporal_information_extraction\tagtask	over\tagSENT_CONTENT	36\tagSENT_CONTENT	documents\tagSENT_CONTENT	taken\tagSENT_CONTENT	from\tagSENT_CONTENT	TimeBank\tagdataset	1.2\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	evaluate\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Causal\tagSENT_CONTENT	-\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	corpus\tagSENT_CONTENT	10\tagSENT_CONTENT	(\tagSENT_CONTENT	Mirza\tagSENT_CONTENT	and\tagSENT_CONTENT	Tonelli\tagSENT_CONTENT	,\tagSENT_CONTENT	2014a\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	TimeBank\tagSENT_CONTENT	-\tagSENT_CONTENT	Dense\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	TimeBank\tagdataset	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	exclude\tagSENT_CONTENT	the\tagSENT_CONTENT	9\tagSENT_CONTENT	test\tagSENT_CONTENT	documents\tagSENT_CONTENT	from\tagSENT_CONTENT	Causal\tagSENT_CONTENT	-\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	11\tagSENT_START	Causal\tagSENT_CONTENT	relations\tagSENT_CONTENT	are\tagSENT_CONTENT	much\tagSENT_CONTENT	sparser\tagSENT_CONTENT	than\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	only\tagSENT_CONTENT	26\tagSENT_CONTENT	CLINKs\tagSENT_CONTENT	.\tagSENT_END	temporal_information_extraction\tagtask	given\tagSENT_CONTENT	gold\tagSENT_CONTENT	entities\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Task\tagSENT_CONTENT	C\tagSENT_CONTENT	'\tagSENT_CONTENT	relation\tagSENT_CONTENT	type\tagSENT_CONTENT	only\tagSENT_CONTENT	'\tagSENT_CONTENT	temporal_information_extraction\tagtask	given\tagSENT_CONTENT	gold\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	related\tagSENT_CONTENT	pairs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	recently\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	timegraphs\tagSENT_CONTENT	and\tagSENT_CONTENT	stacked\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	In\tagSECTITLE_END	RB\tagSENT_START	:\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sieve\tagSENT_CONTENT	,\tagSENT_CONTENT	ML\tagSENT_CONTENT	:\tagSENT_CONTENT	machine\tagSENT_CONTENT	-\tagSENT_CONTENT	learned\tagSENT_CONTENT	sieve\tagSENT_CONTENT	and\tagSENT_CONTENT	TR\tagSENT_CONTENT	:\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	-T\tagSECTITLE_START	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	D\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	T\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	E\tagSECTITLE_CONTENT	Overall\tagSECTITLE_END	The\tagSENT_START	significant\tagSENT_CONTENT	drop\tagSENT_CONTENT	in\tagSENT_CONTENT	precision\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	in\tagSENT_CONTENT	matching\tagSENT_CONTENT	annotators\tagSENT_CONTENT	'\tagSENT_CONTENT	decision\tagSENT_CONTENT	to\tagSENT_CONTENT	set\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	between\tagSENT_CONTENT	entity\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	CATENA\tagSENT_CONTENT	implements\tagSENT_CONTENT	temporal_information_extraction\tagtask	they\tagSENT_CONTENT	had\tagSENT_CONTENT	to\tagSENT_CONTENT	follow\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	guidelines\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	component\tagSENT_CONTENT	to\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	CATENA\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	sieve\tagSENT_CONTENT	both\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	causal\tagSENT_CONTENT	module\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	running\tagSENT_CONTENT	a\tagSENT_CONTENT	transitive\tagSENT_CONTENT	closure\tagSENT_CONTENT	module\tagSENT_CONTENT	after\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sieve\tagSENT_CONTENT	(\tagSENT_CONTENT	RB\tagSENT_CONTENT	+\tagSENT_CONTENT	TR\tagSENT_CONTENT	)\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	improving\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	temporal_information_extraction\tagtask	is\tagSENT_CONTENT	still\tagSENT_CONTENT	lacking\tagSENT_CONTENT	(\tagSENT_CONTENT	less\tagSENT_CONTENT	than\tagSENT_CONTENT	.30\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introducing\tagSENT_START	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sieves\tagSENT_CONTENT	(\tagSENT_CONTENT	RB\tagSENT_CONTENT	+\tagSENT_CONTENT	TR\tagSENT_CONTENT	+\tagSENT_CONTENT	ML\tagSENT_CONTENT	)\tagSENT_CONTENT	proves\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	even\tagSENT_CONTENT	more\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	-\tagSENT_CONTENT	learned\tagSENT_CONTENT	sieves\tagSENT_CONTENT	(\tagSENT_CONTENT	RB\tagSENT_CONTENT	+\tagSENT_CONTENT	ML\tagSENT_CONTENT	)\tagSENT_CONTENT	achieves\tagSENT_CONTENT	.622\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	in\tagSENT_CONTENT	TempEval-3\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	ML\tagSENT_CONTENT	component\tagSENT_CONTENT	contributing\tagSENT_CONTENT	to\tagSENT_CONTENT	increase\tagSENT_CONTENT	:\tagSENT_CONTENT	Examples\tagSENT_CONTENT	of\tagSENT_CONTENT	E\tagSENT_CONTENT	-\tagSENT_CONTENT	E\tagSENT_CONTENT	pairs\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	TempEval-3-platinum\tagSENT_CONTENT	dataset\tagSENT_CONTENT	with\tagSENT_CONTENT	gold\tagSENT_CONTENT	annotated\tagSENT_CONTENT	labels\tagSENT_CONTENT	(\tagSENT_CONTENT	TE3-gold\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	labelled\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	temporal\tagSENT_CONTENT	module\tagSENT_CONTENT	(\tagSENT_CONTENT	TE\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	causal\tagSENT_CONTENT	module\tagSENT_CONTENT	(\tagSENT_CONTENT	CA\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	CATENA\tagSENT_CONTENT	.\tagSENT_END	Interaction\tagSECTITLE_START	between\tagSECTITLE_CONTENT	Temporal\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Causal\tagSECTITLE_CONTENT	Relations\tagSECTITLE_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	E\tagSENT_CONTENT	-\tagSENT_CONTENT	E\tagSENT_CONTENT	labels\tagSENT_CONTENT	returned\tagSENT_CONTENT	by\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	CLINK\tagSENT_CONTENT	classifier\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	whose\tagSENT_CONTENT	causal\tagSENT_CONTENT	relations\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	edit\tagSENT_CONTENT	TLINK\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	temporal_information_extraction\tagtask	is\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	classification\tagSENT_CONTENT	of\tagSENT_CONTENT	causal\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	recall\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	CATENA\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	classification\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	freely\tagSENT_CONTENT	available\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	research\tagSENT_CONTENT	community\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	the\tagSENT_CONTENT	benefits\tagSENT_CONTENT	of\tagSENT_CONTENT	passing\tagSENT_CONTENT	temporal_information_extraction\tagtask	from\tagSENT_CONTENT	one\tagSENT_CONTENT	module\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	,\tagSENT_CONTENT	was\tagSENT_CONTENT	also\tagSENT_CONTENT	analysed\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	system\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	as\tagSENT_CONTENT	defined\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	standard\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	it\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	easily\tagSENT_CONTENT	put\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	relation\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	E\tagSENT_CONTENT	-\tagSENT_CONTENT	E\tagSENT_CONTENT	label\tagSENT_CONTENT	rules\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	(\tagSENT_CONTENT	dep\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	(\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	verb\tagSENT_CONTENT	info\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Appendix\tagSECTITLE_START	A\tagSECTITLE_CONTENT	Temporal\tagSECTITLE_CONTENT	Rule\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	Appendix\tagSECTITLE_START	B\tagSECTITLE_CONTENT	Causal\tagSECTITLE_CONTENT	Rule\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	Relation\tagSECTITLE_END	
5782-character-level-convolutional-networks-for-text-classification	title\tagSECTITLE_END	Character\tagSENT_START	-\tagSENT_CONTENT	level\tagSENT_CONTENT	Convolutional\tagSENT_CONTENT	Networks\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	*\tagSENT_END	abstract\tagSECTITLE_END	This\tagSENT_START	article\tagSENT_CONTENT	offers\tagSENT_CONTENT	an\tagSENT_CONTENT	empirical\tagSENT_CONTENT	exploration\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	convolu\tagSENT_CONTENT	-\tagSENT_CONTENT	tional\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	text_classification\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	classic\tagSENT_CONTENT	topic\tagSENT_CONTENT	for\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	one\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	assign\tagSENT_CONTENT	predefined\tagSENT_CONTENT	categories\tagSENT_CONTENT	to\tagSENT_CONTENT	free\tagSENT_CONTENT	-\tagSENT_CONTENT	text\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	many\tagSENT_CONTENT	researchers\tagSENT_CONTENT	have\tagSENT_CONTENT	found\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	extracting\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	signals\tagSENT_CONTENT	,\tagSENT_CONTENT	ranging\tagSENT_CONTENT	from\tagSENT_CONTENT	text_classification\tagtask	to\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	and\tagSENT_CONTENT	others\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	this\tagSENT_CONTENT	article\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	used\tagSENT_CONTENT	text_classification\tagtask	as\tagSENT_CONTENT	away\tagSENT_CONTENT	to\tagSENT_CONTENT	exemplify\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	'\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	Applying\tagSENT_START	convolutional\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	at\tagSENT_CONTENT	large\tagSENT_CONTENT	was\tagSENT_CONTENT	explored\tagSENT_CONTENT	in\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	Character\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Convolutional\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	In\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	design\tagSENT_CONTENT	of\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	for\tagSENT_CONTENT	text\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	Key\tagSECTITLE_START	Modules\tagSECTITLE_END	The\tagSENT_START	outputs\tagSENT_CONTENT	h\tagSENT_CONTENT	j\tagSENT_CONTENT	(\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	sum\tagSENT_CONTENT	over\tagSENT_CONTENT	i\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	between\tagSENT_CONTENT	g\tagSENT_END	sentiment_analysis\tagtask	by\tagSENT_CONTENT	might\tagSENT_CONTENT	shed\tagSENT_CONTENT	some\tagSENT_CONTENT	light\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	.\tagSENT_END	Character\tagSECTITLE_START	quantization\tagSECTITLE_END	Model\tagSECTITLE_START	Design\tagSECTITLE_END	lists\tagSENT_START	text_classification\tagtask	for\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	table\tagSENT_CONTENT	2\tagSENT_CONTENT	lists\tagSENT_CONTENT	the\tagSENT_CONTENT	configurations\tagSENT_CONTENT	for\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	connected\tagSENT_CONTENT	(\tagSENT_CONTENT	linear\tagSENT_CONTENT	)\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Augmentation\tagSECTITLE_CONTENT	using\tagSECTITLE_CONTENT	Thesaurus\tagSECTITLE_END	In\tagSENT_START	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	texts\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	reasonable\tagSENT_CONTENT	to\tagSENT_CONTENT	augment\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	using\tagSENT_CONTENT	signal\tagSENT_CONTENT	transformations\tagSENT_CONTENT	as\tagSENT_CONTENT	done\tagSENT_CONTENT	in\tagSENT_CONTENT	image\tagSENT_CONTENT	or\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	exact\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	characters\tagSENT_CONTENT	may\tagSENT_CONTENT	form\tagSENT_CONTENT	rigorous\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	way\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	would\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	using\tagSENT_CONTENT	human\tagSENT_CONTENT	rephrases\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	unrealistic\tagSENT_CONTENT	and\tagSENT_CONTENT	expensive\tagSENT_CONTENT	due\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	volume\tagSENT_CONTENT	of\tagSENT_CONTENT	samples\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	Models\tagSECTITLE_END	Traditional\tagSECTITLE_START	Methods\tagSECTITLE_END	We\tagSENT_START	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	traditional\tagSENT_CONTENT	methods\tagSENT_CONTENT	as\tagSENT_CONTENT	those\tagSENT_CONTENT	that\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	hand\tagSENT_CONTENT	-\tagSENT_CONTENT	crafted\tagSENT_CONTENT	feature\tagSENT_CONTENT	extractor\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSENT_START	inverse\tagSENT_CONTENT	document\tagSENT_CONTENT	frequency\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	logarithm\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	between\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	samples\tagSENT_CONTENT	and\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	samples\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	subset\tagSENT_CONTENT	.\tagSENT_END	Deep\tagSECTITLE_START	Learning\tagSECTITLE_CONTENT	Methods\tagSECTITLE_END	Recently\tagSENT_START	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	methods\tagSENT_CONTENT	have\tagSENT_CONTENT	started\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Among\tagSENT_START	the\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	recent\tagSENT_CONTENT	works\tagSENT_CONTENT	on\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	differences\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	choice\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	or\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	learned\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Mean\tagSECTITLE_END	Figure\tagSECTITLE_START	2\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	long\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	short\tagSECTITLE_CONTENT	term\tagSECTITLE_CONTENT	memory\tagSECTITLE_END	Choice\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Alphabet\tagSECTITLE_END	One\tagSENT_START	possible\tagSENT_CONTENT	explanation\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	that\tagSENT_CONTENT	sentiment_analysis\tagtask	do\tagSENT_CONTENT	not\tagSENT_CONTENT	change\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	letter\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	therefore\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Large\tagSECTITLE_START	-\tagSECTITLE_CONTENT	scale\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	most\tagSENT_CONTENT	open\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	are\tagSENT_CONTENT	quite\tagSENT_CONTENT	small\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	datasets\tagSENT_CONTENT	are\tagSENT_CONTENT	splitted\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	significantly\tagSENT_CONTENT	smaller\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	than\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	text_classification\tagtask	are\tagSENT_CONTENT	constructed\tagSENT_CONTENT	from\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	-one\tagSENT_CONTENT	predicting\tagSENT_CONTENT	full\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	stars\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	has\tagSENT_CONTENT	given\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	predicting\tagSENT_CONTENT	a\tagSENT_CONTENT	polarity\tagSENT_CONTENT	label\tagSENT_CONTENT	by\tagSENT_CONTENT	considering\tagSENT_CONTENT	stars\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	negative\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	3\tagSENT_CONTENT	and\tagSENT_CONTENT	4\tagSENT_CONTENT	positive\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	The\tagSENT_START	most\tagSENT_CONTENT	important\tagSENT_CONTENT	conclusion\tagSENT_CONTENT	from\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	could\tagSENT_CONTENT	work\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	without\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	for\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	sentiment_analysis\tagtask	is\tagSENT_CONTENT	needed\tagSENT_CONTENT	to\tagSENT_CONTENT	validate\tagSENT_CONTENT	the\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	ConvNets\tagSENT_CONTENT	are\tagSENT_CONTENT	truly\tagSENT_CONTENT	good\tagSENT_CONTENT	at\tagSENT_CONTENT	identifying\tagSENT_CONTENT	exotic\tagSENT_CONTENT	character\tagSENT_CONTENT	combinations\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	misspellings\tagSENT_CONTENT	and\tagSENT_CONTENT	emoticons\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	alone\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	show\tagSENT_CONTENT	any\tagSENT_CONTENT	explicit\tagSENT_CONTENT	evidence\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	matter\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	datasets\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	Yelp\tagdataset	and\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	reviews\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	all\tagSENT_CONTENT	others\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Comparing\tagSENT_START	with\tagSENT_CONTENT	traditional\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	suggests\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	distributed\tagSENT_CONTENT	word\tagSENT_CONTENT	representation\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	give\tagSENT_CONTENT	us\tagSENT_CONTENT	an\tagSENT_CONTENT	advantage\tagSENT_CONTENT	to\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSENT_START	factors\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	could\tagSENT_CONTENT	all\tagSENT_CONTENT	play\tagSENT_CONTENT	a\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	deciding\tagSENT_CONTENT	which\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	for\tagSENT_CONTENT	some\tagSENT_CONTENT	specific\tagSENT_CONTENT	application\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Outlook\tagSECTITLE_END	This\tagSENT_START	article\tagSENT_CONTENT	offers\tagSENT_CONTENT	an\tagSENT_CONTENT	empirical\tagSENT_CONTENT	study\tagSENT_CONTENT	on\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	networks\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	
P17-1101	title\tagSECTITLE_END	Selective\tagSENT_START	Encoding\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	selective\tagSENT_CONTENT	encoding\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	extend\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	shorten\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	brief\tagSENT_CONTENT	summary\tagSENT_CONTENT	of\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	explicit\tagSENT_CONTENT	alignment\tagSENT_CONTENT	relationship\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	ex\tagSENT_CONTENT	-\tagSENT_CONTENT	cept\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	extracted\tagSENT_CONTENT	common\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	Selective\tagSENT_CONTENT	Encoding\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	SEASS\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	,\tagSENT_CONTENT	also\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	sentence\tagSENT_CONTENT	compression\tagSENT_CONTENT	and\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	headline\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	help\tagSENT_CONTENT	compressor\tagSENT_CONTENT	fuse\tagSENT_CONTENT	the\tagSENT_CONTENT	selected\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	extractive\tagSENT_CONTENT	document\tagSENT_CONTENT	summarization\tagSENT_CONTENT	systems\tagSENT_CONTENT	since\tagSENT_CONTENT	they\tagSENT_CONTENT	may\tagSENT_CONTENT	inadvertently\tagSENT_CONTENT	include\tagSENT_CONTENT	unnecessary\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Problem\tagSECTITLE_START	Formulation\tagSECTITLE_END	For\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	given\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	x\tagSENT_CONTENT	=\tagSENT_END	If\tagSENT_START	|y|\tagSENT_CONTENT	⊆\tagSENT_CONTENT	|x|\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	means\tagSENT_CONTENT	all\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	y\tagSENT_CONTENT	must\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	given\tagSENT_CONTENT	input\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	denote\tagSENT_CONTENT	this\tagSENT_CONTENT	as\tagSENT_CONTENT	extractive\tagSENT_CONTENT	sentence\tagSENT_CONTENT	summarization\tagSENT_CONTENT	.\tagSENT_END	Input\tagSECTITLE_START	:\tagSECTITLE_END	Model\tagSECTITLE_END	Sentence\tagSECTITLE_START	Encoder\tagSECTITLE_END	Selective\tagSECTITLE_START	Mechanism\tagSECTITLE_END	Some\tagSENT_START	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	apply\tagSENT_CONTENT	this\tagSENT_CONTENT	framework\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Herein\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	selective\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	selection\tagSENT_CONTENT	process\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Summary\tagSECTITLE_START	Decoder\tagSECTITLE_END	Objective\tagSECTITLE_START	Function\tagSECTITLE_END	Our\tagmetric	goal\tagmetric	is\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	summary\tagSENT_CONTENT	probability\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	DUC\tagSECTITLE_START	2004\tagSECTITLE_CONTENT	Test\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	It\tagSENT_START	has\tagSENT_CONTENT	500\tagSENT_CONTENT	input\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	MSR\tagSECTITLE_START	-\tagSECTITLE_CONTENT	ATC\tagSECTITLE_CONTENT	Test\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	Evaluation\tagSECTITLE_START	Metric\tagSECTITLE_END	We\tagSENT_START	employ\tagSENT_CONTENT	ROUGE\tagmetric	 \tagmetric	gram\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	LCS\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	reported\tagSENT_CONTENT	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	During\tagSENT_START	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	test\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	performance\tagSENT_CONTENT	(\tagSENT_CONTENT	ROUGE-2\tagmetric	F1\tagmetric	)\tagSENT_CONTENT	on\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	2,000\tagSENT_CONTENT	batches\tagSENT_CONTENT	.\tagSENT_END	Baseline\tagSECTITLE_END	ABS\tagSENT_START	use\tagSENT_CONTENT	an\tagSENT_CONTENT	attentive\tagSENT_CONTENT	CNN\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	NNLM\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	ROUGE\tagmetric	F1\tagmetric	,\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	recall\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	F1\tagSENT_CONTENT	for\tagSENT_CONTENT	English\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	,\tagSENT_CONTENT	DUC\tagSENT_CONTENT	2004\tagSENT_CONTENT	and\tagSENT_CONTENT	MSR\tagSENT_CONTENT	-\tagSENT_CONTENT	ATC\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	The\tagSENT_START	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	our\tagSENT_CONTENT	internal\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	comparable\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	24.58\tagmetric	ROUGE-2\tagmetric	F1\tagmetric	and\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	baselines\tagSENT_CONTENT	.\tagSENT_END	DUC\tagSECTITLE_START	2004\tagSECTITLE_END	Models\tagSECTITLE_END	Models\tagSECTITLE_END	Discussion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	SEASS\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	s2s+att\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	illustrate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	succeeds\tagSENT_CONTENT	in\tagSENT_CONTENT	selecting\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	building\tagSENT_CONTENT	tailored\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	
S18-1146	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Since\tagSENT_START	language\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	vital\tagSENT_CONTENT	organ\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	constantly\tagSENT_CONTENT	evolving\tagSENT_CONTENT	and\tagSENT_CONTENT	changing\tagSENT_CONTENT	overtime\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	many\tagSENT_CONTENT	words\tagSENT_CONTENT	which\tagSENT_CONTENT	lose\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	taxonomy_learning\tagtask	or\tagSENT_CONTENT	attach\tagSENT_CONTENT	anew\tagSENT_CONTENT	meaning\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	well\tagSENT_CONTENT	known\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	biggest\tagSENT_CONTENT	challenges\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	taxonomy_learning\tagtask	of\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	such\tagSENT_START	automatic\tagSENT_CONTENT	hypernymy\tagSENT_CONTENT	detection\tagSENT_CONTENT	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_CONTENT	taxonomy_learning\tagtask	,\tagSENT_CONTENT	recognizing\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	text\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	Question\tagSENT_CONTENT	Answering\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	semantic\tagSENT_CONTENT	search\tagSENT_CONTENT	,\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Inference\tagSENT_CONTENT	,\tagSENT_CONTENT	Coreference\tagSENT_CONTENT	Resolution\tagSENT_CONTENT	and\tagSENT_CONTENT	many\tagSENT_CONTENT	others\tagSENT_CONTENT	.\tagSENT_END	Traditional\tagSENT_START	procedures\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	taxonomy_learning\tagtask	have\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	measuring\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	edges\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	assessing\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	is\tagSENT_CONTENT	-\tagSENT_CONTENT	a\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	new\tagSECTITLE_CONTENT	Approach\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	Detect\tagSECTITLE_CONTENT	Hypernymy\tagSECTITLE_CONTENT	Relation\tagSECTITLE_END	The\tagSECTITLE_START	Web\tagSECTITLE_CONTENT	Interface\tagSECTITLE_END	Results\tagSECTITLE_END	
1701.06538	title\tagSECTITLE_END	abstract\tagSECTITLE_END	The\tagSENT_START	capacity\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	absorb\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	limited\tagSENT_CONTENT	by\tagSENT_CONTENT	its\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	RELATED\tagSECTITLE_CONTENT	WORK\tagSECTITLE_END	CONDITIONAL\tagSECTITLE_START	COMPUTATION\tagSECTITLE_END	Various\tagSENT_START	forms\tagSENT_CONTENT	of\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	machine_translation\tagtask	are\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	trarining\tagSENT_CONTENT	the\tagSENT_CONTENT	gating\tagSENT_CONTENT	decisions\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	works\tagSENT_CONTENT	above\tagSENT_CONTENT	recognize\tagSENT_CONTENT	this\tagSENT_CONTENT	and\tagSENT_CONTENT	propose\tagSENT_CONTENT	turning\tagSENT_CONTENT	on\tagSENT_CONTENT	/\tagSENT_CONTENT	off\tagSENT_CONTENT	large\tagSENT_CONTENT	chunks\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	To\tagSENT_START	be\tagSENT_CONTENT	computationally\tagSENT_CONTENT	efficient\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	computational\tagSENT_CONTENT	versus\tagSENT_CONTENT	network\tagSENT_CONTENT	demands\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	must\tagSENT_CONTENT	exceed\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	OUR\tagSECTITLE_START	APPROACH\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	SPARSELY\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	GATED\tagSECTITLE_CONTENT	MIXTURE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	EXPERTS\tagSECTITLE_CONTENT	LAYER\tagSECTITLE_END	All\tagSENT_START	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	jointly\tagSENT_CONTENT	by\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	introduced\tagSENT_CONTENT	technique\tagSENT_CONTENT	is\tagSENT_CONTENT	generic\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	known\tagSENT_CONTENT	to\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	very\tagSENT_CONTENT	large\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	MIXTURES\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	EXPERTS\tagSECTITLE_END	suggest\tagSENT_START	an\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	format\tagSENT_CONTENT	of\tagSENT_CONTENT	mixture\tagSENT_CONTENT	of\tagSENT_CONTENT	experts\tagSENT_CONTENT	for\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	While\tagSENT_START	uses\tagSENT_CONTENT	two\tagSENT_CONTENT	stacked\tagSENT_CONTENT	MoEs\tagSENT_CONTENT	allowing\tagSENT_CONTENT	for\tagSENT_CONTENT	two\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	gating\tagSENT_CONTENT	decisions\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	MoE\tagSENT_CONTENT	allows\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	gating\tagSENT_CONTENT	decisions\tagSENT_CONTENT	at\tagSENT_CONTENT	machine_translation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	THE\tagSECTITLE_START	STRUCTURE\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	MIXTURE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	EXPERTS\tagSECTITLE_CONTENT	LAYER\tagSECTITLE_END	GATING\tagSECTITLE_START	NETWORK\tagSECTITLE_END	Before\tagSENT_START	taking\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	tunable\tagSENT_CONTENT	Gaussian\tagSENT_CONTENT	noise\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	keep\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	k\tagSENT_CONTENT	values\tagSENT_CONTENT	,\tagSENT_CONTENT	setting\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	to\tagSENT_CONTENT	−∞\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	causes\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	gate\tagSENT_CONTENT	values\tagSENT_CONTENT	to\tagSENT_CONTENT	equal\tagSENT_CONTENT	0\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	ADDRESSING\tagSECTITLE_START	PERFORMANCE\tagSECTITLE_CONTENT	CHALLENGES\tagSECTITLE_END	THE\tagSECTITLE_START	SHRINKING\tagSECTITLE_CONTENT	BATCH\tagSECTITLE_CONTENT	PROBLEM\tagSECTITLE_END	machine_translation\tagtask	to\tagSENT_CONTENT	this\tagSENT_CONTENT	shrinking\tagSENT_CONTENT	batch\tagSENT_CONTENT	problem\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	batch\tagSENT_CONTENT	size\tagSENT_CONTENT	as\tagSENT_CONTENT	large\tagSENT_CONTENT	as\tagSENT_CONTENT	possible\tagSENT_CONTENT	.\tagSENT_END	NETWORK\tagSECTITLE_START	BANDWIDTH\tagSECTITLE_END	To\tagSENT_START	maintain\tagSENT_CONTENT	computational\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	an\tagSENT_CONTENT	expert\tagSENT_CONTENT	's\tagSENT_CONTENT	computation\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	must\tagSENT_CONTENT	exceed\tagSENT_CONTENT	the\tagSENT_CONTENT	ratio\tagSENT_CONTENT	of\tagSENT_CONTENT	computational\tagSENT_CONTENT	to\tagSENT_CONTENT	network\tagSENT_CONTENT	capacity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	computing\tagSENT_CONTENT	device\tagSENT_CONTENT	.\tagSENT_END	BALANCING\tagSECTITLE_START	EXPERT\tagSECTITLE_CONTENT	UTILIZATION\tagSECTITLE_END	machine_translation\tagtask	,\tagSENT_CONTENT	High\tagSENT_CONTENT	Capacity\tagSENT_CONTENT	:\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	100\tagSECTITLE_START	BILLION\tagSECTITLE_CONTENT	WORD\tagSECTITLE_CONTENT	GOOGLE\tagSECTITLE_CONTENT	NEWS\tagSECTITLE_CONTENT	CORPUS\tagSECTITLE_END	MACHINE\tagSECTITLE_START	TRANSLATION\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	SINGLE\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	PAIR\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Our\tagSENT_START	approach\tagSENT_CONTENT	achieved\tagSENT_CONTENT	BLEU\tagmetric	scores\tagmetric	of\tagSENT_CONTENT	40.56\tagSENT_CONTENT	and\tagSENT_CONTENT	26.03\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WMT'14\tagSENT_CONTENT	En→Fr\tagSENT_CONTENT	and\tagSENT_CONTENT	En→De\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	MULTILINGUAL\tagSECTITLE_START	MACHINE\tagSECTITLE_CONTENT	TRANSLATION\tagSECTITLE_END	Results\tagSECTITLE_START	:\tagSECTITLE_END	On\tagSENT_START	BLEU\tagmetric	score\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	MoE\tagSENT_CONTENT	model\tagSENT_CONTENT	significantly\tagSENT_CONTENT	beats\tagSENT_CONTENT	the\tagSENT_CONTENT	multilingual\tagSENT_CONTENT	GNMT\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	11\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	12\tagSENT_CONTENT	language\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	by\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	as\tagSENT_CONTENT	5.84\tagSENT_CONTENT	points\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	even\tagSENT_CONTENT	beats\tagSENT_CONTENT	the\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	GNMT\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	8\tagSENT_CONTENT	of\tagSENT_CONTENT	12\tagSENT_CONTENT	language\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	We\tagSENT_START	carefully\tagSENT_CONTENT	identified\tagSENT_CONTENT	the\tagSENT_CONTENT	design\tagSENT_CONTENT	considerations\tagSENT_CONTENT	and\tagSENT_CONTENT	challenges\tagSENT_CONTENT	of\tagSENT_CONTENT	conditional\tagSENT_CONTENT	computing\tagSENT_CONTENT	and\tagSENT_CONTENT	addressed\tagSENT_CONTENT	them\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	algorithmic\tagSENT_CONTENT	and\tagSENT_CONTENT	engineering\tagSENT_CONTENT	solutions\tagSENT_CONTENT	.\tagSENT_END	ACKNOWLEDGMENTS\tagSECTITLE_END	APPENDICES\tagSECTITLE_START	A\tagSECTITLE_CONTENT	LOAD\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	BALANCING\tagSECTITLE_CONTENT	LOSS\tagSECTITLE_END	Unfortunately\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	examples\tagSENT_CONTENT	received\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	expert\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	discrete\tagSENT_CONTENT	quantity\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	machine_translation\tagtask	containing\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	one\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	losses\tagSENT_CONTENT	led\tagSENT_CONTENT	to\tagSENT_CONTENT	very\tagSENT_CONTENT	similar\tagSENT_CONTENT	model\tagSENT_CONTENT	quality\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	having\tagSENT_CONTENT	no\tagSENT_CONTENT	loss\tagSENT_CONTENT	was\tagSENT_CONTENT	much\tagSENT_CONTENT	worse\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	HIERACHICAL\tagSECTITLE_CONTENT	MIXTURE\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	EXPERTS\tagSECTITLE_END	)\tagSENT_START	j\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	this\tagSENT_CONTENT	would\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	gradient\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	primary\tagSENT_CONTENT	gating\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	machine_translation\tagtask	above\tagSENT_CONTENT	.\tagSENT_END	C\tagSECTITLE_START	1\tagSECTITLE_CONTENT	BILLION\tagSECTITLE_CONTENT	WORD\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	MODELING\tagSECTITLE_CONTENT	BENCHMARK\tagSECTITLE_CONTENT	-EXPERIMENTAL\tagSECTITLE_CONTENT	DETAILS\tagSECTITLE_END	C.1\tagSECTITLE_START	8-MILLION\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	OPERATIONS\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	PER\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	TIMESTEP\tagSECTITLE_CONTENT	MODELS\tagSECTITLE_END	For\tagSENT_START	every\tagSENT_CONTENT	layer\tagSENT_CONTENT	other\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	softmax\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	drouput\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	layer\tagSENT_CONTENT	output\tagSENT_CONTENT	,\tagSENT_CONTENT	dropping\tagSENT_CONTENT	machine_translation\tagtask	with\tagSENT_CONTENT	probability\tagSENT_CONTENT	DropP\tagSENT_CONTENT	rob\tagSENT_CONTENT	,\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	dividing\tagSENT_CONTENT	by\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	−\tagSENT_CONTENT	DropP\tagSENT_CONTENT	rob\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Computationally\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Matched\tagSECTITLE_CONTENT	Baselines\tagSECTITLE_CONTENT	:\tagSECTITLE_END	C.2\tagSECTITLE_START	MORE\tagSECTITLE_CONTENT	EXPENSIVE\tagSECTITLE_CONTENT	MODELS\tagSECTITLE_END	We\tagSENT_START	ran\tagSENT_CONTENT	two\tagSENT_CONTENT	additional\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	effects\tagSENT_CONTENT	of\tagSENT_CONTENT	adding\tagSENT_CONTENT	machine_translation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	MoE\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	two\tagSENT_CONTENT	models\tagSENT_CONTENT	achieved\tagSENT_CONTENT	test\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	of\tagSENT_CONTENT	31.3\tagSENT_CONTENT	and\tagSENT_CONTENT	28.0\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	even\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	MoE\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	still\tagSENT_CONTENT	useful\tagSENT_CONTENT	.\tagSENT_END	D\tagSECTITLE_START	100\tagSECTITLE_CONTENT	BILLION\tagSECTITLE_CONTENT	WORD\tagSECTITLE_CONTENT	GOOGLE\tagSECTITLE_CONTENT	NEWS\tagSECTITLE_CONTENT	CORPUS\tagSECTITLE_CONTENT	-EXPERIMENTAL\tagSECTITLE_CONTENT	DETAILS\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	store\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	experts\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	instead\tagSENT_CONTENT	recompute\tagSENT_CONTENT	them\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	backwards\tagSENT_CONTENT	pass\tagSENT_CONTENT	.\tagSENT_END	E\tagSECTITLE_START	MACHINE\tagSECTITLE_CONTENT	TRANSLATION\tagSECTITLE_CONTENT	-EXPERIMENTAL\tagSECTITLE_CONTENT	DETAILS\tagSECTITLE_END	the\tagSENT_START	first\tagSENT_CONTENT	decoder\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	receiving\tagSENT_CONTENT	output\tagSENT_CONTENT	from\tagSENT_CONTENT	and\tagSENT_CONTENT	providing\tagSENT_CONTENT	input\tagSENT_CONTENT	for\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	machine_translation\tagtask	consisted\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	containing\tagSENT_CONTENT	roughly\tagSENT_CONTENT	16000\tagSENT_CONTENT	words\tagSENT_CONTENT	per\tagSENT_CONTENT	GPU\tagSENT_CONTENT	.\tagSENT_END	Contexts\tagSENT_START	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	2048\tagSENT_CONTENT	experts\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	MoE\tagSENT_CONTENT	layer\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	Top\tagSENT_START	-\tagSENT_CONTENT	K\tagSENT_CONTENT	Mask\tagSENT_CONTENT	:\tagSENT_CONTENT	To\tagSENT_CONTENT	implement\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	k\tagSENT_CONTENT	gating\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	would\tagSENT_CONTENT	let\tagSENT_CONTENT	M\tagSENT_CONTENT	(\tagSENT_CONTENT	v\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	otherwise\tagSENT_START	As\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	suggest\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	observed\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	machine_translation\tagtask	during\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	M\tagSENT_CONTENT	batchwise\tagSENT_CONTENT	)\tagSENT_CONTENT	requires\tagSENT_CONTENT	modifications\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	inference\tagSENT_CONTENT	when\tagSENT_CONTENT	we\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	batch\tagSENT_CONTENT	of\tagSENT_CONTENT	examples\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	slightly\tagSENT_CONTENT	different\tagSENT_CONTENT	attention\tagSENT_CONTENT	function\tagSENT_CONTENT	:\tagSENT_END	
1801.01900	title\tagSECTITLE_END	word_sense_disambiguation\tagtask	using\tagSENT_CONTENT	Topic\tagSENT_CONTENT	Models\tagSENT_END	abstract\tagSECTITLE_END	word_sense_disambiguation\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	open\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	Natural\tagSENT_CONTENT	Language\tagSENT_CONTENT	Processing\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	particularly\tagSENT_CONTENT	challenging\tagSENT_CONTENT	and\tagSENT_CONTENT	useful\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	setting\tagSENT_CONTENT	where\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	any\tagSENT_CONTENT	given\tagSENT_CONTENT	text\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	disambiguated\tagSENT_CONTENT	without\tagSENT_CONTENT	using\tagSENT_CONTENT	any\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	word_sense_disambiguation\tagtask	(\tagSENT_CONTENT	WSD\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	mapping\tagSENT_CONTENT	an\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	context\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	correct\tagSENT_CONTENT	meaning\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	uniform\tagSENT_CONTENT	prior\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	over\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	frequency\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	within\tagSENT_CONTENT	a\tagSENT_CONTENT	synset\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Lesk\tagSENT_START	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	classical\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	WSD\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	which\tagSENT_CONTENT	disambiguates\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	by\tagSENT_CONTENT	selecting\tagSENT_CONTENT	a\tagSENT_CONTENT	sense\tagSENT_CONTENT	word_sense_disambiguation\tagtask	overlaps\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	build\tagSENT_CONTENT	a\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	lexicon\tagSENT_CONTENT	containing\tagSENT_CONTENT	vertices\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	and\tagSENT_CONTENT	then\tagSENT_CONTENT	use\tagSENT_CONTENT	graph\tagSENT_CONTENT	connectivity\tagSENT_CONTENT	measures\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	appropriate\tagSENT_CONTENT	senses\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	a\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	document\tagSENT_CONTENT	is\tagSENT_CONTENT	utilized\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	WordNet\tagSECTITLE_END	Most\tagSENT_START	WSD\tagSENT_CONTENT	systems\tagSENT_CONTENT	use\tagSENT_CONTENT	word_sense_disambiguation\tagtask	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	senses\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	although\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	sense\tagSENT_CONTENT	repository\tagSENT_CONTENT	,\tagSENT_CONTENT	word_sense_disambiguation\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	too\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	scenarios\tagSENT_CONTENT	.\tagSENT_END	Methods\tagSECTITLE_END	Problem\tagSECTITLE_START	Definition\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	formally\tagSENT_CONTENT	define\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	by\tagSENT_CONTENT	illustrating\tagSENT_CONTENT	an\tagSENT_CONTENT	example\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	set\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	senses\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	word_sense_disambiguation\tagtask	like\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	.\tagSENT_END	Semantics\tagSECTITLE_END	•\tagSENT_START	some\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	synset\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	frequent\tagSENT_CONTENT	than\tagSENT_CONTENT	others\tagSENT_CONTENT	:\tagSENT_CONTENT	modeled\tagSENT_CONTENT	using\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	uniform\tagSENT_CONTENT	priors\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	over\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Document\tagSECTITLE_START	context\tagSECTITLE_END	LDA\tagSENT_START	has\tagSENT_CONTENT	an\tagSENT_CONTENT	implicit\tagSENT_CONTENT	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	as\tagSENT_CONTENT	words\tagSENT_CONTENT	with\tagSENT_CONTENT	several\tagSENT_CONTENT	distinct\tagSENT_CONTENT	meanings\tagSENT_CONTENT	can\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	distinct\tagSENT_CONTENT	topics\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	cricket\tagSENT_CONTENT	the\tagSENT_CONTENT	game\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	sports\tagSENT_CONTENT	"\tagSENT_CONTENT	topic\tagSENT_CONTENT	and\tagSENT_CONTENT	cricket\tagSENT_CONTENT	the\tagSENT_CONTENT	insect\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	zoology\tagSENT_CONTENT	"\tagSENT_CONTENT	topic\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	word_sense_disambiguation\tagtask	over\tagSENT_CONTENT	words\tagSENT_CONTENT	Due\tagSENT_CONTENT	to\tagSENT_CONTENT	sparsity\tagSENT_CONTENT	problems\tagSENT_CONTENT	in\tagSENT_CONTENT	large\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	size\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	LDA\tagSENT_CONTENT	model\tagSENT_CONTENT	was\tagSENT_CONTENT	extended\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	smoothed\tagSENT_CONTENT	"\tagSENT_CONTENT	LDA\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	placing\tagSENT_CONTENT	an\tagSENT_CONTENT	exchangeable\tagSENT_CONTENT	Dirichlet\tagSENT_CONTENT	prior\tagSENT_CONTENT	on\tagSENT_CONTENT	topic\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Proposed\tagSECTITLE_START	Model\tagSECTITLE_END	illustrates\tagSENT_START	a\tagSENT_CONTENT	toy\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	word_sense_disambiguation\tagtask	in\tagSENT_CONTENT	synsets\tagSENT_CONTENT	and\tagSENT_CONTENT	synset\tagSENT_CONTENT	proportions\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	learned\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Priors\tagSECTITLE_END	Inference\tagSECTITLE_END	word_sense_disambiguation\tagtask	p(w\tagSENT_CONTENT	mn\tagSENT_CONTENT	|z\tagSENT_CONTENT	mn\tagSENT_CONTENT	,\tagSENT_CONTENT	β\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	multinomial\tagSENT_CONTENT	in\tagSENT_CONTENT	β\tagSENT_CONTENT	zmn\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	conjugate\tagSENT_CONTENT	distribution\tagSENT_CONTENT	p(β\tagSENT_CONTENT	s\tagSENT_CONTENT	|η\tagSENT_CONTENT	s\tagSENT_CONTENT	)\tagSENT_END	All\tagSENT_START	  \tagSENT_CONTENT	α\tagSENT_CONTENT	m\tagSENT_CONTENT	follows\tagSENT_CONTENT	word_sense_disambiguation\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	conjugate\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	multinomial\tagSENT_CONTENT	distribution\tagSENT_CONTENT	:\tagSENT_END	Experiments\tagSECTITLE_START	&\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	This\tagSENT_START	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	using\tagSENT_CONTENT	document\tagSENT_CONTENT	context\tagSENT_CONTENT	helps\tagSENT_CONTENT	in\tagSENT_CONTENT	word_sense_disambiguation\tagtask	words\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	PoS\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	Discussions\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	illustrate\tagSENT_CONTENT	the\tagSENT_CONTENT	benefit\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	document\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	for\tagSENT_CONTENT	word_sense_disambiguation\tagtask	by\tagSENT_CONTENT	illustrat-\tagSENT_CONTENT	  \tagSENT_CONTENT	ing\tagSENT_CONTENT	an\tagSENT_CONTENT	example\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	This\tagSENT_START	would\tagSENT_CONTENT	allow\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	bring\tagSENT_CONTENT	back\tagSENT_CONTENT	the\tagSENT_CONTENT	notion\tagSENT_CONTENT	of\tagSENT_CONTENT	topics\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	to\tagSENT_CONTENT	define\tagSENT_CONTENT	word_sense_disambiguation\tagtask	.\tagSENT_END	
S18-1148	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	SemEval\tagSENT_CONTENT	2018\tagSENT_CONTENT	task9\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	achieve\tagSENT_CONTENT	1st\tagSENT_CONTENT	on\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	,\tagSENT_CONTENT	2nd\tagSENT_CONTENT	on\tagSENT_CONTENT	Italian\tagSENT_CONTENT	,\tagSENT_CONTENT	6th\tagSENT_CONTENT	on\tagSENT_CONTENT	English\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	metric\tagSENT_CONTENT	of\tagSENT_CONTENT	MAP\tagmetric	.\tagSENT_END	Introduction\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	The\tagSENT_START	work\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	hypernymy\tagSENT_CONTENT	relationship\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	categorized\tagSENT_CONTENT	from\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	taxonomy_learning\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	formulization\tagSENT_CONTENT	.\tagSENT_END	Hyponym\tagSECTITLE_START	-\tagSECTITLE_CONTENT	hypernym\tagSECTITLE_CONTENT	Discovery\tagSECTITLE_CONTENT	method\tagSECTITLE_CONTENT	3.1\tagSECTITLE_CONTENT	Preprocessing\tagSECTITLE_END	Word\tagSECTITLE_START	Embedding\tagSECTITLE_END	The\tagSENT_START	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	taxonomy_learning\tagtask	and\tagSENT_CONTENT	nearestneighbour\tagSENT_CONTENT	based\tagSENT_CONTENT	method\tagSENT_CONTENT	.\tagSENT_END	Method\tagSECTITLE_START	based\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Projection\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	The\tagSENT_START	motivation\tagSENT_CONTENT	for\tagSENT_CONTENT	taxonomy_learning\tagtask	is\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	fold\tagSENT_CONTENT	:\tagSENT_CONTENT	firstly\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	hypernym\tagSENT_CONTENT	-\tagSENT_CONTENT	hyponym\tagSENT_CONTENT	relation\tagSENT_CONTENT	is\tagSENT_CONTENT	diverse\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	offset\tagSENT_CONTENT	from\tagSENT_CONTENT	"\tagSENT_CONTENT	carpenter\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	laborer\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	distant\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	from\tagSENT_CONTENT	"\tagSENT_CONTENT	gold\tagSENT_CONTENT	fish\tagSENT_CONTENT	"\tagSENT_CONTENT	to\tagSENT_CONTENT	"\tagSENT_CONTENT	fish\tagSENT_CONTENT	"\tagSENT_CONTENT	;\tagSENT_CONTENT	Secondly\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	hyponym\tagSENT_END	Method\tagSECTITLE_START	Based\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Nearest\tagSECTITLE_CONTENT	Neighbors\tagSECTITLE_END	Evaluation\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Results\tagSECTITLE_START	Based\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Projection\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	For\tagSENT_START	taxonomy_learning\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	followed\tagSENT_CONTENT	experimental\tagSENT_CONTENT	settings\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	Based\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	NN\tagSECTITLE_END	Compared\tagSENT_START	with\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	got\tagSENT_CONTENT	by\tagSENT_CONTENT	cross\tagSENT_CONTENT	validation\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	)\tagSENT_CONTENT	dropped\tagSENT_CONTENT	significantly\tagSENT_CONTENT	on\tagSENT_CONTENT	English\tagSENT_CONTENT	(\tagSENT_CONTENT	MAP\tagmetric	dropped\tagSENT_CONTENT	by\tagSENT_CONTENT	4\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Italian\tagSENT_END	(\tagmetric	MAP\tagmetric	dropped\tagSENT_CONTENT	by\tagSENT_CONTENT	8\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	increased\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	margin\tagSENT_CONTENT	on\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	(\tagSENT_CONTENT	MAP\tagmetric	increased\tagSENT_CONTENT	by\tagSENT_CONTENT	3.6\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	
P18-1064	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	improve\tagSENT_CONTENT	these\tagSENT_CONTENT	important\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	via\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	tasks\tagSENT_CONTENT	of\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	former\tagSENT_CONTENT	teaches\tagSENT_CONTENT	the\tagSENT_CONTENT	summarization\tagSENT_CONTENT	model\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	look\tagSENT_CONTENT	for\tagSENT_CONTENT	salient\tagSENT_CONTENT	questioning\tagSENT_CONTENT	-\tagSENT_CONTENT	worthy\tagSENT_CONTENT	details\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	latter\tagSENT_CONTENT	teaches\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	rewrite\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	directed\tagSENT_CONTENT	-\tagSENT_CONTENT	logical\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	challenging\tagSENT_CONTENT	NLG\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	compressing\tagSENT_CONTENT	and\tagSENT_CONTENT	rewriting\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	,\tagSENT_CONTENT	relevant\tagSENT_CONTENT	,\tagSENT_CONTENT	salient\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	coherent\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	improve\tagSENT_CONTENT	summarization\tagtask	via\tagSENT_CONTENT	soft\tagSENT_CONTENT	,\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	semantic\tagSENT_CONTENT	)\tagSENT_CONTENT	layerspecific\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	relevant\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	progressively\tagSENT_CONTENT	improving\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	initially\tagSENT_CONTENT	more\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	extractive\tagSENT_CONTENT	and\tagSENT_CONTENT	compressive\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	moving\tagSENT_CONTENT	more\tagSENT_CONTENT	towards\tagSENT_CONTENT	compressive\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	graphs\tagSENT_CONTENT	and\tagSENT_CONTENT	concept\tagSENT_CONTENT	maps\tagSENT_CONTENT	and\tagSENT_CONTENT	discourse\tagSENT_CONTENT	trees\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representations\tagSENT_CONTENT	(\tagSENT_CONTENT	AMR\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	some\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	works\tagSENT_CONTENT	have\tagSENT_CONTENT	investigated\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	shared\tagSENT_CONTENT	vs\tagSENT_CONTENT	unshared\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagmetric	.\tagSENT_END	Our\tagSENT_START	previous\tagSENT_CONTENT	workshop\tagSENT_CONTENT	paper\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	presented\tagSENT_CONTENT	some\tagSENT_CONTENT	preliminary\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	task\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	saliency\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	setting\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Baseline\tagSECTITLE_START	Pointer+Coverage\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Pointer\tagSENT_START	-\tagSENT_CONTENT	Generator\tagSENT_CONTENT	Networks\tagSENT_CONTENT	Pointer\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	(\tagSENT_CONTENT	 \tagSENT_CONTENT	helps\tagSENT_CONTENT	in\tagSENT_CONTENT	directly\tagSENT_CONTENT	copying\tagSENT_CONTENT	the\tagmetric	words\tagmetric	from\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	sequence\tagSENT_CONTENT	during\tagSENT_CONTENT	target\tagSENT_CONTENT	sequence\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	fit\tagSENT_CONTENT	fora\tagSENT_CONTENT	task\tagSENT_CONTENT	like\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	,\tagSENT_START	coverage\tagSENT_CONTENT	helps\tagSENT_CONTENT	alleviate\tagSENT_CONTENT	the\tagSENT_CONTENT	issue\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	repetition\tagSENT_CONTENT	while\tagSENT_CONTENT	generating\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Two\tagSECTITLE_START	Auxiliary\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	We\tagSENT_START	teach\tagSENT_CONTENT	these\tagSENT_CONTENT	skills\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	via\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	related\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	task\tagSENT_CONTENT	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	Question\tagSECTITLE_START	Generation\tagSECTITLE_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	sequenceto\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	generation\tagSENT_CONTENT	decoder\tagSENT_CONTENT	also\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	entailed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	contain\tagSENT_CONTENT	any\tagSENT_CONTENT	contradictory\tagSENT_CONTENT	or\tagSENT_CONTENT	unrelated\tagSENT_CONTENT	/\tagSENT_CONTENT	extraneous\tagSENT_CONTENT	information\tagSENT_CONTENT	as\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	We\tagSENT_START	employ\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	parallel\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	three\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	Layer\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Specific\tagSECTITLE_CONTENT	Sharing\tagSECTITLE_CONTENT	Mechanism\tagSECTITLE_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	while\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	have\tagSENT_CONTENT	different\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	distributions\tagSENT_CONTENT	and\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	still\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	sharing\tagSENT_CONTENT	their\tagSENT_CONTENT	models\tagSENT_CONTENT	'\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	components\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	those\tagSENT_CONTENT	that\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	skills\tagSENT_CONTENT	of\tagSENT_CONTENT	saliency\tagSENT_CONTENT	and\tagSENT_CONTENT	inference\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Soft\tagSECTITLE_START	vs.\tagSECTITLE_CONTENT	Hard\tagSECTITLE_CONTENT	Parameter\tagSECTITLE_CONTENT	Sharing\tagSECTITLE_END	Fast\tagSECTITLE_START	Multi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	;\tagSENT_START	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	summarization\tagtask	for\tagSENT_CONTENT	α\tagSENT_CONTENT	s\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	task\tagSENT_CONTENT	for\tagSENT_CONTENT	α\tagSENT_CONTENT	q\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	task\tagSENT_CONTENT	for\tagSENT_CONTENT	α\tagSENT_CONTENT	e\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	2-way\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	only\tagSENT_CONTENT	add\tagSENT_CONTENT	one\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	task\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	then\tagSENT_START	asked\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	choose\tagSENT_CONTENT	the\tagSENT_CONTENT	better\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	model\tagSENT_CONTENT	summaries\tagSENT_CONTENT	or\tagSENT_CONTENT	choose\tagSENT_CONTENT	'\tagSENT_CONTENT	Not\tagSENT_CONTENT	-\tagSENT_CONTENT	Distinguishable\tagSENT_CONTENT	'\tagSENT_CONTENT	if\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	equally\tagSENT_CONTENT	good\tagSENT_CONTENT	/\tagSENT_CONTENT	bad\tagSENT_CONTENT	.\tagSENT_END	Details\tagSENT_START	of\tagSENT_CONTENT	RNN\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	sizes\tagSENT_CONTENT	,\tagSENT_CONTENT	Adam\tagSENT_CONTENT	optimizer\tagSENT_CONTENT	,\tagSENT_CONTENT	mixing\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Summarization\tagSECTITLE_START	(\tagSECTITLE_CONTENT	Primary\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	3\tagSENT_START	shows\tagSENT_CONTENT	We\tagSENT_CONTENT	use\tagSENT_CONTENT	two\tagSENT_CONTENT	layers\tagSENT_CONTENT	so\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	allow\tagSENT_CONTENT	our\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	versus\tagSENT_CONTENT	lowlevel\tagSENT_CONTENT	layer\tagSENT_CONTENT	sharing\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Task\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_CONTENT	Generation\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	perform\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	between\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	with\tagSENT_CONTENT	soft\tagSENT_CONTENT	-\tagSENT_CONTENT	sharing\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	as\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	are\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE-1\tagmetric	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.01\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.05\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.01\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	all\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.01\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	respective\tagSENT_CONTENT	baseline\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Table\tagSENT_START	1\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	full\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	scores\tagSENT_CONTENT	on\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	and\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	improvements\tagSENT_CONTENT	are\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	metrics\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.01\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE-1\tagSENT_CONTENT	/\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	/\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	and\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.02\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE-2\tagmetric	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.01\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	metrics\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluation\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	conducted\tagSENT_CONTENT	a\tagSENT_CONTENT	blind\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	on\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	MTurk\tagSENT_CONTENT	for\tagSENT_CONTENT	relevance\tagSENT_CONTENT	and\tagSENT_CONTENT	readability\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	100\tagSENT_CONTENT	samples\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	and\tagSENT_CONTENT	Gigaword\tagdataset	(\tagSENT_CONTENT	see\tagSENT_CONTENT	instructions\tagSENT_CONTENT	in\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	5\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Generalizability\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DUC-2002\tagSECTITLE_CONTENT	)\tagSECTITLE_END	We\tagSENT_START	only\tagSENT_CONTENT	retune\tagSENT_CONTENT	the\tagSENT_CONTENT	beam\tagSENT_CONTENT	-\tagSENT_CONTENT	size\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	three\tagSENT_CONTENT	models\tagSENT_CONTENT	separately\tagSENT_CONTENT	(\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	DUC-2003\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Auxiliary\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Entailment\tagSENT_START	Generation\tagSENT_CONTENT	We\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	architecture\tagSENT_CONTENT	as\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Sec\tagSENT_CONTENT	.\tagSENT_CONTENT	3.1\tagSENT_CONTENT	with\tagSENT_CONTENT	pointer\tagSENT_CONTENT	mech-7\tagSENT_CONTENT	Note\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	output\tagSENT_CONTENT	files\tagSENT_CONTENT	of\tagSENT_CONTENT	any\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	's\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	Gigaword\tagdataset	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	is\tagSENT_CONTENT	already\tagSENT_CONTENT	a\tagSENT_CONTENT	strong\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	model\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Ablation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_CONTENT	Studies\tagSECTITLE_END	summarization\tagtask	of\tagSENT_CONTENT	Different\tagSENT_CONTENT	Layer\tagSENT_CONTENT	-\tagSENT_CONTENT	Sharing\tagSENT_CONTENT	Methods\tagSENT_CONTENT	We\tagSENT_CONTENT	also\tagSENT_CONTENT	conducted\tagSENT_CONTENT	ablation\tagSENT_CONTENT	studies\tagSENT_CONTENT	among\tagSENT_CONTENT	various\tagSENT_CONTENT	layer\tagSENT_CONTENT	-\tagSENT_CONTENT	sharing\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	Quantitative\tagSECTITLE_START	Improvements\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_END	Models\tagSECTITLE_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	93\tagSENT_CONTENT	more\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	our\tagSENT_CONTENT	2-way\tagSENT_CONTENT	-\tagSENT_CONTENT	QG\tagSENT_CONTENT	MTL\tagSENT_CONTENT	model\tagSENT_CONTENT	detects\tagSENT_CONTENT	2\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	additional\tagSENT_CONTENT	salient\tagSENT_CONTENT	keywords\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	vice\tagSENT_CONTENT	versa\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	helping\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	finding\tagSENT_CONTENT	more\tagSENT_CONTENT	salient\tagSENT_CONTENT	terms\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	3-way\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	model\tagSENT_CONTENT	generates\tagSENT_CONTENT	summarization\tagtask	that\tagSENT_CONTENT	are\tagSENT_CONTENT	both\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	logical\tagSENT_CONTENT	entailment\tagSENT_CONTENT	and\tagSENT_CONTENT	contain\tagSENT_CONTENT	more\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	given\tagSENT_START	the\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	from\tagSENT_CONTENT	our\tagSENT_CONTENT	supporters\tagSENT_CONTENT	and\tagSENT_CONTENT	across\tagSENT_CONTENT	football\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	duty\tagSENT_CONTENT	bound\tagSENT_CONTENT	to\tagSENT_CONTENT	seek\tagSENT_CONTENT	an\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	what\tagSENT_CONTENT	actually\tagSENT_CONTENT	happened\tagSENT_CONTENT	,\tagSENT_CONTENT	´\tagSENT_CONTENT	celtic\tagSENT_CONTENT	said\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	statement\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	logically\tagSENT_CONTENT	entailed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	via\tagSENT_CONTENT	question\tagSENT_CONTENT	generation\tagSENT_CONTENT	and\tagSENT_CONTENT	entailment\tagSENT_CONTENT	generation\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	
1711.07341	title\tagSECTITLE_END	abstract\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	puts\tagSENT_CONTENT	forward\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	concept\tagSENT_CONTENT	of\tagSENT_CONTENT	"\tagSENT_CONTENT	history\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	to\tagSENT_CONTENT	characterize\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	lowest\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	embedding\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	semantic\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Liechtenstein\tagSENT_START	:\tagSENT_CONTENT	question_answering\tagtask	discussing\tagSENT_CONTENT	Alpine\tagSENT_CONTENT	Rhine\tagSENT_CONTENT	.\tagSENT_END	Teaching\tagSENT_START	machines\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	,\tagSENT_CONTENT	process\tagSENT_CONTENT	and\tagSENT_CONTENT	comprehend\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	key\tagSENT_CONTENT	problems\tagSENT_CONTENT	in\tagSENT_CONTENT	artificial\tagSENT_CONTENT	intelligence\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	key\tagSENT_CONTENT	innovation\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	models\tagSENT_CONTENT	lies\tagSENT_CONTENT	in\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	ingest\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	characterize\tagSENT_CONTENT	it\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	an\tagSENT_CONTENT	accurate\tagSENT_CONTENT	answer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	that\tagSENT_CONTENT	thoroughly\tagSENT_CONTENT	captures\tagSENT_CONTENT	the\tagSENT_CONTENT	complete\tagSENT_CONTENT	information\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	submitted\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	MACHINE\tagSECTITLE_START	COMPREHENSION\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	FULLY\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	AWARE\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_END	TASK\tagSECTITLE_START	DESCRIPTION\tagSECTITLE_END	In\tagSENT_START	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	machine\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	and\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	m\tagmetric	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	n\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	CONCEPTUAL\tagSECTITLE_START	ARCHITECTURE\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	MACHINE\tagSECTITLE_CONTENT	READING\tagSECTITLE_CONTENT	COMPREHENSION\tagSECTITLE_END	•\tagSENT_START	Input\tagSENT_CONTENT	vectors\tagSENT_CONTENT	:\tagSENT_CONTENT	Embedding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Architectures\tagSECTITLE_END	Context\tagSECTITLE_START	Question\tagSECTITLE_END	We\tagSENT_START	now\tagSENT_CONTENT	discuss\tagSENT_CONTENT	them\tagmetric	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	providing\tagSENT_CONTENT	the\tagSENT_CONTENT	direct\tagSENT_CONTENT	word\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	quickly\tagSENT_CONTENT	zoom\tagSENT_CONTENT	in\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	related\tagSENT_CONTENT	regions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Informing\tagSENT_START	the\tagSENT_CONTENT	context\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	could\tagSENT_CONTENT	help\tagSENT_CONTENT	us\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	the\tagSENT_CONTENT	context\tagSENT_CONTENT	contains\tagSENT_CONTENT	excessive\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	common\tagSENT_CONTENT	choice\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boosted\tagSENT_CONTENT	fusion\tagSENT_CONTENT	after\tagSENT_CONTENT	fusing\tagSENT_CONTENT	question_answering\tagtask	Another\tagSENT_START	choice\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	directly\tagSENT_CONTENT	condition\tagSENT_CONTENT	the\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boosted\tagSENT_CONTENT	fusion\tagSENT_CONTENT	process\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	coattention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	common\tagSENT_CONTENT	trait\tagSENT_CONTENT	of\tagSENT_CONTENT	existing\tagSENT_CONTENT	fusion\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	none\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	employs\tagSENT_CONTENT	all\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	representation\tagSENT_CONTENT	jointly\tagSENT_CONTENT	.\tagSENT_END	FULLY\tagSECTITLE_START	-\tagSECTITLE_CONTENT	AWARE\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	HISTORY\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	WORD\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	correctly\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	concept\tagSENT_CONTENT	of\tagSENT_CONTENT	forms\tagSENT_CONTENT	the\tagSENT_CONTENT	border\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	information\tagSENT_CONTENT	of\tagSENT_CONTENT	Alpine\tagSENT_CONTENT	Rhine\tagSENT_CONTENT	.\tagSENT_END	Liechtenstein\tagSECTITLE_END	Form\tagSENT_START	question_answering\tagtask	α\tagSENT_CONTENT	ij\tagSENT_CONTENT	through\tagSENT_CONTENT	softmax\tagSENT_CONTENT	:\tagSENT_END	,\tagSENT_START	where\tagSENT_CONTENT	f\tagmetric	(\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	activation\tagSENT_CONTENT	function\tagSENT_CONTENT	applied\tagSENT_CONTENT	element\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	f\tagmetric	(\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	FULLY\tagSECTITLE_START	-\tagSECTITLE_CONTENT	AWARE\tagSECTITLE_CONTENT	FUSION\tagSECTITLE_CONTENT	NETWORK\tagSECTITLE_END	END\tagSECTITLE_START	-\tagSECTITLE_CONTENT	TO\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	END\tagSECTITLE_CONTENT	ARCHITECTURE\tagSECTITLE_END	Based\tagSENT_START	on\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	architecture\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	fusion\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	special\tagSENT_CONTENT	case\tagSENT_CONTENT	where\tagSENT_CONTENT	text\tagSENT_CONTENT	A\tagSENT_CONTENT	is\tagSENT_CONTENT	context\tagSENT_CONTENT	C\tagSENT_CONTENT	and\tagSENT_CONTENT	text\tagSENT_CONTENT	B\tagSENT_CONTENT	is\tagSENT_CONTENT	question\tagSENT_CONTENT	Q.\tagSENT_CONTENT	An\tagSENT_CONTENT	illustration\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	component\tagSENT_CONTENT	fuses\tagSENT_CONTENT	all\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	C\tagSENT_CONTENT	through\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	on\tagSENT_CONTENT	history\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	calculated\tagSENT_CONTENT	through\tagSENT_CONTENT	attention\tagSENT_CONTENT	function\tagSENT_CONTENT	S\tagSENT_CONTENT	l\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	S\tagSENT_CONTENT	h\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	S\tagSENT_CONTENT	u\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	combine\tagSENT_CONTENT	low\tagSENT_CONTENT	,\tagSENT_CONTENT	high\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	understanding\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	concepts\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	new\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	C\tagSENT_CONTENT	fully\tagSENT_CONTENT	fused\tagSENT_CONTENT	with\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	:\tagSENT_END	are\tagSENT_START	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	C.\tagSENT_CONTENT	After\tagSENT_CONTENT	these\tagSENT_CONTENT	components\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	created\tagSENT_CONTENT	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	U\tagSENT_CONTENT	C\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	C\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	fully\tagSENT_CONTENT	fused\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	Q.\tagSENT_CONTENT	We\tagSENT_CONTENT	also\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	U\tagSENT_CONTENT	Q\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	Q.\tagSENT_END	APPLICATION\tagSECTITLE_START	IN\tagSECTITLE_CONTENT	MACHINE\tagSECTITLE_CONTENT	COMPREHENSION\tagSECTITLE_END	We\tagSENT_START	focus\tagSENT_CONTENT	particularly\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	format\tagSENT_CONTENT	in\tagSENT_CONTENT	SQuAD\tagdataset	(\tagSENT_CONTENT	)\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	is\tagSENT_CONTENT	always\tagSENT_CONTENT	a\tagSENT_CONTENT	span\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	use\tagSENT_CONTENT	them\tagmetric	to\tagSENT_CONTENT	find\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	)\tagSENT_START	,\tagSENT_CONTENT	where\tagSENT_CONTENT	i\tagSENT_CONTENT	s\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	e\tagSENT_CONTENT	k\tagSENT_CONTENT	are\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	instance\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	predict\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	be\tagSENT_CONTENT	i\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	Then\tagSENT_START	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	toend\tagSENT_CONTENT	FusionNet\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	DATASETS\tagSECTITLE_END	SQuAD\tagdataset	is\tagSENT_CONTENT	a\tagSENT_CONTENT	popular\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	dataset\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	100,000\tagSENT_CONTENT	+\tagSENT_CONTENT	questions\tagSENT_CONTENT	created\tagSENT_CONTENT	by\tagSENT_CONTENT	crowd\tagSENT_CONTENT	workers\tagSENT_CONTENT	on\tagSENT_CONTENT	536\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	rapid\tagSENT_CONTENT	progress\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	made\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	whether\tagSENT_CONTENT	these\tagSENT_CONTENT	systems\tagSENT_CONTENT	truly\tagSENT_CONTENT	understand\tagSENT_CONTENT	language\tagSENT_CONTENT	remains\tagSENT_CONTENT	unclear\tagSENT_CONTENT	.\tagSENT_END	MAIN\tagSECTITLE_START	RESULTS\tagSECTITLE_END	We\tagSENT_START	submitted\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	SQuAD\tagdataset	for\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Test\tagSECTITLE_START	Set\tagSECTITLE_CONTENT	Single\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	This\tagSENT_START	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	COMPARISON\tagSECTITLE_START	ON\tagSECTITLE_CONTENT	ATTENTION\tagSECTITLE_CONTENT	FUNCTION\tagSECTITLE_END	EFFECTIVENESS\tagSECTITLE_START	OF\tagSECTITLE_CONTENT	HISTORY\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	WORD\tagSECTITLE_END	In\tagSENT_START	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	history\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	major\tagSENT_CONTENT	places\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	good\tagSENT_CONTENT	performance\tagSENT_CONTENT	:\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	fusion\tagSENT_CONTENT	and\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boosted\tagSENT_CONTENT	fusion\tagSENT_CONTENT	.\tagSENT_END	FA\tagSENT_START	All\tagSENT_CONTENT	-\tagSENT_CONTENT	Level\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	naive\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	FA\tagSENT_CONTENT	High\tagSENT_CONTENT	-\tagSENT_CONTENT	Level\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	all\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	are\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	fused\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	using\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Normal\tagSENT_START	means\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	a\tagSENT_CONTENT	standard\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boosted\tagSENT_CONTENT	fusion\tagSENT_CONTENT	after\tagSENT_CONTENT	fusing\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	fuse\tagSENT_CONTENT	all\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	context\tagSENT_CONTENT	C.\tagSENT_CONTENT	FA\tagSENT_END	Together\tagSENT_START	,\tagSENT_CONTENT	these\tagSENT_CONTENT	experiments\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	all\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	whole\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	for\tagSENT_CONTENT	machines\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	CONCLUSIONS\tagSECTITLE_END	question_answering\tagtask	proposes\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	with\tagSENT_CONTENT	following\tagSENT_CONTENT	three\tagSENT_CONTENT	contributions\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	DETAILED\tagSECTITLE_CONTENT	CONFIGURATIONS\tagSECTITLE_CONTENT	IN\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	ABLATION\tagSECTITLE_CONTENT	STUDY\tagSECTITLE_END	For\tagSENT_START	all\tagSENT_CONTENT	configurations\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	C\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	Q\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	generated\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	output\tagSENT_CONTENT	architecture\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.2\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	Firstly\tagSENT_START	,\tagSENT_CONTENT	context\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	transformed\tagSENT_CONTENT	into\tagSENT_CONTENT	input\tagSENT_CONTENT	vectors\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	way\tagSENT_CONTENT	as\tagSENT_CONTENT	FusionNet\tagSENT_CONTENT	,\tagSENT_CONTENT	{\tagSENT_CONTENT	w\tagSENT_CONTENT	C\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_END	Now\tagSENT_START	we\tagSENT_CONTENT	have\tagSENT_CONTENT	obtained\tagSENT_CONTENT	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	is\tagSENT_START	the\tagSENT_CONTENT	common\tagSENT_CONTENT	history\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	The\tagSENT_START	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Understanding\tagSENT_CONTENT	component\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.1\tagSENT_CONTENT	,\tagSENT_END	We\tagSENT_START	have\tagSENT_CONTENT	now\tagSENT_CONTENT	generated\tagSENT_CONTENT	the\tagSENT_CONTENT	understanding\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	This\tagSENT_START	configuration\tagSENT_CONTENT	follows\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Fully\tagSENT_CONTENT	-\tagSENT_CONTENT	Aware\tagSENT_CONTENT	Fusion\tagSENT_CONTENT	Network\tagSENT_CONTENT	(\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.1\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	normal\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boosted\tagSENT_CONTENT	fusion\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	under\tagSENT_CONTENT	our\tagSENT_CONTENT	improved\tagSENT_CONTENT	fusion\tagSENT_CONTENT	approach\tagSENT_CONTENT	between\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	turn\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boosted\tagSENT_CONTENT	fusion\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	useful\tagSENT_CONTENT	component\tagSENT_CONTENT	by\tagSENT_CONTENT	enhancing\tagSENT_CONTENT	it\tagSENT_CONTENT	with\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	C\tagSECTITLE_START	ADDITIONAL\tagSECTITLE_CONTENT	ABLATION\tagSECTITLE_CONTENT	STUDY\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	INPUT\tagSECTITLE_CONTENT	VECTORS\tagSECTITLE_END	For\tagSENT_START	question_answering\tagtask	(\tagSENT_CONTENT	without\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	directly\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	D\tagSECTITLE_START	APPLICATION\tagSECTITLE_CONTENT	TO\tagSECTITLE_CONTENT	NATURAL\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	INFERENCE\tagSECTITLE_END	question_answering\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	improved\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	easily\tagSENT_CONTENT	added\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	is\tagSENT_CONTENT	Enhanced\tagSENT_CONTENT	Sequential\tagSENT_CONTENT	Inference\tagSENT_CONTENT	Model\tagSENT_CONTENT	(\tagSENT_CONTENT	ESIM\tagmetric	)\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagSENT_CONTENT	accuray\tagSENT_CONTENT	of\tagSENT_CONTENT	88.0\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	and\tagSENT_CONTENT	obtained\tagSENT_CONTENT	72.3\tagSENT_CONTENT	%\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	72.1\tagSENT_CONTENT	%\tagSENT_CONTENT	(\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	MultiNLI\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	implemented\tagSENT_CONTENT	aversion\tagSENT_CONTENT	of\tagSENT_CONTENT	ESIM\tagmetric	in\tagSENT_CONTENT	PyTorch\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	ESIM\tagmetric	fuses\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	P\tagSENT_CONTENT	to\tagSENT_CONTENT	H\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	from\tagSENT_CONTENT	H\tagSENT_CONTENT	to\tagSENT_CONTENT	P\tagSENT_CONTENT	using\tagSENT_CONTENT	standard\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	set\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	hidden\tagSENT_CONTENT	vectors\tagSENT_CONTENT	h.\tagSENT_CONTENT	Next\tagSENT_CONTENT	,\tagSENT_CONTENT	ESIM\tagmetric	feed\tagSENT_CONTENT	g\tagSENT_CONTENT	P\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	g\tagSENT_CONTENT	H\tagSENT_CONTENT	j\tagSENT_CONTENT	into\tagSENT_CONTENT	separate\tagSENT_CONTENT	BiLSTMs\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	inference\tagSENT_CONTENT	.\tagSENT_END	Cross\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Domain\tagSECTITLE_CONTENT	In\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Domain\tagSECTITLE_END	Now\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	improving\tagSENT_CONTENT	ESIM\tagmetric	with\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	augment\tagSENT_CONTENT	standard\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	ESIM\tagmetric	with\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	incorporate\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	fusion\tagSENT_CONTENT	into\tagSENT_CONTENT	ESIM\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	change\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	for\tagSENT_CONTENT	inference\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	from\tagSENT_END	For\tagSENT_START	fair\tagSENT_CONTENT	comparison\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	in\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	from\tagSENT_CONTENT	300\tagSENT_CONTENT	to\tagSENT_CONTENT	250\tagSENT_CONTENT	after\tagSENT_CONTENT	adding\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	enhancements\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	the\tagSENT_CONTENT	parameter\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	ESIM\tagmetric	with\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	attention\tagSENT_CONTENT	and\tagSENT_CONTENT	fully\tagSENT_CONTENT	-\tagSENT_CONTENT	aware\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	or\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	ESIM\tagmetric	with\tagSENT_CONTENT	standard\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	of\tagSENT_CONTENT	ESIM\tagmetric	under\tagSENT_CONTENT	different\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Together\tagSENT_START	,\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	conform\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	observations\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	on\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	task\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	all\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	whole\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	for\tagSENT_CONTENT	machines\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	E\tagSECTITLE_START	MODEL\tagSECTITLE_CONTENT	DETAILS\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	voting\tagSENT_CONTENT	scheme\tagSENT_CONTENT	:\tagSENT_CONTENT	each\tagSENT_CONTENT	model\tagSENT_CONTENT	generates\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	votes\tagSENT_CONTENT	is\tagSENT_CONTENT	selected\tagSENT_CONTENT	.\tagSENT_END	F\tagSECTITLE_START	SAMPLE\tagSECTITLE_CONTENT	EXAMPLES\tagSECTITLE_CONTENT	FROM\tagSECTITLE_CONTENT	ADVERSARIAL\tagSECTITLE_CONTENT	SQUAD\tagSECTITLE_CONTENT	DATASET\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	percentage\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answered\tagSENT_CONTENT	correctly\tagSENT_CONTENT	(\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	FusionNet\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	model\tagSENT_CONTENT	BiDAF\tagSENT_CONTENT	.\tagSENT_END	F.1\tagSECTITLE_START	FUSIONNET\tagSECTITLE_CONTENT	ANSWERS\tagSECTITLE_CONTENT	CORRECTLY\tagSECTITLE_CONTENT	WHILE\tagSECTITLE_CONTENT	BIDAF\tagSECTITLE_CONTENT	IS\tagSECTITLE_CONTENT	INCORRECT\tagSECTITLE_END	Those\tagSENT_START	involved\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	design\tagSENT_CONTENT	and\tagSENT_CONTENT	execution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	infrastructure\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	must\tagSENT_CONTENT	consider\tagSENT_CONTENT	zoning\tagSENT_CONTENT	requirements\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	environmental\tagSENT_CONTENT	impact\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	job\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	successful\tagSENT_CONTENT	scheduling\tagSENT_CONTENT	,\tagSENT_CONTENT	budgeting\tagSENT_CONTENT	,\tagSENT_CONTENT	construction\tagSENT_CONTENT	-\tagSENT_CONTENT	site\tagSENT_CONTENT	safety\tagSENT_CONTENT	,\tagSENT_CONTENT	availability\tagSENT_CONTENT	and\tagSENT_CONTENT	transportation\tagSENT_CONTENT	of\tagSENT_CONTENT	building\tagSENT_CONTENT	materials\tagSENT_CONTENT	,\tagSENT_CONTENT	logistics\tagSENT_CONTENT	,\tagSENT_CONTENT	inconvenience\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	public\tagSENT_CONTENT	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	construction\tagSENT_CONTENT	delays\tagSENT_CONTENT	and\tagSENT_CONTENT	bidding\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	:\tagSENT_CONTENT	What\tagSENT_CONTENT	is\tagSENT_CONTENT	essential\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	successful\tagSENT_CONTENT	execution\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	project\tagSENT_CONTENT	?\tagSENT_END	question_answering\tagtask	:\tagSENT_CONTENT	What\tagSENT_CONTENT	publication\tagSENT_CONTENT	printed\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	wealthiest\tagSENT_CONTENT	1\tagSENT_CONTENT	%\tagSENT_CONTENT	have\tagSENT_CONTENT	more\tagSENT_CONTENT	money\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	bottom\tagSENT_CONTENT	90\tagSENT_CONTENT	%\tagSENT_CONTENT	?\tagSENT_END	question_answering\tagtask	:\tagSENT_CONTENT	What\tagSENT_CONTENT	was\tagSENT_CONTENT	Shrewsbury\tagSENT_CONTENT	's\tagSENT_CONTENT	conclusion\tagSENT_CONTENT	?\tagSENT_END	question_answering\tagtask	:\tagSENT_CONTENT	Which\tagSENT_CONTENT	is\tagSENT_CONTENT	older\tagSENT_CONTENT	the\tagSENT_CONTENT	British\tagSENT_CONTENT	Empire\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	Ethiopian\tagSENT_CONTENT	Empire\tagSENT_CONTENT	?\tagSENT_END	
P17-1043	title\tagSECTITLE_END	abstract\tagSECTITLE_END	amr_parsing\tagtask	represent\tagSENT_CONTENT	semantic\tagSENT_CONTENT	content\tagSENT_CONTENT	using\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	properties\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	semantic\tagSENT_CONTENT	roles\tagSENT_CONTENT	,\tagSENT_CONTENT	coref\tagSENT_CONTENT	-\tagSENT_CONTENT	erence\tagSENT_CONTENT	,\tagSENT_CONTENT	negation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	does\tagSENT_CONTENT	not\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	parse\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	heavily\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	uses\tagSENT_CONTENT	five\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	architectural\tagSENT_CONTENT	components\tagSENT_CONTENT	for\tagSENT_CONTENT	inferring\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Semantic\tagSENT_START	analysis\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	extracting\tagSENT_CONTENT	amr_parsing\tagtask	from\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	revealing\tagSENT_CONTENT	key\tagSENT_CONTENT	ideas\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	who\tagSENT_CONTENT	did\tagSENT_CONTENT	what\tagSENT_CONTENT	to\tagSENT_CONTENT	whom\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	,\tagSENT_CONTENT	how\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	where\tagSENT_CONTENT	?\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	complex\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	rise\tagSENT_CONTENT	of\tagSENT_CONTENT	supervised\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	techniques\tagSENT_CONTENT	,\tagSENT_CONTENT	anew\tagSENT_CONTENT	requirement\tagSENT_CONTENT	has\tagSENT_CONTENT	come\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fore\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	human\tagSENT_CONTENT	annotators\tagSENT_CONTENT	to\tagSENT_CONTENT	quickly\tagSENT_CONTENT	and\tagSENT_CONTENT	reliably\tagSENT_CONTENT	generate\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representations\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	data\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	include\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	traditional\tagSENT_CONTENT	NLP\tagSENT_CONTENT	representations\tagSENT_CONTENT	including\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	senses\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	coreference\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	structures\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	More\tagSENT_START	recent\tagSENT_CONTENT	innovations\tagSENT_CONTENT	include\tagSENT_CONTENT	wikification\tagSENT_CONTENT	of\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	normalization\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	A\tagSENT_START	consistent\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	amr_parsing\tagtask	was\tagSENT_CONTENT	defined\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	Semeval-2016\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representation\tagSENT_CONTENT	Parsing\tagSENT_CONTENT	Task\tagSENT_CONTENT	.\tagSENT_END	Viewed\tagSENT_START	as\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	poses\tagSENT_CONTENT	some\tagSENT_CONTENT	difficult\tagSENT_CONTENT	challenges\tagSENT_CONTENT	not\tagSENT_CONTENT	faced\tagSENT_CONTENT	by\tagSENT_CONTENT	other\tagSENT_CONTENT	related\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	including\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	or\tagSENT_CONTENT	se-\tagSENT_CONTENT	 \tagSENT_END	(\tagSENT_START	b\tagSENT_CONTENT	)\tagSENT_CONTENT	General\tagSENT_CONTENT	Architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	creates\tagSENT_CONTENT	an\tagSENT_CONTENT	AMR\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	challenge\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	by\tagSENT_CONTENT	design\tagSENT_CONTENT	abstracted\tagSENT_CONTENT	away\tagSENT_CONTENT	from\tagSENT_CONTENT	their\tagSENT_CONTENT	associated\tagSENT_CONTENT	surface\tagSENT_CONTENT	forms\tagSENT_CONTENT	.\tagSENT_END	Not\tagSENT_START	surprisingly\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	complicates\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	decoding\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	second\tagSENT_CONTENT	challenge\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	noted\tagSENT_CONTENT	earlier\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	amalgam\tagSENT_CONTENT	of\tagSENT_CONTENT	predicate\tagSENT_CONTENT	identification\tagSENT_CONTENT	and\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	reference\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	sense\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeling\tagSENT_CONTENT	-each\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	others\tagSENT_CONTENT	for\tagSENT_CONTENT	successful\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	AMR\tagSECTITLE_START	Parsers\tagSECTITLE_END	The\tagSENT_START	largely\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	converts\tagSENT_CONTENT	logical\tagSENT_CONTENT	forms\tagSENT_CONTENT	from\tagSENT_CONTENT	an\tagSENT_CONTENT	existing\tagSENT_CONTENT	semantic\tagSENT_CONTENT	analyzer\tagSENT_CONTENT	into\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	They\tagSENT_START	demonstrate\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	their\tagSENT_CONTENT	existing\tagSENT_CONTENT	system\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	amr_parsing\tagtask	in\tagSENT_CONTENT	German\tagSENT_CONTENT	,\tagSENT_CONTENT	French\tagSENT_CONTENT	,\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	and\tagSENT_CONTENT	Japanese\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	fora\tagSENT_CONTENT	native\tagSENT_CONTENT	AMR\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	exception\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	heavily\tagSENT_CONTENT	engineered\tagSENT_CONTENT	features\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Bidirectional\tagSECTITLE_START	LSTM\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	Parser\tagSECTITLE_START	Overview\tagSECTITLE_END	amr_parsing\tagtask	5\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	explained\tagSENT_CONTENT	using\tagSENT_CONTENT	this\tagSENT_CONTENT	example\tagSENT_CONTENT	sentence\tagSENT_CONTENT	:\tagSENT_CONTENT	France\tagSENT_CONTENT	plans\tagSENT_CONTENT	further\tagSENT_CONTENT	nuclear\tagSENT_CONTENT	cooperation\tagSENT_CONTENT	with\tagSENT_CONTENT	numerous\tagSENT_CONTENT	countries\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	approach\tagSENT_CONTENT	taken\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	subtasks\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	discover\tagSENT_CONTENT	the\tagSENT_CONTENT	concepts\tagSENT_CONTENT	(\tagSENT_CONTENT	nodes\tagSENT_CONTENT	and\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	graphs\tagSENT_CONTENT	)\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	relations\tagSENT_CONTENT	(\tagSENT_CONTENT	arcs\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	connect\tagSENT_CONTENT	the\tagSENT_CONTENT	concepts\tagSENT_CONTENT	(\tagSENT_CONTENT	relations\tagSENT_CONTENT	capture\tagSENT_CONTENT	both\tagSENT_CONTENT	traditional\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	structures\tagSENT_CONTENT	(\tagSENT_CONTENT	ARGs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	modifier\tagSENT_CONTENT	relations\tagSENT_CONTENT	that\tagSENT_CONTENT	capture\tagSENT_CONTENT	notions\tagSENT_CONTENT	including\tagSENT_CONTENT	quantification\tagSENT_CONTENT	,\tagSENT_CONTENT	polarity\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	cardinality\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	Among\tagSENT_START	the\tagSENT_CONTENT	complications\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	individual\tagSENT_CONTENT	words\tagSENT_CONTENT	may\tagSENT_CONTENT	contribute\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	one\tagSENT_CONTENT	node\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	France\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	maybe\tagSENT_CONTENT	"\tagSENT_CONTENT	reentrant\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	participating\tagSENT_CONTENT	in\tagSENT_CONTENT	relations\tagSENT_CONTENT	with\tagSENT_CONTENT	multiple\tagSENT_CONTENT	concepts\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	and\tagSENT_CONTENT	modifier\tagSENT_CONTENT	relations\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	Features\tagSENT_START	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	these\tagSENT_CONTENT	subgraphs\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	processed\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	B\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	all\tagSENT_CONTENT	subgraphs\tagSENT_CONTENT	.\tagSENT_END	Detailed\tagSECTITLE_START	Parser\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	AMR\tagSECTITLE_START	Spans\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Subgraphs\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Subgraph\tagSECTITLE_CONTENT	Decoding\tagSECTITLE_END	Mapping\tagSENT_START	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	critical\tagSENT_CONTENT	first\tagSENT_CONTENT	step\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	influence\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	Likewise\tagSENT_START	,\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	words\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	mapped\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	connected\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	single\tagSENT_CONTENT	word\tagSENT_CONTENT	span\tagSENT_CONTENT	France\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	mapped\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	concepts\tagSENT_CONTENT	connected\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	name\tagSENT_CONTENT	relation\tagSENT_CONTENT	.\tagSENT_END	Training\tagSENT_START	corpora\tagSENT_CONTENT	provide\tagSENT_CONTENT	sentences\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	annotated\tagSENT_CONTENT	by\tagSENT_CONTENT	humans\tagSENT_CONTENT	with\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	not\tagSENT_CONTENT	necessarily\tagSENT_CONTENT	including\tagSENT_CONTENT	a\tagSENT_CONTENT	reference\tagSENT_CONTENT	span\tagSENT_CONTENT	to\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Features\tagSECTITLE_END	With\tagSENT_START	the\tagSENT_CONTENT	exception\tagSENT_CONTENT	of\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	lookup\tagSENT_CONTENT	tables\tagSENT_CONTENT	are\tagSENT_CONTENT	randomly\tagSENT_CONTENT	initialized\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	created\tagSENT_CONTENT	during\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	process\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	Embeddings\tagSECTITLE_END	We\tagSENT_START	added\tagSENT_CONTENT	two\tagSENT_CONTENT	binary\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	:\tagSENT_CONTENT	one\tagSENT_CONTENT	for\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	one\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	resulting\tagSENT_CONTENT	in\tagSENT_CONTENT	vectors\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	width\tagSENT_CONTENT	of\tagSENT_CONTENT	302\tagSENT_CONTENT	.\tagSENT_END	Wikifier\tagSECTITLE_END	Expert\tagSECTITLE_START	Span\tagSECTITLE_CONTENT	Identifier\tagSECTITLE_END	Compare\tagSECTITLE_END	Subgraph\tagSECTITLE_START	Expander\tagSECTITLE_END	Sentence\tagSECTITLE_END	Subgraph\tagSECTITLE_START	Spans\tagSECTITLE_END	Named\tagSENT_START	Entity\tagSENT_CONTENT	Recognition\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	valuable\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	NER\tagSENT_CONTENT	systems\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	created\tagSENT_CONTENT	using\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	Collobert\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	Chiu\tagSENT_CONTENT	and\tagSENT_CONTENT	Nichols\tagSENT_CONTENT	,\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	aided\tagSENT_CONTENT	by\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	gazetteers\tagSENT_CONTENT	.\tagSENT_END	AMR\tagSECTITLE_START	Subgraph\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	SG\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Predicate\tagSECTITLE_START	Argument\tagSECTITLE_CONTENT	Relations\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	Args\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	The\tagSENT_START	Args\tagSENT_CONTENT	Network\tagSENT_CONTENT	is\tagSENT_CONTENT	run\tagSENT_CONTENT	once\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	predicate\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	produces\tagSENT_CONTENT	amr_parsing\tagtask	which\tagSENT_CONTENT	defines\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	(\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	any\tagSENT_CONTENT	relations\tagSENT_CONTENT	6\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	predicate\tagSENT_CONTENT	argument\tagSENT_CONTENT	relation\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	predicate\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	other\tagSENT_CONTENT	SG\tagSENT_CONTENT	identified\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	,\tagSENT_CONTENT	46x10\tagSENT_CONTENT	:\tagSENT_END	Non\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Predicate\tagSECTITLE_CONTENT	Relations\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	Nargs\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	run\tagSENT_CONTENT	once\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	produces\tagSENT_CONTENT	amr_parsing\tagtask	which\tagSENT_CONTENT	defines\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	relation\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	other\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	,\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	identification\tagSENT_CONTENT	of\tagSENT_CONTENT	any\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Attributes\tagSECTITLE_START	(\tagSECTITLE_CONTENT	Attr\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Named\tagSECTITLE_START	Category\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	NCat\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	Relation\tagSECTITLE_START	Resolution\tagSECTITLE_END	AMR\tagSECTITLE_START	Construction\tagSECTITLE_END	amr_parsing\tagtask	converts\tagSENT_CONTENT	the\tagSENT_CONTENT	connected\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	AMR\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graph\tagSENT_CONTENT	form\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	proper\tagSENT_CONTENT	concepts\tagSENT_CONTENT	,\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	root\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	When\tagSENT_START	a\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	contains\tagSENT_CONTENT	two\tagSENT_CONTENT	concepts\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	choice\tagSENT_CONTENT	of\tagSENT_CONTENT	connecting\tagSENT_CONTENT	to\tagSENT_CONTENT	parent\tagSENT_CONTENT	or\tagSENT_CONTENT	child\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	is\tagSENT_CONTENT	made\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	data\tagSENT_CONTENT	statistics\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	relation\tagSENT_CONTENT	type\tagSENT_CONTENT	(\tagSENT_CONTENT	Arg\tagSENT_CONTENT	or\tagSENT_CONTENT	Narg\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	subgraph\tagSENT_CONTENT	type\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	A\tagSENT_START	practical\tagSENT_CONTENT	graph\tagSENT_CONTENT	comparison\tagSENT_CONTENT	program\tagSENT_CONTENT	called\tagSENT_CONTENT	Smatch\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	consistently\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	After\tagSENT_START	all\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	linear\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	added\tagSENT_CONTENT	dropout\tagSENT_CONTENT	to\tagSENT_CONTENT	minimize\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	batch\tagSENT_CONTENT	normalization\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	sensitivity\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	rates\tagSENT_CONTENT	and\tagSENT_CONTENT	initialization\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	five\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	LDC2015E86\tagSENT_CONTENT	training\tagSENT_CONTENT	split\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	parameters\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	periodically\tagSENT_CONTENT	interrupted\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	run\tagSENT_CONTENT	the\tagSENT_CONTENT	dev\tagSENT_CONTENT	split\tagSENT_CONTENT	(\tagSENT_CONTENT	forward\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	monitor\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagSENT_CONTENT	statistics\tagSENT_CONTENT	for\tagSENT_CONTENT	smatch\tagmetric	results\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	test\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	eval\tagSENT_CONTENT	"\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	12\tagSENT_CONTENT	trained\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	a\tagmetric	smatch\tagmetric	score\tagmetric	of\tagSENT_CONTENT	between\tagSENT_CONTENT	0.651\tagSENT_CONTENT	and\tagSENT_CONTENT	0.654\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	mean\tagSENT_CONTENT	of\tagSENT_CONTENT	0.652\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parser\tagSENT_CONTENT	performance\tagSENT_CONTENT	by\tagSENT_CONTENT	between\tagSENT_CONTENT	5.07\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	5.55\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	mean\tagSENT_CONTENT	of\tagSENT_CONTENT	5.22\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Individual\tagSECTITLE_START	Network\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	amr_parsing\tagtask	effectively\tagSENT_CONTENT	exploits\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	B\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	to\tagSENT_CONTENT	selectively\tagSENT_CONTENT	extract\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	words\tagSENT_CONTENT	separated\tagSENT_CONTENT	by\tagSENT_CONTENT	long\tagSENT_CONTENT	distances\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	buildup\tagSENT_CONTENT	higher\tagSENT_CONTENT	level\tagSENT_CONTENT	representations\tagSENT_CONTENT	by\tagSENT_CONTENT	rejecting\tagSENT_CONTENT	or\tagSENT_CONTENT	remembering\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	during\tagSENT_CONTENT	sequence\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	changes\tagSENT_CONTENT	which\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	made\tagSENT_CONTENT	to\tagSENT_CONTENT	eliminate\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	parser\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Eliminating\tagSENT_START	the\tagSENT_CONTENT	need\tagSENT_CONTENT	for\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	parsing\tagSENT_CONTENT	is\tagSENT_CONTENT	valuable\tagSENT_CONTENT	since\tagSENT_CONTENT	a\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	parser\tagSENT_CONTENT	takes\tagSENT_CONTENT	up\tagSENT_CONTENT	significant\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	computational\tagSENT_CONTENT	resources\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	errors\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	syntax\tagSENT_CONTENT	will\tagSENT_CONTENT	propagate\tagSENT_CONTENT	into\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	But\tagSENT_START	it\tagSENT_CONTENT	would\tagSENT_CONTENT	also\tagSENT_CONTENT	be\tagSENT_CONTENT	fairly\tagSENT_CONTENT	easy\tagSENT_CONTENT	to\tagSENT_CONTENT	add\tagSENT_CONTENT	gazetteer\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	remove\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Improvements\tagSENT_START	in\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	alignment\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	would\tagSENT_CONTENT	improve\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	System\tagSECTITLE_END	Description\tagSECTITLE_START	Test\tagSECTITLE_CONTENT	F1\tagSECTITLE_CONTENT	Eval\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	OOD\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	F1\tagSECTITLE_END	amr_parsing\tagtask	(\tagSENT_CONTENT	summary\tagSENT_CONTENT	of\tagSENT_CONTENT	12\tagSENT_CONTENT	trained\tagSENT_CONTENT	systems\tagSENT_CONTENT	)\tagSENT_CONTENT	mean\tagSENT_CONTENT	0.707\tagSENT_CONTENT	0.652\tagSENT_CONTENT	min\tagSENT_CONTENT	0.706\tagSENT_CONTENT	0.651\tagSENT_END	Smatch\tagmetric	F1\tagmetric	results\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	and\tagSENT_CONTENT	top\tagSENT_CONTENT	5\tagSENT_CONTENT	parsers\tagSENT_CONTENT	from\tagSENT_CONTENT	semeval\tagSENT_CONTENT	2016\tagSENT_CONTENT	task\tagSENT_CONTENT	8\tagSENT_CONTENT	.\tagSENT_END	
1708.02182	title\tagSECTITLE_END	Regularizing\tagSENT_START	and\tagSENT_CONTENT	Optimizing\tagSENT_CONTENT	language_modeling\tagtask	abstract\tagSECTITLE_END	Recurrent\tagSENT_START	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	long\tagSENT_CONTENT	short\tagSENT_CONTENT	-\tagSENT_CONTENT	term\tagSENT_CONTENT	memory\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	building\tagSENT_CONTENT	block\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	sequence\tagSENT_CONTENT	learning\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Given\tagSENT_START	the\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	parameterization\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	generalization\tagmetric	performance\tagmetric	crucially\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	regularize\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	sufficiently\tagSENT_CONTENT	.\tagSENT_END	propose\tagSENT_START	overcoming\tagSENT_CONTENT	this\tagmetric	problem\tagmetric	by\tagSENT_CONTENT	retaining\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dropout\tagSENT_CONTENT	mask\tagSENT_CONTENT	across\tagSENT_CONTENT	multiple\tagSENT_CONTENT	time\tagSENT_CONTENT	steps\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	sampling\tagSENT_CONTENT	anew\tagSENT_CONTENT	binary\tagSENT_CONTENT	mask\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	timestep\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	done\tagSENT_CONTENT	either\tagSENT_CONTENT	through\tagSENT_CONTENT	restricting\tagSENT_CONTENT	the\tagmetric	capacity\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	matrix\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	through\tagSENT_CONTENT	element\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	interactions\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Other\tagmetric	forms\tagmetric	of\tagSENT_CONTENT	regularization\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	act\tagSENT_CONTENT	upon\tagSENT_CONTENT	activations\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	batch\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	batch\tagSENT_CONTENT	normalization\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Once\tagSENT_START	language_modeling\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	defined\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	used\tagSENT_CONTENT	is\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	find\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	minimizer\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	converge\tagSENT_CONTENT	to\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	minimizer\tagSENT_CONTENT	rapidly\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	the\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	SGD\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	within\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	averaged\tagSENT_CONTENT	SGD\tagSENT_CONTENT	(\tagSENT_CONTENT	ASGD\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	known\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	superior\tagSENT_CONTENT	theoretical\tagSENT_CONTENT	guarantees\tagSENT_CONTENT	.\tagSENT_END	Weight\tagSECTITLE_START	-\tagSECTITLE_CONTENT	dropped\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_END	Preventing\tagSENT_START	overfitting\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	connections\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	an\tagSENT_CONTENT	area\tagSENT_CONTENT	of\tagSENT_CONTENT	extensive\tagSENT_CONTENT	research\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	As\tagSENT_START	the\tagSENT_CONTENT	same\tagSENT_CONTENT	weights\tagSENT_CONTENT	are\tagSENT_CONTENT	reused\tagSENT_CONTENT	over\tagSENT_CONTENT	multiple\tagSENT_CONTENT	timesteps\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	individual\tagSENT_CONTENT	dropped\tagSENT_CONTENT	weights\tagSENT_CONTENT	remain\tagSENT_CONTENT	dropped\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagmetric	entirety\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	pass\tagSENT_CONTENT	.\tagSENT_END	Optimization\tagSECTITLE_END	SGD\tagSENT_START	is\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagmetric	most\tagmetric	popular\tagmetric	methods\tagmetric	for\tagSENT_CONTENT	training\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	across\tagSENT_CONTENT	various\tagSENT_CONTENT	modalities\tagSENT_CONTENT	including\tagSENT_CONTENT	computer\tagSENT_CONTENT	vision\tagSENT_CONTENT	,\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	specific\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	traditionally\tagSENT_CONTENT	SGD\tagSENT_CONTENT	without\tagSENT_CONTENT	momentum\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	found\tagSENT_CONTENT	to\tagSENT_CONTENT	outperform\tagSENT_CONTENT	other\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	momentum\tagSENT_CONTENT	SGD\tagSENT_CONTENT	,\tagSENT_CONTENT	Adam\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	Adagrad\tagSENT_CONTENT	(\tagSENT_CONTENT	Duchi\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	RMSProp\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	margin\tagSENT_CONTENT	.\tagSENT_END	ASGD\tagSENT_START	takes\tagSENT_CONTENT	steps\tagSENT_CONTENT	identical\tagSENT_CONTENT	to\tagSENT_CONTENT	equation\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	but\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	returning\tagSENT_CONTENT	the\tagmetric	last\tagmetric	iterate\tagmetric	as\tagSENT_CONTENT	the\tagSENT_CONTENT	solution\tagSENT_CONTENT	,\tagSENT_CONTENT	returns\tagSENT_END	4\tagSECTITLE_START	:\tagSECTITLE_END	Compute\tagmetric	validation\tagmetric	perplexity\tagmetric	v.\tagSENT_END	6\tagSECTITLE_START	:\tagSECTITLE_END	Further\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	constant\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	throughout\tagSENT_CONTENT	the\tagmetric	experiment\tagmetric	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	no\tagSENT_CONTENT	further\tagSENT_CONTENT	tuning\tagSENT_CONTENT	is\tagSENT_CONTENT	necessary\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	decay\tagSENT_CONTENT	scheduling\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	common\tagSENT_CONTENT	strategy\tagSENT_CONTENT	employed\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	rates\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	proportion\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	primary\tagSENT_CONTENT	metric\tagSENT_CONTENT	(\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	)\tagSENT_CONTENT	worsens\tagSENT_CONTENT	or\tagSENT_CONTENT	stagnates\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	the\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	introduces\tagSENT_CONTENT	two\tagmetric	additional\tagmetric	hyperparameters\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	logging\tagSENT_CONTENT	interval\tagSENT_CONTENT	Land\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	monotone\tagSENT_CONTENT	interval\tagSENT_CONTENT	n\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	setting\tagSENT_CONTENT	L\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	iterations\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	epoch\tagSENT_CONTENT	and\tagSENT_CONTENT	n\tagSENT_CONTENT	=\tagSENT_CONTENT	5\tagSENT_CONTENT	worked\tagSENT_CONTENT	well\tagSENT_CONTENT	across\tagSENT_CONTENT	various\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Extended\tagSECTITLE_START	regularization\tagSECTITLE_CONTENT	techniques\tagSECTITLE_END	Variable\tagSECTITLE_START	length\tagSECTITLE_CONTENT	backpropagation\tagSECTITLE_CONTENT	sequences\tagSECTITLE_END	Variational\tagSECTITLE_START	dropout\tagSECTITLE_END	New\tagSENT_START	dropout\tagSENT_CONTENT	masks\tagSENT_CONTENT	are\tagSENT_CONTENT	sampled\tagSENT_CONTENT	even\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	given\tagSENT_CONTENT	connection\tagSENT_CONTENT	is\tagSENT_CONTENT	repeated\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	x\tagSENT_CONTENT	0\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	at\tagSENT_CONTENT	timestep\tagmetric	t\tagmetric	=\tagSENT_CONTENT	0\tagSENT_END	While\tagSENT_START	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	using\tagSENT_CONTENT	DropConnect\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	variational\tagmetric	dropout\tagmetric	to\tagSENT_CONTENT	regularize\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	hidden\tagSENT_CONTENT	transition\tagSENT_CONTENT	within\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	variational\tagSENT_CONTENT	dropout\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	other\tagSENT_CONTENT	dropout\tagSENT_CONTENT	operations\tagSENT_CONTENT	,\tagSENT_CONTENT	specifically\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	dropout\tagSENT_CONTENT	mask\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	inputs\tagSENT_CONTENT	and\tagSENT_CONTENT	outputs\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	within\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	pass\tagSENT_CONTENT	.\tagSENT_END	Embedding\tagSECTITLE_START	dropout\tagSECTITLE_END	The\tagSENT_START	remaining\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	dropped\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	scaled\tagSENT_CONTENT	by\tagSENT_CONTENT	1\tagSENT_CONTENT	1−pe\tagSENT_CONTENT	where\tagSENT_CONTENT	p\tagSENT_CONTENT	e\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagmetric	probability\tagmetric	of\tagSENT_CONTENT	embedding\tagSENT_CONTENT	dropout\tagSENT_CONTENT	.\tagSENT_END	Weight\tagSECTITLE_START	tying\tagSECTITLE_END	Weight\tagSENT_START	tying\tagSENT_CONTENT	shares\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	and\tagSENT_CONTENT	softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	substantially\tagSENT_CONTENT	reducing\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	parameter\tagSENT_CONTENT	count\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Independent\tagSECTITLE_START	embedding\tagSECTITLE_CONTENT	size\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	hidden\tagSECTITLE_CONTENT	size\tagSECTITLE_END	In\tagSENT_START	language_modeling\tagtask	,\tagSENT_CONTENT	both\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	and\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relatively\tagSENT_CONTENT	low\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	-\tagSENT_CONTENT	frequently\tagSENT_CONTENT	between\tagSENT_CONTENT	100\tagSENT_CONTENT	and\tagSENT_CONTENT	400\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	in\tagSENT_CONTENT	size\tagSENT_CONTENT	.\tagSENT_END	Activation\tagSECTITLE_START	Regularization\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	AR\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Temporal\tagSECTITLE_END	Activation\tagmetric	Regularization\tagmetric	(\tagSENT_CONTENT	TAR\tagSENT_CONTENT	)\tagSENT_END	where\tagSENT_START	m\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	dropout\tagSENT_CONTENT	mask\tagSENT_CONTENT	,\tagSENT_CONTENT	L\tagSENT_CONTENT	2\tagSENT_CONTENT	(\tagSENT_CONTENT	·\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_CONTENT	·\tagSENT_CONTENT	·\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	ht\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	at\tagSENT_CONTENT	timestep\tagmetric	t\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	α\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	scaling\tagSENT_CONTENT	coefficient\tagSENT_CONTENT	.\tagSENT_END	Experiment\tagSECTITLE_START	Details\tagSECTITLE_END	For\tagSENT_START	training\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	NT\tagSENT_CONTENT	-\tagSENT_CONTENT	ASGD\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	section\tagSENT_CONTENT	for\tagSENT_CONTENT	750\tagSENT_CONTENT	epochs\tagSENT_CONTENT	with\tagSENT_CONTENT	L\tagSENT_CONTENT	equivalent\tagSENT_CONTENT	to\tagSENT_CONTENT	one\tagSENT_CONTENT	epoch\tagSENT_CONTENT	and\tagSENT_CONTENT	n\tagSENT_CONTENT	=\tagSENT_CONTENT	5\tagSENT_CONTENT	.\tagSENT_END	These\tagmetric	hyperparameters\tagmetric	were\tagSENT_CONTENT	chosen\tagSENT_CONTENT	through\tagSENT_CONTENT	trial\tagSENT_CONTENT	and\tagSENT_CONTENT	error\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	further\tagSENT_CONTENT	improvements\tagSENT_CONTENT	maybe\tagSENT_CONTENT	possible\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	search\tagSENT_CONTENT	were\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	conducted\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Analysis\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	the\tagmetric	single\tagmetric	-\tagmetric	model\tagmetric	perplexity\tagmetric	results\tagmetric	for\tagSENT_CONTENT	both\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	AWD\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	competitive\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	for\tagSENT_CONTENT	PTB\tagSENT_CONTENT	and\tagSENT_CONTENT	WT2\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	comparison\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	recent\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	vanilla\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	Independently\tagSENT_START	of\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	apply\tagSENT_CONTENT	extensive\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	search\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	analyzing\tagSENT_CONTENT	the\tagSENT_CONTENT	sensitivity\tagSENT_CONTENT	of\tagSENT_CONTENT	RNN\tagSENT_CONTENT	based\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	.\tagSENT_END	Pointer\tagSECTITLE_START	models\tagSECTITLE_END	In\tagSENT_START	past\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	pointer\tagSENT_CONTENT	based\tagSENT_CONTENT	attention\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	highly\tagSENT_CONTENT	effective\tagSENT_CONTENT	in\tagSENT_CONTENT	improving\tagSENT_CONTENT	language_modeling\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Parameters\tagSECTITLE_CONTENT	Validation\tagSECTITLE_CONTENT	Test\tagSECTITLE_END	language_modeling\tagtask	(\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	added\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	at\tagSENT_CONTENT	negligible\tagSENT_CONTENT	cost\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	language_modeling\tagtask	further\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	by\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	as\tagSENT_CONTENT	6\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	points\tagSENT_CONTENT	for\tagSENT_CONTENT	PTB\tagSENT_CONTENT	and\tagSENT_CONTENT	11\tagSENT_CONTENT	points\tagSENT_CONTENT	for\tagSENT_CONTENT	WT2\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	impact\tagSENT_CONTENT	the\tagSENT_CONTENT	pointer\tagSENT_CONTENT	had\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	specifically\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	detail\tagSENT_CONTENT	the\tagSENT_CONTENT	contribution\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	has\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	cache\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	overall\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	cache\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	when\tagSENT_CONTENT	handling\tagSENT_CONTENT	frequent\tagSENT_CONTENT	word\tagSENT_CONTENT	categories\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	punctuation\tagSENT_CONTENT	or\tagSENT_CONTENT	stop\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	language_modeling\tagtask	is\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Ablation\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	the\tagSENT_CONTENT	values\tagSENT_CONTENT	of\tagSENT_CONTENT	validation\tagmetric	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	-\tagSENT_CONTENT	performing\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	two\tagSENT_CONTENT	variants\tagSENT_CONTENT	deal\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	optimization\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	while\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	deal\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	regularization\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	also\tagSENT_CONTENT	worsens\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	by\tagSENT_CONTENT	approximately\tagmetric	one\tagmetric	perplexity\tagmetric	unit\tagmetric	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	discuss\tagSENT_CONTENT	regularization\tagSENT_CONTENT	and\tagSENT_CONTENT	optimization\tagSENT_CONTENT	strategies\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	
D18-1208	title\tagSECTITLE_END	Content\tagSENT_START	Selection\tagSENT_CONTENT	in\tagSENT_CONTENT	Deep\tagSENT_CONTENT	Learning\tagSENT_CONTENT	Models\tagSENT_CONTENT	of\tagSENT_CONTENT	abstract\tagSECTITLE_END	We\tagSENT_START	carryout\tagSENT_CONTENT	experiments\tagSENT_CONTENT	with\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	across\tagSENT_CONTENT	the\tagSENT_CONTENT	domains\tagSENT_CONTENT	of\tagSENT_CONTENT	news\tagSENT_CONTENT	,\tagSENT_CONTENT	personal\tagSENT_CONTENT	stories\tagSENT_CONTENT	,\tagSENT_CONTENT	meetings\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	medical\tagSENT_CONTENT	articles\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	how\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	,\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	is\tagSENT_CONTENT	usually\tagSENT_CONTENT	accomplished\tagSENT_CONTENT	through\tagSENT_CONTENT	sentence\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	occasionally\tagSENT_CONTENT	,\tagSENT_CONTENT	phrase\tagSENT_CONTENT	)\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSENT_START	position\tagSENT_CONTENT	bias\tagSENT_CONTENT	dominates\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	signal\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	though\tagSENT_CONTENT	not\tagSENT_CONTENT	for\tagSENT_CONTENT	other\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	Taken\tagSENT_START	together\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	paper\tagSENT_CONTENT	suggest\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	estimating\tagSENT_CONTENT	the\tagSENT_CONTENT	abil\tagSENT_CONTENT	-\tagSENT_CONTENT	ity\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	robust\tagSENT_CONTENT	and\tagSENT_CONTENT	meaningful\tagSENT_CONTENT	content\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	The\tagSENT_START	introduction\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	corpus\tagSENT_CONTENT	by\tagSENT_CONTENT	allowed\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	large\tagSENT_CONTENT	-\tagSENT_CONTENT	scale\tagSENT_CONTENT	training\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Other\tagSENT_START	recent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	approaches\tagSENT_CONTENT	include\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	graphconvolutional\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	GCN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Non\tagSENT_START	-\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	learning\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	The\tagSENT_START	previously\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	works\tagSENT_CONTENT	have\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	While\tagSENT_START	most\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	often\tagSENT_CONTENT	exploit\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	features\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	speaker\tagSENT_CONTENT	identification\tagSENT_CONTENT	in\tagSENT_CONTENT	meeting\tagSENT_CONTENT	summarization\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	purposefully\tagSENT_CONTENT	avoid\tagSENT_CONTENT	such\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	extent\tagSENT_CONTENT	to\tagSENT_CONTENT	which\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	perform\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	surface\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Methods\tagSECTITLE_END	The\tagSENT_START	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	a\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	's\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	gist\tagSENT_CONTENT	or\tagSENT_CONTENT	excerpt\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	central\tagSENT_CONTENT	content\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	s\tagSENT_CONTENT	n\tagSENT_CONTENT	we\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	predicting\tagSENT_CONTENT	a\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	label\tagSENT_CONTENT	sequence\tagSENT_CONTENT	y\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	word\tagmetric	budget\tagSENT_CONTENT	c\tagSENT_END	|s\tagSENT_START	i\tagSENT_CONTENT	|\tagSENT_CONTENT	≤\tagSENT_CONTENT	c.\tagSENT_CONTENT	For\tagSENT_CONTENT	atypical\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	there\tagSENT_CONTENT	are\tagSENT_CONTENT	two\tagSENT_CONTENT	main\tagSENT_CONTENT	design\tagSENT_CONTENT	decisions\tagSENT_CONTENT	:\tagSENT_END	Sentence\tagSECTITLE_START	Encoders\tagSECTITLE_END	CNN\tagSECTITLE_START	Encoder\tagSECTITLE_END	Sentence\tagSECTITLE_START	Extractors\tagSECTITLE_END	Previous\tagSENT_START	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	sentence\tagSENT_CONTENT	extraction\tagSENT_CONTENT	have\tagSENT_CONTENT	assumed\tagSENT_CONTENT	an\tagSENT_CONTENT	auto\tagSENT_CONTENT	-\tagSENT_CONTENT	regressive\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	extractor\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	p(y\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	n\tagSENT_CONTENT	|h\tagSENT_CONTENT	)\tagSENT_END	summarization\tagtask	is\tagSENT_CONTENT	also\tagSENT_CONTENT	constructed\tagSENT_CONTENT	by\tagSENT_CONTENT	taking\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	RNN\tagSENT_CONTENT	outputs\tagSENT_CONTENT	weighted\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	extraction\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	.\tagSENT_END	RNN\tagSECTITLE_START	Extractor\tagSECTITLE_END	Seq2Seq\tagSECTITLE_END	Our\tagSENT_START	second\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Seq2Seq\tagSENT_CONTENT	extractor\tagSENT_CONTENT	mitigates\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_END	Ground\tagSECTITLE_START	Truth\tagSECTITLE_CONTENT	Extract\tagSECTITLE_CONTENT	Summaries\tagSECTITLE_END	i\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	gold\tagSENT_CONTENT	label\tagSENT_CONTENT	sequences\tagSENT_CONTENT	by\tagSENT_CONTENT	greedily\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	ROUGE-1\tagmetric	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	in\tagSENT_CONTENT	Appendix\tagSENT_CONTENT	C.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	recall\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	ROUGE-1\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	LCS\tagSENT_CONTENT	trend\tagSENT_CONTENT	similarity\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_END	Seq2Seq\tagSECTITLE_END	(\tagSENT_START	-0.2\tagSENT_CONTENT	)\tagSENT_CONTENT	5.8\tagSENT_CONTENT	:\tagSENT_CONTENT	ROUGE-2\tagmetric	recall\tagSENT_CONTENT	after\tagSENT_CONTENT	removing\tagSENT_CONTENT	nouns\tagSENT_CONTENT	,\tagSENT_CONTENT	verbs\tagSENT_CONTENT	,\tagSENT_CONTENT	adjectives\tagSENT_CONTENT	/\tagSENT_CONTENT	adverbs\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	function\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	best\tagSENT_CONTENT	model\tagSENT_CONTENT	was\tagSENT_CONTENT	selected\tagSENT_CONTENT	with\tagSENT_CONTENT	early\tagSENT_CONTENT	stopping\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	.\tagSENT_END	Baselines\tagSECTITLE_END	Lead\tagSENT_START	As\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	the\tagSENT_CONTENT	lead\tagSENT_CONTENT	summary\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	taking\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	x\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	x\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	summary\tagSENT_CONTENT	length\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	dataset\tagSENT_END	Oracle\tagSENT_START	To\tagSENT_CONTENT	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	ceiling\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	/\tagSENT_CONTENT	METEOR\tagSENT_CONTENT	scores\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summary\tagSENT_CONTENT	which\tagSENT_CONTENT	results\tagSENT_CONTENT	from\tagSENT_CONTENT	greedily\tagSENT_CONTENT	optimizing\tagSENT_CONTENT	ROUGE-1\tagmetric	.\tagSENT_END	Results\tagSECTITLE_END	Seq2Seq\tagSECTITLE_END	ROUGE-2\tagmetric	recall\tagmetric	using\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	and\tagSENT_CONTENT	shuffled\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	storm\tagmetric	was\tagSENT_CONTENT	approaching\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	southeast\tagSENT_CONTENT	with\tagSENT_CONTENT	sustained\tagSENT_CONTENT	winds\tagSENT_CONTENT	of\tagSENT_CONTENT	75\tagSENT_CONTENT	mph\tagSENT_CONTENT	gusting\tagSENT_CONTENT	to\tagSENT_CONTENT	92\tagSENT_CONTENT	mph\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	storm\tagmetric	was\tagSENT_CONTENT	approaching\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	southeast\tagSENT_CONTENT	with\tagSENT_CONTENT	sustained\tagSENT_CONTENT	winds\tagSENT_CONTENT	of\tagSENT_CONTENT	75\tagSENT_CONTENT	mph\tagSENT_CONTENT	gusting\tagSENT_CONTENT	to\tagSENT_CONTENT	92\tagSENT_CONTENT	mph\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	both\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	initialized\tagSENT_CONTENT	with\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	and\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	removed\tagSENT_CONTENT	words\tagSENT_CONTENT	were\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	zero\tagSENT_CONTENT	vector\tagSENT_CONTENT	,\tagSENT_CONTENT	preserving\tagSENT_CONTENT	the\tagmetric	order\tagmetric	and\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	ablated\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Learning\tagSENT_START	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	news\tagSENT_CONTENT	domain\tagSENT_CONTENT	is\tagSENT_CONTENT	severely\tagSENT_CONTENT	inhibited\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	lead\tagSENT_CONTENT	bias\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	picture\tagSENT_CONTENT	is\tagSENT_CONTENT	rosier\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	where\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	speech\tagSENT_CONTENT	ablation\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	larger\tagSENT_CONTENT	performance\tagSENT_CONTENT	differences\tagSENT_CONTENT	and\tagSENT_CONTENT	shuffling\tagSENT_END	The\tagSENT_START	inability\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	useful\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representations\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	borne\tagSENT_CONTENT	out\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	SummaRunner\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	explicit\tagSENT_CONTENT	similarity\tagSENT_CONTENT	computations\tagSENT_CONTENT	between\tagSENT_CONTENT	document\tagSENT_CONTENT	or\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	;\tagSENT_CONTENT	these\tagSENT_CONTENT	computations\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	seem\tagSENT_CONTENT	to\tagSENT_CONTENT	add\tagSENT_CONTENT	much\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	formance\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	Cheng\tagSENT_CONTENT	&\tagSENT_CONTENT	Lapata\tagSENT_CONTENT	and\tagSENT_CONTENT	Seq2Seq\tagSENT_CONTENT	models\tagSENT_CONTENT	which\tagSENT_CONTENT	lack\tagSENT_CONTENT	these\tagSENT_CONTENT	features\tagSENT_CONTENT	generally\tagSENT_CONTENT	perform\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	or\tagSENT_CONTENT	better\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	news\tagSENT_CONTENT	domain\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	consistently\tagSENT_CONTENT	learned\tagSENT_CONTENT	to\tagSENT_CONTENT	ignore\tagSENT_CONTENT	quoted\tagSENT_CONTENT	material\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	lead\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	often\tagSENT_CONTENT	the\tagSENT_CONTENT	quotes\tagSENT_CONTENT	provide\tagSENT_CONTENT	color\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagmetric	story\tagmetric	but\tagSENT_CONTENT	are\tagSENT_CONTENT	unlikely\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	included\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	"\tagSENT_CONTENT	It\tagSENT_CONTENT	was\tagSENT_CONTENT	like\tagSENT_CONTENT	somebody\tagSENT_CONTENT	slugging\tagSENT_CONTENT	a\tagSENT_CONTENT	punching\tagSENT_CONTENT	bag\tagSENT_CONTENT	.\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	an\tagSENT_CONTENT	empirical\tagSENT_CONTENT	study\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	based\tagSENT_CONTENT	content\tagSENT_CONTENT	selection\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	
1804.09769	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	To\tagSENT_START	tackle\tagSENT_CONTENT	this\tagSENT_CONTENT	issue\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	scaleability\tagSENT_CONTENT	and\tagSENT_CONTENT	privacy\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	concern\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	search\tagSENT_CONTENT	databases\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	understand\tagSENT_CONTENT	what\tagSENT_CONTENT	the\tagSENT_CONTENT	user\tagSENT_CONTENT	is\tagSENT_CONTENT	querying\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	As\tagSENT_START	a\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	sql_parsing\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	SQL\tagSENT_CONTENT	problem\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	studied\tagSENT_CONTENT	for\tagSENT_CONTENT	decades\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	publish\tagSENT_START	the\tagSENT_CONTENT	WikiSQL\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	sql_parsing\tagtask	.\tagSENT_END	Methodology\tagSECTITLE_END	Type\tagSECTITLE_START	Recognition\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Input\tagSECTITLE_CONTENT	Preprocessing\tagSECTITLE_END	To\tagSENT_START	identify\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	search\tagSENT_CONTENT	for\tagSENT_CONTENT	five\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	:\tagSENT_CONTENT	PERSON\tagSENT_CONTENT	,\tagSENT_CONTENT	PLACE\tagmetric	,\tagSENT_CONTENT	COUN\tagSENT_CONTENT	-\tagSENT_CONTENT	TRY\tagSENT_CONTENT	,\tagSENT_CONTENT	ORGANIZATION\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	SPORT\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	1\tagSENT_CONTENT	using\tagSENT_CONTENT	grams\tagSENT_CONTENT	as\tagSENT_CONTENT	keyword\tagSENT_CONTENT	queries\tagSENT_CONTENT	.\tagSENT_END	Input\tagSECTITLE_START	Encoder\tagSECTITLE_END	Slot\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Filling\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
1803.09074	title\tagSECTITLE_END	question_answering\tagtask	for\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Comprehension\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	conduct\tagSENT_CONTENT	extensive\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	three\tagSENT_CONTENT	challenging\tagSENT_CONTENT	MC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagmetric	RACE\tagmetric	,\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	and\tagSENT_CONTENT	NarrativeQA\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	highly\tagSENT_CONTENT	competitive\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	In\tagSENT_START	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	effectively\tagSENT_CONTENT	testing\tagSENT_CONTENT	the\tagSENT_CONTENT	learner\tagSENT_CONTENT	's\tagSENT_CONTENT	capability\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	information\tagSENT_CONTENT	at\tagSENT_CONTENT	multiple\tagSENT_CONTENT	-\tagSENT_CONTENT	ranges\tagSENT_CONTENT	,\tagSENT_CONTENT	modeling\tagSENT_CONTENT	relationships\tagSENT_CONTENT	across\tagSENT_CONTENT	different\tagSENT_CONTENT	granularities\tagSENT_CONTENT	and\tagSENT_CONTENT	hierarchies\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	MC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	often\tagSENT_CONTENT	require\tagSENT_CONTENT	a\tagSENT_CONTENT	considerable\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	good\tagSENT_CONTENT	testbeds\tagSENT_CONTENT	for\tagSENT_CONTENT	benchmarking\tagSENT_CONTENT	encoders\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	RACE\tagdataset	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	Dynamic\tagSENT_CONTENT	Fusion\tagSENT_CONTENT	Networks\tagSENT_CONTENT	(\tagSENT_CONTENT	DFN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	highly\tagSENT_CONTENT	complex\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	NarrativeQA\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	(\tagSENT_CONTENT	summaries\tagSENT_CONTENT	setting\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	MRU\tagSENT_CONTENT	encoders\tagSENT_CONTENT	achieves\tagSENT_CONTENT	highly\tagSENT_CONTENT	competitive\tagSENT_CONTENT	performance\tagSENT_CONTENT	relative\tagSENT_CONTENT	to\tagSENT_CONTENT	BiDAF\tagSENT_CONTENT	question_answering\tagtask	without\tagSENT_CONTENT	using\tagSENT_CONTENT	any\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	/\tagSENT_CONTENT	GRU\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	MRU\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	Contract\tagSECTITLE_START	-\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Expand\tagSECTITLE_CONTENT	Operation\tagSECTITLE_END	Reasoning\tagSECTITLE_START	over\tagSECTITLE_CONTENT	Multi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	ranged\tagSECTITLE_CONTENT	Blocks\tagSECTITLE_END	MRU\tagSECTITLE_START	Encoding\tagSECTITLE_CONTENT	Operation\tagSECTITLE_END	Simple\tagSECTITLE_START	MRU\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	since\tagSENT_CONTENT	our\tagSENT_CONTENT	gating\tagSENT_CONTENT	function\tagSENT_CONTENT	is\tagSENT_CONTENT	learned\tagSENT_CONTENT	via\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	captures\tagSENT_CONTENT	more\tagSENT_CONTENT	compositionality\tagSENT_CONTENT	and\tagSENT_CONTENT	long\tagSENT_CONTENT	range\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Recurrent\tagSECTITLE_START	MRU\tagSECTITLE_END	Overall\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	Architectures\tagSECTITLE_END	Multiple\tagSECTITLE_START	Choice\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	In\tagSENT_START	MCQ\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	three\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	input\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	Passage\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	Q\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Answers\tagSENT_CONTENT	(\tagSENT_CONTENT	A\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Subsequently\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	B(P\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	A\tagSENT_CONTENT	j\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Span\tagSECTITLE_START	Prediction\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Q.\tagSENT_START	The\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	predict\tagSENT_CONTENT	a\tagSENT_CONTENT	span\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_CONTENT	where\tagSENT_CONTENT	P\tagSENT_CONTENT	[\tagSENT_CONTENT	s\tagSENT_CONTENT	:\tagSENT_CONTENT	e\tagSENT_CONTENT	]\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	.\tagSENT_END	During\tagSENT_START	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	finding\tagSENT_CONTENT	question_answering\tagtask	follows\tagSENT_CONTENT	.\tagSENT_END	Empirical\tagSECTITLE_START	Evaluation\tagSECTITLE_END	Datasets\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	four\tagSENT_CONTENT	options\tagSENT_CONTENT	each\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	involves\tagSENT_CONTENT	extracting\tagSENT_CONTENT	passages\tagSENT_CONTENT	from\tagSENT_CONTENT	search\tagSENT_CONTENT	engine\tagSENT_CONTENT	results\tagSENT_CONTENT	and\tagSENT_CONTENT	require\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	and\tagSENT_CONTENT	reading\tagSENT_CONTENT	these\tagSENT_CONTENT	search\tagSENT_CONTENT	snippets\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	from\tagSENT_CONTENT	many\tagSENT_CONTENT	MC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	handwritten\tagSENT_CONTENT	by\tagSENT_CONTENT	human\tagSENT_CONTENT	annotators\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	RACE\tagdataset	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	entire\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	RACE\tagSENT_CONTENT	-\tagSENT_CONTENT	M\tagSENT_CONTENT	and\tagSENT_CONTENT	RACE\tagSENT_CONTENT	-\tagSENT_CONTENT	H\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	separately\tagSENT_CONTENT	.\tagSENT_END	N\tagSECTITLE_START	/\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	BiAttention\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	MRU\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	Ensemble\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	x9\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Competitor\tagSECTITLE_START	Methods\tagSECTITLE_END	AMANDA\tagSENT_START	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	factor\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	module\tagSENT_CONTENT	,\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	focused\tagSENT_CONTENT	span\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Methods\tagSECTITLE_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	Dev\tagSECTITLE_END	Test\tagSECTITLE_END	Model\tagSECTITLE_END	The\tagSENT_START	best\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	score\tagSENT_CONTENT	from\tagSENT_CONTENT	RACE\tagmetric	-\tagmetric	H\tagmetric	and\tagmetric	RACE\tagmetric	-\tagmetric	M\tagmetric	alternates\tagmetric	between\tagSENT_CONTENT	Sim\tagSENT_CONTENT	.\tagSENT_CONTENT	MRU\tagSENT_CONTENT	and\tagSENT_CONTENT	MRU\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	finding\tagSENT_CONTENT	highlights\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	designing\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	at\tagSENT_CONTENT	hand\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	RACE\tagSECTITLE_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	SearchQA\tagSECTITLE_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	NarrativeQA\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	As\tagSENT_START	such\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	often\tagSENT_CONTENT	emphasize\tagSENT_CONTENT	the\tagSENT_CONTENT	extent\tagSENT_CONTENT	of\tagSENT_CONTENT	compositional\tagSENT_CONTENT	and\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	sentence\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	tackle\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
N18-1150	title\tagSECTITLE_END	Deep\tagSENT_START	Communicating\tagSENT_CONTENT	Agents\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	deep\tagSENT_CONTENT	communicating\tagSENT_CONTENT	agents\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	architecture\tagSENT_CONTENT	to\tagSENT_CONTENT	address\tagSENT_CONTENT	the\tagSENT_CONTENT	challenges\tagSENT_CONTENT	of\tagSENT_CONTENT	representing\tagSENT_CONTENT	along\tagSENT_CONTENT	document\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	We\tagSENT_START	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	along\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	behind\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	attend\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	salient\tagSENT_CONTENT	facts\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	work\tagSENT_CONTENT	builds\tagSENT_CONTENT	on\tagSENT_CONTENT	these\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	study\tagSENT_CONTENT	on\tagSENT_CONTENT	using\tagSENT_CONTENT	communicating\tagSENT_CONTENT	agents\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	long\tagSENT_CONTENT	text\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	The\tagmetric	word\tagmetric	context\tagSENT_CONTENT	vectors\tagSENT_CONTENT	ct\tagSENT_CONTENT	a\tagSENT_CONTENT	are\tagSENT_CONTENT	condensed\tagSENT_CONTENT	into\tagSENT_CONTENT	agent\tagSENT_CONTENT	context\tagSENT_CONTENT	c\tagSENT_END	summarization\tagtask	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	more\tagSENT_CONTENT	focused\tagSENT_CONTENT	summaries\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	(\tagSENT_START	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	agent-1\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Agent\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	where\tagSENT_START	v\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	W\tagSENT_CONTENT	3\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	W\tagSENT_CONTENT	4\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	parameters\tagmetric	shared\tagSENT_CONTENT	by\tagSENT_CONTENT	every\tagSENT_CONTENT	agent\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	(\tagSENT_CONTENT	7\tagSENT_CONTENT	)\tagSENT_CONTENT	combines\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	sent\tagSENT_CONTENT	by\tagSENT_CONTENT	other\tagSENT_CONTENT	agents\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	token\tagSENT_CONTENT	from\tagSENT_CONTENT	this\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	Decoder\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Agent\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	At\tagSENT_START	each\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	predicts\tagSENT_CONTENT	anew\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	computes\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	st\tagSENT_CONTENT	by\tagSENT_CONTENT	attending\tagSENT_CONTENT	to\tagSENT_CONTENT	relevant\tagSENT_CONTENT	input\tagSENT_CONTENT	context\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	agents\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	b\tagSENT_CONTENT	1\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	parameters\tagmetric	.\tagSENT_END	*\tagSENT_START	t−1\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	additional\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	decoding\tagSENT_CONTENT	step\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	summarization\tagtask	over\tagSENT_CONTENT	words\tagSENT_CONTENT	:\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Agent\tagSECTITLE_CONTENT	Pointer\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	In\tagSENT_START	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	agent\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	allows\tagSENT_CONTENT	each\tagSENT_CONTENT	agent\tagSENT_CONTENT	to\tagSENT_CONTENT	vote\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	OOV\tagSENT_CONTENT	words\tagSENT_CONTENT	at\tagSENT_CONTENT	time\tagSENT_CONTENT	t\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Mixed\tagSECTITLE_START	Objective\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	To\tagSENT_START	encourage\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	summary\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	informative\tagSENT_CONTENT	without\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	a\tagSENT_CONTENT	semantic\tagSENT_CONTENT	cohesion\tagSENT_CONTENT	loss\tagSENT_CONTENT	to\tagSENT_CONTENT	integrate\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	semantics\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	objective\tagSENT_CONTENT	.\tagSENT_END	Reinforcement\tagSENT_START	Learning\tagSENT_CONTENT	(\tagSENT_CONTENT	RL\tagSENT_CONTENT	)\tagSENT_CONTENT	Loss\tagSENT_CONTENT	Policy\tagSENT_CONTENT	gradient\tagSENT_CONTENT	methods\tagSENT_CONTENT	can\tagSENT_CONTENT	directly\tagSENT_CONTENT	optimize\tagSENT_CONTENT	discrete\tagSENT_CONTENT	target\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ROUGE\tagmetric	that\tagSENT_CONTENT	are\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Mixed\tagSECTITLE_START	Loss\tagSECTITLE_END	summarization\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	objectives\tagSENT_CONTENT	can\tagSENT_CONTENT	yield\tagSENT_CONTENT	improved\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	scores\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	fluency\tagSENT_CONTENT	:\tagSENT_END	Sentences\tagSENT_START	are\tagSENT_CONTENT	rewarded\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	increase\tagSENT_CONTENT	in\tagSENT_CONTENT	ROUGE\tagmetric	they\tagSENT_CONTENT	contribute\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	ensuring\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	sentence\tagSENT_CONTENT	contributed\tagSENT_CONTENT	novel\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Datasets\tagSENT_START	We\tagSENT_CONTENT	conducted\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	:\tagSENT_CONTENT	CNN\tagSENT_CONTENT	/\tagSENT_CONTENT	DailyMail\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	New\tagSENT_CONTENT	York\tagSENT_CONTENT	Times\tagSENT_CONTENT	(\tagSENT_CONTENT	NYT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	fix\tagSENT_CONTENT	γ\tagSENT_CONTENT	=\tagSENT_CONTENT	0.97\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	RL\tagSENT_CONTENT	term\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	λ\tagSENT_END	Evaluation\tagSENT_START	We\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	using\tagSENT_CONTENT	ROUGE-1\tagmetric	(\tagSENT_CONTENT	unigram\tagSENT_CONTENT	recall\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	(\tagSENT_CONTENT	bigram\tagSENT_CONTENT	recall\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	longest\tagSENT_CONTENT	common\tagSENT_CONTENT	sequence\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Quantitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	Overall\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	(\tagSENT_CONTENT	m6\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	m7\tagSENT_CONTENT	)\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	multiagent\tagSENT_CONTENT	encoders\tagSENT_CONTENT	,\tagSENT_CONTENT	pointer\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	are\tagSENT_CONTENT	the\tagSENT_CONTENT	strongest\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	ROUGE-1\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	When\tagSENT_START	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	multiple\tagSENT_CONTENT	agents\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	m4\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	DCA\tagSENT_CONTENT	models\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	single\tagSENT_CONTENT	agent\tagSENT_CONTENT	baselines\tagSENT_CONTENT	(\tagSENT_CONTENT	m1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	(\tagSENT_CONTENT	m3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	uses\tagSENT_CONTENT	sentence\tagSENT_CONTENT	based\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	rewards\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	also\tagSENT_CONTENT	improves\tagSENT_CONTENT	ROUGE\tagmetric	scores\tagmetric	across\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Human\tagSECTITLE_START	Evaluations\tagSECTITLE_END	We\tagSENT_START	perform\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	establish\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	improvements\tagSENT_CONTENT	are\tagSENT_CONTENT	correlated\tagSENT_CONTENT	with\tagSENT_CONTENT	human\tagSENT_CONTENT	judgments\tagSENT_CONTENT	.\tagSENT_END	Results\tagSENT_START	Human\tagSENT_CONTENT	evaluators\tagSENT_CONTENT	significantly\tagSENT_CONTENT	prefer\tagSENT_CONTENT	summarization\tagtask	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	communicating\tagSENT_CONTENT	encoders\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	words\tagSENT_CONTENT	'\tagSENT_CONTENT	primed\tagSENT_CONTENT	minister\tagSENT_CONTENT	'\tagSENT_CONTENT	were\tagSENT_CONTENT	controversially\tagSENT_CONTENT	also\tagSENT_CONTENT	printed\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	cover\tagmetric	.\tagSENT_END	Multi\tagSECTITLE_END	Multi\tagSECTITLE_END	Communication\tagSECTITLE_START	improves\tagSECTITLE_CONTENT	focus\tagSECTITLE_END	To\tagSENT_START	investigate\tagSENT_CONTENT	how\tagSENT_CONTENT	much\tagSENT_CONTENT	the\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	agent\tagSENT_CONTENT	models\tagSENT_CONTENT	discover\tagSENT_CONTENT	salient\tagSENT_CONTENT	concepts\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	single\tagSENT_CONTENT	agent\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	scores\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	attention\tagSENT_CONTENT	received\tagSENT_CONTENT	by\tagSENT_CONTENT	each\tagSENT_CONTENT	agent\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Attention\tagSENT_START	mechanisms\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	crucial\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	as\tagSENT_CONTENT	well\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	pointer\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	help\tagSENT_CONTENT	address\tagSENT_CONTENT	redundancy\tagSENT_CONTENT	and\tagSENT_CONTENT	saliency\tagSENT_CONTENT	in\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	investigated\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	encoding\tagSENT_CONTENT	long\tagSENT_CONTENT	text\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summaries\tagSENT_CONTENT	and\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	communicating\tagSENT_CONTENT	agents\tagSENT_CONTENT	can\tagSENT_CONTENT	improve\tagSENT_CONTENT	summarization\tagtask	by\tagSENT_CONTENT	both\tagSENT_CONTENT	automatic\tagSENT_CONTENT	and\tagSENT_CONTENT	manual\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	Supplementary\tagSECTITLE_CONTENT	Material\tagSECTITLE_END	Although\tagSENT_START	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	has\tagSENT_CONTENT	mainly\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	recently\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	summarization\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	A.2\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	To\tagSENT_START	avoid\tagSENT_CONTENT	summarization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	prevent\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	from\tagSENT_CONTENT	generating\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	trigram\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	once\tagSENT_CONTENT	during\tagSENT_CONTENT	test\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	Generated\tagSECTITLE_CONTENT	Summary\tagSECTITLE_CONTENT	Examples\tagSECTITLE_END	This\tagSENT_START	appendix\tagSENT_CONTENT	provides\tagSENT_CONTENT	example\tagSENT_CONTENT	documents\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	side\tagSENT_CONTENT	-\tagSENT_CONTENT	by\tagSENT_CONTENT	-\tagSENT_CONTENT	side\tagSENT_CONTENT	comparisons\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	generated\tagSENT_CONTENT	(\tagSENT_CONTENT	golden\tagSENT_CONTENT	)\tagSENT_CONTENT	summaries\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	abbey\tagSENT_START	clancy\tagSENT_CONTENT	leads\tagSENT_CONTENT	the\tagSENT_CONTENT	glamour\tagSENT_CONTENT	as\tagSENT_CONTENT	she\tagSENT_CONTENT	joins\tagSENT_CONTENT	forces\tagSENT_CONTENT	with\tagSENT_CONTENT	her\tagSENT_CONTENT	famous\tagSENT_CONTENT	friends\tagSENT_CONTENT	to\tagSENT_CONTENT	target\tagSENT_CONTENT	breast\tagSENT_CONTENT	cancer\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	striking\tagSENT_CONTENT	a\tagSENT_CONTENT	sultry\tagSENT_CONTENT	pose\tagSENT_CONTENT	in\tagSENT_CONTENT	anew\tagSENT_CONTENT	charity\tagSENT_CONTENT	campaign\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	is\tagSENT_CONTENT	mother\tagmetric	to\tagSENT_CONTENT	four\tagSENT_CONTENT	-year\tagSENT_CONTENT	-old\tagSENT_CONTENT	daughter\tagSENT_CONTENT	sophia\tagSENT_CONTENT	with\tagSENT_CONTENT	footballer\tagSENT_CONTENT	husband\tagSENT_CONTENT	peter\tagSENT_CONTENT	crouch\tagSENT_CONTENT	,\tagSENT_CONTENT	said\tagSENT_CONTENT	:\tagSENT_CONTENT	'\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	mum\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	makes\tagSENT_CONTENT	me\tagSENT_CONTENT	proud\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	campaign\tagSENT_CONTENT	that\tagSENT_CONTENT	funds\tagSENT_CONTENT	vital\tagSENT_CONTENT	work\tagSENT_CONTENT	towards\tagSENT_CONTENT	ensuring\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	generation\tagSENT_CONTENT	of\tagSENT_CONTENT	young\tagSENT_CONTENT	women\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	have\tagSENT_CONTENT	be\tagSENT_CONTENT	afraid\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	diagnosis\tagSENT_CONTENT	of\tagSENT_CONTENT	breast\tagSENT_CONTENT	cancer\tagSENT_CONTENT	.\tagSENT_CONTENT	'\tagSENT_END	Multi\tagSECTITLE_START	Agent\tagSECTITLE_END	english\tagSENT_START	would\tagSENT_CONTENT	also\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	writer\tagSENT_CONTENT	,\tagSENT_CONTENT	producer\tagmetric	and\tagSENT_CONTENT	showrunner\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	program\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	ladies\tagSENT_CONTENT	are\tagSENT_CONTENT	currently\tagSENT_CONTENT	in\tagSENT_CONTENT	talks\tagSENT_CONTENT	with\tagSENT_CONTENT	hbo\tagSENT_CONTENT	,\tagSENT_CONTENT	showtime\tagSENT_CONTENT	,\tagSENT_CONTENT	amc\tagSENT_CONTENT	,\tagSENT_CONTENT	netflix\tagSENT_CONTENT	and\tagSENT_CONTENT	summarization\tagtask	to\tagSENT_CONTENT	pickup\tagSENT_CONTENT	the\tagSENT_CONTENT	program\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSECTITLE_START	Agent\tagSECTITLE_END	One\tagSENT_START	interesting\tagSENT_CONTENT	feature\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	agent\tagSENT_CONTENT	model\tagSENT_CONTENT	showcases\tagSENT_CONTENT	is\tagSENT_CONTENT	its\tagSENT_CONTENT	simplification\tagSENT_CONTENT	property\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	accounts\tagSENT_CONTENT	for\tagSENT_CONTENT	its\tagSENT_CONTENT	strength\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	this\tagSENT_START	time\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	brought\tagSENT_CONTENT	back\tagSENT_CONTENT	memories\tagmetric	of\tagSENT_CONTENT	everton\tagSENT_CONTENT	's\tagSENT_CONTENT	match\tagSENT_CONTENT	against\tagSENT_CONTENT	west\tagSENT_CONTENT	brom\tagSENT_CONTENT	in\tagSENT_CONTENT	january\tagSENT_CONTENT	when\tagSENT_CONTENT	kevin\tagSENT_CONTENT	mirallas\tagSENT_CONTENT	grabbed\tagSENT_CONTENT	the\tagSENT_CONTENT	ball\tagSENT_CONTENT	from\tagSENT_CONTENT	baines\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	a\tagSENT_CONTENT	penalty\tagSENT_CONTENT	-and\tagSENT_CONTENT	missed\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	insisted\tagSENT_CONTENT	barkley\tagSENT_CONTENT	was\tagSENT_CONTENT	within\tagSENT_CONTENT	his\tagSENT_CONTENT	rights\tagSENT_CONTENT	to\tagSENT_CONTENT	request\tagSENT_CONTENT	penalty\tagSENT_END	Single\tagSECTITLE_START	Agent\tagSECTITLE_CONTENT	Baseline\tagSECTITLE_END	Multi\tagSECTITLE_START	Agent\tagSECTITLE_END	:\tagSENT_START	The\tagSENT_CONTENT	single\tagSENT_CONTENT	agent\tagSENT_CONTENT	model\tagSENT_CONTENT	generates\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	superfluous\tagSENT_CONTENT	details\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	facts\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	clearly\tagSENT_CONTENT	expressed\tagSENT_CONTENT	.\tagSENT_END	
1805.08092	title\tagSECTITLE_END	question_answering\tagtask	from\tagSENT_CONTENT	Minimal\tagSENT_CONTENT	Context\tagSENT_CONTENT	over\tagSENT_CONTENT	Documents\tagSENT_END	abstract\tagSECTITLE_END	Neural\tagSENT_START	models\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	over\tagSENT_CONTENT	documents\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	significant\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvements\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	textual\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	machine\tagSENT_CONTENT	reads\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	answers\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	and\tagSENT_CONTENT	challenging\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	.\tagSENT_END	Many\tagSENT_START	neural\tagSENT_CONTENT	QA\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	successful\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	leverage\tagSENT_CONTENT	coattention\tagSENT_CONTENT	or\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	that\tagSENT_CONTENT	build\tagSENT_CONTENT	codependent\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	inputs\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	models\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	wrong\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	produce\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	sampling\tagSENT_CONTENT	examples\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	carefully\tagSENT_CONTENT	analyzing\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	this\tagSENT_CONTENT	observation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selector\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	minimal\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	.\tagSECTITLE_START	)\tagSECTITLE_CONTENT	Where\tagSECTITLE_CONTENT	did\tagSECTITLE_CONTENT	Tesla\tagSECTITLE_CONTENT	return\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	1873\tagSECTITLE_CONTENT	?\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	28\tagSECTITLE_CONTENT	After\tagSECTITLE_CONTENT	leaving\tagSECTITLE_CONTENT	Edison\tagSECTITLE_CONTENT	's\tagSECTITLE_CONTENT	company\tagSECTITLE_CONTENT	Tesla\tagSECTITLE_CONTENT	partnered\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	two\tagSECTITLE_CONTENT	businessmen\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	1886\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	What\tagSECTITLE_CONTENT	did\tagSECTITLE_CONTENT	Tesla\tagSECTITLE_CONTENT	Electric\tagSECTITLE_CONTENT	Light\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	Manufacturing\tagSECTITLE_CONTENT	Robert\tagSECTITLE_CONTENT	Lane\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Benjamin\tagSECTITLE_CONTENT	Vail\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	who\tagSECTITLE_CONTENT	agreed\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	finance\tagSECTITLE_CONTENT	an\tagSECTITLE_CONTENT	electric\tagSECTITLE_CONTENT	lighting\tagSECTITLE_CONTENT	do\tagSECTITLE_CONTENT	?\tagSECTITLE_CONTENT	company\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Tesla\tagSECTITLE_CONTENT	's\tagSECTITLE_CONTENT	name\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Tesla\tagSECTITLE_CONTENT	Electric\tagSECTITLE_CONTENT	Light\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	Manufacturing\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	The\tagSECTITLE_CONTENT	company\tagSECTITLE_CONTENT	installed\tagSECTITLE_CONTENT	electrical\tagSECTITLE_CONTENT	arc\tagSECTITLE_CONTENT	light\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	illumination\tagSECTITLE_CONTENT	systems\tagSECTITLE_CONTENT	designed\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	Tesla\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	also\tagSECTITLE_CONTENT	had\tagSECTITLE_CONTENT	designs\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	dynamo\tagSECTITLE_CONTENT	electric\tagSECTITLE_CONTENT	machine\tagSECTITLE_CONTENT	commutators\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	...\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	3↑\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	4\tagSECTITLE_END	N\tagSECTITLE_START	/\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	12\tagSECTITLE_END	Human\tagSENT_START	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	and\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	.\tagSENT_END	Error\tagSENT_START	cases\tagSENT_CONTENT	(\tagSENT_CONTENT	on\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagmetric	EM\tagmetric	)\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	DCN+\tagSENT_CONTENT	given\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	.\tagSENT_END	Task\tagSECTITLE_START	analyses\tagSECTITLE_END	Consequently\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	minimal\tagSENT_CONTENT	context\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Human\tagSECTITLE_START	studies\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	randomly\tagSENT_CONTENT	sample\tagSENT_CONTENT	50\tagSENT_CONTENT	examples\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	minimum\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Finding\tagSENT_START	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	than\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	documents\tagSENT_CONTENT	are\tagSENT_CONTENT	much\tagSENT_CONTENT	longer\tagSENT_CONTENT	than\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	documents\tagSENT_CONTENT	(\tagSENT_CONTENT	488\tagSENT_CONTENT	vs\tagSENT_CONTENT	5\tagSENT_CONTENT	sentences\tagSENT_CONTENT	per\tagSENT_CONTENT	document\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Analyses\tagSECTITLE_START	on\tagSECTITLE_CONTENT	existing\tagSECTITLE_CONTENT	QA\tagSECTITLE_CONTENT	model\tagSECTITLE_END	We\tagSENT_START	analyze\tagSENT_CONTENT	50\tagSENT_CONTENT	randomly\tagSENT_CONTENT	sampled\tagSENT_CONTENT	examples\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	fails\tagSENT_CONTENT	on\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagSENT_CONTENT	EM\tagmetric	)\tagSENT_CONTENT	despite\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	these\tagSENT_CONTENT	examples\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observed\tagSENT_CONTENT	that\tagSENT_CONTENT	40\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	answerable\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	unexpectedly\tagSENT_CONTENT	fails\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	an\tagSENT_CONTENT	effective\tagSENT_CONTENT	,\tagSENT_CONTENT	efficient\tagSENT_CONTENT	and\tagSENT_CONTENT	robust\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	requires\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Method\tagSECTITLE_END	We\tagSENT_START	give\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	a\tagSENT_CONTENT	reduced\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	high\tagSENT_CONTENT	selection\tagSENT_CONTENT	scores\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Neural\tagSECTITLE_START	Question\tagSECTITLE_CONTENT	Answering\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Full\tagSECTITLE_END	Venn\tagSENT_START	diagram\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answered\tagSENT_CONTENT	correctly\tagSENT_CONTENT	(\tagSENT_CONTENT	on\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagSENT_CONTENT	EM\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_END	Sentence\tagSECTITLE_START	Selector\tagSECTITLE_END	Our\tagSENT_START	sentence\tagSENT_CONTENT	selector\tagSENT_CONTENT	scores\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	parallel\tagSENT_CONTENT	.\tagSENT_END	After\tagSENT_START	this\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	encodings\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	module\tagSENT_CONTENT	which\tagSENT_CONTENT	computes\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	by\tagSENT_CONTENT	calculating\tagSENT_CONTENT	bilinear\tagSENT_CONTENT	similarities\tagSENT_CONTENT	between\tagSENT_CONTENT	sentence\tagSENT_CONTENT	encodings\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	Each\tagSENT_START	dimension\tagSENT_CONTENT	in\tagSENT_CONTENT	score\tagSENT_CONTENT	means\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	answerable\tagSENT_CONTENT	or\tagSENT_CONTENT	nonanswerable\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Because\tagSENT_START	the\tagSENT_CONTENT	minimal\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	by\tagSENT_CONTENT	thresholding\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	threshold\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	(\tagSENT_CONTENT	details\tagSENT_CONTENT	in\tagSENT_CONTENT	Appendix\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metrics\tagSECTITLE_END	SQuAD\tagSECTITLE_END	(\tagSENT_START	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	wellstudied\tagSENT_CONTENT	QA\tagSENT_CONTENT	dataset\tagSENT_CONTENT	on\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	articles\tagSENT_CONTENT	that\tagSENT_CONTENT	requires\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	be\tagSENT_CONTENT	answered\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	NewsQA\tagdataset	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	on\tagSENT_CONTENT	news\tagSENT_CONTENT	articles\tagSENT_CONTENT	that\tagSENT_CONTENT	also\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	are\tagSENT_CONTENT	longer\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	in\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	measure\tagSENT_CONTENT	F1\tagSENT_CONTENT	and\tagSENT_CONTENT	EM\tagSENT_CONTENT	(\tagSENT_CONTENT	Exact\tagSENT_CONTENT	Match\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	being\tagSENT_CONTENT	standard\tagSENT_CONTENT	metrics\tagSENT_CONTENT	for\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	span\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	QA\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagSECTITLE_START	and\tagSECTITLE_CONTENT	NewsQA\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	this\tagSENT_CONTENT	last\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	selects\tagSENT_CONTENT	sentences\tagSENT_CONTENT	using\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_CONTENT	   \tagSENT_END	On\tagSENT_START	NewsQA\tagdataset	,\tagSENT_CONTENT	Top\tagSENT_CONTENT	4\tagSENT_CONTENT	achieves\tagSENT_CONTENT	92.5\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	Dyn\tagSENT_CONTENT	achieves\tagSENT_CONTENT	94.6\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	with\tagSENT_CONTENT	3.9\tagSENT_CONTENT	sentences\tagSENT_CONTENT	per\tagSENT_CONTENT	example\tagSENT_CONTENT	.\tagSENT_END	.\tagSECTITLE_START	.\tagSECTITLE_CONTENT	An\tagSECTITLE_CONTENT	Extended\tagSECTITLE_CONTENT	Lunar\tagSECTITLE_CONTENT	Module\tagSECTITLE_CONTENT	weighed\tagSECTITLE_CONTENT	over\tagSECTITLE_CONTENT	36,200\tagSECTITLE_CONTENT	pounds\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	allowed\tagSECTITLE_CONTENT	surface\tagSECTITLE_CONTENT	stays\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	over\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	days\tagSECTITLE_CONTENT	.\tagSECTITLE_END	How\tagSECTITLE_START	many\tagSECTITLE_CONTENT	casualties\tagSECTITLE_CONTENT	did\tagSECTITLE_CONTENT	British\tagSECTITLE_CONTENT	get\tagSECTITLE_CONTENT	?\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	above\tagSENT_CONTENT	two\tagSENT_CONTENT	examples\tagSENT_CONTENT	,\tagSENT_CONTENT	MINIMAL\tagSENT_CONTENT	correctly\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	selecting\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	selected\tagSECTITLE_START	sentence\tagSECTITLE_END	and\tagSENT_START	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	correctly\tagSENT_CONTENT	answers\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	TriviaQA\tagSECTITLE_START	and\tagSECTITLE_CONTENT	SQuAD\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Open\tagSECTITLE_END	They\tagSENT_START	do\tagSENT_CONTENT	not\tagSENT_CONTENT	provide\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	only\tagSENT_CONTENT	provide\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answer\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	since\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	and\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	-\tagSENT_CONTENT	Open\tagSENT_CONTENT	have\tagSENT_CONTENT	many\tagSENT_CONTENT	documents\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	filter\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	similarities\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	feed\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	paragraphs\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	FULL\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	training\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selector\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	two\tagSENT_CONTENT	techniques\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.2\tagSENT_CONTENT	,\tagSENT_CONTENT	weight\tagSENT_CONTENT	transfer\tagSENT_CONTENT	and\tagSENT_CONTENT	score\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	use\tagSENT_CONTENT	data\tagSENT_CONTENT	modification\tagSENT_CONTENT	technique\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	too\tagSENT_CONTENT	many\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	feed\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	to\tagSENT_CONTENT	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	MINI\tagSENT_CONTENT	-\tagSENT_CONTENT	MAL\tagSENT_CONTENT	obtains\tagSENT_CONTENT	higher\tagSENT_CONTENT	F1\tagSENT_CONTENT	and\tagSENT_CONTENT	EM\tagmetric	over\tagSENT_CONTENT	FULL\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	inference\tagSENT_CONTENT	speedup\tagSENT_CONTENT	of\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	13.8×.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selector\tagSENT_CONTENT	with\tagSENT_CONTENT	Dyn\tagSENT_CONTENT	achieves\tagSENT_CONTENT	higher\tagSENT_CONTENT	F1\tagSENT_CONTENT	and\tagSENT_CONTENT	EM\tagmetric	over\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	selector\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	-\tagSENT_CONTENT	full\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	5\tagSENT_CONTENT	sentences\tagSENT_CONTENT	per\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	average\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	Dyn\tagSENT_CONTENT	achieves\tagSENT_CONTENT	59.5\tagSENT_CONTENT	F1\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	TF\tagSENT_CONTENT	-\tagSENT_CONTENT	IDF\tagSENT_CONTENT	method\tagSENT_CONTENT	achieves\tagSENT_CONTENT	51.9\tagSENT_CONTENT	F1\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Adversarial\tagSECTITLE_END	Results\tagSENT_START	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	MINIMAL\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	FULL\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	by\tagSENT_CONTENT	large\tagSENT_CONTENT	margin\tagSENT_CONTENT	(\tagSENT_CONTENT	+11.1\tagSENT_CONTENT	and\tagSENT_CONTENT	+11.5\tagSENT_CONTENT	F1\tagmetric	on\tagSENT_CONTENT	AddSent\tagSENT_CONTENT	and\tagSENT_CONTENT	AddOneSent\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	FULL\tagSENT_CONTENT	selects\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	MINIMAL\tagSENT_CONTENT	first\tagSENT_CONTENT	chooses\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	 \tagSENT_CONTENT	subsequently\tagSENT_CONTENT	predicts\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	question_answering\tagtask	Answering\tagSENT_CONTENT	over\tagSENT_CONTENT	Documents\tagSENT_END	Who\tagSECTITLE_START	was\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	mayor\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	San\tagSECTITLE_CONTENT	Francisco\tagSECTITLE_CONTENT	during\tagSECTITLE_CONTENT	Super\tagSECTITLE_CONTENT	Bowl\tagSECTITLE_CONTENT	50\tagSECTITLE_CONTENT	?\tagSECTITLE_END	Many\tagSENT_START	neural\tagSENT_CONTENT	QA\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	successfully\tagSENT_CONTENT	addressed\tagSENT_CONTENT	these\tagSENT_CONTENT	tasks\tagSENT_CONTENT	by\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	coattention\tagSENT_CONTENT	or\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	codependent\tagSENT_CONTENT	context\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	researchers\tagSENT_CONTENT	have\tagSENT_CONTENT	developed\tagSENT_CONTENT	largescale\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	requires\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	over\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	documents\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	closed\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	selecting\tagSENT_CONTENT	sentences\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	answer\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	studied\tagSENT_CONTENT	across\tagSENT_CONTENT	several\tagSENT_CONTENT	QA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	modeling\tagSENT_CONTENT	relevance\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	studied\tagSENT_CONTENT	the\tagSENT_CONTENT	minimal\tagSENT_CONTENT	context\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	existing\tagSENT_CONTENT	datasets\tagSENT_CONTENT	and\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	most\tagSENT_CONTENT	questions\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	answered\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	Models\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	It\tagSENT_START	first\tagSENT_CONTENT	takes\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	inputs\tagSENT_END	We\tagSENT_START	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	300-dimensional\tagSENT_CONTENT	Glove\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	840B\tagSENT_CONTENT	Common\tagSENT_CONTENT	Crawl\tagSENT_CONTENT	corpus\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	100-dimensional\tagSENT_CONTENT	character\tagSENT_CONTENT	ngram\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	300-dimensional\tagSENT_CONTENT	contextualized\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	on\tagSENT_CONTENT	WMT\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	More\tagSECTITLE_CONTENT	Analyses\tagSECTITLE_END	We\tagSENT_START	randomly\tagSENT_CONTENT	sample\tagSENT_CONTENT	50\tagSENT_CONTENT	examples\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	(\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	)\tagSENT_CONTENT	development\tagSENT_CONTENT	(\tagSENT_CONTENT	verified\tagSENT_CONTENT	)\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	minimum\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Error\tagSENT_START	analyses\tagSENT_CONTENT	We\tagSENT_CONTENT	compare\tagSENT_CONTENT	the\tagSENT_CONTENT	error\tagSENT_CONTENT	cases\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagmetric	EM\tagmetric	)\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	FULL\tagSENT_CONTENT	and\tagSENT_CONTENT	MINIMAL\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	left\tagSENT_CONTENT	-\tagSENT_CONTENT	most\tagSENT_CONTENT	Venn\tagSENT_CONTENT	diagramin\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	MINIMAL\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	correctly\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	97\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answered\tagSENT_CONTENT	correctly\tagSENT_CONTENT	by\tagSENT_CONTENT	FULL\tagSENT_CONTENT	.\tagSENT_END	Human\tagSENT_START	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	TriviaQA\tagSENT_CONTENT	(\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	Examples\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	MINIMAL\tagSENT_CONTENT	predicts\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	two\tagSENT_START	examples\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selector\tagSENT_CONTENT	choose\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	QA\tagSENT_CONTENT	model\tagSENT_CONTENT	fails\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	correctly\tagSENT_CONTENT	,\tagSENT_CONTENT	either\tagSENT_CONTENT	predicting\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	oracle\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	wrong\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	C\tagSECTITLE_START	Full\tagSECTITLE_CONTENT	Results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	TriviaQA\tagSECTITLE_CONTENT	and\tagSECTITLE_END	MINIMAL\tagSENT_START	obtains\tagSENT_CONTENT	higher\tagSENT_CONTENT	F1\tagSENT_CONTENT	and\tagSENT_CONTENT	EM\tagmetric	over\tagSENT_CONTENT	FULL\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	inference\tagSENT_CONTENT	speedup\tagSENT_CONTENT	of\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	13.8×.\tagSENT_END	D\tagSECTITLE_START	Samples\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	SQuAD\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	TriviaQA\tagSECTITLE_CONTENT	and\tagSECTITLE_END	Analysis\tagSECTITLE_END	
N16-1026	title\tagSECTITLE_END	LSTM\tagSENT_START	ccg_supertagging\tagtask	abstract\tagSECTITLE_END	Instead\tagSENT_START	,\tagSENT_CONTENT	all\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	are\tagSENT_CONTENT	implicitly\tagSENT_CONTENT	encoded\tagSENT_CONTENT	in\tagSENT_CONTENT	ccg_supertagging\tagtask	that\tagSENT_CONTENT	assigns\tagSENT_CONTENT	CCG\tagSENT_CONTENT	lexical\tagSENT_CONTENT	categories\tagSENT_CONTENT	.\tagSENT_END	-\tagSENT_START	performs\tagSENT_CONTENT	all\tagSENT_CONTENT	previously\tagSENT_CONTENT	published\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	supports\tagSENT_CONTENT	efficient\tagSENT_CONTENT	and\tagSENT_CONTENT	optimal\tagSENT_CONTENT	A\tagSENT_END	We\tagSENT_START	give\tagSENT_CONTENT	a\tagSENT_CONTENT	detailed\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	demonstrating\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	can\tagSENT_CONTENT	recover\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	with\tagSENT_CONTENT	high\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	enables\tagSENT_CONTENT	significant\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	gains\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	State\tagSENT_START	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	parsers\tagSENT_CONTENT	typically\tagSENT_CONTENT	include\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	possible\tagSENT_CONTENT	lexical\tagSENT_CONTENT	categories\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	lexical\tagSENT_CONTENT	dependency\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	resolve\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	parse\tagSENT_CONTENT	attachment\tagSENT_CONTENT	ambiguities\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	along\tagSENT_CONTENT	shortterm\tagSENT_CONTENT	memory\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	CCG\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	has\tagSENT_CONTENT	no\tagSENT_CONTENT	explicit\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	lexical\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	instead\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	ccg_supertagging\tagtask	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	all\tagSENT_CONTENT	long\tagSENT_CONTENT	distance\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	.\tagSENT_END	ccg_supertagging\tagtask	is\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	and\tagSENT_CONTENT	includes\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	potential\tagSENT_CONTENT	over\tagSENT_CONTENT	tags\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	During\tagSENT_START	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	jointly\tagSENT_CONTENT	optimize\tagSENT_CONTENT	all\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	parameters\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	conditional\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	two\tagSENT_CONTENT	parses\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	attachment\tagSENT_CONTENT	decision\tagSENT_CONTENT	is\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	choice\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	lower\tagSENT_CONTENT	parses\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	attachment\tagSENT_CONTENT	is\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	given\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Whenever\tagSENT_START	there\tagSENT_CONTENT	is\tagSENT_CONTENT	parsing\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	not\tagSENT_CONTENT	specified\tagSENT_CONTENT	by\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	attaches\tagSENT_CONTENT	low\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	ccg_supertagging\tagtask	used\tagSENT_CONTENT	in\tagSENT_CONTENT	practice\tagSENT_CONTENT	are\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	,\tagSENT_CONTENT	providing\tagSENT_CONTENT	a\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	possible\tagSENT_CONTENT	tags\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	Visualization\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	stacked\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	1\tagSENT_CONTENT	follows\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	definition\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	factored\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	2\tagSENT_CONTENT	combines\tagSENT_CONTENT	this\tagSENT_CONTENT	definition\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	max\tagSENT_CONTENT	score\tagSENT_CONTENT	overall\tagSENT_CONTENT	supertags\tagSENT_CONTENT	fora\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	upperbound\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	used\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	parse\tagSENT_CONTENT	.\tagSENT_END	LSTM\tagSECTITLE_START	CCG\tagSECTITLE_CONTENT	Supertagging\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	ccg_supertagging\tagtask	is\tagSENT_CONTENT	almost\tagSENT_CONTENT	parsing\tagSENT_CONTENT	(\tagSENT_CONTENT	Bangalore\tagSENT_CONTENT	and\tagSENT_CONTENT	Joshi\tagSENT_CONTENT	,\tagSENT_CONTENT	1999)-consequently\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	chalAlgorithm\tagSENT_CONTENT	1\tagSENT_CONTENT	Agenda\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsing\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	Definitions\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	...\tagSENT_CONTENT	N\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_CONTENT	variables\tagSENT_CONTENT	denote\tagSENT_CONTENT	scored\tagSENT_CONTENT	partial\tagSENT_CONTENT	parses\tagSENT_CONTENT	.\tagSENT_END	3\tagSECTITLE_START	:\tagSECTITLE_END	10\tagSECTITLE_START	:\tagSECTITLE_END	Firstly\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	both\tagSENT_CONTENT	previous\tagSENT_CONTENT	and\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	sentence\tagSENT_CONTENT	context\tagSENT_CONTENT	into\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	ccg_supertagging\tagtask	is\tagSENT_CONTENT	summarized\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	layer\tagSENT_CONTENT	gives\tagSENT_CONTENT	a\tagSENT_CONTENT	contextdependent\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	fed\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	over\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Training\tagSENT_START	was\tagSENT_CONTENT	run\tagSENT_CONTENT	for\tagSENT_CONTENT	30\tagSENT_CONTENT	epochs\tagSENT_CONTENT	,\tagSENT_CONTENT	shuffling\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	after\tagSENT_CONTENT	each\tagSENT_CONTENT	epoch\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	development\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Parsing\tagSECTITLE_START	Models\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	ccg_supertagging\tagtask	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	a\tagSENT_CONTENT	supertagfactored\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	closely\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	approach\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	Dependencies\tagSENT_START	We\tagSENT_CONTENT	also\tagSENT_CONTENT	train\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	how\tagSENT_CONTENT	much\tagSENT_CONTENT	they\tagSENT_CONTENT	improve\tagSENT_CONTENT	accuracy\tagmetric	beyond\tagSENT_CONTENT	the\tagSENT_CONTENT	supertag\tagSENT_CONTENT	-\tagSENT_CONTENT	factored\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	adapt\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	CCG\tagSENT_CONTENT	and\tagSENT_CONTENT	SRL\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	by\tagSENT_CONTENT	assigning\tagSENT_CONTENT	every\tagSENT_CONTENT	CCGbank\tagSENT_CONTENT	dependency\tagSENT_CONTENT	a\tagSENT_CONTENT	role\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	its\tagSENT_CONTENT	argument\tagSENT_CONTENT	number\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	argument\tagSENT_CONTENT	of\tagSENT_CONTENT	every\tagSENT_CONTENT	category\tagSENT_CONTENT	has\tagSENT_CONTENT	role\tagSENT_CONTENT	ARG0\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	as\tagSENT_CONTENT	,\tagSENT_CONTENT	except\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	supertagger\tagSENT_CONTENT	score\tagSENT_CONTENT	feature\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	separate\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	ccg_supertagging\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	shift\tagSENT_CONTENT	-\tagSENT_CONTENT	reduce\tagSENT_CONTENT	parser\tagSENT_CONTENT	from\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	dependency\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	without\tagSENT_CONTENT	using\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	to\tagSENT_CONTENT	limit\tagSENT_CONTENT	the\tagSENT_CONTENT	correlation\tagSENT_CONTENT	with\tagSENT_CONTENT	ccg_supertagging\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	development\tagSENT_CONTENT	sentences\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	parsers\tagSENT_CONTENT	produce\tagSENT_CONTENT	ccg_supertagging\tagtask	(\tagSENT_CONTENT	40\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	accuracy\tagmetric	is\tagSENT_CONTENT	98.0\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	-\tagSENT_START	ccg_supertagging\tagtask	is\tagSENT_CONTENT	97.4\tagSENT_CONTENT	%\tagSENT_CONTENT	accurate\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	data\tagSENT_CONTENT	-\tagSENT_CONTENT	but\tagSENT_CONTENT	tritraining\tagSENT_CONTENT	still\tagSENT_CONTENT	provides\tagSENT_CONTENT	useful\tagSENT_CONTENT	additional\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	total\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	43\tagSENT_CONTENT	million\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	parsers\tagSENT_CONTENT	annotate\tagSENT_CONTENT	with\tagSENT_CONTENT	ccg_supertagging\tagtask	and\tagSENT_CONTENT	15\tagSENT_CONTENT	copies\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	CCGbank\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	tri\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	improves\tagSENT_CONTENT	both\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	and\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	GPU\tagSECTITLE_START	Parsing\tagSECTITLE_END	Our\tagSENT_START	parser\tagSENT_CONTENT	makes\tagSENT_CONTENT	an\tagSENT_CONTENT	unusual\tagSENT_CONTENT	trade\tagSENT_CONTENT	-\tagSENT_CONTENT	off\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	ccg_supertagging\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	deterministic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	A\tagSENT_CONTENT	*\tagSENT_CONTENT	parsing\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	is\tagSENT_CONTENT	extremely\tagSENT_CONTENT	efficient\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	overall\tagSENT_CONTENT	time\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	process\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	dominated\tagSENT_CONTENT	by\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	In\tagSENT_START	contrast\tagSENT_CONTENT	,\tagSENT_CONTENT	ccg_supertagging\tagtask	only\tagSENT_CONTENT	uses\tagSENT_CONTENT	matrix\tagSENT_CONTENT	operations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	take\tagSENT_CONTENT	any\tagSENT_CONTENT	parse\tagSENT_CONTENT	state\tagSENT_CONTENT	as\tagSENT_CONTENT	inputmeaning\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	to\tagSENT_CONTENT	run\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	GPU\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	setup\tagSECTITLE_END	We\tagSENT_START	trained\tagSENT_CONTENT	our\tagSENT_CONTENT	parser\tagSENT_CONTENT	on\tagSENT_CONTENT	Sections\tagSENT_CONTENT	02\tagSENT_CONTENT	-\tagSENT_CONTENT	21\tagSENT_CONTENT	of\tagSENT_CONTENT	CCGbank\tagdataset	,\tagSENT_CONTENT	using\tagSENT_CONTENT	Section\tagSENT_CONTENT	00\tagSENT_CONTENT	for\tagSENT_CONTENT	development\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Section\tagSENT_CONTENT	23\tagSENT_CONTENT	for\tagSENT_CONTENT	test\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	use\tagSENT_CONTENT	ccg_supertagging\tagtask	of\tagSENT_CONTENT	10\tagSENT_CONTENT	−4\tagSENT_END	Model\tagSECTITLE_END	Where\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	work\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	models\tagSENT_CONTENT	:\tagSENT_CONTENT	EASYCCG\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	neural\tagSENT_CONTENT	-\tagSENT_CONTENT	network\tagSENT_CONTENT	supertagger\tagSENT_CONTENT	(\tagSENT_CONTENT	NN\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	C&C+RNN\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	parser\tagSENT_CONTENT	with\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Supertagging\tagSECTITLE_START	Results\tagSECTITLE_END	The\tagSENT_START	most\tagSENT_CONTENT	direct\tagSENT_CONTENT	measure\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	tri\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	English\tagSECTITLE_START	Parsing\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Out\tagSECTITLE_START	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	domain\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	We\tagSENT_START	follow\tagSENT_CONTENT	Rimell\tagSENT_CONTENT	and\tagSENT_CONTENT	Clark\tagSENT_CONTENT	by\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	ccg_supertagging\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CCGbank\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	10\tagSENT_CONTENT	copies\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	QUESTIONS\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Dependency\tagSENT_START	features\tagSENT_CONTENT	appear\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	much\tagSENT_CONTENT	(\tagSENT_CONTENT	2011b\tagSENT_CONTENT	)\tagSENT_CONTENT	's\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	differences\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	experimental\tagSENT_CONTENT	setup\tagSENT_CONTENT	.\tagSENT_END	Parser\tagSECTITLE_END	Efficiency\tagSECTITLE_START	Experiments\tagSECTITLE_END	In\tagSENT_START	contrast\tagSENT_CONTENT	to\tagSENT_CONTENT	standard\tagSENT_CONTENT	parsing\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	depends\tagSENT_CONTENT	directly\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	ccg_supertagging\tagtask	in\tagSENT_CONTENT	guiding\tagSENT_CONTENT	the\tagSENT_CONTENT	search\tagSENT_CONTENT	.\tagSENT_END	Without\tagSENT_START	dependencies\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	run\tagSENT_CONTENT	time\tagSENT_CONTENT	is\tagSENT_CONTENT	dominated\tagSENT_CONTENT	by\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Running\tagSENT_START	ccg_supertagging\tagtask	on\tagSENT_CONTENT	a\tagSENT_CONTENT	GPU\tagSENT_CONTENT	reduces\tagSENT_CONTENT	parsing\tagSENT_CONTENT	times\tagSENT_CONTENT	dramaticallyoutperforming\tagSENT_CONTENT	SpaCy\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	fastest\tagSENT_CONTENT	publicly\tagSENT_CONTENT	available\tagSENT_CONTENT	parser\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Roughly\tagSENT_START	half\tagSENT_CONTENT	the\tagSENT_CONTENT	parsing\tagSENT_CONTENT	time\tagSENT_CONTENT	is\tagSENT_CONTENT	spent\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	half\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Supertagger\tagSECTITLE_END	Accuracy\tagSECTITLE_END	Bidirectional\tagSECTITLE_START	RNNs\tagSECTITLE_CONTENT	93.4\tagSECTITLE_CONTENT	Forward\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	only\tagSECTITLE_CONTENT	83.5\tagSECTITLE_CONTENT	Backward\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_CONTENT	only\tagSECTITLE_CONTENT	89.5\tagSECTITLE_CONTENT	Bidirectional\tagSECTITLE_CONTENT	LSTMs\tagSECTITLE_END	Ablations\tagSECTITLE_END	Supertagger\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	Numerous\tagSENT_START	variations\tagSENT_CONTENT	are\tagSENT_CONTENT	possible\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	shows\tagSENT_START	performance\tagSENT_CONTENT	while\tagSENT_CONTENT	ablating\tagSENT_CONTENT	these\tagSENT_CONTENT	changes\tagSENT_CONTENT	;\tagSENT_CONTENT	they\tagSENT_CONTENT	all\tagSENT_CONTENT	contribute\tagSENT_CONTENT	substantially\tagSENT_CONTENT	to\tagSENT_CONTENT	tagging\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	This\tagSENT_START	improvement\tagSENT_CONTENT	is\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	deep\tagSENT_CONTENT	architecture\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	better\tagSENT_CONTENT	take\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	the\tagSENT_CONTENT	interaction\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	preposition\tagSENT_CONTENT	,\tagSENT_CONTENT	its\tagSENT_CONTENT	argument\tagSENT_CONTENT	:\tagSENT_CONTENT	Effect\tagSENT_CONTENT	of\tagSENT_CONTENT	simulating\tagSENT_CONTENT	weaker\tagSENT_CONTENT	grammars\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	allowing\tagSENT_CONTENT	the\tagSENT_CONTENT	specified\tagSENT_CONTENT	atomic\tagSENT_CONTENT	categories\tagSENT_CONTENT	to\tagSENT_CONTENT	unify\tagSENT_CONTENT	.\tagSENT_END	Accuracy\tagmetric	improves\tagSENT_CONTENT	on\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	-\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	tri\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	effective\tagSENT_CONTENT	way\tagSENT_CONTENT	of\tagSENT_CONTENT	generalizing\tagSENT_CONTENT	to\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	than\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	alone\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	see\tagSENT_CONTENT	improvement\tagmetric	inaccuracy\tagmetric	on\tagSENT_CONTENT	wh\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	attribute\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	containing\tagSENT_CONTENT	more\tagSENT_CONTENT	examples\tagSENT_CONTENT	of\tagSENT_CONTENT	rare\tagSENT_CONTENT	categories\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	wh\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	piedpiping\tagSENT_CONTENT	and\tagSENT_CONTENT	similar\tagSENT_CONTENT	constructions\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Grammar\tagSECTITLE_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	Perhaps\tagSENT_START	our\tagSENT_CONTENT	most\tagSENT_CONTENT	surprising\tagSENT_CONTENT	result\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	high\tagmetric	accuracy\tagmetric	can\tagSENT_CONTENT	be\tagSENT_CONTENT	achieved\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	grammar\tagSENT_CONTENT	and\tagSENT_CONTENT	no\tagSENT_CONTENT	dependency\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	ccg_supertagging\tagtask	is\tagSENT_CONTENT	still\tagSENT_CONTENT	the\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	A\tagSENT_CONTENT	natural\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	whether\tagSENT_CONTENT	further\tagSENT_CONTENT	improvements\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	will\tagSENT_CONTENT	require\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	powerful\tagSENT_CONTENT	parsing\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	adding\tagSENT_CONTENT	dependency\tagSENT_CONTENT	or\tagSENT_CONTENT	derivation\tagSENT_CONTENT	features\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	if\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	should\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	supertagger\tagSENT_CONTENT	.\tagSENT_END	'\tagSECTITLE_START	Attach\tagSECTITLE_CONTENT	low\tagSECTITLE_CONTENT	'\tagSECTITLE_CONTENT	heuristic\tagSECTITLE_CONTENT	is\tagSECTITLE_CONTENT	surprisingly\tagSECTITLE_CONTENT	effective\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	grammar\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	investigate\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	this\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	performed\tagSENT_CONTENT	oracle\tagSENT_CONTENT	decoding\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	scoring\tagSENT_CONTENT	supertagsand\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	F1\tagSENT_CONTENT	improved\tagSENT_CONTENT	by\tagSENT_CONTENT	1.3\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	limits\tagSENT_CONTENT	to\tagSENT_CONTENT	what\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	achieved\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	rulebased\tagSENT_CONTENT	grammar\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	consider\tagSENT_CONTENT	several\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	whose\tagSENT_CONTENT	attachment\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	ambiguous\tagSENT_CONTENT	given\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	One\tagSENT_START	motivation\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	recover\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	.\tagSENT_END	Instead\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	to\tagSENT_CONTENT	implicitly\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	-\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	that\tagSENT_CONTENT	becomes\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	with\tagSENT_CONTENT	longer\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	investigate\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	parser\tagSENT_CONTENT	for\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	lengths\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Unlike\tagSENT_START	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	none\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	report\tagSENT_CONTENT	both\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	speed\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	Most\tagSENT_START	work\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	has\tagSENT_CONTENT	either\tagSENT_CONTENT	used\tagSENT_CONTENT	CKY\tagSENT_CONTENT	chart\tagSENT_CONTENT	parsing\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	shift\tagSENT_CONTENT	-\tagSENT_CONTENT	reduce\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	ccg_supertagging\tagtask	was\tagSENT_CONTENT	first\tagSENT_CONTENT	attempted\tagSENT_CONTENT	with\tagSENT_CONTENT	maximum\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	Markov\tagSENT_CONTENT	models)-in\tagSENT_CONTENT	practice\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	sparse\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	tag\tagSENT_CONTENT	set\tagSENT_CONTENT	makes\tagSENT_CONTENT	such\tagSENT_CONTENT	models\tagSENT_CONTENT	brittle\tagSENT_CONTENT	.\tagSENT_END	ccg_supertagging\tagtask	is\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	see\tagSENT_CONTENT	larger\tagSENT_CONTENT	gains\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	-\tagSENT_CONTENT	likely\tagSENT_CONTENT	because\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	involves\tagSENT_CONTENT	more\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	than\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	linguistics\tagSENT_CONTENT	and\tagSENT_CONTENT	classic\tagSENT_CONTENT	AI\tagSENT_CONTENT	search\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	a\tagSENT_CONTENT	parser\tagSENT_CONTENT	with\tagSENT_CONTENT	both\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	speed\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagmetric	.\tagSENT_END	The\tagSENT_START	major\tagSENT_CONTENT	obstacle\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	mismatch\tagSENT_CONTENT	between\tagSENT_CONTENT	these\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	
E17-1038	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	flexibility\tagSENT_CONTENT	of\tagSENT_CONTENT	NSE\tagSENT_CONTENT	on\tagSENT_CONTENT	five\tagSENT_CONTENT	different\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	sentence\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	where\tagSENT_CONTENT	NSE\tagSENT_CONTENT	achieved\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	when\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	publically\tagSENT_CONTENT	available\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Particularly\tagSENT_START	,\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	equipped\tagSENT_CONTENT	with\tagSENT_CONTENT	internal\tagSENT_CONTENT	short\tagSENT_CONTENT	memories\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	long\tagSENT_CONTENT	short\tagSENT_CONTENT	-\tagSENT_CONTENT	term\tagSENT_CONTENT	memories\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	a\tagSENT_CONTENT	notable\tagSENT_CONTENT	success\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Therefore\tagSENT_START	unless\tagSENT_CONTENT	the\tagSENT_CONTENT	controller\tagSENT_CONTENT	is\tagSENT_CONTENT	intelligent\tagSENT_CONTENT	enough\tagSENT_CONTENT	to\tagSENT_CONTENT	track\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	read\tagSENT_CONTENT	/\tagSENT_CONTENT	write\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	hard\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	RNN\tagSENT_CONTENT	when\tagSENT_CONTENT	processing\tagSENT_CONTENT	long\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	content\tagSENT_CONTENT	is\tagSENT_CONTENT	overlapped\tagSENT_CONTENT	and\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	overwritten\tagSENT_CONTENT	throughout\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Although\tagSENT_START	NSE\tagSENT_CONTENT	differs\tagSENT_CONTENT	from\tagSENT_CONTENT	other\tagSENT_CONTENT	memoryaugumented\tagSENT_CONTENT	NN\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	aspects\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	all\tagSENT_CONTENT	use\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	similarity\tagSENT_CONTENT	measures\tagSENT_CONTENT	to\tagSENT_CONTENT	retrieve\tagSENT_CONTENT	relevant\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	external\tagSENT_CONTENT	memory\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	aforementioned\tagSENT_CONTENT	memory\tagSENT_CONTENT	augmented\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	tested\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	whereas\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	NSE\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	real\tagSENT_CONTENT	and\tagSENT_CONTENT	largescale\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	applications\tagSENT_CONTENT	.\tagSENT_END	Proposed\tagSECTITLE_START	Approach\tagSECTITLE_END	Read\tagSECTITLE_START	,\tagSECTITLE_CONTENT	Compose\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Write\tagSECTITLE_END	Shared\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Multiple\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	Accesses\tagSECTITLE_END	Experiments\tagSECTITLE_END	Natural\tagSECTITLE_START	Language\tagSECTITLE_CONTENT	Inference\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	NSE\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	reason\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	between\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	premise\tagSENT_CONTENT	-\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	pair\tagSENT_CONTENT	is\tagSENT_CONTENT	entailing\tagSENT_CONTENT	,\tagSENT_CONTENT	contradictory\tagSENT_CONTENT	or\tagSENT_CONTENT	neutral\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	next\tagSENT_CONTENT	group\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	This\tagSENT_START	model\tagSENT_CONTENT	obtained\tagSENT_CONTENT	85.4\tagmetric	%\tagmetric	accuracy\tagmetric	score\tagmetric	.\tagSENT_END	The\tagSENT_START	best\tagSENT_CONTENT	performing\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	performs\tagSENT_CONTENT	tree\tagSENT_CONTENT	matching\tagSENT_CONTENT	with\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	.\tagSENT_END	Answer\tagSECTITLE_START	Sentence\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	Sentence\tagSECTITLE_START	Classification\tagSECTITLE_END	Model\tagSECTITLE_END	87.8\tagSENT_START	48.7\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	MC\tagSENT_CONTENT	88.1\tagSENT_CONTENT	47.4\tagSENT_CONTENT	DRNN\tagSENT_CONTENT	(\tagSENT_CONTENT	86.6\tagSENT_CONTENT	49.8\tagSENT_CONTENT	2-layer\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	86.3\tagSENT_CONTENT	46.0\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	87.5\tagSENT_CONTENT	49.1\tagSENT_CONTENT	CT\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	88.0\tagSENT_CONTENT	51.0\tagSENT_CONTENT	DMN\tagSENT_CONTENT	(\tagSENT_CONTENT	88.6\tagSENT_CONTENT	52.1\tagSENT_CONTENT	NSE\tagSENT_CONTENT	89.7\tagSENT_CONTENT	52.8\tagSENT_CONTENT	:\tagSENT_CONTENT	Test\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	sentence\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	Document\tagSECTITLE_START	Sentiment\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	on\tagSENT_CONTENT	two\tagSENT_CONTENT	publically\tagSENT_CONTENT	available\tagSENT_CONTENT	largescale\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	IMDB\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	335,018\tagSENT_CONTENT	movie\tagSENT_CONTENT	reviews\tagSENT_CONTENT	and\tagSENT_CONTENT	10\tagSENT_CONTENT	different\tagSENT_CONTENT	classes\tagSENT_CONTENT	and\tagSENT_END	Each\tagSENT_START	document\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	is\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	human\tagSENT_CONTENT	ratings\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	these\tagSENT_CONTENT	ratings\tagSENT_CONTENT	as\tagSENT_CONTENT	gold\tagSENT_CONTENT	labels\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	speedup\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	created\tagSENT_CONTENT	document\tagSENT_CONTENT	buckets\tagSENT_CONTENT	by\tagSENT_CONTENT	considering\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	per\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	documents\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	were\tagSENT_CONTENT	put\tagSENT_CONTENT	together\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	bucket\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	report\tagSENT_CONTENT	two\tagSENT_CONTENT	performance\tagSENT_CONTENT	metrics\tagSENT_CONTENT	:\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	MSE\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	NSE\tagSENT_CONTENT	models\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	stateof\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	MSE\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	approximately\tagSENT_CONTENT	2\tagSENT_CONTENT	-\tagSENT_CONTENT	3\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	possibly\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	memory\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	level\tagSENT_CONTENT	NSE\tagSENT_CONTENT	that\tagSENT_CONTENT	preserves\tagSENT_CONTENT	the\tagSENT_CONTENT	long\tagSENT_CONTENT	dependency\tagSENT_CONTENT	in\tagSENT_CONTENT	documents\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Machine\tagSECTITLE_START	Translation\tagSECTITLE_END	sentiment_analysis\tagtask	with\tagSENT_CONTENT	length\tagSENT_CONTENT	longer\tagSENT_CONTENT	than\tagSENT_CONTENT	25\tagSENT_CONTENT	words\tagSENT_CONTENT	were\tagSENT_CONTENT	filtered\tagSENT_CONTENT	out\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	Memory\tagSECTITLE_START	Access\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Compositionality\tagSECTITLE_END	Conclusion\tagSECTITLE_END	One\tagSENT_START	could\tagSENT_CONTENT	also\tagSENT_CONTENT	explore\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	variations\tagSENT_CONTENT	of\tagSENT_CONTENT	NSE\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	encoding\tagSENT_CONTENT	memory\tagSENT_CONTENT	and\tagSENT_CONTENT	representation\tagSENT_CONTENT	vector\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	or\tagSENT_CONTENT	documents\tagSENT_CONTENT	using\tagSENT_CONTENT	either\tagSENT_CONTENT	new\tagSENT_CONTENT	or\tagSENT_CONTENT	existing\tagSENT_CONTENT	models\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	
P16-1072	title\tagSECTITLE_END	Bidirectional\tagSENT_START	Recurrent\tagSENT_CONTENT	Convolutional\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	abstract\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	semantic\tagSENT_CONTENT	processing\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	model\tagSENT_CONTENT	BRCNN\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	further\tagSENT_CONTENT	explore\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	full\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	SDP\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	channel\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	long\tagSENT_CONTENT	short\tagSENT_CONTENT	term\tagSENT_CONTENT	memory\tagSENT_CONTENT	(\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	units\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	architecture\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	relationship_extraction\tagtask	along\tagSENT_CONTENT	the\tagSENT_CONTENT	SDP\tagSENT_CONTENT	forwards\tagSENT_CONTENT	and\tagSENT_CONTENT	backwards\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	benefits\tagSENT_CONTENT	classifying\tagSENT_CONTENT	the\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	"\tagSENT_CONTENT	The\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	water\tagSENT_CONTENT	hammer\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	entities\tagSENT_CONTENT	burst\tagSENT_CONTENT	and\tagSENT_CONTENT	pressure\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	CauseEffect(e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	become\tagSENT_CONTENT	a\tagSENT_CONTENT	hot\tagSENT_CONTENT	research\tagSENT_CONTENT	topic\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Nowadays\tagSENT_START	,\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	techniques\tagSENT_CONTENT	have\tagSENT_CONTENT	made\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	*\tagSENT_END	The\tagSENT_START	NN\tagSENT_CONTENT	research\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	has\tagSENT_CONTENT	centered\tagSENT_CONTENT	around\tagSENT_CONTENT	two\tagSENT_CONTENT	main\tagSENT_CONTENT	network\tagSENT_CONTENT	architectures\tagSENT_CONTENT	:\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	recursive\tagSENT_CONTENT	/\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Convolutional\tagSENT_START	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	generalize\tagSENT_CONTENT	the\tagSENT_CONTENT	local\tagSENT_CONTENT	and\tagSENT_CONTENT	consecutive\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	while\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	adaptively\tagSENT_CONTENT	accumulate\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	sentence\tagSENT_CONTENT	via\tagSENT_CONTENT	memory\tagSENT_CONTENT	units\tagSENT_CONTENT	,\tagSENT_CONTENT	thereby\tagSENT_CONTENT	encoding\tagSENT_CONTENT	the\tagSENT_CONTENT	global\tagSENT_CONTENT	and\tagSENT_CONTENT	possibly\tagSENT_CONTENT	unconsecutive\tagSENT_CONTENT	patterns\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Previous\tagSENT_START	works\tagSENT_CONTENT	treated\tagSENT_CONTENT	dependency\tagSENT_CONTENT	relations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	way\tagSENT_CONTENT	as\tagSENT_CONTENT	words\tagSENT_CONTENT	or\tagSENT_CONTENT	some\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	features\tagSENT_CONTENT	like\tagSENT_CONTENT	partof\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	further\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	directed\tagSENT_CONTENT	.\tagSENT_END	corresponds\tagSENT_START	to\tagSENT_CONTENT	relationship_extraction\tagtask	CauseEffect(e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	SDP\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	also\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	relation\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect(e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	at\tagSENT_CONTENT	front\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	SDP\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	at\tagSENT_CONTENT	back\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	SDP\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	inverse\tagSENT_CONTENT	SDP\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	second\tagSENT_CONTENT	contribution\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	BRCNN\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	relationship_extraction\tagtask	along\tagSENT_CONTENT	the\tagSENT_CONTENT	SDP\tagSENT_CONTENT	forwards\tagSENT_CONTENT	and\tagSENT_CONTENT	backwards\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	also\tagSENT_CONTENT	strengthen\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	classifying\tagSENT_CONTENT	directions\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	Method\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	Framework\tagSECTITLE_END	Our\tagSENT_START	BCRNN\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	relationship_extraction\tagtask	along\tagSENT_CONTENT	the\tagSENT_CONTENT	SDP\tagSENT_CONTENT	forwards\tagSENT_CONTENT	and\tagSENT_CONTENT	backwards\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Shortest\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Path\tagSECTITLE_END	If\tagSENT_START	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	are\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	sentence\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	observed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	path\tagSENT_CONTENT	between\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_END	condenses\tagSENT_START	most\tagSENT_CONTENT	illuminating\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	first\tagSENT_START	used\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	paths\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	predicate\tagSENT_CONTENT	-\tagSENT_CONTENT	argument\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	provided\tagSENT_CONTENT	strong\tagSENT_CONTENT	evidence\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Besides\tagSENT_START	,\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	inverse\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	an\tagSENT_CONTENT	opposite\tagSENT_CONTENT	direction\tagSENT_CONTENT	.\tagSENT_END	Two\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Channel\tagSECTITLE_CONTENT	Recurrent\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Long\tagSECTITLE_CONTENT	Short\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	Units\tagSECTITLE_END	We\tagSENT_START	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	relations\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	SDP\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Traditional\tagSENT_START	recurrent\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	is\tagSENT_CONTENT	linearly\tagSENT_CONTENT	transformed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	weight\tagSENT_CONTENT	matrix\tagSENT_CONTENT	and\tagSENT_CONTENT	nonlinearly\tagSENT_CONTENT	squashed\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	activation\tagSENT_CONTENT	function\tagSENT_CONTENT	.\tagSENT_END	Bidirectional\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	Convolutional\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	f\tagmetric	is\tagSENT_CONTENT	relationship_extraction\tagtask	function(tanh\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	channel\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	better\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	adaptively\tagSENT_CONTENT	accumulating\tagSENT_CONTENT	relationship_extraction\tagtask	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	path\tagSENT_CONTENT	via\tagSENT_CONTENT	memory\tagSENT_CONTENT	units\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	could\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	when\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	located\tagSENT_CONTENT	at\tagSENT_CONTENT	both\tagSENT_CONTENT	ends\tagSENT_CONTENT	of\tagSENT_CONTENT	SDP\tagSENT_CONTENT	and\tagSENT_CONTENT	key\tagSENT_CONTENT	components\tagSENT_CONTENT	could\tagSENT_CONTENT	appear\tagSENT_CONTENT	anywhere\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	SDP\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	basis\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	a\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	SDP\tagSENT_CONTENT	is\tagSENT_CONTENT	asymmetrical\tagSENT_CONTENT	structure\tagSENT_CONTENT	.\tagSENT_END	Coarse\tagSENT_START	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	classifier\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	relationship_extraction\tagtask	ignoring\tagSENT_CONTENT	the\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	learns\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	directed\tagSENT_CONTENT	relations\tagSENT_CONTENT	with\tagSENT_CONTENT	opposite\tagSENT_CONTENT	directions\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Rx\tagSENT_CONTENT	(\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Rx\tagSENT_CONTENT	(\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	→\tagSENT_START	Sand\tagSENT_CONTENT	←\tagSENT_CONTENT	−\tagSENT_CONTENT	S\tagSENT_CONTENT	respecitvely\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	time\tagSENT_CONTENT	can\tagSENT_CONTENT	strengthen\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	judge\tagSENT_CONTENT	the\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	Objective\tagSECTITLE_END	−\tagSENT_START	S\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	−\tagSENT_START	S\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	θ\tagSENT_START	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	learned\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	λ\tagSENT_CONTENT	is\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	where\tagSENT_START	α\tagSENT_CONTENT	is\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	composition\tagSENT_CONTENT	of\tagSENT_CONTENT	distributions\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	value\tagSENT_CONTENT	0.65\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	validation\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	During\tagSENT_START	relationship_extraction\tagtask	of\tagSENT_CONTENT	BRCNN\tagSENT_CONTENT	,\tagSENT_CONTENT	elements\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	class\tagSENT_CONTENT	distributions\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	position\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	−\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	BRCNN\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	established\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	The\tagSENT_START	former\tagSENT_CONTENT	K=9\tagSENT_CONTENT	relations\tagSENT_CONTENT	are\tagSENT_CONTENT	directed\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	the\tagSENT_CONTENT	Other\tagSENT_CONTENT	class\tagSENT_CONTENT	is\tagSENT_CONTENT	undirected\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	(\tagSENT_CONTENT	2K+1)=19\tagSENT_CONTENT	different\tagSENT_CONTENT	classes\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Hyperparameter\tagSECTITLE_START	Settings\tagSECTITLE_END	Embeddings\tagSENT_START	of\tagSENT_CONTENT	relationship_extraction\tagtask	are\tagSENT_CONTENT	50-dimensional\tagSENT_CONTENT	and\tagSENT_CONTENT	initialized\tagSENT_CONTENT	randomly\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Further\tagSENT_START	,\tagSENT_CONTENT	they\tagSENT_CONTENT	extended\tagSENT_CONTENT	their\tagSENT_CONTENT	recursive\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	elevated\tagSENT_CONTENT	the\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	82.4\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	LSTM\tagSENT_START	with\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	only\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	-score\tagSENT_CONTENT	of\tagSENT_CONTENT	76.6\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	proves\tagSENT_CONTENT	that\tagSENT_CONTENT	dependency\tagSENT_CONTENT	relations\tagSENT_CONTENT	in\tagSENT_CONTENT	SDPs\tagSENT_CONTENT	play\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Analysis\tagSECTITLE_END	Model\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	Other\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	dose\tagSENT_CONTENT	not\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	9\tagSENT_CONTENT	directed\tagSENT_CONTENT	classes\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	class\tagSENT_CONTENT	Other\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	noisy\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	groups\tagSENT_CONTENT	many\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	different\tagSENT_CONTENT	directions\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	proves\tagSENT_CONTENT	relationship_extraction\tagtask	provide\tagSENT_CONTENT	more\tagSENT_CONTENT	useful\tagSENT_CONTENT	information\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	directed\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	still\tagSENT_CONTENT	benefits\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	coarse\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	help\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	learn\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	directed\tagSENT_CONTENT	relations\tagSENT_CONTENT	with\tagSENT_CONTENT	opposite\tagSENT_CONTENT	directions\tagSENT_CONTENT	.\tagSENT_END	Beyond\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	general\tagSENT_CONTENT	technique\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	restricted\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	potential\tagSENT_CONTENT	to\tagSENT_CONTENT	benefit\tagSENT_CONTENT	other\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	topic\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	.\tagSENT_END	Traditional\tagSENT_START	Methods\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	mainly\tagSENT_CONTENT	fall\tagSENT_CONTENT	into\tagSENT_CONTENT	three\tagSENT_CONTENT	classes\tagSENT_CONTENT	:\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	,\tagSENT_CONTENT	kernel\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	and\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	.\tagSENT_END	designed\tagSENT_START	a\tagSENT_CONTENT	kernel\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	shortest\tagSENT_CONTENT	dependency\tagSENT_CONTENT	path\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	by\tagSENT_CONTENT	observing\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	strongly\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	SDPs\tagSENT_CONTENT	.\tagSENT_END	provided\tagSENT_START	a\tagSENT_CONTENT	systematic\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	kernels\tagSENT_CONTENT	and\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	can\tagSENT_CONTENT	benefit\tagSENT_CONTENT	from\tagSENT_CONTENT	combining\tagSENT_CONTENT	convolution\tagSENT_CONTENT	kernel\tagSENT_CONTENT	and\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	combined\tagSENT_START	structural\tagSENT_CONTENT	information\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	a\tagSENT_CONTENT	tree\tagSENT_CONTENT	kernel\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	potential\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	of\tagSENT_CONTENT	kernel\tagSENT_CONTENT	methods\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	completely\tagSENT_CONTENT	summarized\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	kernel\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	thus\tagSENT_CONTENT	designing\tagSENT_CONTENT	an\tagSENT_CONTENT	effective\tagSENT_CONTENT	kernel\tagSENT_CONTENT	becomes\tagSENT_CONTENT	crucial\tagSENT_CONTENT	.\tagSENT_END	Convolutional\tagSENT_START	neural\tagSENT_CONTENT	works\tagSENT_CONTENT	are\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	proposed\tagSENT_START	an\tagSENT_CONTENT	approach\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	where\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	through\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	and\tagSENT_CONTENT	position\tagSENT_CONTENT	features\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	tackled\tagSENT_CONTENT	relationship_extraction\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	and\tagSENT_CONTENT	proposed\tagSENT_CONTENT	anew\tagSENT_CONTENT	pairwise\tagSENT_CONTENT	ranking\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	result\tagSENT_CONTENT	in\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	.\tagSENT_END	learned\tagSENT_START	relationship_extraction\tagtask	from\tagSENT_CONTENT	SDP\tagSENT_CONTENT	through\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	negative\tagSENT_CONTENT	sampling\tagSENT_CONTENT	strategy\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	assignment\tagSENT_CONTENT	of\tagSENT_CONTENT	subjects\tagSENT_CONTENT	and\tagSENT_CONTENT	objects\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	BRCNN\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	SDP\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	pickup\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	CNN\tagSENT_CONTENT	.\tagSENT_END	763\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	BRCNN\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	
C16-1238	title\tagSECTITLE_END	Attention\tagSENT_START	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Convolutional\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Network\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	abstract\tagSECTITLE_END	Nowadays\tagSENT_START	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	play\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Classifying\tagSENT_START	relationship_extraction\tagtask	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	context\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	marked\tagSENT_CONTENT	entities\tagSENT_CONTENT	"\tagSENT_CONTENT	valuables\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	safe\tagSENT_CONTENT	"\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	"\tagSENT_CONTENT	Content\tagSENT_CONTENT	-\tagSENT_CONTENT	Container(e1\tagSENT_CONTENT	;\tagSENT_CONTENT	e2\tagSENT_CONTENT	)\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	plays\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	become\tagSENT_CONTENT	a\tagSENT_CONTENT	hot\tagSENT_CONTENT	research\tagSENT_CONTENT	topic\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	methods\tagSENT_CONTENT	mentioned\tagSENT_CONTENT	above\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	scale\tagSENT_CONTENT	well\tagSENT_CONTENT	during\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	it\tagSENT_CONTENT	very\tagSENT_CONTENT	hard\tagSENT_CONTENT	to\tagSENT_CONTENT	engineer\tagSENT_CONTENT	effective\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	learn\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	some\tagSENT_CONTENT	researchers\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	paid\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	feature\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	utilized\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	relationship_extraction\tagtask	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	always\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	.\tagSENT_END	that\tagSENT_START	caused\tagSENT_CONTENT	thee\tagSENT_CONTENT	2\tagSENT_CONTENT	accident\tagSENT_CONTENT	/e\tagSENT_CONTENT	2\tagSENT_CONTENT	was\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	cellphone\tagSENT_CONTENT	and\tagSENT_CONTENT	ran\tagSENT_CONTENT	thru\tagSENT_CONTENT	relationship_extraction\tagtask	without\tagSENT_CONTENT	pausing\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	median\tagSENT_CONTENT	.\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	"\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect(e2,e1\tagSENT_CONTENT	)\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	caused\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	particular\tagSENT_CONTENT	significance\tagSENT_CONTENT	in\tagSENT_CONTENT	determining\tagSENT_CONTENT	relationship_extraction\tagtask	"\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	"\tagSENT_CONTENT	phone\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	correlated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	"\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Compared\tagSENT_START	to\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	full\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tag\tagSENT_CONTENT	embedding\tagSENT_CONTENT	and\tagSENT_CONTENT	position\tagSENT_CONTENT	embedding\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	convolution\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	choose\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Works\tagSECTITLE_END	A\tagSENT_START	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	paradigms\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	supervised\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	researchers\tagSENT_CONTENT	concentrate\tagSENT_CONTENT	on\tagSENT_CONTENT	extracting\tagSENT_CONTENT	complex\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	either\tagSENT_CONTENT	feature\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	or\tagSENT_CONTENT	kernel\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	converted\tagSENT_CONTENT	the\tagSENT_CONTENT	classification\tagSENT_CONTENT	clues\tagSENT_CONTENT	(\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sequences\tagSENT_CONTENT	and\tagSENT_CONTENT	parse\tagSENT_CONTENT	trees\tagSENT_CONTENT	)\tagSENT_CONTENT	into\tagSENT_CONTENT	feature\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	Various\tagSENT_START	kernels\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	convolution\tagSENT_CONTENT	tree\tagSENT_CONTENT	kernel\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	subsequence\tagSENT_CONTENT	kernel\tagSENT_CONTENT	(\tagSENT_CONTENT	Mooney\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	tree\tagSENT_CONTENT	kernel\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_CONTENT	)\tagSENT_END	introduced\tagSENT_START	relationship_extraction\tagtask	into\tagSENT_CONTENT	kernel\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	considering\tagSENT_CONTENT	structural\tagSENT_CONTENT	information\tagSENT_CONTENT	only\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	NLP\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	methods\tagSENT_CONTENT	are\tagSENT_CONTENT	primarily\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	learning\tagSENT_CONTENT	a\tagSENT_CONTENT	distributed\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	called\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	recursive\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	vectors\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	tree\tagSENT_CONTENT	path\tagSENT_CONTENT	connecting\tagSENT_CONTENT	two\tagSENT_CONTENT	nominals\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	their\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relationship\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	also\tagSENT_CONTENT	employed\tagSENT_CONTENT	relationship_extraction\tagtask	allowing\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	explicit\tagSENT_CONTENT	weighting\tagSENT_CONTENT	of\tagSENT_CONTENT	important\tagSENT_CONTENT	phrases\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	reference\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	language\tagSENT_CONTENT	for\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	foreign\tagSENT_CONTENT	language\tagSENT_CONTENT	before\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	relevant\tagSENT_CONTENT	image\tagSENT_CONTENT	regions\tagSENT_CONTENT	when\tagSENT_CONTENT	generating\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	captions\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_END	introduced\tagSENT_START	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	into\tagSENT_CONTENT	relationship_extraction\tagtask	which\tagSENT_CONTENT	relied\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	discover\tagSENT_CONTENT	better\tagSENT_CONTENT	patterns\tagSENT_CONTENT	in\tagSENT_CONTENT	heterogeneous\tagSENT_CONTENT	contexts\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Methodology\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	x\tagSENT_CONTENT	n\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	r.\tagSENT_END	Here\tagSENT_START	,\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	component\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	convolution\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	After\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	two\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	vectors\tagSENT_CONTENT	-the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	convolution\tagSENT_CONTENT	vector\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	context\tagSENT_CONTENT	vector\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	generated\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	•\tagSENT_START	relationship_extraction\tagtask	:\tagSENT_CONTENT	We\tagSENT_CONTENT	use\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	relevant\tagSENT_CONTENT	words\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	Convolution\tagSECTITLE_END	Input\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	more\tagSENT_CONTENT	informative\tagSENT_CONTENT	in\tagSENT_CONTENT	determining\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Google\tagSENT_CONTENT	News\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	slightly\tagSENT_CONTENT	different\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Convolution\tagSECTITLE_START	,\tagSECTITLE_CONTENT	Max\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	pooling\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Non\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	linear\tagSECTITLE_CONTENT	Layers\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	challenges\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	is\tagSENT_CONTENT	variable\tagSENT_CONTENT	and\tagSENT_CONTENT	important\tagSENT_CONTENT	information\tagSENT_CONTENT	can\tagSENT_CONTENT	appear\tagSENT_CONTENT	anywhere\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	should\tagSENT_CONTENT	merge\tagSENT_CONTENT	all\tagSENT_CONTENT	local\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	perform\tagSENT_CONTENT	relationship_extraction\tagtask	globally\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	involves\tagSENT_CONTENT	a\tagSENT_CONTENT	filter\tagSENT_CONTENT	w\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	hk\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	window\tagSENT_CONTENT	of\tagSENT_CONTENT	h\tagSENT_CONTENT	words\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	anew\tagSENT_CONTENT	feature\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	f\tagmetric	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	function\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	hyperbolic\tagSENT_CONTENT	tangent\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Context\tagSECTITLE_CONTENT	Selection\tagSECTITLE_END	For\tagSENT_START	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	That\tagSENT_CONTENT	coupled\tagSENT_CONTENT	with\tagSENT_CONTENT	thee\tagSENT_CONTENT	1\tagSENT_CONTENT	death\tagSENT_CONTENT	/e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	thee\tagSENT_CONTENT	2\tagSENT_CONTENT	storm\tagSENT_CONTENT	/e\tagSENT_CONTENT	2\tagSENT_CONTENT	was\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	traumatic\tagSENT_CONTENT	experience\tagSENT_CONTENT	for\tagSENT_CONTENT	these\tagSENT_CONTENT	residents\tagSENT_CONTENT	.\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Here\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	"\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect(e2,e1\tagSENT_CONTENT	)\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	caused\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	particular\tagSENT_CONTENT	significance\tagSENT_CONTENT	in\tagSENT_CONTENT	determining\tagSENT_CONTENT	relationship_extraction\tagtask	"\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	network\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	MLP\tagSECTITLE_START	Layer\tagSECTITLE_END	Model\tagSECTITLE_START	Training\tagSECTITLE_END	relationship_extraction\tagtask	proposed\tagSENT_CONTENT	here\tagSENT_CONTENT	using\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	stated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	parameter\tagSENT_CONTENT	vector\tagSENT_CONTENT	θ\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	Metrics\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval-2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	established\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	dataset\tagSENT_CONTENT	distinguishes\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	former\tagSENT_CONTENT	9\tagSENT_CONTENT	relations\tagSENT_CONTENT	are\tagSENT_CONTENT	directed\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	Other\tagSENT_CONTENT	"\tagSENT_CONTENT	class\tagSENT_CONTENT	is\tagSENT_CONTENT	undirected\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	We\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	distinguish\tagSENT_CONTENT	the\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Parameter\tagSECTITLE_START	Settings\tagSECTITLE_END	In\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	experimentally\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	effects\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	parameters\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	:\tagSENT_END	Model\tagSECTITLE_END	Results\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Comparison\tagSECTITLE_CONTENT	Experiments\tagSECTITLE_END	All\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	models\tagSENT_CONTENT	adopt\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	except\tagSENT_CONTENT	SVM\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	can\tagSENT_CONTENT	observe\tagSENT_CONTENT	in\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	Attention\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	without\tagSENT_CONTENT	extra\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	and\tagSENT_CONTENT	words\tagSENT_CONTENT	around\tagSENT_CONTENT	nominals\tagSENT_CONTENT	,\tagSENT_CONTENT	still\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	previously\tagSENT_CONTENT	reported\tagSENT_CONTENT	best\tagSENT_CONTENT	systems\tagSENT_CONTENT	of\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	SDP\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	F1\tagmetric	of\tagSENT_CONTENT	83.7\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	though\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	have\tagSENT_CONTENT	taken\tagSENT_CONTENT	extra\tagSENT_CONTENT	lexical\tagSENT_CONTENT	features\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	Attention\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	all\tagSENT_CONTENT	apply\tagSENT_CONTENT	convolution\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	from\tagSENT_CONTENT	that\tagSENT_CONTENT	Attention\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	yield\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	84.3\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	CR\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	.\tagSENT_END	Feature\tagSECTITLE_START	Sets\tagSECTITLE_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Different\tagSECTITLE_CONTENT	Feature\tagSECTITLE_CONTENT	Component\tagSECTITLE_END	From\tagSENT_START	the\tagSENT_CONTENT	results\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	learned\tagSENT_CONTENT	position\tagSENT_CONTENT	embedding\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Visualization\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Relation\tagSECTITLE_END	Representation\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Weight\tagSECTITLE_END	Message\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Topic\tagSECTITLE_END	Cause\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Effect\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	future\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	exploring\tagSENT_CONTENT	better\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	structure\tagSENT_CONTENT	about\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Meanwhile\tagSENT_START	,\tagSENT_CONTENT	because\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	relation\tagSENT_CONTENT	extraction\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	seek\tagSENT_CONTENT	better\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	completing\tagSENT_CONTENT	relationship_extraction\tagtask	jointly\tagSENT_CONTENT	.\tagSENT_END	
1603.03793	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	adapt\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	Dyer\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Parsing\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Parameter\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	Our\tagSENT_START	departure\tagSENT_CONTENT	point\tagSENT_CONTENT	is\tagSENT_CONTENT	dependency_parsing\tagtask	described\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	parser\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	conditional\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	taking\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	correct\tagSENT_CONTENT	"\tagSENT_CONTENT	action\tagSENT_CONTENT	at\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Training\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Static\tagSECTITLE_CONTENT	Oracles\tagSECTITLE_END	Training\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Dynamic\tagSECTITLE_CONTENT	Oracles\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	static\tagSENT_CONTENT	oracle\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	transition\tagSENT_CONTENT	to\tagSENT_CONTENT	take\tagSENT_CONTENT	at\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	assuming\tagSENT_CONTENT	all\tagSENT_CONTENT	previous\tagSENT_CONTENT	transitions\tagSENT_CONTENT	were\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	expose\tagSENT_CONTENT	the\tagSENT_CONTENT	parser\tagSENT_CONTENT	to\tagSENT_CONTENT	configurations\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	result\tagSENT_CONTENT	from\tagSENT_CONTENT	incorrect\tagSENT_CONTENT	parsing\tagSENT_CONTENT	decisions\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	classifier\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	show\tagSENT_CONTENT	below\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	turns\tagSENT_CONTENT	out\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	very\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	configurations\tagSENT_CONTENT	that\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	external\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	parser\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	correct\tagSENT_CONTENT	action\tagSENT_CONTENT	z\tagSENT_CONTENT	g\tagSENT_CONTENT	at\tagSENT_CONTENT	dependency_parsing\tagtask	according\tagSENT_CONTENT	to\tagSENT_CONTENT	Equation\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Training\tagSENT_START	dependency_parsing\tagtask	on\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	gold\tagSENT_CONTENT	outcomes\tagSENT_CONTENT	,\tagSENT_CONTENT	facilitated\tagSENT_CONTENT	by\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	oracles\tagSENT_CONTENT	,\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	by\tagSENT_CONTENT	several\tagSENT_CONTENT	researchers\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	ways\tagSENT_CONTENT	(\tagSENT_CONTENT	We\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	parsers\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	comparable\tagSENT_CONTENT	setup\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	beam\tagSENT_CONTENT	size\tagSENT_CONTENT	1\tagSENT_CONTENT	or\tagSENT_CONTENT	greedy\tagSENT_CONTENT	search\tagSENT_CONTENT	..\tagSENT_END	presented\tagSENT_START	stack\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	and\tagSENT_CONTENT	used\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	implement\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Conclusions\tagSECTITLE_END	
1807.01270	title\tagSECTITLE_END	REACHING\tagSENT_START	HUMAN\tagSENT_CONTENT	-\tagSENT_CONTENT	LEVEL\tagSENT_CONTENT	PERFORMANCE\tagSENT_CONTENT	IN\tagSENT_CONTENT	grammatical_error_correction\tagtask	:\tagSENT_END	abstract\tagSECTITLE_END	Neural\tagSENT_START	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	)\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	proven\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	successful\tagSENT_CONTENT	in\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Sequence\tagSENT_START	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	(\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	)\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	drawn\tagSENT_CONTENT	growing\tagSENT_CONTENT	attention\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	fluency\tagSENT_CONTENT	boosting\tagSENT_CONTENT	learning\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	it\tagSENT_CONTENT	generates\tagSENT_CONTENT	less\tagSENT_CONTENT	fluent\tagSENT_CONTENT	sentences\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	its\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	outputs\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	establish\tagSENT_CONTENT	new\tagSENT_CONTENT	error\tagSENT_CONTENT	-\tagSENT_CONTENT	corrected\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	by\tagSENT_CONTENT	pairing\tagSENT_CONTENT	them\tagSENT_CONTENT	with\tagSENT_CONTENT	their\tagSENT_CONTENT	correct\tagSENT_CONTENT	sentences\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	long\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	sentences\tagSENT_CONTENT	'\tagSENT_CONTENT	fluency\tagSENT_CONTENT	1\tagSENT_CONTENT	is\tagSENT_CONTENT	below\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	correct\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	as(a\tagSENT_CONTENT	)\tagSENT_CONTENT	shows\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	b\tagSENT_CONTENT	)\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	inference\tagSENT_CONTENT	allows\tagSENT_CONTENT	grammatical_error_correction\tagtask	to\tagSENT_CONTENT	correct\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	incrementally\tagSENT_CONTENT	through\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	round\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	inference\tagSENT_CONTENT	as\tagSENT_CONTENT	long\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	fluency\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	improved\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	combining\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	inference\tagSENT_CONTENT	with\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	best\tagSENT_CONTENT	GEC\tagSENT_CONTENT	system\tagSENT_CONTENT	3\tagSENT_CONTENT	achieves\tagSENT_CONTENT	75.72\tagSENT_CONTENT	F\tagSENT_CONTENT	0.5\tagSENT_CONTENT	on\tagSENT_CONTENT	CoNLL-2014\tagSENT_CONTENT	10\tagSENT_CONTENT	annotation\tagSENT_CONTENT	dataset\tagSENT_CONTENT	and\tagSENT_CONTENT	62.42\tagmetric	GLEU\tagmetric	on\tagSENT_CONTENT	JFLEG\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	becoming\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	system\tagSENT_CONTENT	reaching\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	GEC\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	.\tagSENT_END	BACKGROUND\tagSECTITLE_START	:\tagSECTITLE_CONTENT	NEURAL\tagSECTITLE_CONTENT	GRAMMATICAL\tagSECTITLE_CONTENT	ERROR\tagSECTITLE_CONTENT	CORRECTION\tagSECTITLE_END	As\tagSENT_START	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	NMT\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	atypical\tagSENT_CONTENT	neural\tagSENT_CONTENT	GEC\tagSENT_CONTENT	approach\tagSENT_CONTENT	uses\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	edit\tagSENT_CONTENT	a\tagSENT_CONTENT	raw\tagSENT_CONTENT	sentence\tagSENT_CONTENT	into\tagSENT_CONTENT	grammatical_error_correction\tagtask	it\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	,\tagSENT_CONTENT	as(a\tagSENT_CONTENT	)\tagSENT_CONTENT	shows\tagSENT_CONTENT	.\tagSENT_END	rand\tagSENT_START	x\tagSENT_CONTENT	c\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical_error_correction\tagtask	learns\tagSENT_CONTENT	a\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	mapping\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	c\tagSENT_CONTENT	|x\tagSENT_CONTENT	r\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	error\tagSENT_CONTENT	-\tagSENT_CONTENT	corrected\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	through\tagSENT_CONTENT	maximum\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	estimation\tagSENT_CONTENT	(\tagSENT_CONTENT	MLE\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	learns\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	Θ\tagSENT_CONTENT	crt\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	equation\tagSENT_CONTENT	:\tagSENT_END	3\tagSENT_START	FLUENCY\tagSENT_CONTENT	BOOST\tagSENT_CONTENT	LEARNING\tagSENT_CONTENT	Conventional\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagmetric	learn\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	only\tagSENT_CONTENT	from\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	BACK\tagSECTITLE_START	-\tagSECTITLE_CONTENT	BOOST\tagSECTITLE_CONTENT	LEARNING\tagSECTITLE_END	(\tagSENT_START	we\tagSENT_CONTENT	call\tagSENT_CONTENT	it\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	grammatical_error_correction\tagtask	 \tagSENT_CONTENT	model\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	a\tagSENT_CONTENT	fluent\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	less\tagSENT_CONTENT	fluent\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	errors\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	training\tagSENT_CONTENT	epochs\tagSENT_CONTENT	,\tagSENT_CONTENT	grammatical_error_correction\tagtask	will\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	learn\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	error\tagSENT_CONTENT	-\tagSENT_CONTENT	corrected\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	learn\tagSENT_CONTENT	from\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_END	is\tagSENT_START	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Scan\tagSENT_CONTENT	be\tagSENT_CONTENT	tentatively\tagSENT_CONTENT	considered\tagSENT_CONTENT	identical\tagSENT_CONTENT	to\tagSENT_CONTENT	S\tagSENT_END	SELF\tagSECTITLE_START	-\tagSECTITLE_CONTENT	BOOST\tagSECTITLE_CONTENT	LEARNING\tagSECTITLE_END	Unlike\tagSENT_START	back\tagSENT_CONTENT	-\tagSENT_CONTENT	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	an\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	disfluency\tagSENT_CONTENT	candidates\tagSENT_CONTENT	,\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	allows\tagSENT_CONTENT	grammatical_error_correction\tagtask	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	the\tagSENT_CONTENT	candidates\tagSENT_CONTENT	by\tagSENT_CONTENT	itself\tagSENT_CONTENT	.\tagSENT_END	6\tagSECTITLE_START	:\tagSECTITLE_END	7\tagSECTITLE_START	:\tagSECTITLE_END	8\tagSECTITLE_START	:\tagSECTITLE_END	10\tagSECTITLE_START	:\tagSECTITLE_END	S\tagSENT_START	←\tagSENT_CONTENT	S\tagSENT_CONTENT	∪\tagSENT_CONTENT	{\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	}\tagSENT_CONTENT	;\tagSENT_CONTENT	grammatical_error_correction\tagtask	x\tagSENT_START	c\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	considered\tagSENT_CONTENT	as\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	also\tagSENT_CONTENT	noteworthy\tagSENT_CONTENT	that\tagSENT_CONTENT	D\tagSENT_CONTENT	self\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	incrementally\tagSENT_CONTENT	expanded\tagSENT_CONTENT	because\tagSENT_CONTENT	grammatical_error_correction\tagtask	is\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	updated\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Algorithm\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	9\tagSECTITLE_START	:\tagSECTITLE_END	11\tagSECTITLE_START	:\tagSECTITLE_END	12\tagSECTITLE_START	:\tagSECTITLE_END	13\tagSECTITLE_START	:\tagSECTITLE_END	DUAL\tagSECTITLE_START	-\tagSECTITLE_CONTENT	BOOST\tagSECTITLE_CONTENT	LEARNING\tagSECTITLE_END	As\tagSENT_START	introduced\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	generate\tagSENT_CONTENT	disfluency\tagSENT_CONTENT	candidates\tagSENT_CONTENT	from\tagSENT_CONTENT	different\tagSENT_CONTENT	perspectives\tagSENT_CONTENT	to\tagSENT_CONTENT	create\tagSENT_CONTENT	more\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	to\tagSENT_CONTENT	benefit\tagSENT_CONTENT	training\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	Algorithm\tagSECTITLE_START	3\tagSECTITLE_CONTENT	Dual\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	boost\tagSECTITLE_CONTENT	learning\tagSECTITLE_END	6\tagSECTITLE_START	:\tagSECTITLE_END	Update\tagSENT_START	grammatical_error_correction\tagtask	7\tagSECTITLE_START	:\tagSECTITLE_END	10\tagSECTITLE_START	:\tagSECTITLE_END	13\tagSECTITLE_START	:\tagSECTITLE_END	15\tagSECTITLE_START	:\tagSECTITLE_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	grammatical_error_correction\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	dual\tagSENT_CONTENT	and\tagSENT_CONTENT	both\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	are\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	updated\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	improves\tagSENT_CONTENT	each\tagSENT_CONTENT	other\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	disfluency\tagSENT_CONTENT	candidates\tagSENT_CONTENT	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	benefit\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	error\tagSENT_CONTENT	correction\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	disfluency\tagSENT_CONTENT	candidates\tagSENT_CONTENT	created\tagSENT_CONTENT	by\tagSENT_CONTENT	error\tagSENT_CONTENT	correction\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	FLUENCY\tagSECTITLE_START	BOOST\tagSECTITLE_CONTENT	LEARNING\tagSECTITLE_CONTENT	WITH\tagSECTITLE_CONTENT	LARGE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	SCALE\tagSECTITLE_CONTENT	NATIVE\tagSECTITLE_CONTENT	DATA\tagSECTITLE_END	Our\tagSENT_START	proposed\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	strategies\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	easily\tagSENT_CONTENT	extended\tagSENT_CONTENT	to\tagSENT_CONTENT	utilize\tagSENT_CONTENT	massive\tagSENT_CONTENT	native\tagSENT_CONTENT	text\tagSENT_CONTENT	data\tagSENT_CONTENT	which\tagSENT_CONTENT	proved\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	useful\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagmetric	.\tagSENT_END	FLUENCY\tagSECTITLE_START	BOOST\tagSECTITLE_CONTENT	INFERENCE\tagSECTITLE_END	MULTI\tagSECTITLE_START	-\tagSECTITLE_CONTENT	ROUND\tagSECTITLE_CONTENT	ERROR\tagSECTITLE_CONTENT	CORRECTION\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	discuss\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	some\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	grammatical_error_correction\tagtask	usually\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	perfectly\tagSENT_CONTENT	corrected\tagSENT_CONTENT	through\tagSENT_CONTENT	normal\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	inference\tagSENT_CONTENT	which\tagSENT_CONTENT	makes\tagSENT_CONTENT	only\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	round\tagSENT_CONTENT	inference\tagSENT_CONTENT	.\tagSENT_END	grammatical_error_correction\tagtask	makes\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	left\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	well\tagSENT_CONTENT	complement\tagSENT_CONTENT	each\tagSENT_CONTENT	other\tagSENT_CONTENT	,\tagSENT_CONTENT	enabling\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	correct\tagSENT_CONTENT	more\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	errors\tagSENT_CONTENT	than\tagSENT_CONTENT	an\tagSENT_CONTENT	individual\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	ROUND\tagSECTITLE_START	-\tagSECTITLE_CONTENT	WAY\tagSECTITLE_CONTENT	ERROR\tagSECTITLE_CONTENT	CORRECTION\tagSECTITLE_END	Based\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	idea\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	further\tagSENT_CONTENT	propose\tagSENT_CONTENT	an\tagSENT_CONTENT	advanced\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	inference\tagSENT_CONTENT	approach\tagSENT_CONTENT	:\tagSENT_CONTENT	round\tagSENT_CONTENT	-\tagSENT_CONTENT	way\tagSENT_CONTENT	error\tagSENT_CONTENT	correction\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	motivation\tagSENT_CONTENT	of\tagSENT_CONTENT	grammatical_error_correction\tagtask	is\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	DATASET\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	EVALUATION\tagSECTITLE_END	Corpus\tagSECTITLE_START	#\tagSECTITLE_CONTENT	sent\tagSECTITLE_CONTENT	pair\tagSECTITLE_END	EXPERIMENTAL\tagSECTITLE_START	SETTING\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	7-layer\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	as\tagSENT_CONTENT	grammatical_error_correction\tagtask	and\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	have\tagSENT_CONTENT	proven\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	encoders\tagSENT_CONTENT	and\tagSENT_CONTENT	decoders\tagSENT_CONTENT	to\tagSENT_CONTENT	500\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	encoders\tagSENT_CONTENT	and\tagSENT_CONTENT	decoders\tagSENT_CONTENT	to\tagSENT_CONTENT	1,024\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	convolution\tagSENT_CONTENT	window\tagSENT_CONTENT	width\tagSENT_CONTENT	to\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	architecture\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	left\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	grammatical_error_correction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	7\tagSENT_CONTENT	one\tagSENT_CONTENT	except\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	decode\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	opposite\tagSENT_CONTENT	directions\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTAL\tagSECTITLE_START	RESULTS\tagSECTITLE_END	The\tagSENT_START	last\tagSENT_CONTENT	one\tagSENT_CONTENT	)\tagSENT_CONTENT	uses\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	To\tagSENT_START	better\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	inference\tagSENT_CONTENT	grammatical_error_correction\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	recall\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	error\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	left\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	in\tagSENT_CONTENT	CoNLL-2014\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	original\tagSENT_CONTENT	annotation\tagSENT_CONTENT	setting\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	we\tagSENT_CONTENT	use\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	errors\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	corrected\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	rightto\tagSENT_CONTENT	-\tagSENT_CONTENT	left\tagSENT_CONTENT	model\tagSENT_CONTENT	are\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	corrected\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	one\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	reflected\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	recall\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	most\tagSENT_CONTENT	error\tagSENT_CONTENT	types\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	Recently\tagSENT_START	,\tagSENT_CONTENT	many\tagSENT_CONTENT	novel\tagSENT_CONTENT	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagmetric	.\tagSENT_END	Unlike\tagSENT_START	the\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	only\tagSENT_CONTENT	with\tagSENT_CONTENT	grammatical_error_correction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	for\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	data\tagSENT_CONTENT	augmentation\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	training\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	some\tagSENT_CONTENT	related\tagSENT_CONTENT	studies\tagSENT_CONTENT	that\tagSENT_CONTENT	explore\tagSENT_CONTENT	artificial\tagSENT_CONTENT	error\tagSENT_CONTENT	generation\tagSENT_CONTENT	for\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	studies\tagSENT_CONTENT	on\tagSENT_CONTENT	GEC\tagmetric	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	much\tagSENT_CONTENT	research\tagSENT_CONTENT	on\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	and\tagSENT_CONTENT	GEC\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	Fluency\tagSENT_START	boost\tagSENT_CONTENT	learning\tagSENT_CONTENT	fully\tagSENT_CONTENT	exploits\tagSENT_CONTENT	grammatical_error_correction\tagtask	and\tagSENT_CONTENT	native\tagSENT_CONTENT	data\tagSENT_CONTENT	by\tagSENT_CONTENT	generating\tagSENT_CONTENT	diverse\tagSENT_CONTENT	error\tagSENT_CONTENT	-\tagSENT_CONTENT	corrected\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	benefits\tagSENT_CONTENT	model\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	base\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	fluency\tagSENT_CONTENT	boost\tagSENT_CONTENT	inference\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	the\tagSENT_CONTENT	characteristic\tagSENT_CONTENT	of\tagSENT_CONTENT	GEC\tagSENT_CONTENT	to\tagSENT_CONTENT	progressively\tagSENT_CONTENT	improve\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	's\tagSENT_CONTENT	fluency\tagSENT_CONTENT	through\tagSENT_CONTENT	round\tagSENT_CONTENT	-\tagSENT_CONTENT	way\tagSENT_CONTENT	correction\tagSENT_CONTENT	.\tagSENT_END	
N18-1127	title\tagSECTITLE_END	Modeling\tagSENT_START	Noisiness\tagSENT_CONTENT	to\tagSENT_CONTENT	Recognize\tagSENT_CONTENT	named_entity_recognition\tagtask	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Although\tagSENT_START	the\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	directly\tagSENT_CONTENT	comparable\tagSENT_CONTENT	because\tagSENT_CONTENT	they\tagSENT_CONTENT	consider\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	challenges\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	strong\tagSENT_CONTENT	evidence\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	NER\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	is\tagSENT_CONTENT	far\tagSENT_CONTENT	from\tagSENT_CONTENT	being\tagSENT_CONTENT	solved\tagSENT_CONTENT	.\tagSENT_END	49\tagSECTITLE_START	%\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	Tjong\tagSECTITLE_CONTENT	Kim\tagSECTITLE_CONTENT	Sang\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	De\tagSECTITLE_CONTENT	Meulder\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2003\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	CoNLL\tagSECTITLE_END	Based\tagSENT_START	on\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	seen\tagSENT_CONTENT	that\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	networks\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Methods\tagSECTITLE_END	a\tagSENT_START	fusion\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	features\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	multitask\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	whose\tagSENT_CONTENT	main\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	how\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	contextualized\tagSENT_CONTENT	with\tagSENT_CONTENT	and\tagSENT_CONTENT	without\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Feature\tagSECTITLE_START	representation\tagSECTITLE_END	Even\tagSENT_START	though\tagSENT_CONTENT	the\tagSENT_CONTENT	spellings\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	phrases\tagSENT_CONTENT	are\tagSENT_CONTENT	significantly\tagSENT_CONTENT	different\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	phonological\tagSENT_CONTENT	(\tagSENT_CONTENT	articulatory\tagSENT_CONTENT	)\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	those\tagSENT_CONTENT	phrases\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Models\tagSECTITLE_END	That\tagSENT_START	is\tagSENT_CONTENT	,\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	NE\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	is\tagSENT_CONTENT	B\tagSENT_CONTENT	,\tagSENT_CONTENT	I\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	O\tagSENT_CONTENT	regardless\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	We\tagSENT_START	formalize\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	let\tagSENT_CONTENT	X\tagSENT_CONTENT	=\tagSENT_END	At\tagSENT_START	this\tagSENT_CONTENT	point\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	share\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Following\tagSENT_START	Ma\tagSENT_CONTENT	and\tagSENT_CONTENT	Hovy\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	formalize\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CRF\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	let\tagSENT_CONTENT	y\tagSENT_CONTENT	=\tagSENT_END	Where\tagSENT_START	Φ\tagSENT_CONTENT	is\tagSENT_CONTENT	named_entity_recognition\tagtask	that\tagSENT_CONTENT	codifies\tagSENT_CONTENT	the\tagSENT_CONTENT	interactions\tagSENT_CONTENT	between\tagSENT_CONTENT	consecutive\tagSENT_CONTENT	labels\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	t\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_CONTENT	t+1\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	interactions\tagSENT_CONTENT	between\tagSENT_CONTENT	labels\tagSENT_CONTENT	and\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	represented\tagSENT_CONTENT	by\tagSENT_CONTENT	z\tagSENT_CONTENT	t\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CRF\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	described\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	details\tagSECTITLE_END	The\tagSENT_START	models\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	trained\tagSENT_CONTENT	using\tagSENT_CONTENT	weighted\tagSENT_CONTENT	classes\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	forces\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	pay\tagSENT_CONTENT	named_entity_recognition\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	labels\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	less\tagSENT_CONTENT	frequent\tagSENT_CONTENT	.\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	defined\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	and\tagSENT_CONTENT	phonological\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	level\tagSENT_CONTENT	uses\tagSENT_CONTENT	64\tagSENT_CONTENT	units\tagSENT_CONTENT	per\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	adds\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	128\tagSENT_CONTENT	units\tagSENT_CONTENT	.\tagSENT_END	Datasets\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	results\tagSECTITLE_END	WNUT\tagSECTITLE_START	2017\tagSECTITLE_CONTENT	experiments\tagSECTITLE_END	shows\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	stacked\tagSENT_CONTENT	system\tagSENT_CONTENT	has\tagSENT_CONTENT	named_entity_recognition\tagtask	than\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	its\tagSENT_CONTENT	recall\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	named_entity_recognition\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	NER\tagSENT_CONTENT	categorization\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	segmentation\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	results\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	explained\tagSENT_CONTENT	by\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	emerging\tagSENT_CONTENT	and\tagSENT_CONTENT	rare\tagSENT_CONTENT	properties\tagSENT_CONTENT	are\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	with\tagSENT_CONTENT	external\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	CoNLL\tagSECTITLE_START	2003\tagSECTITLE_CONTENT	evaluation\tagSECTITLE_END	Analysis\tagSECTITLE_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	They\tagSENT_START	reported\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tools\tagSENT_CONTENT	were\tagSENT_CONTENT	not\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	adapting\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	showing\tagSENT_CONTENT	a\tagSENT_CONTENT	drop\tagSENT_CONTENT	in\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	around\tagSENT_CONTENT	40\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	metric\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	weighted\tagSENT_CONTENT	classes\tagSENT_CONTENT	force\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	pay\tagSENT_CONTENT	named_entity_recognition\tagtask	on\tagSENT_CONTENT	skewed\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	
1706.03762	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	propose\tagSENT_CONTENT	anew\tagSENT_CONTENT	simple\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	based\tagSENT_CONTENT	solely\tagSENT_CONTENT	on\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	,\tagSENT_CONTENT	dispensing\tagSENT_CONTENT	with\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	and\tagSENT_CONTENT	convolutions\tagSENT_CONTENT	entirely\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Recurrent\tagSENT_START	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	long\tagSENT_CONTENT	short\tagSENT_CONTENT	-\tagSENT_CONTENT	term\tagSENT_CONTENT	memory\tagSENT_CONTENT	and\tagSENT_CONTENT	gated\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	in\tagSENT_CONTENT	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	firmly\tagSENT_CONTENT	established\tagSENT_CONTENT	as\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	approaches\tagSENT_CONTENT	in\tagSENT_CONTENT	sequence\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	transduction\tagSENT_CONTENT	problems\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	This\tagSENT_START	inherently\tagSENT_CONTENT	sequential\tagSENT_CONTENT	nature\tagSENT_CONTENT	precludes\tagSENT_CONTENT	machine_translation\tagtask	within\tagSENT_CONTENT	training\tagSENT_CONTENT	examples\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	becomes\tagSENT_CONTENT	critical\tagSENT_CONTENT	at\tagSENT_CONTENT	longer\tagSENT_CONTENT	sequence\tagSENT_CONTENT	lengths\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	memory\tagSENT_CONTENT	constraints\tagSENT_CONTENT	limit\tagSENT_CONTENT	batching\tagSENT_CONTENT	across\tagSENT_CONTENT	examples\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSENT_START	mechanisms\tagSENT_CONTENT	have\tagSENT_CONTENT	become\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	compelling\tagSENT_CONTENT	sequence\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	transduction\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	various\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	allowing\tagSENT_CONTENT	modeling\tagSENT_CONTENT	of\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	without\tagSENT_CONTENT	regard\tagSENT_CONTENT	to\tagSENT_CONTENT	their\tagSENT_CONTENT	distance\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	or\tagSENT_CONTENT	output\tagSENT_CONTENT	sequences\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	eschewing\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	and\tagSENT_CONTENT	instead\tagSENT_CONTENT	relying\tagSENT_CONTENT	entirely\tagSENT_CONTENT	on\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	draw\tagSENT_CONTENT	global\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	between\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	The\tagSENT_START	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	reducing\tagSENT_CONTENT	sequential\tagSENT_CONTENT	computation\tagSENT_CONTENT	also\tagSENT_CONTENT	forms\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Extended\tagSENT_CONTENT	Neural\tagSENT_CONTENT	GPU\tagSENT_CONTENT	,\tagSENT_CONTENT	ByteNet\tagSENT_CONTENT	and\tagSENT_CONTENT	ConvS2S\tagSENT_CONTENT	,\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	use\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	as\tagSENT_CONTENT	basic\tagSENT_CONTENT	building\tagSENT_CONTENT	block\tagSENT_CONTENT	,\tagSENT_CONTENT	computing\tagSENT_CONTENT	hidden\tagSENT_CONTENT	representations\tagSENT_CONTENT	in\tagSENT_CONTENT	parallel\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	positions\tagSENT_CONTENT	.\tagSENT_END	Self\tagSENT_START	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	called\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	relating\tagSENT_CONTENT	different\tagSENT_CONTENT	positions\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	sequence\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	transduction\tagSENT_CONTENT	model\tagSENT_CONTENT	relying\tagSENT_CONTENT	entirely\tagSENT_CONTENT	on\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	without\tagSENT_CONTENT	using\tagSENT_CONTENT	sequencealigned\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	or\tagSENT_CONTENT	convolution\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Architecture\tagSECTITLE_END	Here\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	maps\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	symbol\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	n\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	z\tagSENT_CONTENT	=\tagSENT_CONTENT	(\tagSENT_CONTENT	z\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	,\tagSENT_CONTENT	z\tagSENT_CONTENT	n\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	machine_translation\tagtask	follows\tagSENT_CONTENT	this\tagSENT_CONTENT	overall\tagSENT_CONTENT	architecture\tagSENT_CONTENT	using\tagSENT_CONTENT	stacked\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	and\tagSENT_CONTENT	point\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	,\tagSENT_CONTENT	fully\tagSENT_CONTENT	connected\tagSENT_CONTENT	layers\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	decoder\tagSENT_CONTENT	,\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	halves\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Encoder\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_CONTENT	Stacks\tagSECTITLE_END	We\tagSENT_START	employ\tagSENT_CONTENT	a\tagSENT_CONTENT	residual\tagSENT_CONTENT	connection\tagSENT_CONTENT	around\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	layers\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	encoder\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	inserts\tagSENT_CONTENT	a\tagSENT_CONTENT	third\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	performs\tagSENT_CONTENT	machine_translation\tagtask	over\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	stack\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSECTITLE_END	Scaled\tagSECTITLE_START	Dot\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Product\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	The\tagSENT_START	two\tagSENT_CONTENT	most\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	attention\tagSENT_CONTENT	functions\tagSENT_CONTENT	are\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	dot\tagSENT_CONTENT	-\tagSENT_CONTENT	product\tagSENT_CONTENT	(\tagSENT_CONTENT	multiplicative\tagSENT_CONTENT	)\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	machine_translation\tagtask	computes\tagSENT_CONTENT	the\tagSENT_CONTENT	compatibility\tagSENT_CONTENT	function\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	suspect\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	large\tagSENT_CONTENT	values\tagSENT_CONTENT	of\tagSENT_CONTENT	d\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	dot\tagSENT_CONTENT	products\tagSENT_CONTENT	grow\tagSENT_CONTENT	large\tagSENT_CONTENT	in\tagSENT_CONTENT	magnitude\tagSENT_CONTENT	,\tagSENT_CONTENT	pushing\tagSENT_CONTENT	machine_translation\tagtask	into\tagSENT_CONTENT	regions\tagSENT_CONTENT	where\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	extremely\tagSENT_CONTENT	small\tagSENT_CONTENT	gradients\tagSENT_CONTENT	4\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Head\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Applications\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	our\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	machine_translation\tagtask	uses\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	head\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	three\tagSENT_CONTENT	different\tagSENT_CONTENT	ways\tagSENT_CONTENT	:\tagSENT_END	machine_translation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	can\tagSENT_CONTENT	attend\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	positions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	layer\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	Similarly\tagSENT_CONTENT	,\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	allow\tagSENT_CONTENT	machine_translation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	positions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	and\tagSENT_CONTENT	including\tagSENT_CONTENT	that\tagSENT_CONTENT	position\tagSENT_CONTENT	.\tagSENT_END	Position\tagSECTITLE_START	-\tagSECTITLE_CONTENT	wise\tagSECTITLE_CONTENT	Feed\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Forward\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	attention\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	layers\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	decoder\tagSENT_CONTENT	contains\tagSENT_CONTENT	a\tagSENT_CONTENT	fully\tagSENT_CONTENT	connected\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	machine_translation\tagtask	separately\tagSENT_CONTENT	and\tagSENT_CONTENT	identically\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	machine_translation\tagtask	are\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	across\tagSENT_CONTENT	different\tagSENT_CONTENT	positions\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	use\tagSENT_CONTENT	different\tagSENT_CONTENT	parameters\tagSENT_CONTENT	from\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	Embeddings\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Softmax\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	use\tagSENT_CONTENT	machine_translation\tagtask	and\tagSENT_CONTENT	softmax\tagSENT_CONTENT	function\tagSENT_CONTENT	to\tagSENT_CONTENT	convert\tagSENT_CONTENT	the\tagSENT_CONTENT	decoder\tagSENT_CONTENT	output\tagSENT_CONTENT	to\tagSENT_CONTENT	predicted\tagSENT_CONTENT	next\tagSENT_CONTENT	-\tagSENT_CONTENT	token\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	.\tagSENT_END	Positional\tagSECTITLE_START	Encoding\tagSECTITLE_END	Since\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	contains\tagSENT_CONTENT	no\tagSENT_CONTENT	recurrence\tagSENT_CONTENT	and\tagSENT_CONTENT	no\tagSENT_CONTENT	convolution\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	order\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	must\tagSENT_CONTENT	inject\tagSENT_CONTENT	machine_translation\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	or\tagSENT_CONTENT	absolute\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	:\tagSENT_CONTENT	Maximum\tagSENT_CONTENT	path\tagSENT_CONTENT	lengths\tagSENT_CONTENT	,\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	complexity\tagSENT_CONTENT	and\tagSENT_CONTENT	minimum\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	sequential\tagSENT_CONTENT	operations\tagSENT_CONTENT	for\tagSENT_CONTENT	different\tagSENT_CONTENT	layer\tagSENT_CONTENT	types\tagSENT_CONTENT	.\tagSENT_END	Layer\tagSECTITLE_START	Type\tagSECTITLE_CONTENT	Complexity\tagSECTITLE_CONTENT	per\tagSECTITLE_CONTENT	Layer\tagSECTITLE_CONTENT	Sequential\tagSECTITLE_CONTENT	Maximum\tagSECTITLE_CONTENT	Path\tagSECTITLE_CONTENT	Length\tagSECTITLE_END	where\tagSENT_START	pos\tagSENT_CONTENT	is\tagSENT_CONTENT	machine_translation\tagtask	We\tagSENT_START	also\tagSENT_CONTENT	experimented\tagSENT_CONTENT	with\tagSENT_CONTENT	using\tagSENT_CONTENT	learned\tagSENT_CONTENT	positional\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	instead\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	machine_translation\tagtask	produced\tagSENT_CONTENT	nearly\tagSENT_CONTENT	identical\tagSENT_CONTENT	results\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	row\tagSENT_CONTENT	(\tagSENT_CONTENT	E\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Why\tagSECTITLE_START	Self\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	In\tagSENT_START	machine_translation\tagtask	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	various\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	and\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	layers\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	mapping\tagSENT_CONTENT	one\tagSENT_CONTENT	variable\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	symbol\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	n\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	another\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	equal\tagSENT_CONTENT	length\tagSENT_CONTENT	(\tagSENT_CONTENT	z\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	...\tagSENT_CONTENT	,\tagSENT_CONTENT	z\tagSENT_CONTENT	n\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	xi\tagSENT_CONTENT	,\tagSENT_CONTENT	z\tagSENT_END	Learning\tagSENT_START	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	challenge\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	In\tagSENT_START	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	computational\tagSENT_CONTENT	complexity\tagSENT_CONTENT	,\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	are\tagSENT_CONTENT	faster\tagSENT_CONTENT	than\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	layers\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	length\tagSENT_CONTENT	n\tagSENT_CONTENT	is\tagSENT_CONTENT	smaller\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	d\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	most\tagSENT_CONTENT	often\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	with\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representations\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	piece\tagSENT_CONTENT	and\tagSENT_CONTENT	byte\tagSENT_CONTENT	-\tagSENT_CONTENT	pair\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Even\tagSENT_START	with\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	n\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	separable\tagSENT_CONTENT	convolution\tagSENT_CONTENT	is\tagSENT_CONTENT	equal\tagSENT_CONTENT	to\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	point\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	approach\tagSENT_CONTENT	we\tagSENT_CONTENT	take\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_END	machine_translation\tagtask	describes\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	regime\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Data\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Batching\tagSECTITLE_END	constituency_parsing\tagtask	were\tagSENT_CONTENT	batched\tagSENT_CONTENT	together\tagSENT_CONTENT	by\tagSENT_CONTENT	approximate\tagSENT_CONTENT	sequence\tagSENT_CONTENT	length\tagSENT_CONTENT	.\tagSENT_END	machine_translation\tagtask	contained\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	containing\tagSENT_CONTENT	approximately\tagSENT_CONTENT	25000\tagSENT_CONTENT	source\tagSENT_CONTENT	tokens\tagSENT_CONTENT	and\tagSENT_CONTENT	25000\tagSENT_CONTENT	target\tagSENT_CONTENT	tokens\tagSENT_CONTENT	.\tagSENT_END	Hardware\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Schedule\tagSECTITLE_END	For\tagSENT_START	our\tagSENT_CONTENT	base\tagSENT_CONTENT	models\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	described\tagSENT_CONTENT	throughout\tagSENT_CONTENT	the\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	took\tagSENT_CONTENT	about\tagSENT_CONTENT	0.4\tagSENT_CONTENT	seconds\tagSENT_CONTENT	.\tagSENT_END	Optimizer\tagSECTITLE_END	Regularization\tagSECTITLE_END	machine_translation\tagtask	achieves\tagSENT_CONTENT	better\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	scores\tagSENT_CONTENT	than\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	German\tagSENT_CONTENT	and\tagSENT_CONTENT	English\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	French\tagSENT_CONTENT	newstest2014\tagSENT_CONTENT	tests\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	fraction\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	cost\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Results\tagSECTITLE_END	Machine\tagSECTITLE_START	Translation\tagSECTITLE_END	Even\tagSENT_START	our\tagSENT_CONTENT	base\tagSENT_CONTENT	model\tagSENT_CONTENT	surpasses\tagSENT_CONTENT	all\tagSENT_CONTENT	previously\tagSENT_CONTENT	published\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	ensembles\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	competitive\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	summarizes\tagSENT_START	our\tagSENT_CONTENT	results\tagSENT_CONTENT	and\tagSENT_CONTENT	compares\tagSENT_CONTENT	machine_translation\tagtask	and\tagSENT_CONTENT	training\tagSENT_CONTENT	costs\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	model\tagSENT_CONTENT	architectures\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Variations\tagSECTITLE_END	To\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	components\tagSENT_CONTENT	of\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	varied\tagSENT_CONTENT	our\tagSENT_CONTENT	base\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	different\tagSENT_CONTENT	ways\tagSENT_CONTENT	,\tagSENT_CONTENT	measuring\tagSENT_CONTENT	the\tagSENT_CONTENT	change\tagSENT_CONTENT	in\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	English\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	German\tagSENT_CONTENT	translation\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	newstest2013\tagSENT_CONTENT	.\tagSENT_END	English\tagSECTITLE_START	Constituency\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	To\tagSENT_START	evaluate\tagSENT_CONTENT	if\tagSENT_CONTENT	machine_translation\tagtask	can\tagSENT_CONTENT	generalize\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	we\tagSENT_CONTENT	performed\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	English\tagSENT_CONTENT	constituency\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	performed\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	experiments\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	dropout\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	attention\tagSENT_CONTENT	and\tagSENT_CONTENT	residual\tagSENT_CONTENT	(\tagSENT_CONTENT	section\tagSENT_CONTENT	5.4\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	learning\tagSENT_CONTENT	rates\tagSENT_CONTENT	and\tagSENT_CONTENT	beam\tagSENT_CONTENT	size\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Section\tagSENT_CONTENT	22\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	all\tagSENT_CONTENT	other\tagSENT_CONTENT	parameters\tagSENT_CONTENT	remained\tagSENT_CONTENT	unchanged\tagSENT_CONTENT	from\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	In\tagSENT_START	machine_translation\tagtask	to\tagSENT_CONTENT	RNN\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	BerkeleyParser\tagSENT_CONTENT	even\tagSENT_CONTENT	when\tagSENT_CONTENT	training\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	40\tagSENT_CONTENT	K\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	presented\tagSENT_CONTENT	machine_translation\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	sequence\tagSENT_CONTENT	transduction\tagSENT_CONTENT	model\tagSENT_CONTENT	based\tagSENT_CONTENT	entirely\tagSENT_CONTENT	on\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	replacing\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	layers\tagSENT_CONTENT	most\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	encoder\tagSENT_CONTENT	-\tagSENT_CONTENT	decoder\tagSENT_CONTENT	architectures\tagSENT_CONTENT	with\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	headed\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	significantly\tagSENT_CONTENT	faster\tagSENT_CONTENT	than\tagSENT_CONTENT	architectures\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	or\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	extend\tagSENT_CONTENT	machine_translation\tagtask	to\tagSENT_CONTENT	problems\tagSENT_CONTENT	involving\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	modalities\tagSENT_CONTENT	other\tagSENT_CONTENT	than\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	local\tagSENT_CONTENT	,\tagSENT_CONTENT	restricted\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	to\tagSENT_CONTENT	efficiently\tagSENT_CONTENT	handle\tagSENT_CONTENT	large\tagSENT_CONTENT	inputs\tagSENT_CONTENT	and\tagSENT_CONTENT	outputs\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	images\tagSENT_CONTENT	,\tagSENT_CONTENT	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	video\tagSENT_CONTENT	.\tagSENT_END	
1711.00106	title\tagSECTITLE_END	DCN+\tagSENT_START	:\tagSENT_CONTENT	MIXED\tagSENT_CONTENT	OBJECTIVE\tagSENT_CONTENT	AND\tagSENT_CONTENT	DEEP\tagSENT_CONTENT	RESIDUAL\tagSENT_CONTENT	COATTENTION\tagSENT_CONTENT	FOR\tagSENT_CONTENT	question_answering\tagtask	abstract\tagSECTITLE_END	Traditional\tagSENT_START	models\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	optimize\tagSENT_CONTENT	using\tagSENT_CONTENT	cross\tagSENT_CONTENT	entropy\tagSENT_CONTENT	loss\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	encourages\tagSENT_CONTENT	exact\tagSENT_CONTENT	answers\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	penalizing\tagSENT_CONTENT	nearby\tagSENT_CONTENT	or\tagSENT_CONTENT	overlapping\tagSENT_CONTENT	answers\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	equally\tagSENT_CONTENT	accurate\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	In\tagSENT_START	question_answering\tagtask	,\tagSENT_CONTENT	aground\tagSENT_CONTENT	truth\tagSENT_CONTENT	answer\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	supervise\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	start\tagSENT_CONTENT	and\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	position\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	show\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	stacking\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	helps\tagSENT_CONTENT	model\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	range\tagSENT_END	The\tagSENT_START	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	deep\tagSENT_CONTENT	residual\tagSENT_CONTENT	coattention\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	mixed\tagSENT_CONTENT	objective\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	higher\tagSENT_CONTENT	performance\tagSENT_CONTENT	across\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	question\tagSENT_CONTENT	lengths\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	lengths\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	Question\tagSENT_CONTENT	Answering\tagSENT_CONTENT	Dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	DCN\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	DCN+\tagSECTITLE_END	We\tagSENT_START	consider\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	are\tagSENT_CONTENT	asked\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	DEEP\tagSECTITLE_START	RESIDUAL\tagSECTITLE_CONTENT	COATTENTION\tagSECTITLE_CONTENT	ENCODER\tagSECTITLE_END	Suppose\tagSENT_START	we\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	of\tagSENT_CONTENT	m\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	of\tagSENT_CONTENT	n\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Like\tagSENT_START	the\tagSENT_CONTENT	original\tagSENT_CONTENT	DCN\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	transform\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	We\tagSENT_START	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	affinity\tagSENT_CONTENT	matrix\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_END	The\tagSENT_START	document\tagSENT_CONTENT	summary\tagSENT_CONTENT	vectors\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	computed\tagSENT_CONTENT	as\tagSENT_END	MIXED\tagSECTITLE_START	OBJECTIVE\tagSECTITLE_CONTENT	USING\tagSECTITLE_CONTENT	SELF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	CRITICAL\tagSECTITLE_CONTENT	POLICY\tagSECTITLE_CONTENT	LEARNING\tagSECTITLE_END	The\tagSENT_START	DCN\tagSENT_CONTENT	produces\tagSENT_CONTENT	a\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	a\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	position\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	answering\tagSENT_CONTENT	task\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	to\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagSENT_CONTENT	F1\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	and\tagSENT_CONTENT	ans\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	denote\tagSENT_CONTENT	question_answering\tagtask	retrieved\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	point\tagSENT_CONTENT	sand\tagSENT_CONTENT	endpoint\tagSENT_CONTENT	e.\tagSENT_END	the\tagSENT_START	former\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	difficult\tagSENT_CONTENT	for\tagSENT_CONTENT	policy\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	converge\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	large\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	documents\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	questions\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	RESULTS\tagSECTITLE_END	shows\tagSENT_START	the\tagSENT_CONTENT	consistent\tagSENT_CONTENT	performance\tagSENT_CONTENT	gain\tagSENT_CONTENT	of\tagSENT_CONTENT	DCN+\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	across\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	question\tagSENT_CONTENT	lengths\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	lengths\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	EM\tagSECTITLE_END	∆EM\tagmetric	F1\tagSENT_CONTENT	∆F1\tagSENT_END	Ablation\tagSENT_START	study\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	SQuAD\tagdataset	.\tagSENT_CONTENT	 \tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	"\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	tape\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	tape\tagSENT_CONTENT	"\tagSENT_CONTENT	both\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	that\tagSENT_CONTENT	provides\tagSENT_CONTENT	provenance\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	Neural\tagSENT_START	models\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	.\tagSENT_END	introduced\tagSENT_START	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	conversational\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	using\tagSENT_CONTENT	policy\tagSENT_CONTENT	gradient\tagSENT_CONTENT	methods\tagSENT_CONTENT	,\tagSENT_CONTENT	whose\tagSENT_CONTENT	reward\tagSENT_CONTENT	function\tagSENT_CONTENT	consisted\tagSENT_CONTENT	of\tagSENT_CONTENT	heuristics\tagSENT_CONTENT	for\tagSENT_CONTENT	ease\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	information\tagSENT_CONTENT	flow\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	coherence\tagSENT_CONTENT	.\tagSENT_END	
N16-1012	title\tagSECTITLE_END	summarization\tagtask	with\tagSENT_CONTENT	Attentive\tagSENT_CONTENT	Recurrent\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Networks\tagSENT_END	abstract\tagSECTITLE_END	i\tagSENT_START	ve\tagSENT_CONTENT	summarization\tagtask	generates\tagSENT_CONTENT	a\tagSENT_CONTENT	shorter\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	sentence\tagSENT_CONTENT	while\tagSENT_CONTENT	attempting\tagSENT_CONTENT	to\tagSENT_CONTENT	preserve\tagSENT_CONTENT	its\tagSENT_CONTENT	meaning\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Generating\tagSENT_START	a\tagSENT_CONTENT	condensed\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	while\tagSENT_CONTENT	preserving\tagSENT_CONTENT	its\tagSENT_CONTENT	meaning\tagSENT_CONTENT	is\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	The\tagSENT_START	main\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	conditional\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	93\tagSECTITLE_END	While\tagSENT_START	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	body\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	for\tagSENT_CONTENT	generating\tagSENT_CONTENT	extractive\tagSENT_CONTENT	summaries\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	much\tagSENT_CONTENT	less\tagSENT_CONTENT	research\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Attentive\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	Recurrent\tagSECTITLE_START	Decoder\tagSECTITLE_END	Attentive\tagSECTITLE_START	Encoder\tagSECTITLE_END	In\tagSENT_START	summarization\tagtask	the\tagSENT_CONTENT	position\tagSENT_CONTENT	i\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	xi\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	learnable\tagSENT_CONTENT	embedding\tagSENT_END	Training\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Generation\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	Datasets\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	Our\tagSENT_START	models\tagSENT_CONTENT	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	annotated\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	only\tagSENT_CONTENT	the\tagSENT_CONTENT	annotations\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	separation\tagSENT_CONTENT	while\tagSENT_CONTENT	discarding\tagSENT_CONTENT	other\tagSENT_CONTENT	annotations\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	tags\tagSENT_CONTENT	and\tagSENT_CONTENT	parses\tagSENT_CONTENT	.\tagSENT_END	Architectural\tagSECTITLE_START	Choices\tagSECTITLE_END	To\tagSENT_START	optimize\tagSENT_CONTENT	our\tagSENT_CONTENT	loss\tagSENT_CONTENT	(\tagSENT_CONTENT	summarization\tagtask	5\tagSENT_CONTENT	)\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	gradient\tagSENT_CONTENT	descent\tagSENT_CONTENT	with\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	32\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Perplexity\tagSECTITLE_END	Convolutional\tagSECTITLE_START	(\tagSECTITLE_CONTENT	TDNN\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	35.9\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	ABS\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	27.1\tagSECTITLE_CONTENT	RAS\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Elman\tagSECTITLE_END	We\tagSENT_START	chose\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	grid\tagSENT_CONTENT	search\tagSENT_CONTENT	and\tagSENT_CONTENT	picked\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	which\tagSENT_CONTENT	gave\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	set\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	then\tagSENT_CONTENT	pick\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	best\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	it\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagSENT_CONTENT	F1-score\tagSENT_CONTENT	of\tagSENT_CONTENT	ROUGE-1\tagmetric	,\tagSENT_CONTENT	ROUGE-2\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	all\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	DUC-2004\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	recall\tagmetric	ROUGE\tagmetric	as\tagSENT_CONTENT	is\tagSENT_CONTENT	customary\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	in\tagSENT_CONTENT	we\tagSENT_CONTENT	highlight\tagSENT_CONTENT	anecdotal\tagSENT_CONTENT	examples\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	RAS\tagSENT_CONTENT	-\tagSENT_CONTENT	Elman\tagSENT_CONTENT	system\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Gigaword\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	Sentence\tagSENT_CONTENT	4\tagSENT_CONTENT	the\tagSENT_CONTENT	RAS\tagSENT_CONTENT	model\tagSENT_CONTENT	mistakes\tagSENT_CONTENT	the\tagSENT_CONTENT	content\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	relative\tagSENT_CONTENT	clause\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	verb\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	opposite\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	extend\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	(\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	
1709.07432	title\tagSECTITLE_END	DYNAMIC\tagSENT_START	EVALUATION\tagSENT_CONTENT	OF\tagSENT_CONTENT	language_modeling\tagtask	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	methodology\tagSENT_CONTENT	for\tagSENT_CONTENT	using\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Sequence\tagSENT_START	generation\tagSENT_CONTENT	and\tagSENT_CONTENT	prediction\tagSENT_CONTENT	tasks\tagSENT_CONTENT	span\tagSENT_CONTENT	language_modeling\tagtask	of\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	ranging\tagSENT_CONTENT	from\tagSENT_CONTENT	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	language\tagSENT_CONTENT	modelling\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	general\tagSENT_CONTENT	timeseries\tagSENT_CONTENT	prediction\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	paper\tagSENT_CONTENT	concerns\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	candidate\tagSENT_CONTENT	solution\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagmetric	problem\tagmetric	.\tagSENT_END	MOTIVATION\tagSECTITLE_END	language_modeling\tagtask	can\tagSENT_CONTENT	assign\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	to\tagSENT_CONTENT	sequences\tagSENT_CONTENT	by\tagSENT_CONTENT	modelling\tagSENT_CONTENT	each\tagSENT_CONTENT	term\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	factorization\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	product\tagSENT_CONTENT	rule\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	adapting\tagSENT_CONTENT	the\tagmetric	model\tagmetric	parameters\tagmetric	learned\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	θ\tagSENT_CONTENT	g\tagSENT_CONTENT	is\tagSENT_CONTENT	justified\tagSENT_CONTENT	.\tagSENT_END	DYNAMIC\tagSECTITLE_START	EVALUATION\tagSECTITLE_END	Dynamic\tagSENT_START	evaluation\tagSENT_CONTENT	methods\tagSENT_CONTENT	continuously\tagSENT_CONTENT	adapt\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θ\tagSENT_CONTENT	g\tagSENT_CONTENT	,\tagSENT_CONTENT	learned\tagSENT_CONTENT	at\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	during\tagSENT_CONTENT	evaluation\tagmetric	.\tagSENT_END	The\tagSENT_START	initial\tagSENT_CONTENT	adapted\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θ\tagSENT_CONTENT	0\tagSENT_CONTENT	l\tagSENT_CONTENT	are\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	θ\tagSENT_CONTENT	g\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	the\tagmetric	probability\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	segment\tagSENT_CONTENT	,\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	s\tagSENT_CONTENT	1\tagSENT_END	As\tagSENT_START	in\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	only\tagSENT_CONTENT	conditions\tagSENT_CONTENT	on\tagSENT_CONTENT	sequence\tagSENT_CONTENT	elements\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	already\tagSENT_CONTENT	predicted\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	so\tagSENT_CONTENT	evaluates\tagSENT_CONTENT	a\tagSENT_CONTENT	valid\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	probability\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	BACKGROUND\tagSECTITLE_END	RELATED\tagSECTITLE_START	APPROACHES\tagSECTITLE_END	language_modeling\tagtask	was\tagSENT_CONTENT	first\tagSENT_CONTENT	considered\tagSENT_CONTENT	for\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	,\tagSENT_CONTENT	adapting\tagSENT_CONTENT	to\tagSENT_CONTENT	recent\tagSENT_CONTENT	history\tagSENT_CONTENT	via\tagSENT_CONTENT	caching\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	language_modeling\tagtask	learns\tagSENT_CONTENT	a\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	parametric\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	fly\tagSENT_CONTENT	attest\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	allows\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	adapt\tagSENT_CONTENT	to\tagSENT_CONTENT	recent\tagSENT_CONTENT	observations\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	e\tagSENT_CONTENT	(\tagSENT_CONTENT	xi+1\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	language_modeling\tagtask	of\tagSENT_CONTENT	x\tagSENT_CONTENT	i+1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ω\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	scaling\tagSENT_CONTENT	parameter\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	neural\tagSENT_CONTENT	cache\tagSENT_CONTENT	closely\tagSENT_CONTENT	relates\tagSENT_CONTENT	to\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	both\tagSENT_CONTENT	methods\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	added\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	for\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	attest\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	This\tagmetric	capability\tagmetric	is\tagSENT_CONTENT	critical\tagSENT_CONTENT	for\tagSENT_CONTENT	adapting\tagSENT_CONTENT	to\tagSENT_CONTENT	sequences\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	element\tagSENT_CONTENT	has\tagSENT_CONTENT	very\tagSENT_CONTENT	little\tagSENT_CONTENT	independent\tagSENT_CONTENT	meaning\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	character\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	modelling\tagSENT_CONTENT	.\tagSENT_END	DYNAMIC\tagSECTITLE_START	EVALUATION\tagSECTITLE_CONTENT	IN\tagSECTITLE_CONTENT	NEURAL\tagSECTITLE_CONTENT	NETWORKS\tagSECTITLE_END	Dynamic\tagSENT_START	evaluation\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	was\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	UPDATE\tagSECTITLE_START	RULE\tagSECTITLE_CONTENT	METHODOLOGY\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	DYNAMIC\tagSECTITLE_CONTENT	EVALUATION\tagSECTITLE_END	This\tagSENT_START	change\tagSENT_CONTENT	provides\tagSENT_CONTENT	more\tagSENT_CONTENT	accurate\tagSENT_CONTENT	gradient\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	computational\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	of\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagmetric	update\tagmetric	rule\tagmetric	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	much\tagSENT_CONTENT	less\tagSENT_CONTENT	often\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	a\tagSENT_CONTENT	global\tagSENT_CONTENT	decay\tagSENT_CONTENT	prior\tagSENT_CONTENT	to\tagSENT_CONTENT	bias\tagSENT_CONTENT	language_modeling\tagtask	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	parameters\tagSENT_CONTENT	θ\tagSENT_CONTENT	g\tagSENT_CONTENT	learned\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	update\tagmetric	rule\tagmetric	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	call\tagSENT_CONTENT	RMS\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	global\tagSENT_CONTENT	prior\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_END	where\tagSENT_START	is\tagSENT_CONTENT	a\tagmetric	stabilization\tagmetric	parameter\tagmetric	.\tagSENT_END	Applying\tagSENT_START	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	to\tagSENT_CONTENT	M\tagSENT_CONTENT	avoids\tagSENT_CONTENT	the\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagmetric	original\tagmetric	parameters\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	,\tagSENT_CONTENT	reduces\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	parameters\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	makes\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batching\tagSENT_CONTENT	less\tagSENT_CONTENT	memory\tagSENT_CONTENT	intensive\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	We\tagSENT_START	applied\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	WORD\tagSECTITLE_START	-\tagSECTITLE_CONTENT	LEVEL\tagSECTITLE_CONTENT	LANGUAGE\tagSECTITLE_CONTENT	MODELLING\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	(\tagSENT_CONTENT	PTB\tagSENT_CONTENT	,\tagSENT_CONTENT	Marcus\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	1993\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	WikiText-2\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	in\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Our\tagSENT_START	standard\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	was\tagSENT_CONTENT	taken\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Chainer\tagSENT_CONTENT	tutorial\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	2\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	used\tagSENT_CONTENT	two\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	650\tagSENT_CONTENT	units\tagSENT_CONTENT	each\tagSENT_CONTENT	,\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	SGD\tagSENT_CONTENT	and\tagSENT_CONTENT	regularized\tagSENT_CONTENT	with\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	dropout\tagSENT_CONTENT	.\tagSENT_END	language_modeling\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	used\tagSENT_CONTENT	3\tagSENT_CONTENT	layers\tagSENT_CONTENT	and\tagSENT_CONTENT	tied\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	was\tagSENT_CONTENT	intended\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	direct\tagSENT_CONTENT	replication\tagSENT_CONTENT	of\tagSENT_CONTENT	AWD\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	code\tagSENT_CONTENT	from\tagSENT_CONTENT	their\tagSENT_CONTENT	implementation\tagSENT_CONTENT	.\tagSENT_END	WikiText-2\tagdataset	is\tagSENT_CONTENT	roughly\tagSENT_CONTENT	twice\tagSENT_CONTENT	the\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	PTB\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	2\tagSENT_CONTENT	million\tagSENT_CONTENT	training\tagSENT_CONTENT	tokens\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	vocab\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	33k\tagSENT_CONTENT	.\tagSENT_END	Dynamic\tagSENT_START	evaluation\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	on\tagSENT_CONTENT	WikiText-2\tagdataset	,\tagSENT_CONTENT	and\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	significantly\tagSENT_CONTENT	greater\tagSENT_CONTENT	improvement\tagSENT_CONTENT	than\tagSENT_CONTENT	neural\tagSENT_CONTENT	caching\tagSENT_CONTENT	to\tagSENT_CONTENT	both\tagSENT_CONTENT	base\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Results\tagSENT_START	for\tagSENT_CONTENT	Hutter\tagdataset	Prize\tagdataset	are\tagSENT_CONTENT	given\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	text8\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Dynamic\tagSENT_START	evaluation\tagSENT_CONTENT	achieves\tagSENT_CONTENT	language_modeling\tagtask	to\tagSENT_CONTENT	our\tagSENT_CONTENT	base\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	TIME\tagSECTITLE_START	-\tagSECTITLE_CONTENT	SCALES\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	DYNAMIC\tagSECTITLE_CONTENT	EVALUATION\tagSECTITLE_END	Starting\tagSENT_START	from\tagSENT_CONTENT	language_modeling\tagtask	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	plot\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	static\tagSENT_CONTENT	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	against\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	characters\tagSENT_CONTENT	processed\tagSENT_CONTENT	on\tagSENT_CONTENT	sequences\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sequences\tagSENT_CONTENT	in\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	European\tagSENT_CONTENT	Parliament\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	divided\tagSENT_CONTENT	the\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	into\tagSENT_CONTENT	500\tagSENT_CONTENT	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	length\tagSENT_CONTENT	10000\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	applied\tagSENT_CONTENT	static\tagSENT_CONTENT	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	to\tagSENT_CONTENT	these\tagSENT_CONTENT	sequences\tagSENT_CONTENT	using\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	methodology\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	Spanish\tagSENT_CONTENT	experiments\tagSENT_CONTENT	measure\tagSENT_CONTENT	how\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	handles\tagSENT_CONTENT	large\tagSENT_CONTENT	distribution\tagSENT_CONTENT	shifts\tagSENT_CONTENT	between\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	Hutter\tagdataset	Prize\tagdataset	contains\tagSENT_CONTENT	very\tagSENT_CONTENT	little\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	gave\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	noticeable\tagSENT_CONTENT	advantage\tagSENT_CONTENT	after\tagSENT_CONTENT	a\tagmetric	few\tagmetric	hundred\tagmetric	characters\tagmetric	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	drew\tagSENT_CONTENT	300\tagSENT_CONTENT	character\tagSENT_CONTENT	conditional\tagSENT_CONTENT	samples\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	static\tagSENT_CONTENT	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	after\tagSENT_CONTENT	viewing\tagSENT_CONTENT	10k\tagSENT_CONTENT	characters\tagSENT_CONTENT	of\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	This\tagSENT_START	work\tagSENT_CONTENT	explores\tagSENT_CONTENT	and\tagSENT_CONTENT	develops\tagSENT_CONTENT	methodology\tagSENT_CONTENT	for\tagSENT_CONTENT	applying\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	
1711.05568	title\tagSECTITLE_END	dialogue_act_classification\tagtask	via\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	Attentive\tagSENT_CONTENT	Structured\tagSENT_CONTENT	Network\tagSENT_END	abstract\tagSECTITLE_END	dialogue_act_classification\tagtask	(\tagSENT_CONTENT	DAR\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	challenging\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	interpretation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	attach\tagSENT_CONTENT	semantic\tagSENT_CONTENT	labels\tagSENT_CONTENT	to\tagSENT_CONTENT	utterances\tagSENT_CONTENT	and\tagSENT_CONTENT	characterize\tagSENT_CONTENT	the\tagSENT_CONTENT	speaker\tagSENT_CONTENT	's\tagSENT_CONTENT	intention\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	dialogue_act_classification\tagtask	(\tagSENT_CONTENT	DAR\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	essential\tagSENT_CONTENT	problem\tagSENT_CONTENT	in\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	detecting\tagSENT_CONTENT	discourse\tagSENT_CONTENT	structure\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	approach\tagSENT_CONTENT	generalizes\tagSENT_CONTENT	the\tagSENT_CONTENT	soft\tagSENT_CONTENT	-\tagSENT_CONTENT	selection\tagSENT_CONTENT	attention\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	CRF\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	and\tagSENT_CONTENT	takes\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	influence\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	nearing\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	studies\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	dialogue_act_classification\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	viewpoint\tagSENT_CONTENT	of\tagSENT_CONTENT	extending\tagSENT_CONTENT	rich\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	attentive\tagSENT_CONTENT	structural\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	proposed\tagSENT_CONTENT	framework\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	trained\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	from\tagSENT_CONTENT	scratch\tagmetric	and\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	easily\tagSENT_CONTENT	extended\tagSENT_CONTENT	across\tagSENT_CONTENT	different\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	section\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	viewpoint\tagSENT_CONTENT	of\tagSENT_CONTENT	introducing\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	structured\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	attentive\tagSENT_CONTENT	structural\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	semantic\tagSENT_CONTENT	inference\tagSENT_CONTENT	and\tagSENT_CONTENT	memory\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	.\tagSENT_END	CRF\tagSECTITLE_START	-\tagSECTITLE_CONTENT	ATTENTIVE\tagSECTITLE_CONTENT	STRUCTURED\tagSECTITLE_CONTENT	NETWORK\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	viewpoint\tagSENT_CONTENT	of\tagSENT_CONTENT	extending\tagSENT_CONTENT	rich\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	attentive\tagSENT_CONTENT	structural\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	problem\tagSECTITLE_END	Before\tagSENT_START	presenting\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	introduce\tagSENT_CONTENT	some\tagSENT_CONTENT	basic\tagSENT_CONTENT	mathematical\tagSENT_CONTENT	notions\tagSENT_CONTENT	and\tagSENT_CONTENT	terminologies\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	We\tagSENT_START	have\tagSENT_CONTENT	dialogue_act_classification\tagtask	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	utterance\tagSENT_CONTENT	u\tagSENT_CONTENT	j\tagSENT_CONTENT	→\tagSENT_CONTENT	y\tagSENT_CONTENT	j\tagSENT_CONTENT	and\tagSENT_CONTENT	each\tagSENT_CONTENT	associated\tagSENT_CONTENT	y\tagSENT_CONTENT	j\tagSENT_CONTENT	∈\tagSENT_END	Most\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	models\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	leverage\tagSENT_CONTENT	the\tagSENT_CONTENT	implicit\tagSENT_CONTENT	and\tagSENT_CONTENT	intrinsic\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	among\tagSENT_CONTENT	dialogue_act_classification\tagtask	and\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	Naturally\tagSENT_START	dialogue_act_classification\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	regarded\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	task\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	assigned\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	act\tagSENT_CONTENT	through\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	classification\tagSENT_CONTENT	method\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	.\tagSENT_END	Hierarchical\tagSECTITLE_START	Semantic\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	The\tagSENT_START	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	composed\tagSENT_CONTENT	by\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	each\tagSENT_CONTENT	u\tagSENT_CONTENT	j\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	constituent\tagSENT_CONTENT	words\tagSENT_CONTENT	wt\tagSENT_CONTENT	.\tagSENT_END	Fine\tagSENT_START	Grained\tagSENT_CONTENT	Embedding\tagSENT_CONTENT	:\tagSENT_CONTENT	For\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	encoded\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	fine\tagSENT_CONTENT	grained\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	GRU\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	the\tagSENT_CONTENT	outputs\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	GRU\tagSENT_CONTENT	hidden\tagSENT_CONTENT	representations\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	After\tagSENT_START	obtained\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representations\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	later\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	memory\tagSENT_CONTENT	enhanced\tagSENT_CONTENT	contextual\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	correlations\tagSENT_CONTENT	between\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	Structured\tagSECTITLE_START	CRF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Network\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	In\tagSENT_CONTENT	DAR\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	structural\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	among\tagSENT_CONTENT	utterances\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Although\tagSENT_START	the\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	among\tagSENT_CONTENT	utterances\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	captured\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	former\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	semantic\tagSENT_CONTENT	networks\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	still\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	explore\tagSENT_CONTENT	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	level\tagSENT_CONTENT	.\tagSENT_END	u\tagSENT_START	and\tagSENT_CONTENT	dialogue_act_classification\tagtask	The\tagSENT_START	conversation\tagSENT_CONTENT	c\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	as\tagSENT_CONTENT	dialogue_act_classification\tagtask	aware\tagSENT_CONTENT	attentive\tagSENT_CONTENT	conversation\tagSENT_CONTENT	as\tagSENT_CONTENT	taking\tagSENT_CONTENT	the\tagSENT_CONTENT	expectation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	function\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	latent\tagSENT_CONTENT	variable\tagSENT_CONTENT	z\tagSENT_CONTENT	∼\tagSENT_CONTENT	p\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	p\tagSENT_CONTENT	is\tagSENT_CONTENT	parameterized\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	utterances\tagSENT_CONTENT	u\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue\tagSENT_END	The\tagSENT_START	expectation\tagSENT_CONTENT	is\tagSENT_CONTENT	dialogue_act_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	representation\tagSENT_CONTENT	and\tagSENT_CONTENT	represents\tagSENT_CONTENT	how\tagSENT_CONTENT	much\tagSENT_CONTENT	attention\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	act\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	that\tagSENT_START	the\tagSENT_CONTENT	utterance\tagSENT_CONTENT	u\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue_act_classification\tagtask	sequence\tagSENT_CONTENT	y\tagSENT_CONTENT	are\tagSENT_CONTENT	both\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	downstream\tagSENT_CONTENT	learned\tagSENT_CONTENT	representation\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	for\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	we\tagSENT_CONTENT	summarize\tagSENT_CONTENT	the\tagSENT_CONTENT	possible\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	act\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	sequential\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	.\tagSENT_END	End\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	End\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	Algorithm\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Viterbi\tagSECTITLE_CONTENT	algorithm\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	CRF\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	ASN\tagSECTITLE_CONTENT	Input\tagSECTITLE_CONTENT	:\tagSECTITLE_END	EXPERIMENTS\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	several\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	public\tagSENT_CONTENT	DA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	and\tagSENT_CONTENT	MRDA\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	ASN\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Data\tagSECTITLE_START	Preparation\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	DA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	:\tagSENT_CONTENT	dialogue_act_classification\tagtask	)\tagSENT_CONTENT	and\tagSENT_CONTENT	The\tagSENT_CONTENT	ICSI\tagSENT_CONTENT	Meeting\tagSENT_CONTENT	Recorder\tagSENT_CONTENT	Dialogue\tagSENT_CONTENT	Act\tagSENT_CONTENT	Corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	MRDA\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	handlabeled\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	1155\tagSENT_CONTENT	conversations\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	Switchboard\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	spontaneous\tagSENT_CONTENT	human\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	human\tagSENT_CONTENT	telephone\tagSENT_CONTENT	speech\tagSENT_CONTENT	.\tagSENT_END	Evaluation\tagSECTITLE_START	Criteria\tagSECTITLE_END	We\tagSENT_START	mainly\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	ASN\tagSENT_CONTENT	method\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	widely\tagSENT_CONTENT	-\tagSENT_CONTENT	used\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	criteria\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	,\tagSENT_CONTENT	Accuracy\tagSENT_CONTENT	.\tagSENT_END	Implemental\tagSECTITLE_START	Details\tagSECTITLE_END	We\tagSENT_START	preprocess\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	using\tagSENT_CONTENT	the\tagSENT_CONTENT	library\tagSENT_CONTENT	of\tagSENT_CONTENT	nltk\tagSENT_CONTENT	and\tagSENT_CONTENT	exploit\tagSENT_CONTENT	the\tagSENT_CONTENT	popular\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	Glove\tagSENT_CONTENT	with\tagSENT_CONTENT	100\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSECTITLE_START	Comparisons\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	propose\tagSENT_CONTENT	method\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	several\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	•\tagSENT_START	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	method\tagSENT_CONTENT	builds\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	as\tagSENT_CONTENT	abase\tagSENT_CONTENT	unit\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	field\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	do\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	LSTM\tagSENT_START	-\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	method\tagSENT_CONTENT	applies\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	structure\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	dialogue_act_classification\tagtask	via\tagSENT_CONTENT	softmax\tagSENT_CONTENT	operation\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	CNN\tagSENT_CONTENT	method\tagSENT_CONTENT	incorporates\tagSENT_CONTENT	the\tagSENT_CONTENT	preceding\tagSENT_CONTENT	short\tagSENT_CONTENT	texts\tagSENT_CONTENT	to\tagSENT_CONTENT	classify\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	•\tagSENT_START	SVM\tagSENT_CONTENT	Simple\tagSENT_CONTENT	baseline\tagSENT_CONTENT	which\tagSENT_CONTENT	applies\tagSENT_CONTENT	dialogue_act_classification\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	DAR\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	RCNN\tagSENT_START	,\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	Softmax\tagSENT_CONTENT	,\tagSENT_CONTENT	SVM\tagSENT_CONTENT	just\tagSENT_CONTENT	adopt\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Numerically\tagSENT_START	,\tagSENT_CONTENT	Our\tagSENT_CONTENT	model\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagmetric	DAR\tagmetric	accuracy\tagmetric	over\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	by\tagSENT_CONTENT	2.1\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	0.8\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	and\tagSENT_CONTENT	MRDA\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	,\tagSENT_START	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	obtain\tagSENT_CONTENT	better\tagSENT_CONTENT	results\tagSENT_CONTENT	than\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	dialogue_act_classification\tagtask	are\tagSENT_CONTENT	essential\tagSENT_CONTENT	and\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	significantly\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Results\tagSECTITLE_END	We\tagSENT_START	replace\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	structured\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	simple\tagSENT_CONTENT	CRF\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	show\tagSENT_CONTENT	structured\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layer\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	major\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	approximately\tagSENT_CONTENT	over\tagSENT_CONTENT	2.1\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	points\tagSENT_CONTENT	.\tagSENT_END	Visualization\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	displayed\tagSENT_CONTENT	as\tagSENT_CONTENT	4\tagSENT_CONTENT	→\tagSENT_CONTENT	5\tagSENT_CONTENT	→\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	briefly\tagSENT_CONTENT	review\tagSENT_CONTENT	some\tagSENT_CONTENT	related\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	dialogue_act_classification\tagtask	and\tagSENT_CONTENT	attention\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	Dialogue\tagSECTITLE_START	Act\tagSECTITLE_CONTENT	Recognition\tagSECTITLE_END	The\tagSENT_START	main\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	assign\tagSENT_CONTENT	an\tagSENT_CONTENT	act\tagSENT_CONTENT	label\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	supervised\tagSENT_CONTENT	problem\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	properties\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	act\tagSENT_CONTENT	label\tagSENT_CONTENT	.\tagSENT_END	Regarding\tagSENT_START	the\tagSENT_CONTENT	DAR\tagSENT_CONTENT	as\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	also\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	linear\tagSENT_CONTENT	support\tagSENT_CONTENT	vector\tagSENT_CONTENT	machines\tagSENT_CONTENT	and\tagSENT_CONTENT	hidden\tagSENT_CONTENT	markov\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	dialogue_act_classification\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	HCRC\tagSENT_CONTENT	MapTask\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	approaches\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	methods\tagSENT_CONTENT	improved\tagSENT_CONTENT	many\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	techniques\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	including\tagSENT_CONTENT	DAR\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	conversations\tagSENT_CONTENT	[\tagSENT_CONTENT	48\tagSENT_CONTENT	]\tagSENT_END	Attention\tagSECTITLE_START	Network\tagSECTITLE_END	[\tagSENT_START	8\tagSENT_CONTENT	]\tagSENT_CONTENT	,\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	[\tagSENT_CONTENT	9\tagSENT_CONTENT	]\tagSENT_CONTENT	,\tagSENT_CONTENT	abstract\tagSENT_CONTENT	summarization\tagSENT_CONTENT	,\tagSENT_CONTENT	dialogue_act_classification\tagtask	[\tagSENT_CONTENT	47\tagSENT_CONTENT	]\tagSENT_CONTENT	and\tagSENT_CONTENT	soon\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	the\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	attentive\tagSENT_CONTENT	structured\tagSENT_CONTENT	network\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	internal\tagSENT_CONTENT	utterance\tagSENT_CONTENT	inference\tagSENT_CONTENT	with\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	formulate\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	viewpoint\tagSENT_CONTENT	of\tagSENT_CONTENT	capturing\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	rich\tagSENT_CONTENT	utterance\tagSENT_CONTENT	representations\tagSENT_CONTENT	and\tagSENT_CONTENT	generalize\tagSENT_CONTENT	richer\tagSENT_CONTENT	CRF\tagSENT_CONTENT	attentive\tagSENT_CONTENT	graphical\tagSENT_CONTENT	structural\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	without\tagSENT_CONTENT	abandoning\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	
1605.07725	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	provide\tagSENT_CONTENT	visualizations\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	learned\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	have\tagSENT_CONTENT	improved\tagSENT_CONTENT	in\tagSENT_CONTENT	quality\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	while\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	prone\tagSENT_CONTENT	to\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	pretraining\tagSENT_CONTENT	as\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	for\tagSENT_CONTENT	multiple\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	text\tagSENT_CONTENT	classification\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	topic\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	MODEL\tagSECTITLE_END	ADVERSARIAL\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	VIRTUAL\tagSECTITLE_CONTENT	ADVERSARIAL\tagSECTITLE_CONTENT	TRAINING\tagSECTITLE_END	EXPERIMENTAL\tagSECTITLE_START	SETTINGS\tagSECTITLE_END	The\tagSENT_START	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	dimension\tagSENT_CONTENT	D\tagSENT_CONTENT	was\tagSENT_CONTENT	256\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	and\tagSENT_CONTENT	512\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	tested\tagSENT_CONTENT	the\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	,\tagSENT_CONTENT	Elec\tagSENT_CONTENT	and\tagSENT_CONTENT	RCV\tagSENT_CONTENT	because\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	relatively\tagSENT_CONTENT	long\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	TRAINING\tagSECTITLE_START	CLASSIFICATION\tagSECTITLE_CONTENT	MODELS\tagSECTITLE_END	Between\tagSENT_START	the\tagSENT_CONTENT	softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	y\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	added\tagSENT_CONTENT	a\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	dimension\tagSENT_CONTENT	30\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	,\tagSENT_CONTENT	Elec\tagSENT_CONTENT	and\tagSENT_CONTENT	Rotten\tagSENT_CONTENT	Tomatoes\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	128\tagSENT_CONTENT	on\tagSENT_CONTENT	DBpedia\tagSENT_CONTENT	and\tagSENT_CONTENT	RCV1\tagSENT_CONTENT	.\tagSENT_END	Batch\tagSENT_START	sizes\tagSENT_CONTENT	are\tagSENT_CONTENT	64\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	,\tagSENT_CONTENT	Elec\tagSENT_CONTENT	,\tagSENT_CONTENT	RCV1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	128\tagSENT_CONTENT	on\tagSENT_CONTENT	DBpedia\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	iterated\tagSENT_CONTENT	10,000\tagSENT_CONTENT	training\tagSENT_CONTENT	stepson\tagSENT_CONTENT	all\tagSENT_CONTENT	datasets\tagSENT_CONTENT	except\tagSENT_CONTENT	IMDB\tagdataset	and\tagSENT_CONTENT	DBpedia\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	15,000\tagSENT_CONTENT	and\tagSENT_CONTENT	20,000\tagSENT_CONTENT	training\tagSENT_CONTENT	steps\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	the\tagSENT_CONTENT	test\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	IMDB\tagdataset	with\tagSENT_CONTENT	each\tagSENT_CONTENT	training\tagSENT_CONTENT	method\tagSENT_CONTENT	.\tagSENT_CONTENT	'\tagSENT_END	RESULTS\tagSECTITLE_END	TEST\tagSECTITLE_START	PERFORMANCE\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	IMDB\tagSECTITLE_CONTENT	DATASET\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_CONTENT	ANALYSIS\tagSECTITLE_END	TEST\tagSECTITLE_START	PERFORMANCE\tagSECTITLE_CONTENT	ON\tagSECTITLE_CONTENT	ELEC\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	RCV1\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	ROTTEN\tagSECTITLE_CONTENT	TOMATOES\tagSECTITLE_CONTENT	DATASET\tagSECTITLE_END	PERFORMANCE\tagSECTITLE_START	ON\tagSECTITLE_CONTENT	THE\tagSECTITLE_CONTENT	DBPEDIA\tagSECTITLE_CONTENT	PURELY\tagSECTITLE_CONTENT	SUPERVISED\tagSECTITLE_CONTENT	CLASSIFICATION\tagSECTITLE_CONTENT	TASK\tagSECTITLE_END	CONCLUSION\tagSECTITLE_END	
N18-2045	title\tagSECTITLE_END	Recurrent\tagSENT_START	Entity\tagSENT_CONTENT	Networks\tagSENT_CONTENT	with\tagSENT_CONTENT	Delayed\tagSENT_CONTENT	Memory\tagSENT_CONTENT	Update\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	abstract\tagSECTITLE_END	While\tagSENT_START	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	impressive\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	targeted\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	(\tagSENT_CONTENT	TABSA)-extraction\tagSENT_CONTENT	of\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	opinion\tagSENT_CONTENT	polarity\tagSENT_END	Introduction\tagSECTITLE_END	sentiment_analysis\tagtask	(\tagSENT_CONTENT	TABSA\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	opinion\tagSENT_CONTENT	polarity\tagSENT_CONTENT	towards\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	aspect\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	target\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	earliest\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	(\tagSENT_CONTENT	T)ABSA\tagSENT_CONTENT	relied\tagSENT_CONTENT	heavily\tagSENT_CONTENT	on\tagSENT_CONTENT	feature\tagSENT_CONTENT	engineering\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	more\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	deep\tagSENT_CONTENT	learning\tagSENT_CONTENT	has\tagSENT_CONTENT	used\tagSENT_CONTENT	models\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	learn\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	dependent\tagSENT_CONTENT	biLSTM\tagSENT_CONTENT	is\tagSENT_CONTENT	ineffective\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	aspect\tagmetric	detection\tagmetric	and\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	logistic\tagSENT_CONTENT	regression\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	TABSA\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	common\tagSENT_CONTENT	practice\tagSENT_CONTENT	for\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	operate\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	chunk\tagSENT_CONTENT	/\tagSENT_CONTENT	sentencelevel\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagmetric	sentence\tagmetric	starts\tagSENT_CONTENT	with\tagSENT_CONTENT	LOC1\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	negative\tagSENT_CONTENT	PRICE\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	expressed\tagSENT_CONTENT	until\tagSENT_CONTENT	much\tagSENT_CONTENT	later\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	TABSA\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	achieve\tagSENT_CONTENT	substantial\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	baselines\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	one\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	external\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	bases\tagSENT_CONTENT	,\tagSENT_CONTENT	setting\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment_analysis\tagtask	and\tagSENT_CONTENT	aspect\tagSENT_CONTENT	detection\tagSENT_CONTENT	.\tagSENT_END	Methodology\tagSECTITLE_END	In\tagSENT_START	TABSA\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagmetric	sentence\tagmetric	s\tagSENT_CONTENT	typically\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	:\tagSENT_CONTENT	{\tagSENT_CONTENT	w\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	frame\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	3-class\tagSENT_CONTENT	classification\tagSENT_CONTENT	problem\tagSENT_CONTENT	:\tagSENT_CONTENT	given\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	identified\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	T\tagSENT_CONTENT	and\tagSENT_CONTENT	fixed\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	aspects\tagSENT_CONTENT	A\tagSENT_CONTENT	,\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	polarity\tagSENT_CONTENT	y\tagSENT_CONTENT	∈\tagSENT_CONTENT	{\tagSENT_CONTENT	positive\tagSENT_CONTENT	,\tagSENT_CONTENT	negative\tagSENT_CONTENT	,\tagSENT_CONTENT	none\tagSENT_CONTENT	}\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	aspect\tagSENT_CONTENT	pairs\tagSENT_CONTENT	{\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_END	To\tagSENT_START	this\tagSENT_CONTENT	end\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	design\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architecture\tagSENT_CONTENT	,\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	tracking\tagSENT_CONTENT	and\tagSENT_CONTENT	updating\tagSENT_CONTENT	the\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	at\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	time\tagSENT_CONTENT	with\tagSENT_CONTENT	external\tagSENT_CONTENT	memory\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	it\tagSENT_CONTENT	a\tagSENT_CONTENT	natural\tagSENT_CONTENT	fit\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	above\tagSENT_CONTENT	steps\tagSENT_CONTENT	both\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagmetric	sentence\tagmetric	,\tagSENT_CONTENT	enabling\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	sentiment_analysis\tagtask	appearing\tagSENT_CONTENT	before\tagSENT_CONTENT	and\tagSENT_CONTENT	after\tagSENT_CONTENT	its\tagSENT_CONTENT	associated\tagSENT_CONTENT	entity\tagSENT_CONTENT	.\tagSENT_END	Admittedly\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	EntNets\tagSENT_CONTENT	on\tagSENT_CONTENT	bAbI\tagSENT_CONTENT	and\tagSENT_CONTENT	CBT\tagSENT_CONTENT	,\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	coarse\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	nature\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	granularity\tagSENT_CONTENT	of\tagSENT_CONTENT	inputs\tagSENT_CONTENT	(\tagSENT_CONTENT	sentiment_analysis\tagtask	vs.\tagSENT_CONTENT	words\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	demand\tagSENT_CONTENT	for\tagSENT_CONTENT	modelling\tagSENT_CONTENT	delayed\tagSENT_CONTENT	memory\tagSENT_CONTENT	update\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	obvious\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	To\tagSENT_START	test\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	Sentihood\tagdataset	,\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	constructed\tagSENT_CONTENT	by\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	purpose\tagSENT_CONTENT	of\tagSENT_CONTENT	detecting\tagSENT_CONTENT	aspects\tagSENT_CONTENT	and\tagSENT_CONTENT	identifying\tagSENT_CONTENT	sentiments\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	targetaspect\tagSENT_CONTENT	pair\tagSENT_CONTENT	,\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	5\tagSENT_CONTENT	,\tagSENT_CONTENT	215\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	3\tagSENT_CONTENT	,\tagSENT_CONTENT	862\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	contain\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	target\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	remainder\tagSENT_CONTENT	multiple\tagSENT_CONTENT	targets\tagSENT_CONTENT	.\tagSENT_END	Ultimately\tagSENT_START	,\tagSENT_CONTENT	given\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	interested\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	detecting\tagSENT_CONTENT	the\tagSENT_CONTENT	mention\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	aspect\tagSENT_CONTENT	a\tagSENT_CONTENT	for\tagSENT_CONTENT	target\tagSENT_CONTENT	t\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	label\tagSENT_CONTENT	other\tagSENT_CONTENT	than\tagSENT_CONTENT	none\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	specific\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	y\tagSENT_CONTENT	w.r.t\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	4\tagSENT_CONTENT	aspects\tagSENT_CONTENT	only\tagSENT_CONTENT	(\tagSENT_CONTENT	GENERAL\tagSENT_CONTENT	,\tagSENT_CONTENT	PRICE\tagSENT_CONTENT	,\tagSENT_CONTENT	TRANSIT\tagSENT_CONTENT	-\tagSENT_CONTENT	LOCATION\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	SAFETY\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	employ\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	:\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	average\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	AUC\tagSENT_CONTENT	for\tagSENT_CONTENT	aspect\tagmetric	detection\tagmetric	ignoring\tagSENT_CONTENT	the\tagSENT_CONTENT	none\tagSENT_CONTENT	class\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	and\tagSENT_CONTENT	macro\tagSENT_CONTENT	-\tagSENT_CONTENT	average\tagSENT_CONTENT	AUC\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Results\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	aspect\tagSENT_CONTENT	detection\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	We\tagSENT_START	see\tagSENT_CONTENT	consistent\tagSENT_CONTENT	performance\tagSENT_CONTENT	gains\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	aspect\tagSENT_CONTENT	detection\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	EntNet\tagSENT_CONTENT	,\tagSENT_CONTENT	esp\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Observe\tagSENT_START	that\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	updated\tagSENT_CONTENT	less\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	mention\tagSENT_CONTENT	of\tagSENT_CONTENT	LOC1\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	carries\tagSENT_CONTENT	out\tagSENT_CONTENT	memory\tagSENT_CONTENT	updates\tagSENT_CONTENT	upon\tagSENT_CONTENT	seeing\tagSENT_CONTENT	lovely\tagSENT_CONTENT	town\tagSENT_CONTENT	and\tagSENT_CONTENT	plenty\tagSENT_CONTENT	of\tagSENT_CONTENT	restaurants\tagSENT_CONTENT	,\tagSENT_CONTENT	key\tagSENT_CONTENT	phrases\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	aspects\tagmetric	such\tagSENT_CONTENT	as\tagSENT_CONTENT	GENERAL\tagSENT_CONTENT	and\tagSENT_CONTENT	DINNING\tagSENT_CONTENT	.\tagSENT_END	Perhaps\tagSENT_START	even\tagSENT_CONTENT	more\tagSENT_CONTENT	importantly\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	the\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	LOC1\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	portion\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	sentence\tagmetric	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	recognises\tagSENT_CONTENT	the\tagSENT_CONTENT	relevance\tagSENT_CONTENT	to\tagSENT_CONTENT	TRANSIT\tagSENT_CONTENT	-\tagSENT_CONTENT	LOCATION\tagSENT_CONTENT	and\tagSENT_CONTENT	keeps\tagSENT_CONTENT	the\tagSENT_CONTENT	update\tagSENT_CONTENT	gates\tagSENT_CONTENT	open\tagSENT_CONTENT	to\tagSENT_CONTENT	track\tagSENT_CONTENT	this\tagSENT_CONTENT	particular\tagSENT_CONTENT	aspect\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	opposed\tagSENT_CONTENT	to\tagSENT_CONTENT	EntNet\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	last\tagSENT_CONTENT	phase\tagSENT_CONTENT	is\tagSENT_CONTENT	overlooked\tagSENT_CONTENT	.\tagSENT_END	Observe\tagSENT_START	that\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	n\tagSENT_CONTENT	<\tagSENT_CONTENT	5\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	suffers\tagSENT_CONTENT	from\tagSENT_CONTENT	insufficient\tagSENT_CONTENT	capacity\tagSENT_CONTENT	(\tagSENT_CONTENT	not\tagSENT_CONTENT	enough\tagSENT_CONTENT	memory\tagSENT_CONTENT	chains\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	various\tagSENT_CONTENT	aspects\tagSENT_CONTENT	required\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	aspect\tagmetric	detection\tagmetric	F\tagmetric	1\tagSENT_CONTENT	remaining\tagSENT_CONTENT	below\tagSENT_CONTENT	78\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	tracking\tagSENT_CONTENT	sentiment_analysis\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	delayed\tagSENT_CONTENT	memory\tagSENT_CONTENT	update\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	method\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	targeted\tagSENT_CONTENT	aspect\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	.\tagSENT_END	
N18-2102	title\tagSECTITLE_END	summarization\tagtask	with\tagSENT_CONTENT	Saliency\tagSENT_CONTENT	and\tagSENT_CONTENT	Entailment\tagSENT_END	abstract\tagSECTITLE_END	i\tagSENT_START	ve\tagSENT_CONTENT	summarization\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	compressing\tagSENT_CONTENT	and\tagSENT_CONTENT	rewriting\tagSENT_CONTENT	along\tagSENT_CONTENT	document\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	summary\tagSENT_CONTENT	while\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	saliency\tagSENT_CONTENT	,\tagSENT_CONTENT	directed\tagSENT_CONTENT	logical\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	redundancy\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	summarization\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	generating\tagSENT_CONTENT	a\tagSENT_CONTENT	natural\tagSENT_CONTENT	short\tagSENT_CONTENT	summary\tagSENT_CONTENT	of\tagSENT_CONTENT	along\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	extractive\tagSENT_CONTENT	paradigm\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	involves\tagSENT_CONTENT	selection\tagSENT_CONTENT	of\tagSENT_CONTENT	important\tagSENT_CONTENT	sentences\tagSENT_CONTENT	or\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	sentences\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Towards\tagSENT_START	this\tagSENT_CONTENT	goal\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	via\tagSENT_CONTENT	a\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	introduction\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	novel\tagSENT_END	Our\tagSENT_START	Entail\tagSENT_CONTENT	reward\tagSENT_CONTENT	gives\tagSENT_CONTENT	higher\tagSENT_CONTENT	weight\tagSENT_CONTENT	to\tagSENT_CONTENT	summarization\tagtask	whose\tagSENT_CONTENT	sentences\tagSENT_CONTENT	logically\tagSENT_CONTENT	follow\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	-\tagSENT_CONTENT	truth\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	further\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvements\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	these\tagSENT_CONTENT	rewards\tagSENT_CONTENT	via\tagSENT_CONTENT	our\tagSENT_CONTENT	novel\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	reward\tagSENT_CONTENT	optimization\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	optimize\tagSENT_CONTENT	multiple\tagSENT_CONTENT	rewards\tagSENT_CONTENT	simultaneously\tagSENT_CONTENT	in\tagSENT_CONTENT	alternate\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	(\tagSENT_CONTENT	hence\tagSENT_CONTENT	avoiding\tagSENT_CONTENT	complex\tagSENT_CONTENT	scaling\tagSENT_CONTENT	and\tagSENT_CONTENT	weighting\tagSENT_CONTENT	issues\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	inspired\tagSENT_CONTENT	from\tagSENT_CONTENT	how\tagSENT_CONTENT	humans\tagSENT_CONTENT	take\tagSENT_CONTENT	multiple\tagSENT_CONTENT	concurrent\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	rewards\tagSENT_CONTENT	(\tagSENT_CONTENT	feedback\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	summarization\tagtask	was\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	extraction\tagSENT_CONTENT	and\tagSENT_CONTENT	compression\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	more\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	discourse\tagSENT_CONTENT	tree\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	)\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	explored\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	RTE\tagSENT_CONTENT	by\tagSENT_CONTENT	modeling\tagSENT_CONTENT	graphbased\tagSENT_CONTENT	relationships\tagSENT_CONTENT	between\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	redundant\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	For\tagSENT_START	our\tagSENT_CONTENT	saliency\tagSENT_CONTENT	prediction\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	spans\tagSENT_CONTENT	annotated\tagSENT_CONTENT	by\tagSENT_CONTENT	humans\tagSENT_CONTENT	for\tagSENT_CONTENT	important\tagSENT_CONTENT	questions\tagSENT_CONTENT	,\tagSENT_CONTENT	serve\tagSENT_CONTENT	as\tagSENT_CONTENT	an\tagSENT_CONTENT	interesting\tagSENT_CONTENT	and\tagSENT_CONTENT	effective\tagSENT_CONTENT	proxy\tagSENT_CONTENT	for\tagSENT_CONTENT	keyphrase\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Models\tagSECTITLE_END	Baseline\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Sequence\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Policy\tagSECTITLE_START	Gradient\tagSECTITLE_CONTENT	Reinforce\tagSECTITLE_END	The\tagSENT_START	derivative\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	loss\tagSENT_CONTENT	function\tagSENT_CONTENT	with\tagSENT_CONTENT	summarization\tagtask	using\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	sample\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	variance\tagSENT_CONTENT	reduction\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	bias\tagSENT_CONTENT	estimator\tagSENT_CONTENT	is\tagSENT_CONTENT	:\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	reward\tagSECTITLE_CONTENT	Optimization\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	basic\tagSENT_CONTENT	reward\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	summarization\tagtask	of\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	package\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	to\tagSENT_START	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	video\tagSENT_CONTENT	captioning\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	instead\tagSENT_CONTENT	directly\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	entailment\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	from\tagSENT_CONTENT	an\tagSENT_CONTENT	entailment\tagSENT_CONTENT	scorer\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	multisentence\tagSENT_CONTENT	,\tagSENT_CONTENT	length\tagSENT_CONTENT	-\tagSENT_CONTENT	normalized\tagSENT_CONTENT	extension\tagSENT_CONTENT	as\tagSENT_CONTENT	our\tagSENT_CONTENT	'\tagSENT_CONTENT	Entail\tagSENT_CONTENT	'\tagSENT_CONTENT	reward\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Evaluation\tagSECTITLE_START	Metrics\tagSECTITLE_END	Results\tagSECTITLE_END	summarization\tagtask	has\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	pointer\tagSENT_CONTENT	-\tagSENT_CONTENT	copy\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	coverage\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	baseline\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	w.r.t\tagSENT_CONTENT	.\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	reward\tagSENT_CONTENT	results\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.001\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	showing\tagSENT_CONTENT	that\tagSENT_CONTENT	saliency\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	is\tagSENT_CONTENT	strongly\tagSENT_CONTENT	improving\tagSENT_CONTENT	summarization\tagtask	.\tagSENT_END	Multi\tagSENT_START	-\tagSENT_CONTENT	Reward\tagSENT_CONTENT	Results\tagSENT_CONTENT	Similar\tagSENT_CONTENT	to\tagSENT_CONTENT	Output\tagSECTITLE_START	Analysis\tagSECTITLE_END	better\tagSENT_START	in\tagSENT_CONTENT	saliency\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagmetric	-\tagmetric	reward\tagmetric	models\tagmetric	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.001\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	the\tagSENT_CONTENT	entailment\tagSENT_CONTENT	scores\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	generated\tagSENT_CONTENT	summaries\tagSENT_CONTENT	from\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	ROUGEreward\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Entail\tagSENT_CONTENT	-\tagSENT_CONTENT	reward\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	27.33\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	27.21\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	28.23\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	28.98\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Compared\tagSENT_START	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	Entailreward\tagSENT_CONTENT	and\tagSENT_CONTENT	ROUGE\tagSENT_CONTENT	-\tagSENT_CONTENT	reward\tagSENT_CONTENT	models\tagSENT_CONTENT	achieve\tagSENT_CONTENT	statistically\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvement\tagSENT_CONTENT	(\tagSENT_CONTENT	p\tagSENT_CONTENT	<\tagSENT_CONTENT	0.01\tagSENT_CONTENT	)\tagSENT_CONTENT	while\tagSENT_CONTENT	ROUGESal\tagmetric	is\tagSENT_CONTENT	comparable\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	summarization\tagtask	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	novel\tagSENT_CONTENT	RL\tagSENT_CONTENT	reward\tagSENT_CONTENT	functions\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	saliency\tagSENT_CONTENT	and\tagSENT_CONTENT	directed\tagSENT_CONTENT	logical\tagSENT_CONTENT	entailment\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	summary\tagSENT_CONTENT	.\tagSENT_END	summarization\tagtask	.\tagSENT_END	A\tagSECTITLE_START	Supplementary\tagSECTITLE_CONTENT	Material\tagSECTITLE_END	A.1\tagSECTITLE_START	Saliency\tagSECTITLE_CONTENT	Rewards\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	precision\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	lcs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	recall\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	lcs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	(\tagSENT_CONTENT	F\tagSENT_CONTENT	lcs\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	ROUGE\tagmetric	-\tagmetric	L\tagmetric	are\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	our\tagSENT_CONTENT	novel\tagSENT_CONTENT	saliency\tagSENT_CONTENT	predictor\tagSENT_CONTENT	to\tagSENT_CONTENT	modify\tagSENT_CONTENT	the\tagmetric	ROUGE\tagmetric	-\tagmetric	L\tagmetric	scores\tagmetric	with\tagSENT_CONTENT	salient\tagSENT_CONTENT	information\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	A.2\tagSECTITLE_START	Experimental\tagSECTITLE_CONTENT	Setup\tagSECTITLE_END	A.2.1\tagSECTITLE_START	Datasets\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	Dataset\tagSECTITLE_CONTENT	CNN\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	Daily\tagSECTITLE_END	summarization\tagtask	are\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	written\tagSENT_CONTENT	highlights\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	articles\tagSENT_CONTENT	.\tagSENT_END	DUC\tagSECTITLE_START	Test\tagSECTITLE_CONTENT	Corpus\tagSECTITLE_END	A.2.2\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	A.3\tagSECTITLE_START	Results\tagSECTITLE_END	A.3.1\tagSECTITLE_START	Saliency\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Entailment\tagSECTITLE_CONTENT	Scorer\tagSECTITLE_END	
1709.04250	title\tagSECTITLE_END	dialogue_act_classification\tagtask	using\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	with\tagSENT_CONTENT	CRF\tagSENT_END	abstract\tagSECTITLE_END	dialogue_act_classification\tagtask	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	semantic\tagSENT_CONTENT	labels\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	utterances\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	dialogue_act_classification\tagtask	(\tagSENT_CONTENT	DA\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	semantic\tagSENT_CONTENT	labels\tagSENT_CONTENT	attached\tagSENT_CONTENT	to\tagSENT_CONTENT	utterances\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	that\tagSENT_CONTENT	serve\tagSENT_CONTENT	to\tagSENT_CONTENT	concisely\tagSENT_CONTENT	characterize\tagSENT_CONTENT	speakers\tagSENT_CONTENT	'\tagSENT_CONTENT	intention\tagSENT_CONTENT	in\tagSENT_CONTENT	producing\tagSENT_CONTENT	those\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	DA\tagSENT_START	recognition\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	understood\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	several\tagSENT_CONTENT	different\tagSENT_CONTENT	approaches\tagSENT_CONTENT	ranging\tagSENT_CONTENT	from\tagSENT_CONTENT	dialogue_act_classification\tagtask	to\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	it\tagSENT_CONTENT	(\tagSENT_CONTENT	Grau\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	(\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	Long\tagSENT_CONTENT	Short\tagSENT_CONTENT	Term\tagSENT_CONTENT	Memory\tagSENT_CONTENT	with\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	DA\tagSENT_CONTENT	recognition\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	capture\tagSENT_CONTENT	both\tagSENT_CONTENT	kind\tagSENT_CONTENT	of\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	among\tagSENT_CONTENT	dialogue_act_classification\tagtask	and\tagSENT_CONTENT	among\tagSENT_CONTENT	utterances\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	an\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	79.2\tagSENT_CONTENT	%\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	77\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	step\tagSENT_CONTENT	closer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	reported\tagSENT_CONTENT	interannotator\tagSENT_CONTENT	agreement\tagSENT_CONTENT	of\tagSENT_CONTENT	84\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	DA\tagSENT_START	recognition\tagSENT_CONTENT	is\tagSENT_CONTENT	dialogue_act_classification\tagtask	that\tagSENT_CONTENT	assigns\tagSENT_CONTENT	DA\tagSENT_CONTENT	label\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	another\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	builds\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	CNN\tagSENT_CONTENT	(\tagSENT_CONTENT	HCNN\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	dialogue_act_classification\tagtask	of\tagSENT_CONTENT	these\tagSENT_CONTENT	sentence\tagSENT_CONTENT	representation\tagSENT_CONTENT	into\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	DAs\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	they\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	language\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	they\tagSENT_CONTENT	take\tagSENT_CONTENT	into\tagSENT_CONTENT	account\tagmetric	the\tagSENT_CONTENT	label\tagSENT_CONTENT	dependency\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	among\tagSENT_CONTENT	utterances\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	principled\tagSENT_CONTENT	way\tagSENT_CONTENT	.\tagSENT_END	Methodology\tagSECTITLE_END	Before\tagSENT_START	describing\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	mathematical\tagSENT_CONTENT	notation\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	In\tagSENT_START	other\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	an\tagSENT_CONTENT	associated\tagSENT_CONTENT	target\tagSENT_CONTENT	label\tagSENT_CONTENT	y\tagSENT_CONTENT	j\tagSENT_CONTENT	∈\tagSENT_END	The\tagSENT_START	whole\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	utterances\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	conversation\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	considered\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	very\tagSENT_CONTENT	long\tagSENT_CONTENT	chain\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	output\tagSENT_CONTENT	tags\tagSENT_CONTENT	or\tagSENT_CONTENT	labels\tagSENT_CONTENT	only\tagSENT_CONTENT	appearing\tagSENT_CONTENT	sparsely\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	encoder\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	encoder\tagSENT_CONTENT	operates\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	utterance\tagSENT_CONTENT	level\tagSENT_CONTENT	,\tagSENT_CONTENT	encoding\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	encoder\tagSENT_CONTENT	operates\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	conversation\tagSENT_CONTENT	level\tagSENT_CONTENT	,\tagSENT_CONTENT	encoding\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	output\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	encoder\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	any\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	which\tagSENT_CONTENT	takes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	utterance\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	formulation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	linear\tagSENT_CONTENT	chain\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	field\tagSENT_CONTENT	(\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	structured\tagSENT_CONTENT	prediction\tagSENT_CONTENT	.\tagSENT_END	Hierarchical\tagSECTITLE_START	Recurrent\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	For\tagSENT_START	a\tagSENT_CONTENT	given\tagSENT_CONTENT	conversation\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	wk\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	processed\tagSENT_CONTENT	by\tagSENT_CONTENT	an\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	which\tagSENT_CONTENT	converts\tagSENT_CONTENT	onehot\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	vectors\tagSENT_CONTENT	to\tagSENT_CONTENT	dense\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	Hochreiter\tagSENT_CONTENT	and\tagSENT_CONTENT	Schmidhuber\tagSENT_CONTENT	1997\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	encoder\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	conversations\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	denoted\tagSENT_CONTENT	by\tagSENT_CONTENT	v\tagSENT_CONTENT	j\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	by\tagSENT_CONTENT	combining\tagSENT_CONTENT	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	constituent\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	Ci\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	left\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	representation\tagSENT_CONTENT	g\tagSENT_CONTENT	j\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	passed\tagSENT_CONTENT	forward\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	classification\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	Linear\tagSECTITLE_START	Chain\tagSECTITLE_CONTENT	CRF\tagSECTITLE_END	y\tagSENT_START	Ri\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	dialogue_act_classification\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	written\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	g\tagSENT_CONTENT	j\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	dense\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	u\tagSENT_CONTENT	j\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	level\tagSENT_CONTENT	encoder\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	Parameter\tagSECTITLE_END	Hyperparameter\tagSECTITLE_START	Tuning\tagSECTITLE_END	Conversations\tagSENT_START	with\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	utterances\tagSENT_CONTENT	were\tagSENT_CONTENT	grouped\tagSENT_CONTENT	together\tagSENT_CONTENT	into\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	each\tagmetric	utterance\tagmetric	in\tagSENT_CONTENT	a\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batch\tagSENT_CONTENT	was\tagSENT_CONTENT	padded\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	length\tagSENT_CONTENT	for\tagSENT_CONTENT	that\tagSENT_CONTENT	batch\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	LSTMs\tagSENT_START	on\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	CNN\tagSENT_START	on\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	utterances\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	RNN\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	CRF\tagSENT_START	-Simple\tagSENT_CONTENT	baseline\tagSENT_CONTENT	with\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	:\tagSENT_START	Comparing\tagSENT_CONTENT	accuracy\tagmetric	of\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	(\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	on\tagSENT_CONTENT	SwDA\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	means\tagSENT_CONTENT	two\tagSENT_CONTENT	utterances\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	underlying\tagSENT_CONTENT	text\tagSENT_CONTENT	have\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Hierarchy\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Label\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	discuss\tagSENT_CONTENT	the\tagSENT_CONTENT	influence\tagSENT_CONTENT	of\tagSENT_CONTENT	adding\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	layers\tagSENT_CONTENT	(\tagSENT_CONTENT	utterance\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	conversation\tagSENT_CONTENT	layer\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	dialogue_act_classification\tagtask	on\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	first\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	WE\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	plain\tagSENT_CONTENT	two\tagSENT_CONTENT	layer\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	dialogue_act_classification\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	Glove\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	fed\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	classification\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	Effect\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Linguistic\tagSECTITLE_CONTENT	Features\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Context\tagSECTITLE_END	For\tagSENT_START	dialogue_act_classification\tagtask	,\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	features-\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	context\tagSENT_CONTENT	information\tagSENT_CONTENT	(\tagSENT_CONTENT	Ribeiro\tagSENT_CONTENT	,\tagSENT_CONTENT	Ribeiro\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	de\tagSENT_CONTENT	Matos\tagSENT_CONTENT	2015\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	underlying\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	addition\tagSENT_CONTENT	of\tagSENT_CONTENT	POS\tagSENT_CONTENT	reduces\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	by\tagSENT_CONTENT	approximately\tagSENT_CONTENT	1\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	Accuracy\tagmetric	obtained\tagSENT_CONTENT	using\tagSENT_CONTENT	two\tagSENT_CONTENT	extensions\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	labeling\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	utterances\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	conversation\tagSENT_CONTENT	with\tagSENT_CONTENT	dialogue_act_classification\tagtask	.\tagSENT_END	
P15-1032	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	structured\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	training\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	Lately\tagSENT_START	,\tagSENT_CONTENT	dependency_parsing\tagtask	has\tagSENT_CONTENT	emerged\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	popular\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	availability\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency\tagSENT_CONTENT	treebanks\tagSENT_CONTENT	in\tagSENT_CONTENT	many\tagSENT_CONTENT	languages\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	efficiency\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parsers\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	distributed\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	lexical\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagmetric	)\tagSENT_CONTENT	tag\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	arc\tagSENT_CONTENT	label\tagSENT_CONTENT	similarities\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	continuous\tagSENT_CONTENT	space\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	combine\tagSENT_CONTENT	the\tagSENT_CONTENT	representational\tagSENT_CONTENT	power\tagSENT_CONTENT	of\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	superior\tagSENT_CONTENT	search\tagSENT_CONTENT	enabled\tagSENT_CONTENT	by\tagSENT_CONTENT	structured\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	inference\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	our\tagSENT_CONTENT	parser\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	to\tagSENT_CONTENT	date\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	representations\tagSENT_CONTENT	have\tagSENT_CONTENT	along\tagSENT_CONTENT	history\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	network\tagSENT_CONTENT	avoids\tagSENT_CONTENT	any\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	structure\tagSENT_CONTENT	so\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	keep\tagSENT_CONTENT	inference\tagSENT_CONTENT	fast\tagSENT_CONTENT	and\tagSENT_CONTENT	efficient\tagSENT_CONTENT	and\tagSENT_CONTENT	to\tagSENT_CONTENT	allow\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	simple\tagSENT_CONTENT	backpropagation\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	gradients\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	final\tagSENT_CONTENT	greedy\tagSENT_CONTENT	parser\tagSENT_CONTENT	achieves\tagSENT_CONTENT	an\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	attachment\tagSENT_CONTENT	score\tagSENT_CONTENT	(\tagSENT_CONTENT	UAS\tagmetric	)\tagSENT_CONTENT	of\tagSENT_CONTENT	93.46\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	abeam\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	8\tagSENT_CONTENT	produces\tagSENT_CONTENT	an\tagSENT_CONTENT	UAS\tagSENT_CONTENT	of\tagSENT_CONTENT	94.08\tagSENT_CONTENT	%\tagSENT_CONTENT	(\tagSENT_CONTENT	section\tagSENT_CONTENT	4\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSENT_START	network\tagSENT_CONTENT	representations\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	structured\tagSENT_CONTENT	models\tagSENT_CONTENT	before\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	alas\tagSENT_CONTENT	with\tagSENT_CONTENT	fairly\tagSENT_CONTENT	complex\tagSENT_CONTENT	architectures\tagSENT_CONTENT	and\tagSENT_CONTENT	constraints\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Network\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	separate\tagSENT_CONTENT	dependency_parsing\tagtask	to\tagSENT_CONTENT	a\tagSENT_CONTENT	distinct\tagSENT_CONTENT	"\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	"\tagSENT_CONTENT	for\tagSENT_CONTENT	clarity\tagSENT_CONTENT	of\tagSENT_CONTENT	presentation\tagSENT_CONTENT	.\tagSENT_END	Configuration\tagSECTITLE_END	Softmax\tagSECTITLE_START	Layer\tagSECTITLE_END	Input\tagSECTITLE_START	layer\tagSECTITLE_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	group\tagSENT_CONTENT	these\tagSENT_CONTENT	features\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	input\tagSENT_CONTENT	source\tagSENT_CONTENT	:\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagmetric	tags\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	arc\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	two\tagSENT_CONTENT	elements\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	arc\tagSENT_CONTENT	features\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	four\tagSENT_CONTENT	tokens\tagSENT_CONTENT	on\tagSENT_CONTENT	stack\tagSENT_CONTENT	and\tagSENT_CONTENT	buffer\tagSENT_CONTENT	for\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	tags\tagmetric	and\tagSENT_CONTENT	arc\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	tends\tagSENT_START	this\tagSENT_CONTENT	line\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	setting\tagSENT_CONTENT	of\tagSENT_CONTENT	inexact\tagSENT_CONTENT	search\tagSENT_CONTENT	with\tagSENT_CONTENT	beam\tagSENT_CONTENT	decoding\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	;\tagSENT_CONTENT	concurrently\tagSENT_CONTENT	explored\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	approach\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	ranking\tagSENT_CONTENT	objective\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Network\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	separate\tagSENT_CONTENT	dependency_parsing\tagtask	to\tagSENT_CONTENT	a\tagSENT_CONTENT	distinct\tagSENT_CONTENT	"\tagSENT_CONTENT	embedding\tagSENT_CONTENT	layer\tagSENT_CONTENT	"\tagSENT_CONTENT	for\tagSENT_CONTENT	clarity\tagSENT_CONTENT	of\tagSENT_CONTENT	presentation\tagSENT_CONTENT	.\tagSENT_END	Input\tagSECTITLE_START	layer\tagSECTITLE_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	group\tagSENT_CONTENT	these\tagSENT_CONTENT	features\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	input\tagSENT_CONTENT	source\tagSENT_CONTENT	:\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	POS\tagmetric	tags\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	arc\tagSENT_CONTENT	labels\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	all\tagSENT_CONTENT	feature\tagSENT_CONTENT	groups\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	additional\tagSENT_CONTENT	special\tagSENT_CONTENT	values\tagSENT_CONTENT	for\tagSENT_CONTENT	"\tagSENT_CONTENT	ROOT\tagSENT_CONTENT	"\tagSENT_CONTENT	(\tagSENT_CONTENT	indicating\tagSENT_CONTENT	the\tagmetric	POS\tagmetric	or\tagSENT_CONTENT	word\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	root\tagSENT_CONTENT	token\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	NULL\tagSENT_CONTENT	"\tagSENT_END	Embedding\tagSECTITLE_START	layer\tagSECTITLE_END	Hidden\tagSECTITLE_START	layers\tagSECTITLE_END	Relu\tagSENT_START	layers\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	well\tagSENT_CONTENT	studied\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	literature\tagSENT_CONTENT	and\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	work\tagSENT_CONTENT	well\tagSENT_CONTENT	fora\tagSENT_CONTENT	wide\tagSENT_CONTENT	domain\tagSENT_CONTENT	of\tagSENT_CONTENT	problems\tagmetric	(\tagSENT_CONTENT	.\tagSENT_END	Relationship\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Chen\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Manning\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	2014\tagSECTITLE_CONTENT	)\tagSECTITLE_END	(\tagSENT_START	1\tagSENT_CONTENT	)\tagSENT_CONTENT	we\tagSENT_CONTENT	allow\tagSENT_CONTENT	for\tagSENT_CONTENT	much\tagSENT_CONTENT	smaller\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	POS\tagmetric	tags\tagmetric	and\tagSENT_CONTENT	labels\tagmetric	,\tagSENT_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Supervised\tagSECTITLE_CONTENT	Structured\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	In\tagSENT_START	both\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	soft\tagSENT_CONTENT	-\tagSENT_CONTENT	max\tagSENT_CONTENT	function\tagSENT_CONTENT	taking\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	input\tagSENT_CONTENT	:\tagSENT_END	i\tagSENT_START	dimensional\tagSENT_CONTENT	vector\tagSENT_CONTENT	of\tagSENT_CONTENT	weights\tagSENT_CONTENT	for\tagSENT_CONTENT	Backpropagation\tagSECTITLE_START	Pretraining\tagSECTITLE_END	In\tagSENT_START	addition\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	we\tagSENT_CONTENT	did\tagSENT_CONTENT	not\tagSENT_CONTENT	tune\tagSENT_CONTENT	the\tagSENT_CONTENT	regularization\tagSENT_CONTENT	parameter\tagSENT_CONTENT	λ\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	exponential\tagSENT_CONTENT	step\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	decay\tagSENT_CONTENT	to\tagSENT_CONTENT	η\tagSENT_CONTENT	t\tagSENT_CONTENT	;\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	γ\tagSENT_CONTENT	rounds\tagSENT_CONTENT	of\tagSENT_CONTENT	updates\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	multiply\tagSENT_CONTENT	η\tagSENT_CONTENT	t\tagSENT_CONTENT	=\tagSENT_CONTENT	0.96η\tagSENT_END	Structured\tagSECTITLE_START	Perceptron\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	Y\tagSENT_CONTENT	to\tagSENT_CONTENT	denote\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	decisions\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	to\tagSENT_CONTENT	continue\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	backpropagation\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	φ(x\tagSENT_CONTENT	,\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	during\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	training\tagSENT_CONTENT	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	using\tagSENT_CONTENT	ASGD\tagmetric	to\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	representation\tagSENT_CONTENT	always\tagSENT_CONTENT	led\tagSENT_CONTENT	to\tagSENT_CONTENT	faster\tagSENT_CONTENT	,\tagSENT_CONTENT	more\tagSENT_CONTENT	accurate\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	preliminary\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	left\tagSENT_CONTENT	further\tagSENT_CONTENT	investigation\tagSENT_CONTENT	for\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	Incorporating\tagSECTITLE_START	Unlabeled\tagSECTITLE_CONTENT	Data\tagSECTITLE_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	a\tagSENT_CONTENT	CRF\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagger\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	5-fold\tagSENT_CONTENT	jack\tagSENT_CONTENT	-\tagSENT_CONTENT	knifed\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	predicted\tagSENT_CONTENT	tags\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	dev\tagSENT_CONTENT	,\tagSENT_CONTENT	test\tagSENT_CONTENT	and\tagSENT_CONTENT	tune\tagSENT_CONTENT	sets\tagSENT_CONTENT	;\tagSENT_CONTENT	our\tagSENT_CONTENT	tagger\tagSENT_CONTENT	gets\tagSENT_CONTENT	comparable\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagger\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	97.44\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	increases\tagSENT_CONTENT	Method\tagSECTITLE_END	UAS\tagSECTITLE_START	LAS\tagSECTITLE_CONTENT	Beam\tagSECTITLE_END	Graph\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_END	Model\tagSECTITLE_START	Initialization\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	Hyperparameters\tagSECTITLE_END	Graph\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	These\tagSENT_START	parsers\tagSENT_CONTENT	use\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	are\tagSENT_CONTENT	therefore\tagSENT_CONTENT	not\tagSENT_CONTENT	directly\tagSENT_CONTENT	comparable\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	We\tagSENT_START	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	UAS\tagmetric	as\tagSENT_CONTENT	we\tagSENT_CONTENT	found\tagSENT_CONTENT	the\tagSENT_CONTENT	LAS\tagSENT_CONTENT	scores\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	strongly\tagSENT_CONTENT	correlated\tagSENT_CONTENT	.\tagSENT_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	Structure\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	 \tagSENT_CONTENT	Figure\tagSENT_CONTENT	2\tagSENT_CONTENT	:\tagSENT_CONTENT	Effect\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	on\tagSENT_CONTENT	variance\tagSENT_CONTENT	of\tagSENT_CONTENT	random\tagSENT_CONTENT	restarts\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	any\tagSENT_CONTENT	given\tagSENT_CONTENT	experiment\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	ran\tagSENT_CONTENT	multiple\tagSENT_CONTENT	random\tagSENT_CONTENT	restarts\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	our\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	and\tagSENT_CONTENT	picked\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	performed\tagSENT_CONTENT	best\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	tune\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Pre\tagSECTITLE_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Structured\tagSECTITLE_CONTENT	Perceptron\tagSECTITLE_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Tri\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	Error\tagSECTITLE_START	Analysis\tagSECTITLE_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	:\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	parser\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	structured\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	and\tagSENT_CONTENT	ASGD\tagSENT_CONTENT	.\tagSENT_END	
P15-1089	title\tagSECTITLE_END	lexical_normalization\tagtask	with\tagSENT_CONTENT	Syllables\tagSENT_END	abstract\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	syllable\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	method\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	to\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	cognitive\tagSENT_CONTENT	process\tagSENT_CONTENT	of\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	word\tagSENT_CONTENT	creation\tagSENT_CONTENT	in\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	.\tagSENT_END	Novelty\tagSENT_START	of\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	threefold\tagSENT_CONTENT	:\tagSENT_CONTENT	First\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	early\tagSENT_CONTENT	attempt\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	syllables\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	lexical_normalization\tagtask	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	samples\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	it\tagSENT_CONTENT	much\tagSENT_CONTENT	easier\tagSENT_CONTENT	to\tagSENT_CONTENT	adapt\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	any\tagSENT_CONTENT	period\tagSENT_CONTENT	of\tagSENT_CONTENT	history\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	third\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	a\tagSENT_CONTENT	series\tagSENT_CONTENT	of\tagSENT_CONTENT	experiments\tagSENT_CONTENT	and\tagSENT_CONTENT	prove\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	is\tagSENT_CONTENT	advantageous\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	solutions\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	lexical_normalization\tagtask	poses\tagSENT_CONTENT	challenges\tagSENT_CONTENT	when\tagSENT_CONTENT	performing\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	tasks\tagSENT_CONTENT	)\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	such\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	,\tagSENT_CONTENT	aiming\tagSENT_CONTENT	at\tagSENT_CONTENT	converting\tagSENT_CONTENT	these\tagSENT_CONTENT	OOV\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	words\tagSENT_CONTENT	into\tagSENT_CONTENT	their\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	(\tagSENT_CONTENT	IV\tagSENT_CONTENT	)\tagSENT_CONTENT	formal\tagSENT_CONTENT	forms\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	therefore\tagSENT_CONTENT	viewed\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	important\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Researchers\tagSENT_START	focus\tagSENT_CONTENT	their\tagSENT_CONTENT	studies\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	at\tagSENT_CONTENT	different\tagSENT_CONTENT	levels\tagSENT_CONTENT	.\tagSENT_END	Challenges\tagSENT_START	are\tagSENT_CONTENT	encountered\tagSENT_CONTENT	in\tagSENT_CONTENT	these\tagSENT_CONTENT	different\tagSENT_CONTENT	levels\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	characterlevel\tagSENT_CONTENT	sequential\tagSENT_CONTENT	labeling\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	required\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	character\tagSENT_CONTENT	and\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	noise\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	later\tagSENT_CONTENT	reverse\tagSENT_CONTENT	table\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	process\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	strict\tagSENT_CONTENT	restriction\tagSENT_CONTENT	can\tagSENT_CONTENT	result\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	great\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	construction\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	loss\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	lexical_normalization\tagtask	can\tagSENT_CONTENT	not\tagSENT_CONTENT	properly\tagSENT_CONTENT	model\tagSENT_CONTENT	how\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	formed\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	some\tagSENT_CONTENT	patterns\tagSENT_CONTENT	or\tagSENT_CONTENT	consistencies\tagSENT_CONTENT	within\tagSENT_CONTENT	words\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	omitted\tagSENT_CONTENT	and\tagSENT_CONTENT	altered\tagSENT_CONTENT	.\tagSENT_END	Inspired\tagSENT_START	by\tagSENT_CONTENT	this\tagSENT_CONTENT	cognitive\tagSENT_CONTENT	observation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	nonstandard\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	first\tagSENT_CONTENT	segmented\tagSENT_CONTENT	into\tagSENT_CONTENT	syllables\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	empirical\tagSENT_CONTENT	study\tagSENT_CONTENT	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	syllable\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	proper\tagSENT_CONTENT	level\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	lexical_normalization\tagtask	utilizes\tagSENT_CONTENT	effective\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	:\tagSENT_END	(\tagSENT_START	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Like\tagSENT_CONTENT	characterlevel\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	capture\tagSENT_CONTENT	lexical_normalization\tagtask	about\tagSENT_CONTENT	how\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	words\tagSENT_CONTENT	are\tagSENT_CONTENT	generated\tagSENT_CONTENT	;\tagSENT_END	This\tagSENT_START	makes\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	extendable\tagSENT_CONTENT	to\tagSENT_CONTENT	lexical_normalization\tagtask	or\tagSENT_CONTENT	domains\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	rest\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	organized\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	lexical_normalization\tagtask	are\tagSENT_CONTENT	reviewed\tagSENT_CONTENT	and\tagSENT_CONTENT	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	lexical_normalization\tagtask	of\tagSENT_CONTENT	an\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	word\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_END	lexical_normalization\tagtask	in\tagSENT_CONTENT	existence\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	procedure\tagSENT_CONTENT	:\tagSENT_CONTENT	candidates\tagSENT_CONTENT	are\tagSENT_CONTENT	first\tagSENT_CONTENT	generated\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	put\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	to\tagSENT_CONTENT	check\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	reasonable\tagSENT_CONTENT	sentence\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	formed\tagSENT_CONTENT	.\tagSENT_END	Orthographical\tagSECTITLE_START	similarity\tagSECTITLE_END	Phonetic\tagSECTITLE_START	similarity\tagSECTITLE_END	Contextual\tagSECTITLE_START	similarity\tagSECTITLE_END	Most\tagSENT_START	researchers\tagSENT_CONTENT	use\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	normalize\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	several\tagSENT_CONTENT	researches\tagSENT_CONTENT	use\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	phonebased\tagSENT_CONTENT	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	Li\tagSENT_CONTENT	and\tagSENT_CONTENT	Liu\tagSENT_CONTENT	,\tagSENT_CONTENT	2012b\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	and\tagSENT_CONTENT	lexical_normalization\tagtask	were\tagSENT_CONTENT	treated\tagSENT_CONTENT	separately\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	candidates\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	(\tagSENT_CONTENT	Han\tagSENT_CONTENT	and\tagSENT_CONTENT	Baldwin\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	candidates\tagSENT_CONTENT	from\tagSENT_CONTENT	lexical_normalization\tagtask	and\tagSENT_CONTENT	phonemic\tagSENT_CONTENT	edit\tagSENT_CONTENT	distance\tagSENT_CONTENT	are\tagSENT_CONTENT	merged\tagSENT_CONTENT	together\tagSENT_CONTENT	.\tagSENT_END	But\tagSENT_START	improper\tagSENT_CONTENT	processing\tagSENT_CONTENT	level\tagSENT_CONTENT	makes\tagSENT_CONTENT	it\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	model\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	simultaneously\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Single\tagSENT_CONTENT	character\tagSENT_CONTENT	can\tagSENT_CONTENT	hardly\tagSENT_CONTENT	reflect\tagSENT_CONTENT	orthographical\tagSENT_CONTENT	features\tagSENT_CONTENT	of\tagSENT_CONTENT	one\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	Approach\tagSECTITLE_END	Framework\tagSECTITLE_END	(\tagSENT_START	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Combination\tagSENT_CONTENT	:\tagSENT_CONTENT	When\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	will\tagSENT_CONTENT	occur\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	mind\tagSENT_CONTENT	.\tagSENT_END	And\tagSENT_START	also\tagSENT_CONTENT	,\tagSENT_CONTENT	because\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	fast\tagSENT_CONTENT	,\tagSENT_CONTENT	people\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	ignore\tagSENT_CONTENT	some\tagSENT_CONTENT	minor\tagSENT_CONTENT	flaws\tagSENT_CONTENT	in\tagSENT_CONTENT	spelling\tagSENT_CONTENT	intentionally\tagSENT_CONTENT	or\tagSENT_CONTENT	unintentionally\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	this\tagSENT_CONTENT	often\tagSENT_CONTENT	occurs\tagSENT_CONTENT	in\tagSENT_CONTENT	people\tagSENT_CONTENT	's\tagSENT_CONTENT	real\tagSENT_CONTENT	-\tagSENT_CONTENT	life\tagSENT_CONTENT	interacting\tagSENT_CONTENT	with\tagSENT_CONTENT	these\tagSENT_CONTENT	social\tagSENT_CONTENT	media\tagSENT_CONTENT	language\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	and\tagSENT_CONTENT	orthographical\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	great\tagSENT_CONTENT	significance\tagSENT_CONTENT	.\tagSENT_END	Inspired\tagSENT_START	by\tagSENT_CONTENT	lexical_normalization\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	pinyin\tagSENT_CONTENT	(\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	transcripts\tagSENT_CONTENT	of\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	syllable\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	as\tagSENT_CONTENT	basic\tagSENT_CONTENT	unit\tagSENT_CONTENT	when\tagSENT_CONTENT	processing\tagSENT_CONTENT	pronunciation\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	candidates\tagSENT_CONTENT	are\tagSENT_CONTENT	generated\tagSENT_CONTENT	and\tagSENT_CONTENT	weighted\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	Viterbi\tagSENT_CONTENT	decoder\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Method\tagSECTITLE_END	lexical_normalization\tagtask	grows\tagSENT_CONTENT	tremendously\tagSENT_CONTENT	as\tagSENT_CONTENT	its\tagSENT_CONTENT	argument\tagSENT_CONTENT	increases\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	much\tagSENT_CONTENT	more\tagSENT_CONTENT	weight\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	assigned\tagSENT_CONTENT	if\tagSENT_CONTENT	syllables\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	similar\tagSENT_CONTENT	.\tagSENT_END	Description\tagSECTITLE_END	Rules\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	lexical_normalization\tagtask	between\tagSENT_CONTENT	suffix\tagSENT_CONTENT	z\tagSENT_CONTENT	and\tagSENT_CONTENT	scan\tagSENT_CONTENT	always\tagSENT_CONTENT	happen\tagSENT_CONTENT	,\tagSENT_CONTENT	PED(plz\tagSENT_CONTENT	,\tagSENT_CONTENT	please\tagSENT_CONTENT	)\tagSENT_CONTENT	equals\tagSENT_CONTENT	string\tagSENT_CONTENT	edit\tagSENT_CONTENT	distance\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	transcripts\tagSENT_CONTENT	.\tagSENT_END	But\tagSENT_START	as\tagSENT_CONTENT	lexical_normalization\tagtask	off\tagSENT_CONTENT	and\tagSENT_CONTENT	dis\tagSENT_CONTENT	rare\tagSENT_CONTENT	,\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	distance\tagSENT_CONTENT	of\tagSENT_CONTENT	fly\tagSENT_CONTENT	and\tagSENT_CONTENT	sky\tagSENT_CONTENT	is\tagSENT_CONTENT	assigned\tagSENT_CONTENT	infinity\tagSENT_CONTENT	.\tagSENT_END	Parameter\tagSECTITLE_END	Implementation\tagSECTITLE_END	Preprocessing\tagSECTITLE_END	Before\tagSENT_START	performing\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	process\tagSENT_CONTENT	several\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	words\tagSENT_CONTENT	:\tagSENT_END	Letter\tagSECTITLE_START	-\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	sound\tagSECTITLE_CONTENT	conversion\tagSECTITLE_END	But\tagSENT_START	it\tagSENT_CONTENT	uses\tagSENT_CONTENT	consonants\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	gives\tagSENT_CONTENT	lexical_normalization\tagtask	than\tagSENT_CONTENT	we\tagSENT_CONTENT	need\tagSENT_CONTENT	.\tagSENT_END	Dictionary\tagSECTITLE_START	preparation\tagSECTITLE_END	Automatic\tagSECTITLE_START	syllabification\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	non\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	standard\tagSECTITLE_CONTENT	words\tagSECTITLE_END	Language\tagSECTITLE_START	model\tagSECTITLE_END	Evaluation\tagSECTITLE_END	Datasets\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	two\tagSENT_CONTENT	labeled\tagSENT_CONTENT	twitter\tagSENT_CONTENT	datasets\tagSENT_CONTENT	in\tagSENT_CONTENT	existence\tagSENT_CONTENT	to\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Evaluation\tagSECTITLE_START	criteria\tagSECTITLE_END	As\tagSENT_START	lexical_normalization\tagtask	on\tagSENT_CONTENT	these\tagSENT_CONTENT	datasets\tagSENT_CONTENT	focused\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	labeled\tagSENT_CONTENT	nonstandard\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	recall\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	requiring\tagSENT_CONTENT	lexical_normalization\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	normalized\tagSENT_CONTENT	correctly\tagSENT_CONTENT	;\tagSENT_CONTENT	precision\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	proportion\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	lexical_normalization\tagtask	,\tagSENT_CONTENT	every\tagSENT_CONTENT	error\tagSENT_CONTENT	is\tagSENT_CONTENT	both\tagSENT_CONTENT	a\tagSENT_CONTENT	false\tagSENT_CONTENT	positive\tagSENT_CONTENT	and\tagSENT_CONTENT	false\tagSENT_CONTENT	negative\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	precision\tagSENT_CONTENT	equals\tagSENT_CONTENT	to\tagSENT_CONTENT	recall\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	level\tagSECTITLE_CONTENT	normalization\tagSECTITLE_END	We\tagSENT_START	choose\tagSENT_CONTENT	lexical_normalization\tagtask	:\tagSENT_END	bipartite\tagSENT_START	graph\tagSENT_CONTENT	major\tagSENT_CONTENT	exploit\tagSENT_CONTENT	contextual\tagSENT_CONTENT	similarity\tagSENT_CONTENT	;\tagSENT_CONTENT	:\tagSENT_CONTENT	Experiment\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	the\tagSENT_START	orthographyphone\tagSENT_CONTENT	combined\tagSENT_CONTENT	system\tagSENT_CONTENT	using\tagSENT_CONTENT	lexical_normalization\tagtask	and\tagSENT_CONTENT	phonemic\tagSENT_CONTENT	edit\tagSENT_CONTENT	distance\tagSENT_CONTENT	.\tagSENT_END	Recall\tagSENT_START	we\tagSENT_CONTENT	argue\tagSENT_CONTENT	that\tagSENT_CONTENT	lexical_normalization\tagtask	of\tagSENT_CONTENT	three\tagSENT_CONTENT	similarity\tagSENT_CONTENT	is\tagSENT_CONTENT	necessary\tagSENT_CONTENT	when\tagSENT_CONTENT	performing\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Apart\tagSENT_START	from\tagSENT_CONTENT	contextual\tagSENT_CONTENT	similarity\tagSENT_CONTENT	like\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	or\tagSENT_CONTENT	graphic\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	(\tagSENT_CONTENT	Hassan\tagSENT_CONTENT	and\tagSENT_CONTENT	Menezes\tagSENT_CONTENT	,\tagSENT_CONTENT	2013\tagSENT_CONTENT	)\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	include\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	measure\tagSENT_CONTENT	,\tagSENT_CONTENT	causing\tagSENT_CONTENT	loss\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	Like\tagSENT_START	(\tagSENT_CONTENT	Han\tagSENT_CONTENT	and\tagSENT_CONTENT	Baldwin\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	use\tagSENT_CONTENT	lexical_normalization\tagtask	and\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	measure\tagSENT_CONTENT	.\tagSENT_END	Contributions\tagSECTITLE_START	of\tagSECTITLE_CONTENT	phone\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	orthography\tagSECTITLE_END	This\tagSENT_START	justifies\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	combining\tagSENT_CONTENT	orthographical\tagSENT_CONTENT	and\tagSENT_CONTENT	phonetic\tagSENT_CONTENT	measure\tagSENT_CONTENT	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	that\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	properly\tagSENT_CONTENT	modeled\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Our\tagSECTITLE_START	exceptions\tagSECTITLE_END	Deeper\tagSENT_START	observation\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	several\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	exceptions\tagSENT_CONTENT	beyond\tagSENT_CONTENT	our\tagSENT_CONTENT	consonant\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	rules\tagSENT_CONTENT	.\tagSENT_END	Non\tagSECTITLE_START	-\tagSECTITLE_CONTENT	standard\tagSECTITLE_CONTENT	words\tagSECTITLE_CONTENT	involving\tagSECTITLE_CONTENT	multiple\tagSECTITLE_CONTENT	syllables\tagSECTITLE_END	Annotation\tagSECTITLE_START	issue\tagSECTITLE_END	Conventions\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	observed\tagSENT_CONTENT	lexical_normalization\tagtask	like\tagSENT_CONTENT	atl\tagSENT_CONTENT	/\tagSENT_CONTENT	atlanta\tagSENT_CONTENT	or\tagSENT_CONTENT	wx\tagSENT_CONTENT	/\tagSENT_CONTENT	weather\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical_normalization\tagtask	pose\tagSENT_CONTENT	great\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	to\tagSENT_CONTENT	us\tagSENT_CONTENT	.\tagSENT_END	lexical_normalization\tagtask	of\tagSENT_CONTENT	those\tagSENT_CONTENT	conventional\tagSENT_CONTENT	nonstandard\tagSENT_CONTENT	words\tagSENT_CONTENT	still\tagSENT_CONTENT	needs\tagSENT_CONTENT	further\tagSENT_CONTENT	study\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical_normalization\tagtask	is\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	lexical_normalization\tagtask	.\tagSENT_END	
D10-1117	title\tagSECTITLE_END	Unsupervised\tagSENT_START	Induction\tagSENT_CONTENT	of\tagSENT_CONTENT	Tree\tagSENT_CONTENT	Substitution\tagSENT_CONTENT	Grammars\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	abstract\tagSECTITLE_END	Significant\tagSENT_START	progress\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	made\tagSENT_CONTENT	for\tagSENT_CONTENT	inducing\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	however\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	employed\tagSENT_CONTENT	are\tagSENT_CONTENT	overly\tagSENT_CONTENT	simplistic\tagSENT_CONTENT	,\tagSENT_CONTENT	particularly\tagSENT_CONTENT	in\tagSENT_CONTENT	comparison\tagSENT_CONTENT	to\tagSENT_CONTENT	supervised\tagSENT_CONTENT	parsing\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	an\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency\tagSENT_CONTENT	grammar\tagSENT_CONTENT	induction\tagSENT_CONTENT	using\tagSENT_CONTENT	tree\tagSENT_CONTENT	substitution\tagSENT_CONTENT	grammar\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	thereby\tagSENT_CONTENT	better\tagSENT_CONTENT	modelling\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	However\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	induction\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	has\tagSENT_CONTENT	proved\tagSENT_CONTENT	more\tagSENT_CONTENT	fruitful\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	grammars\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	easier\tagSENT_CONTENT	to\tagSENT_CONTENT	induce\tagSENT_CONTENT	from\tagSENT_CONTENT	text\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	structure\tagSENT_CONTENT	grammars\tagSENT_CONTENT	because\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	labels\tagSENT_CONTENT	(\tagSENT_CONTENT	heads\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	directly\tagSENT_CONTENT	observed\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	allows\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	dependency_parsing\tagtask	to\tagSENT_CONTENT	best\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	prior\tagSENT_CONTENT	biasing\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	towards\tagSENT_CONTENT	fewer\tagSENT_CONTENT	and\tagSENT_CONTENT	smaller\tagSENT_CONTENT	grammar\tagSENT_CONTENT	productions\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	adopt\tagSENT_CONTENT	the\tagSENT_CONTENT	split\tagSENT_CONTENT	-\tagSENT_CONTENT	head\tagSENT_CONTENT	construction\tagSENT_CONTENT	to\tagSENT_CONTENT	map\tagSENT_CONTENT	dependency_parsing\tagtask	to\tagSENT_CONTENT	context\tagSENT_CONTENT	free\tagSENT_CONTENT	grammar\tagSENT_CONTENT	(\tagSENT_CONTENT	CFG\tagSENT_CONTENT	)\tagSENT_CONTENT	derivations\tagSENT_CONTENT	,\tagSENT_CONTENT	over\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	TSG\tagSENT_CONTENT	induction\tagSENT_CONTENT	.\tagSENT_END	CFG\tagSECTITLE_START	Rule\tagSECTITLE_END	DMV\tagSECTITLE_START	Distribution\tagSECTITLE_CONTENT	Description\tagSECTITLE_END	Land\tagSENT_START	R\tagSENT_CONTENT	indicates\tagSENT_CONTENT	dependency_parsing\tagtask	left\tagSENT_CONTENT	or\tagSENT_CONTENT	right\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	parent\tagSENT_CONTENT	;\tagSENT_CONTENT	superscripts\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	stopping\tagSENT_CONTENT	and\tagSENT_CONTENT	valency\tagSENT_CONTENT	distributions\tagSENT_CONTENT	,\tagSENT_CONTENT	X\tagSENT_CONTENT	1\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	will\tagSENT_CONTENT	continue\tagSENT_CONTENT	to\tagSENT_CONTENT	attach\tagSENT_CONTENT	more\tagSENT_CONTENT	children\tagSENT_CONTENT	and\tagSENT_CONTENT	X\tagSENT_CONTENT	*\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	already\tagSENT_CONTENT	attached\tagSENT_CONTENT	a\tagSENT_CONTENT	child\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	The\tagSENT_START	most\tagSENT_CONTENT	successful\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	dependency_parsing\tagtask	with\tagSENT_CONTENT	Valence\tagSENT_CONTENT	(\tagSENT_CONTENT	DMV\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	model\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	adapted\tagSENT_CONTENT	and\tagSENT_CONTENT	extended\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	authors\tagSENT_CONTENT	and\tagSENT_CONTENT	currently\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	stateof\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	employ\tagSENT_CONTENT	the\tagSENT_CONTENT	related\tagSENT_CONTENT	fold\tagSENT_CONTENT	-\tagSENT_CONTENT	unfold\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	Johnson\tagSENT_CONTENT	(\tagSENT_CONTENT	2007\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	defines\tagSENT_CONTENT	a\tagSENT_CONTENT	CFG\tagSENT_CONTENT	equivalent\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	splithead\tagSENT_CONTENT	parsing\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	,\tagSENT_CONTENT	allowing\tagSENT_CONTENT	us\tagmetric	to\tagSENT_CONTENT	easily\tagSENT_CONTENT	adapt\tagSENT_CONTENT	CFG\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	grammar\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency\tagSENT_CONTENT	grammar\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	grammar\tagSENT_CONTENT	allows\tagSENT_CONTENT	O(|w|\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	parsing\tagSENT_CONTENT	complexity\tagSENT_CONTENT	which\tagSENT_CONTENT	follows\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	terminals\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	being\tagSENT_CONTENT	observed\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	parse\tagSENT_CONTENT	chart\tagSENT_CONTENT	uniquely\tagSENT_CONTENT	specifies\tagSENT_CONTENT	its\tagSENT_CONTENT	possible\tagSENT_CONTENT	heads\tagSENT_CONTENT	(\tagSENT_CONTENT	either\tagSENT_CONTENT	the\tagSENT_CONTENT	leftmost\tagSENT_CONTENT	,\tagSENT_CONTENT	rightmost\tagSENT_CONTENT	or\tagSENT_CONTENT	both\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	possible\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	terminals\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	span\tagSENT_CONTENT	is\tagSENT_CONTENT	constant\tagSENT_CONTENT	.\tagSENT_END	showed\tagSENT_START	that\tagSENT_CONTENT	performance\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	improved\tagSENT_CONTENT	by\tagSENT_CONTENT	including\tagSENT_CONTENT	high\tagSENT_CONTENT	frequency\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	tags\tagmetric	in\tagSENT_CONTENT	their\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	rule\tagSENT_CONTENT	encodes\tagSENT_CONTENT	dependency_parsing\tagtask	between\tagSENT_CONTENT	the\tagSENT_CONTENT	subject\tagSENT_CONTENT	and\tagSENT_CONTENT	object\tagSENT_CONTENT	of\tagSENT_CONTENT	hates\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	CFG\tagSENT_CONTENT	-\tagSENT_CONTENT	DMV\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	inserted\tagSENT_CONTENT	using\tagSENT_CONTENT	additional\tagSENT_CONTENT	rules\tagSENT_CONTENT	below\tagSENT_CONTENT	the\tagSENT_CONTENT	M\tagSENT_CONTENT	/\tagSENT_CONTENT	L\tagSENT_CONTENT	/\tagSENT_CONTENT	R\tagSENT_CONTENT	frontier\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	terminals\tagSENT_CONTENT	.\tagSENT_END	Lexicalised\tagSECTITLE_START	TSG\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	DMV\tagSECTITLE_END	shows\tagSENT_START	a\tagSENT_CONTENT	TSG\tagSENT_CONTENT	derivation\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	where\tagSENT_CONTENT	bold\tagSENT_CONTENT	nonterminal\tagSENT_CONTENT	labels\tagSENT_CONTENT	denote\tagSENT_CONTENT	substitution\tagSENT_CONTENT	sites\tagSENT_CONTENT	(\tagSENT_CONTENT	root\tagSENT_CONTENT	/\tagSENT_CONTENT	frontier\tagSENT_CONTENT	nodes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	elementary\tagSENT_CONTENT	trees\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	involves\tagSENT_CONTENT	finding\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	probable\tagSENT_CONTENT	tree\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	string\tagSENT_CONTENT	(\tagSENT_CONTENT	arg\tagSENT_CONTENT	max\tagSENT_CONTENT	t\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	t|w\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Inference\tagSECTITLE_END	Training\tagSECTITLE_END	Sampling\tagSECTITLE_START	hyperparameters\tagSECTITLE_END	Parsing\tagSECTITLE_END	Experiments\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	we\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	of\tagSENT_CONTENT	section\tagSENT_CONTENT	23\tagSENT_CONTENT	,\tagSENT_CONTENT	without\tagSENT_CONTENT	dependency_parsing\tagtask	for\tagSENT_CONTENT	length\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	We\tagSENT_START	can\tagSENT_CONTENT	identify\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	differences\tagSENT_CONTENT	that\tagSENT_CONTENT	may\tagSENT_CONTENT	impact\tagSENT_CONTENT	these\tagSENT_CONTENT	results\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	Adaptor\tagSENT_CONTENT	Grammar\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	using\tagSENT_CONTENT	variational\tagSENT_CONTENT	inference\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	tree\tagSENT_CONTENT	fragments\tagSENT_CONTENT	truncated\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	a\tagSENT_CONTENT	sampler\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	nominally\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	tree\tagSENT_CONTENT	fragments\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	adapted\tagSENT_CONTENT	tree\tagSENT_CONTENT	fragments\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	complete\tagSENT_CONTENT	subtrees\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	they\tagSENT_CONTENT	do\tagSENT_CONTENT	n't\tagSENT_CONTENT	contain\tagSENT_CONTENT	variables\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	arbitrary\tagSENT_CONTENT	tree\tagSENT_CONTENT	fragments\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	further\tagSENT_CONTENT	analysis\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	at\tagSENT_CONTENT	predicting\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	for\tagSENT_CONTENT	frequent\tagSENT_CONTENT	types\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	various\tagSENT_CONTENT	lengths\tagSENT_CONTENT	.\tagSENT_END	Unsurprisingly\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	appears\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	more\tagSENT_CONTENT	accurate\tagSENT_CONTENT	when\tagSENT_CONTENT	predicting\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	result\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	reflected\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	per\tagSENT_CONTENT	type\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	.\tagSENT_END	Conjunctions\tagSENT_START	such\tagSENT_CONTENT	as\tagSENT_CONTENT	and\tagSENT_CONTENT	pose\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	when\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	dependency_parsing\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	modelling\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	remains\tagSENT_CONTENT	a\tagSENT_CONTENT	 \tagSENT_CONTENT	contentious\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	issue\tagSENT_END	Conclusion\tagSECTITLE_END	By\tagSENT_START	applying\tagSENT_CONTENT	these\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	induction\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	grammars\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	advance\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	increasing\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	attachment\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	section\tagSENT_CONTENT	23\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	Corpus\tagSENT_CONTENT	by\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	5\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	envisage\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	future\tagSENT_CONTENT	many\tagSENT_CONTENT	grammar\tagSENT_CONTENT	formalisms\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	effective\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	categorial\tagSENT_CONTENT	,\tagSENT_CONTENT	unification\tagSENT_CONTENT	and\tagSENT_CONTENT	tree\tagSENT_CONTENT	adjoining\tagSENT_CONTENT	grammars\tagSENT_CONTENT	,\tagSENT_CONTENT	will\tagSENT_CONTENT	prove\tagSENT_CONTENT	amenable\tagSENT_CONTENT	to\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	induction\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	nonparametric\tagSENT_CONTENT	modelling\tagSENT_CONTENT	approaches\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	
language_understanding_paper	title\tagSECTITLE_END	Improving\tagSENT_START	natural_language_inference\tagtask	by\tagSENT_CONTENT	Generative\tagSENT_CONTENT	Pre\tagSENT_CONTENT	-\tagSENT_CONTENT	Training\tagSENT_END	abstract\tagSECTITLE_END	natural_language_inference\tagtask	comprises\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	diverse\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	semantic\tagSENT_CONTENT	similarity\tagSENT_CONTENT	assessment\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	document\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	The\tagSENT_START	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	effectively\tagSENT_CONTENT	from\tagSENT_CONTENT	raw\tagSENT_CONTENT	text\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	to\tagSENT_CONTENT	alleviating\tagSENT_CONTENT	the\tagSENT_CONTENT	dependence\tagSENT_CONTENT	on\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	in\tagSENT_CONTENT	natural_language_inference\tagtask	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Recent\tagSENT_START	research\tagSENT_CONTENT	has\tagSENT_CONTENT	looked\tagSENT_CONTENT	at\tagSENT_CONTENT	various\tagSENT_CONTENT	objectives\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	natural_language_inference\tagtask	,\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	discourse\tagSENT_CONTENT	coherence\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	method\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	the\tagSENT_CONTENT	others\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	natural_language_inference\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	the\tagSENT_CONTENT	initial\tagSENT_CONTENT	parameters\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	shown\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	strongly\tagSENT_CONTENT	on\tagSENT_CONTENT	various\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	,\tagSENT_CONTENT	document\tagSENT_CONTENT	generation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Our\tagSENT_START	work\tagSENT_CONTENT	broadly\tagSENT_CONTENT	falls\tagSENT_CONTENT	under\tagSENT_CONTENT	the\tagSENT_CONTENT	category\tagSENT_CONTENT	of\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	for\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	The\tagSENT_START	closest\tagSENT_CONTENT	line\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	to\tagSENT_CONTENT	ours\tagSENT_CONTENT	involves\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	using\tagSENT_CONTENT	natural_language_inference\tagtask	and\tagSENT_CONTENT	then\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	it\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	target\tagSENT_CONTENT	task\tagSENT_CONTENT	with\tagSENT_CONTENT	supervision\tagSENT_CONTENT	.\tagSENT_END	Early\tagSENT_START	work\tagSENT_CONTENT	by\tagSENT_CONTENT	Collobert\tagSENT_CONTENT	and\tagSENT_CONTENT	Weston\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	natural_language_inference\tagtask	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeling\tagSENT_CONTENT	.\tagSENT_END	Framework\tagSECTITLE_END	Unsupervised\tagSECTITLE_START	pre\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	training\tagSECTITLE_END	Given\tagSENT_START	an\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	U\tagSENT_CONTENT	=\tagSENT_CONTENT	{\tagSENT_CONTENT	u\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	u\tagSENT_CONTENT	n\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	natural_language_inference\tagtask	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	:\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	Transformer\tagSENT_CONTENT	decoder\tagSENT_CONTENT	for\tagSENT_CONTENT	natural_language_inference\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	transformer\tagSENT_CONTENT	.\tagSENT_END	Supervised\tagSECTITLE_START	fine\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	tuning\tagSECTITLE_END	We\tagSENT_START	additionally\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	including\tagSENT_CONTENT	natural_language_inference\tagtask	as\tagSENT_CONTENT	an\tagSENT_CONTENT	auxiliary\tagSENT_CONTENT	objective\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	helped\tagSENT_CONTENT	learning\tagSENT_CONTENT	by\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_CONTENT	improving\tagSENT_CONTENT	generalization\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	supervised\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_END	Task\tagSECTITLE_START	-\tagSECTITLE_CONTENT	specific\tagSECTITLE_CONTENT	input\tagSECTITLE_CONTENT	transformations\tagSECTITLE_END	Certain\tagSENT_START	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	have\tagSENT_CONTENT	structured\tagSENT_CONTENT	inputs\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	ordered\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	triplets\tagSENT_CONTENT	of\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	answers\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	and\tagSENT_CONTENT	Commonsense\tagSENT_CONTENT	Reasoning\tagSENT_END	Experiments\tagSECTITLE_END	Setup\tagSECTITLE_END	Unsupervised\tagSENT_START	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	We\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	BooksCorpus\tagSENT_CONTENT	dataset\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	natural_language_inference\tagtask	.\tagSENT_END	Supervised\tagSECTITLE_START	fine\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	tuning\tagSECTITLE_END	We\tagSENT_START	perform\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	supervised\tagSENT_CONTENT	tasks\tagSENT_CONTENT	including\tagSENT_CONTENT	natural_language_inference\tagtask	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	semantic\tagSENT_CONTENT	similarity\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	text\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	Natural\tagSECTITLE_START	Language\tagSECTITLE_CONTENT	Inference\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	natural_language_inference\tagtask	(\tagSENT_CONTENT	NLI\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	also\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	recognizing\tagSENT_CONTENT	textual\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	involves\tagSENT_CONTENT	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	and\tagSENT_CONTENT	judging\tagSENT_CONTENT	the\tagSENT_CONTENT	relationship\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	from\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	contradiction\tagSENT_CONTENT	or\tagSENT_CONTENT	neutral\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	three\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	-the\tagSENT_CONTENT	Microsoft\tagSENT_CONTENT	Paraphrase\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	MRPC\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	collected\tagSENT_CONTENT	from\tagSENT_CONTENT	news\tagSENT_CONTENT	sources\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	QQP\tagSENT_CONTENT	)\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	Semantic\tagSENT_CONTENT	Textual\tagSENT_CONTENT	Similarity\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	(\tagSENT_CONTENT	STS\tagSENT_CONTENT	-\tagSENT_CONTENT	B\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	also\tagSENT_CONTENT	achieves\tagSENT_CONTENT	91.3\tagmetric	%\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	SST-2\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	competitive\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	illustrates\tagSENT_START	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	on\tagSENT_CONTENT	MultiNLI\tagdataset	and\tagSENT_CONTENT	RACE\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	function\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	layers\tagSENT_CONTENT	transferred\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	observe\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	result\tagSENT_CONTENT	that\tagSENT_CONTENT	transferring\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	improves\tagSENT_CONTENT	performance\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	transformer\tagSENT_CONTENT	layer\tagSENT_CONTENT	provides\tagSENT_CONTENT	further\tagSENT_CONTENT	benefits\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	9\tagSENT_CONTENT	%\tagSENT_CONTENT	for\tagSENT_CONTENT	full\tagSENT_CONTENT	transfer\tagSENT_CONTENT	on\tagSENT_CONTENT	MultiNLI\tagdataset	.\tagSENT_END	For\tagSENT_START	RACE\tagdataset	(\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	pick\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	the\tagSENT_CONTENT	generative\tagSENT_CONTENT	model\tagSENT_CONTENT	assigns\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	average\tagSENT_CONTENT	token\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	probability\tagSENT_CONTENT	when\tagSENT_CONTENT	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	introduced\tagSENT_CONTENT	a\tagSENT_CONTENT	framework\tagSENT_CONTENT	for\tagSENT_CONTENT	achieving\tagSENT_CONTENT	natural_language_inference\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	task\tagSENT_CONTENT	-\tagSENT_CONTENT	agnostic\tagSENT_CONTENT	model\tagSENT_CONTENT	through\tagSENT_CONTENT	generative\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	tuning\tagSENT_CONTENT	.\tagSENT_END	
1611.01734	title\tagSECTITLE_END	DEEP\tagSENT_START	BIAFFINE\tagSENT_CONTENT	ATTENTION\tagSENT_CONTENT	FOR\tagSENT_CONTENT	dependency_parsing\tagtask	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	builds\tagSENT_CONTENT	off\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	from\tagSENT_CONTENT	Kiperwasser\tagSENT_CONTENT	&\tagSENT_CONTENT	Goldberg\tagSENT_CONTENT	(\tagSENT_CONTENT	2016\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	neu\tagSENT_CONTENT	-\tagSENT_CONTENT	ral\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	dependency_parsing\tagtask	-\tagSENT_CONTENT	which\tagSENT_CONTENT	annotate\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	away\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	easy\tagSENT_CONTENT	for\tagSENT_CONTENT	humans\tagSENT_CONTENT	and\tagSENT_CONTENT	computers\tagSENT_CONTENT	alike\tagSENT_CONTENT	to\tagSENT_CONTENT	understand\tagSENT_CONTENT	-\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	found\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	extremely\tagSENT_CONTENT	useful\tagSENT_CONTENT	fora\tagSENT_CONTENT	sizable\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	those\tagSENT_CONTENT	involving\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	in\tagSENT_CONTENT	someway\tagSENT_CONTENT	.\tagSENT_END	BACKGROUND\tagSECTITLE_START	AND\tagSECTITLE_CONTENT	RELATED\tagSECTITLE_CONTENT	WORK\tagSECTITLE_END	Transition\tagSENT_START	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsers\tagSENT_CONTENT	-\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	shift\tagSENT_CONTENT	-\tagSENT_CONTENT	reduce\tagSENT_CONTENT	parsers\tagSENT_CONTENT	-\tagSENT_CONTENT	parse\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	left\tagSENT_CONTENT	to\tagSENT_CONTENT	right\tagSENT_CONTENT	,\tagSENT_CONTENT	maintaining\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	buffer\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	not\tagSENT_CONTENT	yet\tagSENT_CONTENT	been\tagSENT_CONTENT	parsed\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	stack\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	whose\tagSENT_CONTENT	head\tagSENT_CONTENT	has\tagSENT_CONTENT	not\tagSENT_CONTENT	been\tagSENT_CONTENT	seen\tagSENT_CONTENT	or\tagSENT_CONTENT	dependency_parsing\tagtask	have\tagSENT_CONTENT	not\tagSENT_CONTENT	all\tagSENT_CONTENT	been\tagSENT_CONTENT	fully\tagSENT_CONTENT	parsed\tagSENT_CONTENT	.\tagSENT_END	Chen\tagSENT_START	&\tagSENT_CONTENT	Manning\tagSENT_CONTENT	(\tagSENT_CONTENT	2014\tagSENT_CONTENT	)\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	successful\tagSENT_CONTENT	attempt\tagSENT_CONTENT	at\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	dependency_parsing\tagtask	into\tagSENT_CONTENT	a\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	dependency\tagSENT_CONTENT	parser\tagSENT_CONTENT	.\tagSENT_END	Labels\tagmetric	are\tagSENT_CONTENT	generated\tagSENT_CONTENT	analogously\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	's\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	output\tagSENT_CONTENT	vector\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	gold\tagSENT_CONTENT	or\tagSENT_CONTENT	predicted\tagSENT_CONTENT	head\tagSENT_CONTENT	word\tagSENT_CONTENT	's\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	vector\tagSENT_CONTENT	being\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	MLP\tagSENT_CONTENT	.\tagSENT_END	Similarly\tagSENT_START	,\tagSENT_CONTENT	include\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	their\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	neural\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	being\tagSENT_CONTENT	arguably\tagSENT_CONTENT	simpler\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	MLP\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	(\tagSENT_CONTENT	involving\tagSENT_CONTENT	one\tagSENT_CONTENT	bilinear\tagSENT_CONTENT	layer\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	two\tagSENT_CONTENT	linear\tagSENT_CONTENT	layers\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	nonlinearity\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	conceptual\tagSENT_CONTENT	advantage\tagSENT_CONTENT	of\tagSENT_CONTENT	directly\tagSENT_CONTENT	modeling\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	prior\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	j\tagSENT_CONTENT	receiving\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	term\tagSENT_CONTENT	r\tagSENT_END	This\tagSENT_START	likewise\tagSENT_CONTENT	directly\tagSENT_CONTENT	models\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	prior\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	class\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	class\tagmetric	given\tagSENT_CONTENT	just\tagSENT_CONTENT	word\tagSENT_END	We\tagSENT_START	apply\tagSENT_CONTENT	MLPs\tagmetric	to\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	states\tagSENT_CONTENT	before\tagSENT_CONTENT	using\tagSENT_CONTENT	them\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	classifier\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	HYPERPARAMETER\tagSECTITLE_START	CONFIGURATION\tagSECTITLE_END	EXPERIMENTS\tagSECTITLE_START	&\tagSECTITLE_CONTENT	RESULTS\tagSECTITLE_END	DATASETS\tagSECTITLE_END	We\tagSENT_START	show\tagSENT_CONTENT	test\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	English\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	,\tagSENT_CONTENT	converted\tagSENT_CONTENT	into\tagSENT_CONTENT	dependency_parsing\tagtask	using\tagSENT_CONTENT	both\tagSENT_CONTENT	version\tagSENT_CONTENT	3.3.0\tagSENT_CONTENT	and\tagSENT_CONTENT	version\tagSENT_CONTENT	3.5.0\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Stanford\tagSENT_CONTENT	Dependency\tagSENT_CONTENT	converter\tagSENT_CONTENT	(\tagSENT_CONTENT	PTB\tagSENT_CONTENT	-\tagSENT_CONTENT	SD\tagSENT_CONTENT	3.3.0\tagSENT_CONTENT	and\tagSENT_CONTENT	PTB\tagSENT_CONTENT	-\tagSENT_CONTENT	SD\tagSENT_CONTENT	3.5.0\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	09\tagSENT_CONTENT	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	3\tagSENT_CONTENT	following\tagSENT_CONTENT	standard\tagSENT_CONTENT	practices\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	HYPERPARAMETER\tagSECTITLE_START	CHOICES\tagSECTITLE_END	ATTENTION\tagSECTITLE_START	MECHANISM\tagSECTITLE_END	NETWORK\tagSECTITLE_START	SIZE\tagSECTITLE_END	In\tagSENT_START	Kiperwasser\tagSENT_CONTENT	&\tagSENT_CONTENT	Goldberg\tagSENT_CONTENT	's\tagSENT_CONTENT	2016\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	uses\tagSENT_CONTENT	2\tagmetric	layers\tagmetric	of\tagSENT_CONTENT	125-dimensional\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	;\tagSENT_CONTENT	in\tagSENT_CONTENT	Hashimoto\tagSENT_END	RECURRENT\tagSECTITLE_START	CELL\tagSECTITLE_END	We\tagSENT_START	drop\tagSENT_CONTENT	33\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	33\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	tags\tagmetric	during\tagSENT_CONTENT	training\tagSENT_CONTENT	:\tagSENT_CONTENT	when\tagSENT_CONTENT	one\tagSENT_CONTENT	is\tagSENT_CONTENT	dropped\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	is\tagSENT_CONTENT	scaled\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	factor\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	to\tagSENT_CONTENT	compensate\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	when\tagSENT_CONTENT	both\tagSENT_CONTENT	are\tagSENT_CONTENT	dropped\tagSENT_CONTENT	together\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	simply\tagSENT_CONTENT	gets\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	of\tagSENT_CONTENT	zeros\tagSENT_CONTENT	.\tagSENT_END	OPTIMIZER\tagSECTITLE_END	RESULTS\tagSECTITLE_END	Where\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	appears\tagSENT_CONTENT	to\tagSENT_CONTENT	lag\tagSENT_CONTENT	behind\tagSENT_CONTENT	the\tagSENT_CONTENT	SOTA\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	in\tagSENT_CONTENT	LAS\tagmetric	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	possibilities\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	proposed\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	modified\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	bilinear\tagSENT_CONTENT	attention\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	that\tagSENT_CONTENT	increases\tagSENT_CONTENT	parsing\tagSENT_CONTENT	speed\tagSENT_CONTENT	without\tagSENT_CONTENT	hurting\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	
P17-1168	title\tagSECTITLE_END	abstract\tagSECTITLE_END	This\tagSENT_START	enables\tagSENT_CONTENT	the\tagSENT_CONTENT	reader\tagSENT_CONTENT	to\tagSENT_CONTENT	build\tagSENT_CONTENT	query\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	A\tagSENT_START	recent\tagSENT_CONTENT	trend\tagSENT_CONTENT	to\tagSENT_CONTENT	measure\tagSENT_CONTENT	progress\tagSENT_CONTENT	towards\tagSENT_CONTENT	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	's\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	to\tagSENT_CONTENT	comprehend\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	success\tagSENT_CONTENT	of\tagSENT_CONTENT	many\tagSENT_CONTENT	recent\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	attributed\tagSENT_CONTENT	primarily\tagSENT_CONTENT	to\tagSENT_CONTENT	two\tagSENT_CONTENT	factors\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	hop\tagSENT_CONTENT	architectures\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	allow\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	scan\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	iteratively\tagSENT_CONTENT	for\tagSENT_CONTENT	multiple\tagSENT_CONTENT	passes\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	attentions\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	explored\tagSENT_CONTENT	orthogonally\tagSENT_CONTENT	so\tagSENT_CONTENT	far\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	show\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	GA\tagSENT_CONTENT	reader\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	its\tagSENT_CONTENT	relative\tagSENT_CONTENT	simplicity\tagSENT_CONTENT	,\tagSENT_CONTENT	consis\tagSENT_CONTENT	-\tagSENT_CONTENT	tently\tagSENT_CONTENT	improves\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	three\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	The\tagSENT_START	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	QA\tagSENT_CONTENT	task\tagSENT_CONTENT	involves\tagSENT_CONTENT	tuples\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	(\tagSENT_CONTENT	d\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	,\tagSENT_CONTENT	C\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	dis\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	(\tagSENT_CONTENT	context\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	q\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	query\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	contents\tagSENT_CONTENT	of\tagSENT_CONTENT	d\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	phrase\tagSENT_CONTENT	is\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	placeholder\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	is\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	q\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	candidates\tagSENT_CONTENT	C.\tagSENT_END	Gated\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Reader\tagSECTITLE_END	In\tagSENT_START	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	ideally\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	carried\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	across\tagSENT_CONTENT	hops\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	design\tagSENT_CONTENT	of\tagSENT_CONTENT	gated\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	layers\tagSENT_CONTENT	is\tagSENT_CONTENT	motivated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	multiplicative\tagSENT_CONTENT	interaction\tagSENT_CONTENT	among\tagSENT_CONTENT	vector\tagSENT_CONTENT	-\tagSENT_CONTENT	space\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	various\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	units\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Details\tagSECTITLE_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Hop\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_END	Gated\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Module\tagSECTITLE_END	Answer\tagSECTITLE_START	Prediction\tagSECTITLE_END	The\tagSENT_START	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	candidate\tagSENT_CONTENT	c\tagSENT_CONTENT	∈\tagSENT_CONTENT	C\tagSENT_CONTENT	as\tagSENT_CONTENT	being\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	then\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	aggregating\tagSENT_CONTENT	the\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	all\tagSENT_CONTENT	document\tagSENT_CONTENT	tokens\tagSENT_CONTENT	which\tagSENT_CONTENT	appear\tagSENT_CONTENT	inc\tagSENT_CONTENT	and\tagSENT_CONTENT	renormalizing\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	candidates\tagSENT_CONTENT	:\tagSENT_END	a\tagSENT_START	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	entropy\tagSENT_CONTENT	loss\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Further\tagSECTITLE_START	Enhancements\tagSECTITLE_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_END	Datasets\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	two\tagSENT_CONTENT	,\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	news\tagSENT_CONTENT	stories\tagSENT_CONTENT	2\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	articles\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	popular\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagSENT_CONTENT	Mail\tagSENT_CONTENT	websites\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	which\tagSENT_CONTENT	are\tagSENT_CONTENT	easily\tagSENT_CONTENT	answered\tagSENT_CONTENT	by\tagSENT_CONTENT	simple\tagSENT_CONTENT	baselines\tagSENT_CONTENT	are\tagSENT_CONTENT	filtered\tagSENT_CONTENT	out\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	more\tagSENT_CONTENT	challenging\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSECTITLE_START	Comparison\tagSECTITLE_END	Model\tagSECTITLE_START	Strict\tagSECTITLE_CONTENT	Relaxed\tagSECTITLE_END	Val\tagSENT_START	 \tagSENT_CONTENT	and\tagSENT_CONTENT	CBT\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	for\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Daily\tagmetric	Mail\tagmetric	.\tagSENT_END	Comparing\tagSENT_START	with\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WDW\tagSENT_CONTENT	dataset\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	GA\tagSENT_CONTENT	Reader\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	all\tagSENT_CONTENT	previously\tagSENT_CONTENT	published\tagSENT_CONTENT	models\tagSENT_CONTENT	when\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	GA\tagSECTITLE_START	Reader\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	This\tagSENT_START	model\tagSENT_CONTENT	ends\tagSENT_CONTENT	up\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	one\tagSENT_CONTENT	query\tagSENT_CONTENT	GRU\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	selecting\tagSENT_CONTENT	question_answering\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	Next\tagSENT_START	we\tagSENT_CONTENT	look\tagSENT_CONTENT	at\tagSENT_CONTENT	question_answering\tagtask	of\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	gate\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	document\tagSENT_CONTENT	reader\tagSENT_CONTENT	states\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	what\tagSENT_CONTENT	operation\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	in\tagSENT_CONTENT	equation\tagSENT_CONTENT	6\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	shows\tagSENT_START	accuracy\tagmetric	on\tagSENT_CONTENT	WDW\tagSENT_CONTENT	by\tagSENT_CONTENT	removing\tagSENT_CONTENT	one\tagSENT_CONTENT	component\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Study\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Components\tagSECTITLE_END	Model\tagSECTITLE_START	Accuracy\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	question_answering\tagtask	on\tagSENT_CONTENT	WDW\tagSENT_CONTENT	,\tagSENT_CONTENT	NSE\tagSENT_CONTENT	,\tagSENT_CONTENT	also\tagSENT_CONTENT	uses\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	hence\tagSENT_CONTENT	the\tagSENT_CONTENT	comparison\tagSENT_CONTENT	is\tagSENT_CONTENT	fair\tagSENT_CONTENT	in\tagSENT_CONTENT	that\tagSENT_CONTENT	respect\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSECTITLE_START	Visualization\tagSECTITLE_END	A\tagSENT_START	generic\tagSENT_CONTENT	pattern\tagSENT_CONTENT	observed\tagSENT_CONTENT	in\tagSENT_CONTENT	these\tagSENT_CONTENT	examples\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	in\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	layers\tagSENT_CONTENT	,\tagSENT_CONTENT	candidates\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	(\tagSENT_CONTENT	shown\tagSENT_CONTENT	along\tagSENT_CONTENT	rows\tagSENT_CONTENT	)\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	pick\tagSENT_CONTENT	out\tagSENT_CONTENT	salient\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	which\tagSENT_CONTENT	provide\tagSENT_CONTENT	clues\tagSENT_CONTENT	about\tagSENT_CONTENT	the\tagSENT_CONTENT	cloze\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	layer\tagSENT_CONTENT	the\tagSENT_CONTENT	candidate\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	match\tagSENT_CONTENT	with\tagSENT_CONTENT	these\tagSENT_CONTENT	tokens\tagSENT_CONTENT	is\tagSENT_CONTENT	selected\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	Analysis\tagSENT_START	of\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	query\tagSENT_CONTENT	attentions\tagSENT_CONTENT	in\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	reader\tagSENT_CONTENT	further\tagSENT_CONTENT	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	iteratively\tagSENT_CONTENT	attends\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	to\tagSENT_CONTENT	arrive\tagSENT_CONTENT	at\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	CNN\tagSECTITLE_START	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	CBT\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	NE\tagSECTITLE_CONTENT	CBT\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	CN\tagSECTITLE_CONTENT	WDW\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Strict\tagSECTITLE_CONTENT	WDW\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Relaxed\tagSECTITLE_END	
S18-1151	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Two\tagSENT_START	words\tagSENT_CONTENT	have\tagSENT_CONTENT	a\tagSENT_CONTENT	hypernymic\tagSENT_CONTENT	relation\tagSENT_CONTENT	if\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	belongs\tagSENT_CONTENT	to\tagSENT_CONTENT	taxonomy_learning\tagtask	that\tagSENT_CONTENT	is\tagSENT_CONTENT	more\tagSENT_CONTENT	general\tagSENT_CONTENT	than\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	word\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	differs\tagSENT_CONTENT	from\tagSENT_CONTENT	taxonomy_learning\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	concentrating\tagSENT_CONTENT	on\tagSENT_CONTENT	Hypernym\tagSENT_CONTENT	Discovery\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	(\tagSENT_CONTENT	discovering\tagSENT_CONTENT	)\tagSENT_CONTENT	n\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	System\tagSECTITLE_START	Description\tagSECTITLE_END	Results\tagSECTITLE_END	Our\tagSENT_START	official\tagSENT_CONTENT	submission\tagSENT_CONTENT	ranked\tagSENT_CONTENT	at\tagSENT_CONTENT	eleven\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	eighteen\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	medical\tagSENT_CONTENT	domain\tagSENT_CONTENT	subtask\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Average\tagSENT_CONTENT	Precision\tagSENT_CONTENT	(\tagmetric	MAP\tagmetric	)\tagSENT_CONTENT	of\tagSENT_CONTENT	8.13\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	music\tagSENT_CONTENT	industry\tagSENT_CONTENT	domain\tagSENT_CONTENT	subtask\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	ranked\tagSENT_CONTENT	13th\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	16\tagSENT_CONTENT	places\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagmetric	MAP\tagmetric	of\tagSENT_CONTENT	1.88\tagSENT_CONTENT	,\tagSENT_CONTENT	ranking\tagSENT_CONTENT	4th\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	Another\tagSENT_START	avenue\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	involves\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	taxonomy_learning\tagtask	into\tagSENT_CONTENT	our\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	approaches\tagSENT_CONTENT	(\tagSENT_CONTENT	Hypervec\tagSENT_CONTENT	,\tagSENT_CONTENT	retrofitting\tagSENT_CONTENT	and\tagSENT_CONTENT	taxonomy_learning\tagtask	)\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	would\tagSENT_CONTENT	relax\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	constraint\tagSENT_CONTENT	we\tagSENT_CONTENT	followed\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	implementation\tagSENT_CONTENT	.\tagSENT_END	
P15-2141	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	final\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	results\tagSENT_CONTENT	that\tagSENT_CONTENT	show\tagSENT_CONTENT	an\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	7\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	in\tagSENT_CONTENT	F\tagmetric	1\tagmetric	score\tagmetric	over\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	previously\tagSENT_CONTENT	reported\tagSENT_CONTENT	result\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	is\tagSENT_CONTENT	available\tagSENT_CONTENT	at\tagSENT_CONTENT	:\tagSENT_CONTENT	https://github.com/\tagSENT_CONTENT	Juicechuan\tagSENT_CONTENT	/\tagSENT_CONTENT	AMRParsing\tagSENT_END	Introduction\tagSECTITLE_END	amr_parsing\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	taking\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	producing\tagSENT_CONTENT	as\tagSENT_CONTENT	output\tagSENT_CONTENT	an\tagSENT_CONTENT	Abstract\tagSENT_CONTENT	Meaning\tagSENT_CONTENT	Representation\tagSENT_CONTENT	(\tagSENT_CONTENT	AMR\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	rooted\tagSENT_CONTENT	,\tagSENT_CONTENT	directed\tagSENT_CONTENT	,\tagSENT_CONTENT	edge\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	and\tagSENT_CONTENT	leaf\tagSENT_CONTENT	-\tagSENT_CONTENT	labeled\tagSENT_CONTENT	graph\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	competitive\tagSENT_CONTENT	alternative\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	MSCG\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	amr_parsing\tagtask	are\tagSENT_CONTENT	in\tagSENT_CONTENT	their\tagSENT_CONTENT	early\tagSENT_CONTENT	stages\tagSENT_CONTENT	of\tagSENT_CONTENT	development\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	their\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	yet\tagSENT_CONTENT	fully\tagSENT_CONTENT	developed\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	experimented\tagSENT_CONTENT	with\tagSENT_CONTENT	adding\tagSENT_CONTENT	Brown\tagSENT_CONTENT	clusters\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Transition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	AMR\tagSECTITLE_CONTENT	Parser\tagSECTITLE_END	Parser\tagSECTITLE_START	Extensions\tagSECTITLE_END	Inferring\tagSECTITLE_START	Abstract\tagSECTITLE_CONTENT	Concepts\tagSECTITLE_END	We\tagSENT_START	previously\tagSENT_CONTENT	create\tagSENT_CONTENT	the\tagSENT_CONTENT	learning\tagSENT_CONTENT	target\tagSENT_CONTENT	by\tagSENT_CONTENT	representing\tagSENT_CONTENT	an\tagSENT_CONTENT	AMR\tagSENT_CONTENT	graph\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	AMR\tagSENT_CONTENT	concept\tagSENT_CONTENT	is\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	(\tagSENT_CONTENT	contiguous\tagSENT_CONTENT	)\tagSENT_CONTENT	word\tagSENT_CONTENT	sequence\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	aligned\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	Feature\tagSECTITLE_START	Enrichment\tagSECTITLE_END	Coreference\tagSENT_START	features\tagSENT_CONTENT	Coreference\tagSENT_CONTENT	is\tagSENT_CONTENT	typically\tagSENT_CONTENT	represented\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	mentions\tagSENT_CONTENT	realized\tagSENT_CONTENT	as\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrases\tagSENT_CONTENT	or\tagSENT_CONTENT	pronouns\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	tune\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	newswire\tagmetric	section\tagmetric	of\tagSENT_CONTENT	LDC2013E117\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	LDC2013E117\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	conduct\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagmetric	newswire\tagmetric	section\tagmetric	of\tagSENT_CONTENT	AMR\tagSENT_CONTENT	annotation\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	LDC2013E117\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	with\tagSENT_CONTENT	Smatch\tagSENT_CONTENT	v2.0\tagSENT_CONTENT	:\tagSENT_CONTENT	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	syntactic\tagSECTITLE_CONTENT	parsers\tagSECTITLE_END	All\tagSENT_START	the\tagSENT_CONTENT	different\tagSENT_CONTENT	dependency\tagSENT_CONTENT	trees\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	system\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Impact\tagSECTITLE_START	of\tagSECTITLE_CONTENT	parser\tagSECTITLE_CONTENT	extensions\tagSECTITLE_END	From\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	INFER\tagSENT_CONTENT	action\tagSENT_CONTENT	yields\tagSENT_CONTENT	a\tagSENT_CONTENT	4\tagSENT_CONTENT	point\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	F\tagmetric	1\tagmetric	score\tagmetric	over\tagSENT_CONTENT	the\tagSENT_CONTENT	CHAR\tagSENT_CONTENT	-\tagSENT_CONTENT	NIAK(ON\tagSENT_CONTENT	)\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	Adding\tagSENT_START	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	features\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Brown\tagSENT_CONTENT	clusters\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	another\tagSENT_CONTENT	2\tagSENT_CONTENT	points\tagSENT_CONTENT	in\tagSENT_CONTENT	F\tagmetric	1\tagmetric	score\tagmetric	,\tagSENT_CONTENT	and\tagSENT_CONTENT	gives\tagSENT_CONTENT	us\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	result\tagSENT_CONTENT	.\tagSENT_END	Final\tagSECTITLE_START	Result\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	Test\tagSECTITLE_CONTENT	Set\tagSECTITLE_END	From\tagSENT_START	we\tagSENT_CONTENT	can\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	amr_parsing\tagtask	has\tagSENT_CONTENT	significant\tagSENT_CONTENT	improvement\tagSENT_CONTENT	overall\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	parsers\tagSENT_CONTENT	and\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	best\tagSENT_CONTENT	parser\tagSENT_CONTENT	by\tagSENT_CONTENT	7\tagSENT_CONTENT	%\tagSENT_CONTENT	points\tagSENT_CONTENT	in\tagSENT_CONTENT	Smatch\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	on\tagSECTITLE_CONTENT	LDC2014T12\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conduct\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	AMR\tagSENT_CONTENT	annotation\tagSENT_CONTENT	release\tagSENT_CONTENT	1.0\tagSENT_CONTENT	(\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	contains\tagSENT_CONTENT	13,051\tagSENT_CONTENT	AMRs\tagSENT_CONTENT	from\tagSENT_CONTENT	newswire\tagmetric	,\tagSENT_CONTENT	weblogs\tagSENT_CONTENT	and\tagSENT_CONTENT	web\tagSENT_CONTENT	discussion\tagSENT_CONTENT	forums\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	/\tagSENT_CONTENT	development\tagSENT_CONTENT	/\tagSENT_CONTENT	test\tagSENT_CONTENT	split\tagSENT_CONTENT	recommended\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	release\tagSENT_CONTENT	:\tagSENT_CONTENT	10,312\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	1,368\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	1,371\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	testing\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_END	:\tagSENT_START	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	LDC2014T12\tagdataset	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	amr_parsing\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	newswire\tagSENT_CONTENT	section\tagSENT_CONTENT	of\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_END	:\tagSENT_START	AMR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	newswire\tagmetric	section\tagmetric	of\tagSENT_CONTENT	LDC2014T12\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_END	And\tagSENT_START	our\tagSENT_CONTENT	system\tagSENT_CONTENT	still\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	parsers\tagSENT_CONTENT	by\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	
Q18-1025	title\tagSECTITLE_END	From\tagSENT_START	Characters\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	:\tagSENT_CONTENT	New\tagSENT_CONTENT	Paradigms\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	and\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Parsing\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	abstract\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	presents\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	,\tagSENT_CONTENT	timex_normalisation\tagtask	are\tagSENT_CONTENT	annotated\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	semantic\tagSENT_CONTENT	composition\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	To\tagSENT_START	compare\tagSENT_CONTENT	predictions\tagSENT_CONTENT	of\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	follow\tagSENT_CONTENT	both\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	and\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	anew\tagSENT_CONTENT	scoring\tagSENT_CONTENT	metric\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	apply\tagSENT_CONTENT	this\tagSENT_CONTENT	new\tagSENT_CONTENT	metric\tagSENT_CONTENT	to\tagSENT_CONTENT	carryout\tagSENT_CONTENT	a\tagSENT_CONTENT	comparative\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	both\tagSENT_CONTENT	schemes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	timex_normalisation\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	translating\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	expressions\tagSENT_CONTENT	of\tagSENT_CONTENT	time\tagSENT_CONTENT	to\tagSENT_CONTENT	computer\tagSENT_CONTENT	-\tagSENT_CONTENT	readable\tagSENT_CONTENT	forms\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	expression\tagSENT_CONTENT	three\tagSENT_CONTENT	days\tagSENT_CONTENT	ago\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	normalized\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	2017\tagSENT_CONTENT	-\tagSENT_CONTENT	08\tagSENT_CONTENT	-\tagSENT_CONTENT	28\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	ISO-8601\tagSENT_CONTENT	standard\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	timex_normalisation\tagtask	allows\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	events\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	placed\tagSENT_CONTENT	along\tagSENT_CONTENT	a\tagSENT_CONTENT	timeline\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	crucial\tagSENT_CONTENT	step\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	information\tagSENT_CONTENT	extraction\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	shared\tagSENT_CONTENT	tasks\tagSENT_CONTENT	on\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	interest\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	growing\tagSENT_CONTENT	.\tagSENT_END	extract\tagSENT_START	and\tagSENT_CONTENT	normalize\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	starting\tagSENT_CONTENT	point\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	study\tagSENT_CONTENT	on\tagSENT_CONTENT	trends\tagSENT_CONTENT	and\tagSENT_CONTENT	patterns\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	dates\tagSENT_CONTENT	in\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	key\tagSENT_CONTENT	consideration\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	what\tagSENT_CONTENT	formal\tagSENT_CONTENT	representation\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	normalized\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	most\tagSENT_CONTENT	popular\tagSENT_CONTENT	scheme\tagSENT_CONTENT	for\tagSENT_CONTENT	annotating\tagSENT_CONTENT	normalized\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	is\tagSENT_CONTENT	ISO\tagSENT_CONTENT	-\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	several\tagSENT_CONTENT	important\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	bounded\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	intervals\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	Saturdays\tagSENT_CONTENT	since\tagSENT_CONTENT	March\tagSENT_CONTENT	6\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	easily\tagSENT_CONTENT	amenable\tagSENT_CONTENT	to\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	HeidelTime\tagSENT_CONTENT	)\tagSENT_END	We\tagSENT_START	present\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	machine\tagSENT_CONTENT	-\tagSENT_CONTENT	learning\tagSENT_CONTENT	models\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	We\tagSENT_START	introduce\tagSENT_CONTENT	anew\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	that\tagSENT_CONTENT	can\tagSENT_CONTENT	compare\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	different\tagSENT_CONTENT	annotation\tagSENT_CONTENT	schemes\tagSENT_CONTENT	by\tagSENT_CONTENT	measuring\tagSENT_CONTENT	overlap\tagSENT_CONTENT	of\tagSENT_CONTENT	intervals\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	timeline\tagSENT_CONTENT	.\tagSENT_END	•\tagSENT_START	We\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	metric\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	timex_normalisation\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	confirm\tagSENT_CONTENT	that\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	covers\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	 \tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	We\tagSENT_START	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	for\tagSENT_CONTENT	learning\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	HeidelTime\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_END	ISO\tagSENT_START	-\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	popular\tagSENT_CONTENT	scheme\tagSENT_CONTENT	for\tagSENT_CONTENT	annotating\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	It\tagSENT_START	annotates\tagSENT_CONTENT	timex_normalisation\tagtask	as\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	assigns\tagSENT_CONTENT	timex_normalisation\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	1990\tagSENT_CONTENT	-\tagSENT_CONTENT	08\tagSENT_CONTENT	-\tagSENT_CONTENT	15T13:37\tagSENT_CONTENT	or\tagSENT_CONTENT	PT24H\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	VALUE\tagSENT_CONTENT	attribute\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Second\tagSENT_START	,\tagSENT_CONTENT	timex_normalisation\tagtask	receives\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	VALUE\tagSENT_CONTENT	,\tagSENT_CONTENT	regardless\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	span\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	compositional\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	expression\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	represented\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	most\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	taken\tagSENT_CONTENT	a\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	,\tagSENT_CONTENT	looking\tagSENT_CONTENT	up\tagSENT_CONTENT	each\tagSENT_CONTENT	token\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	in\tagSENT_CONTENT	timex_normalisation\tagtask	and\tagSENT_CONTENT	then\tagSENT_CONTENT	mapping\tagSENT_CONTENT	this\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical\tagSENT_CONTENT	entries\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	As\tagSENT_START	an\tagSENT_CONTENT	alternative\tagSENT_CONTENT	to\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	,\tagSENT_CONTENT	Schilder\tagSENT_CONTENT	(\tagSENT_CONTENT	2004\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	proposed\tagSENT_CONTENT	Semantically\tagSENT_CONTENT	Compositional\tagSENT_CONTENT	Annotation\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	(\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	,\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	annotated\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	compositional\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	over\tagSENT_CONTENT	intervals\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	timeline\tagSENT_CONTENT	.\tagSENT_END	An\tagSENT_START	example\tagSENT_CONTENT	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	corresponding\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	formally\tagSENT_CONTENT	defined\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	can\tagSENT_CONTENT	represent\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	provides\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Unlike\tagSENT_START	TimeML\tagSENT_CONTENT	,\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	graph\tagSENT_CONTENT	structure\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	compositional\tagSENT_CONTENT	semantics\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	represent\tagSENT_CONTENT	timex_normalisation\tagtask	that\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	expressed\tagSENT_CONTENT	with\tagSENT_CONTENT	contiguous\tagSENT_CONTENT	phrases\tagSENT_CONTENT	.\tagSENT_END	An\tagSECTITLE_START	interval\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	evaluation\tagSECTITLE_CONTENT	metric\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	normalized\tagSECTITLE_CONTENT	times\tagSECTITLE_END	Before\tagSENT_START	attempting\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	machine\tagSENT_CONTENT	-\tagSENT_CONTENT	learned\tagSENT_CONTENT	models\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	were\tagSENT_CONTENT	interested\tagSENT_CONTENT	in\tagSENT_CONTENT	evaluating\tagSENT_CONTENT	's\tagSENT_CONTENT	claim\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	than\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	do\tagSENT_CONTENT	so\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	anew\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	to\tagSENT_CONTENT	compare\tagSENT_CONTENT	timex_normalisation\tagtask	annotated\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	ISO\tagSENT_CONTENT	8601\tagSENT_CONTENT	format\tagSENT_CONTENT	of\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	interprets\tagSENT_CONTENT	timex_normalisation\tagtask	as\tagSENT_CONTENT	intervals\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	timeline\tagSENT_CONTENT	and\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	overlap\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	intervals\tagSENT_CONTENT	.\tagSENT_END	TimeML\tagSENT_START	TIMEX3\tagSENT_CONTENT	(\tagSENT_CONTENT	timex_normalisation\tagtask	)\tagSENT_CONTENT	annotations\tagSENT_CONTENT	are\tagSENT_CONTENT	converted\tagSENT_CONTENT	to\tagSENT_CONTENT	intervals\tagSENT_CONTENT	following\tagSENT_CONTENT	ISO\tagSENT_CONTENT	8601\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	VALUE\tagSENT_CONTENT	attribute\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	are\tagSENT_CONTENT	converted\tagSENT_CONTENT	to\tagSENT_CONTENT	intervals\tagSENT_CONTENT	following\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	library\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	there\tagSENT_CONTENT	maybe\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	one\tagSENT_CONTENT	interval\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Saturdays\tagSENT_CONTENT	since\tagSENT_CONTENT	March\tagSENT_CONTENT	6\tagSENT_CONTENT	example\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	two\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	intervals\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	define\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	P\tagSENT_CONTENT	int\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	intervals\tagSENT_CONTENT	in\tagSENT_CONTENT	common\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	divided\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	length\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	intervals\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	each\tagSENT_CONTENT	from\tagSENT_CONTENT	timex_normalisation\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	define\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	P\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	where\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	all\tagSENT_CONTENT	annotations\tagSENT_CONTENT	that\tagSENT_CONTENT	textually\tagSENT_CONTENT	overlap\tagSENT_CONTENT	it\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	the\tagSENT_START	average\tagSENT_CONTENT	of\tagSENT_CONTENT	interval\tagSENT_CONTENT	recalls\tagSENT_CONTENT	where\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	set\tagSENT_CONTENT	is\tagSENT_CONTENT	paired\tagSENT_CONTENT	with\tagSENT_CONTENT	all\tagSENT_CONTENT	annotations\tagSENT_CONTENT	that\tagSENT_CONTENT	textually\tagSENT_CONTENT	overlap\tagSENT_CONTENT	it\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	Sand\tagSENT_CONTENT	H\tagSENT_CONTENT	are\tagSENT_CONTENT	sets\tagSENT_CONTENT	of\tagSENT_CONTENT	annotations\tagSENT_CONTENT	,\tagSENT_CONTENT	gives\tagSENT_CONTENT	timex_normalisation\tagtask	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	OVERLAPS(a\tagSENT_CONTENT	,\tagSENT_CONTENT	b\tagSENT_CONTENT	)\tagSENT_CONTENT	decide\tagSENT_CONTENT	whether\tagSENT_CONTENT	timex_normalisation\tagtask	a\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	share\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	one\tagSENT_CONTENT	character\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	in\tagSENT_CONTENT	common\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	these\tagSENT_CONTENT	metrics\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	applied\tagSENT_CONTENT	only\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	that\tagSENT_CONTENT	yield\tagSENT_CONTENT	bounded\tagSENT_CONTENT	intervals\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	that\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	intervals\tagSENT_CONTENT	with\tagSENT_CONTENT	undefined\tagSENT_CONTENT	boundaries\tagSENT_CONTENT	are\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	scope\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	in\tagSENT_END	We\tagSENT_START	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	interval\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	AQUAINT\tagSENT_CONTENT	and\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	treating\tagSENT_CONTENT	timex_normalisation\tagtask	as\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	(\tagSENT_CONTENT	S\tagSENT_CONTENT	)\tagSENT_CONTENT	annotator\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	annotations\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	(\tagSENT_CONTENT	H\tagSENT_CONTENT	)\tagSENT_CONTENT	annotator\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	annotations\tagSENT_CONTENT	cover\tagSENT_CONTENT	different\tagSENT_CONTENT	time\tagSENT_CONTENT	intervals\tagSENT_CONTENT	than\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	row\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	recall\tagSENT_CONTENT	of\tagSENT_CONTENT	only\tagSENT_CONTENT	92\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	identified\tagSENT_CONTENT	by\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	AQUAINT\tagSENT_CONTENT	corpus\tagSENT_CONTENT	and\tagSENT_CONTENT	of\tagSENT_CONTENT	only\tagSENT_CONTENT	83\tagSENT_CONTENT	%\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	corpus\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	manually\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	all\tagSENT_CONTENT	places\tagSENT_CONTENT	where\tagSENT_CONTENT	timex_normalisation\tagtask	differed\tagSENT_CONTENT	and\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	interpretation\tagSENT_CONTENT	was\tagSENT_CONTENT	always\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	one\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	common\tagSENT_CONTENT	case\tagSENT_CONTENT	where\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	and\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	annotations\tagSENT_CONTENT	overlap\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	identical\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	timex_normalisation\tagtask	preceded\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	preposition\tagSENT_CONTENT	like\tagSENT_CONTENT	"\tagSENT_CONTENT	since\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	for\tagSENT_CONTENT	"\tagSENT_CONTENT	Since\tagSENT_CONTENT	1985\tagSENT_CONTENT	"\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	DCT\tagSENT_CONTENT	of\tagSENT_CONTENT	1998\tagSENT_CONTENT	-\tagSENT_CONTENT	03\tagSENT_CONTENT	-\tagSENT_CONTENT	01T14:11\tagSENT_CONTENT	)\tagSENT_END	timex_normalisation\tagtask	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	expression\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	consequently\tagSENT_CONTENT	,\tagSENT_CONTENT	produces\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	time\tagSENT_CONTENT	interval\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	for\tagSENT_CONTENT	"\tagSENT_CONTENT	10:35\tagSENT_CONTENT	a.m.\tagSENT_CONTENT	(\tagSENT_CONTENT	0735\tagSENT_CONTENT	GMT\tagSENT_CONTENT	)\tagSENT_CONTENT	Friday\tagSENT_CONTENT	"\tagSENT_CONTENT	annotates\tagSENT_CONTENT	two\tagSENT_CONTENT	separate\tagSENT_CONTENT	intervals\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	day\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	ignores\tagSENT_CONTENT	"\tagSENT_CONTENT	0735\tagSENT_CONTENT	GMT\tagSENT_CONTENT	"\tagSENT_CONTENT	entirely\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	recognizes\tagSENT_CONTENT	this\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	description\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	time\tagSENT_CONTENT	interval\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_END	timex_normalisation\tagtask	also\tagSENT_CONTENT	differ\tagSENT_CONTENT	in\tagSENT_CONTENT	how\tagSENT_CONTENT	references\tagSENT_CONTENT	to\tagSENT_CONTENT	particular\tagSENT_CONTENT	past\tagSENT_CONTENT	periods\tagSENT_CONTENT	are\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	.\tagSENT_END	Beyond\tagSENT_START	these\tagSENT_CONTENT	differences\tagSENT_CONTENT	in\tagSENT_CONTENT	interpretation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	observed\tagSENT_CONTENT	that\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	corpus\tagSENT_CONTENT	annotates\tagSENT_CONTENT	timex_normalisation\tagtask	anywhere\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	in\tagSENT_CONTENT	metadata\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	timex_normalisation\tagtask	are\tagSENT_CONTENT	restricted\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	main\tagSENT_CONTENT	text\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	documents\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	second\tagSENT_CONTENT	row\tagSENT_CONTENT	of\tagSENT_CONTENT	shows\tagSENT_CONTENT	timex_normalisation\tagtask	when\tagSENT_CONTENT	comparing\tagSENT_CONTENT	overall\tagSENT_CONTENT	text\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	,\tagSENT_CONTENT	not\tagSENT_CONTENT	just\tagSENT_CONTENT	the\tagSENT_CONTENT	body\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Unsurprisingly\tagSENT_START	,\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	has\tagSENT_CONTENT	a\tagSENT_CONTENT	lower\tagSENT_CONTENT	recall\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	annotations\tagSENT_CONTENT	under\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Types\tagSECTITLE_START	of\tagSECTITLE_CONTENT	SCATE\tagSECTITLE_CONTENT	annotations\tagSECTITLE_END	346\tagSECTITLE_END	Non\tagSENT_START	-\tagSENT_CONTENT	Op\tagSENT_CONTENT	Exp\tagSENT_CONTENT	-\tagSENT_CONTENT	Op\tagSENT_CONTENT	Imp-\tagSENT_CONTENT	15\tagSENT_CONTENT	%\tagSENT_CONTENT	11\tagSENT_CONTENT	%\tagSENT_CONTENT	100\tagSENT_CONTENT	%\tagSENT_CONTENT	terpreted\tagSENT_CONTENT	without\tagSENT_CONTENT	having\tagSENT_CONTENT	to\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Operators\tagSENT_START	are\tagSENT_CONTENT	not\tagSENT_CONTENT	atomic\tagSENT_CONTENT	;\tagSENT_CONTENT	they\tagSENT_CONTENT	can\tagSENT_CONTENT	only\tagSENT_CONTENT	be\tagSENT_CONTENT	interpreted\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	they\tagSENT_CONTENT	link\tagSENT_CONTENT	to\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	define\tagSENT_CONTENT	an\tagSENT_CONTENT	operator\tagSENT_CONTENT	as\tagSENT_CONTENT	explicit\tagSENT_CONTENT	if\tagSENT_CONTENT	it\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	overlap\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	An\tagSENT_START	operator\tagSENT_CONTENT	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	implicit\tagSENT_CONTENT	if\tagSENT_CONTENT	it\tagSENT_CONTENT	overlaps\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Models\tagSECTITLE_END	We\tagSENT_START	decompose\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	timex_normalisation\tagtask	into\tagSENT_CONTENT	two\tagSENT_CONTENT	subtasks\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	identification\tagSENT_CONTENT	which\tagSENT_CONTENT	detects\tagSENT_CONTENT	the\tagSENT_CONTENT	spans\tagSENT_CONTENT	of\tagSENT_CONTENT	characters\tagSENT_CONTENT	that\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	expression\tagSENT_CONTENT	and\tagSENT_CONTENT	labels\tagSENT_CONTENT	them\tagSENT_CONTENT	with\tagSENT_CONTENT	their\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	;\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	that\tagSENT_CONTENT	links\tagSENT_CONTENT	relevant\tagSENT_CONTENT	entities\tagSENT_CONTENT	together\tagSENT_CONTENT	while\tagSENT_CONTENT	respecting\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	type\tagSENT_CONTENT	constraints\tagSENT_CONTENT	imposed\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	.\tagSENT_END	Once\tagSENT_START	identification\tagSENT_CONTENT	and\tagSENT_CONTENT	composition\tagSENT_CONTENT	steps\tagSENT_CONTENT	are\tagSENT_CONTENT	completed\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	product\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	semantic\tagSENT_CONTENT	compositional\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	to\tagSENT_CONTENT	feed\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	interpreter\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	encode\tagSENT_CONTENT	time\tagSENT_CONTENT	intervals\tagSENT_CONTENT	.\tagSENT_END	Time\tagSECTITLE_START	entity\tagSECTITLE_CONTENT	identification\tagSECTITLE_END	timex_normalisation\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	task\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	piece\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	assigned\tagSENT_CONTENT	a\tagSENT_CONTENT	label\tagSENT_CONTENT	that\tagSENT_CONTENT	identifies\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	evokes\tagSENT_CONTENT	.\tagSENT_END	Differing\tagSENT_START	somewhat\tagSENT_CONTENT	from\tagSENT_CONTENT	standard\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	schema\tagSENT_CONTENT	allows\tagSENT_CONTENT	timex_normalisation\tagtask	over\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	span\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	Saturdays\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	is\tagSENT_CONTENT	both\tagSENT_CONTENT	a\tagSENT_CONTENT	DAY\tagSENT_CONTENT	-\tagSENT_CONTENT	OF\tagSENT_CONTENT	-\tagSENT_CONTENT	WEEK\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	THIS\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	entity\tagSENT_CONTENT	identification\tagSENT_CONTENT	models\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	such\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	architectures\tagSECTITLE_END	Unicode\tagSECTITLE_START	character\tagSECTITLE_CONTENT	categories\tagSECTITLE_CONTENT	:\tagSECTITLE_END	This\tagSENT_START	encodes\tagSENT_CONTENT	timex_normalisation\tagtask	like\tagSENT_CONTENT	the\tagSENT_CONTENT	presence\tagSENT_CONTENT	of\tagSENT_CONTENT	uppercase\tagSENT_CONTENT	(\tagSENT_CONTENT	Lu\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	lowercase\tagSENT_END	Input\tagSECTITLE_START	:\tagSECTITLE_CONTENT	words\tagSECTITLE_CONTENT	vs.\tagSECTITLE_CONTENT	characters\tagSECTITLE_END	Identifying\tagSENT_START	SCATE\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	take\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	neural\tagSENT_CONTENT	architectures\tagSENT_CONTENT	for\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Several\tagSENT_START	aspects\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	make\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	approach\tagSENT_CONTENT	especially\tagSENT_CONTENT	appealing\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	our\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	and\tagSENT_CONTENT	every\tagSENT_CONTENT	character\tagSENT_CONTENT	(\tagSENT_CONTENT	including\tagSENT_CONTENT	whitespace\tagSENT_CONTENT	characters\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	fed\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	Time\tagSECTITLE_START	entity\tagSECTITLE_CONTENT	composition\tagSECTITLE_END	Once\tagSENT_START	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	are\tagSENT_CONTENT	identified\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	composed\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	their\tagSENT_CONTENT	semantic\tagSENT_CONTENT	interpretation\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	step\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	parts\tagSENT_CONTENT	:\tagSENT_CONTENT	linking\tagSENT_CONTENT	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	that\tagSENT_CONTENT	makeup\tagSENT_CONTENT	timex_normalisation\tagtask	together\tagSENT_CONTENT	and\tagSENT_CONTENT	completing\tagSENT_CONTENT	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	'\tagSENT_CONTENT	properties\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	proper\tagSENT_CONTENT	values\tagSENT_CONTENT	.\tagSENT_END	Time\tagSECTITLE_START	entity\tagSECTITLE_CONTENT	linking\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	iterate\tagSENT_CONTENT	over\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	sorted\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	starting\tagSENT_CONTENT	character\tagSENT_CONTENT	offsets\tagSENT_CONTENT	(\tagSENT_CONTENT	SORTBYSTART\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	if\tagSENT_START	end\tagSENT_CONTENT	for\tagSENT_CONTENT	PUSH(stack\tagSENT_CONTENT	,\tagSENT_CONTENT	entity\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	end\tagSENT_CONTENT	for\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	not\tagSENT_CONTENT	already\tagSENT_CONTENT	been\tagSENT_CONTENT	filled\tagSENT_CONTENT	by\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	greedily\tagSENT_CONTENT	make\tagSENT_CONTENT	the\tagSENT_CONTENT	link\tagSENT_CONTENT	(\tagSENT_CONTENT	CREATELINK\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	the\tagSENT_CONTENT	distance\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	characters\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	is\tagSENT_CONTENT	bigger\tagSENT_CONTENT	than\tagSENT_CONTENT	10\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	identification\tagSENT_CONTENT	model\tagSENT_CONTENT	gets\tagSENT_CONTENT	the\tagSENT_CONTENT	YEAR\tagSENT_CONTENT	,\tagSENT_CONTENT	MONTH\tagSENT_CONTENT	-\tagSENT_CONTENT	OF\tagSENT_CONTENT	-\tagSENT_CONTENT	YEAR\tagSENT_CONTENT	and\tagSENT_CONTENT	DAY\tagSENT_CONTENT	-\tagSENT_CONTENT	OF\tagSENT_CONTENT	-\tagSENT_CONTENT	MONTH\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	1992\tagSENT_CONTENT	-\tagSENT_CONTENT	12\tagSENT_CONTENT	-\tagSENT_CONTENT	23\tagSENT_CONTENT	.\tagSENT_END	Now\tagSENT_START	,\tagSENT_CONTENT	suppose\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	several\tagSENT_CONTENT	words\tagSENT_CONTENT	ahead\tagSENT_CONTENT	of\tagSENT_CONTENT	23\tagSENT_END	If\tagSENT_START	that\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	is\tagSENT_CONTENT	empty\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	process\tagSENT_CONTENT	starts\tagSENT_CONTENT	again\tagSENT_CONTENT	to\tagSENT_CONTENT	compose\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Property\tagSECTITLE_START	completion\tagSECTITLE_END	The\tagSENT_START	last\tagSENT_CONTENT	step\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	associate\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	properties\tagSENT_CONTENT	that\tagSENT_CONTENT	include\tagSENT_CONTENT	timex_normalisation\tagtask	needed\tagSENT_CONTENT	for\tagSENT_CONTENT	its\tagSENT_CONTENT	interpretation\tagSENT_CONTENT	.\tagSENT_END	SEMANTICS\tagSECTITLE_START	:\tagSECTITLE_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	next\tagSENT_CONTENT	week\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	week\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	DCT\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	such\tagSENT_CONTENT	a\tagSENT_CONTENT	case\tagSENT_CONTENT	the\tagSENT_CONTENT	value\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	property\tagSENT_CONTENT	INTERVAL\tagSENT_CONTENT	-\tagSENT_CONTENT	TYPE\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	NEXT\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	DOCTIME\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	sometimes\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	linked\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	interval\tagSENT_CONTENT	that\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	reference\tagSENT_CONTENT	by\tagSENT_CONTENT	itself\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	year\tagSENT_CONTENT	2000\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	system\tagSENT_CONTENT	sets\tagSENT_CONTENT	the\tagSENT_CONTENT	value\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	property\tagSENT_CONTENT	to\tagSENT_CONTENT	LINK\tagSENT_CONTENT	if\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	linked\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	YEAR\tagSENT_CONTENT	and\tagSENT_CONTENT	DOCTIME\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	.\tagSENT_END	Automatically\tagSECTITLE_START	generated\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	data\tagSECTITLE_END	These\tagSENT_START	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	are\tagSENT_CONTENT	quite\tagSENT_CONTENT	particular\tagSENT_CONTENT	;\tagSENT_CONTENT	they\tagSENT_CONTENT	occur\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	and\tagSENT_CONTENT	not\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	and\tagSENT_CONTENT	they\tagSENT_CONTENT	always\tagSENT_CONTENT	yield\tagSENT_CONTENT	a\tagSENT_CONTENT	bounded\tagSENT_CONTENT	interval\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	timex_normalisation\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	critical\tagSENT_CONTENT	factor\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	interval\tagSENT_CONTENT	based\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	therefore\tagSENT_CONTENT	designed\tagSENT_CONTENT	timex_normalisation\tagtask	to\tagSENT_CONTENT	randomly\tagSENT_CONTENT	generate\tagSENT_CONTENT	an\tagSENT_CONTENT	extra\tagSENT_CONTENT	800\tagSENT_CONTENT	isolated\tagSENT_CONTENT	training\tagSENT_CONTENT	examples\tagSENT_CONTENT	fora\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	such\tagSENT_CONTENT	expression\tagSENT_CONTENT	formats\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	generator\tagSENT_CONTENT	covers\tagSENT_CONTENT	33\tagSENT_CONTENT	different\tagSENT_CONTENT	formats\tagSENT_CONTENT	which\tagSENT_CONTENT	include\tagSENT_CONTENT	variants\tagSENT_CONTENT	covering\tagSENT_CONTENT	abbreviation\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	/\tagSENT_CONTENT	without\tagSENT_CONTENT	delimiters\tagSENT_CONTENT	,\tagSENT_CONTENT	mixture\tagSENT_CONTENT	of\tagSENT_CONTENT	digits\tagSENT_CONTENT	and\tagSENT_CONTENT	strings\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	different\tagSENT_CONTENT	sequences\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Experiments\tagSECTITLE_END	timex_normalisation\tagtask	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	broadcast\tagSENT_CONTENT	news\tagSENT_CONTENT	documents\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	ABC\tagSENT_CONTENT	,\tagSENT_CONTENT	1\tagSENT_CONTENT	CNN\tagSENT_CONTENT	,\tagSENT_CONTENT	1\tagSENT_CONTENT	PRI\tagSENT_CONTENT	,\tagSENT_CONTENT	1\tagSENT_CONTENT	VOA\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	newswire\tagSENT_CONTENT	documents\tagSENT_CONTENT	(\tagSENT_CONTENT	5\tagSENT_CONTENT	AP\tagSENT_CONTENT	,\tagSENT_CONTENT	1\tagSENT_CONTENT	NYT\tagSENT_CONTENT	,\tagSENT_CONTENT	4\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	interval\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	report\tagSENT_CONTENT	more\tagSENT_CONTENT	traditional\tagSENT_CONTENT	information\tagSENT_CONTENT	extraction\tagSENT_CONTENT	metrics\tagSENT_CONTENT	(\tagSENT_CONTENT	precision\tagSENT_CONTENT	,\tagSENT_CONTENT	recall\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	identification\tagSENT_CONTENT	and\tagSENT_CONTENT	composition\tagSENT_CONTENT	steps\tagSENT_CONTENT	.\tagSENT_END	is\tagSENT_START	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	items\tagSENT_CONTENT	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	humans\tagSENT_CONTENT	,\tagSENT_CONTENT	precision\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	recall\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	are\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_END	For\tagSENT_START	timex_normalisation\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	item\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	annotation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	considered\tagSENT_CONTENT	equal\tagSENT_CONTENT	to\tagSENT_CONTENT	another\tagSENT_CONTENT	if\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	character\tagSENT_CONTENT	span\tagSENT_CONTENT	(\tagSENT_CONTENT	offsets\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	type\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	properties\tagSENT_CONTENT	(\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	applying\tagSENT_CONTENT	recursively\tagSENT_CONTENT	for\tagSENT_CONTENT	properties\tagSENT_CONTENT	that\tagSENT_CONTENT	point\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	trained\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	on\tagSENT_CONTENT	mini\tagSENT_CONTENT	-\tagSENT_CONTENT	batches\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	120\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	followed\tagSENT_CONTENT	standard\tagSENT_CONTENT	recommendations\tagSENT_CONTENT	to\tagSENT_CONTENT	leave\tagSENT_CONTENT	the\tagSENT_CONTENT	optimizer\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	settings\tagSENT_CONTENT	at\tagSENT_CONTENT	their\tagSENT_CONTENT	default\tagSENT_CONTENT	values\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	selection\tagSECTITLE_END	recall\tagSENT_START	(\tagSENT_CONTENT	R\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architectures\tagSENT_CONTENT	on\tagSENT_CONTENT	timex_normalisation\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	is\tagSENT_CONTENT	probably\tagSENT_CONTENT	a\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	small\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	development\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	From\tagSENT_START	this\tagSENT_CONTENT	analysis\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	select\tagSENT_CONTENT	two\tagSENT_CONTENT	variants\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	Char\tagSENT_CONTENT	3-softmax\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	:\tagSENT_END	Model\tagSECTITLE_START	evaluation\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	both\tagSENT_CONTENT	Char\tagSENT_CONTENT	3-Softmax\tagSENT_CONTENT	and\tagSENT_CONTENT	Char\tagSENT_CONTENT	3-Softmax\tagSENT_CONTENT	extra\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	and\tagSENT_CONTENT	We\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	paired\tagSENT_CONTENT	bootstrap\tagSENT_CONTENT	resampling\tagSENT_CONTENT	significance\tagSENT_CONTENT	test\tagSENT_CONTENT	.\tagSENT_END	Char\tagSECTITLE_START	3-Softmax\tagSECTITLE_END	70.3\tagSECTITLE_START	87.4\tagSECTITLE_CONTENT	73.4\tagSECTITLE_END	52.3\tagSENT_START	57.7\tagSENT_CONTENT	46.0\tagSENT_CONTENT	51.2\tagSENT_CONTENT	:\tagSENT_CONTENT	Results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	(\tagSENT_CONTENT	Ident\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	Time\tagSENT_CONTENT	entity\tagSENT_CONTENT	composition\tagSENT_CONTENT	(\tagSENT_CONTENT	Comp\tagSENT_CONTENT	)\tagSENT_CONTENT	steps\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	gets\tagSENT_CONTENT	3.3\tagSENT_CONTENT	more\tagSENT_CONTENT	percentage\tagSENT_CONTENT	points\tagSENT_CONTENT	than\tagSENT_CONTENT	HeidelTime\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	(\tagSENT_CONTENT	p=0.2485\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Notice\tagSENT_START	that\tagSENT_CONTENT	,\tagSENT_CONTENT	although\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	without\tagSENT_CONTENT	timex_normalisation\tagtask	is\tagSENT_CONTENT	better\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	performs\tagSENT_CONTENT	much\tagSENT_CONTENT	worse\tagSENT_CONTENT	at\tagSENT_CONTENT	producing\tagSENT_CONTENT	final\tagSENT_CONTENT	intervals\tagSENT_CONTENT	.\tagSENT_END	Precision\tagSENT_START	(\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	recall\tagSENT_CONTENT	(\tagSENT_CONTENT	R\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	on\tagSENT_CONTENT	bounded\tagSENT_CONTENT	intervals\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	/\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	perfect\tagSENT_CONTENT	overlapping\tagSENT_CONTENT	test\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	HeidelTime\tagSENT_START	was\tagSENT_CONTENT	developed\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	schema\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	,\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	covers\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	For\tagSENT_START	timex_normalisation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	perform\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	timex_normalisation\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	using\tagSENT_CONTENT	our\tagSENT_CONTENT	interval\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	metric\tagSENT_CONTENT	,\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	select\tagSENT_CONTENT	those\tagSENT_CONTENT	cases\tagSENT_CONTENT	where\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	and\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	match\tagSENT_CONTENT	perfectly\tagSENT_CONTENT	.\tagSENT_END	Consequently\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	remove\tagSENT_CONTENT	timex_normalisation\tagtask	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	ours\tagSENT_CONTENT	and\tagSENT_CONTENT	HeidelTime\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	those\tagSENT_CONTENT	instances\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	run\tagSENT_CONTENT	the\tagSENT_CONTENT	interval\tagSENT_CONTENT	scorer\tagSENT_CONTENT	using\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	still\tagSENT_CONTENT	performs\tagSENT_CONTENT	better\tagSENT_CONTENT	when\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	The\tagSENT_START	SCATE\tagSENT_CONTENT	interpreter\tagSENT_CONTENT	that\tagSENT_CONTENT	encodes\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	intervals\tagSENT_CONTENT	needs\tagSENT_CONTENT	the\tagSENT_CONTENT	compositional\tagSENT_CONTENT	graph\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	to\tagSENT_CONTENT	have\tagSENT_CONTENT	all\tagSENT_CONTENT	its\tagSENT_CONTENT	elements\tagSENT_CONTENT	correct\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	failing\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	any\tagSENT_CONTENT	entity\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	timeexpression\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	totally\tagSENT_CONTENT	uninterpretable\tagSENT_CONTENT	graphs\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	can\tagSENT_CONTENT	also\tagSENT_CONTENT	fail\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	some\tagSENT_CONTENT	time\tagSENT_CONTENT	-\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	like\tagSENT_CONTENT	summer\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	expression\tagSENT_CONTENT	last\tagSENT_CONTENT	summer\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	As\tagSENT_START	for\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	entity\tagSENT_CONTENT	identification\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	differences\tagSENT_CONTENT	between\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	dataset\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	attributed\tagSENT_CONTENT	to\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	10\tagSENT_CONTENT	Season\tagSENT_CONTENT	-\tagSENT_CONTENT	Of\tagSENT_CONTENT	-\tagSENT_CONTENT	Year\tagSENT_CONTENT	annotations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	while\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	no\tagSENT_CONTENT	such\tagSENT_CONTENT	annotations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	dataset\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	frequencies\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	MinuteOf\tagSENT_CONTENT	-\tagSENT_CONTENT	Hour\tagSENT_CONTENT	,\tagSENT_CONTENT	Hour\tagSENT_CONTENT	-\tagSENT_CONTENT	Of\tagSENT_CONTENT	-\tagSENT_CONTENT	Day\tagSENT_CONTENT	,\tagSENT_CONTENT	Two\tagSENT_CONTENT	-\tagSENT_CONTENT	Digit\tagSENT_CONTENT	-\tagSENT_CONTENT	Year\tagSENT_CONTENT	and\tagSENT_CONTENT	TimeZone\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	are\tagSENT_CONTENT	much\tagSENT_CONTENT	lower\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	good\tagSENT_CONTENT	at\tagSENT_CONTENT	predicting\tagSENT_CONTENT	such\tagSENT_CONTENT	annotations\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	verify\tagSENT_CONTENT	the\tagSENT_CONTENT	advantages\tagSENT_CONTENT	of\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	-\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	predicting\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	in\tagSENT_CONTENT	agreement\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	explanations\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	5.1.2\tagSENT_CONTENT	:\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	-\tagSENT_CONTENT	models\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	fail\tagSENT_CONTENT	to\tagSENT_CONTENT	distinguish\tagSENT_CONTENT	numbers\tagSENT_CONTENT	from\tagSENT_CONTENT	digit\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	's\tagSENT_CONTENT	difficult\tagSENT_CONTENT	for\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	-\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	catch\tagSENT_CONTENT	some\tagSENT_CONTENT	patterns\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	24th\tagSENT_CONTENT	and\tagSENT_CONTENT	25th\tagSENT_CONTENT	,\tagSENT_CONTENT	August\tagSENT_CONTENT	and\tagSENT_CONTENT	Aug.\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	characterbased\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	robust\tagSENT_CONTENT	to\tagSENT_CONTENT	such\tagSENT_CONTENT	variance\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	ran\tagSENT_CONTENT	an\tagSENT_CONTENT	experiment\tagSENT_CONTENT	to\tagSENT_CONTENT	see\tagSENT_CONTENT	whether\tagSENT_CONTENT	these\tagSENT_CONTENT	benefits\tagSENT_CONTENT	were\tagSENT_CONTENT	unique\tagSENT_CONTENT	to\tagSENT_CONTENT	compositional\tagSENT_CONTENT	annotations\tagSENT_CONTENT	like\tagSENT_CONTENT	those\tagSENT_CONTENT	of\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	generally\tagSENT_CONTENT	to\tagSENT_CONTENT	simply\tagSENT_CONTENT	recognizing\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	We\tagSENT_START	used\tagSENT_CONTENT	timex_normalisation\tagtask	from\tagSENT_CONTENT	AQUAINT\tagSENT_CONTENT	and\tagSENT_CONTENT	TimeBank\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	two\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	As\tagSENT_START	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	 \tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	time\tagSENT_CONTENT	expressions\tagSENT_CONTENT	(\tagSENT_CONTENT	p=0.0428\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	digits\tagSENT_CONTENT	(\tagSENT_CONTENT	p=0.0007\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	running\tagSENT_CONTENT	the\tagSENT_CONTENT	entity\tagSENT_CONTENT	composition\tagSENT_CONTENT	step\tagSENT_CONTENT	with\tagSENT_CONTENT	gold\tagSENT_CONTENT	entity\tagSENT_CONTENT	identification\tagSENT_CONTENT	achieves\tagSENT_CONTENT	72.6\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	F1\tagmetric	.\tagSENT_END	timex_normalisation\tagtask	prevents\tagSENT_CONTENT	timex_normalisation\tagtask	of\tagSENT_CONTENT	some\tagSENT_CONTENT	links\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	expression\tagSENT_CONTENT	"\tagSENT_CONTENT	Later\tagSENT_CONTENT	"\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	typically\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	another\tagSENT_CONTENT	time\tagSENT_CONTENT	interval\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	previous\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	the\tagSENT_CONTENT	distance\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	longer\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	annotations\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	rule\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	proving\tagSENT_CONTENT	that\tagSENT_CONTENT	describing\tagSENT_CONTENT	timex_normalisation\tagtask	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	compositional\tagSENT_CONTENT	time\tagSENT_CONTENT	entities\tagSENT_CONTENT	is\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	approaches\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	broadens\tagSENT_CONTENT	the\tagSENT_CONTENT	research\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	beyond\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	restricted\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	schema\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	defined\tagSENT_CONTENT	anew\tagSENT_CONTENT	interval\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	that\tagSENT_CONTENT	allows\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	timex_normalisation\tagtask	between\tagSENT_CONTENT	annotations\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	and\tagSENT_CONTENT	TimeML\tagSENT_CONTENT	schema\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	SCATE\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	seen\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	sparse\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	available\tagSENT_CONTENT	induces\tagSENT_CONTENT	model\tagSENT_CONTENT	overfitting\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	largest\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	errors\tagSENT_CONTENT	are\tagSENT_CONTENT	committed\tagSENT_CONTENT	in\tagSENT_CONTENT	those\tagSENT_CONTENT	cases\tagSENT_CONTENT	that\tagSENT_CONTENT	appear\tagSENT_CONTENT	less\tagSENT_CONTENT	frequently\tagSENT_CONTENT	in\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	According\tagSENT_START	to\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	seems\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	solution\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	a\tagSENT_CONTENT	wider\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	a\tagSENT_CONTENT	promising\tagSENT_CONTENT	research\tagSENT_CONTENT	line\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	extend\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	generate\tagSENT_CONTENT	timex_normalisation\tagtask	.\tagSENT_END	Software\tagSECTITLE_END	The\tagSENT_START	code\tagSENT_CONTENT	for\tagSENT_CONTENT	timex_normalisation\tagtask	introduced\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	is\tagSENT_CONTENT	available\tagSENT_CONTENT	at\tagSENT_CONTENT	https://github.com/clulab/timenorm\tagSENT_CONTENT	.\tagSENT_END	
1603.09025	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Whereas\tagSENT_START	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	only\tagSENT_CONTENT	apply\tagSENT_CONTENT	batch\tagSENT_CONTENT	normalization\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	hidden\tagSENT_CONTENT	transformation\tagSENT_CONTENT	of\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	both\tagSENT_CONTENT	possible\tagSENT_CONTENT	and\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	batch\tagSENT_CONTENT	-\tagSENT_CONTENT	normalize\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	hidden\tagSENT_CONTENT	transition\tagSENT_CONTENT	,\tagSENT_CONTENT	thereby\tagSENT_CONTENT	reducing\tagSENT_CONTENT	internal\tagmetric	covariate\tagmetric	shift\tagmetric	between\tagSENT_CONTENT	time\tagSENT_CONTENT	steps\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	proposal\tagSENT_CONTENT	on\tagSENT_CONTENT	various\tagSENT_CONTENT	sequential\tagSENT_CONTENT	problems\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	sequence\tagSENT_CONTENT	classification\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Covariate\tagSENT_START	shift\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	change\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	distribution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	inputs\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	Batch\tagSENT_START	normalization\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	recently\tagSENT_CONTENT	proposed\tagSENT_CONTENT	technique\tagSENT_CONTENT	for\tagSENT_CONTENT	controlling\tagSENT_CONTENT	the\tagSENT_CONTENT	distributions\tagSENT_CONTENT	of\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	activations\tagSENT_CONTENT	,\tagSENT_CONTENT	thereby\tagSENT_CONTENT	reducing\tagSENT_CONTENT	internal\tagmetric	covariate\tagmetric	shift\tagmetric	.\tagSENT_END	It\tagSENT_START	involves\tagSENT_CONTENT	standardizing\tagSENT_CONTENT	the\tagSENT_CONTENT	activations\tagSENT_CONTENT	going\tagSENT_CONTENT	into\tagSENT_CONTENT	each\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	enforcing\tagSENT_CONTENT	their\tagSENT_CONTENT	means\tagSENT_CONTENT	and\tagSENT_CONTENT	variances\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	invariant\tagSENT_CONTENT	to\tagSENT_CONTENT	changes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	parameters\tagmetric	of\tagSENT_CONTENT	the\tagSENT_CONTENT	underlying\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	PREREQUISITES\tagSECTITLE_END	The\tagSENT_START	output\tagSENT_CONTENT	gate\tagSENT_CONTENT	o\tagSENT_CONTENT	t\tagSENT_CONTENT	allows\tagSENT_CONTENT	language_modeling\tagtask	to\tagSENT_CONTENT	read\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	cell\tagSENT_CONTENT	.\tagSENT_END	BATCH\tagSECTITLE_START	NORMALIZATION\tagSECTITLE_END	Covariate\tagSENT_START	shift\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	phenomenon\tagSENT_CONTENT	in\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	features\tagSENT_CONTENT	presented\tagSENT_CONTENT	to\tagSENT_CONTENT	language_modeling\tagtask	in\tagSENT_CONTENT	distribution\tagSENT_CONTENT	.\tagSENT_END	Batch\tagSENT_START	Normalization\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	recently\tagSENT_CONTENT	proposed\tagSENT_CONTENT	network\tagSENT_CONTENT	reparameterization\tagSENT_CONTENT	which\tagSENT_CONTENT	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	reduce\tagSENT_CONTENT	internal\tagmetric	covariate\tagmetric	shift\tagmetric	.\tagSENT_END	Rd\tagSENT_START	are\tagSENT_CONTENT	model\tagmetric	parameters\tagmetric	that\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	and\tagSENT_CONTENT	standard\tagSENT_CONTENT	deviation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	normalized\tagSENT_CONTENT	activation\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	regularization\tagSENT_CONTENT	hyperparameter\tagSENT_CONTENT	.\tagSENT_END	BATCH\tagSECTITLE_START	-\tagSECTITLE_CONTENT	NORMALIZED\tagSECTITLE_CONTENT	LSTM\tagSECTITLE_END	Normalizing\tagSENT_START	these\tagSENT_CONTENT	terms\tagSENT_CONTENT	individually\tagSENT_CONTENT	gives\tagSENT_CONTENT	language_modeling\tagtask	better\tagSENT_CONTENT	control\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	terms\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	γ\tagSENT_CONTENT	hand\tagSENT_CONTENT	γ\tagSENT_CONTENT	x\tagSENT_CONTENT	parameters\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	would\tagSENT_CONTENT	seem\tagSENT_CONTENT	natural\tagSENT_CONTENT	to\tagSENT_CONTENT	share\tagSENT_CONTENT	the\tagSENT_CONTENT	statistics\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	normalization\tagSENT_CONTENT	across\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	just\tagSENT_CONTENT	as\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	share\tagSENT_CONTENT	their\tagmetric	parameters\tagmetric	overtime\tagSENT_CONTENT	.\tagSENT_END	Generalizing\tagSENT_START	language_modeling\tagtask	to\tagSENT_CONTENT	sequences\tagSENT_CONTENT	longer\tagSENT_CONTENT	than\tagSENT_CONTENT	those\tagSENT_CONTENT	seen\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	thanks\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	rapid\tagSENT_CONTENT	convergence\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	activations\tagSENT_CONTENT	to\tagSENT_CONTENT	their\tagSENT_CONTENT	steady\tagSENT_CONTENT	-\tagSENT_CONTENT	state\tagSENT_CONTENT	distributions\tagSENT_CONTENT	(\tagSENT_CONTENT	cf\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	INITIALIZING\tagSECTITLE_START	γ\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	GRADIENT\tagSECTITLE_CONTENT	FLOW\tagSECTITLE_END	Although\tagSENT_START	batch\tagSENT_CONTENT	normalization\tagSENT_CONTENT	allows\tagSENT_CONTENT	for\tagSENT_CONTENT	easy\tagSENT_CONTENT	control\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	activation\tagSENT_CONTENT	variance\tagSENT_CONTENT	through\tagSENT_CONTENT	the\tagmetric	γ\tagmetric	parameters\tagmetric	,\tagSENT_CONTENT	common\tagSENT_CONTENT	practice\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	normalize\tagSENT_CONTENT	to\tagSENT_CONTENT	unit\tagSENT_CONTENT	variance\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	SEQUENTIAL\tagSECTITLE_START	MNIST\tagSECTITLE_END	language_modeling\tagtask	processes\tagSENT_CONTENT	each\tagSENT_CONTENT	image\tagSENT_CONTENT	one\tagSENT_CONTENT	pixel\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	finally\tagSENT_CONTENT	predicts\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	.\tagSENT_END	language_modeling\tagtask	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	using\tagSENT_CONTENT	RMSProp\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	learning\tagSENT_CONTENT	rate\tagSENT_CONTENT	of\tagSENT_CONTENT	10\tagSENT_CONTENT	−3\tagSENT_CONTENT	and\tagSENT_CONTENT	0.9\tagSENT_CONTENT	momentum\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	in\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	MNIST\tagSENT_CONTENT	task\tagSENT_CONTENT	poses\tagSENT_CONTENT	a\tagSENT_CONTENT	unique\tagSENT_CONTENT	problem\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	:\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	hundred\tagSENT_CONTENT	or\tagSENT_CONTENT	so\tagSENT_CONTENT	timesteps\tagSENT_CONTENT	is\tagSENT_CONTENT	constant\tagSENT_CONTENT	across\tagSENT_CONTENT	examples\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	pixels\tagSENT_CONTENT	are\tagSENT_CONTENT	almost\tagSENT_CONTENT	always\tagSENT_CONTENT	black\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	CHARACTER\tagSECTITLE_START	-\tagSECTITLE_CONTENT	LEVEL\tagSECTITLE_CONTENT	PENN\tagSECTITLE_CONTENT	TREEBANK\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_END	Our\tagSENT_START	baseline\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	1000\tagSENT_CONTENT	units\tagSENT_CONTENT	,\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagmetric	next\tagmetric	character\tagmetric	using\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	ht\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	the\tagSENT_CONTENT	generalization\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	to\tagSENT_CONTENT	longer\tagSENT_CONTENT	sequences\tagSENT_CONTENT	.\tagSENT_END	TEXT8\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	a\tagSENT_CONTENT	second\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	task\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	much\tagSENT_CONTENT	larger\tagSENT_CONTENT	text8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	and\tagSENT_CONTENT	batch\tagSENT_CONTENT	-\tagSENT_CONTENT	normalized\tagSENT_CONTENT	models\tagSENT_CONTENT	are\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	with\tagSENT_CONTENT	2000\tagSENT_CONTENT	units\tagSENT_CONTENT	,\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagmetric	next\tagmetric	character\tagmetric	using\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	classifier\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	ht\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	text8\tagSECTITLE_END	td\tagSENT_START	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	:\tagSENT_CONTENT	Bits\tagSENT_CONTENT	-\tagSENT_CONTENT	per\tagSENT_CONTENT	-\tagSENT_CONTENT	character\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	text8\tagSENT_CONTENT	test\tagSENT_CONTENT	sequence\tagSENT_CONTENT	.\tagSENT_END	TEACHING\tagSECTITLE_START	MACHINES\tagSECTITLE_CONTENT	TO\tagSECTITLE_CONTENT	READ\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	COMPREHEND\tagSECTITLE_END	Recently\tagSENT_START	,\tagSENT_CONTENT	introduced\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	challenging\tagSENT_CONTENT	benchmarks\tagSENT_CONTENT	for\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	architectures\tagSENT_CONTENT	to\tagSENT_CONTENT	address\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	See\tagSENT_START	Appendix\tagSENT_CONTENT	C\tagSENT_CONTENT	for\tagSENT_CONTENT	hyperparameters\tagmetric	and\tagSENT_CONTENT	task\tagSENT_CONTENT	details\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	train\tagSENT_CONTENT	and\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	BN\tagSENT_CONTENT	-\tagSENT_CONTENT	e\tagSENT_END	Model\tagSECTITLE_END	CONCLUSION\tagSECTITLE_END	our\tagSENT_START	proposed\tagSENT_CONTENT	BN\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	trains\tagSENT_CONTENT	faster\tagSENT_CONTENT	and\tagSENT_CONTENT	generalizes\tagSENT_CONTENT	better\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	tasks\tagSENT_CONTENT	including\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	B\tagSECTITLE_START	SENSITIVITY\tagSECTITLE_CONTENT	TO\tagSECTITLE_CONTENT	INITIALIZATION\tagSECTITLE_CONTENT	OF\tagSECTITLE_CONTENT	γ\tagSECTITLE_END	The\tagSENT_START	pMNIST\tagSENT_CONTENT	training\tagSENT_CONTENT	curves\tagSENT_CONTENT	confirm\tagSENT_CONTENT	that\tagSENT_CONTENT	higher\tagSENT_CONTENT	initial\tagSENT_CONTENT	values\tagSENT_CONTENT	of\tagSENT_CONTENT	γ\tagSENT_CONTENT	are\tagSENT_CONTENT	detrimental\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	optimization\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	.\tagSENT_END	For\tagSENT_START	pMNIST\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	absorbs\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	and\tagSENT_CONTENT	only\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	does\tagSENT_CONTENT	it\tagSENT_CONTENT	make\tagSENT_CONTENT	a\tagSENT_CONTENT	prediction\tagSENT_CONTENT	on\tagSENT_CONTENT	which\tagSENT_CONTENT	it\tagSENT_CONTENT	receives\tagSENT_CONTENT	feedback\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	task\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	makes\tagSENT_CONTENT	a\tagSENT_CONTENT	prediction\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	timestep\tagSENT_CONTENT	.\tagSENT_END	C\tagSECTITLE_START	TEACHING\tagSECTITLE_CONTENT	MACHINES\tagSECTITLE_CONTENT	TO\tagSECTITLE_CONTENT	READ\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	COMPREHEND\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	TASK\tagSECTITLE_CONTENT	SETUP\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	language_modeling\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	task\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	CNN\tagSENT_CONTENT	corpus\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	placeholders\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	named\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	D\tagSECTITLE_START	HYPERPARAMETER\tagSECTITLE_CONTENT	SEARCHES\tagSECTITLE_END	For\tagSENT_START	MNIST\tagSENT_CONTENT	and\tagSENT_CONTENT	pMNIST\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	hyperparameters\tagmetric	were\tagSENT_CONTENT	varied\tagSENT_CONTENT	independently\tagSENT_CONTENT	.\tagSENT_END	
1711.04903	title\tagSECTITLE_END	abstract\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	corpus\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	Universal\tagSENT_CONTENT	Dependencies\tagSENT_CONTENT	(\tagSENT_CONTENT	UD\tagdataset	)\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	27\tagSENT_CONTENT	languages\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	find\tagSENT_CONTENT	that\tagSENT_CONTENT	AT\tagSENT_CONTENT	not\tagSENT_CONTENT	only\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagmetric	overall\tagmetric	tagging\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	prevents\tagSENT_CONTENT	over\tagSENT_CONTENT	-\tagSENT_CONTENT	fitting\tagSENT_CONTENT	well\tagSENT_CONTENT	in\tagSENT_CONTENT	low\tagSENT_CONTENT	resource\tagSENT_CONTENT	languages\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	boosts\tagSENT_CONTENT	tagging\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	rare\tagSENT_CONTENT	/\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Figure\tagSENT_START	1\tagSENT_CONTENT	:\tagSENT_CONTENT	Illustration\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	architecture\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	.\tagSENT_END	Effects\tagSECTITLE_START	on\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	target\tagSECTITLE_CONTENT	languages\tagSECTITLE_CONTENT	•\tagSECTITLE_CONTENT	Vocabulary\tagSECTITLE_CONTENT	statistics\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	tagging\tagSECTITLE_CONTENT	accuracy\tagSECTITLE_CONTENT	•\tagSECTITLE_CONTENT	Influence\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	downstream\tagSECTITLE_CONTENT	tasks\tagSECTITLE_CONTENT	•\tagSECTITLE_CONTENT	Representation\tagSECTITLE_CONTENT	learning\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	words\tagSECTITLE_END	•\tagSENT_START	AT\tagSENT_CONTENT	can\tagSENT_CONTENT	boost\tagSENT_CONTENT	the\tagSENT_CONTENT	tagging\tagSENT_CONTENT	performance\tagSENT_CONTENT	for\tagSENT_CONTENT	rare/\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	increase\tagSENT_CONTENT	the\tagmetric	sentence\tagmetric	-\tagmetric	level\tagmetric	accuracy\tagmetric	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	POS\tagSECTITLE_START	Tagging\tagSECTITLE_END	While\tagSENT_START	current\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	theart\tagSENT_CONTENT	POS\tagSENT_CONTENT	taggers\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	yield\tagSENT_CONTENT	accuracy\tagmetric	over\tagSENT_CONTENT	97.5\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	PTB\tagSENT_CONTENT	-\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	still\tagSENT_CONTENT	remain\tagSENT_CONTENT	issues\tagSENT_CONTENT	.\tagSENT_END	Adversarial\tagSECTITLE_START	Training\tagSECTITLE_END	Method\tagSECTITLE_END	Baseline\tagSECTITLE_START	POS\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Prior\tagSENT_START	work\tagSENT_CONTENT	has\tagSENT_CONTENT	shown\tagSENT_CONTENT	that\tagSENT_CONTENT	incorporating\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	can\tagSENT_CONTENT	boost\tagSENT_CONTENT	part-of-speech_tagging\tagtask	by\tagSENT_CONTENT	capturing\tagSENT_CONTENT	morphological\tagSENT_CONTENT	information\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	Adversarial\tagSECTITLE_START	Training\tagSECTITLE_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	per\tagSENT_CONTENT	token\tagmetric	tagging\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	As\tagSENT_START	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	(\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	accuracy\tagmetric	97.54\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	performs\tagSENT_CONTENT	on\tagSENT_CONTENT	par\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	.\tagSENT_END	Our\tagSECTITLE_START	Models\tagSECTITLE_END	Analysis\tagSECTITLE_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	AT\tagSENT_CONTENT	can\tagSENT_CONTENT	boost\tagSENT_CONTENT	tagging\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	rare\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	neighbors\tagSENT_CONTENT	of\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	5.1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Word\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	Poor\tagmetric	tagging\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	rare\tagSENT_CONTENT	/\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	is\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	bottlenecks\tagSENT_CONTENT	in\tagSENT_CONTENT	current\tagSENT_CONTENT	POS\tagSENT_CONTENT	taggers\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	define\tagSENT_CONTENT	rare\tagSENT_CONTENT	/\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	's\tagSENT_CONTENT	frequency\tagSENT_CONTENT	of\tagSENT_CONTENT	occurrence\tagmetric	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	categorize\tagSENT_CONTENT	all\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	this\tagSENT_CONTENT	frequency\tagSENT_CONTENT	and\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagmetric	test\tagmetric	tagging\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	each\tagSENT_CONTENT	group\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	cluster\tagSENT_CONTENT	all\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	frequency\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	again\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	consider\tagSENT_CONTENT	the\tagmetric	tagging\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	neighbors\tagSENT_CONTENT	(\tagSENT_CONTENT	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	&\tagSECTITLE_CONTENT	Downstream\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	AT\tagSENT_CONTENT	can\tagSENT_CONTENT	boost\tagSENT_CONTENT	tagging\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	rare\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	neighbors\tagSENT_CONTENT	of\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	enhancing\tagSENT_CONTENT	overall\tagSENT_CONTENT	robustness\tagSENT_CONTENT	on\tagSENT_CONTENT	rare\tagSENT_CONTENT	/\tagSENT_CONTENT	unseen\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	AT\tagSENT_START	POS\tagSENT_CONTENT	taggers\tagSENT_CONTENT	,\tagSENT_CONTENT	supporting\tagSENT_CONTENT	the\tagSENT_CONTENT	claim\tagSENT_CONTENT	that\tagSENT_CONTENT	part-of-speech_tagging\tagtask	needs\tagSENT_CONTENT	further\tagSENT_CONTENT	improvement\tagSENT_CONTENT	for\tagSENT_CONTENT	downstream\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Effects\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Representation\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	We\tagSENT_START	compare\tagSENT_CONTENT	this\tagSENT_CONTENT	clustering\tagSENT_CONTENT	quality\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	settings\tagSENT_CONTENT	:\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	beginning\tagSENT_CONTENT	(\tagSENT_CONTENT	initialized\tagSENT_CONTENT	with\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	or\tagSENT_CONTENT	Polyglot\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	after\tagSENT_CONTENT	part-of-speech_tagging\tagtask	(\tagSENT_CONTENT	50\tagSENT_CONTENT	epochs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	after\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	50\tagSENT_CONTENT	epochs\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	effects\tagSENT_CONTENT	of\tagSENT_CONTENT	AT\tagSENT_CONTENT	on\tagSENT_CONTENT	word\tagSENT_CONTENT	representation\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Other\tagSECTITLE_START	Sequence\tagSECTITLE_CONTENT	Labeling\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	These\tagSENT_START	improvements\tagSENT_CONTENT	made\tagSENT_CONTENT	by\tagSENT_CONTENT	AT\tagSENT_CONTENT	are\tagSENT_CONTENT	bigger\tagSENT_CONTENT	than\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	part-of-speech_tagging\tagtask	,\tagSENT_CONTENT	most\tagSENT_CONTENT	likely\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	larger\tagSENT_CONTENT	room\tagSENT_CONTENT	for\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	chunking\tagSENT_CONTENT	and\tagSENT_CONTENT	NER\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	and\tagSENT_CONTENT	carefully\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	part-of-speech_tagging\tagtask	that\tagSENT_CONTENT	exploits\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	training\tagSENT_CONTENT	(\tagSENT_CONTENT	AT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	
1811.04210	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Our\tagSENT_START	proposed\tagSENT_CONTENT	approach\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	all\tagSENT_CONTENT	four\tagSENT_CONTENT	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	question_answering\tagtask	by\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	2.6\tagSENT_CONTENT	%\tagSENT_CONTENT	−\tagSENT_CONTENT	14.2\tagSENT_CONTENT	%\tagSENT_CONTENT	in\tagSENT_CONTENT	absolute\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Finally\tagSENT_START	,\tagSENT_CONTENT	these\tagSENT_CONTENT	attended\tagSENT_CONTENT	representations\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	reasoned\tagSENT_CONTENT	over\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	(\tagSENT_CONTENT	point\tagSENT_CONTENT	to\tagSENT_CONTENT	)\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	established\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	increasing\tagSENT_CONTENT	the\tagSENT_CONTENT	depth\tagSENT_CONTENT	may\tagSENT_CONTENT	impair\tagSENT_CONTENT	gradient\tagSENT_CONTENT	flow\tagSENT_CONTENT	and\tagSENT_CONTENT	feature\tagSENT_CONTENT	propagation\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	networks\tagmetric	harder\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	propagated\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	collectively\tagSENT_CONTENT	passed\tagSENT_CONTENT	into\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	effectively\tagSENT_CONTENT	connect\tagSENT_CONTENT	shallow\tagSENT_CONTENT	layers\tagSENT_CONTENT	to\tagSENT_CONTENT	deeper\tagSENT_CONTENT	layers\tagSENT_CONTENT	.\tagSENT_END	DECAPROP\tagSENT_START	achieves\tagSENT_CONTENT	a\tagSENT_CONTENT	significant\tagSENT_CONTENT	gain\tagSENT_CONTENT	of\tagSENT_CONTENT	2.6\tagSENT_CONTENT	%\tagSENT_CONTENT	−\tagSENT_CONTENT	14.2\tagSENT_CONTENT	%\tagSENT_CONTENT	absolute\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	existing\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	four\tagSENT_CONTENT	challenging\tagSENT_CONTENT	RC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	,\tagSENT_CONTENT	Quasar\tagmetric	-\tagmetric	T\tagmetric	[\tagSENT_CONTENT	,\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	and\tagSENT_CONTENT	NarrativeQA\tagSENT_CONTENT	.\tagSENT_END	Bidirectional\tagSECTITLE_START	Attention\tagSECTITLE_CONTENT	Connectors\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	BAC\tagSECTITLE_CONTENT	)\tagSECTITLE_END	where\tagSENT_START	F\tagmetric	(\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	standard\tagSENT_CONTENT	dense\tagSENT_CONTENT	layer\tagSENT_CONTENT	with\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	activations\tagSENT_CONTENT	and\tagSENT_CONTENT	dis\tagSENT_CONTENT	the\tagSENT_CONTENT	dimensionality\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	vectors\tagSENT_CONTENT	.\tagSENT_END	Densely\tagSECTITLE_START	Connected\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Propagation\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DECAPROP\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Contextualized\tagSECTITLE_START	Input\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_END	Given\tagSENT_START	Q\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	RC\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	select\tagSENT_CONTENT	a\tagSENT_CONTENT	sequence\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	P\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Densely\tagSECTITLE_START	Connected\tagSECTITLE_CONTENT	Attention\tagSECTITLE_CONTENT	Encoder\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DECAENC\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Densely\tagSECTITLE_START	Connected\tagSECTITLE_CONTENT	Core\tagSECTITLE_CONTENT	Architecture\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	DECACORE\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Gated\tagSECTITLE_START	Attention\tagSECTITLE_END	where\tagSENT_START	σ\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	sigmoid\tagSENT_CONTENT	function\tagSENT_CONTENT	and\tagSENT_CONTENT	F\tagmetric	(\tagSENT_CONTENT	.\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	dense\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	activations\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	denote\tagSENT_CONTENT	them\tagmetric	as\tagSENT_CONTENT	U\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	U\tagSENT_CONTENT	2\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Answer\tagSECTITLE_START	Pointer\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Prediction\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Next\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	pass\tagSENT_CONTENT	M\tagmetric	through\tagSENT_CONTENT	a\tagSENT_CONTENT	stacked\tagSENT_CONTENT	BiRNN\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	layers\tagSENT_CONTENT	and\tagSENT_CONTENT	obtain\tagSENT_CONTENT	two\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	H\tagSENT_CONTENT	†\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	H\tagSENT_CONTENT	†\tagSENT_CONTENT	2\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	The\tagmetric	start\tagmetric	and\tagSENT_CONTENT	end\tagSENT_CONTENT	pointers\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	learned\tagSENT_CONTENT	via\tagSENT_CONTENT	:\tagSENT_END	where\tagSENT_START	w\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	2\tagSENT_CONTENT	∈\tagSENT_CONTENT	Rd\tagSENT_CONTENT	are\tagSENT_CONTENT	parameters\tagmetric	of\tagSENT_CONTENT	this\tagSENT_CONTENT	layer\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	train\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	minimize\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	negative\tagSENT_CONTENT	log\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagmetric	start\tagmetric	and\tagSENT_CONTENT	end\tagSENT_CONTENT	indices\tagSENT_CONTENT	:\tagSENT_END	i\tagSENT_START	are\tagSENT_CONTENT	the\tagmetric	true\tagmetric	start\tagmetric	and\tagSENT_CONTENT	end\tagSENT_CONTENT	indices\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Competitor\tagSECTITLE_CONTENT	Baselines\tagSECTITLE_END	NewsQA\tagdataset	This\tagSENT_CONTENT	challenging\tagSENT_CONTENT	RC\tagSENT_CONTENT	dataset\tagSENT_CONTENT	comprises\tagSENT_CONTENT	100k\tagSENT_CONTENT	QA\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	The\tagSENT_START	sequence\tagSENT_CONTENT	lengths\tagSENT_CONTENT	are\tagSENT_CONTENT	capped\tagSENT_CONTENT	at\tagSENT_CONTENT	800/700/1500/1100\tagSENT_CONTENT	for\tagSENT_CONTENT	NewsQA\tagdataset	,\tagSENT_CONTENT	SearchQA\tagSENT_CONTENT	,\tagSENT_CONTENT	Quasar\tagSENT_CONTENT	-\tagSENT_CONTENT	T\tagSENT_CONTENT	and\tagSENT_CONTENT	NarrativeQA\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	NewsQA\tagdataset	reports\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	.\tagSENT_END	Quasar\tagmetric	-\tagmetric	T\tagmetric	reports\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	Quasar\tagSENT_CONTENT	-\tagSENT_CONTENT	T.\tagSENT_END	SearchQA\tagSENT_START	report\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	8\tagSENT_CONTENT	on\tagSENT_CONTENT	SearchQA\tagdataset	.\tagSENT_END	NarrativeQA\tagdataset	reports\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	NarrativeQA\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	our\tagSENT_CONTENT	model\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	achieve\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	outperform\tagSENT_CONTENT	the\tagmetric	base\tagmetric	R\tagmetric	-\tagmetric	NET\tagmetric	(\tagSENT_CONTENT	both\tagSENT_CONTENT	our\tagSENT_CONTENT	implementation\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	published\tagSENT_CONTENT	score\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Ablation\tagSECTITLE_START	Study\tagSECTITLE_END	More\tagSENT_START	specifically\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	scores\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSENT_START	lieu\tagmetric	of\tagSENT_CONTENT	reviewer\tagSENT_CONTENT	requests\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	include\tagSENT_CONTENT	preliminary\tagSENT_CONTENT	results\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	dev\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	original\tagSENT_CONTENT	R\tagSENT_CONTENT	-\tagSENT_CONTENT	NET\tagSENT_CONTENT	performs\tagSENT_CONTENT	at\tagSENT_CONTENT	≈\tagSENT_CONTENT	2\tagSENT_CONTENT	%\tagSENT_CONTENT	lower\tagSENT_CONTENT	on\tagSENT_CONTENT	NewsQA\tagdataset	.\tagSENT_END	(\tagSENT_START	2\tagSENT_CONTENT	)\tagSENT_CONTENT	invoking\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	Mnemonic\tagSENT_CONTENT	Reader\tagSENT_CONTENT	,\tagSENT_CONTENT	ReasoNet\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_END	Conclusion\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	first\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	explore\tagSENT_CONTENT	the\tagSENT_CONTENT	possibilities\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	skip\tagSENT_CONTENT	-\tagSENT_CONTENT	connector\tagSENT_CONTENT	.\tagSENT_END	
1805.01052	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	approaches\tagSENT_CONTENT	have\tagSENT_CONTENT	led\tagSENT_CONTENT	to\tagSENT_CONTENT	improvements\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	parser\tagSENT_CONTENT	that\tagSENT_CONTENT	combines\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	built\tagSENT_CONTENT	using\tagSENT_CONTENT	this\tagSENT_CONTENT	kind\tagSENT_CONTENT	of\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attentive\tagSENT_CONTENT	architecture\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	decoder\tagSENT_CONTENT	customized\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	neural\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	makes\tagSENT_CONTENT	explicit\tagSENT_CONTENT	the\tagSENT_CONTENT	manner\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	transferred\tagSENT_CONTENT	between\tagSENT_CONTENT	different\tagSENT_CONTENT	locations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	to\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	importance\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	to\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Our\tagSENT_START	parser\tagSENT_CONTENT	achieves\tagSENT_CONTENT	93.55\tagSENT_CONTENT	F1\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	when\tagSENT_CONTENT	not\tagSENT_CONTENT	using\tagSENT_CONTENT	external\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	constituency_parsing\tagtask	trained\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Base\tagSECTITLE_START	Model\tagSECTITLE_END	Tree\tagSECTITLE_START	Scores\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Chart\tagSECTITLE_CONTENT	Decoder\tagSECTITLE_END	Context\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Aware\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Representations\tagSECTITLE_END	All\tagSENT_START	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	are\tagSENT_CONTENT	learned\tagSENT_CONTENT	jointly\tagSENT_CONTENT	with\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Multi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Head\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Self\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Position\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Wise\tagSECTITLE_CONTENT	Feed\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Forward\tagSECTITLE_CONTENT	Sublayer\tagSECTITLE_END	Span\tagSECTITLE_START	Scores\tagSECTITLE_END	Results\tagSECTITLE_END	Content\tagSECTITLE_START	vs.\tagSECTITLE_CONTENT	Position\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	In\tagSENT_START	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	addition\tagSENT_CONTENT	often\tagSENT_CONTENT	perform\tagSENT_CONTENT	similarly\tagSENT_CONTENT	in\tagSENT_CONTENT	high\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	(\tagSENT_CONTENT	especially\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	immediately\tagSENT_CONTENT	multiplied\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	that\tagSENT_CONTENT	intermingles\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	sources\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	simplicity\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	split\tagSENT_CONTENT	each\tagSENT_CONTENT	vector\tagSENT_CONTENT	into\tagSENT_CONTENT	equal\tagSENT_CONTENT	halves\tagSENT_CONTENT	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	position\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	cutting\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	model\tagSENT_CONTENT	parameters\tagSENT_CONTENT	roughly\tagSENT_CONTENT	in\tagSENT_CONTENT	half\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	model\tagSENT_CONTENT	achieves\tagSENT_CONTENT	92.63\tagSENT_CONTENT	F1\tagSENT_CONTENT	(\tagSENT_CONTENT	not\tagSENT_CONTENT	much\tagSENT_CONTENT	different\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	unfactored\tagSENT_CONTENT	model\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	supports\tagSENT_CONTENT	our\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	constituency_parsing\tagtask	of\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSECTITLE_END	Content\tagSECTITLE_END	Position\tagSENT_START	attention\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	contributor\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	also\tagSENT_CONTENT	helpful\tagSENT_CONTENT	(\tagSENT_CONTENT	especially\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_START	of\tagSECTITLE_CONTENT	our\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Content\tagSECTITLE_START	vs.\tagSECTITLE_CONTENT	Position\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	Windowed\tagSECTITLE_START	Attention\tagSECTITLE_END	Lexical\tagSECTITLE_START	Models\tagSECTITLE_END	Models\tagSECTITLE_START	with\tagSECTITLE_CONTENT	Subword\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	External\tagSECTITLE_START	Embeddings\tagSECTITLE_END	LR\tagSECTITLE_START	LP\tagSECTITLE_CONTENT	F1\tagSECTITLE_END	Results\tagSECTITLE_END	English\tagSECTITLE_START	(\tagSECTITLE_CONTENT	WSJ\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Our\tagSENT_START	WSJ\tagSENT_CONTENT	-\tagSENT_CONTENT	constituency_parsing\tagtask	took\tagSENT_CONTENT	18\tagSENT_CONTENT	hours\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	Tesla\tagSENT_CONTENT	K80\tagSENT_CONTENT	GPU\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	parse\tagSENT_CONTENT	the\tagSENT_CONTENT	  \tagSENT_CONTENT	1,700-sentence\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	in\tagSENT_CONTENT	8\tagSENT_CONTENT	seconds\tagSENT_CONTENT	.\tagSENT_END	Multilingual\tagSECTITLE_START	(\tagSECTITLE_CONTENT	SPMRL\tagSECTITLE_CONTENT	)\tagSECTITLE_END	Conclusion\tagSECTITLE_END	Our\tagSENT_START	results\tagSENT_CONTENT	suggest\tagSENT_CONTENT	that\tagSENT_CONTENT	further\tagSENT_CONTENT	research\tagSENT_CONTENT	into\tagSENT_CONTENT	different\tagSENT_CONTENT	ways\tagSENT_CONTENT	of\tagSENT_CONTENT	encoding\tagSENT_CONTENT	utterances\tagSENT_CONTENT	can\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	additional\tagSENT_CONTENT	improvements\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	and\tagSENT_CONTENT	other\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Symbol\tagSECTITLE_START	Description\tagSECTITLE_END	A\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	Details\tagSECTITLE_END	A.1\tagSECTITLE_START	Model\tagSECTITLE_CONTENT	Hyperparameters\tagSECTITLE_END	A.2\tagSECTITLE_START	Optimizer\tagSECTITLE_CONTENT	Parameters\tagSECTITLE_END	A.3\tagSECTITLE_START	Position\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_END	
S18-1152	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Formal\tagSECTITLE_START	concept\tagSECTITLE_CONTENT	analysis\tagSECTITLE_END	Our\tagSECTITLE_START	approach\tagSECTITLE_END	Results\tagSECTITLE_END	Our\tagSECTITLE_START	submissions\tagSECTITLE_END	Query\tagSECTITLE_START	type\tagSECTITLE_CONTENT	sensitive\tagSECTITLE_CONTENT	baselining\tagSECTITLE_END	Post\tagSECTITLE_START	-\tagSECTITLE_CONTENT	evaluation\tagSECTITLE_CONTENT	analysis\tagSECTITLE_END	Conclusion\tagSECTITLE_END	
1609.05284	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Teaching\tagSENT_START	a\tagSENT_CONTENT	computer\tagSENT_CONTENT	to\tagSENT_CONTENT	read\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	pertaining\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	challenging\tagSENT_CONTENT	yet\tagSENT_CONTENT	unsolved\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Toward\tagSENT_START	solving\tagSENT_CONTENT	this\tagSENT_CONTENT	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	several\tagSENT_CONTENT	works\tagSENT_CONTENT	have\tagSENT_CONTENT	collected\tagSENT_CONTENT	various\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	machine\tagSENT_CONTENT	on\tagSENT_CONTENT	answering\tagSENT_CONTENT	a\tagSENT_CONTENT	question\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	provided\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	considering\tagSENT_CONTENT	the\tagSENT_CONTENT	sophistication\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	after\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	turn\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	,\tagSENT_CONTENT	readers\tagSENT_CONTENT	often\tagSENT_CONTENT	revisit\tagSENT_CONTENT	some\tagSENT_CONTENT	speciic\tagSENT_CONTENT	passage\tagSENT_CONTENT	or\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	grasp\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	when\tagSENT_CONTENT	human\tagSENT_CONTENT	read\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	with\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	mind\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	often\tagSENT_CONTENT	decide\tagSENT_CONTENT	whether\tagSENT_CONTENT	we\tagSENT_CONTENT	want\tagSENT_CONTENT	to\tagSENT_CONTENT	stop\tagSENT_CONTENT	reading\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	the\tagSENT_CONTENT	observed\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	adequate\tagSENT_CONTENT	already\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	continue\tagSENT_CONTENT	reading\tagSENT_CONTENT	after\tagSENT_CONTENT	digesting\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	information\tagSENT_CONTENT	until\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	answer\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	with\tagSENT_CONTENT	conndence\tagSENT_CONTENT	.\tagSENT_END	With\tagSENT_START	question_answering\tagtask	in\tagSENT_CONTENT	mind\tagSENT_CONTENT	,\tagSENT_CONTENT	ReasoNets\tagSENT_CONTENT	read\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	repeatedly\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	focusing\tagSENT_CONTENT	on\tagSENT_CONTENT	diierent\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	until\tagSENT_CONTENT	a\tagSENT_CONTENT	satisfying\tagSENT_CONTENT	answer\tagSENT_CONTENT	is\tagSENT_CONTENT	found\tagSENT_CONTENT	or\tagSENT_CONTENT	formed\tagSENT_CONTENT	.\tagSENT_END	RELATED\tagSECTITLE_START	WORK\tagSECTITLE_END	This\tagSENT_START	can\tagSENT_CONTENT	bethought\tagSENT_CONTENT	of\tagSENT_CONTENT	as\tagSENT_CONTENT	treating\tagSENT_CONTENT	some\tagSENT_CONTENT	parts\tagSENT_CONTENT	unimportant\tagSENT_CONTENT	while\tagSENT_CONTENT	focusing\tagSENT_CONTENT	on\tagSENT_CONTENT	other\tagSENT_CONTENT	important\tagSENT_CONTENT	ones\tagSENT_CONTENT	to\tagSENT_CONTENT	nd\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Iterative\tagSENT_START	Alternative\tagSENT_CONTENT	(\tagSENT_CONTENT	IA\tagSENT_CONTENT	)\tagSENT_CONTENT	reader\tagSENT_CONTENT	produces\tagSENT_CONTENT	anew\tagSENT_CONTENT	query\tagSENT_CONTENT	glimpse\tagSENT_CONTENT	and\tagSENT_CONTENT	document\tagSENT_CONTENT	glimpse\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	iteration\tagSENT_CONTENT	and\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	them\tagmetric	alternatively\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	iteration\tagSENT_CONTENT	.\tagSENT_END	By\tagSENT_START	reading\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	enriching\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	in\tagSENT_CONTENT	an\tagSENT_CONTENT	iterative\tagSENT_CONTENT	fashion\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	has\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	their\tagSENT_CONTENT	superior\tagSENT_CONTENT	performance\tagSENT_CONTENT	consistently\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	termination\tagSENT_CONTENT	module\tagSENT_CONTENT	can\tagSENT_CONTENT	decide\tagSENT_CONTENT	whether\tagSENT_CONTENT	to\tagSENT_CONTENT	continue\tagSENT_CONTENT	to\tagSENT_CONTENT	infer\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	turn\tagSENT_CONTENT	after\tagSENT_CONTENT	digesting\tagSENT_CONTENT	intermediate\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	to\tagSENT_CONTENT	terminate\tagSENT_CONTENT	the\tagSENT_CONTENT	whole\tagSENT_CONTENT	inference\tagSENT_CONTENT	process\tagSENT_CONTENT	when\tagSENT_CONTENT	it\tagSENT_CONTENT	concludes\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	suucient\tagSENT_CONTENT	to\tagSENT_CONTENT	yield\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	REASONING\tagSECTITLE_START	NETWORKS\tagSECTITLE_END	ReasoNets\tagSENT_START	read\tagSENT_CONTENT	a\tagSENT_CONTENT	document\tagSENT_CONTENT	repeatedly\tagSENT_CONTENT	with\tagSENT_CONTENT	attention\tagSENT_CONTENT	on\tagSENT_CONTENT	diierent\tagSENT_CONTENT	parts\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	until\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	found\tagSENT_CONTENT	.\tagSENT_END	M\tagmetric	:\tagSENT_CONTENT	x\tagSENT_END	s\tagSENT_START	t\tagSENT_CONTENT	,\tagSENT_CONTENT	M\tagmetric	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Internal\tagSENT_START	State\tagSENT_CONTENT	:\tagSENT_CONTENT	The\tagSENT_CONTENT	internal\tagSENT_CONTENT	state\tagSENT_CONTENT	is\tagSENT_CONTENT	denoted\tagSENT_CONTENT	ass\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	s\tagSENT_START	t\tagSENT_CONTENT	,\tagSENT_CONTENT	M\tagmetric	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	4\tagSENT_CONTENT	Update\tagSENT_CONTENT	internal\tagSENT_CONTENT	state\tagSENT_CONTENT	st\tagSENT_CONTENT	+1\tagSENT_CONTENT	=\tagSENT_END	The\tagSENT_START	ReasoNet\tagSENT_CONTENT	performs\tagSENT_CONTENT	question_answering\tagtask	a\tagSENT_CONTENT	T\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	T\tagSENT_CONTENT	-th\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	implies\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	termination\tagSENT_CONTENT	gate\tagSENT_CONTENT	variables\tagSENT_CONTENT	t\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_END	The\tagSENT_START	reward\tagSENT_CONTENT	can\tagSENT_CONTENT	only\tagSENT_CONTENT	be\tagSENT_CONTENT	received\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	nal\tagSENT_CONTENT	termination\tagSENT_CONTENT	step\tagSENT_CONTENT	when\tagSENT_CONTENT	question_answering\tagtask	a\tagSENT_CONTENT	T\tagSENT_CONTENT	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	A\tagSENT_CONTENT	†\tagSENT_CONTENT	is\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	possible\tagSENT_CONTENT	episodes\tagSENT_CONTENT	,\tagSENT_CONTENT	T\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	T\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	T\tagSENT_CONTENT	and\tagSENT_CONTENT	r\tagSENT_CONTENT	T\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	termination\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	termination\tagSENT_CONTENT	action\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	reward\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	1\tagSENT_CONTENT	:\tagSENT_CONTENT	T\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	T\tagSENT_CONTENT	)\tagSENT_CONTENT	episode\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Details\tagSECTITLE_END	Given\tagSENT_START	M\tagmetric	and\tagSENT_CONTENT	s\tagSENT_CONTENT	1\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	training\tagSENT_CONTENT	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	ReasoNet\tagSENT_CONTENT	executes\tagSENT_CONTENT	|A\tagSENT_CONTENT	†\tagSENT_CONTENT	|\tagSENT_CONTENT	episodes\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	all\tagSENT_CONTENT	possible\tagSENT_CONTENT	episodes\tagSENT_CONTENT	A\tagSENT_CONTENT	†\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	enumerated\tagSENT_CONTENT	by\tagSENT_CONTENT	setting\tagSENT_CONTENT	a\tagSENT_CONTENT	maximum\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	CNN\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Daily\tagSECTITLE_CONTENT	Mail\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	Query\tagSECTITLE_START	:\tagSECTITLE_CONTENT	passenger\tagSECTITLE_CONTENT	@placeholder\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	36\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	died\tagSECTITLE_CONTENT	at\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	scene\tagSECTITLE_END	Answer\tagSECTITLE_START	:\tagSECTITLE_CONTENT	@entity14\tagSECTITLE_END	The\tagSENT_START	corresponding\tagSENT_CONTENT	termination\tagSENT_CONTENT	probability\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	scores\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	table\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	right\tagSENT_CONTENT	.\tagSENT_END	Comparing\tagSENT_START	with\tagSENT_CONTENT	the\tagSENT_CONTENT	AS\tagSENT_CONTENT	Reader\tagSENT_CONTENT	,\tagSENT_CONTENT	ReasoNet\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	signiicant\tagSENT_CONTENT	improvement\tagSENT_CONTENT	by\tagSENT_CONTENT	capturing\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagSECTITLE_START	Dataset\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	ReasoNet\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	answering\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	python\tagSENT_CONTENT	NLTK\tagSENT_CONTENT	tokenizer\tagSENT_CONTENT	6\tagSENT_CONTENT	to\tagSENT_CONTENT	preprocess\tagSENT_CONTENT	passages\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	obtain\tagSENT_CONTENT	about\tagSENT_CONTENT	100\tagSENT_CONTENT	K\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	vocabulary\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	module\tagSENT_CONTENT	requires\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	indices\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Graph\tagSECTITLE_START	Reachability\tagSECTITLE_CONTENT	Task\tagSECTITLE_END	Recent\tagSENT_START	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	cloze\tagSENT_CONTENT	-\tagSENT_CONTENT	style\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	tasks\tagSENT_CONTENT	have\tagSENT_CONTENT	suggested\tagSENT_CONTENT	some\tagSENT_CONTENT	simple\tagSENT_CONTENT	models\tagSENT_CONTENT	without\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	reasonable\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	last\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	on\tagSENT_CONTENT	query\tagSENT_CONTENT	are\tagSENT_CONTENT	concatenated\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	the\tagSENT_CONTENT	initial\tagSENT_CONTENT	internal\tagSENT_CONTENT	state\tagSENT_CONTENT	Answer\tagSENT_CONTENT	Module\tagSENT_CONTENT	:\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	either\tagSENT_CONTENT	"\tagSENT_CONTENT	Yes\tagSENT_CONTENT	"\tagSENT_CONTENT	or\tagSENT_CONTENT	"\tagSENT_CONTENT	No\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	logistical\tagSENT_CONTENT	regression\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	module\tagSENT_CONTENT	:\tagSENT_END	To\tagSENT_START	study\tagSENT_CONTENT	the\tagSENT_CONTENT	eeectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	choose\tagSENT_CONTENT	"\tagSENT_CONTENT	ReasoNet\tagSENT_CONTENT	-\tagSENT_CONTENT	T\tagSENT_CONTENT	max\tagSENT_CONTENT	=\tagSENT_CONTENT	2\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	only\tagSENT_CONTENT	has\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	turn\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	.\tagSENT_END	-\tagSECTITLE_START	>\tagSECTITLE_CONTENT	16\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	12\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	14\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	7\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	17\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	0\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	12\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	0\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	3\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	6\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	7\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	8\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	2\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	8\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	4\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	8\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	13\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	8\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	14\tagSECTITLE_CONTENT	#\tagSECTITLE_CONTENT	9\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	>\tagSECTITLE_CONTENT	16\tagSECTITLE_END	CONCLUSION\tagSECTITLE_END	
yu_gormley_dredze.nipsw.2014	title\tagSECTITLE_END	abstract\tagSECTITLE_END	
P16-1231	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	introduce\tagSENT_CONTENT	a\tagSENT_CONTENT	globally\tagSENT_CONTENT	normalized\tagSENT_CONTENT	transition\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	compression\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	potheses\tagmetric	and\tagSENT_CONTENT	introduce\tagSENT_CONTENT	global\tagSENT_CONTENT	normalization\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	conditional\tagSENT_CONTENT	random\tagSENT_CONTENT	field\tagSENT_CONTENT	(\tagSENT_CONTENT	CRF\tagSENT_CONTENT	)\tagSENT_CONTENT	objective\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	overcome\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	bias\tagSENT_CONTENT	problem\tagSENT_CONTENT	that\tagSENT_CONTENT	locally\tagSENT_CONTENT	normalized\tagSENT_CONTENT	models\tagSENT_CONTENT	suffer\tagSENT_CONTENT	from\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	empirically\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	the\tagSENT_CONTENT	effectiveness\tagSENT_CONTENT	of\tagSENT_CONTENT	global\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	compression\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	Transition\tagSECTITLE_START	System\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	brevity\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	drop\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	x\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	functions\tagSENT_CONTENT	given\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	simply\tagSENT_CONTENT	writing\tagSENT_CONTENT	S\tagSENT_CONTENT	,\tagSENT_CONTENT	A(s\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	t(s\tagSENT_CONTENT	,\tagSENT_CONTENT	d\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ρ(s\tagSENT_CONTENT	,\tagSENT_CONTENT	d\tagSENT_CONTENT	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	ρ(s\tagSENT_CONTENT	,\tagSENT_CONTENT	d\tagSENT_CONTENT	;\tagSENT_CONTENT	θ\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	defined\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	ways\tagmetric	.\tagSENT_END	Global\tagSECTITLE_START	vs.\tagSECTITLE_CONTENT	Local\tagSECTITLE_CONTENT	Normalization\tagSECTITLE_END	Training\tagSECTITLE_END	The\tagSECTITLE_START	Label\tagSECTITLE_CONTENT	Bias\tagSECTITLE_CONTENT	Problem\tagSECTITLE_END	This\tagSECTITLE_START	model\tagSECTITLE_CONTENT	again\tagSECTITLE_CONTENT	makes\tagSECTITLE_CONTENT	use\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	scoring\tagSECTITLE_CONTENT	function\tagSECTITLE_END	For\tagSENT_START	a\tagSENT_CONTENT	detailed\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	tradeoffs\tagSENT_CONTENT	between\tagSENT_CONTENT	structural\tagSENT_CONTENT	features\tagSENT_CONTENT	in\tagSENT_CONTENT	CRFs\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	powerful\tagSENT_CONTENT	local\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	without\tagSENT_CONTENT	structural\tagSENT_CONTENT	constraints\tagSENT_CONTENT	,\tagSENT_CONTENT	see\tagSENT_CONTENT	;\tagSENT_CONTENT	in\tagSENT_CONTENT	these\tagSENT_CONTENT	experiments\tagSENT_CONTENT	local\tagSENT_CONTENT	classifiers\tagSENT_CONTENT	are\tagSENT_CONTENT	unable\tagSENT_CONTENT	to\tagSENT_CONTENT	reach\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	CRFs\tagSENT_CONTENT	on\tagSENT_CONTENT	problems\tagmetric	such\tagSENT_CONTENT	as\tagSENT_CONTENT	parsing\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	recognition\tagSENT_CONTENT	where\tagSENT_CONTENT	structural\tagSENT_CONTENT	constraints\tagSENT_CONTENT	are\tagSENT_CONTENT	important\tagSENT_CONTENT	.\tagSENT_END	Note\tagSENT_START	that\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	nothing\tagSENT_CONTENT	to\tagSENT_CONTENT	preclude\tagSENT_CONTENT	an\tagSENT_CONTENT	approach\tagSENT_CONTENT	that\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	both\tagSENT_CONTENT	global\tagSENT_CONTENT	normalization\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	powerful\tagSENT_CONTENT	scoring\tagSENT_CONTENT	functions\tagSENT_CONTENT	ρ(d\tagSENT_CONTENT	1\tagSENT_END	The\tagSENT_START	experiments\tagSENT_CONTENT	that\tagSENT_CONTENT	follow\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	both\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	apply\tagSENT_CONTENT	our\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	compression\tagSENT_CONTENT	.\tagSENT_END	Part\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Speech\tagSECTITLE_CONTENT	Tagging\tagSECTITLE_END	Part\tagSENT_START	of\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagmetric	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	classic\tagSENT_CONTENT	NLP\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	modeling\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	for\tagSENT_CONTENT	achieving\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	&\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_CONTENT	.\tagSECTITLE_CONTENT	We\tagSECTITLE_CONTENT	conducted\tagSECTITLE_CONTENT	experiments\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	a\tagSECTITLE_CONTENT	number\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	datasets\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	1\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	English\tagSECTITLE_CONTENT	Wall\tagSECTITLE_CONTENT	Street\tagSECTITLE_CONTENT	Journal\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	WSJ\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	part\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	Penn\tagSECTITLE_END	Dependency\tagSECTITLE_START	Parsing\tagSECTITLE_END	In\tagSENT_START	dependency_parsing\tagtask	parsing\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	a\tagSENT_CONTENT	directed\tagSENT_CONTENT	tree\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	report\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	and\tagSENT_CONTENT	labeled\tagSENT_CONTENT	attachment\tagSENT_CONTENT	scores\tagSENT_CONTENT	(\tagSENT_CONTENT	UAS\tagmetric	/\tagmetric	LAS\tagmetric	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	arc\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	and\tagSENT_CONTENT	extract\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	as\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	:\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	speech\tagSENT_CONTENT	tags\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	labels\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	k\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	tags\tagSENT_CONTENT	as\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	we\tagSENT_CONTENT	artificially\tagSENT_CONTENT	restrict\tagSENT_CONTENT	ourselves\tagSENT_CONTENT	to\tagSENT_CONTENT	not\tagSENT_CONTENT	use\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	modest\tagSENT_CONTENT	drop\tagSENT_CONTENT	of\tagSENT_CONTENT	∼0.5\tagSENT_CONTENT	%\tagSENT_CONTENT	UAS\tagSENT_CONTENT	;\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	training\tagSENT_CONTENT	only\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	WSJ\tagSENT_CONTENT	yields\tagSENT_CONTENT	94.08\tagSENT_CONTENT	%\tagSENT_CONTENT	UAS\tagSENT_CONTENT	and\tagSENT_CONTENT	92.15\tagSENT_CONTENT	%\tagSENT_CONTENT	LAS\tagmetric	for\tagSENT_CONTENT	our\tagSENT_CONTENT	global\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	abeam\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	32\tagSENT_CONTENT	.\tagSENT_END	Sentence\tagSECTITLE_START	Compression\tagSECTITLE_END	The\tagSENT_START	transition\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	:\tagSENT_CONTENT	we\tagSENT_CONTENT	scan\tagSENT_CONTENT	sentences\tagSENT_CONTENT	from\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	right\tagSENT_CONTENT	and\tagSENT_CONTENT	label\tagSENT_CONTENT	each\tagSENT_CONTENT	token\tagSENT_CONTENT	as\tagSENT_CONTENT	keep\tagSENT_CONTENT	or\tagSENT_CONTENT	drop\tagSENT_CONTENT	.\tagSENT_END	Discussion\tagSECTITLE_END	Related\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	CRF\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	Related\tagSECTITLE_START	Transition\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	perform\tagSENT_START	full\tagSENT_CONTENT	backpropagation\tagSENT_CONTENT	training\tagSENT_CONTENT	like\tagSENT_CONTENT	us\tagmetric	,\tagSENT_CONTENT	but\tagSENT_CONTENT	even\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	much\tagSENT_CONTENT	larger\tagSENT_CONTENT	beam\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	performance\tagSENT_CONTENT	is\tagSENT_CONTENT	significantly\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	ours\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	apply\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	two\tagSENT_CONTENT	additional\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	they\tagSENT_CONTENT	experiment\tagSENT_CONTENT	only\tagSENT_CONTENT	with\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Label\tagSECTITLE_START	Bias\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	Practice\tagSECTITLE_END	We\tagSENT_START	observed\tagSENT_CONTENT	several\tagSENT_CONTENT	instances\tagSENT_CONTENT	of\tagSENT_CONTENT	severe\tagSENT_CONTENT	label\tagSENT_CONTENT	bias\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	trained\tagSENT_CONTENT	models\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	scoring\tagSENT_CONTENT	functions\tagSENT_CONTENT	in\tagSENT_CONTENT	parsing\tagSENT_CONTENT	at\tagSENT_CONTENT	dependency_parsing\tagtask	where\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	bias\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	locally\tagSENT_CONTENT	normalized\tagSENT_CONTENT	model\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	breakdown\tagSENT_CONTENT	during\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	.\tagSENT_END	Goldberg\tagSENT_START	and\tagSENT_CONTENT	Nivre\tagSENT_CONTENT	(\tagSENT_CONTENT	2013\tagSENT_CONTENT	)\tagSENT_CONTENT	describe\tagSENT_CONTENT	improvements\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	that\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	methods\tagSENT_CONTENT	from\tagSENT_CONTENT	imitation\tagSENT_CONTENT	learning\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	augment\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	and\tagSENT_CONTENT	yet\tagSENT_CONTENT	powerful\tagSENT_CONTENT	model\tagSENT_CONTENT	architecture\tagSENT_CONTENT	that\tagSENT_CONTENT	produces\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	sentence\tagSENT_CONTENT	compression\tagSENT_CONTENT	.\tagSENT_END	
1806.06228	title\tagSECTITLE_END	multimodal_emotion_recognition\tagtask	using\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Fusion\tagSENT_CONTENT	with\tagSENT_CONTENT	Context\tagSENT_CONTENT	Modeling\tagSENT_END	abstract\tagSECTITLE_END	multimodal_emotion_recognition\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	actively\tagSENT_CONTENT	growing\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	research\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	promising\tagSENT_CONTENT	area\tagSENT_CONTENT	of\tagSENT_CONTENT	opportunity\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	field\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	On\tagSENT_START	multimodal_emotion_recognition\tagtask	of\tagSENT_CONTENT	individual\tagSENT_CONTENT	utterances\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	strategy\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	conventional\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	by\tagSENT_CONTENT	1\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	amounts\tagSENT_CONTENT	to\tagSENT_CONTENT	5\tagSENT_CONTENT	%\tagSENT_CONTENT	reduction\tagSENT_CONTENT	in\tagSENT_CONTENT	error\tagSENT_CONTENT	rate\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Sentiment\tagSENT_START	analysis\tagSENT_CONTENT	techniques\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	broadly\tagSENT_CONTENT	categorized\tagSENT_CONTENT	into\tagSENT_CONTENT	symbolic\tagSENT_CONTENT	and\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	symbolic\tagSENT_CONTENT	approaches\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	former\tagSENT_CONTENT	include\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	lexicons\tagSENT_CONTENT	,\tagSENT_CONTENT	ontologies\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	networks\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	polarity\tagSENT_CONTENT	associated\tagSENT_CONTENT	with\tagSENT_CONTENT	words\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	;\tagSENT_CONTENT	the\tagSENT_CONTENT	latter\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	supervised\tagSENT_CONTENT	,\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	and\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	techniques\tagSENT_CONTENT	that\tagSENT_CONTENT	perform\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	classification\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	word\tagSENT_CONTENT	cooccurrence\tagSENT_CONTENT	frequencies\tagSENT_CONTENT	.\tagSENT_END	While\tagSENT_START	most\tagSENT_CONTENT	works\tagSENT_CONTENT	approach\tagSENT_CONTENT	it\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	categorization\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	is\tagSENT_CONTENT	actually\tagSENT_CONTENT	a\tagSENT_CONTENT	suitcase\tagSENT_CONTENT	research\tagSENT_CONTENT	problem\tagSENT_CONTENT	that\tagSENT_CONTENT	requires\tagSENT_CONTENT	tackling\tagSENT_CONTENT	many\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	word\tagSENT_CONTENT	polarity\tagSENT_CONTENT	disambiguation\tagSENT_CONTENT	,\tagSENT_CONTENT	subjectivity\tagSENT_CONTENT	detection\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	microtext\tagSENT_CONTENT	normalization\tagSENT_CONTENT	,\tagSENT_CONTENT	concept\tagSENT_CONTENT	extraction\tagSENT_CONTENT	,\tagSENT_CONTENT	time\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	aspect\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	Sentiment\tagSENT_START	analysis\tagSENT_CONTENT	has\tagSENT_CONTENT	raised\tagSENT_CONTENT	growing\tagSENT_CONTENT	interest\tagSENT_CONTENT	both\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	scientific\tagSENT_CONTENT	community\tagSENT_CONTENT	,\tagSENT_CONTENT	leading\tagSENT_CONTENT	to\tagSENT_CONTENT	many\tagSENT_CONTENT	exciting\tagSENT_CONTENT	open\tagSENT_CONTENT	challenges\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	business\tagSENT_CONTENT	world\tagSENT_CONTENT	,\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	remarkable\tagSENT_CONTENT	benefits\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	had\tagSENT_CONTENT	from\tagSENT_CONTENT	financial\tagSENT_CONTENT	and\tagSENT_CONTENT	political\tagSENT_CONTENT	forecasting\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	-\tagSENT_CONTENT	health\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	-\tagSENT_CONTENT	tourism\tagSENT_CONTENT	,\tagSENT_CONTENT	user\tagSENT_CONTENT	profiling\tagSENT_CONTENT	and\tagSENT_CONTENT	community\tagSENT_CONTENT	detection\tagSENT_CONTENT	,\tagSENT_CONTENT	manufacturing\tagSENT_CONTENT	and\tagSENT_CONTENT	supply\tagSENT_CONTENT	chain\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	and\tagSENT_CONTENT	dialogue\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	early\tagSENT_CONTENT	works\tagSENT_CONTENT	by\tagSENT_CONTENT	De\tagSENT_CONTENT	Silva\tagSENT_END	showed\tagSENT_START	that\tagSENT_CONTENT	fusion\tagSENT_CONTENT	of\tagSENT_CONTENT	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	visual\tagSENT_CONTENT	systems\tagSENT_CONTENT	,\tagSENT_CONTENT	creating\tagSENT_CONTENT	a\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	signal\tagSENT_CONTENT	,\tagSENT_CONTENT	yielded\tagSENT_CONTENT	a\tagmetric	higher\tagmetric	accuracy\tagmetric	than\tagSENT_CONTENT	any\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	there\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	work\tagSENT_CONTENT	done\tagSENT_CONTENT	on\tagSENT_CONTENT	audio\tagSENT_CONTENT	-\tagSENT_CONTENT	visual\tagSENT_CONTENT	fusion\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	exploring\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	along\tagSENT_CONTENT	with\tagSENT_CONTENT	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	visual\tagSENT_CONTENT	modalities\tagSENT_CONTENT	in\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	little\tagSENT_CONTENT	explored\tagSENT_CONTENT	.\tagSENT_END	fused\tagSENT_START	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	textual\tagSENT_CONTENT	modalities\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Unlike\tagSENT_START	existing\tagSENT_CONTENT	approaches\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	use\tagSENT_CONTENT	simple\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	based\tagSENT_CONTENT	early\tagSENT_CONTENT	fusion\tagSENT_CONTENT	and\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	trainable\tagSENT_CONTENT	tensors\tagSENT_CONTENT	based\tagSENT_CONTENT	fusion\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	proposes\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	fusion\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	the\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	for\tagSENT_CONTENT	data\tagSENT_CONTENT	fusion\tagSENT_CONTENT	using\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	method\tagSENT_CONTENT	is\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	accomplish\tagSENT_CONTENT	the\tagSENT_CONTENT	fusion\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	plugged\tagSENT_CONTENT	into\tagSENT_CONTENT	any\tagSENT_CONTENT	deep\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	based\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Our\tagSECTITLE_START	Method\tagSECTITLE_END	Overview\tagSECTITLE_END	Unimodal\tagSECTITLE_START	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Multimodal\tagSECTITLE_START	Fusion\tagSECTITLE_END	The\tagSENT_START	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	or\tagSENT_CONTENT	early\tagSENT_CONTENT	fusion\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	their\tagSENT_CONTENT	fusion\tagSENT_CONTENT	strategy\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	address\tagSENT_CONTENT	this\tagSENT_CONTENT	major\tagSENT_CONTENT	issue\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	devise\tagSENT_CONTENT	an\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	approach\tagSENT_CONTENT	which\tagSENT_CONTENT	proceeds\tagSENT_CONTENT	from\tagSENT_CONTENT	unimodal\tagSENT_CONTENT	to\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	vectors\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	to\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Softmax\tagSECTITLE_START	Output\tagSECTITLE_END	Audio\tagSECTITLE_START	Features\tagSECTITLE_CONTENT	Textual\tagSECTITLE_CONTENT	Features\tagSECTITLE_CONTENT	Video\tagSECTITLE_CONTENT	Features\tagSECTITLE_END	We\tagSENT_START	fuse\tagSENT_CONTENT	the\tagSENT_CONTENT	utterance\tagSENT_CONTENT	feature\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	T+V\tagSENT_CONTENT	,\tagSENT_CONTENT	T+A\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	A+V.\tagSENT_END	We\tagSENT_START	fuse\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	as\tagSENT_CONTENT	depicted\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Softmax\tagSECTITLE_START	Output\tagSECTITLE_END	Unimodal\tagSECTITLE_START	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Textual\tagSECTITLE_START	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Audio\tagSECTITLE_START	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Visual\tagSECTITLE_START	Feature\tagSECTITLE_CONTENT	Extraction\tagSECTITLE_END	Context\tagSECTITLE_START	Modeling\tagSECTITLE_END	Let\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	items\tagSENT_CONTENT	represent\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	:\tagSENT_END	Multimodal\tagSECTITLE_START	Fusion\tagSECTITLE_END	Classification\tagSECTITLE_END	Training\tagSECTITLE_END	9\tagSECTITLE_START	:\tagSECTITLE_END	22\tagSECTITLE_START	:\tagSECTITLE_END	return\tagSENT_START	fz\tagSENT_CONTENT	1\tagSENT_CONTENT	z\tagSENT_CONTENT	2\tagSENT_CONTENT	31\tagSENT_CONTENT	:\tagSENT_CONTENT	procedure\tagSENT_CONTENT	TrimodalFusion(fz\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	fz\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	fz\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	1\tagSENT_CONTENT	,\tagSENT_CONTENT	z\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	z\tagSENT_CONTENT	3\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	z\tagSENT_CONTENT	1\tagSENT_CONTENT	=\tagSENT_CONTENT	z\tagSENT_CONTENT	2\tagSENT_END	Baselines\tagSECTITLE_END	We\tagSENT_START	extract\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.2\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	simply\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	them\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	they\tagSENT_CONTENT	proposed\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	tensors\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	was\tagSENT_CONTENT	different\tagSENT_CONTENT	than\tagSENT_CONTENT	us\tagSENT_END	Experimental\tagSECTITLE_START	Setting\tagSECTITLE_END	HFusion\tagSECTITLE_START	.\tagSECTITLE_CONTENT	In\tagSECTITLE_CONTENT	this\tagSECTITLE_CONTENT	setup\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	we\tagSECTITLE_CONTENT	evaluated\tagSECTITLE_CONTENT	hierarchical\tagSECTITLE_CONTENT	fusion\tagSECTITLE_CONTENT	without\tagSECTITLE_CONTENT	context\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	aware\tagSECTITLE_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	Hierarchical\tagSECTITLE_START	Fusion\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	HFusion\tagSECTITLE_CONTENT	)\tagSECTITLE_END	We\tagSENT_START	evaluated\tagSENT_CONTENT	this\tagSENT_CONTENT	setup\tagSENT_CONTENT	with\tagSENT_CONTENT	CMU\tagSENT_CONTENT	-\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.1.1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	two\tagSENT_CONTENT	feature\tagSENT_CONTENT	sets\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3.2\tagSENT_CONTENT	.\tagSENT_END	:\tagSENT_START	Comparison\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	accuracy\tagmetric	of\tagSENT_CONTENT	Hierarchical\tagSENT_CONTENT	Fusion\tagSENT_CONTENT	(\tagSENT_CONTENT	HFusion\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	fusion\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	CMU\tagSENT_CONTENT	-\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	dataset\tagSENT_CONTENT	;\tagSENT_CONTENT	bold\tagSENT_CONTENT	font\tagSENT_CONTENT	signifies\tagSENT_CONTENT	best\tagmetric	accuracy\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	feature\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	modality\tagSENT_CONTENT	or\tagSENT_CONTENT	modalities\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	T\tagSENT_CONTENT	stands\tagSENT_CONTENT	for\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	V\tagSENT_CONTENT	for\tagSENT_CONTENT	video\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	A\tagSENT_CONTENT	for\tagSENT_CONTENT	audio\tagSENT_CONTENT	.\tagSENT_END	multimodal_emotion_recognition\tagtask	 \tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	employed\tagSENT_CONTENT	MKL\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	by\tagSENT_CONTENT	a\tagSENT_CONTENT	margin\tagSENT_CONTENT	of\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	1.8\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Although\tagSENT_START	other\tagSENT_CONTENT	modalities\tagSENT_CONTENT	contribute\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	is\tagSENT_CONTENT	little\tagSENT_CONTENT	in\tagSENT_CONTENT	compare\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	textual\tagSENT_CONTENT	modality\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	proposed\tagSENT_CONTENT	method\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	their\tagSENT_CONTENT	approach\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	significant\tagSENT_CONTENT	margin\tagSENT_CONTENT	;\tagSENT_CONTENT	thanks\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	power\tagSENT_CONTENT	of\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	fusion\tagSENT_CONTENT	which\tagSENT_CONTENT	proves\tagSENT_CONTENT	the\tagSENT_CONTENT	capability\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	in\tagSENT_CONTENT	modeling\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Tensor\tagSENT_START	fusion\tagSENT_CONTENT	network\tagSENT_CONTENT	is\tagSENT_CONTENT	incapable\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	fusion\tagSENT_CONTENT	.\tagSENT_END	Context\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Aware\tagSECTITLE_CONTENT	Hierarchical\tagSECTITLE_CONTENT	Fusion\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	CHFusion\tagSECTITLE_CONTENT	)\tagSECTITLE_END	We\tagSENT_START	applied\tagSENT_CONTENT	this\tagSENT_CONTENT	experimental\tagSENT_CONTENT	setting\tagSENT_CONTENT	for\tagSENT_CONTENT	two\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	CMU\tagSENT_CONTENT	-\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.1.1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	IEMOCAP\tagdataset	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	4.1.2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	achieve\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	2\tagSENT_CONTENT	%\tagSENT_CONTENT	performance\tagSENT_CONTENT	improvement\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	having\tagSENT_CONTENT	textual\tagSENT_CONTENT	component\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	multimodal_emotion_recognition\tagtask	we\tagSENT_CONTENT	achieve\tagSENT_CONTENT	better\tagSENT_CONTENT	but\tagSENT_CONTENT	similar\tagSENT_CONTENT	performance\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	IEMOCAP\tagSECTITLE_START	.\tagSECTITLE_END	This\tagSENT_START	method\tagSENT_CONTENT	performs\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	2.4\tagSENT_CONTENT	%\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Also\tagSENT_START	,\tagSENT_CONTENT	trimodal\tagmetric	accuracy\tagmetric	is\tagSENT_CONTENT	3\tagSENT_CONTENT	%\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	for\tagSENT_CONTENT	textual\tagSENT_CONTENT	modality\tagSENT_CONTENT	.\tagSENT_END	Since\tagSENT_START	,\tagSENT_CONTENT	IEMOCAP\tagSENT_CONTENT	dataset\tagSENT_CONTENT	imbalanced\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	present\tagSENT_CONTENT	the\tagSENT_CONTENT	f\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	fora\tagSENT_CONTENT	better\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	key\tagSENT_CONTENT	observation\tagSENT_CONTENT	for\tagSENT_CONTENT	IEMOCAP\tagSENT_CONTENT	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	performs\tagSENT_CONTENT	significantly\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	of\tagSENT_CONTENT	CMU\tagSENT_CONTENT	-\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	dataset\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	think\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	audio\tagSENT_CONTENT	and\tagSENT_CONTENT	video\tagSENT_CONTENT	modality\tagSENT_CONTENT	of\tagSENT_CONTENT	IEMOCAP\tagdataset	being\tagSENT_CONTENT	richer\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	of\tagSENT_CONTENT	CMU\tagSENT_CONTENT	-\tagSENT_CONTENT	MOSI\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	think\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	mainly\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	the\tagSENT_CONTENT	weights\tagSENT_CONTENT	of\tagSENT_CONTENT	bimodal\tagSENT_CONTENT	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	(\tagSENT_CONTENT	representing\tagSENT_CONTENT	the\tagSENT_CONTENT	degree\tagSENT_CONTENT	of\tagSENT_CONTENT	correlations\tagSENT_CONTENT	)\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	class\tagmetric	-\tagmetric	wise\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	f\tagSENT_CONTENT	-\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	IEMOCAP\tagdataset	for\tagSENT_END	multimodal_emotion_recognition\tagtask	in\tagSENT_CONTENT	.\tagSENT_END	HFusion\tagSECTITLE_START	vs.\tagSECTITLE_CONTENT	CHFusion\tagSECTITLE_END	We\tagSENT_START	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	CHFusion\tagSENT_CONTENT	performs\tagSENT_CONTENT	1\tagSENT_CONTENT	-\tagSENT_CONTENT	2\tagSENT_CONTENT	%\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	HFusion\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	multimodal_emotion_recognition\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	issue\tagSENT_CONTENT	in\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Our\tagSENT_START	method\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	widely\tagSENT_CONTENT	used\tagSENT_CONTENT	early\tagSENT_CONTENT	fusion\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	datasets\tagSENT_CONTENT	typically\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	.\tagSENT_END	Moreover\tagSENT_START	,\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	addition\tagSENT_CONTENT	of\tagSENT_CONTENT	context\tagSENT_CONTENT	modeling\tagSENT_CONTENT	with\tagSENT_CONTENT	GRU\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	method\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	in\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	and\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	by\tagSENT_CONTENT	significant\tagSENT_CONTENT	margin\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	our\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	plan\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	multimodal_emotion_recognition\tagtask	,\tagSENT_CONTENT	especially\tagSENT_CONTENT	textual\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	will\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	of\tagSENT_CONTENT	classification\tagSENT_CONTENT	.\tagSENT_END	
P16-1123	title\tagSECTITLE_END	relationship_extraction\tagtask	via\tagSENT_CONTENT	Multi\tagSENT_CONTENT	-\tagSENT_CONTENT	Level\tagSENT_CONTENT	Attention\tagSENT_CONTENT	CNNs\tagSENT_END	abstract\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	crucial\tagSENT_CONTENT	ingredient\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	seeking\tagSENT_CONTENT	to\tagSENT_CONTENT	mine\tagSENT_CONTENT	structured\tagSENT_CONTENT	facts\tagSENT_CONTENT	from\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relationship_extraction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relation\tagSENT_CONTENT	holding\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	nominal\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	text\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	crucial\tagSENT_CONTENT	component\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	need\tagSENT_CONTENT	to\tagSENT_CONTENT	mine\tagSENT_CONTENT	explicit\tagSENT_CONTENT	facts\tagSENT_CONTENT	from\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	for\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	and\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	completion\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	with\tagSENT_START	annotated\tagSENT_CONTENT	target\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	=\tagSENT_CONTENT	"\tagSENT_CONTENT	drinks\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	=\tagSENT_CONTENT	"\tagSENT_CONTENT	diabetes\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	recognize\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	sentence\tagSENT_CONTENT	expresses\tagSENT_CONTENT	a\tagSENT_CONTENT	causeeffect\tagSENT_CONTENT	relationship\tagSENT_CONTENT	between\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	relationship_extraction\tagtask	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	relationship_extraction\tagtask	facilitates\tagSENT_CONTENT	precise\tagSENT_CONTENT	sentence\tagSENT_CONTENT	interpretations\tagSENT_CONTENT	,\tagSENT_CONTENT	discourse\tagSENT_CONTENT	processing\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	higherlevel\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	liuzy@tsinghua.edu.cn\tagSENT_START	relationship_extraction\tagtask	has\tagSENT_CONTENT	attracted\tagSENT_CONTENT	considerable\tagSENT_CONTENT	attention\tagSENT_CONTENT	from\tagSENT_CONTENT	researchers\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	course\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	past\tagSENT_CONTENT	decades\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	wild\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	encounter\tagSENT_CONTENT	a\tagSENT_CONTENT	multitude\tagSENT_CONTENT	of\tagSENT_CONTENT	different\tagSENT_CONTENT	ways\tagSENT_CONTENT	of\tagSENT_CONTENT	expressing\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	kind\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	In\tagSENT_START	recent\tagSENT_CONTENT	years\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	seen\tagSENT_CONTENT	a\tagSENT_CONTENT	move\tagSENT_CONTENT	towards\tagSENT_CONTENT	deep\tagSENT_CONTENT	architectures\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	capable\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	relationship_extraction\tagtask	and\tagSENT_CONTENT	features\tagSENT_CONTENT	without\tagSENT_CONTENT	extensive\tagSENT_CONTENT	manual\tagSENT_CONTENT	feature\tagSENT_CONTENT	engineering\tagSENT_CONTENT	or\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	external\tagSENT_CONTENT	resources\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	number\tagSENT_CONTENT	of\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	CNN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	neural\tagSENT_CONTENT	architectures\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	proposed\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	CNN\tagSENT_CONTENT	architecture\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	both\tagSENT_CONTENT	entity\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	primary\tagSENT_CONTENT	attention\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	level\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	secondary\tagSENT_CONTENT	attention\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	an\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	88.0\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SemEval\tagSENT_CONTENT	2010\tagSENT_CONTENT	Task\tagSENT_CONTENT	8\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	methods\tagSENT_CONTENT	relying\tagSENT_CONTENT	on\tagSENT_CONTENT	significantly\tagSENT_CONTENT	richer\tagSENT_CONTENT	prior\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Apart\tagSENT_START	from\tagSENT_CONTENT	a\tagSENT_CONTENT	few\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	clustering\tagSENT_CONTENT	methods\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	majority\tagSENT_CONTENT	of\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	supervised\tagSENT_CONTENT	,\tagSENT_CONTENT	typically\tagSENT_CONTENT	cast\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	standard\tagSENT_CONTENT	multiclass\tagSENT_CONTENT	or\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	Proposed\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	S\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	labeled\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	example\tagSENT_CONTENT	from\tagSENT_CONTENT	Section\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	identifying\tagSENT_CONTENT	the\tagSENT_CONTENT	semantic\tagSENT_CONTENT	relation\tagSENT_CONTENT	holding\tagSENT_CONTENT	between\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	among\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	candidate\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Notation\tagSECTITLE_END	Definition\tagSECTITLE_END	relationship_extraction\tagtask	:\tagSENT_CONTENT	Overview\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	output\tagSENT_CONTENT	matrix\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	then\tagSENT_CONTENT	applies\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	contextual\tagSENT_CONTENT	information\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	relevant\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	,\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	max\tagSENT_CONTENT	-\tagSENT_CONTENT	pooling\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	secondary\tagSENT_CONTENT	attention\tagSENT_CONTENT	pooling\tagSENT_CONTENT	layer\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	useful\tagSENT_CONTENT	convolved\tagSENT_CONTENT	features\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	an\tagSENT_CONTENT	attention\tagSENT_CONTENT	pooling\tagSENT_CONTENT	matrix\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	remainder\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	will\tagSENT_CONTENT	provide\tagSENT_CONTENT	further\tagSENT_CONTENT	details\tagSENT_CONTENT	about\tagSENT_CONTENT	this\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	provides\tagSENT_START	an\tagSENT_CONTENT	overview\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	we\tagSENT_CONTENT	will\tagSENT_CONTENT	use\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	.\tagSENT_END	Classification\tagSECTITLE_START	Objective\tagSECTITLE_END	Input\tagSECTITLE_START	Representation\tagSECTITLE_END	To\tagSENT_START	additionally\tagSENT_CONTENT	capture\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	word\tagSENT_CONTENT	position\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	(\tagSENT_CONTENT	WPE\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	reflect\tagSENT_CONTENT	the\tagSENT_CONTENT	relative\tagSENT_CONTENT	distances\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	word\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	marked\tagSENT_CONTENT	entity\tagSENT_CONTENT	mentions\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Input\tagSECTITLE_START	Attention\tagSECTITLE_CONTENT	Mechanism\tagSECTITLE_END	While\tagSENT_START	position\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	encodings\tagSENT_CONTENT	are\tagSENT_CONTENT	useful\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	conjecture\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	suffice\tagSENT_CONTENT	to\tagSENT_CONTENT	fully\tagSENT_CONTENT	capture\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	specific\tagSENT_CONTENT	words\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	influence\tagSENT_CONTENT	that\tagSENT_CONTENT	they\tagSENT_CONTENT	may\tagSENT_CONTENT	bear\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	of\tagSENT_CONTENT	interest\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	design\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	so\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	automatically\tagSENT_CONTENT	identify\tagSENT_CONTENT	the\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sentence\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	relevant\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Attention\tagSENT_START	mechanisms\tagSENT_CONTENT	have\tagSENT_CONTENT	successfully\tagSENT_CONTENT	been\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	sequence\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	sequence\tagSENT_CONTENT	learning\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	abstractive\tagSENT_CONTENT	sentence\tagSENT_CONTENT	summarization\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	modeling\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	date\tagSENT_CONTENT	,\tagSENT_CONTENT	these\tagSENT_CONTENT	mechanisms\tagSENT_CONTENT	have\tagSENT_CONTENT	generally\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	allow\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	alignment\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	sentence\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	or\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	alignment\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	input\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	sentence\tagSENT_CONTENT	similarity\tagSENT_CONTENT	scoring\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	Consider\tagSENT_START	that\tagSENT_CONTENT	in\tagSENT_CONTENT	along\tagSENT_CONTENT	sentence\tagSENT_CONTENT	with\tagSENT_CONTENT	multiple\tagSENT_CONTENT	clauses\tagSENT_CONTENT	,\tagSENT_CONTENT	perhaps\tagSENT_CONTENT	only\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	verb\tagSENT_CONTENT	or\tagSENT_CONTENT	noun\tagSENT_CONTENT	might\tagSENT_CONTENT	stand\tagSENT_CONTENT	in\tagSENT_CONTENT	relationship_extraction\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	target\tagSENT_CONTENT	entity\tagSENT_CONTENT	.\tagSENT_END	Consider\tagSENT_START	the\tagSENT_CONTENT	example\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	word\tagSENT_CONTENT	"\tagSENT_CONTENT	cause\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	of\tagSENT_CONTENT	particular\tagSENT_CONTENT	significance\tagSENT_CONTENT	in\tagSENT_CONTENT	determining\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	f\tagmetric	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	inner\tagSENT_CONTENT	product\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	respective\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	word\tagSENT_END	i\tagSENT_START	and\tagSENT_CONTENT	model\tagSENT_CONTENT	their\tagSENT_CONTENT	joint\tagSENT_CONTENT	impact\tagSENT_CONTENT	for\tagSENT_CONTENT	recognizing\tagSENT_CONTENT	relationship_extraction\tagtask	via\tagSENT_CONTENT	simple\tagSENT_CONTENT	averaging\tagSENT_CONTENT	as\tagSENT_END	to\tagSENT_START	obtain\tagSENT_CONTENT	an\tagSENT_CONTENT	information\tagSENT_CONTENT	-\tagSENT_CONTENT	enriched\tagSENT_CONTENT	input\tagSENT_CONTENT	attention\tagSENT_CONTENT	component\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	specific\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	contains\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	both\tagSENT_CONTENT	entity\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	entity\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	second\tagSENT_CONTENT	variant\tagSENT_CONTENT	(\tagSENT_CONTENT	Variant-2\tagSENT_CONTENT	)\tagSENT_CONTENT	interprets\tagSENT_CONTENT	relationship_extraction\tagtask	as\tagSENT_CONTENT	mappings\tagSENT_CONTENT	between\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	combines\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	entity\tagSENT_CONTENT	-\tagSENT_CONTENT	specific\tagSENT_CONTENT	weights\tagSENT_CONTENT	as\tagSENT_END	to\tagSENT_START	capture\tagSENT_CONTENT	relationship_extraction\tagtask	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Convolutional\tagSECTITLE_START	Max\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Pooling\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Secondary\tagSECTITLE_CONTENT	Attention\tagSECTITLE_END	After\tagSENT_START	relationship_extraction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	maxpooling\tagSENT_CONTENT	with\tagSENT_CONTENT	another\tagSENT_CONTENT	secondary\tagSENT_CONTENT	attention\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	more\tagSENT_CONTENT	abstract\tagSENT_CONTENT	higher\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	layer\tagSENT_CONTENT	's\tagSENT_CONTENT	output\tagSENT_CONTENT	matrix\tagSENT_CONTENT	R.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	multiply\tagSENT_CONTENT	this\tagSENT_CONTENT	attention\tagSENT_CONTENT	pooling\tagSENT_CONTENT	matrix\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	convolved\tagSENT_CONTENT	output\tagSENT_CONTENT	R\tagSENT_CONTENT	*\tagSENT_CONTENT	to\tagSENT_CONTENT	highlight\tagSENT_CONTENT	important\tagSENT_CONTENT	individual\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	components\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	apply\tagSENT_CONTENT	relationship_extraction\tagtask	to\tagSENT_CONTENT	select\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	salient\tagSENT_CONTENT	one\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	fora\tagSENT_CONTENT	given\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Procedure\tagSECTITLE_END	Experiments\tagSECTITLE_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	The\tagSENT_START	nine\tagSENT_CONTENT	types\tagSENT_CONTENT	are\tagSENT_CONTENT	:\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect\tagSENT_CONTENT	,\tagSENT_CONTENT	Component\tagSENT_CONTENT	-\tagSENT_CONTENT	Whole\tagSENT_CONTENT	,\tagSENT_CONTENT	Content\tagSENT_CONTENT	-\tagSENT_CONTENT	Container\tagSENT_CONTENT	,\tagSENT_CONTENT	EntityDestination\tagSENT_CONTENT	,\tagSENT_CONTENT	Entity\tagSENT_CONTENT	-\tagSENT_CONTENT	Origin\tagSENT_CONTENT	,\tagSENT_CONTENT	Instrument\tagSENT_CONTENT	-\tagSENT_CONTENT	Agency\tagSENT_CONTENT	,\tagSENT_CONTENT	Member\tagSENT_CONTENT	-\tagSENT_CONTENT	Collection\tagSENT_CONTENT	,\tagSENT_CONTENT	Message\tagSENT_CONTENT	-\tagSENT_CONTENT	Topic\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	ProductProducer\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	type\tagSENT_CONTENT	"\tagSENT_CONTENT	Other\tagSENT_CONTENT	"\tagSENT_CONTENT	indicates\tagSENT_CONTENT	that\tagSENT_CONTENT	relationship_extraction\tagtask	expressed\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	among\tagSENT_CONTENT	the\tagSENT_CONTENT	nine\tagSENT_CONTENT	types\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	Cause\tagSENT_CONTENT	-\tagSENT_CONTENT	Effect(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	CauseEffect(e\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	considered\tagSENT_CONTENT	two\tagSENT_CONTENT	distinct\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	the\tagSENT_CONTENT	total\tagSENT_CONTENT	number\tagSENT_CONTENT	|Y|\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	is\tagSENT_CONTENT	19\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	We\tagSENT_START	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	our\tagSENT_CONTENT	novel\tagSENT_CONTENT	attentionbased\tagSENT_CONTENT	architecture\tagSENT_CONTENT	achieves\tagSENT_CONTENT	new\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	relationship_extraction\tagtask	dataset\tagSENT_CONTENT	.\tagSENT_END	Detailed\tagSECTITLE_START	Analysis\tagSECTITLE_END	Classifier\tagSECTITLE_END	F1\tagSECTITLE_END	This\tagSENT_START	appears\tagSENT_CONTENT	sensible\tagSENT_CONTENT	in\tagSENT_CONTENT	light\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	-\tagSENT_CONTENT	truth\tagSENT_CONTENT	labeling\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	ComponentWhole(e\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	words\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	this\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	rather\tagSENT_CONTENT	irrelevant\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	indeed\tagSENT_CONTENT	have\tagSENT_CONTENT	significantly\tagSENT_CONTENT	lower\tagSENT_CONTENT	attention\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	Significant\tagSENT_CONTENT	Features\tagSENT_CONTENT	for\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Table\tagSENT_START	5\tagSENT_CONTENT	lists\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	-\tagSENT_CONTENT	ranked\tagSENT_CONTENT	trigrams\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	relation\tagSENT_CONTENT	classy\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	contribution\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	for\tagSENT_CONTENT	determining\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	Classifier\tagSECTITLE_START	F1\tagSECTITLE_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	these\tagSENT_CONTENT	are\tagSENT_CONTENT	indeed\tagSENT_CONTENT	very\tagSENT_CONTENT	informative\tagSENT_CONTENT	for\tagSENT_CONTENT	deducing\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	The\tagSENT_START	following\tagSENT_CONTENT	is\tagSENT_CONTENT	atypical\tagSENT_CONTENT	example\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	wrongly\tagSENT_CONTENT	classified\tagSENT_CONTENT	sentence\tagSENT_CONTENT	:\tagSENT_CONTENT	relationship_extraction\tagtask	(\tagSENT_CONTENT	e1\tagSENT_CONTENT	,\tagSENT_CONTENT	e2\tagSENT_CONTENT	)\tagSENT_END	The\tagSENT_START	phrase\tagSENT_CONTENT	"\tagSENT_CONTENT	revolves\tagSENT_CONTENT	around\tagSENT_CONTENT	"\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	moreover\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	metaphorically\tagSENT_CONTENT	,\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	in\tagSENT_CONTENT	its\tagSENT_CONTENT	original\tagSENT_CONTENT	sense\tagSENT_CONTENT	of\tagSENT_CONTENT	turning\tagSENT_CONTENT	around\tagSENT_CONTENT	,\tagSENT_CONTENT	making\tagSENT_CONTENT	it\tagSENT_CONTENT	difficult\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	recognize\tagSENT_CONTENT	relationship_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	plot\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Att\tagSENT_CONTENT	-\tagSENT_CONTENT	Input\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	and\tagSENT_CONTENT	Att\tagSENT_CONTENT	-\tagSENT_CONTENT	Pooling\tagSENT_CONTENT	-\tagSENT_CONTENT	CNN\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	expect\tagSENT_CONTENT	this\tagSENT_CONTENT	sort\tagSENT_CONTENT	of\tagSENT_CONTENT	architecture\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	of\tagSENT_CONTENT	interest\tagSENT_CONTENT	also\tagSENT_CONTENT	beyond\tagSENT_CONTENT	the\tagSENT_CONTENT	specific\tagSENT_CONTENT	task\tagSENT_CONTENT	of\tagSENT_CONTENT	relationship_extraction\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	intend\tagSENT_CONTENT	to\tagSENT_CONTENT	explore\tagSENT_CONTENT	in\tagSENT_CONTENT	future\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	
P15-1067	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Knowledge\tagSENT_START	graphs\tagSENT_CONTENT	are\tagSENT_CONTENT	useful\tagSENT_CONTENT	resources\tagSENT_CONTENT	for\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	they\tagSENT_CONTENT	are\tagSENT_CONTENT	far\tagSENT_CONTENT	from\tagSENT_CONTENT	completeness\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Knowledge\tagSENT_START	Graphs\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	WordNet\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	playing\tagSENT_CONTENT	a\tagSENT_CONTENT	pivotal\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	relation\tagSENT_CONTENT	extraction(RE\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering(Q&A\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	learns\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	for\tagSENT_CONTENT	every\tagSENT_CONTENT	entity\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	in\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graphs\tagSENT_CONTENT	.\tagSENT_END	Mr\tagSENT_START	t.\tagSENT_CONTENT	CTransR\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	TransR\tagSENT_CONTENT	by\tagSENT_CONTENT	clustering\tagSENT_CONTENT	diverse\tagSENT_CONTENT	headtail\tagSENT_CONTENT	entity\tagSENT_CONTENT	pairs\tagSENT_CONTENT	into\tagSENT_CONTENT	groups\tagSENT_CONTENT	and\tagSENT_CONTENT	learning\tagSENT_CONTENT	distinct\tagSENT_CONTENT	relation\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	group\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	TransD\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	define\tagSENT_CONTENT	two\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Our\tagSENT_START	contributions\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	are\tagSENT_CONTENT	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1)We\tagSENT_CONTENT	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	novel\tagSENT_CONTENT	model\tagSENT_CONTENT	TransD\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	constructs\tagSENT_CONTENT	a\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	mapping\tagSENT_CONTENT	matrix\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	entity\tagSENT_CONTENT	-\tagSENT_CONTENT	relation\tagSENT_CONTENT	pair\tagSENT_CONTENT	by\tagSENT_CONTENT	considering\tagSENT_CONTENT	the\tagSENT_CONTENT	diversity\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	simultaneously\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Other\tagSENT_START	notations\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	described\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	TransE\tagSECTITLE_START	,\tagSECTITLE_CONTENT	TransH\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	TransR\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	CTransR\tagSECTITLE_END	As\tagSENT_START	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	)\tagSENT_CONTENT	regards\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	r\tagSENT_CONTENT	as\tagSENT_CONTENT	translation\tagSENT_CONTENT	from\tagSENT_CONTENT	h\tagSENT_CONTENT	tot\tagSENT_CONTENT	fora\tagSENT_CONTENT	golden\tagSENT_CONTENT	triplet\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	TransE\tagSENT_START	is\tagSENT_CONTENT	only\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	there\tagSENT_CONTENT	remain\tagSENT_CONTENT	flaws\tagSENT_CONTENT	for\tagSENT_CONTENT	1-to\tagSENT_CONTENT	-\tagSENT_CONTENT	N\tagSENT_CONTENT	,\tagSENT_CONTENT	N\tagSENT_CONTENT	-\tagSENT_CONTENT	to-1\tagSENT_CONTENT	and\tagSENT_CONTENT	N\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	N\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	hyperplanes\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	entity\tagSENT_CONTENT	has\tagSENT_CONTENT	different\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	TransE\tagSENT_CONTENT	and\tagSENT_CONTENT	TransH\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	are\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	vector\tagSENT_CONTENT	space\tagSENT_CONTENT	.\tagSENT_END	CTransR\tagSENT_START	is\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	TransR.\tagSENT_END	Other\tagSECTITLE_START	Models\tagSECTITLE_END	Unstructured\tagSENT_START	model\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	ignores\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	only\tagSENT_CONTENT	models\tagSENT_CONTENT	entities\tagSENT_CONTENT	as\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	encodes\tagSENT_START	each\tagSENT_CONTENT	named\tagSENT_CONTENT	symbolic\tagSENT_CONTENT	object\tagSENT_CONTENT	(\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	)\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	b\tagSENT_START	rare\tagSENT_CONTENT	parameters\tagSENT_CONTENT	indexed\tagSENT_CONTENT	by\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	f\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	tanh\tagSENT_CONTENT	operation\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	W\tagSENT_CONTENT	r\tagSENT_CONTENT	represents\tagSENT_CONTENT	a\tagSENT_CONTENT	3-way\tagSENT_CONTENT	tensor\tagSENT_CONTENT	,\tagSENT_CONTENT	Mr\tagmetric	denotes\tagSENT_CONTENT	the\tagSENT_CONTENT	weight\tagSENT_CONTENT	matrix\tagSENT_END	(\tagSENT_START	)\tagSENT_CONTENT	is\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Our\tagSECTITLE_START	Method\tagSECTITLE_END	i\tagSENT_START	denotes\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Multiple\tagSECTITLE_START	Types\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Entities\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Relations\tagSECTITLE_END	Considering\tagSENT_START	the\tagSENT_CONTENT	diversity\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	CTransR\tagSENT_CONTENT	segments\tagSENT_CONTENT	triplets\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	specific\tagSENT_CONTENT	relation\tagSENT_CONTENT	r\tagSENT_CONTENT	into\tagSENT_CONTENT	several\tagSENT_CONTENT	groups\tagSENT_CONTENT	and\tagSENT_CONTENT	learns\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	group\tagSENT_CONTENT	.\tagSENT_END	TransD\tagSECTITLE_END	The\tagSENT_START	first\tagSENT_CONTENT	one\tagSENT_CONTENT	captures\tagSENT_CONTENT	the\tagSENT_CONTENT	meaning\tagSENT_CONTENT	of\tagSENT_CONTENT	entity\tagSENT_CONTENT	(\tagSENT_CONTENT	relation_prediction\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	one\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	mapping\tagSENT_CONTENT	matrices\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	mapping\tagSENT_CONTENT	matrices\tagSENT_CONTENT	are\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	both\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	this\tagSENT_CONTENT	kind\tagSENT_CONTENT	of\tagSENT_CONTENT	operation\tagSENT_CONTENT	makes\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	projection\tagSENT_CONTENT	vectors\tagSENT_CONTENT	interact\tagSENT_CONTENT	sufficiently\tagSENT_CONTENT	because\tagSENT_CONTENT	each\tagSENT_CONTENT	element\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagSENT_CONTENT	can\tagSENT_CONTENT	meet\tagSENT_CONTENT	every\tagSENT_CONTENT	entry\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	another\tagSENT_CONTENT	vector\tagSENT_CONTENT	.\tagSENT_END	Connections\tagSECTITLE_START	with\tagSECTITLE_CONTENT	TransE\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	TransH\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	TransR\tagSECTITLE_CONTENT	/\tagSECTITLE_CONTENT	CTransR\tagSECTITLE_END	TransE\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	TransD\tagSENT_CONTENT	when\tagSENT_CONTENT	the\tagSENT_CONTENT	dimension\tagSENT_CONTENT	of\tagSENT_CONTENT	vectors\tagSENT_CONTENT	satisfies\tagSENT_CONTENT	m\tagSENT_CONTENT	=\tagSENT_CONTENT	n\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	are\tagSENT_CONTENT	set\tagSENT_CONTENT	zero\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	when\tagSENT_CONTENT	m\tagSENT_CONTENT	=\tagSENT_CONTENT	n\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	between\tagSENT_CONTENT	TransD\tagSENT_CONTENT	and\tagSENT_CONTENT	TransH\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	relation_prediction\tagtask	are\tagSENT_CONTENT	determinded\tagSENT_CONTENT	only\tagSENT_CONTENT	by\tagSENT_CONTENT	relations\tagSENT_CONTENT	in\tagSENT_CONTENT	TransH\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	TransD\tagSENT_CONTENT	's\tagSENT_CONTENT	projection\tagSENT_CONTENT	vectors\tagSENT_CONTENT	are\tagSENT_CONTENT	determinded\tagSENT_CONTENT	by\tagSENT_CONTENT	both\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Results\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	apporach\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Data\tagSECTITLE_START	Sets\tagSECTITLE_END	Triplets\tagSECTITLE_START	Classification\tagSECTITLE_END	relation_prediction\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	judge\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	given\tagSENT_CONTENT	triplet\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	corrector\tagSENT_CONTENT	not\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	binary\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	relation_prediction\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	set\tagSENT_CONTENT	a\tagSENT_CONTENT	threshold\tagSENT_CONTENT	δ\tagSENT_CONTENT	r\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	relation\tagSENT_END	We\tagSENT_START	compare\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	several\tagSENT_CONTENT	previous\tagSENT_CONTENT	embedding\tagSENT_CONTENT	models\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	As\tagSENT_START	described\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	TransD\tagSENT_CONTENT	trains\tagSENT_CONTENT	much\tagSENT_CONTENT	faster\tagSENT_CONTENT	than\tagSENT_CONTENT	TransR\tagSENT_END	FB15\tagSECTITLE_START	K\tagSECTITLE_END	Classification\tagSENT_START	accuracies\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	on\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	of\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	new\tagSENT_CONTENT	facts\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graphs\tagSENT_CONTENT	is\tagSENT_CONTENT	under\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	complementary\tagSENT_CONTENT	approach\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	facts\tagSENT_CONTENT	from\tagSENT_CONTENT	plain\tagSENT_CONTENT	texts\tagSENT_CONTENT	.\tagSENT_END	Link\tagSECTITLE_START	Prediction\tagSECTITLE_END	relation_prediction\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	missing\tagSENT_CONTENT	h\tagSENT_CONTENT	or\tagSENT_CONTENT	t\tagSENT_CONTENT	fora\tagSENT_CONTENT	golden\tagSENT_CONTENT	triplet\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	r\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	2\tagSENT_CONTENT	)\tagSENT_CONTENT	Compared\tagSENT_CONTENT	with\tagSENT_CONTENT	CTransR\tagSENT_CONTENT	,\tagSENT_CONTENT	TransD\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	fine\tagSENT_CONTENT	-\tagSENT_CONTENT	grained\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	considers\tagSENT_CONTENT	the\tagSENT_CONTENT	multiple\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	simultaneously\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	achieves\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	comparison\tagSENT_CONTENT	of\tagSENT_CONTENT	Hits@10\tagmetric	of\tagSENT_CONTENT	different\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	shows\tagSENT_CONTENT	the\tagSENT_CONTENT	detailed\tagSENT_CONTENT	results\tagSENT_CONTENT	by\tagSENT_CONTENT	mapping\tagSENT_CONTENT	properties\tagSENT_CONTENT	of\tagSENT_CONTENT	relations\tagSENT_CONTENT	1\tagSENT_CONTENT	on\tagSENT_CONTENT	FB15k\tagSENT_CONTENT	.\tagSENT_END	Properties\tagSECTITLE_START	of\tagSECTITLE_CONTENT	Projection\tagSECTITLE_CONTENT	Vectors\tagSECTITLE_END	As\tagSENT_START	mentioned\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	"\tagSENT_CONTENT	,\tagSENT_CONTENT	TransD\tagSENT_CONTENT	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	motivation\tagSENT_CONTENT	that\tagSENT_CONTENT	each\tagSENT_CONTENT	mapping\tagSENT_CONTENT	matrix\tagSENT_CONTENT	is\tagSENT_CONTENT	determined\tagSENT_CONTENT	by\tagSENT_CONTENT	entity\tagSENT_CONTENT	-\tagSENT_CONTENT	relation\tagSENT_CONTENT	pair\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	We\tagSENT_START	introduced\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	TransD\tagSENT_CONTENT	that\tagSENT_CONTENT	embed\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	graphs\tagSENT_CONTENT	into\tagSENT_CONTENT	continues\tagSENT_CONTENT	vector\tagSENT_CONTENT	space\tagSENT_CONTENT	for\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Datesets\tagSECTITLE_END	WN18\tagSECTITLE_START	Entities\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Definitions\tagSECTITLE_END	Similar\tagSECTITLE_START	Entities\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Definitions\tagSECTITLE_END	a\tagSENT_START	former\tagSENT_CONTENT	country\tagSENT_CONTENT	bordering\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Adriatic\tagSENT_CONTENT	Sea\tagSENT_CONTENT	shift\tagSENT_CONTENT	VB\tagSENT_CONTENT	2\tagSENT_CONTENT	change\tagSENT_CONTENT	place\tagSENT_CONTENT	or\tagSENT_CONTENT	relation_prediction\tagtask	1\tagSENT_CONTENT	a\tagSENT_CONTENT	Romanian\tagSENT_CONTENT	resort\tagSENT_CONTENT	city\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Black\tagSENT_CONTENT	Sea\tagSENT_CONTENT	flap\tagSENT_CONTENT	VB\tagSENT_CONTENT	3\tagSENT_CONTENT	move\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	thrashing\tagSENT_CONTENT	motion\tagSENT_CONTENT	lappland\tagSENT_CONTENT	NN\tagSENT_CONTENT	1\tagSENT_END	Datesets\tagSECTITLE_END	
P18-2038	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Experimental\tagSENT_START	results\tagSENT_CONTENT	on\tagSENT_CONTENT	CoNLL\tagSENT_CONTENT	2003\tagSENT_CONTENT	named\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_END	Introduction\tagSECTITLE_END	Sequence\tagSENT_START	labeling\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	category\tagSENT_CONTENT	of\tagSENT_CONTENT	fundamental\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Different\tagSENT_START	from\tagSENT_CONTENT	CRFs\tagSENT_CONTENT	,\tagSENT_CONTENT	SCRFs\tagSENT_CONTENT	adopt\tagSENT_CONTENT	segments\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	basic\tagSENT_CONTENT	units\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	transition\tagSENT_CONTENT	modeling\tagSENT_CONTENT	.\tagSENT_END	Methods\tagSECTITLE_END	Hybrid\tagSECTITLE_START	semi\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Markov\tagSECTITLE_CONTENT	CRFs\tagSECTITLE_END	where\tagSENT_START	S\tagSENT_CONTENT	contains\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Jointly\tagSECTITLE_START	training\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	decoding\tagSECTITLE_CONTENT	using\tagSECTITLE_CONTENT	CRFs\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	HSCRFs\tagSECTITLE_END	A\tagSENT_START	naive\tagSENT_CONTENT	joint\tagSENT_CONTENT	decoding\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	is\tagSENT_CONTENT	also\tagSENT_CONTENT	designed\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	named_entity_recognition\tagtask	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Dataset\tagSECTITLE_END	This\tagSENT_START	dataset\tagSENT_CONTENT	contained\tagSENT_CONTENT	four\tagSENT_CONTENT	labels\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	PER\tagSENT_CONTENT	,\tagSENT_CONTENT	LOC\tagSENT_CONTENT	,\tagSENT_CONTENT	ORG\tagSENT_CONTENT	and\tagSENT_CONTENT	MISC\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	label\tagSENT_CONTENT	O\tagSENT_CONTENT	for\tagSENT_CONTENT	others\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_END	Results\tagSECTITLE_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	existing\tagSECTITLE_CONTENT	work\tagSECTITLE_END	No\tagSECTITLE_START	.\tagSECTITLE_CONTENT	Model\tagSECTITLE_CONTENT	Name\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	Representation\tagSECTITLE_CONTENT	Top\tagSECTITLE_CONTENT	Layer\tagSECTITLE_END	Analysis\tagSECTITLE_END	One\tagSENT_START	possible\tagSENT_CONTENT	explanation\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	labels\tagSENT_CONTENT	may\tagSENT_CONTENT	supervise\tagSENT_CONTENT	models\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	descriptions\tagSENT_CONTENT	which\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	benefit\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	short\tagSENT_CONTENT	entities\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	LM\tagSENT_CONTENT	-\tagSENT_CONTENT	BLSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	JNT(JNT\tagSENT_CONTENT	)\tagSENT_CONTENT	model\tagSENT_CONTENT	which\tagSENT_CONTENT	adopted\tagSENT_CONTENT	jointly\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	decoding\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	performance\tagSENT_CONTENT	among\tagSENT_CONTENT	all\tagSENT_CONTENT	models\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	
ke18a	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	for\tagSENT_CONTENT	focus\tagSENT_CONTENT	-\tagSENT_CONTENT	ing\tagSENT_CONTENT	RNN\tagSENT_CONTENT	encoders\tagSENT_CONTENT	for\tagSENT_CONTENT	sequence\tagSENT_CONTENT	modelling\tagSENT_CONTENT	tasks\tagSENT_CONTENT	which\tagSENT_CONTENT	allows\tagSENT_CONTENT	them\tagmetric	to\tagSENT_CONTENT	attend\tagSENT_CONTENT	to\tagSENT_CONTENT	key\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	as\tagSENT_CONTENT	needed\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	formulate\tagSENT_CONTENT	this\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	conditional\tagSENT_CONTENT	sequence\tagSENT_CONTENT	encoder\tagSENT_CONTENT	that\tagSENT_CONTENT	reads\tagSENT_CONTENT	in\tagSENT_CONTENT	one\tagSENT_CONTENT	token\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	makes\tagSENT_CONTENT	a\tagSENT_CONTENT	discrete\tagSENT_CONTENT	decision\tagSENT_CONTENT	on\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	is\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	or\tagSENT_CONTENT	question_answering\tagtask	being\tagSENT_CONTENT	asked\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Recurrent\tagSENT_START	Neural\tagSENT_CONTENT	Networks\tagSENT_CONTENT	(\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	attention\tagSENT_CONTENT	are\tagSENT_CONTENT	wildly\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	many\tagSENT_CONTENT	sequence\tagSENT_CONTENT	modeling\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	:\tagSENT_CONTENT	image\tagSENT_CONTENT	captioning\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	text\tagSENT_CONTENT	summarization\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	Answering\tagSENT_CONTENT	(\tagSENT_CONTENT	QA\tagSENT_CONTENT	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Imagine\tagSENT_START	reading\tagSENT_CONTENT	a\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	article\tagSENT_CONTENT	and\tagSENT_CONTENT	trying\tagSENT_CONTENT	to\tagSENT_CONTENT	identify\tagSENT_CONTENT	information\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	relevant\tagSENT_CONTENT	to\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	before\tagSENT_CONTENT	one\tagSENT_CONTENT	knows\tagSENT_CONTENT	what\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	.\tagSENT_END	Keeping\tagSENT_START	this\tagSENT_CONTENT	intuition\tagSENT_CONTENT	in\tagSENT_CONTENT	mind\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	developed\tagSENT_CONTENT	a\tagSENT_CONTENT	focused\tagSENT_CONTENT	RNN\tagSENT_CONTENT	encoder\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	modeled\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	RNN\tagSENT_CONTENT	that\tagSENT_CONTENT	groups\tagSENT_CONTENT	input\tagSENT_CONTENT	sub\tagSENT_CONTENT	-\tagSENT_CONTENT	sequences\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	gates\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	controlled\tagSENT_CONTENT	or\tagSENT_CONTENT	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	or\tagSENT_CONTENT	input\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	move\tagSENT_CONTENT	onto\tagSENT_CONTENT	challenging\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	QA\tagSENT_CONTENT	tasks\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	MS\tagSENT_CONTENT	MARCO\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	SearchQA\tagdataset	(\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	takes\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	or\tagSENT_CONTENT	context\tagSENT_CONTENT	sequence\tagSENT_CONTENT	and\tagSENT_CONTENT	generates\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	Focused\tagSECTITLE_START	Hierarchical\tagSECTITLE_CONTENT	RNN\tagSECTITLE_END	Architecture\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	a\tagSENT_CONTENT	conditional\tagSENT_CONTENT	boundary\tagSENT_CONTENT	gate\tagSENT_CONTENT	to\tagSENT_CONTENT	decide\tagSENT_CONTENT	,\tagSENT_CONTENT	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	or\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	whether\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	useful\tagSENT_CONTENT	to\tagSENT_CONTENT	update\tagSENT_CONTENT	the\tagSENT_CONTENT	upper\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	summary\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	current\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	or\tagSENT_CONTENT	not\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	for\tagSENT_CONTENT	large\tagSENT_CONTENT	QA\tagSENT_CONTENT	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	trivial\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	we\tagSENT_CONTENT	augment\tagSENT_END	We\tagSENT_START	hypothesize\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	essential\tagSENT_CONTENT	in\tagSENT_CONTENT	deciding\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Hence\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	essentially\tagSENT_CONTENT	use\tagSENT_CONTENT	three\tagSENT_CONTENT	groups\tagSENT_CONTENT	of\tagSENT_CONTENT	features\tagSENT_CONTENT	:\tagSENT_CONTENT	question_answering\tagtask	multiplied\tagSENT_CONTENT	with\tagSENT_CONTENT	lower\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	lower\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	.\tagSENT_START	.\tagSENT_CONTENT	,\tagSENT_CONTENT	h\tagSENT_CONTENT	u\tagSENT_CONTENT	n\tagSENT_CONTENT	}\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	only\tagSENT_CONTENT	k\tagSENT_CONTENT	of\tagSENT_CONTENT	them\tagmetric	are\tagSENT_CONTENT	unique\tagSENT_CONTENT	and\tagSENT_CONTENT	k\tagSENT_CONTENT	=\tagSENT_CONTENT	t\tagSENT_CONTENT	˜\tagSENT_CONTENT	b\tagSENT_CONTENT	t\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	times\tagSENT_END	Training\tagSECTITLE_END	We\tagSENT_START	train\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	A\tagSENT_CONTENT	)\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	(\tagSENT_CONTENT	Q\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	our\tagSENT_CONTENT	answer\tagSENT_CONTENT	decoder\tagSENT_CONTENT	:\tagSENT_END	Sparsity\tagSECTITLE_START	Constraints\tagSECTITLE_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	have\tagSENT_CONTENT	discussed\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	focused\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	encoder\tagSENT_CONTENT	is\tagSENT_CONTENT	modeled\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	RNN\tagSENT_CONTENT	controlled\tagSENT_CONTENT	by\tagSENT_CONTENT	gates\tagSENT_CONTENT	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	context\tagSENT_CONTENT	or\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Synthetic\tagSECTITLE_START	Experiments\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	study\tagSENT_CONTENT	two\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	tasks\tagSENT_CONTENT	that\tagSENT_CONTENT	allow\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	analyze\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	gating\tagSENT_CONTENT	,\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	generalization\tagSENT_CONTENT	ability\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	5\tagSENT_CONTENT	we\tagSENT_CONTENT	study\tagSENT_CONTENT	the\tagSENT_CONTENT	more\tagSENT_CONTENT	complex\tagSENT_CONTENT	tasks\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	For\tagSENT_START	the\tagSENT_CONTENT	picking\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	gating\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	context\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	group\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	tokens\tagSENT_CONTENT	and\tagSENT_CONTENT	how\tagSENT_CONTENT	the\tagSENT_CONTENT	attention\tagSENT_CONTENT	mechanism\tagSENT_CONTENT	utilizes\tagSENT_CONTENT	this\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	INPUT\tagSECTITLE_START	TARGET\tagSECTITLE_CONTENT	SEQUENCE\tagSECTITLE_END	Picking\tagSECTITLE_START	task\tagSECTITLE_END	n.\tagSENT_START	Hence\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	value\tagSENT_CONTENT	of\tagSENT_CONTENT	k\tagSENT_CONTENT	is\tagSENT_CONTENT	understood\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	This\tagSENT_START	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	level\tagSENT_CONTENT	of\tagSENT_CONTENT	control\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	-\tagSENT_CONTENT	sparsity\tagSENT_CONTENT	tradeoff\tagSENT_CONTENT	-we\tagSENT_CONTENT	used\tagSENT_CONTENT	this\tagSENT_CONTENT	approach\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	requirement\tagSENT_CONTENT	of\tagSENT_CONTENT	achieving\tagSENT_CONTENT	a\tagSENT_CONTENT	desired\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	a.\tagSENT_CONTENT	We\tagSENT_CONTENT	tested\tagSENT_CONTENT	FHE\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	∈\tagSENT_CONTENT	{\tagSENT_CONTENT	80\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	90\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	95\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	98\tagSENT_CONTENT	%\tagSENT_CONTENT	}\tagSENT_CONTENT	and\tagSENT_CONTENT	call\tagSENT_CONTENT	them\tagmetric	FHE80\tagSENT_CONTENT	,\tagSENT_CONTENT	FHE90\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	LENGTH\tagSECTITLE_END	LSTM1\tagSECTITLE_START	LSTM2\tagSECTITLE_CONTENT	FHE\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	FIXED\tagSECTITLE_END	98.4\tagSECTITLE_START	99.1\tagSECTITLE_END	The\tagSENT_START	models\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	fork\tagSENT_CONTENT	larger\tagSENT_CONTENT	than\tagSENT_CONTENT	maximum\tagSENT_CONTENT	sequence\tagSENT_CONTENT	length\tagSENT_CONTENT	used\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	because\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Pixel\tagSECTITLE_START	-\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Pixel\tagSECTITLE_CONTENT	MNIST\tagSECTITLE_CONTENT	QA\tagSECTITLE_CONTENT	task\tagSECTITLE_END	We\tagSENT_START	adapt\tagSENT_CONTENT	the\tagSENT_CONTENT	Pixel\tagSENT_CONTENT	-\tagSENT_CONTENT	by\tagSENT_CONTENT	-\tagSENT_CONTENT	Pixel\tagSENT_CONTENT	MNIST\tagSENT_CONTENT	classification\tagSENT_CONTENT	task\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	answering\tagSENT_CONTENT	setting\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	found\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	particular\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	gates\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	depend\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Large\tagSECTITLE_START	Scale\tagSECTITLE_CONTENT	Natural\tagSECTITLE_CONTENT	Language\tagSECTITLE_CONTENT	QA\tagSECTITLE_CONTENT	Tasks\tagSECTITLE_END	These\tagSENT_START	tasks\tagSENT_CONTENT	are\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	suited\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	since\tagSENT_CONTENT	they\tagSENT_CONTENT	both\tagSENT_CONTENT	involve\tagSENT_CONTENT	searching\tagSENT_CONTENT	over\tagSENT_CONTENT	along\tagSENT_CONTENT	input\tagSENT_CONTENT	passage\tagSENT_CONTENT	for\tagSENT_CONTENT	answers\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	To\tagSENT_START	obtain\tagSENT_CONTENT	competitive\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	we\tagSENT_CONTENT	embed\tagSENT_CONTENT	FHE\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	modified\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	encoder\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	decoder\tagSENT_CONTENT	.\tagSENT_END	Question\tagSECTITLE_START	Encoder\tagSECTITLE_END	Following\tagSENT_START	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	that\tagSENT_CONTENT	first\tagSENT_CONTENT	reads\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	then\tagSENT_CONTENT	performs\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Decoder\tagSECTITLE_END	h\tagSENT_START	u\tagSENT_CONTENT	t\tagSENT_CONTENT	learned\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	FHE\tagSENT_CONTENT	conditioned\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	In\tagSENT_START	addition\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	Bleu-1\tagSENT_CONTENT	and\tagSENT_CONTENT	Rouge\tagSENT_CONTENT	-\tagSENT_CONTENT	L\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	outperform\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	MODELS\tagSECTITLE_END	SearchQA\tagSECTITLE_START	Question\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Answering\tagSECTITLE_CONTENT	Task\tagSECTITLE_END	MS\tagSECTITLE_START	MARCO\tagSECTITLE_CONTENT	Question\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Answering\tagSECTITLE_CONTENT	Task\tagSECTITLE_END	Span\tagSENT_START	-\tagSENT_CONTENT	based\tagSENT_CONTENT	vs\tagSENT_CONTENT	Generative\tagSENT_CONTENT	Most\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	recent\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	MS\tagSENT_CONTENT	MARCO\tagSENT_CONTENT	are\tagSENT_CONTENT	span\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	5\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	all\tagSENT_CONTENT	competing\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	Bleu-1\tagSENT_CONTENT	and\tagSENT_CONTENT	Rouge\tagSENT_CONTENT	-\tagSENT_CONTENT	L.\tagSENT_END	The\tagSENT_START	largest\tagSENT_CONTENT	gain\tagSENT_CONTENT	came\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	elementwise\tagSENT_CONTENT	-\tagSENT_CONTENT	product\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	results\tagSENT_CONTENT	is\tagSENT_CONTENT	supportive\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	hypothesis\tagSENT_CONTENT	that\tagSENT_CONTENT	learned\tagSENT_CONTENT	boundaries\tagSENT_CONTENT	help\tagSENT_CONTENT	with\tagSENT_CONTENT	better\tagSENT_CONTENT	document\tagSENT_CONTENT	encoding\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	therefore\tagSENT_CONTENT	generates\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Our\tagSENT_START	attention\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	relevant\tagSENT_CONTENT	passage\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	that\tagSENT_CONTENT	contains\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	other\tagSENT_CONTENT	salient\tagSENT_CONTENT	phrases\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	given\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	order\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	randomized\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	questionnaire\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Our\tagSENT_START	proposed\tagSENT_CONTENT	model\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	discrete\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	gating\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	conditions\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	vector\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	control\tagSENT_CONTENT	information\tagSENT_CONTENT	flow\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	concept\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	.\tagSENT_END	
N18-1140	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	skills\tagSENT_CONTENT	required\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	reader\tagSENT_CONTENT	performance\tagSENT_CONTENT	varies\tagSENT_CONTENT	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	applicable\tagSENT_CONTENT	skills\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Machine\tagSENT_START	comprehension\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	task\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	reads\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	answers\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	progress\tagSENT_CONTENT	in\tagSENT_CONTENT	machine\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	heavily\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	introduction\tagSENT_CONTENT	of\tagSENT_CONTENT	new\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	encourages\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	of\tagSENT_CONTENT	new\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	and\tagSENT_CONTENT	deepens\tagSENT_CONTENT	question_answering\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	(\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	)\tagSENT_CONTENT	challenges\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	or\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	tackled\tagSENT_CONTENT	well\tagSENT_CONTENT	by\tagSENT_CONTENT	these\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	.\tagSENT_END	passage\tagSECTITLE_START	:\tagSECTITLE_END	Thereafter\tagSENT_START	,\tagSENT_CONTENT	question_answering\tagtask	of\tagSENT_CONTENT	corticosteroids\tagSENT_CONTENT	was\tagSENT_CONTENT	initiated\tagSENT_CONTENT	with\tagSENT_CONTENT	no\tagSENT_CONTENT	clinical\tagSENT_CONTENT	relapse\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	typical\tagSENT_CONTENT	application\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	clinical\tagSENT_CONTENT	decision\tagSENT_CONTENT	support\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	given\tagSENT_CONTENT	a\tagSENT_CONTENT	massive\tagSENT_CONTENT	amount\tagSENT_CONTENT	of\tagSENT_CONTENT	text\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	clinician\tagSENT_CONTENT	asks\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	either\tagSENT_CONTENT	external\tagSENT_CONTENT	,\tagSENT_CONTENT	medical\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	(\tagSENT_CONTENT	reading\tagSENT_CONTENT	literature\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	about\tagSENT_CONTENT	particular\tagSENT_CONTENT	patients\tagSENT_CONTENT	(\tagSENT_CONTENT	reading\tagSENT_CONTENT	electronic\tagSENT_CONTENT	health\tagSENT_CONTENT	records\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	enable\tagSENT_CONTENT	a\tagSENT_CONTENT	more\tagSENT_CONTENT	flexible\tagSENT_CONTENT	answer\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	expand\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	their\tagSENT_CONTENT	respective\tagSENT_CONTENT	synonyms\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	medical\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	base\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	additionally\tagSENT_CONTENT	supplement\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	with\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	and\tagSENT_CONTENT	embedding\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	results\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	gated\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	approach\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	embedding\tagSENT_CONTENT	similarity\tagSENT_CONTENT	proves\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	categorizing\tagSENT_CONTENT	the\tagSENT_CONTENT	skills\tagSENT_CONTENT	necessary\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	skills\tagSENT_CONTENT	get\tagSENT_CONTENT	activated\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	prior\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	lexico\tagSENT_CONTENT	-\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	inferences\tagSENT_CONTENT	matters\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	.\tagSENT_END	Size\tagSENT_START	:\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	datasets\tagSECTITLE_END	SciQ\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	science\tagSENT_CONTENT	exam\tagSENT_CONTENT	questions\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	question_answering\tagtask	are\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	retrieve\tagSENT_CONTENT	the\tagSENT_CONTENT	text\tagSENT_CONTENT	passages\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	question_answering\tagtask	,\tagSENT_CONTENT	four\tagSENT_CONTENT	candidate\tagSENT_CONTENT	answers\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	may\tagSENT_CONTENT	also\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	less\tagSENT_CONTENT	varied\tagSENT_CONTENT	datasets\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	would\tagSENT_CONTENT	tend\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	of\tagSENT_CONTENT	wh\tagSENT_CONTENT	-\tagSENT_CONTENT	type\tagSENT_CONTENT	;\tagSENT_CONTENT	for\tagSENT_CONTENT	cloze\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	maybe\tagSENT_CONTENT	more\tagSENT_CONTENT	varied\tagSENT_CONTENT	and\tagSENT_CONTENT	might\tagSENT_CONTENT	require\tagSENT_CONTENT	readers\tagSENT_CONTENT	to\tagSENT_CONTENT	possess\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	skills\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_START	design\tagSECTITLE_END	Query\tagSECTITLE_START	construction\tagSECTITLE_END	Answer\tagSECTITLE_START	set\tagSECTITLE_END	Similarly\tagSENT_START	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	certain\tagSENT_CONTENT	queries\tagSENT_CONTENT	none\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	A\tagSENT_CONTENT	occurs\tagSENT_CONTENT	verbatim\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Task\tagSECTITLE_START	formulation\tagSECTITLE_END	Whenever\tagSENT_START	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	are\tagSENT_CONTENT	marked\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	can\tagSENT_CONTENT	learn\tagSENT_CONTENT	to\tagSENT_CONTENT	exploit\tagSENT_CONTENT	this\tagSENT_CONTENT	cue\tagSENT_CONTENT	to\tagSENT_CONTENT	find\tagSENT_CONTENT	question_answering\tagtask	more\tagSENT_CONTENT	easily\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	all\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	reader\tagSENT_CONTENT	chooses\tagSENT_CONTENT	question_answering\tagtask	among\tagSENT_CONTENT	the\tagSENT_CONTENT	candidates\tagSENT_CONTENT	E\tagSENT_CONTENT	collected\tagSENT_CONTENT	from\tagSENT_CONTENT	all\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Dataset\tagSECTITLE_START	analysis\tagSECTITLE_END	Upon\tagSENT_START	extending\tagSENT_CONTENT	question_answering\tagtask	set\tagSENT_CONTENT	with\tagSENT_CONTENT	UMLS\tagSENT_CONTENT	R\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	on\tagSENT_CONTENT	average\tagSENT_CONTENT	four\tagSENT_CONTENT	alternative\tagSENT_CONTENT	answers\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	original\tagSENT_CONTENT	one\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	59\tagSENT_CONTENT	%\tagSENT_CONTENT	of\tagSENT_CONTENT	instances\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	found\tagSENT_CONTENT	verbatim\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	relevant\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	can\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	,\tagSENT_CONTENT	treatment\tagSENT_CONTENT	or\tagSENT_CONTENT	test\tagSENT_CONTENT	categories\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	usually\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	words\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_START	of\tagSECTITLE_CONTENT	comprehension\tagSECTITLE_CONTENT	skills\tagSECTITLE_END	Methods\tagSECTITLE_END	Baselines\tagSECTITLE_END	Our\tagSENT_START	simplest\tagSENT_CONTENT	baselines\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	include\tagSENT_CONTENT	choosing\tagSENT_CONTENT	a\tagSENT_CONTENT	random\tagSENT_CONTENT	entity\tagSENT_CONTENT	(\tagSENT_CONTENT	rand\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	selecting\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	frequent\tagSENT_CONTENT	passage\tagSENT_CONTENT	entity\tagSENT_CONTENT	(\tagSENT_CONTENT	maxfreq\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	)\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Neural\tagSECTITLE_START	readers\tagSECTITLE_END	It\tagSENT_START	predicts\tagSENT_CONTENT	question_answering\tagtask	using\tagSENT_CONTENT	:\tagSENT_END	At\tagSENT_START	prediction\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	attention\tagSENT_CONTENT	should\tagSENT_CONTENT	highlight\tagSENT_CONTENT	that\tagSENT_CONTENT	position\tagSENT_CONTENT	tin\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	where\tagSENT_CONTENT	question_answering\tagtask	occurs\tagSENT_CONTENT	.\tagSENT_END	Returning\tagSENT_START	to\tagSENT_CONTENT	our\tagSENT_CONTENT	different\tagSENT_CONTENT	set\tagSENT_CONTENT	-\tagSENT_CONTENT	ups\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	entity\tagSENT_CONTENT	annotation\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	3.3\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	means\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	apply\tagSENT_CONTENT	SA\tagSENT_CONTENT	reader\tagSENT_CONTENT	with\tagSENT_CONTENT	Ent\tagSENT_CONTENT	and\tagSENT_CONTENT	Anonym\tagSENT_CONTENT	setups\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	with\tagSENT_CONTENT	NoEnt\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	question_answering\tagtask	should\tagSENT_CONTENT	be\tagSENT_CONTENT	allowed\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	predicts\tagSENT_CONTENT	question_answering\tagtask	using\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	explicit\tagSENT_CONTENT	reference\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	positions\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	:\tagSENT_END	Since\tagSENT_START	the\tagSENT_CONTENT	model\tagSENT_CONTENT	marks\tagSENT_CONTENT	the\tagSENT_CONTENT	references\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	token\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	separately\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	allows\tagSENT_CONTENT	us\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	also\tagSENT_CONTENT	the\tagSENT_CONTENT	NoEnt\tagSENT_CONTENT	set\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	.\tagSENT_END	Embedding\tagSECTITLE_START	data\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	pre\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	training\tagSECTITLE_END	Evaluation\tagSECTITLE_END	In\tagSENT_START	our\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	or\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	phrase\tagSENT_CONTENT	representing\tagSENT_CONTENT	a\tagSENT_CONTENT	medical\tagSENT_CONTENT	entity\tagSENT_CONTENT	.\tagSENT_END	Alternatively\tagSENT_START	,\tagSENT_CONTENT	one\tagSENT_CONTENT	could\tagSENT_CONTENT	also\tagSENT_CONTENT	take\tagSENT_CONTENT	the\tagSENT_CONTENT	UMLS\tagSENT_CONTENT	R\tagSENT_CONTENT	CUI\tagSENT_CONTENT	identifier\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	current\tagSENT_CONTENT	setup\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	keep\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	word\tagSENT_CONTENT	phrase\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	The\tagSENT_START	CUI\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	an\tagSENT_CONTENT	integral\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	our\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	by\tagSENT_CONTENT	other\tagSENT_CONTENT	researchers\tagSENT_CONTENT	if\tagSENT_CONTENT	preferred\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	4\tagSENT_CONTENT	)\tagSENT_CONTENT	Since\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	question_answering\tagtask	First\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	measure\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	grams\tagSENT_CONTENT	of\tagSENT_CONTENT	length\tagSENT_CONTENT	2\tagSENT_CONTENT	(\tagSENT_CONTENT	shortly\tagSENT_CONTENT	,\tagSENT_CONTENT	B2\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	4\tagSENT_CONTENT	(\tagSENT_CONTENT	B4\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	package\tagSENT_CONTENT	by\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	aim\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	contiguity\tagSENT_CONTENT	of\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	analysis\tagSECTITLE_END	The\tagSENT_START	language\tagSENT_CONTENT	model\tagSENT_CONTENT	performs\tagSENT_CONTENT	poorly\tagSENT_CONTENT	on\tagSENT_CONTENT	EM\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagmetric	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	-\tagSENT_CONTENT	metric\tagSENT_CONTENT	score\tagSENT_CONTENT	is\tagSENT_CONTENT	higher\tagSENT_CONTENT	,\tagSENT_CONTENT	likely\tagSENT_CONTENT	reflecting\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	answers\tagSENT_CONTENT	-\tagSENT_CONTENT	though\tagSENT_CONTENT	mostly\tagSENT_CONTENT	incorrect\tagSENT_CONTENT	-\tagSENT_CONTENT	are\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	-\tagSENT_CONTENT	truth\tagSENT_CONTENT	answers\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	poor\tagSENT_CONTENT	performance\tagSENT_CONTENT	means\tagSENT_CONTENT	that\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	queries\tagSENT_CONTENT	alone\tagSENT_CONTENT	(\tagSENT_CONTENT	without\tagSENT_CONTENT	reading\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Upon\tagSENT_START	inspecting\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	answers\tagSENT_CONTENT	more\tagSENT_CONTENT	closely\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	observed\tagSENT_CONTENT	that\tagSENT_CONTENT	GA\tagSENT_CONTENT	-\tagSENT_CONTENT	NoEnt\tagSENT_CONTENT	tends\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	question_answering\tagtask	than\tagSENT_CONTENT	GA\tagSENT_CONTENT	-\tagSENT_CONTENT	Ent\tagSENT_CONTENT	/\tagSENT_CONTENT	Anonym\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	predicted\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	GA\tagSENT_CONTENT	-\tagSENT_CONTENT	NoEnt\tagSENT_CONTENT	was\tagSENT_CONTENT	as\tagSENT_CONTENT	high\tagSENT_CONTENT	as\tagSENT_CONTENT	3.7\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	whereas\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	two\tagSENT_CONTENT	set\tagSENT_CONTENT	-\tagSENT_CONTENT	ups\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	-\tagSENT_CONTENT	truth\tagSENT_CONTENT	answers\tagSENT_CONTENT	the\tagSENT_CONTENT	numbers\tagSENT_CONTENT	range\tagSENT_CONTENT	between\tagSENT_CONTENT	2.3\tagSENT_CONTENT	and\tagSENT_CONTENT	2.5\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	plausible\tagSENT_CONTENT	explanation\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	lies\tagSENT_CONTENT	in\tagSENT_CONTENT	how\tagSENT_CONTENT	GA\tagSENT_CONTENT	reaches\tagSENT_CONTENT	its\tagSENT_CONTENT	prediction\tagSENT_CONTENT	(\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	by\tagSENT_CONTENT	accumulating\tagSENT_CONTENT	question_answering\tagtask	without\tagSENT_CONTENT	normalizing\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	would\tagSENT_CONTENT	then\tagSENT_CONTENT	drive\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	prefer\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Human\tagSECTITLE_START	performance\tagSECTITLE_END	To\tagSENT_START	measure\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	sample\tagSENT_CONTENT	of\tagSENT_CONTENT	data\tagSENT_CONTENT	instances\tagSENT_CONTENT	as\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	skills\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	expert\tagSENT_CONTENT	scores\tagSENT_CONTENT	higher\tagSENT_CONTENT	across\tagSENT_CONTENT	all\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	7-point\tagSENT_CONTENT	advantage\tagSENT_CONTENT	in\tagSENT_CONTENT	%\tagmetric	F1\tagmetric	.\tagSENT_END	swer\tagSENT_START	is\tagSENT_CONTENT	possible\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	correct\tagSENT_CONTENT	to\tagSENT_CONTENT	various\tagSENT_CONTENT	degrees\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	aimed\tagSENT_CONTENT	to\tagSENT_CONTENT	capture\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	metric\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	Breakdown\tagSECTITLE_START	of\tagSECTITLE_CONTENT	results\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	skill\tagSECTITLE_END	To\tagSENT_START	see\tagSENT_CONTENT	how\tagSENT_CONTENT	question_answering\tagtask	relates\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	skill\tagSENT_CONTENT	requirements\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	have\tagSENT_CONTENT	analyzed\tagSENT_CONTENT	the\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	set\tagSENT_CONTENT	annotated\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	skills\tagSENT_CONTENT	by\tagSENT_CONTENT	averaging\tagSENT_CONTENT	F1\tagSENT_CONTENT	values\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	instances\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	skill\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	future\tagSECTITLE_CONTENT	work\tagSECTITLE_END	A\tagSECTITLE_START	Training\tagSECTITLE_CONTENT	details\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	hyper\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	parameter\tagSECTITLE_CONTENT	optimization\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	baseline\tagSENT_CONTENT	sim\tagSENT_CONTENT	-\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	was\tagSENT_CONTENT	carried\tagSENT_CONTENT	out\tagSENT_CONTENT	20\tagSENT_CONTENT	times\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	validation\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	chose\tagSENT_CONTENT	the\tagSENT_CONTENT	parameter\tagSENT_CONTENT	configuration\tagSENT_CONTENT	that\tagSENT_CONTENT	led\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	-\tagSENT_CONTENT	performing\tagSENT_CONTENT	embedding\tagSENT_CONTENT	model\tagSENT_CONTENT	as\tagSENT_CONTENT	measured\tagSENT_CONTENT	by\tagSENT_CONTENT	F1\tagmetric	.\tagSENT_END	B\tagSECTITLE_START	List\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	skills\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	selected\tagSECTITLE_CONTENT	examples\tagSECTITLE_END	Mathematical\tagSENT_START	reasoning\tagSENT_CONTENT	:\tagSENT_CONTENT	whenever\tagSENT_CONTENT	a\tagSENT_CONTENT	mathematical\tagSENT_CONTENT	operation\tagSENT_CONTENT	is\tagSENT_CONTENT	involved\tagSENT_CONTENT	in\tagSENT_CONTENT	finding\tagSENT_CONTENT	question_answering\tagtask	3\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	parentheses\tagSENT_CONTENT	,\tagSENT_CONTENT	dashes\tagSENT_CONTENT	,\tagSENT_CONTENT	quotations\tagSENT_CONTENT	,\tagSENT_CONTENT	colons\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	B.1\tagSECTITLE_START	Bridging\tagSECTITLE_CONTENT	inference\tagSECTITLE_CONTENT	passage\tagSECTITLE_END	The\tagSENT_START	reader\tagSENT_CONTENT	needs\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	background\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	that\tagSENT_CONTENT	prednisolone\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	glucocorticoid\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	it\tagSENT_CONTENT	becomes\tagSENT_CONTENT	obvious\tagSENT_CONTENT	that\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	cyclophoshamide\tagSENT_CONTENT	.\tagSENT_END	B.2\tagSECTITLE_START	Object\tagSECTITLE_CONTENT	tracking\tagSECTITLE_CONTENT	passage\tagSECTITLE_END	B.3\tagSECTITLE_START	Meta\tagSECTITLE_CONTENT	knowledge\tagSECTITLE_END	question_answering\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	inferred\tagSENT_CONTENT	from\tagSENT_CONTENT	several\tagSENT_CONTENT	parts\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	(\tagSENT_CONTENT	not\tagSENT_CONTENT	shown\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	even\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	title\tagSENT_CONTENT	or\tagSENT_CONTENT	the\tagSENT_CONTENT	query\tagSENT_CONTENT	.\tagSENT_END	
1609.07561	title\tagSECTITLE_END	Distilling\tagSENT_START	an\tagSENT_CONTENT	Ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	into\tagSENT_CONTENT	One\tagSENT_CONTENT	MST\tagSENT_CONTENT	Parser\tagSENT_END	abstract\tagSECTITLE_END	dependency_parsing\tagtask	is\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	distillation\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	dependency_parsing\tagtask	achieve\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	training\tagSENT_CONTENT	them\tagSENT_CONTENT	involves\tagSENT_CONTENT	gradient\tagSENT_CONTENT	descent\tagSENT_CONTENT	on\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	convex\tagSENT_CONTENT	objectives\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	unstable\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	initial\tagSENT_CONTENT	parameter\tagSENT_CONTENT	values\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	is\tagSENT_CONTENT	not\tagSENT_CONTENT	a\tagSENT_CONTENT	practical\tagSENT_CONTENT	solution\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	an\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	N\tagSENT_CONTENT	parsers\tagSENT_CONTENT	requires\tagSENT_CONTENT	N\tagSENT_CONTENT	times\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	computation\tagSENT_CONTENT	,\tagSENT_CONTENT	plus\tagSENT_CONTENT	the\tagSENT_CONTENT	runtime\tagSENT_CONTENT	of\tagSENT_CONTENT	finding\tagSENT_CONTENT	consensus\tagSENT_CONTENT	.\tagSENT_END	Notation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Definitions\tagSECTITLE_END	dependency_parsing\tagtask	for\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	denoted\tagSENT_CONTENT	y\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	tuples\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	h\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	index\tagSENT_CONTENT	of\tagSENT_CONTENT	ahead\tagSENT_CONTENT	,\tagSENT_CONTENT	m\tagSENT_END	A\tagSENT_START	first\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	(\tagSENT_CONTENT	FOG\tagSENT_CONTENT	;\tagSENT_CONTENT	also\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	dependency_parsing\tagtask	exactly\tagSENT_CONTENT	solvesˆy\tagSENT_CONTENT	solvesˆ\tagSENT_CONTENT	solvesˆy(x\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	,\tagSENT_START	where\tagSENT_CONTENT	T\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	directed\tagSENT_CONTENT	trees\tagSENT_CONTENT	over\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	sis\tagSENT_CONTENT	a\tagSENT_CONTENT	local\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	considers\tagSENT_CONTENT	dependency_parsing\tagtask	at\tagSENT_CONTENT	a\tagSENT_CONTENT	time\tagSENT_CONTENT	.\tagSENT_END	Given\tagSENT_START	dependency_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	sentence\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	and\tagSENT_CONTENT	y\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Hamming\tagSENT_CONTENT	cost\tagSENT_CONTENT	is\tagSENT_END	This\tagSENT_START	cost\tagSENT_CONTENT	underlies\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	and\tagSENT_CONTENT	labeled\tagSENT_CONTENT	attachment\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	henceforth\tagSENT_CONTENT	UAS\tagSENT_CONTENT	and\tagSENT_CONTENT	LAS\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Under\tagSENT_START	the\tagSENT_CONTENT	Hamming\tagSENT_CONTENT	cost\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	equates\tagSENT_CONTENT	algorithmically\tagSENT_CONTENT	to\tagSENT_CONTENT	FOG\tagSENT_CONTENT	parsing\tagSENT_CONTENT	with\tagSENT_CONTENT	s(h\tagSENT_CONTENT	,\tagSENT_CONTENT	m\tagSENT_CONTENT	,\tagSENT_CONTENT	x\tagSENT_CONTENT	)\tagSENT_CONTENT	=\tagSENT_END	Variants\tagSENT_START	have\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	extensively\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parsers\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	typically\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	Hamming\tagSENT_CONTENT	cost\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	inner\tagSENT_CONTENT	max\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	solved\tagSENT_CONTENT	efficiently\tagSENT_CONTENT	using\tagSENT_CONTENT	FOG\tagSENT_CONTENT	parsing\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	slightly\tagSENT_CONTENT	revised\tagSENT_CONTENT	local\tagSENT_CONTENT	scoring\tagSENT_CONTENT	function\tagSENT_CONTENT	:\tagSENT_END	Plugging\tagSENT_START	this\tagSENT_CONTENT	into\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	1\tagSENT_CONTENT	is\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Consensus\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Minimum\tagSECTITLE_CONTENT	Bayes\tagSECTITLE_CONTENT	Risk\tagSECTITLE_END	Despite\tagSENT_START	the\tagSENT_CONTENT	recent\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	most\tagSENT_CONTENT	prior\tagSENT_CONTENT	works\tagSENT_CONTENT	exclusively\tagSENT_CONTENT	report\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	model\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	What\tagSECTITLE_START	is\tagSECTITLE_CONTENT	Ensemble\tagSECTITLE_CONTENT	Uncertainty\tagSECTITLE_CONTENT	?\tagSECTITLE_END	While\tagSENT_START	previous\tagSENT_CONTENT	works\tagSENT_CONTENT	have\tagSENT_CONTENT	already\tagSENT_CONTENT	demonstrated\tagSENT_CONTENT	the\tagSENT_CONTENT	merit\tagSENT_CONTENT	of\tagSENT_CONTENT	ensembling\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	,\tagSENT_CONTENT	usually\tagSENT_CONTENT	with\tagSENT_CONTENT	diverse\tagSENT_CONTENT	base\tagSENT_CONTENT	parsers\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	posterior\tagSENT_CONTENT	marginals\tagSENT_CONTENT	estimated\tagSENT_CONTENT	byˆp\tagSENT_CONTENT	byˆ\tagSENT_CONTENT	byˆp((h\tagSENT_CONTENT	,\tagSENT_CONTENT	m\tagSENT_CONTENT	)\tagSENT_END	Our\tagSENT_START	next\tagSENT_CONTENT	idea\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	transform\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	uncertainty\tagSENT_CONTENT	into\tagSENT_CONTENT	anew\tagSENT_CONTENT	estimate\tagSENT_CONTENT	of\tagSENT_CONTENT	cost\tagmetric	-\tagSENT_CONTENT	a\tagSENT_CONTENT	replacement\tagSENT_END	Distilling\tagSECTITLE_START	the\tagSECTITLE_CONTENT	Ensemble\tagSECTITLE_END	Despite\tagSENT_START	its\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	performance\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	requires\tagSENT_CONTENT	dependency_parsing\tagtask	to\tagSENT_CONTENT	decode\tagSENT_CONTENT	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	their\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	provides\tagSENT_CONTENT	a\tagSENT_CONTENT	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	labels\tagmetric	for\tagSENT_CONTENT	each\tagSENT_CONTENT	input\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	this\tagSENT_CONTENT	predicted\tagSENT_CONTENT	distribution\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	training\tagSENT_CONTENT	target\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	distilled\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	cross\tagSENT_CONTENT	entropies\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	targeting\tagSENT_CONTENT	the\tagSENT_CONTENT	empirical\tagSENT_CONTENT	training\tagSENT_CONTENT	distribution\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	targeting\tagSENT_CONTENT	the\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	's\tagSENT_CONTENT	posterior\tagSENT_CONTENT	distribution\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Soft\tagSENT_START	targets\tagSENT_CONTENT	allow\tagSENT_CONTENT	us\tagmetric	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	notion\tagSENT_CONTENT	that\tagSENT_CONTENT	mistaking\tagSENT_CONTENT	woman\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	parent\tagSENT_CONTENT	of\tagSENT_CONTENT	with\tagSENT_CONTENT	is\tagSENT_CONTENT	less\tagSENT_CONTENT	bad\tagSENT_CONTENT	than\tagSENT_CONTENT	attaching\tagSENT_CONTENT	with\tagSENT_CONTENT	to\tagSENT_CONTENT	John\tagSENT_CONTENT	or\tagSENT_CONTENT	telescope\tagSENT_CONTENT	.\tagSENT_END	Distillation\tagSECTITLE_START	Cost\tagSECTITLE_CONTENT	Function\tagSECTITLE_END	In\tagSENT_START	contrast\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagmetric	case\tagmetric	,\tagSENT_CONTENT	the\tagSENT_CONTENT	structured\tagSENT_CONTENT	hinge\tagSENT_CONTENT	loss\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	penalty\tagSENT_CONTENT	"\tagSENT_CONTENT	the\tagSENT_CONTENT	learner\tagSENT_CONTENT	tries\tagSENT_CONTENT	to\tagSENT_CONTENT	minimize\tagSENT_CONTENT	while\tagSENT_CONTENT	training\tagSENT_CONTENT	the\tagSENT_CONTENT	graph\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parser\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	and\tagSENT_CONTENT	model\tagSENT_CONTENT	score\tagSENT_CONTENT	as\tagSENT_CONTENT	defined\tagSENT_CONTENT	in\tagSENT_CONTENT	Equation\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	Distilled\tagSECTITLE_START	Parser\tagSECTITLE_END	Further\tagSENT_START	,\tagSENT_CONTENT	because\tagSENT_CONTENT	our\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	's\tagSENT_CONTENT	posterior\tagSENT_CONTENT	gives\tagSENT_CONTENT	us\tagmetric	information\tagSENT_CONTENT	about\tagSENT_CONTENT	each\tagSENT_CONTENT	attachment\tagSENT_CONTENT	individually\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	function\tagSENT_CONTENT	we\tagSENT_CONTENT	construct\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	first\tagSENT_CONTENT	-\tagSENT_CONTENT	order\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	simplifies\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	exact\tagSENT_CONTENT	inference\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	dependency_parsing\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	same\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	thread\tagSENT_CONTENT	CPU\tagSENT_CONTENT	hardware\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	distilled\tagSENT_CONTENT	MST\tagSENT_CONTENT	parser\tagSENT_CONTENT	9\tagSENT_CONTENT	parses\tagSENT_CONTENT	20\tagSENT_CONTENT	sentences\tagSENT_CONTENT	per\tagSENT_CONTENT	second\tagSENT_CONTENT	without\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	while\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	stack\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	  \tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	three\tagSENT_CONTENT	times\tagSENT_CONTENT	faster\tagSENT_CONTENT	at\tagSENT_CONTENT	60\tagSENT_CONTENT	sentences\tagSENT_CONTENT	per\tagSENT_CONTENT	second\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	Chinese\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	achieves\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	published\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	German\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	published\tagSENT_CONTENT	UAS\tagSENT_CONTENT	scores\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	just\tagSENT_CONTENT	after\tagSENT_CONTENT	Bohnet\tagSENT_CONTENT	and\tagSENT_CONTENT	Nivre\tagSENT_CONTENT	for\tagSENT_CONTENT	LAS\tagmetric	.\tagSENT_END	The\tagSENT_START	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	with\tagSENT_CONTENT	Hamming\tagSENT_CONTENT	cost\tagSENT_CONTENT	achieved\tagSENT_CONTENT	93.1\tagSENT_CONTENT	UAS\tagSENT_CONTENT	and\tagSENT_CONTENT	90.9\tagSENT_CONTENT	LAS\tagSENT_CONTENT	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	93.6\tagmetric	UAS\tagmetric	and\tagSENT_CONTENT	91.1\tagmetric	LAS\tagmetric	for\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	distillation\tagSENT_CONTENT	cost\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	parsing\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	English\tagSENT_CONTENT	,\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	German\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	Our\tagSENT_START	work\tagSENT_CONTENT	on\tagSENT_CONTENT	ensembling\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	and\tagSENT_CONTENT	;\tagSENT_CONTENT	an\tagSENT_CONTENT	additional\tagSENT_CONTENT	contribution\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	normalized\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	votes\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	MBR\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	an\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	of\tagSENT_CONTENT	20\tagSENT_CONTENT	greedy\tagSENT_CONTENT	stack\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	(\tagSENT_CONTENT	can\tagSENT_CONTENT	achieve\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	
P04-1061	title\tagSECTITLE_END	Corpus\tagSENT_START	-\tagSENT_CONTENT	Based\tagSENT_CONTENT	Induction\tagSENT_CONTENT	of\tagSENT_CONTENT	Syntactic\tagSENT_CONTENT	Structure\tagSENT_CONTENT	:\tagSENT_CONTENT	Models\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	Constituency\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	present\tagSENT_CONTENT	a\tagSENT_CONTENT	generative\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	learning\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	multiplicative\tagSENT_CONTENT	combination\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	linear\tagSENT_CONTENT	constituency\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	product\tagSENT_CONTENT	model\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	both\tagSENT_CONTENT	components\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	respective\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	,\tagSENT_CONTENT	giving\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	published\tagSENT_CONTENT	figures\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	This\tagSENT_START	paper\tagSENT_CONTENT	falls\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	latter\tagSENT_CONTENT	category\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	inducing\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	constituency\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency_parsing\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	recovering\tagSENT_CONTENT	linguistically\tagSENT_CONTENT	plausible\tagSENT_CONTENT	structures\tagSENT_CONTENT	.\tagSENT_END	Unsupervised\tagSECTITLE_START	Dependency\tagSECTITLE_CONTENT	Parsing\tagSECTITLE_END	Most\tagSENT_START	recent\tagSENT_CONTENT	progress\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	has\tagSENT_CONTENT	come\tagSENT_CONTENT	from\tagSENT_CONTENT	tree\tagSENT_CONTENT	or\tagSENT_CONTENT	phrase\tagSENT_CONTENT	-\tagSENT_CONTENT	structure\tagSENT_CONTENT	grammar\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	compelling\tagSENT_CONTENT	reasons\tagSENT_CONTENT	to\tagSENT_CONTENT	reconsider\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	most\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	ofthe\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	supervised\tagSENT_CONTENT	parsers\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagmetric	of\tagSENT_CONTENT	specific\tagSENT_CONTENT	lexical\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	level\tagSENT_CONTENT	information\tagSENT_CONTENT	-perhaps\tagSENT_CONTENT	lexical\tagSENT_CONTENT	information\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	useful\tagSENT_CONTENT	source\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	for\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Third\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	below\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	languages\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	have\tagSENT_CONTENT	few\tagSENT_CONTENT	function\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	for\tagSENT_CONTENT	which\tagSENT_CONTENT	the\tagSENT_CONTENT	definition\tagSENT_CONTENT	of\tagSENT_CONTENT	lexical\tagSENT_CONTENT	categories\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	less\tagSENT_CONTENT	clear\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	maybe\tagSENT_CONTENT	easier\tagSENT_CONTENT	to\tagSENT_CONTENT	detect\tagSENT_CONTENT	.\tagSENT_END	Representation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Evaluation\tagSECTITLE_END	dependency_parsing\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	short\tagSENT_CONTENT	sentence\tagSENT_CONTENT	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	traditional\tagSENT_CONTENT	dependency\tagSENT_CONTENT	grammar\tagSENT_CONTENT	notation\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	regent\tagSENT_CONTENT	or\tagSENT_CONTENT	head\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	marked\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	tail\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	dependent\tagSENT_CONTENT	is\tagSENT_CONTENT	marked\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	arrowhead\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Depending\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of-\tagSENT_CONTENT	speech\tagSENT_CONTENT	categories\tagSENT_CONTENT	maybe\tagSENT_CONTENT	included\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	dependency_parsing\tagtask	maybe\tagSENT_CONTENT	directly\tagSENT_CONTENT	between\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	will\tagSENT_CONTENT	always\tagSENT_CONTENT	consist\tagSENT_CONTENT	of\tagSENT_CONTENT	exactly\tagSENT_CONTENT	as\tagSENT_CONTENT	many\tagSENT_CONTENT	dependencies\tagSENT_CONTENT	as\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	of\tagSENT_CONTENT	figure\tagSENT_CONTENT	1(b\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	are\tagSENT_CONTENT	{\tagSENT_CONTENT	(\tagSENT_CONTENT	ROOT\tagSENT_CONTENT	,\tagSENT_CONTENT	fell\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	fell\tagSENT_CONTENT	,\tagSENT_CONTENT	payrolls\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	fell\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	September\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	(\tagSENT_CONTENT	payrolls\tagSENT_CONTENT	,\tagSENT_CONTENT	Factory\tagSENT_CONTENT	)\tagSENT_CONTENT	}\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	quality\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	hypothesized\tagSENT_CONTENT	dependency\tagSENT_CONTENT	structure\tagSENT_CONTENT	can\tagSENT_CONTENT	hence\tagSENT_CONTENT	be\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	by\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	as\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	gold\tagSENT_CONTENT	-\tagSENT_CONTENT	standard\tagSENT_CONTENT	dependency\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	reporting\tagSENT_CONTENT	the\tagSENT_CONTENT	percentage\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	shared\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	analyses\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	next\tagSENT_CONTENT	section\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	discuss\tagSENT_CONTENT	several\tagSENT_CONTENT	models\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	throughout\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	various\tagSENT_CONTENT	methods\tagSENT_CONTENT	at\tagSENT_CONTENT	recovering\tagSENT_CONTENT	dependency_parsing\tagtask	from\tagSENT_CONTENT	various\tagSENT_CONTENT	corpora\tagSENT_CONTENT	,\tagSENT_CONTENT	detailed\tagSENT_CONTENT	here\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	important\tagSENT_CONTENT	to\tagSENT_CONTENT	note\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	treebanks\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	include\tagSENT_CONTENT	dependency_parsing\tagtask	;\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	dependency_parsing\tagtask	from\tagSENT_CONTENT	are\tagSENT_CONTENT	sufficiently\tagSENT_CONTENT	accurate\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	a\tagSENT_CONTENT	good\tagSENT_CONTENT	benchmark\tagSENT_CONTENT	for\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	systems\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	time\tagSENT_CONTENT	being\tagSENT_CONTENT	(\tagSENT_CONTENT	though\tagSENT_CONTENT	see\tagSENT_CONTENT	below\tagSENT_CONTENT	for\tagSENT_CONTENT	specific\tagSENT_CONTENT	issues\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Dependency\tagSECTITLE_START	Models\tagSECTITLE_END	dependency_parsing\tagtask	has\tagSENT_CONTENT	received\tagSENT_CONTENT	relatively\tagSENT_CONTENT	little\tagSENT_CONTENT	attention\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	known\tagSENT_CONTENT	work\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	operate\tagSENT_CONTENT	under\tagSENT_CONTENT	the\tagSENT_CONTENT	assumption\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	product\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	scores\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	attachments\tagSENT_CONTENT	)\tagSENT_CONTENT	in\tagSENT_CONTENT	that\tagSENT_CONTENT	structure\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	are\tagSENT_CONTENT	seen\tagSENT_CONTENT	as\tagSENT_CONTENT	ordered\tagSENT_CONTENT	(\tagSENT_CONTENT	head\tagSENT_CONTENT	,\tagSENT_CONTENT	dependent\tagSENT_CONTENT	)\tagSENT_END	pairs\tagSENT_START	of\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	can\tagSENT_CONTENT	optionally\tagSENT_CONTENT	condition\tagSENT_CONTENT	on\tagSENT_CONTENT	other\tagSENT_CONTENT	characteristics\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	most\tagSENT_CONTENT	often\tagSENT_CONTENT	the\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	arrow\tagSENT_CONTENT	points\tagSENT_CONTENT	left\tagSENT_CONTENT	or\tagSENT_CONTENT	right\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Some\tagSENT_START	notation\tagSENT_CONTENT	before\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	specific\tagSENT_CONTENT	models\tagSENT_CONTENT	:\tagSENT_CONTENT	dependency_parsing\tagtask	dis\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	of\tagSENT_CONTENT	ahead\tagSENT_CONTENT	and\tagSENT_CONTENT	argument\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	are\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	corpus\tagSENT_CONTENT	S.\tagSENT_CONTENT	For\tagSENT_CONTENT	uniformity\tagSENT_CONTENT	of\tagSENT_CONTENT	notation\tagSENT_CONTENT	with\tagSENT_CONTENT	section\tagSENT_CONTENT	4\tagSENT_END	dependency_parsing\tagtask	However\tagSENT_START	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	parser\tagSENT_CONTENT	predicted\tagSENT_CONTENT	dependency_parsing\tagtask	at\tagSENT_CONTENT	below\tagSENT_CONTENT	chance\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	measured\tagSENT_CONTENT	by\tagSENT_CONTENT	choosing\tagSENT_CONTENT	dependency_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	one\tagSENT_CONTENT	were\tagSENT_CONTENT	to\tagSENT_CONTENT	apply\tagSENT_CONTENT	the\tagSENT_CONTENT	Paskin\tagSENT_CONTENT	(\tagSENT_CONTENT	2002\tagSENT_CONTENT	)\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency\tagSENT_CONTENT	structures\tagSENT_CONTENT	parameterized\tagSENT_CONTENT	simply\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	classes\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	result\tagSENT_CONTENT	would\tagSENT_CONTENT	be\tagSENT_CONTENT	isomorphic\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	described\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	one\tagSENT_CONTENT	nice\tagSENT_CONTENT	property\tagSENT_CONTENT	of\tagSENT_CONTENT	their\tagSENT_CONTENT	structural\tagSENT_CONTENT	constraint\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	dependency_parsing\tagtask	share\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	symbols\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	grammar\tagSENT_CONTENT	are\tagSENT_CONTENT	not\tagSENT_CONTENT	symmetric\tagSENT_CONTENT	.\tagSENT_END	If\tagSENT_START	one\tagSENT_CONTENT	recasts\tagSENT_CONTENT	their\tagSENT_CONTENT	experiments\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	way\tagSENT_CONTENT	,\tagSENT_CONTENT	they\tagSENT_CONTENT	achieve\tagSENT_CONTENT	an\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	44.7\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	treebank\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	choosing\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	but\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	simply\tagSENT_CONTENT	linking\tagSENT_CONTENT	all\tagSENT_CONTENT	adjacent\tagSENT_CONTENT	words\tagSENT_CONTENT	into\tagSENT_CONTENT	a\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	headed\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	branching\tagSENT_CONTENT	)\tagSENT_CONTENT	structure\tagSENT_CONTENT	(\tagSENT_CONTENT	53.2\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	An\tagSECTITLE_START	Improved\tagSECTITLE_CONTENT	Dependency\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	dependency_parsing\tagtask	discussed\tagSENT_CONTENT	above\tagSENT_CONTENT	are\tagSENT_CONTENT	distinct\tagSENT_CONTENT	from\tagSENT_CONTENT	dependency_parsing\tagtask	used\tagSENT_CONTENT	inside\tagSENT_CONTENT	highperformance\tagSENT_CONTENT	supervised\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	parsers\tagSENT_CONTENT	in\tagSENT_CONTENT	several\tagSENT_CONTENT	ways\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	propose\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	head\tagSENT_CONTENT	-\tagSENT_CONTENT	outward\tagSENT_CONTENT	dependency\tagSENT_CONTENT	model\tagSENT_CONTENT	over\tagSENT_CONTENT	word\tagSENT_CONTENT	classes\tagSENT_CONTENT	which\tagSENT_CONTENT	includes\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	valence\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	call\tagSENT_CONTENT	DMV\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	dependency_parsing\tagtask	with\tagSENT_CONTENT	valence\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	in\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	child\tagSENT_CONTENT	of\tagSENT_CONTENT	ROOT\tagSENT_CONTENT	,\tagSENT_CONTENT	here\tagSENT_CONTENT	fell\tagSENT_CONTENT	.\tagSENT_END	After\tagSENT_START	an\tagSENT_CONTENT	argument\tagSENT_CONTENT	is\tagSENT_CONTENT	generated\tagSENT_CONTENT	,\tagSENT_CONTENT	its\tagSENT_CONTENT	subtree\tagSENT_CONTENT	in\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	recursively\tagSENT_CONTENT	generated\tagSENT_CONTENT	.\tagSENT_END	Formally\tagSENT_START	,\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	let\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	h\tagSENT_CONTENT	have\tagSENT_CONTENT	left\tagSENT_CONTENT	For\tagSENT_START	each\tagSENT_CONTENT	sentence\tagSENT_CONTENT	s\tagSENT_CONTENT	∈\tagSENT_CONTENT	S\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	gives\tagSENT_CONTENT	us\tagmetric	c\tagSENT_CONTENT	s\tagSENT_CONTENT	(\tagSENT_END	We\tagSENT_START	chose\tagSENT_CONTENT	to\tagSENT_CONTENT	initialize\tagSENT_CONTENT	EM\tagSENT_CONTENT	not\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	initial\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	initial\tagSENT_CONTENT	guess\tagSENT_CONTENT	at\tagSENT_CONTENT	posterior\tagSENT_CONTENT	distributions\tagSENT_CONTENT	over\tagSENT_CONTENT	dependency_parsing\tagtask	(\tagSENT_CONTENT	completions\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	structure\tagSENT_CONTENT	had\tagSENT_CONTENT	two\tagSENT_CONTENT	advantages\tagSENT_CONTENT	:\tagSENT_CONTENT	first\tagSENT_CONTENT	,\tagSENT_CONTENT	when\tagSENT_CONTENT	testing\tagSENT_CONTENT	multiple\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	easier\tagSENT_CONTENT	to\tagSENT_CONTENT	start\tagSENT_CONTENT	them\tagSENT_CONTENT	all\tagSENT_CONTENT	off\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	common\tagSENT_CONTENT	way\tagSENT_CONTENT	by\tagSENT_CONTENT	beginning\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	M\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	second\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	allowed\tagSENT_CONTENT	us\tagmetric	to\tagSENT_CONTENT	point\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	vague\tagSENT_CONTENT	general\tagSENT_CONTENT	direction\tagSENT_CONTENT	of\tagSENT_CONTENT	what\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	dependency\tagSENT_CONTENT	structures\tagSENT_CONTENT	should\tagSENT_CONTENT	look\tagSENT_CONTENT	like\tagSENT_CONTENT	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	WSJ10\tagSENT_CONTENT	corpus\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	DMV\tagSENT_CONTENT	model\tagSENT_CONTENT	recovers\tagSENT_CONTENT	a\tagSENT_CONTENT	substantial\tagSENT_CONTENT	fraction\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	:\tagSENT_END	The\tagSENT_START	most\tagSENT_CONTENT	common\tagSENT_CONTENT	source\tagSENT_CONTENT	of\tagSENT_CONTENT	discrepancy\tagSENT_CONTENT	between\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	guesses\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	result\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	systematically\tagSENT_CONTENT	choosing\tagSENT_CONTENT	determiners\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	heads\tagSENT_CONTENT	of\tagSENT_CONTENT	noun\tagSENT_CONTENT	phrases\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	test\tagSENT_CONTENT	trees\tagSENT_CONTENT	have\tagSENT_CONTENT	the\tagSENT_CONTENT	rightmost\tagSENT_CONTENT	noun\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	.\tagSENT_END	dependency_parsing\tagtask	is\tagSENT_CONTENT	reasonably\tagSENT_CONTENT	successful\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	this\tagSENT_CONTENT	end\tagSENT_CONTENT	,\tagSENT_CONTENT	after\tagSENT_CONTENT	briefly\tagSENT_CONTENT	recapping\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	combined\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	exploits\tagSENT_CONTENT	dependency_parsing\tagtask	and\tagSENT_CONTENT	constituencies\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	will\tagSENT_CONTENT	see\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	combined\tagSENT_CONTENT	model\tagSENT_CONTENT	finds\tagSENT_CONTENT	dependency_parsing\tagtask	more\tagSENT_CONTENT	successfully\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	above\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	finds\tagSENT_CONTENT	constituents\tagSENT_CONTENT	more\tagSENT_CONTENT	successfully\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	Distributional\tagSECTITLE_START	Constituency\tagSECTITLE_CONTENT	Induction\tagSECTITLE_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	if\tagSENT_CONTENT	one\tagSENT_CONTENT	is\tagSENT_CONTENT	given\tagSENT_CONTENT	all\tagSENT_CONTENT	contiguous\tagSENT_CONTENT	subsequences\tagSENT_CONTENT	(\tagSENT_CONTENT	subspans\tagmetric	)\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	corpus\tagSENT_CONTENT	of\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	most\tagSENT_CONTENT	natural\tagSENT_CONTENT	clusters\tagSENT_CONTENT	will\tagSENT_CONTENT	not\tagSENT_CONTENT	represent\tagSENT_CONTENT	valid\tagSENT_CONTENT	constituents\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	extent\tagSENT_CONTENT	that\tagSENT_CONTENT	constituency\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	situated\tagSENT_CONTENT	sequence\tagSENT_CONTENT	is\tagSENT_CONTENT	even\tagSENT_CONTENT	a\tagSENT_CONTENT	well\tagSENT_CONTENT	-\tagSENT_CONTENT	formed\tagSENT_CONTENT	notion\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	Combined\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	P\tagSECTITLE_START	(\tagSECTITLE_CONTENT	i\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	k\tagSECTITLE_CONTENT	|true)P\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	i−1\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	i\tagSECTITLE_CONTENT	∼\tagSECTITLE_CONTENT	k\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	k+1\tagSECTITLE_CONTENT	|true\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	P\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	i\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	k\tagSECTITLE_CONTENT	|false)P\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	i−1\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	i\tagSECTITLE_CONTENT	∼\tagSECTITLE_CONTENT	k\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	k+1\tagSECTITLE_CONTENT	|false\tagSECTITLE_CONTENT	)\tagSECTITLE_END	though\tagSENT_START	it\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	arbitrary\tagSENT_CONTENT	convention\tagSENT_CONTENT	as\tagSENT_CONTENT	far\tagSENT_CONTENT	as\tagSENT_CONTENT	dependency_parsing\tagtask	are\tagSENT_CONTENT	concerned\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	using\tagSENT_CONTENT	dependency_parsing\tagtask	alone\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	allow\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	even\tagSENT_CONTENT	probability\tagSENT_CONTENT	for\tagSENT_CONTENT	either\tagSENT_CONTENT	generation\tagSENT_CONTENT	order\tagSENT_CONTENT	(\tagSENT_CONTENT	but\tagSENT_CONTENT	in\tagSENT_CONTENT	each\tagSENT_CONTENT	actual\tagSENT_CONTENT	head\tagSENT_CONTENT	derivation\tagSENT_CONTENT	,\tagSENT_CONTENT	only\tagSENT_CONTENT	one\tagSENT_CONTENT	order\tagSENT_CONTENT	occurs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	give\tagSENT_CONTENT	the\tagSENT_CONTENT	behavior\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CCM\tagSENT_CONTENT	constituency\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency_parsing\tagtask	on\tagSENT_CONTENT	both\tagSENT_CONTENT	constituency\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency\tagSENT_CONTENT	induction\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	CCM\tagSENT_CONTENT	is\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	recovering\tagSENT_CONTENT	constituency\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	dependency_parsing\tagtask	is\tagSENT_CONTENT	better\tagSENT_CONTENT	at\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	In\tagSENT_START	dependency_parsing\tagtask	,\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	,\tagSENT_CONTENT	scoring\tagSENT_CONTENT	a\tagSENT_CONTENT	lexicalized\tagSENT_CONTENT	tree\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	product\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	lexical\tagSENT_CONTENT	dependency\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	PCFG\tagSENT_CONTENT	model\tagSENT_CONTENT	can\tagSENT_CONTENT	outperform\tagSENT_CONTENT	each\tagSENT_CONTENT	factor\tagSENT_CONTENT	on\tagSENT_CONTENT	its\tagSENT_CONTENT	respective\tagSENT_CONTENT	metric\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	practice\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	correction\tagSENT_CONTENT	factor\tagSENT_CONTENT	was\tagSENT_CONTENT	harmful\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	combination\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	duplicated\tagSENT_CONTENT	a\tagSENT_CONTENT	strength\tagSENT_CONTENT	of\tagSENT_CONTENT	dependency_parsing\tagtask	,\tagSENT_CONTENT	badly\tagSENT_CONTENT	.\tagSENT_CONTENT	  \tagSENT_END	From\tagSENT_START	dependency_parsing\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	pay\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	h\tagSENT_CONTENT	taking\tagSENT_CONTENT	a\tagSENT_CONTENT	as\tagSENT_CONTENT	aright\tagSENT_CONTENT	argument\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	CHOOSE\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	cost\tagSENT_CONTENT	of\tagSENT_CONTENT	choosing\tagSENT_CONTENT	not\tagSENT_CONTENT	to\tagSENT_CONTENT	stop\tagSENT_CONTENT	(\tagSENT_CONTENT	P\tagSENT_CONTENT	STOP\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Again\tagSENT_START	,\tagSENT_CONTENT	if\tagSENT_CONTENT	we\tagSENT_CONTENT	modify\tagSENT_CONTENT	the\tagSENT_CONTENT	gold\tagSENT_CONTENT	standard\tagSENT_CONTENT	so\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	determiners\tagSENT_CONTENT	the\tagSENT_CONTENT	head\tagSENT_CONTENT	of\tagSENT_CONTENT	NPs\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	this\tagSENT_CONTENT	model\tagSENT_CONTENT	with\tagSENT_CONTENT	distributional\tagSENT_CONTENT	tags\tagSENT_CONTENT	scores\tagSENT_CONTENT	50.6\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	directed\tagSENT_CONTENT	and\tagSENT_CONTENT	64.8\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	German\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	combination\tagSENT_CONTENT	again\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	each\tagSENT_CONTENT	factor\tagSENT_CONTENT	alone\tagSENT_CONTENT	,\tagSENT_CONTENT	though\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	combination\tagSENT_CONTENT	was\tagSENT_CONTENT	most\tagSENT_CONTENT	helpful\tagSENT_CONTENT	at\tagSENT_CONTENT	boosting\tagSENT_CONTENT	constituency\tagSENT_CONTENT	quality\tagSENT_CONTENT	for\tagSENT_CONTENT	English\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	German\tagSENT_CONTENT	it\tagSENT_CONTENT	provided\tagSENT_CONTENT	a\tagSENT_CONTENT	larger\tagSENT_CONTENT	boost\tagSENT_CONTENT	to\tagSENT_CONTENT	dependency_parsing\tagtask	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Chinese\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	combination\tagSENT_CONTENT	did\tagSENT_CONTENT	substantially\tagSENT_CONTENT	boost\tagSENT_CONTENT	dependency_parsing\tagtask	over\tagSENT_CONTENT	either\tagSENT_CONTENT	single\tagSENT_CONTENT	factor\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	actually\tagSENT_CONTENT	suffered\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	drop\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	have\tagSENT_CONTENT	presented\tagSENT_CONTENT	a\tagSENT_CONTENT	successful\tagSENT_CONTENT	new\tagSENT_CONTENT	dependencybased\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	induction\tagSENT_CONTENT	of\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	structure\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	picks\tagSENT_CONTENT	up\tagSENT_CONTENT	the\tagSENT_CONTENT	key\tagSENT_CONTENT	ideas\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	made\tagSENT_CONTENT	dependency_parsing\tagtask	successful\tagSENT_CONTENT	in\tagSENT_CONTENT	supervised\tagSENT_CONTENT	statistical\tagSENT_CONTENT	parsing\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	
N18-2046	title\tagSECTITLE_END	Near\tagSENT_START	Human\tagSENT_CONTENT	-\tagSENT_CONTENT	Level\tagSENT_CONTENT	Performance\tagSENT_CONTENT	in\tagSENT_CONTENT	grammatical_error_correction\tagtask	with\tagSENT_CONTENT	Hybrid\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	combine\tagSENT_CONTENT	two\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	popular\tagSENT_CONTENT	approaches\tagSENT_CONTENT	to\tagSENT_CONTENT	grammatical_error_correction\tagtask	(\tagSENT_CONTENT	GEC\tagSENT_CONTENT	)\tagSENT_CONTENT	:\tagSENT_CONTENT	GEC\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	Statistical\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_CONTENT	(\tagSENT_CONTENT	SMT\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	GEC\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	Neural\tagSENT_CONTENT	Machine\tagSENT_CONTENT	Translation\tagSENT_CONTENT	(\tagSENT_CONTENT	NMT\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Data\tagSECTITLE_START	and\tagSECTITLE_CONTENT	preprocessing\tagSECTITLE_END	SMT\tagSECTITLE_START	systems\tagSECTITLE_END	we\tagSENT_START	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	4-fold\tagSENT_CONTENT	cross\tagSENT_CONTENT	-\tagSENT_CONTENT	validation\tagSENT_CONTENT	on\tagSENT_CONTENT	NUCLE\tagSENT_CONTENT	with\tagSENT_CONTENT	grammatical_error_correction\tagtask	recommended\tagSENT_CONTENT	by\tagSENT_CONTENT	JunczysDowmunt\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	M\tagSENT_START	2\tagSENT_CONTENT	-tuned\tagSENT_CONTENT	SMT\tagSENT_CONTENT	system\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	though\tagSENT_CONTENT	grammatical_error_correction\tagtask	has\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	at\tagSENT_CONTENT	this\tagSENT_CONTENT	point\tagSENT_CONTENT	.\tagSENT_END	NMT\tagSECTITLE_START	systems\tagSECTITLE_END	Hybrid\tagSECTITLE_START	SMT\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	NMT\tagSECTITLE_CONTENT	systems\tagSECTITLE_END	As\tagSENT_START	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	NMT\tagSENT_CONTENT	system\tagSENT_CONTENT	without\tagSENT_CONTENT	a\tagSENT_CONTENT	RNN\tagSENT_CONTENT	LM\tagSENT_CONTENT	is\tagSENT_CONTENT	much\tagSENT_CONTENT	lower\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	SMT\tagSENT_CONTENT	system\tagSENT_CONTENT	alone\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	implies\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	approaches\tagSENT_CONTENT	produce\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	It\tagSENT_START	seems\tagSENT_CONTENT	the\tagSENT_CONTENT	SMT\tagSENT_CONTENT	system\tagSENT_CONTENT	is\tagSENT_CONTENT	notable\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	as\tagSENT_CONTENT	grammatical_error_correction\tagtask	in\tagSENT_CONTENT	an\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	list\tagSENT_CONTENT	as\tagSENT_CONTENT	those\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	NMT\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	.\tagSENT_END	grammatical_error_correction\tagtask	and\tagSENT_CONTENT	final\tagSENT_CONTENT	results\tagSENT_CONTENT	Pipelining\tagSENT_CONTENT	the\tagSENT_CONTENT	NMT\tagSENT_CONTENT	-\tagSENT_CONTENT	rescored\tagSENT_CONTENT	SMT\tagSENT_CONTENT	system\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	NMT\tagSENT_CONTENT	system\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	improvement\tagSENT_CONTENT	.\tagSENT_END	System\tagSECTITLE_END	Best\tagSECTITLE_START	SMT\tagSECTITLE_END	Best\tagSECTITLE_START	NMT\tagSECTITLE_END	Rescoring\tagSECTITLE_END	Reference\tagSECTITLE_START	1\tagSECTITLE_END	Reference\tagSECTITLE_START	2\tagSECTITLE_END	Reference\tagSECTITLE_START	3\tagSECTITLE_END	Reference\tagSECTITLE_START	4\tagSECTITLE_END	Analysis\tagSECTITLE_START	and\tagSECTITLE_CONTENT	future\tagSECTITLE_CONTENT	work\tagSECTITLE_END	The\tagSENT_START	SMT\tagSENT_CONTENT	and\tagSENT_CONTENT	NMT\tagSENT_CONTENT	systems\tagSENT_CONTENT	produce\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	Comparison\tagSENT_START	with\tagSENT_CONTENT	human\tagSENT_CONTENT	annotations\tagSENT_CONTENT	created\tagSENT_CONTENT	an\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	CoNLL-2014\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	with\tagSENT_CONTENT	10\tagSENT_CONTENT	annotators\tagSENT_CONTENT	in\tagSENT_CONTENT	total\tagSENT_CONTENT	,\tagSENT_CONTENT	JFLEG\tagSENT_CONTENT	already\tagSENT_CONTENT	incorporates\tagSENT_CONTENT	grammatical_error_correction\tagtask	from\tagSENT_CONTENT	4\tagSENT_CONTENT	annotators\tagSENT_CONTENT	.\tagSENT_END	Further\tagSENT_START	inspection\tagSENT_CONTENT	reveals\tagSENT_CONTENT	,\tagSENT_CONTENT	however\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	precision\tagSENT_CONTENT	/\tagSENT_CONTENT	recall\tagSENT_CONTENT	trade\tagSENT_CONTENT	-\tagSENT_CONTENT	off\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	automatic\tagSENT_CONTENT	system\tagSENT_CONTENT	indicates\tagSENT_CONTENT	lower\tagSENT_CONTENT	coverage\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	grammatical_error_correction\tagtask	A\tagSENT_START	nested\tagSENT_CONTENT	attention\tagSENT_CONTENT	neural\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	grammatical_error_correction\tagtask	.\tagSENT_END	
1805.05286	title\tagSECTITLE_END	abstract\tagSECTITLE_END	meaning\tagSENT_START	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	amr_parsing\tagtask	)\tagSENT_CONTENT	are\tagSENT_CONTENT	broad\tagSENT_CONTENT	-\tagSENT_CONTENT	coverage\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Abstract\tagSENT_START	meaning\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	amr_parsing\tagtask	)\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	are\tagSENT_CONTENT	broad\tagSENT_CONTENT	-\tagSENT_CONTENT	coverage\tagSENT_CONTENT	sentencelevel\tagSENT_CONTENT	semantic\tagSENT_CONTENT	representations\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	has\tagSENT_CONTENT	recently\tagSENT_CONTENT	received\tagSENT_CONTENT	a\tagSENT_CONTENT	lot\tagSENT_CONTENT	of\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	alignments\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	treated\tagSENT_CONTENT	as\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	joint\tagSENT_CONTENT	probabilistic\tagSENT_CONTENT	model\tagSENT_CONTENT	and\tagSENT_CONTENT	induced\tagSENT_CONTENT	in\tagSENT_CONTENT	such\tagSENT_CONTENT	away\tagSENT_CONTENT	as\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	deal\tagSENT_CONTENT	with\tagSENT_CONTENT	these\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	categorized\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	When\tagSENT_START	,\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	inducing\tagSENT_CONTENT	alignments\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	approach\tagSENT_CONTENT	and\tagSENT_CONTENT	produce\tagSENT_CONTENT	them\tagSENT_CONTENT	on\tagSENT_CONTENT	preprocessing\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	drops\tagSENT_CONTENT	by\tagSENT_CONTENT	0.9\tagmetric	%\tagmetric	Smatch\tagmetric	.\tagSENT_END	Probabilistic\tagSECTITLE_START	Model\tagSECTITLE_END	Notation\tagSECTITLE_START	and\tagSECTITLE_CONTENT	setting\tagSECTITLE_END	Method\tagSECTITLE_START	overview\tagSECTITLE_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	using\tagSENT_CONTENT	discrete\tagSENT_CONTENT	alignments\tagSENT_CONTENT	,\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	attention\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	for\tagSENT_CONTENT	amr_parsing\tagtask	.\tagSENT_END	Our\tagSENT_START	model\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	:\tagSENT_CONTENT	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	concept\tagSENT_CONTENT	identification\tagSENT_CONTENT	model\tagSENT_CONTENT	P\tagSENT_CONTENT	θ\tagSENT_CONTENT	(\tagSENT_CONTENT	c|a\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	(\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	identification\tagSENT_CONTENT	model\tagSENT_CONTENT	P\tagSENT_CONTENT	φ\tagSENT_CONTENT	(\tagSENT_CONTENT	R|a\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	,\tagSENT_CONTENT	c\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_END	amr_parsing\tagtask	are\tagSENT_CONTENT	assumed\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	generated\tagSENT_CONTENT	conditional\tagSENT_CONTENT	independently\tagSENT_CONTENT	relying\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	states\tagSENT_CONTENT	and\tagSENT_CONTENT	surface\tagSENT_CONTENT	forms\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	aligned\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Concept\tagSECTITLE_START	identification\tagSECTITLE_CONTENT	model\tagSECTITLE_END	Relation\tagSECTITLE_START	identification\tagSECTITLE_CONTENT	model\tagSECTITLE_END	In\tagSENT_START	semantic\tagSENT_CONTENT	role\tagSENT_CONTENT	labeling\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	closely\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	identification\tagSENT_CONTENT	stage\tagSENT_CONTENT	of\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	a\tagSENT_CONTENT	slight\tagSENT_CONTENT	modification\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	approach\tagSENT_CONTENT	was\tagSENT_CONTENT	shown\tagSENT_CONTENT	more\tagSENT_CONTENT	effective\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Alignment\tagSECTITLE_START	model\tagSECTITLE_END	Recall\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	alignment\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	used\tagSENT_CONTENT	at\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	rely\tagSENT_CONTENT	both\tagSENT_CONTENT	on\tagSENT_CONTENT	input\tagSENT_CONTENT	(\tagSENT_CONTENT	states\tagSENT_CONTENT	h\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_END	Estimating\tagSECTITLE_START	model\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Gumbel\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Sinkhorn\tagSECTITLE_END	Our\tagSENT_START	final\tagSENT_CONTENT	objective\tagSENT_CONTENT	is\tagSENT_CONTENT	fully\tagSENT_CONTENT	differentiable\tagSENT_CONTENT	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	all\tagSENT_CONTENT	parameters\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	θ\tagSENT_CONTENT	,\tagSENT_CONTENT	φ\tagSENT_CONTENT	and\tagSENT_CONTENT	ψ\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	has\tagSENT_CONTENT	low\tagSENT_CONTENT	variance\tagSENT_CONTENT	as\tagSENT_CONTENT	amr_parsing\tagtask	is\tagSENT_CONTENT	performed\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	fixed\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	parameterized\tagSENT_CONTENT	distribution\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	standard\tagSENT_CONTENT	VAEs\tagSENT_CONTENT	.\tagSENT_END	Relaxing\tagSECTITLE_START	concept\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	relation\tagSECTITLE_CONTENT	identification\tagSECTITLE_END	As\tagSENT_START	we\tagSENT_CONTENT	will\tagSENT_CONTENT	show\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	amr_parsing\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	loss\tagSENT_CONTENT	is\tagSENT_CONTENT	even\tagSENT_CONTENT	more\tagSENT_CONTENT	effective\tagSENT_CONTENT	:\tagSENT_END	Re\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Categorization\tagSECTITLE_END	amr_parsing\tagtask	often\tagSENT_CONTENT	rely\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	stage\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	specific\tagSENT_CONTENT	subgraphs\tagSENT_CONTENT	of\tagSENT_CONTENT	AMR\tagSENT_CONTENT	are\tagSENT_CONTENT	grouped\tagSENT_CONTENT	together\tagSENT_CONTENT	and\tagSENT_CONTENT	assigned\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	node\tagSENT_CONTENT	with\tagSENT_CONTENT	anew\tagSENT_CONTENT	compound\tagSENT_CONTENT	category\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	;\tagSENT_CONTENT	Foland\tagSENT_CONTENT	and\tagSENT_CONTENT	Martin\tagSENT_CONTENT	(\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	this\tagSENT_CONTENT	transformation\tagSENT_CONTENT	is\tagSENT_CONTENT	reversed\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	post\tagSENT_CONTENT	-\tagSENT_CONTENT	processing\tagSENT_CONTENT	stage\tagSENT_CONTENT	.\tagSENT_END	Details\tagSENT_START	of\tagSENT_CONTENT	the\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	categorization\tagSENT_CONTENT	procedure\tagSENT_CONTENT	and\tagSENT_CONTENT	amr_parsing\tagtask	are\tagSENT_CONTENT	provided\tagSENT_CONTENT	in\tagSENT_CONTENT	appendix\tagSENT_CONTENT	.\tagSENT_END	Post\tagSECTITLE_START	-\tagSECTITLE_CONTENT	processing\tagSECTITLE_END	Model\tagSECTITLE_END	Data\tagmetric	Smatch\tagmetric	JAMR\tagmetric	R1\tagSENT_CONTENT	67.0\tagSENT_CONTENT	AMREager\tagSENT_CONTENT	R1\tagSENT_CONTENT	64.0\tagSENT_CONTENT	CAMR\tagSENT_CONTENT	(\tagSENT_CONTENT	R1\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	Data\tagSECTITLE_START	and\tagSECTITLE_CONTENT	setting\tagSECTITLE_END	We\tagSENT_START	primarily\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	recent\tagSENT_CONTENT	LDC2016E25\tagSENT_CONTENT	(\tagSENT_CONTENT	R2\tagSENT_CONTENT	)\tagSENT_CONTENT	dataset\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	36521\tagSENT_CONTENT	,\tagSENT_CONTENT	1368\tagSENT_CONTENT	and\tagSENT_CONTENT	1371\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	development\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	sets\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	amr_parsing\tagtask	takes\tagSENT_CONTENT	approximately\tagSENT_CONTENT	6\tagSENT_CONTENT	hours\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	GeForce\tagSENT_CONTENT	GTX\tagSENT_CONTENT	1080\tagSENT_END	Experiments\tagSECTITLE_START	and\tagSECTITLE_CONTENT	discussion\tagSECTITLE_END	We\tagSENT_START	start\tagSENT_CONTENT	by\tagSENT_CONTENT	comparing\tagSENT_CONTENT	amr_parsing\tagtask	to\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Models\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	this\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	create\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	version\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	system\tagSENT_CONTENT	(\tagSENT_CONTENT	'\tagSENT_CONTENT	prealign\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	Flanilong\tagSENT_CONTENT	hours\tagSENT_CONTENT	and\tagSENT_CONTENT	lots\tagSENT_CONTENT	of\tagSENT_CONTENT	long\tagSENT_CONTENT	nights\tagSENT_CONTENT	:\tagSENT_END	Ablation\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	amr_parsing\tagtask	,\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	concept\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	aligned\tagSENT_CONTENT	after\tagSENT_CONTENT	JAMR\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	try\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	our\tagSENT_CONTENT	copy\tagSENT_CONTENT	function\tagSENT_CONTENT	to\tagSENT_CONTENT	align\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	When\tagSENT_START	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	joint\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	'\tagSENT_CONTENT	full\tagSENT_CONTENT	model\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	observe\tagSENT_CONTENT	a\tagSENT_CONTENT	substantial\tagSENT_CONTENT	drop\tagSENT_CONTENT	in\tagSENT_CONTENT	Smatch\tagmetric	score\tagmetric	(\tagSENT_CONTENT	-0.8\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	performance\tagSENT_CONTENT	drop\tagSENT_CONTENT	in\tagSENT_CONTENT	Smatch\tagmetric	score\tagmetric	(\tagSENT_CONTENT	'\tagSENT_CONTENT	No\tagSENT_CONTENT	Sinkhorn\tagSENT_CONTENT	reg\tagSENT_CONTENT	'\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	only\tagSENT_CONTENT	moderate\tagSENT_CONTENT	.\tagSENT_END	Additional\tagSECTITLE_START	Related\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	Alignment\tagSENT_START	performance\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	previously\tagSENT_CONTENT	identified\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	potential\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	affecting\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Such\tagSENT_START	translation\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	they\tagSENT_CONTENT	rivaled\tagSENT_CONTENT	specialized\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsers\tagSENT_CONTENT	from\tagSENT_CONTENT	that\tagSENT_CONTENT	period\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	amr_parsing\tagtask	,\tagSENT_CONTENT	another\tagSENT_CONTENT	way\tagSENT_CONTENT	to\tagSENT_CONTENT	avoid\tagSENT_CONTENT	using\tagSENT_CONTENT	pre\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	aligners\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	seq2seq\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_END	We\tagSENT_START	introduced\tagSENT_CONTENT	amr_parsing\tagtask	trained\tagSENT_CONTENT	by\tagSENT_CONTENT	jointly\tagSENT_CONTENT	modeling\tagSENT_CONTENT	alignments\tagSENT_CONTENT	,\tagSENT_CONTENT	concepts\tagSENT_CONTENT	and\tagSENT_CONTENT	relations\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	approach\tagSENT_CONTENT	maybe\tagSENT_CONTENT	extended\tagSENT_CONTENT	to\tagSENT_CONTENT	amr_parsing\tagtask	where\tagSENT_CONTENT	alignments\tagSENT_CONTENT	are\tagSENT_CONTENT	latent\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	parsing\tagSENT_CONTENT	to\tagSENT_CONTENT	logical\tagSENT_CONTENT	form\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Supplementary\tagSECTITLE_START	Material\tagSECTITLE_CONTENT	7\tagSECTITLE_CONTENT	Matching\tagSECTITLE_CONTENT	algorithm\tagSECTITLE_CONTENT	for\tagSECTITLE_CONTENT	copying\tagSECTITLE_CONTENT	concepts\tagSECTITLE_END	Rules\tagSECTITLE_END	Re\tagSECTITLE_START	-\tagSECTITLE_CONTENT	categorization\tagSECTITLE_CONTENT	details\tagSECTITLE_END	Additional\tagSECTITLE_START	pre\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	processing\tagSECTITLE_END	We\tagSENT_START	take\tagSENT_CONTENT	all\tagSENT_CONTENT	dashed\tagSENT_CONTENT	amr_parsing\tagtask	(\tagSENT_CONTENT	e.g\tagSENT_CONTENT	,\tagSENT_CONTENT	make\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	and\tagSENT_CONTENT	more\tagSENT_CONTENT	-\tagSENT_CONTENT	than\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	the\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	spans\tagSENT_CONTENT	(\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	statistics\tagSENT_CONTENT	from\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	PropBank\tagSENT_CONTENT	frame\tagSENT_CONTENT	files\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	parameters\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	optimization\tagSECTITLE_CONTENT	details\tagSECTITLE_END	
1708.00107	title\tagSECTITLE_END	Learned\tagSENT_START	in\tagSENT_CONTENT	text_classification\tagtask	:\tagSENT_END	abstract\tagSECTITLE_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	adding\tagSENT_CONTENT	these\tagSENT_CONTENT	context\tagSENT_CONTENT	vectors\tagSENT_CONTENT	(\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	)\tagSENT_CONTENT	improves\tagSENT_CONTENT	performance\tagSENT_CONTENT	over\tagSENT_CONTENT	using\tagSENT_CONTENT	only\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	character\tagSENT_CONTENT	vectors\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	common\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment_analysis\tagtask	(\tagSENT_CONTENT	SST\tagSENT_CONTENT	,\tagSENT_CONTENT	IMDb\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	classification\tagSENT_CONTENT	(\tagSENT_CONTENT	TREC\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	entailment\tagSENT_CONTENT	(\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	(\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	sentiment_analysis\tagtask	have\tagSENT_CONTENT	been\tagSENT_CONTENT	made\tagSENT_CONTENT	through\tagSENT_CONTENT	transfer\tagSENT_CONTENT	and\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	task\tagSENT_CONTENT	learning\tagSENT_CONTENT	between\tagSENT_CONTENT	synergistic\tagSENT_CONTENT	tasks\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	share\tagSENT_CONTENT	a\tagSENT_CONTENT	common\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	that\tagSENT_CONTENT	include\tagSENT_CONTENT	them\tagSENT_CONTENT	could\tagSENT_CONTENT	further\tagSENT_CONTENT	improve\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	.\tagSENT_END	T\tagSECTITLE_START	a\tagSECTITLE_CONTENT	s\tagSECTITLE_CONTENT	k\tagSECTITLE_CONTENT	-s\tagSECTITLE_CONTENT	p\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	i\tagSECTITLE_CONTENT	f\tagSECTITLE_CONTENT	i\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	M\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	l\tagSECTITLE_CONTENT	D\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	c\tagSECTITLE_CONTENT	o\tagSECTITLE_CONTENT	d\tagSECTITLE_CONTENT	e\tagSECTITLE_CONTENT	r\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	test\tagSENT_CONTENT	the\tagSENT_CONTENT	transferability\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	encoders\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	common\tagSENT_CONTENT	architecture\tagSENT_CONTENT	fora\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	modify\tagSENT_CONTENT	the\tagSENT_CONTENT	Dynamic\tagSENT_CONTENT	Coattention\tagSENT_CONTENT	Network\tagSENT_CONTENT	for\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	adapt\tagSENT_START	object\tagSENT_CONTENT	recognition\tagSENT_CONTENT	models\tagSENT_CONTENT	developed\tagSENT_CONTENT	for\tagSENT_CONTENT	one\tagSENT_CONTENT	visual\tagSENT_CONTENT	domain\tagSENT_CONTENT	to\tagSENT_CONTENT	new\tagSENT_CONTENT	imaging\tagSENT_CONTENT	conditions\tagSENT_CONTENT	by\tagSENT_CONTENT	learning\tagSENT_CONTENT	text_classification\tagtask	that\tagSENT_CONTENT	minimizes\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	induced\tagSENT_CONTENT	changes\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	feature\tagSENT_CONTENT	distribution\tagSENT_CONTENT	.\tagSENT_END	al\tagSENT_START	.\tagSENT_CONTENT	use\tagSENT_CONTENT	matrix\tagSENT_CONTENT	factorization\tagSENT_CONTENT	to\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	text_classification\tagtask	into\tagSENT_CONTENT	tagged\tagSENT_CONTENT	images\tagSENT_CONTENT	to\tagSENT_CONTENT	enhance\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Recent\tagSENT_START	work\tagSENT_CONTENT	in\tagSENT_CONTENT	NLP\tagSENT_CONTENT	has\tagSENT_CONTENT	continued\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	direction\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	.\tagSENT_END	sentiment_analysis\tagtask	have\tagSENT_CONTENT	also\tagSENT_CONTENT	been\tagSENT_CONTENT	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	to\tagSENT_CONTENT	NLP\tagSENT_CONTENT	tasks\tagSENT_CONTENT	like\tagSENT_CONTENT	entailment\tagSENT_CONTENT	,\tagSENT_CONTENT	summarization\tagSENT_CONTENT	,\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	semantic\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	further\tagSENT_START	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	fixed\tagSENT_CONTENT	-\tagSENT_CONTENT	length\tagSENT_CONTENT	representations\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	NMT\tagSENT_CONTENT	encoders\tagSENT_CONTENT	outperform\tagSENT_CONTENT	those\tagSENT_CONTENT	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	language\tagSENT_CONTENT	modeling\tagSENT_CONTENT	)\tagSENT_CONTENT	encoders\tagSENT_CONTENT	on\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	show\tagSENT_START	that\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	CNN\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	region\tagSENT_CONTENT	proposals\tagSENT_CONTENT	improves\tagSENT_CONTENT	object\tagSENT_CONTENT	detection\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	Machine\tagSECTITLE_START	Translation\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	text_classification\tagtask	over\tagSENT_CONTENT	output\tagSENT_CONTENT	words\tagSENT_CONTENT	is\tagSENT_CONTENT	generated\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	final\tagSENT_CONTENT	transformation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	adjusted\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	:\tagSENT_CONTENT	p\tagSENT_CONTENT	(\tagSENT_CONTENT	ˆ\tagSENT_CONTENT	w\tagSENT_CONTENT	z\tagSENT_CONTENT	t\tagSENT_CONTENT	|X\tagSENT_CONTENT	,\tagSENT_CONTENT	w\tagSENT_CONTENT	z\tagSENT_CONTENT	1\tagSENT_CONTENT	,\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_END	Context\tagSECTITLE_START	Vectors\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	CoVe\tagSECTITLE_CONTENT	)\tagSECTITLE_END	For\tagSENT_START	text_classification\tagtask	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	an\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	w\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	concatenate\tagSENT_CONTENT	each\tagSENT_CONTENT	vector\tagSENT_CONTENT	in\tagSENT_CONTENT	GloVe(w\tagSENT_CONTENT	)\tagSENT_CONTENT	with\tagSENT_CONTENT	its\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	vector\tagSENT_CONTENT	in\tagSENT_CONTENT	CoVe(w\tagSENT_CONTENT	)\tagSENT_END	Classification\tagSECTITLE_START	with\tagSECTITLE_CONTENT	CoVe\tagSECTITLE_END	We\tagSENT_START	now\tagSENT_CONTENT	describe\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	BCN\tagSENT_CONTENT	)\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	sequence\tagSENT_CONTENT	is\tagSENT_CONTENT	duplicated\tagSENT_CONTENT	to\tagSENT_CONTENT	form\tagSENT_CONTENT	two\tagSENT_CONTENT	sequences\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	assume\tagSENT_CONTENT	two\tagSENT_CONTENT	input\tagSENT_CONTENT	sequences\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	section\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	function\tagSENT_CONTENT	f\tagSENT_CONTENT	applies\tagSENT_CONTENT	a\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	text_classification\tagtask	to\tagSENT_CONTENT	each\tagSENT_CONTENT	element\tagSENT_CONTENT	of˜wof˜\tagSENT_END	of˜w\tagSENT_START	x\tagSENT_CONTENT	and˜wand˜\tagSENT_CONTENT	and˜w\tagSENT_CONTENT	y\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	processes\tagSENT_CONTENT	the\tagSENT_CONTENT	resulting\tagSENT_CONTENT	sequences\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	task\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_END	text_classification\tagtask	first\tagSENT_CONTENT	computes\tagSENT_CONTENT	an\tagSENT_CONTENT	affinity\tagSENT_CONTENT	matrix\tagSENT_CONTENT	A\tagSENT_CONTENT	=\tagSENT_CONTENT	XY\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	integrate\tagSENT_CONTENT	the\tagSENT_CONTENT	conditioning\tagSENT_CONTENT	information\tagSENT_CONTENT	into\tagSENT_CONTENT	our\tagSENT_CONTENT	representations\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	sequence\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	separate\tagSENT_CONTENT	one\tagSENT_CONTENT	-\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	that\tagSENT_CONTENT	operate\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	ensure\tagSENT_CONTENT	no\tagSENT_CONTENT	information\tagSENT_CONTENT	is\tagSENT_CONTENT	lost\tagSENT_CONTENT	in\tagSENT_CONTENT	conditioning\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	differences\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	summaries\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	capture\tagSENT_CONTENT	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	signals\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	element\tagSENT_CONTENT	-\tagSENT_CONTENT	wise\tagSENT_CONTENT	products\tagSENT_CONTENT	between\tagSENT_CONTENT	originals\tagSENT_CONTENT	and\tagSENT_CONTENT	context\tagSENT_CONTENT	summaries\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	amplify\tagSENT_CONTENT	or\tagSENT_CONTENT	dampen\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	signals\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Question\tagSECTITLE_START	Answering\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	CoVe\tagSECTITLE_END	and\tagSENT_START	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	8\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	except\tagSENT_CONTENT	that\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	function\tagSENT_CONTENT	g\tagSENT_CONTENT	that\tagSENT_CONTENT	uses\tagSENT_CONTENT	a\tagSENT_CONTENT	tanh\tagSENT_CONTENT	activation\tagSENT_CONTENT	instead\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	activation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	case\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	sequences\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	document\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	document\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	sequences\tagSENT_CONTENT	are\tagSENT_CONTENT	then\tagSENT_CONTENT	fed\tagSENT_CONTENT	through\tagSENT_CONTENT	text_classification\tagtask	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	decoder\tagSENT_CONTENT	implemented\tagSENT_CONTENT	as\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	Dynamic\tagSENT_CONTENT	Coattention\tagSENT_CONTENT	Network\tagSENT_CONTENT	(\tagSENT_CONTENT	DCN\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Datasets\tagSECTITLE_END	The\tagSENT_START	training\tagSENT_CONTENT	set\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	that\tagSENT_CONTENT	briefly\tagSENT_CONTENT	describe\tagSENT_CONTENT	Flickr\tagSENT_CONTENT	captions\tagSENT_CONTENT	and\tagSENT_CONTENT	is\tagSENT_CONTENT	often\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	Multi30k\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	largest\tagSENT_CONTENT	MT\tagSENT_CONTENT	dataset\tagSENT_CONTENT	comes\tagSENT_CONTENT	from\tagSENT_CONTENT	text_classification\tagtask	shared\tagSENT_CONTENT	task\tagSENT_CONTENT	from\tagSENT_CONTENT	WMT\tagSENT_CONTENT	2017\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	MT\tagSENT_CONTENT	datasets\tagSENT_CONTENT	as\tagSENT_CONTENT	MT\tagSENT_CONTENT	-\tagSENT_CONTENT	Small\tagSENT_CONTENT	,\tagSENT_CONTENT	MT\tagSENT_CONTENT	-\tagSENT_CONTENT	Medium\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	MT\tagSENT_CONTENT	-\tagSENT_CONTENT	Large\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	we\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	context\tagSENT_CONTENT	vectors\tagSENT_CONTENT	from\tagSENT_CONTENT	encoders\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	each\tagSENT_CONTENT	in\tagSENT_CONTENT	turn\tagSENT_CONTENT	as\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	-\tagSENT_CONTENT	S\tagSENT_CONTENT	,\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	-\tagSENT_CONTENT	M\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	6\tagSENT_CONTENT	classes\tagSENT_CONTENT	5k\tagSENT_CONTENT	TREC-50\tagSENT_CONTENT	Question\tagSENT_CONTENT	Classification\tagSENT_CONTENT	50\tagSENT_CONTENT	classes\tagSENT_CONTENT	5k\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	text_classification\tagtask	2\tagSENT_CONTENT	classes\tagSENT_END	Dataset\tagSECTITLE_END	sentiment_analysis\tagtask	.\tagSENT_END	text_classification\tagtask	.\tagSENT_END	For\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	small\tagSENT_CONTENT	TREC\tagSENT_CONTENT	dataset\tagSENT_CONTENT	dataset\tagSENT_CONTENT	of\tagSENT_CONTENT	open\tagSENT_CONTENT	-\tagSENT_CONTENT	domain\tagSENT_CONTENT	,\tagSENT_CONTENT	fact\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	questions\tagSENT_CONTENT	divided\tagSENT_CONTENT	into\tagSENT_CONTENT	broad\tagSENT_CONTENT	semantic\tagSENT_CONTENT	categories\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	experiment\tagSENT_CONTENT	with\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	six\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	and\tagSENT_CONTENT	fifty\tagSENT_CONTENT	-\tagSENT_CONTENT	class\tagSENT_CONTENT	versions\tagSENT_CONTENT	of\tagSENT_CONTENT	TREC\tagdataset	,\tagSENT_CONTENT	which\tagSENT_CONTENT	which\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	TREC-6\tagSENT_CONTENT	and\tagSENT_CONTENT	TREC-50\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	SQuAD\tagSENT_START	examples\tagSENT_CONTENT	assume\tagSENT_CONTENT	that\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	answerable\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	is\tagSENT_CONTENT	contained\tagSENT_CONTENT	verbatim\tagSENT_CONTENT	somewhere\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	paragraph\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Machine\tagSECTITLE_START	Translation\tagSECTITLE_END	We\tagSENT_START	used\tagSENT_CONTENT	the\tagSENT_CONTENT	CommonCrawl-840B\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	English\tagSENT_CONTENT	word\tagSENT_CONTENT	vectors\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	were\tagSENT_CONTENT	completely\tagSENT_CONTENT	fixed\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	MT\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	had\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	pretrained\tagSENT_CONTENT	vectors\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Classification\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Question\tagSECTITLE_CONTENT	Answering\tagSECTITLE_END	For\tagSENT_START	text_classification\tagtask	and\tagSENT_CONTENT	question\tagSENT_CONTENT	answering\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	explore\tagSENT_CONTENT	how\tagSENT_CONTENT	varying\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	representations\tagSENT_CONTENT	affects\tagSENT_CONTENT	final\tagSENT_CONTENT	performance\tagSENT_CONTENT	.\tagSENT_END	Accuracy\tagmetric	is\tagSENT_CONTENT	reported\tagSENT_CONTENT	for\tagSENT_CONTENT	classification\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	F1\tagSENT_CONTENT	is\tagSENT_CONTENT	reported\tagSENT_CONTENT	for\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	text_classification\tagtask	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	is\tagSENT_CONTENT	complementary\tagSENT_CONTENT	to\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	information\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	information\tagSENT_CONTENT	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	character\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	shows\tagSENT_START	the\tagSENT_CONTENT	final\tagSENT_CONTENT	test\tagSENT_CONTENT	accuracies\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	which\tagSENT_CONTENT	achieved\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	validation\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	its\tagSENT_CONTENT	task\tagSENT_CONTENT	using\tagSENT_CONTENT	GloVe\tagSENT_CONTENT	,\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	character\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	Final\tagSENT_START	test\tagSENT_CONTENT	performances\tagSENT_CONTENT	on\tagSENT_CONTENT	SST-5\tagdataset	and\tagSENT_CONTENT	SNLI\tagSENT_CONTENT	reached\tagSENT_CONTENT	anew\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	EM\tagSECTITLE_CONTENT	F1\tagSECTITLE_END	shows\tagSENT_START	that\tagSENT_CONTENT	these\tagSENT_CONTENT	differences\tagSENT_CONTENT	make\tagSENT_CONTENT	CoVe\tagSENT_CONTENT	more\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	transfer\tagSENT_CONTENT	learning\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	
64f0dab74295e5eb139c160ed79ff262558a	title\tagSECTITLE_END	Effective\tagSENT_START	Self\tagSENT_CONTENT	-\tagSENT_CONTENT	Training\tagSENT_CONTENT	for\tagSENT_CONTENT	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	Examples\tagSENT_START	of\tagSENT_CONTENT	this\tagSENT_CONTENT	include\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	constituency_parsing\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Previous\tagSECTITLE_START	work\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	not\tagSENT_CONTENT	surprising\tagSENT_CONTENT	that\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	normally\tagSENT_CONTENT	effective\tagSENT_CONTENT	:\tagSENT_CONTENT	Charniak\tagSENT_CONTENT	(\tagSENT_CONTENT	1997\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	report\tagSENT_CONTENT	either\tagSENT_CONTENT	minor\tagSENT_CONTENT	improvements\tagSENT_CONTENT	or\tagSENT_CONTENT	significant\tagSENT_CONTENT	damage\tagSENT_CONTENT	from\tagSENT_CONTENT	using\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	constituency_parsing\tagtask	is\tagSENT_CONTENT	another\tagSENT_CONTENT	way\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	models\tagSENT_CONTENT	from\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	data\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Unlike\tagSENT_START	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	constituency_parsing\tagtask	requires\tagSENT_CONTENT	multiple\tagSENT_CONTENT	learners\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	different\tagSENT_CONTENT	"\tagSENT_CONTENT	view\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	investigated\tagSENT_CONTENT	using\tagSENT_CONTENT	constituency_parsing\tagtask	for\tagSENT_CONTENT	parsing\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	studies\tagSENT_CONTENT	suggest\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	most\tagSENT_CONTENT	effective\tagSENT_CONTENT	when\tagSENT_CONTENT	small\tagSENT_CONTENT	amounts\tagSENT_CONTENT	of\tagSENT_CONTENT	labelled\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	constituency_parsing\tagtask	for\tagSENT_CONTENT	constituency_parsing\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	helpful\tagSENT_CONTENT	for\tagSENT_CONTENT	parser\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	constituency_parsing\tagtask	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	phases\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	first\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	stage\tagSECTITLE_CONTENT	50-best\tagSECTITLE_CONTENT	parser\tagSECTITLE_END	The\tagSENT_START	parser\tagSENT_CONTENT	uses\tagSENT_CONTENT	five\tagSENT_CONTENT	probability\tagSENT_CONTENT	distributions\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	each\tagSENT_CONTENT	for\tagSENT_CONTENT	heads\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	parts\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	,\tagSENT_CONTENT	constituency_parsing\tagtask	,\tagSENT_CONTENT	left\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	head\tagSENT_CONTENT	constituents\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	-\tagSENT_CONTENT	ofhead\tagSENT_CONTENT	constituents\tagSENT_CONTENT	.\tagSENT_END	The\tagSECTITLE_START	MaxEnt\tagSECTITLE_CONTENT	Reranker\tagSECTITLE_END	the\tagSENT_START	left\tagSENT_CONTENT	and\tagSENT_CONTENT	right\tagSENT_CONTENT	edges\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	There\tagSENT_START	are\tagSENT_CONTENT	147,456\tagSENT_CONTENT	such\tagSENT_CONTENT	features\tagSENT_CONTENT	involving\tagSENT_CONTENT	constituency_parsing\tagtask	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	and\tagSENT_CONTENT	454,101\tagSENT_CONTENT	features\tagSENT_CONTENT	involving\tagSENT_CONTENT	parts\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	and\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Corpora\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	perform\tagSENT_CONTENT	some\tagSENT_CONTENT	basic\tagSENT_CONTENT	cleanups\tagSENT_CONTENT	on\tagSENT_CONTENT	NANC\tagSENT_CONTENT	to\tagSENT_CONTENT	ease\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	The\tagSENT_START	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	combined\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	NANC\tagSENT_CONTENT	data\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	way\tagSENT_CONTENT	:\tagSENT_CONTENT	The\tagSENT_CONTENT	count\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	the\tagSENT_CONTENT	(\tagSENT_CONTENT	optionally\tagSENT_CONTENT	weighted\tagSENT_CONTENT	)\tagSENT_CONTENT	sum\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	counts\tagSENT_CONTENT	of\tagSENT_CONTENT	that\tagSENT_CONTENT	event\tagSENT_CONTENT	in\tagSENT_CONTENT	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	and\tagSENT_CONTENT	NANC\tagSENT_CONTENT	.\tagSENT_END	show\tagSENT_START	that\tagSENT_CONTENT	constituency_parsing\tagtask	is\tagSENT_CONTENT	more\tagSENT_CONTENT	effective\tagSENT_CONTENT	than\tagSENT_CONTENT	creating\tagSENT_CONTENT	multiple\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	calculating\tagSENT_CONTENT	weights\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	model\tagSENT_CONTENT	interpolation\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Indeed\tagSENT_START	,\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	case\tagSENT_CONTENT	for\tagSENT_CONTENT	constituency_parsing\tagtask	(\tagSENT_CONTENT	figure\tagSENT_CONTENT	not\tagSENT_CONTENT	shown\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	reranking\tagSENT_CONTENT	parser\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Global\tagSECTITLE_START	Changes\tagSECTITLE_END	Sentence\tagSECTITLE_START	-\tagSECTITLE_CONTENT	level\tagSECTITLE_CONTENT	Analysis\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	fair\tagSENT_CONTENT	to\tagSENT_CONTENT	say\tagSENT_CONTENT	that\tagSENT_CONTENT	neither\tagSENT_CONTENT	we\tagSENT_CONTENT	,\tagSENT_CONTENT	nor\tagSENT_CONTENT	anyone\tagSENT_CONTENT	we\tagSENT_CONTENT	talked\tagSENT_CONTENT	to\tagSENT_CONTENT	,\tagSENT_CONTENT	thought\tagSENT_CONTENT	constituency_parsing\tagtask	would\tagSENT_CONTENT	be\tagSENT_CONTENT	improved\tagSENT_CONTENT	.\tagSENT_END	One\tagSENT_START	thing\tagSENT_CONTENT	we\tagSENT_CONTENT	know\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	always\tagSENT_CONTENT	improves\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency_parsing\tagtask	when\tagSENT_CONTENT	used\tagSENT_CONTENT	as\tagSENT_CONTENT	a\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Second\tagSENT_START	,\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	many\tagSENT_CONTENT	other\tagSENT_CONTENT	ways\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	trained\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	.\tagSENT_END	restricting\tagSENT_START	constituency_parsing\tagtask	to\tagSENT_CONTENT	more\tagSENT_CONTENT	accurately\tagSENT_CONTENT	parsed\tagSENT_CONTENT	sentences\tagSENT_CONTENT	as\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	(\tagSENT_CONTENT	sentence\tagSENT_CONTENT	selection\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	trying\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	grammatical\tagSENT_CONTENT	generalizations\tagSENT_CONTENT	directly\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	simply\tagSENT_CONTENT	including\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	etc\tagSENT_CONTENT	.\tagSENT_END	Those\tagSENT_START	of\tagSENT_CONTENT	us\tagSENT_CONTENT	in\tagSENT_CONTENT	constituency_parsing\tagtask	have\tagSENT_CONTENT	learned\tagSENT_CONTENT	to\tagSENT_CONTENT	expect\tagSENT_CONTENT	significant\tagSENT_CONTENT	decreases\tagSENT_CONTENT	in\tagSENT_CONTENT	parsing\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	even\tagSENT_CONTENT	when\tagSENT_CONTENT	moving\tagSENT_CONTENT	the\tagSENT_CONTENT	short\tagSENT_CONTENT	distance\tagSENT_CONTENT	from\tagSENT_CONTENT	LA\tagSENT_CONTENT	Times\tagSENT_CONTENT	to\tagSENT_CONTENT	Wall\tagSENT_CONTENT	Street\tagSENT_CONTENT	Journal\tagSENT_CONTENT	.\tagSENT_END	
1808.09381	title\tagSECTITLE_END	Understanding\tagSENT_START	machine_translation\tagtask	at\tagSENT_CONTENT	Scale\tagSENT_END	abstract\tagSECTITLE_END	An\tagSENT_START	effective\tagSENT_CONTENT	method\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	machine_translation\tagtask	with\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	augment\tagSENT_CONTENT	the\tagSENT_CONTENT	parallel\tagSENT_CONTENT	training\tagSENT_CONTENT	corpus\tagSENT_CONTENT	with\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	translations\tagSENT_CONTENT	of\tagSENT_CONTENT	target\tagSENT_CONTENT	language\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	machine_translation\tagtask	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	statistics\tagSENT_CONTENT	of\tagSENT_CONTENT	large\tagSENT_CONTENT	parallel\tagSENT_CONTENT	corpora\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	datasets\tagSENT_CONTENT	of\tagSENT_CONTENT	paired\tagSENT_CONTENT	sentences\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	source\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	language\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	NMT\tagSENT_CONTENT	;\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	extensive\tagSENT_CONTENT	work\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	fusion\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	translation\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	dual\tagSENT_CONTENT	learning\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	BT\tagSENT_CONTENT	)\tagSENT_CONTENT	which\tagSENT_CONTENT	operates\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	setup\tagSENT_CONTENT	where\tagSENT_CONTENT	both\tagSENT_CONTENT	bilingual\tagSENT_CONTENT	and\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	data\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	target\tagSENT_CONTENT	language\tagSENT_CONTENT	are\tagSENT_CONTENT	available\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	machine_translation\tagtask	for\tagSENT_CONTENT	neural\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	at\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	scale\tagSENT_CONTENT	by\tagSENT_CONTENT	adding\tagSENT_CONTENT	hundreds\tagSENT_CONTENT	of\tagSENT_CONTENT	millions\tagSENT_CONTENT	of\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	translated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	bitext\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	machine_translation\tagtask	describes\tagSENT_CONTENT	prior\tagSENT_CONTENT	work\tagSENT_CONTENT	in\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	with\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	semisupervised\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	machine\tagSECTITLE_CONTENT	translation\tagSECTITLE_END	We\tagSENT_START	build\tagSENT_CONTENT	upon\tagSENT_CONTENT	recent\tagSENT_CONTENT	work\tagSENT_CONTENT	on\tagSENT_CONTENT	machine_translation\tagtask	which\tagSENT_CONTENT	is\tagSENT_CONTENT	typically\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	an\tagSENT_CONTENT	encoder\tagSENT_CONTENT	/\tagSENT_CONTENT	decoder\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	Attention\tagSENT_START	has\tagSENT_CONTENT	been\tagSENT_CONTENT	refined\tagSENT_CONTENT	with\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	hop\tagSENT_CONTENT	attention\tagSENT_CONTENT	,\tagSENT_CONTENT	self\tagSENT_CONTENT	-\tagSENT_CONTENT	attention\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	.\tagSENT_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	NMT\tagSECTITLE_END	Monolingual\tagSENT_START	target\tagSENT_CONTENT	data\tagSENT_CONTENT	has\tagSENT_CONTENT	been\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	fluency\tagSENT_CONTENT	of\tagSENT_CONTENT	machine_translation\tagtask	since\tagSENT_CONTENT	the\tagSENT_CONTENT	early\tagSENT_CONTENT	IBM\tagSENT_CONTENT	models\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	machine_translation\tagtask	(\tagSENT_CONTENT	BT\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	alternative\tagSENT_CONTENT	to\tagSENT_CONTENT	leverage\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	;\tagSENT_CONTENT	;\tagSENT_CONTENT	show\tagSENT_CONTENT	how\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	text\tagSENT_CONTENT	from\tagSENT_CONTENT	both\tagSENT_CONTENT	languages\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	leveraged\tagSENT_CONTENT	by\tagSENT_CONTENT	extending\tagSENT_CONTENT	machine_translation\tagtask	to\tagSENT_CONTENT	dual\tagSENT_CONTENT	learning\tagSENT_CONTENT	:\tagSENT_CONTENT	when\tagSENT_CONTENT	training\tagSENT_CONTENT	both\tagSENT_CONTENT	source\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	target\tagSENT_CONTENT	and\tagSENT_CONTENT	target\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	source\tagSENT_CONTENT	models\tagSENT_CONTENT	jointly\tagSENT_CONTENT	,\tagSENT_CONTENT	one\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	translation\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	directions\tagSENT_CONTENT	and\tagSENT_CONTENT	perform\tagSENT_CONTENT	multiple\tagSENT_CONTENT	rounds\tagSENT_CONTENT	of\tagSENT_CONTENT	BT\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	generative\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	GANs\tagSENT_CONTENT	)\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	successfully\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	end\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	learn\tagSENT_CONTENT	distributions\tagSENT_CONTENT	over\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Generating\tagSECTITLE_START	synthetic\tagSECTITLE_CONTENT	sources\tagSECTITLE_END	machine_translation\tagtask	typically\tagSENT_CONTENT	uses\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	just\tagSENT_CONTENT	greedy\tagSENT_CONTENT	search\tagSENT_CONTENT	(\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	MAP\tagSENT_CONTENT	prediction\tagSENT_CONTENT	can\tagSENT_CONTENT	lead\tagSENT_CONTENT	to\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	Ott\tagSENT_CONTENT	et\tagSENT_CONTENT	al\tagSENT_CONTENT	.\tagSENT_CONTENT	,\tagSENT_CONTENT	2018a\tagSENT_CONTENT	)\tagSENT_CONTENT	since\tagSENT_CONTENT	it\tagSENT_CONTENT	always\tagSENT_CONTENT	favors\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	likely\tagSENT_CONTENT	alternative\tagSENT_CONTENT	in\tagSENT_CONTENT	case\tagSENT_CONTENT	of\tagSENT_CONTENT	ambiguity\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	noising\tagSENT_CONTENT	to\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	outputs\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	transform\tagSENT_CONTENT	source\tagSENT_CONTENT	sentences\tagSENT_CONTENT	with\tagSENT_CONTENT	three\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	noise\tagSENT_CONTENT	:\tagSENT_CONTENT	deleting\tagSENT_CONTENT	words\tagSENT_CONTENT	with\tagSENT_CONTENT	probability\tagSENT_CONTENT	0.1\tagSENT_CONTENT	,\tagSENT_CONTENT	replacing\tagSENT_CONTENT	words\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	filler\tagSENT_CONTENT	token\tagSENT_CONTENT	with\tagSENT_CONTENT	probability\tagSENT_CONTENT	0.1\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	swapping\tagSENT_CONTENT	words\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	implemented\tagSENT_CONTENT	as\tagSENT_CONTENT	machine_translation\tagtask	over\tagSENT_CONTENT	the\tagSENT_CONTENT	tokens\tagSENT_CONTENT	,\tagSENT_CONTENT	drawn\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	uniform\tagSENT_CONTENT	distribution\tagSENT_CONTENT	but\tagSENT_CONTENT	restricted\tagSENT_CONTENT	to\tagSENT_CONTENT	swapping\tagSENT_CONTENT	words\tagSENT_CONTENT	no\tagSENT_CONTENT	further\tagSENT_CONTENT	than\tagSENT_CONTENT	three\tagSENT_CONTENT	positions\tagSENT_CONTENT	apart\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	setup\tagSECTITLE_CONTENT	4.1\tagSECTITLE_CONTENT	Datasets\tagSECTITLE_END	For\tagSENT_START	machine_translation\tagtask	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	German\tagSENT_CONTENT	monolingual\tagSENT_CONTENT	newscrawl\tagSENT_CONTENT	data\tagSENT_CONTENT	distributed\tagSENT_CONTENT	with\tagSENT_CONTENT	WMT'18\tagSENT_CONTENT	comprising\tagSENT_CONTENT	226\tagSENT_CONTENT	M\tagSENT_CONTENT	sentences\tagSENT_CONTENT	after\tagSENT_CONTENT	removing\tagSENT_CONTENT	duplicates\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	and\tagSECTITLE_CONTENT	hyperparameters\tagSECTITLE_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	hyper\tagSENT_CONTENT	-\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	all\tagSENT_CONTENT	experiments\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	size\tagSENT_CONTENT	1024\tagSENT_CONTENT	,\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	layers\tagSENT_CONTENT	with\tagSENT_CONTENT	machine_translation\tagtask	4096\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	We\tagSENT_START	also\tagSENT_CONTENT	compare\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	bitext\tagSENT_CONTENT	to\tagSENT_CONTENT	genuine\tagSENT_CONTENT	parallel\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	examine\tagSENT_CONTENT	domain\tagSENT_CONTENT	effects\tagSENT_CONTENT	arising\tagSENT_CONTENT	in\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	§\tagSENT_CONTENT	5.4\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Synthetic\tagSECTITLE_START	data\tagSECTITLE_CONTENT	generation\tagSECTITLE_CONTENT	methods\tagSECTITLE_END	We\tagSENT_START	first\tagSENT_CONTENT	investigate\tagSENT_CONTENT	different\tagSENT_CONTENT	methods\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	machine_translation\tagtask	given\tagSENT_CONTENT	a\tagSENT_CONTENT	backtranslation\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	model\tagSENT_CONTENT	trained\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	reverse\tagSENT_CONTENT	language\tagSENT_CONTENT	direction\tagSENT_CONTENT	(\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	machine_translation\tagtask	,\tagSENT_CONTENT	this\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	enough\tagSENT_CONTENT	updates\tagSENT_CONTENT	to\tagSENT_CONTENT	reach\tagSENT_CONTENT	convergence\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagSENT_CONTENT	of\tagSENT_CONTENT	held\tagSENT_CONTENT	-\tagSENT_CONTENT	out\tagSENT_CONTENT	loss\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_START	of\tagSECTITLE_CONTENT	generation\tagSECTITLE_CONTENT	methods\tagSECTITLE_END	Beam\tagSENT_START	search\tagSENT_CONTENT	focuses\tagSENT_CONTENT	on\tagSENT_CONTENT	very\tagSENT_CONTENT	likely\tagSENT_CONTENT	outputs\tagSENT_CONTENT	which\tagSENT_CONTENT	reduces\tagSENT_CONTENT	the\tagSENT_CONTENT	diversity\tagSENT_CONTENT	and\tagSENT_CONTENT	richness\tagSENT_CONTENT	of\tagSENT_CONTENT	machine_translation\tagtask	.\tagSENT_END	On\tagSENT_START	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	450\tagSENT_CONTENT	K\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	apply\tagSENT_CONTENT	machine_translation\tagtask	using\tagSENT_CONTENT	beam\tagSENT_CONTENT	,\tagSENT_CONTENT	sampling\tagSENT_CONTENT	and\tagSENT_CONTENT	top10\tagSENT_CONTENT	generation\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	lack\tagSENT_CONTENT	of\tagSENT_CONTENT	variability\tagSENT_CONTENT	probably\tagSENT_CONTENT	explains\tagSENT_CONTENT	in\tagSENT_CONTENT	part\tagSENT_CONTENT	why\tagSENT_CONTENT	machine_translation\tagtask	from\tagSENT_CONTENT	pure\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	weaker\tagSENT_CONTENT	training\tagSENT_CONTENT	signal\tagSENT_CONTENT	than\tagSENT_CONTENT	alternatives\tagSENT_CONTENT	.\tagSENT_END	Closer\tagSENT_START	inspection\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	sources\tagSENT_CONTENT	(\tagSENT_CONTENT	Table\tagmetric	3\tagSENT_CONTENT	)\tagSENT_CONTENT	reveals\tagSENT_CONTENT	that\tagSENT_CONTENT	sampled\tagSENT_CONTENT	and\tagSENT_CONTENT	noised\tagSENT_END	Low\tagSECTITLE_START	resource\tagSECTITLE_CONTENT	vs.\tagSECTITLE_CONTENT	high\tagSECTITLE_CONTENT	resource\tagSECTITLE_CONTENT	setup\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	in\tagSENT_CONTENT	resource\tagSENT_CONTENT	poor\tagSENT_CONTENT	settings\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	of\tagSENT_CONTENT	much\tagSENT_CONTENT	lower\tagSENT_CONTENT	quality\tagSENT_CONTENT	.\tagSENT_END	:\tagmetric	BLEU\tagmetric	when\tagSENT_CONTENT	adding\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	data\tagSENT_CONTENT	from\tagSENT_CONTENT	beam\tagSENT_CONTENT	and\tagSENT_CONTENT	sampling\tagSENT_CONTENT	to\tagSENT_CONTENT	bitext\tagSENT_CONTENT	systems\tagSENT_CONTENT	with\tagSENT_CONTENT	80\tagSENT_CONTENT	K\tagSENT_CONTENT	,\tagSENT_CONTENT	640\tagSENT_CONTENT	K\tagSENT_CONTENT	and\tagSENT_CONTENT	5\tagSENT_CONTENT	M\tagSENT_CONTENT	sentence\tagSENT_CONTENT	pairs\tagSENT_CONTENT	.\tagSENT_END	Domain\tagSECTITLE_START	of\tagSECTITLE_CONTENT	synthetic\tagSECTITLE_CONTENT	data\tagSECTITLE_END	To\tagSENT_START	answer\tagSENT_CONTENT	these\tagSENT_CONTENT	questions\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	subsample\tagSENT_CONTENT	640\tagSENT_CONTENT	K\tagSENT_CONTENT	sentence\tagSENT_CONTENT	-\tagSENT_CONTENT	pairs\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	bitext\tagSENT_CONTENT	and\tagSENT_CONTENT	train\tagSENT_CONTENT	machine_translation\tagtask	on\tagSENT_CONTENT	this\tagSENT_CONTENT	set\tagSENT_CONTENT	.\tagSENT_END	machine_translation\tagtask	is\tagSENT_CONTENT	generated\tagSENT_CONTENT	via\tagSENT_CONTENT	sampling\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	strikingly\tagSENT_CONTENT	,\tagSENT_CONTENT	BT\tagSENT_CONTENT	-\tagSENT_CONTENT	news\tagSENT_CONTENT	performs\tagSENT_CONTENT	almost\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	bitext\tagSENT_CONTENT	on\tagSENT_CONTENT	newstest2012\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	improves\tagSENT_CONTENT	machine_translation\tagtask	(\tagSENT_CONTENT	640\tagSENT_CONTENT	K\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	2.6\tagSENT_CONTENT	BLEU\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	absence\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	parallel\tagSENT_CONTENT	corpus\tagSENT_CONTENT	for\tagSENT_CONTENT	news\tagSENT_CONTENT	,\tagSENT_CONTENT	machine_translation\tagtask	therefore\tagSENT_CONTENT	offers\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	,\tagSENT_CONTENT	yet\tagSENT_CONTENT	very\tagSENT_CONTENT	effective\tagSENT_CONTENT	domain\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	technique\tagSENT_CONTENT	.\tagSENT_END	640\tagSECTITLE_START	K\tagSECTITLE_END	1.28\tagSECTITLE_START	M\tagSECTITLE_END	Upsampling\tagSECTITLE_START	the\tagSECTITLE_CONTENT	bitext\tagSECTITLE_END	We\tagSENT_START	found\tagSENT_CONTENT	it\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	to\tagSENT_CONTENT	adjust\tagSENT_CONTENT	machine_translation\tagtask	of\tagSENT_CONTENT	bitext\tagSENT_CONTENT	to\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	data\tagSENT_CONTENT	observed\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	.\tagSENT_END	Large\tagSECTITLE_START	scale\tagSECTITLE_CONTENT	results\tagSECTITLE_END	Submission\tagSECTITLE_START	to\tagSECTITLE_CONTENT	WMT'18\tagSECTITLE_END	machine_translation\tagtask	describes\tagSENT_CONTENT	our\tagSENT_CONTENT	entry\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	WMT'18\tagSENT_CONTENT	English\tagSENT_CONTENT	-\tagSENT_CONTENT	German\tagSENT_CONTENT	news\tagSENT_CONTENT	translation\tagSENT_CONTENT	task\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	ranked\tagSENT_CONTENT	#\tagSENT_CONTENT	1\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	human\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	future\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	would\tagSENT_CONTENT	like\tagSENT_CONTENT	to\tagSENT_CONTENT	investigate\tagSENT_CONTENT	an\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	to\tagSENT_CONTENT	-\tagSENT_CONTENT	end\tagSENT_CONTENT	approach\tagSENT_CONTENT	where\tagSENT_CONTENT	machine_translation\tagtask	is\tagSENT_CONTENT	optimized\tagSENT_CONTENT	to\tagSENT_CONTENT	output\tagSENT_CONTENT	synthetic\tagSENT_CONTENT	sources\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	most\tagSENT_CONTENT	helpful\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	forward\tagSENT_CONTENT	model\tagSENT_CONTENT	.\tagSENT_END	
N16-1027	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	analyze\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	several\tagSENT_CONTENT	neural\tagSENT_CONTENT	models\tagSENT_CONTENT	and\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	while\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	architectures\tagSENT_CONTENT	can\tagSENT_CONTENT	compete\tagSENT_CONTENT	with\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	complete\tagSENT_CONTENT	sentence\tagSENT_CONTENT	are\tagSENT_CONTENT	necessary\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	long\tagSENT_CONTENT	range\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	information\tagSENT_CONTENT	encoded\tagSENT_CONTENT	in\tagSENT_CONTENT	supertags\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	For\tagSENT_START	this\tagSENT_CONTENT	reason\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tagging\tagSENT_CONTENT	and\tagSENT_CONTENT	ccg_supertagging\tagtask	have\tagSENT_CONTENT	drawn\tagSENT_CONTENT	significant\tagSENT_CONTENT	attention\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	community\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	also\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	a\tagSENT_CONTENT	baseline\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	NN\tagSENT_CONTENT	)\tagSENT_CONTENT	architecture\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	previous\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	NN\tagSENT_CONTENT	baselines\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	slightly\tagSENT_CONTENT	fewer\tagSENT_CONTENT	features\tagSENT_CONTENT	,\tagSENT_CONTENT	achieving\tagSENT_CONTENT	better\tagmetric	accuracy\tagmetric	than\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	model\tagSENT_CONTENT	from\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Recently\tagSENT_START	,\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	high\tagmetric	accuracies\tagmetric	in\tagSENT_CONTENT	a\tagSENT_CONTENT	simpler\tagSENT_CONTENT	sequence\tagSENT_CONTENT	labeling\tagSENT_CONTENT	task\tagSENT_CONTENT	:\tagSENT_CONTENT	partof\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tagging\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	treebank\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	small\tagSENT_CONTENT	improvements\tagSENT_CONTENT	over\tagSENT_CONTENT	local\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	main\tagSENT_CONTENT	contributions\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	introduction\tagSENT_CONTENT	of\tagSENT_CONTENT	anew\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	model\tagSENT_CONTENT	for\tagSENT_CONTENT	CCG\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	that\tagSENT_CONTENT	achieves\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	both\tagSENT_CONTENT	CCG\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	and\tagSENT_CONTENT	parsing\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	detailed\tagSENT_CONTENT	analysis\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	including\tagSENT_CONTENT	a\tagSENT_CONTENT	comparison\tagSENT_CONTENT	of\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	and\tagSENT_CONTENT	simpler\tagSENT_CONTENT	feed\tagSENT_CONTENT	forward\tagSENT_CONTENT	NN\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	and\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	suggests\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	added\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	may\tagSENT_CONTENT	not\tagSENT_CONTENT	be\tagSENT_CONTENT	necessary\tagSENT_CONTENT	for\tagSENT_CONTENT	POS\tagSENT_CONTENT	tagging\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	local\tagSENT_CONTENT	contexts\tagSENT_CONTENT	suffice\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	much\tagSENT_CONTENT	greater\tagSENT_CONTENT	extent\tagSENT_CONTENT	than\tagSENT_CONTENT	in\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	.\tagSENT_END	232\tagSECTITLE_END	Feed\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Forward\tagSECTITLE_END	For\tagSENT_START	ccg_supertagging\tagtask	and\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	supertagging\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	rectified\tagSENT_CONTENT	linear\tagSENT_CONTENT	units\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	ccg_supertagging\tagtask	,\tagSENT_CONTENT	when\tagSENT_CONTENT	tagging\tagSENT_CONTENT	word\tagSENT_CONTENT	w\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	consider\tagSENT_CONTENT	only\tagSENT_CONTENT	features\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	window\tagSENT_CONTENT	of\tagSENT_CONTENT	five\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	w\tagSENT_CONTENT	i\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	center\tagSENT_CONTENT	.\tagSENT_END	LSTM\tagSECTITLE_START	models\tagSECTITLE_END	The\tagSENT_START	unnormalized\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	using\tagSENT_CONTENT	ccg_supertagging\tagtask	To\tagSENT_START	explicitly\tagSENT_CONTENT	model\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	our\tagSENT_CONTENT	next\tagSENT_CONTENT	model\tagSENT_CONTENT	combines\tagSENT_CONTENT	two\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	language\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	LM\tagSENT_CONTENT	)\tagSENT_CONTENT	over\tagSENT_CONTENT	ccg_supertagging\tagtask	  \tagSENT_CONTENT	to\tagSENT_CONTENT	hi\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	combiner\tagSENT_CONTENT	for˜hfor˜\tagSENT_CONTENT	for˜h\tagSENT_CONTENT	i\tagSENT_CONTENT	(\tagSENT_CONTENT	Equation\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_END	Since\tagSENT_START	ccg_supertagging\tagtask	are\tagSENT_CONTENT	available\tagSENT_CONTENT	during\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	and\tagSENT_CONTENT	not\tagSENT_CONTENT	while\tagSENT_CONTENT	decoding\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	-\tagSENT_CONTENT	LM\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	might\tagSENT_CONTENT	not\tagSENT_CONTENT	recover\tagSENT_CONTENT	from\tagSENT_CONTENT	errors\tagSENT_CONTENT	caused\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	incorrectly\tagSENT_CONTENT	predicted\tagSENT_CONTENT	supertags\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	we\tagSENT_CONTENT	refer\tagSENT_CONTENT	to\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	ccg_supertagging\tagtask	as\tagSENT_CONTENT	g\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	(\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	each\tagSENT_CONTENT	output\tagSENT_CONTENT	token\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	some\tagSENT_CONTENT	probability\tagSENT_CONTENT	p\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	most\tagSENT_CONTENT	likely\tagSENT_CONTENT	predicted\tagSENT_CONTENT	supertag\tagSENT_CONTENT	(\tagSENT_CONTENT	arg\tagSENT_CONTENT	max\tagSENT_CONTENT	ti\tagSENT_CONTENT	P\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	i\tagSENT_CONTENT	|\tagSENT_CONTENT	hi\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	position\tagSENT_CONTENT	i−1\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	supertag\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	LM\tagSENT_CONTENT	in\tagSENT_CONTENT	position\tagSENT_CONTENT	i\tagSENT_CONTENT	and\tagSENT_CONTENT	use\tagSENT_CONTENT	ccg_supertagging\tagtask	with\tagSENT_CONTENT	probability\tagSENT_END	Additionally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	 \tagSENT_CONTENT	g\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	ss\tagSENT_CONTENT	-\tagSENT_CONTENT	train-1\tagSENT_CONTENT	ss\tagSENT_CONTENT	-\tagSENT_CONTENT	train-5\tagSENT_CONTENT	񮽙\tagSENT_CONTENT	1\tagSENT_CONTENT	use\tagSENT_CONTENT	their\tagSENT_CONTENT	probabilities\tagSENT_CONTENT	(\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	normalized\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	5-best\tagSENT_CONTENT	tags\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	scale\tagSENT_CONTENT	ccg_supertagging\tagtask	with\tagSENT_CONTENT	their\tagSENT_CONTENT	re\tagSENT_CONTENT	-\tagSENT_CONTENT	normalized\tagSENT_CONTENT	probability\tagSENT_CONTENT	during\tagSENT_CONTENT	look\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	see\tagSENT_CONTENT	that\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	scheduled\tagSENT_CONTENT	sampling\tagSENT_CONTENT	improves\tagSENT_CONTENT	the\tagSENT_CONTENT	perplexity\tagSENT_CONTENT	of\tagSENT_CONTENT	ccg_supertagging\tagtask	when\tagSENT_CONTENT	using\tagSENT_CONTENT	ccg_supertagging\tagtask	,\tagSENT_CONTENT	indicating\tagSENT_CONTENT	better\tagSENT_CONTENT	recovery\tagSENT_CONTENT	from\tagSENT_CONTENT	conditioning\tagSENT_CONTENT	on\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	For\tagSENT_START	both\tagSENT_CONTENT	ss\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	and\tagSENT_CONTENT	g\tagSENT_CONTENT	-\tagSENT_CONTENT	train\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	ccg_supertagging\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	train\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	maximize\tagSENT_CONTENT	the\tagSENT_CONTENT	log\tagSENT_CONTENT	-\tagSENT_CONTENT	likelihood\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	Architectures\tagSECTITLE_END	Our\tagSENT_START	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	models\tagSENT_CONTENT	use\tagSENT_CONTENT	2048\tagSENT_CONTENT	rectifier\tagSENT_CONTENT	units\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	50\tagSENT_CONTENT	and\tagSENT_CONTENT	128\tagSENT_CONTENT	rectifier\tagSENT_CONTENT	units\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	second\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	for\tagSENT_CONTENT	ccg_supertagging\tagtask	and\tagSENT_CONTENT	Supertagging\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	64\tagSENT_CONTENT	dim\tagSENT_CONTENT	.\tagSENT_END	Supertag\tagSECTITLE_START	Accuracy\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Decoding\tagSECTITLE_END	Data\tagSECTITLE_END	For\tagSENT_START	supertagging\tagSENT_CONTENT	,\tagSENT_CONTENT	experiments\tagSENT_CONTENT	were\tagSENT_CONTENT	run\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	splits\tagSENT_CONTENT	of\tagSENT_CONTENT	CCGbank\tagdataset	.\tagSENT_END	Accuracies\tagmetric	on\tagSENT_CONTENT	these\tagSENT_CONTENT	unseen\tagSENT_CONTENT	(\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	cat\tagSENT_CONTENT	)\tagSENT_CONTENT	pairs\tagSENT_CONTENT	are\tagSENT_CONTENT	presented\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	third\tagSENT_CONTENT	column\tagSENT_CONTENT	of\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Parsing\tagSECTITLE_END	These\tagSENT_START	results\tagSENT_CONTENT	were\tagSENT_CONTENT	attained\tagSENT_CONTENT	using\tagSENT_CONTENT	our\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	tags\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	Java\tagSENT_CONTENT	implementation\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	C&C\tagSENT_CONTENT	parser\tagSENT_CONTENT	(\tagSENT_CONTENT	Clark\tagSENT_CONTENT	and\tagSENT_CONTENT	Curran\tagmetric	,\tagSENT_CONTENT	2007\tagSENT_CONTENT	)\tagSENT_CONTENT	6\tagSENT_CONTENT	.\tagSENT_END	Error\tagSECTITLE_START	Analysis\tagSECTITLE_END	This\tagSENT_START	implies\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	long\tagSENT_CONTENT	range\tagSENT_CONTENT	information\tagSENT_CONTENT	necessary\tagSENT_CONTENT	for\tagSENT_CONTENT	choosing\tagSENT_CONTENT	ccg_supertagging\tagtask	.\tagSENT_END	Because\tagSENT_START	ccg_supertagging\tagtask	are\tagSENT_CONTENT	highly\tagSENT_CONTENT	structured\tagSENT_CONTENT	their\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	occurence\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	must\tagSENT_CONTENT	be\tagSENT_CONTENT	permitted\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	combinators\tagSENT_CONTENT	of\tagSENT_CONTENT	CCG\tagSENT_CONTENT	.\tagSENT_END	Conclusions\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
1603.01360	title\tagSECTITLE_END	Neural\tagSENT_START	Architectures\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	abstract\tagSECTITLE_END	Introduction\tagSECTITLE_END	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	challenging\tagSENT_CONTENT	learning\tagSENT_CONTENT	problem\tagSENT_CONTENT	.\tagSENT_END	LSTM\tagSECTITLE_START	-\tagSECTITLE_CONTENT	CRF\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	We\tagSENT_START	provide\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	and\tagSENT_CONTENT	CRFs\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	present\tagSENT_CONTENT	a\tagSENT_CONTENT	hybrid\tagSENT_CONTENT	tagging\tagSENT_CONTENT	architecture\tagSENT_CONTENT	.\tagSENT_END	LSTM\tagSECTITLE_END	CRF\tagSECTITLE_START	Tagging\tagSECTITLE_CONTENT	Models\tagSECTITLE_END	Avery\tagSENT_START	simple\tagSENT_CONTENT	-\tagSENT_CONTENT	but\tagSENT_CONTENT	surprisingly\tagSENT_CONTENT	effective\tagSENT_CONTENT	-\tagSENT_CONTENT	tagging\tagSENT_CONTENT	model\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	ht\tagSENT_CONTENT	's\tagSENT_CONTENT	as\tagSENT_CONTENT	features\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	named_entity_recognition\tagtask	for\tagSENT_CONTENT	each\tagSENT_CONTENT	output\tagSENT_CONTENT	y\tagSENT_CONTENT	t\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	A\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	matrix\tagSENT_CONTENT	of\tagSENT_CONTENT	transition\tagSENT_CONTENT	scores\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	A\tagSENT_CONTENT	i\tagSENT_CONTENT	,\tagSENT_CONTENT	j\tagSENT_CONTENT	represents\tagSENT_CONTENT	the\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	from\tagSENT_CONTENT	the\tagSENT_CONTENT	tag\tagSENT_CONTENT	i\tagSENT_CONTENT	to\tagSENT_CONTENT	tag\tagSENT_CONTENT	j.\tagSENT_CONTENT	y\tagSENT_END	Since\tagSENT_START	we\tagSENT_CONTENT	are\tagSENT_CONTENT	only\tagSENT_CONTENT	modeling\tagSENT_CONTENT	named_entity_recognition\tagtask	between\tagSENT_CONTENT	outputs\tagSENT_CONTENT	,\tagSENT_CONTENT	both\tagSENT_CONTENT	the\tagSENT_CONTENT	summation\tagSENT_CONTENT	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	1\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	a\tagSENT_CONTENT	posteriori\tagSENT_CONTENT	sequence\tagSENT_END	Parameterization\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Training\tagSECTITLE_END	Tagging\tagSECTITLE_START	Schemes\tagSECTITLE_END	The\tagSENT_START	task\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	assign\tagSENT_CONTENT	named_entity_recognition\tagtask	to\tagSENT_CONTENT	every\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	could\tagSENT_CONTENT	span\tagSENT_CONTENT	several\tagSENT_CONTENT	tokens\tagSENT_CONTENT	within\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_CONTENT	.\tagSENT_END	Sentences\tagSENT_START	are\tagSENT_CONTENT	usually\tagSENT_CONTENT	represented\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	IOB\tagSENT_CONTENT	format\tagSENT_CONTENT	(\tagSENT_CONTENT	Inside\tagSENT_CONTENT	,\tagSENT_CONTENT	Outside\tagSENT_CONTENT	,\tagSENT_CONTENT	Beginning\tagSENT_CONTENT	)\tagSENT_CONTENT	where\tagSENT_CONTENT	every\tagSENT_CONTENT	token\tagSENT_CONTENT	is\tagSENT_CONTENT	labeled\tagSENT_CONTENT	as\tagSENT_CONTENT	B\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	token\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	beginning\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	I\tagSENT_CONTENT	-\tagSENT_CONTENT	label\tagSENT_CONTENT	if\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	inside\tagSENT_CONTENT	named_entity_recognition\tagtask	but\tagSENT_CONTENT	not\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	token\tagSENT_CONTENT	within\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	or\tagSENT_CONTENT	O\tagSENT_CONTENT	otherwise\tagSENT_CONTENT	.\tagSENT_END	However\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	decided\tagSENT_CONTENT	to\tagSENT_CONTENT	use\tagSENT_CONTENT	the\tagSENT_CONTENT	IOBES\tagSENT_CONTENT	tagging\tagSENT_CONTENT	scheme\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	variant\tagSENT_CONTENT	of\tagSENT_CONTENT	IOB\tagSENT_CONTENT	commonly\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	encodes\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	singleton\tagSENT_CONTENT	entities\tagSENT_CONTENT	(\tagSENT_CONTENT	S\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	explicitly\tagSENT_CONTENT	marks\tagSENT_CONTENT	the\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	E\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Transition\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Based\tagSECTITLE_CONTENT	Chunking\tagSECTITLE_CONTENT	Model\tagSECTITLE_END	Chunking\tagSECTITLE_START	Algorithm\tagSECTITLE_END	The\tagSENT_START	transition\tagSENT_CONTENT	inventory\tagSENT_CONTENT	contains\tagSENT_CONTENT	the\tagSENT_CONTENT	following\tagSENT_CONTENT	transitions\tagSENT_CONTENT	:\tagSENT_CONTENT	named_entity_recognition\tagtask	moves\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	buffer\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	,\tagSENT_CONTENT	named_entity_recognition\tagtask	moves\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	buffer\tagSENT_CONTENT	directly\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	stack\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	REDUCE(y\tagSENT_CONTENT	)\tagSENT_CONTENT	transition\tagSENT_CONTENT	pops\tagSENT_CONTENT	all\tagSENT_CONTENT	items\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	stack\tagSENT_CONTENT	creating\tagSENT_CONTENT	a\tagSENT_CONTENT	"\tagSENT_CONTENT	chunk\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	labels\tagSENT_CONTENT	this\tagSENT_CONTENT	with\tagSENT_CONTENT	label\tagSENT_CONTENT	y\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	pushes\tagSENT_CONTENT	a\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	chunk\tagSENT_CONTENT	onto\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	stack\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	stack\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	embedding\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	of\tagSENT_CONTENT	these\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	take\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	these\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	state\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	define\tagSENT_CONTENT	named_entity_recognition\tagtask	over\tagSENT_CONTENT	the\tagSENT_CONTENT	possible\tagSENT_CONTENT	actions\tagSENT_CONTENT	that\tagSENT_CONTENT	can\tagSENT_CONTENT	betaken\tagSENT_CONTENT	at\tagSENT_CONTENT	each\tagSENT_CONTENT	time\tagSENT_CONTENT	step\tagSENT_CONTENT	.\tagSENT_END	Representing\tagSECTITLE_START	Labeled\tagSECTITLE_CONTENT	Chunks\tagSECTITLE_END	Input\tagSECTITLE_START	Word\tagSECTITLE_CONTENT	Embeddings\tagSECTITLE_END	Learning\tagSENT_START	named_entity_recognition\tagtask	for\tagSENT_CONTENT	word\tagSENT_CONTENT	types\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	limited\tagSENT_CONTENT	NER\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	difficult\tagSENT_CONTENT	problem\tagSENT_CONTENT	:\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	simply\tagSENT_CONTENT	too\tagSENT_CONTENT	many\tagSENT_CONTENT	parameters\tagSENT_CONTENT	to\tagSENT_CONTENT	reliably\tagSENT_CONTENT	estimate\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	to\tagSENT_CONTENT	prevent\tagSENT_CONTENT	the\tagSENT_CONTENT	models\tagSENT_CONTENT	from\tagSENT_CONTENT	depending\tagSENT_CONTENT	on\tagSENT_CONTENT	named_entity_recognition\tagtask	or\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	too\tagSENT_CONTENT	strongly\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	use\tagSENT_CONTENT	dropout\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	find\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	crucial\tagSENT_CONTENT	for\tagSENT_CONTENT	good\tagSENT_CONTENT	generalization\tagSENT_CONTENT	performance\tagSENT_CONTENT	(\tagSENT_CONTENT	4.3\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Character\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	models\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	words\tagSECTITLE_END	As\tagSENT_START	a\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	expect\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	bean\tagSENT_CONTENT	accurate\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	suffix\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	backward\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	named_entity_recognition\tagtask	of\tagSENT_CONTENT	its\tagSENT_CONTENT	prefix\tagSENT_CONTENT	.\tagSENT_END	Pretrained\tagSECTITLE_START	embeddings\tagSECTITLE_END	Dropout\tagSECTITLE_START	training\tagSECTITLE_END	Experiments\tagSECTITLE_END	Training\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	a\tagSENT_CONTENT	greedy\tagSENT_CONTENT	model\tagSENT_CONTENT	that\tagSENT_CONTENT	apply\tagSENT_CONTENT	locally\tagSENT_CONTENT	optimal\tagSENT_CONTENT	actions\tagSENT_CONTENT	until\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	processed\tagSENT_CONTENT	,\tagSENT_CONTENT	further\tagSENT_CONTENT	improvements\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	obtained\tagSENT_CONTENT	with\tagSENT_CONTENT	beam\tagSENT_CONTENT	search\tagSENT_CONTENT	(\tagSENT_CONTENT	Zhang\tagSENT_CONTENT	and\tagSENT_CONTENT	Clark\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	or\tagSENT_CONTENT	training\tagSENT_CONTENT	with\tagSENT_CONTENT	exploration\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	Data\tagSECTITLE_START	Sets\tagSECTITLE_END	We\tagSENT_START	test\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	different\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	To\tagSENT_START	demonstrate\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	ability\tagSENT_CONTENT	to\tagSENT_CONTENT	generalize\tagSENT_CONTENT	to\tagSENT_CONTENT	different\tagSENT_CONTENT	languages\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	contain\tagSENT_CONTENT	named_entity_recognition\tagtask	for\tagSENT_CONTENT	English\tagSENT_CONTENT	,\tagSENT_CONTENT	Spanish\tagSENT_CONTENT	,\tagSENT_CONTENT	German\tagSENT_CONTENT	and\tagSENT_CONTENT	Dutch\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	datasets\tagSENT_CONTENT	contain\tagSENT_CONTENT	four\tagSENT_CONTENT	different\tagSENT_CONTENT	types\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	:\tagSENT_CONTENT	locations\tagSENT_CONTENT	,\tagSENT_CONTENT	persons\tagSENT_CONTENT	,\tagSENT_CONTENT	organizations\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	miscellaneous\tagSENT_CONTENT	entities\tagSENT_CONTENT	that\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	belong\tagSENT_CONTENT	in\tagSENT_CONTENT	any\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	three\tagSENT_CONTENT	previous\tagSENT_CONTENT	categories\tagSENT_CONTENT	.\tagSENT_END	presents\tagSENT_START	our\tagSENT_CONTENT	comparisons\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	models\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	in\tagSENT_CONTENT	English\tagSENT_CONTENT	.\tagSENT_END	named_entity_recognition\tagtask	is\tagSENT_CONTENT	Dutch\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	can\tagSENT_CONTENT	perform\tagSENT_CONTENT	better\tagSENT_CONTENT	by\tagSENT_CONTENT	leveraging\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	from\tagSENT_CONTENT	other\tagSENT_CONTENT	NER\tagSENT_CONTENT	datasets\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	Network\tagSECTITLE_START	architectures\tagSECTITLE_END	We\tagSENT_START	explored\tagSENT_CONTENT	the\tagSENT_CONTENT	impact\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	CRF\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representations\tagSENT_CONTENT	,\tagSENT_CONTENT	pretraining\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	:\tagSENT_CONTENT	English\tagSENT_CONTENT	NER\tagSENT_CONTENT	results\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	using\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	present\tagSENT_START	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	bootstrapping\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	by\tagSENT_CONTENT	co\tagSENT_CONTENT	-\tagSENT_CONTENT	training\tagSENT_CONTENT	character\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	internal\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	token\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	(\tagSENT_CONTENT	context\tagSENT_CONTENT	)\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	use\tagSENT_START	Bayesian\tagSENT_CONTENT	nonparametrics\tagSENT_CONTENT	to\tagSENT_CONTENT	construct\tagSENT_CONTENT	a\tagSENT_CONTENT	database\tagSENT_CONTENT	of\tagSENT_CONTENT	named_entity_recognition\tagtask	in\tagSENT_CONTENT	an\tagSENT_CONTENT	almost\tagSENT_CONTENT	unsupervised\tagSENT_CONTENT	setting\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	
1703.04816	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	find\tagSENT_CONTENT	that\tagSENT_CONTENT	there\tagSENT_CONTENT	are\tagSENT_CONTENT	two\tagSENT_CONTENT	ingredients\tagSENT_CONTENT	necessary\tagSENT_CONTENT	for\tagSENT_CONTENT	building\tagSENT_CONTENT	a\tagSENT_CONTENT	high\tagSENT_CONTENT	-\tagSENT_CONTENT	performing\tagSENT_CONTENT	neural\tagSENT_CONTENT	QA\tagSENT_CONTENT	system\tagSENT_CONTENT	:\tagSENT_CONTENT	first\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	awareness\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	while\tagSENT_CONTENT	processing\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	second\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	composition\tagSENT_CONTENT	function\tagSENT_CONTENT	that\tagSENT_CONTENT	goes\tagSENT_CONTENT	beyond\tagSENT_CONTENT	simple\tagSENT_CONTENT	bag\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	words\tagSENT_CONTENT	modeling\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	question_answering\tagtask	is\tagSENT_CONTENT	an\tagSENT_CONTENT	important\tagSENT_CONTENT	end\tagSENT_CONTENT	-\tagSENT_CONTENT	user\tagSENT_CONTENT	task\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	intersection\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	processing\tagSENT_CONTENT	(\tagSENT_CONTENT	NLP\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	(\tagSENT_CONTENT	IR\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Most\tagSENT_START	such\tagSENT_CONTENT	systems\tagSENT_CONTENT	describe\tagSENT_CONTENT	several\tagSENT_CONTENT	innovations\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	different\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	architecture\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	special\tagSENT_CONTENT	focus\tagSENT_CONTENT	on\tagSENT_CONTENT	developing\tagSENT_CONTENT	powerful\tagSENT_CONTENT	interaction\tagSENT_CONTENT	layer\tagSENT_CONTENT	that\tagSENT_CONTENT	aims\tagSENT_CONTENT	at\tagSENT_CONTENT	modeling\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	by\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	interaction\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	gap\tagSENT_CONTENT	raises\tagSENT_CONTENT	question_answering\tagtask	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	current\tagSENT_CONTENT	systems\tagSENT_CONTENT	is\tagSENT_CONTENT	justified\tagSENT_CONTENT	solely\tagSENT_CONTENT	by\tagSENT_CONTENT	their\tagSENT_CONTENT	empirical\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	Although\tagSENT_CONTENT	it\tagSENT_CONTENT	seems\tagSENT_CONTENT	that\tagSENT_CONTENT	evidence\tagSENT_CONTENT	synthesis\tagSENT_CONTENT	of\tagSENT_CONTENT	multiple\tagSENT_CONTENT	sentences\tagSENT_CONTENT	is\tagSENT_CONTENT	necessary\tagSENT_CONTENT	to\tagSENT_CONTENT	fully\tagSENT_CONTENT	understand\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	answering\tagSENT_CONTENT	this\tagSENT_CONTENT	question\tagSENT_CONTENT	is\tagSENT_CONTENT	easily\tagSENT_CONTENT	possible\tagSENT_CONTENT	by\tagSENT_CONTENT	applying\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	context\tagSENT_CONTENT	/\tagSENT_CONTENT	type\tagSENT_CONTENT	matching\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	.\tagSENT_END	Crucially\tagSENT_START	,\tagSENT_CONTENT	both\tagSENT_CONTENT	models\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	make\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	complex\tagSENT_CONTENT	interaction\tagSENT_CONTENT	layer\tagSENT_CONTENT	but\tagSENT_CONTENT	model\tagSENT_CONTENT	interaction\tagSENT_CONTENT	between\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	only\tagSENT_CONTENT	through\tagSENT_CONTENT	computable\tagSENT_CONTENT	features\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	word\tagSENT_CONTENT	level\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	Bag\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Words\tagSECTITLE_CONTENT	Neural\tagSECTITLE_CONTENT	QA\tagSECTITLE_CONTENT	System\tagSECTITLE_END	We\tagSENT_START	begin\tagSENT_CONTENT	by\tagSENT_CONTENT	motivating\tagSENT_CONTENT	our\tagSENT_CONTENT	architectures\tagSENT_CONTENT	by\tagSENT_CONTENT	defining\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	context\tagSENT_CONTENT	/\tagSENT_CONTENT	type\tagSENT_CONTENT	matching\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	should\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	expected\tagSENT_CONTENT	answer\tagSENT_CONTENT	type\tagSENT_CONTENT	given\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	b\tagSENT_CONTENT	)\tagSENT_CONTENT	the\tagSENT_CONTENT	correct\tagSENT_CONTENT	answer\tagSENT_CONTENT	should\tagSENT_CONTENT	further\tagSENT_CONTENT	be\tagSENT_CONTENT	surrounded\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	context\tagSENT_CONTENT	that\tagSENT_CONTENT	fits\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	,\tagSENT_CONTENT	more\tagSENT_CONTENT	precisely\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	surrounded\tagSENT_CONTENT	by\tagSENT_CONTENT	many\tagSENT_CONTENT	question\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Embedding\tagSECTITLE_END	Typically\tagSENT_START	this\tagSENT_CONTENT	is\tagSENT_CONTENT	done\tagSENT_CONTENT	by\tagSENT_CONTENT	mapping\tagSENT_CONTENT	each\tagSENT_CONTENT	word\tagSENT_CONTENT	x\tagSENT_CONTENT	to\tagSENT_CONTENT	its\tagSENT_CONTENT	corresponding\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	x\tagSENT_CONTENT	w\tagSENT_CONTENT	(\tagSENT_CONTENT	lookup\tagSENT_CONTENT	-\tagSENT_CONTENT	embedding\tagSENT_CONTENT	)\tagSENT_CONTENT	using\tagSENT_CONTENT	an\tagSENT_CONTENT	embedding\tagSENT_CONTENT	matrix\tagSENT_CONTENT	E\tagmetric	,\tagSENT_END	Type\tagSECTITLE_START	Matching\tagSECTITLE_END	For\tagSENT_START	the\tagSENT_CONTENT	BoW\tagSENT_CONTENT	baseline\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	extract\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	that\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	lexical\tagSENT_CONTENT	answer\tagSENT_CONTENT	type\tagSENT_CONTENT	(\tagSENT_CONTENT	LAT\tagSENT_CONTENT	)\tagSENT_CONTENT	by\tagSENT_CONTENT	extracting\tagSENT_CONTENT	either\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	word(s\tagSENT_CONTENT	)\tagSENT_END	Because\tagSENT_START	the\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	context\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	give\tagSENT_CONTENT	important\tagSENT_CONTENT	clues\tagSENT_CONTENT	towards\tagSENT_CONTENT	the\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	an\tagSENT_CONTENT	answer\tagSENT_CONTENT	span\tagSENT_CONTENT	,\tagSENT_CONTENT	for\tagSENT_CONTENT	instance\tagSENT_CONTENT	,\tagSENT_CONTENT	through\tagSENT_CONTENT	nominal\tagSENT_CONTENT	modifiers\tagSENT_CONTENT	left\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	...\tagSENT_CONTENT	president\tagSENT_CONTENT	obama\tagSENT_CONTENT	...\tagSENT_END	Context\tagSECTITLE_START	Matching\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	account\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	surrounding\tagSENT_CONTENT	words\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	as\tagSENT_CONTENT	a\tagSENT_CONTENT	measure\tagSENT_CONTENT	for\tagSENT_CONTENT	question\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	span\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagSENT_CONTENT	context\tagSENT_CONTENT	match\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	two\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	question\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	motivated\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	one\tagSENT_CONTENT	hand\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	intuition\tagSENT_CONTENT	that\tagSENT_CONTENT	question\tagSENT_CONTENT	tokens\tagSENT_CONTENT	which\tagSENT_CONTENT	rarely\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	likely\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	important\tagSENT_CONTENT	for\tagSENT_CONTENT	answering\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	question\tagSENT_CONTENT	words\tagSENT_CONTENT	might\tagSENT_CONTENT	occur\tagSENT_CONTENT	as\tagSENT_CONTENT	morphological\tagSENT_CONTENT	variants\tagSENT_CONTENT	,\tagSENT_CONTENT	synonyms\tagSENT_CONTENT	or\tagSENT_CONTENT	related\tagSENT_CONTENT	words\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	derivation\tagSENT_CONTENT	that\tagSENT_CONTENT	connects\tagSENT_CONTENT	wiq\tagSENT_CONTENT	w\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	termfrequencies\tagSENT_CONTENT	(\tagSENT_CONTENT	a\tagSENT_CONTENT	prominent\tagSENT_CONTENT	information\tagSENT_CONTENT	retrieval\tagSENT_CONTENT	measure\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	provided\tagSENT_CONTENT	in\tagSENT_CONTENT	Appendix\tagSENT_CONTENT	A.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_END	Answer\tagSECTITLE_START	Span\tagSECTITLE_CONTENT	Scoring\tagSECTITLE_END	FastQA\tagSECTITLE_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	semantics\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	dramatically\tagSENT_CONTENT	reduced\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	BoW\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	expected\tagSENT_CONTENT	answer\tagSENT_CONTENT	-\tagSENT_CONTENT	type\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	scalar\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	question\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	account\tagSENT_CONTENT	for\tagSENT_CONTENT	these\tagSENT_CONTENT	shortcomings\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	another\tagSENT_CONTENT	baseline\tagSENT_CONTENT	which\tagSENT_CONTENT	relies\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	application\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	single\tagSENT_CONTENT	bi\tagSENT_CONTENT	-\tagSENT_CONTENT	directional\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	BiRNN\tagSENT_CONTENT	)\tagSENT_CONTENT	followed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	answer\tagSENT_CONTENT	layer\tagSENT_CONTENT	that\tagSENT_CONTENT	separates\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Encoding\tagSECTITLE_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	the\tagSENT_CONTENT	encoding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	analogous\tagSENT_CONTENT	to\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Because\tagSENT_START	we\tagSENT_CONTENT	want\tagSENT_CONTENT	the\tagSENT_CONTENT	encoder\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	aware\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	we\tagSENT_CONTENT	feed\tagSENT_CONTENT	the\tagSENT_CONTENT	binary\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	weighted\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	question\tagSENT_CONTENT	feature\tagSENT_CONTENT	of\tagSENT_CONTENT	§\tagSENT_CONTENT	2.3\tagSENT_CONTENT	in\tagSENT_CONTENT	addition\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	embedded\tagSENT_CONTENT	context\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	mentioned\tagSENT_CONTENT	before\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	utilize\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	encoder\tagSENT_CONTENT	parameters\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	context\tagSENT_CONTENT	,\tagSENT_CONTENT	except\tagSENT_CONTENT	the\tagSENT_CONTENT	projection\tagSENT_CONTENT	matrix\tagSENT_CONTENT	B\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	shared\tagSENT_CONTENT	.\tagSENT_END	Answer\tagSECTITLE_START	Layer\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	this\tagSENT_CONTENT	representation\tagSENT_CONTENT	is\tagSENT_CONTENT	context\tagSENT_CONTENT	-\tagSENT_CONTENT	independent\tagSENT_CONTENT	and\tagSENT_CONTENT	as\tagSENT_CONTENT	such\tagSENT_CONTENT	only\tagSENT_CONTENT	computed\tagSENT_CONTENT	once\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	no\tagSENT_CONTENT	additional\tagSENT_CONTENT	wordby\tagSENT_CONTENT	-\tagSENT_CONTENT	word\tagSENT_CONTENT	interaction\tagSENT_CONTENT	between\tagSENT_CONTENT	context\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	The\tagSENT_START	probability\tagSENT_CONTENT	distribution\tagSENT_CONTENT	p\tagSENT_CONTENT	s\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	start\tagSENT_CONTENT	location\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	2-layer\tagSENT_CONTENT	feedforward\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	rectified\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	(\tagSENT_CONTENT	ReLU\tagSENT_CONTENT	)\tagSENT_CONTENT	activated\tagSENT_CONTENT	,\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	s\tagSENT_CONTENT	j\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	:\tagSENT_CONTENT	 \tagSENT_END	The\tagSENT_START	overall\tagSENT_CONTENT	probability\tagSENT_CONTENT	p\tagSENT_CONTENT	of\tagSENT_CONTENT	predicting\tagSENT_CONTENT	question_answering\tagtask	(\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	p(s\tagSENT_CONTENT	,\tagSENT_CONTENT	e\tagSENT_CONTENT	)\tagSENT_END	Beam\tagSENT_START	-\tagSENT_CONTENT	search\tagSENT_CONTENT	During\tagSENT_CONTENT	prediction\tagSENT_CONTENT	time\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	compute\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	the\tagSENT_CONTENT	highest\tagSENT_CONTENT	probability\tagSENT_CONTENT	by\tagSENT_CONTENT	employing\tagSENT_CONTENT	beam\tagSENT_CONTENT	-\tagSENT_CONTENT	search\tagSENT_CONTENT	using\tagSENT_CONTENT	a\tagSENT_CONTENT	beam\tagSENT_CONTENT	-\tagSENT_CONTENT	size\tagSENT_CONTENT	of\tagSENT_CONTENT	k.\tagSENT_END	Comparison\tagSECTITLE_START	to\tagSECTITLE_CONTENT	Prior\tagSECTITLE_CONTENT	Architectures\tagSECTITLE_END	Our\tagSENT_START	proposed\tagSENT_CONTENT	embedder\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	2.1\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	very\tagSENT_CONTENT	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	question_answering\tagtask	used\tagSENT_CONTENT	for\tagSENT_CONTENT	example\tagSENT_CONTENT	in\tagSENT_CONTENT	;\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	further\tagSENT_CONTENT	introduce\tagSENT_CONTENT	beam\tagSENT_CONTENT	-\tagSENT_CONTENT	search\tagSENT_CONTENT	to\tagSENT_CONTENT	extract\tagSENT_CONTENT	question_answering\tagtask	with\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	2-layer\tagSENT_CONTENT	feed\tagSENT_CONTENT	-\tagSENT_CONTENT	forward\tagSENT_CONTENT	network\tagSENT_CONTENT	.\tagSENT_END	FastQA\tagSECTITLE_START	Extended\tagSECTITLE_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduce\tagSENT_CONTENT	question_answering\tagtask	to\tagSENT_CONTENT	enable\tagSENT_CONTENT	the\tagSENT_CONTENT	exchange\tagSENT_CONTENT	of\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	between\tagSENT_CONTENT	passages\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	(\tagSENT_CONTENT	intra\tagSENT_CONTENT	-\tagSENT_CONTENT	fusion\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	question\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	context\tagSENT_CONTENT	(\tagSENT_CONTENT	inter\tagSENT_CONTENT	-\tagSENT_CONTENT	fusion\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	Setup\tagSECTITLE_END	contains\tagSENT_START	100k\tagSENT_CONTENT	answerable\tagSENT_CONTENT	questions\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	total\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	SQuAD\tagSECTITLE_END	Performance\tagSENT_START	on\tagSENT_CONTENT	the\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	and\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	datasets\tagSENT_CONTENT	is\tagSENT_CONTENT	measured\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	exact\tagSENT_CONTENT	match\tagSENT_CONTENT	(\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	mean\tagSENT_CONTENT	,\tagSENT_CONTENT	per\tagSENT_CONTENT	answer\tagSENT_CONTENT	token\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	F1\tagSENT_CONTENT	measure\tagSENT_CONTENT	which\tagSENT_CONTENT	was\tagSENT_CONTENT	originally\tagSENT_CONTENT	proposed\tagSENT_CONTENT	by\tagSENT_CONTENT	to\tagSENT_CONTENT	also\tagSENT_CONTENT	account\tagSENT_CONTENT	for\tagSENT_CONTENT	partial\tagSENT_CONTENT	matches\tagSENT_CONTENT	.\tagSENT_END	Implementation\tagSECTITLE_START	Details\tagSECTITLE_END	This\tagSENT_START	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	upper\tagSENT_CONTENT	bound\tagSENT_CONTENT	of\tagSENT_CONTENT	about\tagSENT_CONTENT	95\tagSENT_CONTENT	%\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	and\tagSENT_CONTENT	87\tagSENT_CONTENT	%\tagSENT_CONTENT	on\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	binary\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	computed\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	words\tagSENT_CONTENT	as\tagSENT_CONTENT	they\tagSENT_CONTENT	appear\tagSENT_CONTENT	in\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Cutting\tagSENT_START	Context\tagSENT_CONTENT	Length\tagSENT_CONTENT	Because\tagSENT_CONTENT	NewsQA\tagdataset	contains\tagSENT_CONTENT	examples\tagSENT_CONTENT	with\tagSENT_CONTENT	very\tagSENT_CONTENT	large\tagSENT_CONTENT	contexts\tagSENT_CONTENT	(\tagSENT_CONTENT	up\tagSENT_CONTENT	to\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	1500\tagSENT_CONTENT	tokens\tagSENT_CONTENT	)\tagSENT_END	An\tagSENT_START	informed\tagSENT_CONTENT	encoder\tagSENT_CONTENT	,\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	hand\tagSENT_CONTENT	,\tagSENT_CONTENT	can\tagSENT_CONTENT	selectively\tagSENT_CONTENT	keep\tagSENT_CONTENT	track\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Comparing\tagSECTITLE_START	to\tagSECTITLE_CONTENT	State\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Art\tagSECTITLE_END	It\tagSENT_START	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	half\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	a\tagSENT_CONTENT	third\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	in\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	or\tagSENT_CONTENT	NewsQA\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	(\tagSENT_CONTENT	partially\tagSENT_CONTENT	)\tagSENT_CONTENT	answerable\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	very\tagSENT_CONTENT	simple\tagSENT_CONTENT	neural\tagSENT_CONTENT	BoW\tagSENT_CONTENT	baseline\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	is\tagSENT_CONTENT	very\tagSENT_CONTENT	competitive\tagSENT_CONTENT	to\tagSENT_CONTENT	previously\tagSENT_CONTENT	established\tagSENT_CONTENT	stateof\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	two\tagSENT_CONTENT	datasets\tagSENT_CONTENT	and\tagSENT_CONTENT	even\tagSENT_CONTENT	improves\tagSENT_CONTENT	those\tagSENT_CONTENT	for\tagSENT_CONTENT	NewsQA\tagdataset	.\tagSENT_END	Do\tagSECTITLE_START	we\tagSECTITLE_CONTENT	need\tagSECTITLE_CONTENT	additional\tagSECTITLE_CONTENT	interaction\tagSECTITLE_CONTENT	?\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	we\tagSENT_CONTENT	compare\tagSENT_CONTENT	FastQA\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	system\tagSENT_CONTENT	without\tagSENT_CONTENT	a\tagSENT_CONTENT	complex\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	byword\tagSENT_CONTENT	interaction\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	to\tagSENT_CONTENT	representative\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	have\tagSENT_CONTENT	an\tagSENT_CONTENT	interaction\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_END	We\tagSENT_START	studied\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	question\tagSENT_CONTENT	-\tagSENT_CONTENT	and\tagSENT_CONTENT	answer\tagSENT_CONTENT	length\tagSENT_CONTENT	as\tagSENT_CONTENT	well\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	for\tagSENT_CONTENT	these\tagSENT_CONTENT	two\tagSENT_CONTENT	sets\tagSENT_CONTENT	but\tagSENT_CONTENT	could\tagSENT_CONTENT	not\tagSENT_CONTENT	find\tagSENT_CONTENT	any\tagSENT_CONTENT	systematic\tagSENT_CONTENT	difference\tagSENT_CONTENT	.\tagSENT_END	Qualitative\tagSECTITLE_START	Analysis\tagSECTITLE_END	Other\tagSENT_START	error\tagSENT_CONTENT	types\tagSENT_CONTENT	are\tagSENT_CONTENT	mostly\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	annotation\tagSENT_CONTENT	preferences\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	answer\tagSENT_CONTENT	is\tagSENT_CONTENT	good\tagSENT_CONTENT	but\tagSENT_CONTENT	there\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	better\tagSENT_CONTENT	,\tagSENT_CONTENT	more\tagSENT_CONTENT	specific\tagSENT_CONTENT	one\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	ambiguities\tagSENT_CONTENT	within\tagSENT_CONTENT	question_answering\tagtask	or\tagSENT_CONTENT	context\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	New\tagSENT_START	datasets\tagSENT_CONTENT	were\tagSENT_CONTENT	constructed\tagSENT_CONTENT	to\tagSENT_CONTENT	eliminate\tagSENT_CONTENT	these\tagSENT_CONTENT	problems\tagSENT_CONTENT	including\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	and\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	introduced\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	,\tagSENT_CONTENT	context\tagSENT_CONTENT	/\tagSENT_CONTENT	type\tagSENT_CONTENT	matching\tagSENT_CONTENT	heuristic\tagSENT_CONTENT	for\tagSENT_CONTENT	question_answering\tagtask	which\tagSENT_CONTENT	serves\tagSENT_CONTENT	as\tagSENT_CONTENT	guideline\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	neural\tagSENT_CONTENT	baseline\tagSENT_CONTENT	system\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	Weighted\tagSECTITLE_CONTENT	Word\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Question\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	Term\tagSECTITLE_CONTENT	Frequency\tagSECTITLE_END	In\tagSENT_START	this\tagSENT_CONTENT	section\tagSENT_CONTENT	we\tagSENT_CONTENT	explain\tagSENT_CONTENT	the\tagSENT_CONTENT	connection\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	weighted\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	in\tagSENT_CONTENT	-\tagSENT_CONTENT	question_answering\tagtask	feature\tagSENT_CONTENT	(\tagSENT_CONTENT	§\tagSENT_CONTENT	2.3\tagSENT_CONTENT	)\tagSENT_CONTENT	defined\tagSENT_CONTENT	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_CONTENT	3\tagSENT_END	B\tagSECTITLE_START	Representation\tagSECTITLE_CONTENT	Fusion\tagSECTITLE_END	B.1\tagSECTITLE_START	Intra\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	Fusion\tagSECTITLE_END	Hence\tagSENT_START	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	hard\tagSENT_CONTENT	for\tagSENT_CONTENT	our\tagSENT_CONTENT	proposed\tagSENT_CONTENT	baseline\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	that\tagSENT_CONTENT	require\tagSENT_CONTENT	synthesizing\tagSENT_CONTENT	evidence\tagSENT_CONTENT	from\tagSENT_CONTENT	different\tagSENT_CONTENT	text\tagSENT_CONTENT	passages\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	correctly\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	the\tagSENT_CONTENT	representations\tagSENT_CONTENT	of\tagSENT_CONTENT	Rochester\tagSENT_CONTENT	,\tagSENT_CONTENT	New\tagSENT_CONTENT	York\tagSENT_CONTENT	should\tagSENT_CONTENT	contain\tagSENT_CONTENT	the\tagSENT_CONTENT	information\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	Brittanee\tagSENT_CONTENT	Drexel\tagSENT_CONTENT	.\tagSENT_END	
1705.08639	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Processing\tagSENT_START	sequential\tagSENT_CONTENT	data\tagSENT_CONTENT	of\tagSENT_CONTENT	variable\tagSENT_CONTENT	length\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	challenge\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	wide\tagSENT_CONTENT	range\tagSENT_CONTENT	of\tagSENT_CONTENT	applications\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	speech\tagSENT_CONTENT	recognition\tagSENT_CONTENT	,\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	generative\tagSENT_CONTENT	image\tagSENT_CONTENT	modeling\tagSENT_CONTENT	and\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Processing\tagSENT_START	,\tagSENT_CONTENT	language_modeling\tagtask	and\tagSENT_CONTENT	predicting\tagSENT_CONTENT	sequential\tagSENT_CONTENT	data\tagSENT_CONTENT	of\tagSENT_CONTENT	variable\tagSENT_CONTENT	length\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	challenge\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	field\tagSENT_CONTENT	of\tagSENT_CONTENT	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	.\tagSENT_END	Thus\tagSENT_START	,\tagSENT_CONTENT	language_modeling\tagtask	exploits\tagSENT_CONTENT	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	deep\tagSENT_CONTENT	models\tagSENT_CONTENT	can\tagSENT_CONTENT	represent\tagSENT_CONTENT	some\tagSENT_CONTENT	functions\tagSENT_CONTENT	exponentially\tagSENT_CONTENT	more\tagSENT_CONTENT	efficiently\tagSENT_CONTENT	than\tagSENT_CONTENT	shallow\tagSENT_CONTENT	models\tagSENT_CONTENT	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	will\tagSENT_CONTENT	not\tagSENT_CONTENT	further\tagSENT_CONTENT	investigate\tagSENT_CONTENT	this\tagSENT_CONTENT	extension\tagSENT_CONTENT	of\tagSENT_CONTENT	language_modeling\tagtask	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	even\tagSENT_CONTENT	though\tagSENT_CONTENT	it\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	beneficial\tagSENT_CONTENT	for\tagSENT_CONTENT	other\tagSENT_CONTENT	tasks\tagSENT_CONTENT	or\tagSENT_CONTENT	larger\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	The\tagSENT_START	FS\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	is\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	and\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	will\tagSENT_CONTENT	be\tagSENT_CONTENT	referred\tagSENT_CONTENT	to\tagSENT_CONTENT	as\tagSENT_CONTENT	enwik8\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	section\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSECTITLE_START	on\tagSECTITLE_CONTENT	Penn\tagSECTITLE_CONTENT	Treebank\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Hutter\tagSECTITLE_CONTENT	Prize\tagSECTITLE_CONTENT	Wikipedia\tagSECTITLE_END	These\tagSENT_START	results\tagSENT_CONTENT	are\tagSENT_CONTENT	compared\tagSENT_CONTENT	to\tagSENT_CONTENT	other\tagSENT_CONTENT	approaches\tagSENT_CONTENT	in\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	baseline\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	results\tagSENT_CONTENT	without\tagSENT_CONTENT	citations\tagSENT_CONTENT	are\tagSENT_CONTENT	taken\tagSENT_CONTENT	from\tagSENT_CONTENT	for\tagSENT_CONTENT	Penn\tagdataset	Treebank\tagdataset	and\tagSENT_CONTENT	from\tagSENT_CONTENT	for\tagSENT_CONTENT	enwik8\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	split\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	into\tagSENT_CONTENT	train\tagSENT_CONTENT	,\tagSENT_CONTENT	validation\tagSENT_CONTENT	and\tagSENT_CONTENT	test\tagSENT_CONTENT	sets\tagSENT_CONTENT	consisting\tagSENT_CONTENT	of\tagSENT_CONTENT	5.1\tagSENT_CONTENT	M\tagSENT_CONTENT	,\tagSENT_CONTENT	400\tagSENT_CONTENT	K\tagSENT_CONTENT	and\tagSENT_CONTENT	450\tagmetric	K\tagmetric	characters\tagmetric	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	and\tagSENT_START	it\tagSENT_CONTENT	consists\tagSENT_CONTENT	of\tagSENT_CONTENT	"\tagSENT_CONTENT	raw\tagSENT_CONTENT	"\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	English\tagSENT_CONTENT	articles\tagSENT_CONTENT	,\tagSENT_CONTENT	tables\tagSENT_CONTENT	,\tagSENT_CONTENT	XML\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	hyperlinks\tagSENT_CONTENT	and\tagSENT_CONTENT	special\tagmetric	characters\tagmetric	.\tagSENT_END	Comparison\tagSECTITLE_START	of\tagSECTITLE_CONTENT	network\tagSECTITLE_CONTENT	dynamics\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	architectures\tagSECTITLE_END	language_modeling\tagtask	are\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	enwik8\tagSENT_CONTENT	for\tagSENT_CONTENT	20\tagSENT_CONTENT	epochs\tagSENT_CONTENT	with\tagSENT_CONTENT	minibatch\tagSENT_CONTENT	gradient\tagSENT_CONTENT	descent\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	Adam\tagSENT_CONTENT	optimizer\tagSENT_CONTENT	without\tagSENT_CONTENT	any\tagSENT_CONTENT	regularization\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	layer\tagSENT_CONTENT	normalization\tagSENT_CONTENT	is\tagSENT_CONTENT	applied\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	cell\tagSENT_CONTENT	states\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	investigate\tagSENT_CONTENT	whether\tagSENT_CONTENT	the\tagSENT_CONTENT	FS\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	quickly\tagSENT_CONTENT	adapts\tagSENT_CONTENT	to\tagSENT_CONTENT	unexpected\tagmetric	characters\tagmetric	,\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	whether\tagSENT_CONTENT	it\tagSENT_CONTENT	performs\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	subsequent\tagSENT_CONTENT	ones\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	The\tagSENT_START	FS\tagSENT_CONTENT	-\tagSENT_CONTENT	RNN\tagSENT_CONTENT	architecture\tagSENT_CONTENT	improved\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	on\tagSENT_CONTENT	language_modeling\tagtask	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	Penn\tagSENT_CONTENT	Treebank\tagSENT_CONTENT	and\tagSENT_CONTENT	Hutter\tagSENT_CONTENT	Prize\tagSENT_CONTENT	Wikipedia\tagSENT_CONTENT	data\tagSENT_CONTENT	sets\tagSENT_CONTENT	.\tagSENT_END	
1712.03556	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	show\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	simple\tagSENT_CONTENT	trick\tagSENT_CONTENT	improves\tagSENT_CONTENT	robustness\tagSENT_CONTENT	and\tagSENT_CONTENT	achieves\tagSENT_CONTENT	results\tagSENT_CONTENT	competitive\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	Adver\tagSENT_CONTENT	-\tagSENT_CONTENT	sarial\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	Microsoft\tagSENT_CONTENT	MAchine\tagSENT_CONTENT	Reading\tagSENT_CONTENT	COmprehension\tagSENT_CONTENT	Dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	MS\tagSENT_CONTENT	MARCO\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Machine\tagSENT_START	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	(\tagSENT_CONTENT	MRC\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	challenging\tagSENT_CONTENT	task\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	goal\tagSENT_CONTENT	is\tagSENT_CONTENT	to\tagSENT_CONTENT	have\tagSENT_CONTENT	machines\tagSENT_CONTENT	read\tagSENT_CONTENT	a\tagSENT_CONTENT	text\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	Later\tagSENT_START	,\tagSENT_CONTENT	proposed\tagSENT_CONTENT	using\tagSENT_CONTENT	reinforcement\tagSENT_CONTENT	learning\tagSENT_CONTENT	to\tagSENT_CONTENT	dynamically\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	steps\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	complexity\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Intuitively\tagSENT_START	this\tagSENT_CONTENT	works\tagSENT_CONTENT	because\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	successively\tagSENT_CONTENT	refines\tagSENT_CONTENT	its\tagSENT_CONTENT	prediction\tagSENT_CONTENT	over\tagSENT_CONTENT	multiple\tagSENT_CONTENT	steps\tagSENT_CONTENT	,\tagSENT_CONTENT	each\tagSENT_CONTENT	step\tagSENT_CONTENT	is\tagSENT_CONTENT	still\tagSENT_CONTENT	trained\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	question_answering\tagtask	;\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	performing\tagSENT_CONTENT	a\tagSENT_CONTENT	kind\tagSENT_CONTENT	of\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	ensemble\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	's\tagSENT_CONTENT	successive\tagSENT_CONTENT	predic-\tagSENT_END	Proposed\tagSECTITLE_START	model\tagSECTITLE_CONTENT	:\tagSECTITLE_CONTENT	SAN\tagSECTITLE_END	The\tagSENT_START	machine\tagSENT_CONTENT	reading\tagSENT_CONTENT	comprehension\tagSENT_CONTENT	(\tagSENT_CONTENT	MRC\tagSENT_CONTENT	)\tagSENT_CONTENT	task\tagSENT_CONTENT	as\tagSENT_CONTENT	defined\tagSENT_CONTENT	here\tagSENT_CONTENT	involves\tagSENT_CONTENT	question_answering\tagtask	A\tagSENT_START	typical\tagSENT_CONTENT	technique\tagSENT_CONTENT	to\tagSENT_CONTENT	obtain\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	concatenation\tagSENT_CONTENT	of\tagSENT_CONTENT	its\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	linguistic\tagSENT_CONTENT	embedding\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	those\tagSENT_CONTENT	derived\tagSENT_CONTENT	from\tagSENT_CONTENT	Part\tagSENT_CONTENT	-\tagSENT_CONTENT	Of\tagSENT_CONTENT	-\tagSENT_CONTENT	Speech\tagSENT_CONTENT	(\tagSENT_CONTENT	POS\tagSENT_CONTENT	)\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	This\tagSENT_START	checks\tagSENT_CONTENT	whether\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	token\tagSENT_CONTENT	pi\tagSENT_CONTENT	matches\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	,\tagSENT_CONTENT	lowercase\tagSENT_CONTENT	or\tagSENT_CONTENT	lemma\tagSENT_CONTENT	form\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	token\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	enhanced\tagSENT_CONTENT	passages\tagSENT_CONTENT	word\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	:\tagSENT_END	measures\tagSENT_START	the\tagSENT_CONTENT	similarity\tagSENT_CONTENT	in\tagSENT_CONTENT	word\tagSENT_CONTENT	embedding\tagSENT_CONTENT	space\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	token\tagSENT_CONTENT	pi\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	token\tagSENT_CONTENT	q\tagSENT_CONTENT	j\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Due\tagSENT_START	to\tagSENT_CONTENT	different\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	for\tagSENT_CONTENT	the\tagSENT_CONTENT	passages\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	next\tagSENT_CONTENT	layer\tagSENT_CONTENT	two\tagSENT_CONTENT	different\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	maybe\tagSENT_CONTENT	required\tagSENT_CONTENT	to\tagSENT_CONTENT	encode\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	information\tagSENT_CONTENT	.\tagSENT_END	Both\tagSENT_START	passage\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	a\tagSENT_CONTENT	shared\tagSENT_CONTENT	two\tagSENT_CONTENT	-\tagSENT_CONTENT	layers\tagSENT_CONTENT	BiLSTM\tagSENT_CONTENT	as\tagSENT_CONTENT	the\tagSENT_CONTENT	contextual\tagSENT_CONTENT	encoding\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	projects\tagSENT_CONTENT	the\tagSENT_CONTENT	lexicon\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	to\tagSENT_CONTENT	contextual\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	.\tagSENT_END	question_answering\tagtask	q\tagSENT_END	Formally\tagSENT_START	,\tagSENT_CONTENT	our\tagSENT_CONTENT	answer\tagSENT_CONTENT	module\tagSENT_CONTENT	will\tagSENT_CONTENT	compute\tagSENT_CONTENT	over\tagSENT_CONTENT	T\tagSENT_CONTENT	memory\tagSENT_CONTENT	steps\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	(\tagSENT_START	6\tagSENT_CONTENT	)\tagSENT_CONTENT	From\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	begin\tagSENT_CONTENT	and\tagSENT_CONTENT	end\tagSENT_CONTENT	points\tagSENT_CONTENT	,\tagSENT_CONTENT	question_answering\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	extracted\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	passage\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	example\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	illustrated\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	randomly\tagSENT_CONTENT	delete\tagSENT_CONTENT	several\tagSENT_CONTENT	steps\tagSENT_CONTENT	'\tagSENT_CONTENT	predictions\tagSENT_CONTENT	in\tagSENT_CONTENT	question_answering\tagtask	7\tagSENT_CONTENT	and\tagSENT_CONTENT	8\tagSENT_CONTENT	so\tagSENT_CONTENT	that\tagSENT_CONTENT	P\tagSENT_CONTENT	begin\tagSENT_CONTENT	might\tagSENT_CONTENT	be\tagSENT_CONTENT	avg([P\tagSENT_CONTENT	begin\tagSENT_CONTENT	Our\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	prediction\tagSENT_CONTENT	dropout\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	in\tagSENT_CONTENT	motivation\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	dropout\tagSENT_CONTENT	introduced\tagSENT_CONTENT	by\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experiment\tagSECTITLE_START	Setup\tagSECTITLE_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	on\tagSENT_CONTENT	question_answering\tagtask	)\tagSENT_END	Two\tagSENT_START	evaluation\tagSENT_CONTENT	metrics\tagSENT_CONTENT	are\tagSENT_CONTENT	used\tagSENT_CONTENT	:\tagSENT_CONTENT	Exact\tagSENT_CONTENT	Match\tagSENT_CONTENT	(\tagSENT_CONTENT	EM\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	percentage\tagSENT_CONTENT	of\tagSENT_CONTENT	span\tagSENT_CONTENT	predictions\tagSENT_CONTENT	that\tagSENT_CONTENT	matched\tagSENT_CONTENT	anyone\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	answer\tagSENT_CONTENT	exactly\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	Macro\tagSENT_CONTENT	-\tagSENT_CONTENT	averaged\tagSENT_CONTENT	F1\tagSENT_CONTENT	score\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	measures\tagSENT_CONTENT	the\tagSENT_CONTENT	average\tagSENT_CONTENT	overlap\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	answer\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	spaCy\tagSENT_CONTENT	tool\tagSENT_CONTENT	2\tagSENT_CONTENT	is\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	tokenize\tagSENT_CONTENT	the\tagSENT_CONTENT	both\tagSENT_CONTENT	passages\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	generate\tagSENT_CONTENT	lemma\tagSENT_CONTENT	,\tagSENT_CONTENT	part\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	speech\tagSENT_CONTENT	and\tagSENT_CONTENT	named\tagSENT_CONTENT	entity\tagSENT_CONTENT	tags\tagSENT_CONTENT	.\tagSENT_END	Results\tagSECTITLE_END	proposed\tagSENT_START	answer\tagSENT_CONTENT	module\tagSENT_CONTENT	that\tagSENT_CONTENT	uses\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	dropout\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	The\tagSENT_START	main\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	EM\tagmetric	and\tagSENT_CONTENT	F1\tagmetric	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	The\tagSENT_CONTENT	K\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	oracle\tagSENT_CONTENT	results\tagSENT_CONTENT	is\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	limit\tagSENT_CONTENT	K\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	range\tagSENT_CONTENT	1\tagSENT_CONTENT	to\tagSENT_CONTENT	4\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	pick\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	EM\tagSENT_CONTENT	or\tagSENT_CONTENT	F1\tagmetric	as\tagSENT_CONTENT	oracle\tagSENT_CONTENT	.\tagSENT_END	SAN\tagSENT_START	also\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	other\tagSENT_CONTENT	models\tagSENT_CONTENT	in\tagSENT_CONTENT	terms\tagmetric	of\tagSENT_CONTENT	K\tagSENT_CONTENT	-\tagSENT_CONTENT	best\tagSENT_CONTENT	oracle\tagSENT_CONTENT	scores\tagSENT_CONTENT	.\tagSENT_END	=\tagSENT_START	2\tagSENT_CONTENT	for\tagSENT_CONTENT	EM\tagmetric	and\tagSENT_CONTENT	K\tagSENT_END	=\tagSENT_START	3\tagSENT_CONTENT	for\tagSENT_CONTENT	F1\tagmetric	.\tagSENT_END	Answer\tagSECTITLE_START	Module\tagSECTITLE_END	EM\tagSECTITLE_START	F1\tagSECTITLE_CONTENT	Standard\tagSECTITLE_CONTENT	1-step\tagSECTITLE_CONTENT	75.139\tagSECTITLE_CONTENT	83.367\tagSECTITLE_CONTENT	Fixed\tagSECTITLE_CONTENT	5-step\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	prediction\tagSECTITLE_CONTENT	from\tagSECTITLE_CONTENT	final\tagSECTITLE_CONTENT	step\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	75.033\tagSECTITLE_CONTENT	83.327\tagSECTITLE_CONTENT	Fixed\tagSECTITLE_CONTENT	5-step\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	Memory\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	prediction\tagSECTITLE_CONTENT	averaged\tagSECTITLE_CONTENT	from\tagSECTITLE_CONTENT	all\tagSECTITLE_CONTENT	steps\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	75.256\tagSECTITLE_CONTENT	83.215\tagSECTITLE_CONTENT	Dynamic\tagSECTITLE_CONTENT	steps\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	max\tagSECTITLE_CONTENT	5\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	ReasoNet\tagSECTITLE_CONTENT	75.355\tagSECTITLE_CONTENT	83.360\tagSECTITLE_CONTENT	Stochastic\tagSECTITLE_CONTENT	Answer\tagSECTITLE_CONTENT	Network\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	SAN\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	,\tagSECTITLE_CONTENT	Fixed\tagSECTITLE_CONTENT	5-step\tagSECTITLE_END	Analysis\tagSECTITLE_END	How\tagSECTITLE_START	robust\tagSECTITLE_CONTENT	are\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	results\tagSECTITLE_CONTENT	?\tagSECTITLE_END	In\tagSENT_START	fact\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	EM\tagSENT_CONTENT	/\tagSENT_CONTENT	F1\tagSENT_CONTENT	scores\tagSENT_CONTENT	drop\tagSENT_CONTENT	slightly\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	considering\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	random\tagSENT_CONTENT	initialization\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	show\tagSENT_CONTENT	a\tagSENT_CONTENT	standard\tagSENT_CONTENT	deviation\tagSENT_CONTENT	of\tagSENT_CONTENT	0.142\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	spread\tagSENT_CONTENT	of\tagSENT_CONTENT	0.426\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	EM\tagmetric	)\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	T\tagSENT_CONTENT	=\tagSENT_CONTENT	10\tagSENT_CONTENT	result\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	statistically\tagSENT_CONTENT	differ\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	T\tagSENT_CONTENT	=\tagSENT_CONTENT	5\tagSENT_CONTENT	result\tagSENT_CONTENT	.\tagSENT_END	Finally\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	test\tagSENT_CONTENT	SAN\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	Adversarial\tagSENT_CONTENT	SQuAD\tagSENT_CONTENT	datasets\tagSENT_CONTENT	,\tagSENT_CONTENT	AddSent\tagSENT_CONTENT	and\tagSENT_CONTENT	AddOneSent\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	passages\tagSENT_CONTENT	contain\tagSENT_CONTENT	 \tagSENT_CONTENT	auto\tagSENT_CONTENT	-\tagSENT_CONTENT	generated\tagSENT_CONTENT	adversarial\tagSENT_CONTENT	distracting\tagSENT_CONTENT	sentences\tagSENT_CONTENT	to\tagSENT_CONTENT	fool\tagSENT_CONTENT	computer\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	developed\tagSENT_CONTENT	to\tagSENT_CONTENT	answer\tagSENT_CONTENT	question_answering\tagtask	about\tagSENT_CONTENT	the\tagSENT_CONTENT	passages\tagSENT_CONTENT	.\tagSENT_END	Is\tagSECTITLE_START	it\tagSECTITLE_CONTENT	possible\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	use\tagSECTITLE_CONTENT	different\tagSECTITLE_CONTENT	numbers\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	steps\tagSECTITLE_CONTENT	in\tagSECTITLE_CONTENT	test\tagSECTITLE_CONTENT	vs.\tagSECTITLE_CONTENT	train\tagSECTITLE_CONTENT	?\tagSECTITLE_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	question_answering\tagtask	is\tagSENT_CONTENT	whether\tagSENT_CONTENT	SAN\tagSENT_CONTENT	can\tagSENT_CONTENT	train\tagSENT_CONTENT	with\tagSENT_CONTENT	,\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	T\tagSENT_CONTENT	=\tagSENT_CONTENT	5\tagSENT_CONTENT	steps\tagSENT_CONTENT	but\tagSENT_CONTENT	test\tagSENT_CONTENT	with\tagSENT_CONTENT	T\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	steps\tagSENT_CONTENT	.\tagSENT_END	(\tagmetric	EM\tagmetric	)\tagSENT_CONTENT	Mean\tagSENT_CONTENT	:\tagSENT_CONTENT	83.977\tagSENT_CONTENT	,\tagSENT_CONTENT	Std\tagSENT_CONTENT	.\tagSENT_END	deviation\tagSENT_START	:\tagSENT_CONTENT	0.126\tagSENT_CONTENT	(\tagmetric	F1\tagmetric	)\tagSENT_CONTENT	:\tagSENT_END	How\tagSECTITLE_START	does\tagSECTITLE_CONTENT	the\tagSECTITLE_CONTENT	training\tagSECTITLE_CONTENT	time\tagSECTITLE_CONTENT	compare\tagSECTITLE_CONTENT	?\tagSECTITLE_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	while\tagSENT_CONTENT	training\tagSENT_CONTENT	time\tagSENT_CONTENT	per\tagSENT_CONTENT	epoch\tagSENT_CONTENT	is\tagSENT_CONTENT	similar\tagSENT_CONTENT	between\tagSENT_CONTENT	SAN\tagSENT_CONTENT	and\tagSENT_CONTENT	other\tagSENT_CONTENT	models\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	recommended\tagSENT_CONTENT	to\tagSENT_CONTENT	train\tagSENT_CONTENT	SAN\tagSENT_CONTENT	for\tagSENT_CONTENT	more\tagSENT_CONTENT	epochs\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	achieve\tagSENT_CONTENT	gains\tagSENT_CONTENT	in\tagSENT_CONTENT	EM\tagmetric	/\tagmetric	F1\tagmetric	.\tagSENT_END	How\tagSECTITLE_START	does\tagSECTITLE_CONTENT	SAN\tagSECTITLE_CONTENT	perform\tagSECTITLE_CONTENT	by\tagSECTITLE_CONTENT	question\tagSECTITLE_CONTENT	type\tagSECTITLE_CONTENT	?\tagSECTITLE_END	To\tagSENT_START	see\tagSENT_CONTENT	whether\tagSENT_CONTENT	SAN\tagSENT_CONTENT	performs\tagSENT_CONTENT	well\tagSENT_CONTENT	on\tagSENT_CONTENT	a\tagSENT_CONTENT	particular\tagSENT_CONTENT	type\tagSENT_CONTENT	of\tagSENT_CONTENT	question_answering\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	divided\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	by\tagSENT_CONTENT	questions\tagSENT_CONTENT	type\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	their\tagSENT_CONTENT	respective\tagSENT_CONTENT	Whword\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	who\tagSENT_CONTENT	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagSENT_CONTENT	where\tagSENT_CONTENT	"\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_START	results\tagSECTITLE_CONTENT	on\tagSECTITLE_CONTENT	MS\tagSECTITLE_CONTENT	MARCO\tagSECTITLE_END	SingleM\tagSECTITLE_START	odel\tagSECTITLE_END	ROUGE\tagSECTITLE_START	BLEU\tagSECTITLE_END	Then\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	multiply\tagSENT_CONTENT	the\tagSENT_CONTENT	SAN\tagSENT_CONTENT	score\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	candidate\tagSENT_CONTENT	answer\tagSENT_CONTENT	span\tagSENT_CONTENT	with\tagSENT_CONTENT	its\tagSENT_CONTENT	relevance\tagSENT_CONTENT	score\tagSENT_CONTENT	r(P\tagSENT_CONTENT	j\tagSENT_CONTENT	,\tagSENT_CONTENT	Q\tagSENT_CONTENT	)\tagSENT_CONTENT	assigned\tagSENT_CONTENT	by\tagSENT_CONTENT	a\tagSENT_CONTENT	passage\tagSENT_CONTENT	ranker\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	output\tagSENT_CONTENT	the\tagSENT_CONTENT	span\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	maximum\tagSENT_CONTENT	score\tagSENT_CONTENT	as\tagSENT_CONTENT	question_answering\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	Work\tagSECTITLE_END	In\tagSENT_START	spite\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	variety\tagSENT_CONTENT	of\tagSENT_CONTENT	model\tagSENT_CONTENT	structures\tagSENT_CONTENT	and\tagSENT_CONTENT	attenion\tagSENT_CONTENT	types\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	atypical\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	MRC\tagSENT_CONTENT	model\tagSENT_CONTENT	first\tagSENT_CONTENT	maps\tagSENT_CONTENT	the\tagSENT_CONTENT	symbolic\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	documents\tagSENT_CONTENT	and\tagSENT_CONTENT	question_answering\tagtask	into\tagSENT_CONTENT	a\tagSENT_CONTENT	neural\tagSENT_CONTENT	space\tagSENT_CONTENT	,\tagSENT_CONTENT	then\tagSENT_CONTENT	search\tagSENT_CONTENT	answers\tagSENT_CONTENT	on\tagSENT_CONTENT	top\tagSENT_CONTENT	of\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	A\tagSENT_START	single\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	model\tagSENT_CONTENT	matches\tagSENT_CONTENT	question_answering\tagtask	and\tagSENT_CONTENT	document\tagSENT_CONTENT	only\tagSENT_CONTENT	once\tagSENT_CONTENT	and\tagSENT_CONTENT	produce\tagSENT_CONTENT	the\tagSENT_CONTENT	final\tagSENT_CONTENT	answers\tagSENT_CONTENT	.\tagSENT_END	Pioneered\tagSENT_START	by\tagSENT_CONTENT	,\tagSENT_CONTENT	who\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	predetermined\tagSENT_CONTENT	fixed\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	steps\tagSENT_CONTENT	,\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	single\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	ones\tagSENT_CONTENT	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	reasoning\tagSENT_CONTENT	further\tagSENT_CONTENT	outperforms\tagSENT_CONTENT	the\tagSENT_CONTENT	fixed\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	step\tagSENT_CONTENT	ones\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	distinct\tagSENT_CONTENT	MRC\tagSENT_CONTENT	datasets\tagSENT_CONTENT	(\tagSENT_CONTENT	SQuAD\tagdataset	and\tagSENT_CONTENT	MS\tagSENT_CONTENT	MARCO\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	The\tagSENT_START	use\tagSENT_CONTENT	of\tagSENT_CONTENT	stochastic\tagSENT_CONTENT	dropout\tagSENT_CONTENT	in\tagSENT_CONTENT	training\tagSENT_CONTENT	and\tagSENT_CONTENT	averaging\tagSENT_CONTENT	in\tagSENT_CONTENT	test\tagSENT_CONTENT	at\tagSENT_CONTENT	the\tagSENT_CONTENT	answer\tagSENT_CONTENT	module\tagSENT_CONTENT	leads\tagSENT_CONTENT	to\tagSENT_CONTENT	robust\tagSENT_CONTENT	improvements\tagSENT_CONTENT	on\tagSENT_CONTENT	SQuAD\tagdataset	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	both\tagSENT_CONTENT	fixed\tagSENT_CONTENT	step\tagSENT_CONTENT	memory\tagSENT_CONTENT	networks\tagSENT_CONTENT	and\tagSENT_CONTENT	dynamic\tagSENT_CONTENT	step\tagSENT_CONTENT	ReasoNet\tagSENT_CONTENT	.\tagSENT_END	
D17-1108	title\tagSECTITLE_END	A\tagSENT_START	Structured\tagSENT_CONTENT	Learning\tagSENT_CONTENT	Approach\tagSENT_CONTENT	to\tagSENT_CONTENT	temporal_information_extraction\tagtask	abstract\tagSECTITLE_END	Identifying\tagSENT_START	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	events\tagSENT_CONTENT	is\tagSENT_CONTENT	an\tagSENT_CONTENT	essential\tagSENT_CONTENT	step\tagSENT_CONTENT	towards\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Understanding\tagSENT_START	temporal_information_extraction\tagtask	described\tagSENT_CONTENT	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	text\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	key\tagSENT_CONTENT	component\tagSENT_CONTENT	of\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	understanding\tagSENT_CONTENT	(\tagSENT_CONTENT	and\tagSENT_CONTENT	,\tagSENT_CONTENT	following\tagSENT_CONTENT	a\tagSENT_CONTENT	series\tagSENT_CONTENT	of\tagSENT_CONTENT	TempEval\tagSENT_CONTENT	(\tagSENT_CONTENT	TE\tagSENT_CONTENT	)\tagSENT_CONTENT	workshops\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	has\tagSENT_CONTENT	drawn\tagSENT_CONTENT	increased\tagSENT_CONTENT	attention\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	fundamental\tagSENT_CONTENT	tasks\tagSENT_CONTENT	in\tagSENT_CONTENT	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	as\tagSENT_CONTENT	identified\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	TE\tagSENT_CONTENT	workshops\tagSENT_CONTENT	,\tagSENT_CONTENT	are\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	time\tagSENT_CONTENT	expression\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	so\tagSENT_CONTENT	-\tagSENT_CONTENT	called\tagSENT_CONTENT	"\tagSENT_CONTENT	timex\tagSENT_CONTENT	"\tagSENT_CONTENT	)\tagSENT_CONTENT	extraction\tagSENT_CONTENT	and\tagSENT_CONTENT	normalization\tagSENT_CONTENT	and\tagSENT_CONTENT	2\tagSENT_CONTENT	)\tagSENT_CONTENT	temporal\tagSENT_CONTENT	relation\tagSENT_CONTENT	(\tagSENT_CONTENT	also\tagSENT_CONTENT	known\tagSENT_CONTENT	as\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	extraction\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	goal\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	is\tagSENT_CONTENT	to\tagSENT_CONTENT	generate\tagSENT_CONTENT	a\tagSENT_CONTENT	directed\tagSENT_CONTENT	temporal\tagSENT_CONTENT	graph\tagSENT_CONTENT	whose\tagSENT_CONTENT	nodes\tagSENT_CONTENT	represent\tagSENT_CONTENT	temporal\tagSENT_CONTENT	entities\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	,\tagSENT_CONTENT	events\tagSENT_CONTENT	or\tagSENT_CONTENT	timexes\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	edges\tagSENT_CONTENT	represent\tagSENT_CONTENT	the\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	temporal_information_extraction\tagtask	,\tagSENT_CONTENT	temporal_information_extraction\tagtask	are\tagSENT_CONTENT	categorized\tagSENT_CONTENT	into\tagSENT_CONTENT	three\tagSENT_CONTENT	types\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	E\tagSENT_CONTENT	-\tagSENT_CONTENT	E\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	(\tagSENT_CONTENT	those\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	T\tagSENT_CONTENT	-\tagSENT_CONTENT	T\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	(\tagSENT_CONTENT	those\tagSENT_CONTENT	between\tagSENT_CONTENT	a\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	timexes\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	E\tagSENT_CONTENT	-\tagSENT_CONTENT	T\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	(\tagSENT_CONTENT	those\tagSENT_CONTENT	between\tagSENT_CONTENT	an\tagSENT_CONTENT	event\tagSENT_CONTENT	and\tagSENT_CONTENT	a\tagSENT_CONTENT	timex\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	discussed\tagSENT_CONTENT	in\tagSENT_CONTENT	existing\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	temporal\tagmetric	graph\tagmetric	is\tagSENT_CONTENT	constrained\tagSENT_CONTENT	by\tagSENT_CONTENT	some\tagSENT_CONTENT	rather\tagSENT_CONTENT	simple\tagSENT_CONTENT	rules\tagSENT_CONTENT	:\tagSENT_END	This\tagSENT_START	particular\tagSENT_CONTENT	structure\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagmetric	temporal\tagmetric	graph\tagmetric	(\tagSENT_CONTENT	especially\tagSENT_CONTENT	the\tagSENT_CONTENT	transitivity\tagSENT_CONTENT	structure\tagSENT_CONTENT	)\tagSENT_CONTENT	makes\tagSENT_CONTENT	its\tagSENT_CONTENT	nodes\tagSENT_CONTENT	highly\tagSENT_CONTENT	interrelated\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	seen\tagSENT_CONTENT	from\tagSENT_CONTENT	.\tagSENT_END	shows\tagSENT_START	temporal_information_extraction\tagtask	provided\tagSENT_CONTENT	by\tagSENT_CONTENT	TE3\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	,\tagSENT_CONTENT	and\tagSENT_CONTENT	NavyTime\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	use\tagSENT_CONTENT	better\tagSENT_CONTENT	designed\tagSENT_CONTENT	rules\tagSENT_CONTENT	or\tagSENT_CONTENT	more\tagmetric	features\tagmetric	such\tagSENT_CONTENT	as\tagSENT_CONTENT	syntactic\tagSENT_CONTENT	tree\tagSENT_CONTENT	paths\tagSENT_CONTENT	and\tagSENT_CONTENT	achieve\tagSENT_CONTENT	better\tagSENT_CONTENT	results\tagSENT_CONTENT	.\tagSENT_END	(\tagSENT_START	ILP\tagSENT_CONTENT	)\tagSENT_CONTENT	methods\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	were\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	domain\tagSENT_CONTENT	to\tagSENT_CONTENT	enforce\tagSENT_CONTENT	global\tagSENT_CONTENT	consistency\tagSENT_CONTENT	by\tagSENT_CONTENT	several\tagSENT_CONTENT	authors\tagSENT_CONTENT	including\tagSENT_CONTENT	;\tagSENT_CONTENT	;\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	formulated\tagSENT_CONTENT	temporal_information_extraction\tagtask	as\tagSENT_CONTENT	an\tagSENT_CONTENT	ILP\tagSENT_CONTENT	and\tagSENT_CONTENT	showed\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	improves\tagSENT_CONTENT	over\tagSENT_CONTENT	local\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	densely\tagSENT_CONTENT	connected\tagSENT_CONTENT	graphs\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	parallel\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	work\tagSENT_CONTENT	presented\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	Leeuwenberg\tagSENT_CONTENT	and\tagSENT_CONTENT	Moens\tagSENT_CONTENT	(\tagSENT_CONTENT	2017\tagSENT_CONTENT	)\tagSENT_CONTENT	also\tagSENT_CONTENT	proposed\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	extracting\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Section\tagSENT_START	2\tagSENT_CONTENT	clarifies\tagSENT_CONTENT	temporal_information_extraction\tagtask	and\tagSENT_CONTENT	the\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	of\tagSENT_CONTENT	a\tagSENT_CONTENT	temporal\tagSENT_CONTENT	graph\tagSENT_CONTENT	used\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	paper\tagSENT_END	Background\tagSECTITLE_END	Temporal\tagSECTITLE_START	Relation\tagSECTITLE_CONTENT	Types\tagSECTITLE_END	Existing\tagSENT_START	corpora\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	often\tagSENT_CONTENT	follows\tagSENT_CONTENT	the\tagSENT_CONTENT	interval\tagSENT_CONTENT	representation\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	makes\tagSENT_CONTENT	use\tagSENT_CONTENT	of\tagSENT_CONTENT	13\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	in\tagSENT_CONTENT	total\tagSENT_CONTENT	.\tagSENT_END	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	relation\tagSENT_CONTENT	types\tagSENT_CONTENT	makes\tagSENT_CONTENT	it\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	separate\tagSENT_CONTENT	lowfrequency\tagSENT_CONTENT	ones\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	others\tagSENT_CONTENT	(\tagSENT_CONTENT	see\tagSENT_CONTENT	in\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	this\tagSENT_CONTENT	work\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	follow\tagSENT_CONTENT	the\tagSENT_CONTENT	reduced\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal_information_extraction\tagtask	used\tagSENT_CONTENT	in\tagSENT_CONTENT	CAEVO\tagSENT_CONTENT	(\tagSENT_CONTENT	):\tagSENT_CONTENT	before\tagSENT_CONTENT	,\tagSENT_CONTENT	after\tagSENT_CONTENT	,\tagSENT_CONTENT	includes\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	included\tagSENT_CONTENT	,\tagSENT_CONTENT	equal\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	vague\tagSENT_CONTENT	.\tagSENT_END	Quality\tagSECTITLE_START	of\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	Temporal\tagSECTITLE_CONTENT	Graph\tagSECTITLE_END	The\tagSENT_START	most\tagSENT_CONTENT	recent\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	in\tagSENT_CONTENT	TE3\tagSENT_CONTENT	,\tagmetric	i.e.\tagmetric	,\tagmetric	the\tagmetric	temporal\tagmetric	awareness\tagmetric	(\tagSENT_CONTENT	UzZaman\tagSENT_CONTENT	and\tagSENT_CONTENT	Allen\tagSENT_CONTENT	,\tagSENT_CONTENT	2011\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_CONTENT	adopted\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	work\tagSENT_CONTENT	.\tagSENT_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	let\tagSENT_CONTENT	G\tagSENT_CONTENT	sys\tagSENT_CONTENT	and\tagSENT_CONTENT	G\tagSENT_CONTENT	true\tagSENT_CONTENT	be\tagSENT_CONTENT	two\tagmetric	temporal\tagmetric	graphs\tagmetric	from\tagSENT_CONTENT	the\tagSENT_CONTENT	system\tagSENT_CONTENT	prediction\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	ground\tagSENT_CONTENT	truth\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	precision\tagSENT_CONTENT	and\tagSENT_CONTENT	recall\tagSENT_CONTENT	of\tagSENT_CONTENT	temporal\tagmetric	awareness\tagmetric	are\tagSENT_CONTENT	defined\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	where\tagSENT_START	G\tagSENT_CONTENT	+\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	closure\tagSENT_CONTENT	of\tagSENT_CONTENT	graph\tagSENT_CONTENT	G\tagSENT_CONTENT	,\tagSENT_CONTENT	G\tagSENT_CONTENT	−\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	reduction\tagSENT_CONTENT	of\tagSENT_CONTENT	G\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	∩\tagSENT_CONTENT	"\tagSENT_CONTENT	is\tagSENT_CONTENT	temporal_information_extraction\tagtask	between\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	in\tagSENT_CONTENT	two\tagSENT_CONTENT	graphs\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	|G|\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	in\tagSENT_END	G.\tagSENT_START	The\tagSENT_CONTENT	temporal\tagmetric	awareness\tagmetric	metric\tagSENT_CONTENT	better\tagSENT_CONTENT	captures\tagSENT_CONTENT	how\tagSENT_CONTENT	"\tagSENT_CONTENT	useful\tagSENT_CONTENT	"\tagSENT_CONTENT	a\tagmetric	temporal\tagmetric	graph\tagmetric	is\tagSENT_CONTENT	.\tagSENT_END	A\tagSECTITLE_START	Structured\tagSECTITLE_CONTENT	Training\tagSECTITLE_CONTENT	Approach\tagSECTITLE_END	In\tagSENT_START	order\tagSENT_CONTENT	to\tagSENT_CONTENT	introduce\tagSENT_CONTENT	the\tagSENT_CONTENT	structured\tagSENT_CONTENT	learning\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	first\tagSENT_CONTENT	explain\tagSENT_CONTENT	its\tagSENT_CONTENT	most\tagSENT_CONTENT	important\tagSENT_CONTENT	component\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	global\tagmetric	inference\tagmetric	step\tagmetric	.\tagSENT_END	Inference\tagSECTITLE_END	Y\tagSENT_START	be\tagSENT_CONTENT	temporal_information_extraction\tagtask	for\tagSENT_CONTENT	the\tagSENT_CONTENT	i\tagSENT_CONTENT	-\tagSENT_CONTENT	th\tagSENT_CONTENT	pair\tagSENT_CONTENT	of\tagSENT_CONTENT	events\tagSENT_CONTENT	,\tagSENT_END	is\tagSENT_START	the\tagSENT_CONTENT	label\tagSENT_CONTENT	set\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	we\tagSENT_CONTENT	use\tagSENT_CONTENT	.\tagSENT_END	⊆\tagSENT_START	Y\tagSENT_CONTENT	n\tagSENT_CONTENT	constrains\tagSENT_CONTENT	the\tagmetric	temporal\tagmetric	graph\tagmetric	to\tagSENT_CONTENT	be\tagSENT_CONTENT	symmetrically\tagSENT_CONTENT	and\tagSENT_CONTENT	transitively\tagSENT_CONTENT	consistent\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	f\tagSENT_CONTENT	(\tagSENT_CONTENT	x\tagSENT_CONTENT	,\tagSENT_CONTENT	y\tagSENT_CONTENT	)\tagSENT_CONTENT	is\tagSENT_CONTENT	temporal_information_extraction\tagtask	:\tagSENT_END	0\tagSENT_START	,\tagSENT_CONTENT	1\tagSENT_CONTENT	}\tagSENT_CONTENT	be\tagSENT_CONTENT	temporal_information_extraction\tagtask	of\tagSENT_CONTENT	relation\tagSENT_CONTENT	r\tagSENT_CONTENT	for\tagSENT_CONTENT	event\tagSENT_END	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	Eq\tagSENT_CONTENT	.\tagSENT_END	temporal_information_extraction\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	easily\tagSENT_CONTENT	exploited\tagSENT_CONTENT	by\tagSENT_CONTENT	allowing\tagSENT_CONTENT	N\tagSENT_CONTENT	>\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_END	With\tagSENT_START	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	instance\tagSENT_CONTENT	instead\tagSENT_CONTENT	,\tagSENT_CONTENT	Line\tagSENT_CONTENT	6\tagSENT_CONTENT	becomes\tagSENT_CONTENT	slower\tagSENT_CONTENT	to\tagSENT_CONTENT	solve\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	it\tagSENT_CONTENT	can\tagSENT_CONTENT	provide\tagSENT_CONTENT	temporal_information_extraction\tagtask	so\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	learner\tagSENT_CONTENT	is\tagSENT_CONTENT	able\tagSENT_CONTENT	to\tagSENT_CONTENT	look\tagSENT_CONTENT	further\tagSENT_CONTENT	at\tagSENT_CONTENT	other\tagSENT_CONTENT	labels\tagSENT_CONTENT	rather\tagSENT_CONTENT	than\tagSENT_CONTENT	an\tagSENT_CONTENT	isolated\tagSENT_CONTENT	pair\tagSENT_CONTENT	.\tagSENT_END	Semi\tagSECTITLE_START	-\tagSECTITLE_CONTENT	supervised\tagSECTITLE_CONTENT	Structured\tagSECTITLE_CONTENT	Learning\tagSECTITLE_END	The\tagSENT_START	scarcity\tagSENT_CONTENT	of\tagSENT_CONTENT	training\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	difficulty\tagSENT_CONTENT	in\tagSENT_CONTENT	annotation\tagSENT_CONTENT	have\tagSENT_CONTENT	long\tagSENT_CONTENT	been\tagSENT_CONTENT	a\tagSENT_CONTENT	bottleneck\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal\tagmetric	processing\tagmetric	systems\tagmetric	.\tagSENT_END	Given\tagSENT_START	the\tagSENT_CONTENT	inherent\tagSENT_CONTENT	global\tagSENT_CONTENT	constraints\tagSENT_CONTENT	in\tagSENT_CONTENT	temporal\tagmetric	graphs\tagmetric	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	to\tagSENT_CONTENT	perform\tagSENT_CONTENT	semi\tagSENT_CONTENT	-\tagSENT_CONTENT	supervised\tagSENT_CONTENT	structured\tagSENT_CONTENT	learning\tagSENT_CONTENT	using\tagSENT_CONTENT	the\tagSENT_CONTENT	constraint\tagSENT_CONTENT	-\tagSENT_CONTENT	driven\tagSENT_CONTENT	learning\tagSENT_CONTENT	(\tagSENT_CONTENT	CoDL\tagSENT_CONTENT	)\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	Algorithm\tagSENT_CONTENT	2\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	the\tagSENT_CONTENT	function\tagSENT_CONTENT	"\tagSENT_CONTENT	Learn\tagSENT_CONTENT	"\tagSENT_CONTENT	in\tagSENT_CONTENT	Lines\tagSENT_CONTENT	2\tagSENT_CONTENT	and\tagSENT_CONTENT	9\tagSENT_CONTENT	represents\tagSENT_CONTENT	any\tagSENT_CONTENT	standard\tagSENT_CONTENT	learning\tagSENT_CONTENT	algorithm\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	,\tagSENT_CONTENT	SVM\tagSENT_CONTENT	,\tagSENT_CONTENT	or\tagSENT_CONTENT	even\tagSENT_CONTENT	structured\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	;\tagSENT_CONTENT	here\tagSENT_CONTENT	we\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	averaged\tagSENT_CONTENT	perceptron\tagSENT_CONTENT	(\tagSENT_CONTENT	Freund\tagSENT_CONTENT	and\tagSENT_CONTENT	Schapire\tagSENT_CONTENT	,\tagSENT_CONTENT	1998\tagSENT_CONTENT	)\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	subscript\tagSENT_CONTENT	"\tagSENT_CONTENT	r\tagSENT_CONTENT	"\tagSENT_CONTENT	means\tagSENT_CONTENT	selecting\tagSENT_CONTENT	the\tagSENT_CONTENT	learned\tagSENT_CONTENT	weight\tagSENT_CONTENT	vector\tagSENT_CONTENT	for\tagSENT_CONTENT	relation\tagSENT_CONTENT	r\tagSENT_CONTENT	∈\tagSENT_END	Missing\tagSECTITLE_START	Annotations\tagSECTITLE_END	Since\tagSENT_START	even\tagSENT_CONTENT	human\tagSENT_CONTENT	annotators\tagSENT_CONTENT	find\tagSENT_CONTENT	it\tagSENT_CONTENT	difficult\tagSENT_CONTENT	to\tagSENT_CONTENT	annotate\tagSENT_CONTENT	temporal\tagmetric	graphs\tagmetric	,\tagSENT_CONTENT	many\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	are\tagSENT_CONTENT	left\tagSENT_CONTENT	unspecified\tagSENT_CONTENT	by\tagSENT_CONTENT	annotators\tagSENT_CONTENT	(\tagSENT_CONTENT	compare\tagSENT_CONTENT	to\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Fourth\tagSENT_START	,\tagSENT_CONTENT	without\tagSENT_CONTENT	the\tagSENT_CONTENT	vague\tagSENT_CONTENT	classifier\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	predicted\tagSENT_CONTENT	temporal\tagSENT_CONTENT	graph\tagSENT_CONTENT	tends\tagSENT_CONTENT	to\tagSENT_CONTENT	become\tagSENT_CONTENT	more\tagSENT_CONTENT	densely\tagSENT_CONTENT	connected\tagSENT_CONTENT	,\tagSENT_CONTENT	thus\tagSENT_CONTENT	temporal_information_extraction\tagtask	can\tagSENT_CONTENT	be\tagSENT_CONTENT	more\tagSENT_CONTENT	effective\tagSENT_CONTENT	in\tagSENT_CONTENT	correcting\tagSENT_CONTENT	local\tagSENT_CONTENT	mistakes\tagSENT_CONTENT	.\tagSENT_END	Specifically\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	take\tagSENT_CONTENT	each\tagSENT_CONTENT	TLINK\tagSENT_CONTENT	produced\tagSENT_CONTENT	by\tagSENT_CONTENT	ILP\tagSENT_CONTENT	and\tagSENT_CONTENT	determine\tagSENT_CONTENT	whether\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	vague\tagSENT_CONTENT	using\tagSENT_CONTENT	its\tagSENT_CONTENT	relative\tagSENT_CONTENT	entropy\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	Kullback\tagSENT_CONTENT	-\tagSENT_CONTENT	Leibler\tagSENT_CONTENT	divergence\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	We\tagSENT_START	then\tagSENT_CONTENT	compare\tagSENT_CONTENT	δ\tagSENT_CONTENT	i\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	fixed\tagSENT_CONTENT	threshold\tagSENT_CONTENT	τ\tagSENT_CONTENT	to\tagSENT_CONTENT	determine\tagSENT_CONTENT	the\tagmetric	vagueness\tagmetric	of\tagSENT_CONTENT	this\tagSENT_CONTENT	TLINK\tagSENT_CONTENT	;\tagSENT_CONTENT	we\tagSENT_CONTENT	accept\tagSENT_CONTENT	its\tagSENT_CONTENT	originally\tagSENT_CONTENT	predicted\tagSENT_CONTENT	label\tagSENT_CONTENT	if\tagSENT_CONTENT	δ\tagSENT_END	Using\tagSENT_START	relative\tagSENT_CONTENT	entropy\tagSENT_CONTENT	here\tagSENT_CONTENT	is\tagSENT_CONTENT	intuitively\tagSENT_CONTENT	appealing\tagSENT_CONTENT	and\tagSENT_CONTENT	empirically\tagSENT_CONTENT	useful\tagSENT_CONTENT	as\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	temporal_information_extraction\tagtask	;\tagSENT_CONTENT	better\tagSENT_CONTENT	metrics\tagSENT_CONTENT	are\tagSENT_CONTENT	of\tagSENT_CONTENT	course\tagSENT_CONTENT	yet\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	designed\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Datasets\tagSECTITLE_END	Two\tagSENT_START	popular\tagSENT_CONTENT	augmentations\tagSENT_CONTENT	on\tagSENT_CONTENT	TB\tagSENT_CONTENT	are\tagSENT_CONTENT	temporal_information_extraction\tagtask	(\tagSENT_CONTENT	VC\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	TimebankDense\tagSENT_CONTENT	dataset\tagSENT_CONTENT	(\tagSENT_CONTENT	TD\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Therefore\tagSENT_START	,\tagSENT_CONTENT	some\tagSENT_CONTENT	statistics\tagSENT_CONTENT	on\tagSENT_CONTENT	them\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	in\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	Dataset\tagSECTITLE_END	Baseline\tagSECTITLE_START	Methods\tagSECTITLE_END	Results\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Discussion\tagSECTITLE_END	TE3\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	C\tagSECTITLE_CONTENT	-Relation\tagSECTITLE_CONTENT	Only\tagSECTITLE_END	Note\tagSENT_START	that\tagSENT_CONTENT	the\tagSENT_CONTENT	reported\tagSENT_CONTENT	numbers\tagSENT_CONTENT	below\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagmetric	temporal\tagmetric	awareness\tagmetric	scores\tagmetric	obtained\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	script\tagSENT_CONTENT	provided\tagSENT_CONTENT	in\tagSENT_CONTENT	TE3\tagSENT_CONTENT	.\tagSENT_END	Temporal\tagmetric	awareness\tagmetric	scores\tagmetric	given\tagSENT_CONTENT	gold\tagSENT_CONTENT	events\tagSENT_CONTENT	but\tagSENT_CONTENT	with\tagSENT_CONTENT	no\tagSENT_CONTENT	gold\tagSENT_CONTENT	pairs\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	S+I\tagSENT_CONTENT	methods\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	in\tagSENT_CONTENT	various\tagSENT_CONTENT	settings\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	fourth\tagSENT_CONTENT	column\tagSENT_CONTENT	indicates\tagSENT_CONTENT	the\tagSENT_CONTENT	annotation\tagSENT_CONTENT	sources\tagSENT_CONTENT	used\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	additional\tagSENT_CONTENT	unlabeled\tagSENT_CONTENT	dataset\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagmetric	parentheses\tagmetric	.\tagSENT_END	TE3\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	C\tagSECTITLE_END	It\tagSENT_START	confirms\tagSENT_CONTENT	our\tagSENT_CONTENT	assertion\tagSENT_CONTENT	that\tagSENT_CONTENT	how\tagSENT_CONTENT	to\tagSENT_CONTENT	handle\tagSENT_CONTENT	vague\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	is\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	issue\tagSENT_CONTENT	for\tagSENT_CONTENT	temporal_information_extraction\tagtask	.\tagSENT_END	(\tagSENT_START	line\tagSENT_CONTENT	7\tagSENT_CONTENT	is\tagSENT_CONTENT	higher\tagSENT_CONTENT	than\tagSENT_CONTENT	its\tagSENT_CONTENT	reported\tagSENT_CONTENT	values\tagSENT_CONTENT	in\tagSENT_CONTENT	TE3\tagSENT_CONTENT	because\tagSENT_CONTENT	of\tagSENT_CONTENT	later\tagmetric	changes\tagmetric	in\tagSENT_CONTENT	ClearTK\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	so\tagSENT_CONTENT	we\tagSENT_CONTENT	retrained\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	systems\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	and\tagSENT_CONTENT	results\tagSENT_CONTENT	are\tagSENT_CONTENT	shown\tagSENT_CONTENT	on\tagSENT_CONTENT	lines\tagSENT_CONTENT	8\tagSENT_CONTENT	-\tagSENT_CONTENT	9\tagSENT_CONTENT	.\tagSENT_END	Comparison\tagSECTITLE_START	with\tagSECTITLE_CONTENT	CAEVO\tagSECTITLE_END	In\tagSENT_START	,\tagSENT_CONTENT	CAEVO\tagSENT_CONTENT	was\tagSENT_CONTENT	reported\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	straightforward\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	including\tagSENT_CONTENT	the\tagSENT_CONTENT	vague\tagSENT_CONTENT	TLINKs\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagmetric	temporal\tagmetric	awareness\tagmetric	scores\tagmetric	were\tagSENT_CONTENT	used\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	explains\tagSENT_CONTENT	the\tagSENT_CONTENT	difference\tagSENT_CONTENT	between\tagSENT_CONTENT	line\tagSENT_CONTENT	11\tagSENT_CONTENT	in\tagSENT_CONTENT	and\tagSENT_CONTENT	what\tagSENT_CONTENT	was\tagSENT_CONTENT	reported\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	We\tagSENT_START	develop\tagSENT_CONTENT	a\tagSENT_CONTENT	structured\tagSENT_CONTENT	learning\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	identifying\tagSENT_CONTENT	temporal_information_extraction\tagtask	in\tagSENT_CONTENT	natural\tagSENT_CONTENT	language\tagSENT_CONTENT	text\tagSENT_CONTENT	and\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	it\tagSENT_CONTENT	captures\tagSENT_CONTENT	the\tagSENT_CONTENT	global\tagSENT_CONTENT	nature\tagSENT_CONTENT	of\tagSENT_CONTENT	this\tagSENT_CONTENT	problem\tagSENT_CONTENT	better\tagSENT_CONTENT	than\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	systems\tagSENT_CONTENT	do\tagSENT_CONTENT	.\tagSENT_END	
5071-translating-embeddings-for-modeling-multi-relational-data	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	consider\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	embedding\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	relational\tagSENT_CONTENT	data\tagSENT_CONTENT	in\tagSENT_CONTENT	low\tagSENT_CONTENT	-\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	vector\tagSENT_CONTENT	spaces\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	relation_prediction\tagtask	refers\tagSENT_CONTENT	to\tagSENT_CONTENT	directed\tagSENT_CONTENT	graphs\tagSENT_CONTENT	whose\tagSENT_CONTENT	nodes\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	edges\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	form\tagSENT_CONTENT	(\tagSENT_CONTENT	head\tagSENT_CONTENT	,\tagSENT_CONTENT	label\tagSENT_CONTENT	,\tagSENT_CONTENT	tail\tagSENT_CONTENT	)\tagSENT_END	Modeling\tagSENT_START	relation_prediction\tagtask	Following\tagSENT_START	the\tagSENT_CONTENT	success\tagSENT_CONTENT	of\tagSENT_CONTENT	user\tagSENT_CONTENT	/\tagSENT_CONTENT	item\tagSENT_CONTENT	clustering\tagSENT_CONTENT	or\tagSENT_CONTENT	matrix\tagSENT_CONTENT	factorization\tagSENT_CONTENT	techniques\tagSENT_CONTENT	in\tagSENT_CONTENT	collaborative\tagSENT_CONTENT	filtering\tagSENT_CONTENT	to\tagSENT_CONTENT	represent\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	trivial\tagSENT_CONTENT	similarities\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	connectivity\tagSENT_CONTENT	patterns\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	most\tagSENT_CONTENT	existing\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	multi\tagSENT_CONTENT	-\tagSENT_CONTENT	relational\tagSENT_CONTENT	data\tagSENT_CONTENT	have\tagSENT_CONTENT	been\tagSENT_CONTENT	designed\tagSENT_CONTENT	within\tagSENT_CONTENT	the\tagSENT_CONTENT	framework\tagSENT_CONTENT	of\tagSENT_CONTENT	relational\tagSENT_CONTENT	learning\tagSENT_CONTENT	from\tagSENT_CONTENT	latent\tagSENT_CONTENT	attributes\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	pointed\tagSENT_CONTENT	out\tagSENT_CONTENT	by\tagSENT_CONTENT	;\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	,\tagSENT_CONTENT	by\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	operating\tagSENT_CONTENT	on\tagSENT_CONTENT	latent\tagSENT_CONTENT	representations\tagSENT_CONTENT	(\tagSENT_CONTENT	or\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	constituents\tagSENT_CONTENT	(\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relationships\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	relation_prediction\tagtask	as\tagSENT_CONTENT	translations\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	embedding\tagSENT_CONTENT	space\tagSENT_END	relation_prediction\tagtask	behind\tagSENT_CONTENT	our\tagSENT_CONTENT	translation\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	parameterization\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	relationships\tagSENT_CONTENT	are\tagSENT_CONTENT	extremely\tagSENT_CONTENT	common\tagSENT_CONTENT	in\tagSENT_CONTENT	KBs\tagSENT_CONTENT	and\tagSENT_CONTENT	translations\tagSENT_CONTENT	are\tagSENT_CONTENT	the\tagSENT_CONTENT	natural\tagSENT_CONTENT	transformations\tagSENT_CONTENT	for\tagSENT_CONTENT	representing\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	Our\tagSENT_START	experiments\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	4\tagSENT_CONTENT	demonstrate\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	new\tagSENT_CONTENT	model\tagSENT_CONTENT	,\tagSENT_CONTENT	despite\tagSENT_CONTENT	its\tagSENT_CONTENT	simplicity\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	architecture\tagSENT_CONTENT	primarily\tagSENT_CONTENT	designed\tagSENT_CONTENT	for\tagSENT_CONTENT	modeling\tagSENT_CONTENT	hierarchies\tagSENT_CONTENT	,\tagSENT_CONTENT	ends\tagSENT_CONTENT	up\tagSENT_CONTENT	being\tagSENT_CONTENT	powerful\tagSENT_CONTENT	on\tagSENT_CONTENT	most\tagSENT_CONTENT	kinds\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	significantly\tagSENT_CONTENT	outperform\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	link\tagSENT_CONTENT	prediction\tagSENT_CONTENT	on\tagSENT_CONTENT	realworld\tagSENT_CONTENT	KBs\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	remainder\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	paper\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	describe\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	2\tagSENT_CONTENT	and\tagSENT_CONTENT	discuss\tagSENT_CONTENT	relation_prediction\tagtask	with\tagSENT_CONTENT	related\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	Section\tagSENT_CONTENT	3\tagSENT_CONTENT	.\tagSENT_END	Algorithm\tagSECTITLE_START	1\tagSECTITLE_CONTENT	Learning\tagSECTITLE_CONTENT	TransE\tagSECTITLE_END	5\tagSECTITLE_START	:\tagSECTITLE_END	6\tagSECTITLE_START	:\tagSECTITLE_END	7\tagSECTITLE_START	:\tagSECTITLE_END	Given\tagSENT_START	a\tagSENT_CONTENT	training\tagSENT_CONTENT	set\tagSENT_CONTENT	S\tagSENT_CONTENT	of\tagSENT_CONTENT	triplets\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	)\tagSENT_CONTENT	composed\tagSENT_CONTENT	of\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	h\tagSENT_CONTENT	,\tagSENT_CONTENT	t\tagSENT_CONTENT	∈\tagSENT_CONTENT	E\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	∈\tagSENT_CONTENT	L\tagSENT_CONTENT	(\tagSENT_CONTENT	the\tagSENT_CONTENT	set\tagSENT_CONTENT	of\tagSENT_CONTENT	relationships\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	learns\tagSENT_CONTENT	vector\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	the\tagSENT_CONTENT	relationships\tagSENT_CONTENT	.\tagSENT_END	relation_prediction\tagtask	or\tagSENT_CONTENT	norm\tagSENT_CONTENT	constraints\tagSENT_CONTENT	are\tagSENT_CONTENT	given\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	All\tagSENT_START	embeddings\tagSENT_CONTENT	for\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	are\tagSENT_CONTENT	first\tagSENT_CONTENT	initialized\tagSENT_CONTENT	following\tagSENT_CONTENT	the\tagSENT_CONTENT	random\tagSENT_CONTENT	procedure\tagSENT_CONTENT	proposed\tagSENT_CONTENT	in\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	algorithm\tagSENT_CONTENT	is\tagSENT_CONTENT	stopped\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	its\tagSENT_CONTENT	performance\tagSENT_CONTENT	on\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	of\tagSENT_START	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	;\tagSENT_CONTENT	k\tagSENT_CONTENT	the\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	dimension\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	basic\tagSENT_CONTENT	idea\tagSENT_CONTENT	is\tagSENT_CONTENT	that\tagSENT_CONTENT	when\tagSENT_CONTENT	two\tagSENT_CONTENT	entities\tagSENT_CONTENT	belong\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	triplet\tagSENT_CONTENT	,\tagSENT_CONTENT	their\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	should\tagSENT_CONTENT	be\tagSENT_CONTENT	close\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	other\tagSENT_CONTENT	in\tagSENT_CONTENT	some\tagSENT_CONTENT	subspace\tagSENT_CONTENT	that\tagSENT_CONTENT	depends\tagSENT_CONTENT	on\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	Considering\tagSENT_START	our\tagSENT_CONTENT	norm\tagSENT_CONTENT	constraints\tagSENT_CONTENT	(\tagSENT_CONTENT	h\tagSENT_CONTENT	2\tagSENT_CONTENT	2\tagSENT_CONTENT	=\tagSENT_CONTENT	t\tagSENT_CONTENT	2\tagSENT_CONTENT	2\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	(\tagSENT_CONTENT	1\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	which\tagSENT_CONTENT	2\tagSENT_CONTENT	2\tagSENT_CONTENT	does\tagSENT_CONTENT	not\tagSENT_CONTENT	play\tagSENT_CONTENT	any\tagSENT_CONTENT	role\tagSENT_CONTENT	in\tagSENT_CONTENT	comparing\tagSENT_CONTENT	corrupted\tagSENT_CONTENT	triplets\tagSENT_CONTENT	,\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	thus\tagSENT_CONTENT	involves\tagSENT_CONTENT	scoring\tagSENT_CONTENT	the\tagSENT_CONTENT	triplets\tagSENT_CONTENT	with\tagSENT_CONTENT	h\tagSENT_CONTENT	T\tagSENT_CONTENT	t\tagSENT_CONTENT	+\tagSENT_CONTENT	T\tagSENT_CONTENT	(\tagSENT_CONTENT	t\tagSENT_CONTENT	−\tagSENT_CONTENT	h\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	hence\tagSENT_CONTENT	corresponds\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	of\tagSENT_CONTENT	(\tagSENT_CONTENT	Equation\tagSENT_CONTENT	)\tagSENT_CONTENT	where\tagSENT_CONTENT	L\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	identity\tagSENT_CONTENT	matrix\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	=\tagSENT_CONTENT	1\tagSENT_CONTENT	=\tagSENT_CONTENT	−\tagSENT_CONTENT	2\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	Data\tagSECTITLE_START	sets\tagSECTITLE_END	Its\tagSENT_START	entities\tagSENT_CONTENT	(\tagSENT_CONTENT	termed\tagSENT_CONTENT	synsets\tagSENT_CONTENT	)\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	word\tagSENT_CONTENT	senses\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	define\tagSENT_CONTENT	lexical\tagSENT_CONTENT	relations\tagSENT_CONTENT	between\tagSENT_CONTENT	them\tagSENT_CONTENT	.\tagSENT_END	First\tagSENT_START	,\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	a\tagSENT_CONTENT	small\tagSENT_CONTENT	data\tagSENT_CONTENT	set\tagSENT_CONTENT	to\tagSENT_CONTENT	experiment\tagSENT_CONTENT	on\tagSENT_CONTENT	we\tagSENT_CONTENT	selected\tagSENT_CONTENT	the\tagSENT_CONTENT	subset\tagSENT_CONTENT	of\tagSENT_CONTENT	entities\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	also\tagSENT_CONTENT	present\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	Wikilinks\tagSENT_CONTENT	database\tagSENT_CONTENT	and\tagSENT_CONTENT	that\tagSENT_CONTENT	also\tagSENT_CONTENT	have\tagSENT_CONTENT	at\tagSENT_CONTENT	least\tagSENT_CONTENT	100\tagSENT_CONTENT	mentions\tagSENT_CONTENT	in\tagSENT_CONTENT	Freebase\tagSENT_CONTENT	(\tagSENT_CONTENT	for\tagSENT_CONTENT	both\tagSENT_CONTENT	entities\tagSENT_CONTENT	and\tagSENT_CONTENT	relation_prediction\tagtask	)\tagSENT_CONTENT	.\tagSENT_END	Experimental\tagSECTITLE_START	setup\tagSECTITLE_END	relation_prediction\tagtask	For\tagSENT_CONTENT	evaluation\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	following\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	report\tagSENT_CONTENT	mean\tagSENT_CONTENT	ranks\tagSENT_CONTENT	and\tagSENT_CONTENT	hits@10\tagmetric	according\tagSENT_CONTENT	to\tagSENT_CONTENT	both\tagSENT_CONTENT	settings\tagSENT_CONTENT	:\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	(\tagSENT_CONTENT	possibly\tagSENT_CONTENT	flawed\tagSENT_CONTENT	)\tagSENT_END	For\tagSENT_START	RESCAL\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	had\tagSENT_CONTENT	to\tagSENT_CONTENT	set\tagSENT_CONTENT	relation_prediction\tagtask	parameter\tagSENT_CONTENT	to\tagSENT_CONTENT	0\tagSENT_CONTENT	for\tagSENT_CONTENT	scalability\tagSENT_CONTENT	reasons\tagSENT_CONTENT	,\tagSENT_CONTENT	as\tagSENT_CONTENT	it\tagSENT_CONTENT	is\tagSENT_CONTENT	indicated\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	chose\tagSENT_CONTENT	the\tagSENT_CONTENT	latent\tagSENT_CONTENT	dimension\tagSENT_CONTENT	k\tagSENT_CONTENT	among\tagSENT_CONTENT	{\tagSENT_CONTENT	50\tagSENT_CONTENT	,\tagSENT_CONTENT	250\tagSENT_CONTENT	,\tagSENT_CONTENT	500\tagSENT_CONTENT	,\tagSENT_CONTENT	1000\tagSENT_CONTENT	,\tagSENT_CONTENT	2000\tagSENT_CONTENT	}\tagSENT_CONTENT	that\tagSENT_CONTENT	led\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	lowest\tagSENT_CONTENT	mean\tagSENT_END	The\tagSENT_START	dissimilarity\tagSENT_CONTENT	measured\tagSENT_CONTENT	was\tagSENT_CONTENT	set\tagSENT_CONTENT	either\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	L\tagSENT_CONTENT	1\tagSENT_CONTENT	or\tagSENT_CONTENT	L\tagSENT_CONTENT	2\tagSENT_CONTENT	distance\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	relation_prediction\tagtask	as\tagSENT_CONTENT	well\tagSENT_CONTENT	.\tagSENT_END	Link\tagSECTITLE_START	prediction\tagSECTITLE_END	As\tagSENT_START	expected\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	filtered\tagSENT_CONTENT	setting\tagSENT_CONTENT	provides\tagSENT_CONTENT	lower\tagSENT_CONTENT	mean\tagSENT_CONTENT	ranks\tagSENT_CONTENT	and\tagSENT_CONTENT	higher\tagSENT_CONTENT	hits@10\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	we\tagSENT_CONTENT	believe\tagSENT_CONTENT	area\tagSENT_CONTENT	clearer\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	methods\tagSENT_CONTENT	in\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	We\tagSENT_START	believe\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	good\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	TransE\tagSENT_CONTENT	is\tagSENT_CONTENT	due\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	appropriate\tagSENT_CONTENT	design\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	according\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	also\tagSENT_CONTENT	to\tagSENT_CONTENT	relation_prediction\tagtask	.\tagSENT_END	When\tagSENT_START	one\tagSENT_CONTENT	compares\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	TransE\tagSENT_CONTENT	and\tagSENT_CONTENT	Unstructured\tagSENT_CONTENT	(\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	TransE\tagSENT_CONTENT	without\tagSENT_CONTENT	translation\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	mean\tagSENT_CONTENT	ranks\tagSENT_CONTENT	of\tagSENT_CONTENT	Unstructured\tagSENT_CONTENT	appear\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	rather\tagSENT_CONTENT	good\tagSENT_CONTENT	(\tagSENT_CONTENT	best\tagSENT_CONTENT	runner\tagSENT_CONTENT	-\tagSENT_CONTENT	up\tagSENT_CONTENT	on\tagSENT_CONTENT	WN\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	hits@10\tagmetric	are\tagSENT_CONTENT	very\tagSENT_CONTENT	poor\tagSENT_CONTENT	.\tagSENT_END	INPUT\tagSECTITLE_START	(\tagSECTITLE_CONTENT	HEAD\tagSECTITLE_CONTENT	AND\tagSECTITLE_CONTENT	LABEL\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	PREDICTED\tagSECTITLE_CONTENT	TAILS\tagSECTITLE_END	Detailed\tagSENT_START	results\tagSENT_CONTENT	classifies\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	(\tagSENT_CONTENT	in\tagSENT_CONTENT	hits@10\tagmetric	)\tagSENT_CONTENT	on\tagSENT_CONTENT	FB15k\tagSENT_END	These\tagSENT_START	detailed\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	allow\tagSENT_CONTENT	relation_prediction\tagtask	and\tagSENT_CONTENT	understanding\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	behavior\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	Illustration\tagSENT_START	gives\tagSENT_CONTENT	examples\tagSENT_CONTENT	of\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	TransE\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	FB15k\tagSENT_CONTENT	test\tagSENT_CONTENT	set\tagSENT_CONTENT	(\tagSENT_CONTENT	predicting\tagSENT_CONTENT	tail\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Learning\tagSECTITLE_START	to\tagSECTITLE_CONTENT	predict\tagSECTITLE_CONTENT	new\tagSECTITLE_CONTENT	relationships\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	few\tagSECTITLE_CONTENT	examples\tagSECTITLE_END	To\tagSENT_START	that\tagSENT_CONTENT	end\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	randomly\tagSENT_CONTENT	selected\tagSENT_CONTENT	relation_prediction\tagtask	and\tagSENT_CONTENT	split\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	into\tagSENT_CONTENT	two\tagSENT_CONTENT	sets\tagSENT_CONTENT	:\tagSENT_CONTENT	a\tagSENT_CONTENT	set\tagSENT_CONTENT	(\tagSENT_CONTENT	named\tagSENT_CONTENT	FB15k-40rel\tagSENT_CONTENT	)\tagSENT_CONTENT	containing\tagSENT_CONTENT	all\tagSENT_CONTENT	triplets\tagSENT_CONTENT	with\tagSENT_CONTENT	these\tagSENT_CONTENT	40\tagSENT_CONTENT	relationships\tagSENT_CONTENT	and\tagSENT_CONTENT	another\tagSENT_CONTENT	set\tagSENT_CONTENT	(\tagSENT_CONTENT	FB15k\tagSENT_CONTENT	-\tagSENT_CONTENT	rest\tagSENT_CONTENT	)\tagSENT_CONTENT	containing\tagSENT_CONTENT	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	.\tagSENT_END	with\tagSENT_START	only\tagSENT_CONTENT	10\tagSENT_CONTENT	examples\tagSENT_CONTENT	of\tagSENT_CONTENT	anew\tagSENT_CONTENT	relationship\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagmetric	hits@10\tagmetric	is\tagSENT_CONTENT	already\tagSENT_CONTENT	18\tagSENT_CONTENT	%\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	improves\tagSENT_CONTENT	monotonically\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	number\tagSENT_CONTENT	of\tagSENT_CONTENT	provided\tagSENT_CONTENT	samples\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	future\tagSECTITLE_CONTENT	work\tagSECTITLE_END	We\tagSENT_START	proposed\tagSENT_CONTENT	anew\tagSENT_CONTENT	approach\tagSENT_CONTENT	to\tagSENT_CONTENT	learn\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	of\tagSENT_CONTENT	KBs\tagSENT_CONTENT	,\tagSENT_CONTENT	focusing\tagSENT_CONTENT	on\tagSENT_CONTENT	relation_prediction\tagtask	of\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	to\tagSENT_CONTENT	primarily\tagSENT_CONTENT	represent\tagSENT_CONTENT	hierarchical\tagSENT_CONTENT	relationships\tagSENT_CONTENT	.\tagSENT_END	Future\tagSENT_START	work\tagSENT_CONTENT	could\tagSENT_CONTENT	analyze\tagSENT_CONTENT	this\tagSENT_CONTENT	model\tagSENT_CONTENT	further\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	also\tagSENT_CONTENT	concentrates\tagSENT_CONTENT	on\tagSENT_CONTENT	exploiting\tagSENT_CONTENT	it\tagSENT_CONTENT	in\tagSENT_CONTENT	more\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	relation_prediction\tagtask	such\tagSENT_CONTENT	as\tagSENT_CONTENT	learning\tagSENT_CONTENT	word\tagSENT_CONTENT	representations\tagSENT_CONTENT	inspired\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	
1705.00108	title\tagSECTITLE_END	abstract\tagSECTITLE_END	However\tagSENT_START	,\tagSENT_CONTENT	inmost\tagSENT_CONTENT	cases\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	network\tagSENT_CONTENT	that\tagSENT_CONTENT	operates\tagSENT_CONTENT	on\tagSENT_CONTENT	word\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	representations\tagSENT_CONTENT	to\tagSENT_CONTENT	produce\tagSENT_CONTENT	named_entity_recognition\tagtask	is\tagSENT_CONTENT	trained\tagSENT_CONTENT	on\tagSENT_CONTENT	relatively\tagSENT_CONTENT	little\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	model\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	standard\tagSENT_CONTENT	datasets\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	NER\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	chunking\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	cases\tagSENT_CONTENT	achieve\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	surpassing\tagSENT_CONTENT	previous\tagSENT_CONTENT	systems\tagSENT_CONTENT	that\tagSENT_CONTENT	use\tagSENT_CONTENT	other\tagSENT_CONTENT	forms\tagSENT_CONTENT	of\tagSENT_CONTENT	transfer\tagSENT_CONTENT	or\tagSENT_CONTENT	joint\tagSENT_CONTENT	learning\tagSENT_CONTENT	with\tagSENT_CONTENT	additional\tagSENT_CONTENT	labeled\tagSENT_CONTENT	data\tagSENT_CONTENT	and\tagSENT_CONTENT	task\tagSENT_CONTENT	specific\tagSENT_CONTENT	gazetteers\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	Accordingly\tagSENT_START	,\tagSENT_CONTENT	current\tagSENT_CONTENT	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	models\tagSENT_CONTENT	typically\tagSENT_CONTENT	include\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	recurrent\tagSENT_CONTENT	neural\tagSENT_CONTENT	network\tagSENT_CONTENT	(\tagSENT_CONTENT	RNN\tagSENT_CONTENT	)\tagSENT_CONTENT	that\tagSENT_CONTENT	encodes\tagSENT_CONTENT	token\tagSENT_CONTENT	sequences\tagSENT_CONTENT	into\tagSENT_CONTENT	named_entity_recognition\tagtask	before\tagSENT_CONTENT	making\tagSENT_CONTENT	token\tagSENT_CONTENT	specific\tagSENT_CONTENT	predictions\tagSENT_CONTENT	(\tagSENT_CONTENT	.\tagSENT_END	As\tagSENT_START	named_entity_recognition\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	using\tagSENT_CONTENT	both\tagSENT_CONTENT	forward\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	LM\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	boosts\tagSENT_CONTENT	performance\tagSENT_CONTENT	over\tagSENT_CONTENT	a\tagSENT_CONTENT	forward\tagSENT_CONTENT	only\tagSENT_CONTENT	LM\tagSENT_CONTENT	.\tagSENT_END	Language\tagSECTITLE_START	model\tagSECTITLE_CONTENT	augmented\tagSECTITLE_CONTENT	sequence\tagSECTITLE_CONTENT	taggers\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	TagLM\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	2.1\tagSECTITLE_CONTENT	Overview\tagSECTITLE_END	Baseline\tagSECTITLE_START	sequence\tagSECTITLE_CONTENT	tagging\tagSECTITLE_CONTENT	model\tagSECTITLE_END	To\tagSENT_START	learn\tagSENT_CONTENT	named_entity_recognition\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	employ\tagSENT_CONTENT	multiple\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	named_entity_recognition\tagtask	,\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	state\tagSENT_CONTENT	h\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	of\tagSENT_CONTENT	RNN\tagSENT_CONTENT	layer\tagSENT_CONTENT	i\tagSENT_CONTENT	is\tagSENT_CONTENT	formed\tagSENT_CONTENT	by\tagSENT_CONTENT	concatenating\tagSENT_CONTENT	the\tagSENT_CONTENT	hidden\tagSENT_CONTENT	states\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	(\tagSENT_CONTENT	−\tagSENT_CONTENT	→\tagSENT_CONTENT	h\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_CONTENT	i\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	backward\tagSENT_CONTENT	(\tagSENT_CONTENT	←\tagSENT_CONTENT	−\tagSENT_CONTENT	h\tagSENT_CONTENT	k\tagSENT_CONTENT	,\tagSENT_END	Bidirectional\tagSECTITLE_START	LM\tagSECTITLE_END	Recent\tagSENT_START	state\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	art\tagSENT_CONTENT	neural\tagSENT_CONTENT	language\tagSENT_CONTENT	models\tagSENT_CONTENT	)\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	similar\tagSENT_CONTENT	architecture\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagger\tagSENT_CONTENT	where\tagSENT_CONTENT	they\tagSENT_CONTENT	pass\tagSENT_CONTENT	named_entity_recognition\tagtask	(\tagSENT_CONTENT	either\tagSENT_CONTENT	from\tagSENT_CONTENT	a\tagSENT_CONTENT	CNN\tagSENT_CONTENT	over\tagSENT_CONTENT	characters\tagSENT_CONTENT	or\tagSENT_CONTENT	as\tagSENT_CONTENT	token\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	)\tagSENT_CONTENT	through\tagSENT_CONTENT	multiple\tagSENT_CONTENT	layers\tagSENT_CONTENT	of\tagSENT_CONTENT	LSTMs\tagSENT_CONTENT	to\tagSENT_CONTENT	embed\tagSENT_CONTENT	the\tagSENT_CONTENT	history\tagSENT_END	Combining\tagSECTITLE_START	LM\tagSECTITLE_CONTENT	with\tagSECTITLE_CONTENT	sequence\tagSECTITLE_CONTENT	model\tagSECTITLE_END	where\tagSENT_START	f\tagmetric	is\tagSENT_CONTENT	a\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linear\tagSENT_CONTENT	function\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Experiments\tagSECTITLE_END	We\tagSENT_START	report\tagSENT_CONTENT	the\tagSENT_CONTENT	official\tagSENT_CONTENT	evaluation\tagSENT_CONTENT	metric\tagSENT_CONTENT	(\tagSENT_CONTENT	micro\tagSENT_CONTENT	-\tagSENT_CONTENT	averaged\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	regularization\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	25\tagSENT_CONTENT	%\tagSENT_CONTENT	dropout\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	GRU\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	not\tagSENT_CONTENT	to\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Following\tagSENT_START	we\tagSENT_CONTENT	added\tagSENT_CONTENT	50\tagSENT_CONTENT	%\tagSENT_CONTENT	dropout\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	character\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	each\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	layer\tagSENT_CONTENT	(\tagSENT_CONTENT	but\tagSENT_CONTENT	named_entity_recognition\tagtask	)\tagSENT_END	Following\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	train\tagSENT_CONTENT	named_entity_recognition\tagtask	ten\tagSENT_CONTENT	times\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	random\tagSENT_CONTENT	seeds\tagSENT_CONTENT	and\tagSENT_CONTENT	report\tagSENT_CONTENT	the\tagSENT_CONTENT	mean\tagSENT_CONTENT	and\tagSENT_CONTENT	standard\tagSENT_CONTENT	deviation\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	.\tagSENT_END	Overall\tagSECTITLE_START	system\tagSECTITLE_CONTENT	results\tagSECTITLE_END	Importantly\tagSENT_START	,\tagSENT_CONTENT	the\tagSENT_CONTENT	LM\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	amounts\tagSENT_CONTENT	to\tagSENT_CONTENT	an\tagSENT_CONTENT	average\tagSENT_CONTENT	absolute\tagSENT_CONTENT	improvement\tagSENT_CONTENT	of\tagSENT_CONTENT	1.06\tagSENT_CONTENT	and\tagSENT_CONTENT	1.37\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	NER\tagSENT_CONTENT	and\tagSENT_CONTENT	Chunking\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	respectively\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	Chunking\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	previous\tagSENT_CONTENT	work\tagSENT_CONTENT	has\tagSENT_CONTENT	reported\tagSENT_CONTENT	from\tagSENT_CONTENT	0.28\tagSENT_CONTENT	to\tagSENT_CONTENT	0.75\tagSENT_CONTENT	improvement\tagSENT_CONTENT	in\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	when\tagSENT_CONTENT	including\tagSENT_CONTENT	supervised\tagSENT_CONTENT	labels\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	PTB\tagSENT_CONTENT	POS\tagSENT_CONTENT	tags\tagSENT_CONTENT	or\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Analysis\tagSECTITLE_END	Does\tagSECTITLE_START	it\tagSECTITLE_CONTENT	matter\tagSECTITLE_CONTENT	which\tagSECTITLE_CONTENT	language\tagSECTITLE_CONTENT	model\tagSECTITLE_CONTENT	to\tagSECTITLE_CONTENT	use\tagSECTITLE_CONTENT	?\tagSECTITLE_END	LM\tagSENT_START	size\tagSENT_CONTENT	is\tagSENT_CONTENT	important\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	replacing\tagSENT_CONTENT	the\tagSENT_CONTENT	forward\tagSENT_CONTENT	LSTM-2048\tagSENT_CONTENT	-\tagSENT_CONTENT	512\tagSENT_CONTENT	with\tagSENT_CONTENT	CNN\tagSENT_CONTENT	-\tagSENT_CONTENT	BIG\tagSENT_CONTENT	-\tagSENT_CONTENT	LSTM\tagSENT_CONTENT	(\tagSENT_CONTENT	test\tagSENT_CONTENT	perplexities\tagSENT_CONTENT	of\tagSENT_CONTENT	47.7\tagSENT_CONTENT	to\tagSENT_CONTENT	30.0\tagSENT_CONTENT	on\tagSENT_CONTENT	1B\tagSENT_CONTENT	Word\tagSENT_CONTENT	Benchmark\tagSENT_CONTENT	)\tagSENT_CONTENT	improves\tagSENT_CONTENT	F\tagmetric	1\tagSENT_CONTENT	by\tagSENT_CONTENT	0.26\tagSENT_CONTENT	-0.31\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	about\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	as\tagSENT_CONTENT	adding\tagSENT_CONTENT	backward\tagSENT_CONTENT	LM\tagSENT_CONTENT	.\tagSENT_END	30.0\tagSENT_START	47.3\tagSENT_CONTENT	91.93\tagSENT_CONTENT	±\tagSENT_CONTENT	0.19\tagSENT_CONTENT	set\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	decreased\tagSENT_CONTENT	the\tagSENT_CONTENT	model\tagSENT_CONTENT	size\tagSENT_CONTENT	to\tagSENT_CONTENT	512\tagSENT_CONTENT	hidden\tagSENT_CONTENT	units\tagSENT_CONTENT	with\tagSENT_CONTENT	named_entity_recognition\tagtask	and\tagSENT_CONTENT	normalized\tagSENT_CONTENT	tokens\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	same\tagSENT_CONTENT	manner\tagSENT_CONTENT	as\tagSENT_CONTENT	input\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	sequence\tagSENT_CONTENT	tagging\tagSENT_CONTENT	model\tagSENT_CONTENT	(\tagSENT_CONTENT	lower\tagSENT_CONTENT	-\tagSENT_CONTENT	cased\tagSENT_CONTENT	,\tagSENT_CONTENT	with\tagSENT_CONTENT	all\tagSENT_CONTENT	digits\tagSENT_CONTENT	replaced\tagSENT_CONTENT	with\tagSENT_CONTENT	0\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	this\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	TagLM\tagSENT_CONTENT	increased\tagSENT_CONTENT	F\tagSENT_CONTENT	1\tagSENT_CONTENT	on\tagSENT_CONTENT	the\tagSENT_CONTENT	development\tagSENT_CONTENT	set\tagSENT_CONTENT	by\tagSENT_CONTENT	4.12\tagSENT_CONTENT	%\tagSENT_CONTENT	(\tagSENT_CONTENT	from\tagSENT_CONTENT	49.93\tagSENT_CONTENT	to\tagSENT_CONTENT	to\tagSENT_CONTENT	54.05\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	over\tagSENT_CONTENT	our\tagSENT_CONTENT	baseline\tagSENT_CONTENT	without\tagSENT_CONTENT	LM\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	and\tagSENT_CONTENT	it\tagSENT_CONTENT	was\tagSENT_CONTENT	a\tagSENT_CONTENT	major\tagSENT_CONTENT	component\tagSENT_CONTENT	in\tagSENT_CONTENT	our\tagSENT_CONTENT	winning\tagSENT_CONTENT	submission\tagSENT_CONTENT	to\tagSENT_CONTENT	ScienceIE\tagSENT_CONTENT	,\tagSENT_CONTENT	Scenario\tagSENT_CONTENT	1\tagSENT_END	Related\tagSECTITLE_START	work\tagSECTITLE_END	Most\tagSENT_START	similar\tagSENT_CONTENT	to\tagSENT_CONTENT	our\tagSENT_CONTENT	formulation\tagSENT_CONTENT	,\tagSENT_CONTENT	used\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	neural\tagSENT_CONTENT	LM\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	statistical\tagSENT_CONTENT	machine\tagSENT_CONTENT	translation\tagSENT_CONTENT	system\tagSENT_CONTENT	for\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	also\tagSENT_START	used\tagSENT_CONTENT	a\tagSENT_CONTENT	bidirectional\tagSENT_CONTENT	n\tagSENT_CONTENT	-\tagSENT_CONTENT	gram\tagSENT_CONTENT	LM\tagSENT_CONTENT	for\tagSENT_CONTENT	handwriting\tagSENT_CONTENT	named_entity_recognition\tagtask	.\tagSENT_END	Conclusion\tagSECTITLE_END	
1511.00830	title\tagSECTITLE_END	abstract\tagSECTITLE_END	We\tagSENT_START	investigate\tagSENT_CONTENT	the\tagSENT_CONTENT	problem\tagSENT_CONTENT	of\tagSENT_CONTENT	learning\tagSENT_CONTENT	representations\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	invariant\tagSENT_CONTENT	to\tagSENT_CONTENT	certain\tagSENT_CONTENT	nuisance\tagSENT_CONTENT	or\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	variation\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	while\tagSENT_CONTENT	retaining\tagSENT_CONTENT	as\tagSENT_CONTENT	much\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	remaining\tagSENT_CONTENT	information\tagSENT_CONTENT	as\tagSENT_CONTENT	possible\tagSENT_CONTENT	.\tagSENT_END	INTRODUCTION\tagSECTITLE_END	Many\tagSENT_START	machine\tagSENT_CONTENT	learning\tagSENT_CONTENT	algorithms\tagSENT_CONTENT	can\tagSENT_CONTENT	be\tagSENT_CONTENT	understood\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	way\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	nonlinear\tagSENT_CONTENT	dimensional\tagSENT_CONTENT	reduction\tagSENT_CONTENT	and\tagSENT_CONTENT	latent\tagSENT_CONTENT	Dirichlet\tagSENT_CONTENT	allocation\tagSENT_CONTENT	are\tagSENT_CONTENT	all\tagSENT_CONTENT	models\tagSENT_CONTENT	that\tagSENT_CONTENT	extract\tagSENT_CONTENT	informative\tagSENT_CONTENT	factors\tagSENT_CONTENT	(\tagSENT_CONTENT	dimensions\tagSENT_CONTENT	,\tagSENT_CONTENT	causes\tagSENT_CONTENT	,\tagSENT_CONTENT	topics\tagSENT_CONTENT	)\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	often\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	to\tagSENT_CONTENT	visualize\tagSENT_CONTENT	the\tagSENT_CONTENT	data\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	other\tagSENT_CONTENT	words\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	want\tagSENT_CONTENT	a\tagSENT_CONTENT	latent\tagSENT_CONTENT	representation\tagSENT_CONTENT	z\tagSENT_CONTENT	that\tagSENT_CONTENT	is\tagSENT_CONTENT	maximally\tagSENT_CONTENT	informative\tagSENT_CONTENT	about\tagSENT_CONTENT	an\tagSENT_CONTENT	observed\tagSENT_CONTENT	random\tagSENT_CONTENT	variable\tagSENT_CONTENT	y\tagSENT_CONTENT	(\tagSENT_CONTENT	e.g.\tagSENT_CONTENT	,\tagSENT_CONTENT	class\tagSENT_CONTENT	label\tagSENT_CONTENT	)\tagSENT_CONTENT	while\tagSENT_CONTENT	minimally\tagSENT_CONTENT	informative\tagSENT_CONTENT	about\tagSENT_CONTENT	a\tagSENT_CONTENT	sensitive\tagSENT_CONTENT	or\tagSENT_CONTENT	nuisance\tagSENT_CONTENT	variable\tagSENT_CONTENT	s.\tagSENT_CONTENT	By\tagSENT_CONTENT	treating\tagSENT_CONTENT	s\tagSENT_CONTENT	as\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	sis\tagSENT_CONTENT	correlated\tagSENT_CONTENT	with\tagSENT_CONTENT	our\tagSENT_CONTENT	objective\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	are\tagSENT_CONTENT	dealing\tagSENT_CONTENT	with\tagSENT_CONTENT	"\tagSENT_CONTENT	fair\tagSENT_CONTENT	representations\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	a\tagSENT_CONTENT	problem\tagSENT_CONTENT	previously\tagSENT_CONTENT	considered\tagSENT_CONTENT	by\tagSENT_CONTENT	.\tagSENT_END	These\tagSENT_START	models\tagSENT_CONTENT	can\tagSENT_CONTENT	naturally\tagSENT_CONTENT	encourage\tagSENT_CONTENT	separation\tagSENT_CONTENT	between\tagSENT_CONTENT	latent\tagSENT_CONTENT	variables\tagSENT_CONTENT	z\tagSENT_CONTENT	and\tagSENT_CONTENT	sentiment_analysis\tagtask	s\tagSENT_CONTENT	by\tagSENT_CONTENT	using\tagSENT_CONTENT	factorized\tagSENT_CONTENT	priors\tagSENT_CONTENT	p(s)p(z\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	SEMI\tagSECTITLE_START	-\tagSECTITLE_CONTENT	SUPERVISED\tagSECTITLE_CONTENT	MODEL\tagSECTITLE_END	This\tagSENT_START	can\tagSENT_CONTENT	be\tagSENT_CONTENT	quite\tagSENT_CONTENT	simply\tagSENT_CONTENT	achieved\tagSENT_CONTENT	by\tagSENT_CONTENT	introducing\tagSENT_CONTENT	a\tagSENT_CONTENT	second\tagSENT_CONTENT	"\tagSENT_CONTENT	layer\tagSENT_CONTENT	"\tagSENT_CONTENT	of\tagSENT_CONTENT	sentiment_analysis\tagtask	to\tagSENT_CONTENT	our\tagSENT_CONTENT	generative\tagSENT_CONTENT	model\tagSENT_CONTENT	where\tagSENT_CONTENT	we\tagSENT_CONTENT	try\tagSENT_CONTENT	to\tagSENT_CONTENT	correlate\tagSENT_CONTENT	z\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	prediction\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	FURTHER\tagSECTITLE_START	INVARIANCE\tagSECTITLE_CONTENT	VIA\tagSECTITLE_CONTENT	MAXIMUM\tagSECTITLE_CONTENT	MEAN\tagSECTITLE_CONTENT	DISCREPANCY\tagSECTITLE_END	In\tagSENT_START	particular\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	can\tagSENT_CONTENT	happen\tagSENT_CONTENT	if\tagSENT_CONTENT	the\tagSENT_CONTENT	label\tagSENT_CONTENT	y\tagSENT_CONTENT	is\tagSENT_CONTENT	correlated\tagSENT_CONTENT	with\tagSENT_CONTENT	sentiment_analysis\tagtask	,\tagSENT_CONTENT	which\tagSENT_CONTENT	can\tagSENT_CONTENT	allow\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	s\tagSENT_CONTENT	to\tagSENT_CONTENT	"\tagSENT_CONTENT	leak\tagSENT_CONTENT	"\tagSENT_CONTENT	into\tagSENT_CONTENT	the\tagSENT_CONTENT	posterior\tagSENT_CONTENT	.\tagSENT_END	MAXIMUM\tagSECTITLE_START	MEAN\tagSECTITLE_CONTENT	DISCREPANCY\tagSECTITLE_END	FAST\tagSECTITLE_START	MMD\tagSECTITLE_CONTENT	VIA\tagSECTITLE_CONTENT	RANDOM\tagSECTITLE_CONTENT	FOURIER\tagSECTITLE_CONTENT	FEATURES\tagSECTITLE_END	Instead\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	use\tagSENT_CONTENT	random\tagmetric	kitchen\tagmetric	sinks\tagmetric	)\tagSENT_CONTENT	to\tagSENT_CONTENT	compute\tagSENT_CONTENT	a\tagSENT_CONTENT	feature\tagSENT_CONTENT	expansion\tagSENT_CONTENT	such\tagSENT_CONTENT	that\tagSENT_CONTENT	computing\tagSENT_CONTENT	the\tagSENT_CONTENT	estimator\tagSENT_CONTENT	(\tagSENT_CONTENT	6\tagSENT_CONTENT	)\tagSENT_CONTENT	approximates\tagSENT_CONTENT	the\tagSENT_CONTENT	full\tagSENT_CONTENT	MMD\tagSENT_CONTENT	(\tagSENT_CONTENT	7\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	have\tagSENT_START	successfully\tagSENT_CONTENT	applied\tagSENT_CONTENT	the\tagSENT_CONTENT	idea\tagSENT_CONTENT	of\tagSENT_CONTENT	using\tagSENT_CONTENT	random\tagmetric	kitchen\tagmetric	sinks\tagmetric	to\tagSENT_CONTENT	approximate\tagSENT_CONTENT	MMD\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTS\tagSECTITLE_END	Furthermore\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	also\tagSENT_CONTENT	experimented\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	Amazon\tagSENT_CONTENT	reviews\tagSENT_CONTENT	dataset\tagSENT_CONTENT	to\tagSENT_CONTENT	make\tagSENT_CONTENT	a\tagmetric	connection\tagmetric	with\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	domain\tagSENT_CONTENT	-\tagSENT_CONTENT	adaptation\tagSENT_CONTENT	"\tagSENT_CONTENT	literature\tagSENT_CONTENT	.\tagSENT_END	DATASETS\tagSECTITLE_END	It\tagSENT_START	is\tagSENT_CONTENT	composed\tagSENT_CONTENT	from\tagSENT_CONTENT	text\tagSENT_CONTENT	reviews\tagSENT_CONTENT	about\tagSENT_CONTENT	particular\tagSENT_CONTENT	products\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	each\tagSENT_CONTENT	product\tagSENT_CONTENT	belongs\tagSENT_CONTENT	to\tagSENT_CONTENT	one\tagSENT_CONTENT	out\tagSENT_CONTENT	of\tagSENT_CONTENT	four\tagSENT_CONTENT	different\tagSENT_CONTENT	domains\tagSENT_CONTENT	:\tagSENT_CONTENT	"\tagSENT_CONTENT	books\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagSENT_CONTENT	dvd\tagSENT_CONTENT	"\tagSENT_CONTENT	,\tagSENT_CONTENT	"\tagmetric	electronics\tagmetric	"\tagSENT_CONTENT	and\tagSENT_CONTENT	"\tagmetric	kitchen\tagmetric	"\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	labels\tagSENT_CONTENT	y\tagSENT_CONTENT	correspond\tagSENT_CONTENT	to\tagSENT_CONTENT	sentiment_analysis\tagtask	of\tagSENT_CONTENT	each\tagSENT_CONTENT	review\tagSENT_CONTENT	,\tagSENT_CONTENT	i.e.\tagSENT_CONTENT	either\tagSENT_CONTENT	positive\tagSENT_CONTENT	or\tagSENT_CONTENT	negative\tagSENT_CONTENT	.\tagSENT_END	EXPERIMENTAL\tagSECTITLE_START	SETUP\tagSECTITLE_END	To\tagSENT_START	measure\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	yin\tagSENT_CONTENT	the\tagSENT_CONTENT	results\tagSENT_CONTENT	below\tagSENT_CONTENT	we\tagSENT_CONTENT	similarly\tagSENT_CONTENT	used\tagSENT_CONTENT	the\tagSENT_CONTENT	LFR\tagSENT_CONTENT	model\tagSENT_CONTENT	predictions\tagSENT_CONTENT	.\tagSENT_END	RESULTS\tagSECTITLE_END	FAIR\tagSECTITLE_START	CLASSIFICATION\tagSECTITLE_END	Since\tagSENT_START	we\tagSENT_CONTENT	are\tagSENT_CONTENT	dealing\tagSENT_CONTENT	with\tagSENT_CONTENT	the\tagSENT_CONTENT	"\tagSENT_CONTENT	fair\tagSENT_CONTENT	"\tagSENT_CONTENT	classification\tagSENT_CONTENT	scenario\tagSENT_CONTENT	here\tagSENT_CONTENT	,\tagSENT_CONTENT	low\tagmetric	accuracy\tagmetric	and\tagSENT_CONTENT	discrimination\tagSENT_CONTENT	against\tagSENT_CONTENT	sis\tagSENT_CONTENT	more\tagSENT_CONTENT	important\tagSENT_CONTENT	than\tagSENT_CONTENT	the\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	y\tagSENT_CONTENT	(\tagSENT_CONTENT	as\tagSENT_CONTENT	long\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	do\tagSENT_CONTENT	not\tagSENT_CONTENT	produce\tagSENT_CONTENT	degenerate\tagSENT_CONTENT	representations\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Despite\tagSENT_START	the\tagSENT_CONTENT	fact\tagSENT_CONTENT	that\tagSENT_CONTENT	LFR\tagSENT_CONTENT	appears\tagSENT_CONTENT	to\tagSENT_CONTENT	give\tagSENT_CONTENT	the\tagSENT_CONTENT	best\tagSENT_CONTENT	tradeoff\tagSENT_CONTENT	between\tagSENT_CONTENT	accuracy\tagmetric	and\tagSENT_CONTENT	discrimination\tagSENT_CONTENT	,\tagSENT_CONTENT	it\tagSENT_CONTENT	appears\tagSENT_CONTENT	to\tagSENT_CONTENT	retain\tagSENT_CONTENT	information\tagSENT_CONTENT	about\tagSENT_CONTENT	sin\tagSENT_CONTENT	its\tagSENT_CONTENT	representation\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	is\tagSENT_CONTENT	discovered\tagSENT_CONTENT	from\tagSENT_CONTENT	the\tagSENT_CONTENT	random\tagSENT_CONTENT	forest\tagSENT_CONTENT	classifier\tagSENT_CONTENT	.\tagSENT_END	The\tagSENT_START	MMD\tagSENT_CONTENT	penalty\tagSENT_CONTENT	in\tagSENT_CONTENT	VFAE\tagSENT_CONTENT	did\tagSENT_CONTENT	seem\tagSENT_CONTENT	improve\tagSENT_CONTENT	the\tagSENT_CONTENT	discrimination\tagSENT_CONTENT	scores\tagSENT_CONTENT	over\tagSENT_CONTENT	the\tagSENT_CONTENT	original\tagSENT_CONTENT	VAE\tagSENT_CONTENT	,\tagSENT_CONTENT	while\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	the\tagSENT_CONTENT	labels\tagSENT_CONTENT	y\tagSENT_CONTENT	remained\tagSENT_CONTENT	similar\tagSENT_CONTENT	.\tagSENT_END	DOMAIN\tagSECTITLE_START	ADAPTATION\tagSECTITLE_END	Our\tagSENT_START	model\tagSENT_CONTENT	was\tagSENT_CONTENT	successful\tagSENT_CONTENT	in\tagSENT_CONTENT	factoring\tagSENT_CONTENT	out\tagSENT_CONTENT	the\tagSENT_CONTENT	domain\tagSENT_CONTENT	information\tagSENT_CONTENT	,\tagSENT_CONTENT	since\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	,\tagSENT_CONTENT	measured\tagSENT_CONTENT	both\tagSENT_CONTENT	linearly\tagSENT_CONTENT	(\tagSENT_CONTENT	LR\tagSENT_CONTENT	)\tagSENT_CONTENT	and\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linearly\tagSENT_CONTENT	(\tagSENT_CONTENT	RF\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	was\tagSENT_CONTENT	towards\tagSENT_CONTENT	random\tagSENT_CONTENT	chance\tagSENT_CONTENT	(\tagSENT_CONTENT	which\tagSENT_CONTENT	for\tagSENT_CONTENT	this\tagSENT_CONTENT	dataset\tagSENT_CONTENT	is\tagSENT_CONTENT	0.5\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	LEARNING\tagSECTITLE_START	INVARIANT\tagSECTITLE_CONTENT	REPRESENTATIONS\tagSECTITLE_END	As\tagSENT_START	soon\tagSENT_CONTENT	as\tagSENT_CONTENT	we\tagSENT_CONTENT	utilize\tagSENT_CONTENT	our\tagSENT_CONTENT	VFAE\tagSENT_CONTENT	model\tagSENT_CONTENT	we\tagSENT_CONTENT	simultaneously\tagSENT_CONTENT	decrease\tagSENT_CONTENT	the\tagmetric	accuracy\tagmetric	on\tagSENT_CONTENT	s\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	96\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	about\tagSENT_CONTENT	50\tagSENT_CONTENT	%\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	increase\tagSENT_CONTENT	our\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	on\tagSENT_CONTENT	y\tagSENT_CONTENT	,\tagSENT_CONTENT	from\tagSENT_CONTENT	78\tagSENT_CONTENT	%\tagSENT_CONTENT	to\tagSENT_CONTENT	about\tagSENT_CONTENT	85\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	CONCLUSION\tagSECTITLE_END	We\tagSENT_START	further\tagSENT_CONTENT	use\tagSENT_CONTENT	a\tagSENT_CONTENT	Maximum\tagSENT_CONTENT	Mean\tagSENT_CONTENT	Discrepancy\tagSENT_CONTENT	regularizer\tagSENT_CONTENT	in\tagSENT_CONTENT	order\tagSENT_CONTENT	to\tagSENT_CONTENT	further\tagSENT_CONTENT	promote\tagSENT_CONTENT	invariance\tagSENT_CONTENT	in\tagSENT_CONTENT	the\tagSENT_CONTENT	posterior\tagSENT_CONTENT	distribution\tagSENT_CONTENT	over\tagSENT_CONTENT	sentiment_analysis\tagtask	.\tagSENT_END	A\tagSECTITLE_START	DISCRIMINATION\tagSECTITLE_CONTENT	METRICS\tagSECTITLE_END	B\tagSECTITLE_START	PROXY\tagSECTITLE_CONTENT	A\tagSECTITLE_CONTENT	-\tagSECTITLE_CONTENT	DISTANCE\tagSECTITLE_CONTENT	(\tagSECTITLE_CONTENT	PAD\tagSECTITLE_CONTENT	)\tagSECTITLE_CONTENT	FOR\tagSECTITLE_CONTENT	AMAZON\tagSECTITLE_CONTENT	REVIEWS\tagSECTITLE_CONTENT	DATASET\tagSECTITLE_END	
P18-2058	title\tagSECTITLE_END	Jointly\tagSENT_START	Predicting\tagSENT_CONTENT	Predicates\tagSENT_CONTENT	and\tagSENT_CONTENT	Arguments\tagSENT_CONTENT	in\tagSENT_CONTENT	semantic_role_labeling\tagtask	abstract\tagSECTITLE_END	semantic_role_labeling\tagtask	are\tagSENT_CONTENT	very\tagSENT_CONTENT	high\tagSENT_CONTENT	performing\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	assume\tagSENT_CONTENT	gold\tagSENT_CONTENT	predicates\tagSENT_CONTENT	as\tagSENT_CONTENT	part\tagSENT_CONTENT	of\tagSENT_CONTENT	the\tagSENT_CONTENT	input\tagSENT_CONTENT	and\tagSENT_CONTENT	can\tagSENT_CONTENT	not\tagSENT_CONTENT	incorporate\tagSENT_CONTENT	span\tagSENT_CONTENT	-\tagSENT_CONTENT	level\tagSENT_CONTENT	features\tagSENT_CONTENT	.\tagSENT_END	Introduction\tagSECTITLE_END	semantic_role_labeling\tagtask	labeling\tagSENT_CONTENT	(\tagSENT_CONTENT	SRL\tagSENT_CONTENT	)\tagSENT_CONTENT	captures\tagSENT_CONTENT	predicateargument\tagSENT_CONTENT	relations\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	"\tagSENT_CONTENT	who\tagSENT_CONTENT	did\tagSENT_CONTENT	what\tagSENT_CONTENT	to\tagSENT_CONTENT	whom\tagSENT_CONTENT	.\tagSENT_END	It\tagSENT_START	also\tagSENT_CONTENT	reinforces\tagSENT_CONTENT	the\tagSENT_CONTENT	strong\tagSENT_CONTENT	performance\tagSENT_CONTENT	of\tagSENT_CONTENT	similar\tagSENT_CONTENT	span\tagSENT_CONTENT	embedding\tagSENT_CONTENT	methods\tagSENT_CONTENT	for\tagSENT_CONTENT	coreference\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	suggesting\tagSENT_CONTENT	that\tagSENT_CONTENT	this\tagSENT_CONTENT	style\tagSENT_CONTENT	of\tagSENT_CONTENT	models\tagSENT_CONTENT	could\tagSENT_CONTENT	be\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	other\tagSENT_CONTENT	span\tagSENT_CONTENT	-\tagSENT_CONTENT	span\tagSENT_CONTENT	relation\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	semantic_role_labeling\tagtask	,\tagSENT_CONTENT	relation\tagSENT_CONTENT	extraction\tagSENT_CONTENT	(\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	QA\tagSENT_CONTENT	-\tagSENT_CONTENT	SRL\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	i\tagSENT_START	≤\tagSENT_CONTENT	j\tagSENT_CONTENT	≤\tagSENT_CONTENT	n\tagSENT_CONTENT	}\tagSENT_CONTENT	contains\tagSENT_CONTENT	all\tagSENT_CONTENT	the\tagSENT_CONTENT	spans\tagSENT_CONTENT	(\tagSENT_CONTENT	arguments\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	L\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	space\tagSENT_CONTENT	of\tagSENT_CONTENT	semantic_role_labeling\tagtask	,\tagSENT_CONTENT	including\tagSENT_CONTENT	semantic_role_labeling\tagtask	indicating\tagSENT_CONTENT	no\tagSENT_CONTENT	relation\tagSENT_CONTENT	.\tagSENT_END	Neural\tagSECTITLE_START	Architecture\tagSECTITLE_END	Experiments\tagSECTITLE_END	SRL\tagSECTITLE_START	-\tagSECTITLE_CONTENT	Violations\tagSECTITLE_END	Conclusion\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Future\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	
D15-1279	title\tagSECTITLE_END	abstract\tagSECTITLE_END	Such\tagSENT_START	architecture\tagSENT_CONTENT	allows\tagSENT_CONTENT	short\tagSENT_CONTENT	propagation\tagSENT_CONTENT	paths\tagSENT_CONTENT	between\tagSENT_CONTENT	the\tagSENT_CONTENT	output\tagSENT_CONTENT	layer\tagSENT_CONTENT	and\tagSENT_CONTENT	underlying\tagSENT_CONTENT	feature\tagSENT_CONTENT	detectors\tagSENT_CONTENT	,\tagSENT_CONTENT	enabling\tagSENT_CONTENT	effective\tagSENT_CONTENT	structural\tagSENT_CONTENT	feature\tagSENT_CONTENT	learning\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	We\tagSENT_START	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	:\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Introduction\tagSECTITLE_END	TBCNNs\tagSENT_START	are\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	on\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	;\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	have\tagSENT_CONTENT	outperformed\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	results\tagSENT_CONTENT	in\tagSENT_CONTENT	both\tagSENT_CONTENT	experiments\tagSENT_CONTENT	.\tagSENT_END	Background\tagSECTITLE_START	and\tagSECTITLE_CONTENT	Related\tagSECTITLE_CONTENT	Work\tagSECTITLE_END	In\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	present\tagSENT_CONTENT	the\tagSENT_CONTENT	background\tagSENT_CONTENT	and\tagSENT_CONTENT	related\tagSENT_CONTENT	work\tagSENT_CONTENT	regarding\tagSENT_CONTENT	two\tagSENT_CONTENT	prevailing\tagSENT_CONTENT	neural\tagSENT_CONTENT	architectures\tagSENT_CONTENT	for\tagSENT_CONTENT	discriminative\tagSENT_CONTENT	sentence\tagSENT_CONTENT	modeling\tagSENT_CONTENT	.\tagSENT_END	Convolutional\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	The\tagSENT_START	output\tagSENT_CONTENT	of\tagSENT_CONTENT	convolution\tagSENT_CONTENT	,\tagSENT_CONTENT	evaluated\tagSENT_CONTENT	at\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	is\tagSENT_END	b\tagSENT_START	∈\tagSENT_CONTENT	R\tagSENT_CONTENT	nc\tagSENT_CONTENT	are\tagSENT_CONTENT	parame-2\tagSENT_CONTENT	https://sites.google.com/site/tbcnnsentence/\tagSENT_CONTENT	ters\tagSENT_CONTENT	;\tagSENT_CONTENT	f\tagSENT_CONTENT	is\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	After\tagSENT_START	convolution\tagSENT_CONTENT	,\tagSENT_CONTENT	the\tagSENT_CONTENT	extracted\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	pooled\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	fixedsize\tagSENT_CONTENT	vector\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Recursive\tagSECTITLE_START	Neural\tagSECTITLE_CONTENT	Networks\tagSECTITLE_END	This\tagSENT_START	process\tagSENT_CONTENT	is\tagSENT_CONTENT	done\tagSENT_CONTENT	recursively\tagSENT_CONTENT	along\tagSENT_CONTENT	the\tagSENT_CONTENT	tree\tagSENT_CONTENT	;\tagSENT_CONTENT	the\tagSENT_CONTENT	root\tagSENT_CONTENT	vector\tagSENT_CONTENT	is\tagSENT_CONTENT	then\tagSENT_CONTENT	used\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	They\tagSENT_START	are\tagSENT_CONTENT	more\tagSENT_CONTENT	suitable\tagSENT_CONTENT	for\tagSENT_CONTENT	capturing\tagSENT_CONTENT	logical\tagSENT_CONTENT	information\tagSENT_CONTENT	in\tagSENT_CONTENT	sentences\tagSENT_CONTENT	,\tagSENT_CONTENT	such\tagSENT_CONTENT	as\tagSENT_CONTENT	negation\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Tree\tagSECTITLE_START	-\tagSECTITLE_CONTENT	based\tagSECTITLE_CONTENT	Convolution\tagSECTITLE_END	text_classification\tagtask	introduces\tagSENT_CONTENT	the\tagSENT_CONTENT	proposed\tagSENT_CONTENT	tree\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	convolutional\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	(\tagSENT_CONTENT	TBCNNs\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	In\tagSENT_START	the\tagSENT_CONTENT	rest\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	explain\tagSENT_CONTENT	model\tagSENT_CONTENT	variants\tagSENT_CONTENT	in\tagSENT_CONTENT	detail\tagSENT_CONTENT	.\tagSENT_END	c\tagSECTITLE_START	-\tagSECTITLE_CONTENT	TBCNN\tagSECTITLE_END	text_classification\tagtask	,\tagSENT_CONTENT	specific\tagSENT_CONTENT	for\tagSENT_CONTENT	c\tagSENT_CONTENT	-\tagSENT_CONTENT	TBCNN\tagSENT_CONTENT	,\tagSENT_CONTENT	is\tagSENT_END	d\tagSECTITLE_START	-\tagSECTITLE_CONTENT	TBCNN\tagSECTITLE_END	We\tagSENT_START	believe\tagSENT_CONTENT	this\tagSENT_CONTENT	strategy\tagSENT_CONTENT	makes\tagSENT_CONTENT	much\tagSENT_CONTENT	sense\tagSENT_CONTENT	because\tagSENT_CONTENT	dependency\tagSENT_CONTENT	types\tagSENT_CONTENT	)\tagSENT_CONTENT	reflect\tagSENT_CONTENT	text_classification\tagtask	between\tagSENT_CONTENT	a\tagSENT_CONTENT	governing\tagSENT_CONTENT	word\tagSENT_CONTENT	and\tagSENT_CONTENT	its\tagSENT_CONTENT	child\tagSENT_CONTENT	words\tagSENT_CONTENT	.\tagSENT_END	Pooling\tagSECTITLE_START	Heuristics\tagSECTITLE_END	Task\tagSECTITLE_END	Data\tagSECTITLE_START	samples\tagSECTITLE_CONTENT	Label\tagSECTITLE_END	Sentiment\tagSECTITLE_START	Analysis\tagSECTITLE_END	Each\tagSENT_START	slot\tagSENT_CONTENT	should\tagSENT_CONTENT	have\tagSENT_CONTENT	similar\tagSENT_CONTENT	numbers\tagSENT_CONTENT	of\tagSENT_CONTENT	nodes\tagSENT_CONTENT	,\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	pooled\tagSENT_CONTENT	to\tagSENT_CONTENT	it\tagSENT_CONTENT	.\tagSENT_END	Following\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	pooling\tagSENT_CONTENT	heuristics\tagSENT_CONTENT	as\tagSENT_CONTENT	follows\tagSENT_CONTENT	.\tagSENT_END	To\tagSENT_START	preserve\tagSENT_CONTENT	text_classification\tagtask	over\tagSENT_CONTENT	different\tagSENT_CONTENT	parts\tagSENT_CONTENT	of\tagSENT_CONTENT	constituency\tagSENT_CONTENT	trees\tagSENT_CONTENT	,\tagSENT_CONTENT	we\tagSENT_CONTENT	propose\tagSENT_CONTENT	3-slot\tagSENT_CONTENT	pooling\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	according\tagSENT_START	to\tagSENT_CONTENT	text_classification\tagtask	with\tagSENT_CONTENT	respect\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	root\tagSENT_CONTENT	node\tagSENT_CONTENT	.\tagSENT_END	Let\tagSENT_START	i\tagSENT_CONTENT	be\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	word\tagSENT_CONTENT	in\tagSENT_CONTENT	a\tagSENT_CONTENT	sentence\tagSENT_END	As\tagSENT_START	we\tagSENT_CONTENT	shall\tagSENT_CONTENT	see\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	experimental\tagSENT_CONTENT	results\tagSENT_CONTENT	,\tagSENT_CONTENT	complicated\tagSENT_CONTENT	pooling\tagSENT_CONTENT	methods\tagSENT_CONTENT	do\tagSENT_CONTENT	preserve\tagSENT_CONTENT	text_classification\tagtask	along\tagSENT_CONTENT	tree\tagSENT_CONTENT	structures\tagSENT_CONTENT	to\tagSENT_CONTENT	some\tagSENT_CONTENT	extent\tagSENT_CONTENT	,\tagSENT_CONTENT	but\tagSENT_CONTENT	the\tagSENT_CONTENT	effect\tagSENT_CONTENT	is\tagSENT_CONTENT	not\tagSENT_CONTENT	large\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Objective\tagSECTITLE_END	We\tagSENT_START	add\tagSENT_CONTENT	a\tagSENT_CONTENT	hidden\tagSENT_CONTENT	layer\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	then\tagSENT_CONTENT	a\tagSENT_CONTENT	softmax\tagSENT_CONTENT	layer\tagSENT_CONTENT	to\tagSENT_CONTENT	predict\tagSENT_CONTENT	the\tagSENT_CONTENT	probability\tagSENT_CONTENT	of\tagSENT_CONTENT	each\tagSENT_CONTENT	target\tagSENT_CONTENT	label\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Experimental\tagSECTITLE_START	Results\tagSECTITLE_END	In\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	our\tagSENT_CONTENT	models\tagSENT_CONTENT	with\tagSENT_CONTENT	two\tagSENT_CONTENT	tasks\tagSENT_CONTENT	,\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	Sentiment\tagSECTITLE_START	Analysis\tagSECTITLE_END	The\tagSECTITLE_START	Task\tagSECTITLE_CONTENT	and\tagSECTITLE_CONTENT	Dataset\tagSECTITLE_END	Two\tagSENT_START	settings\tagSENT_CONTENT	are\tagSENT_CONTENT	considered\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	:\tagSENT_CONTENT	text_classification\tagtask	with\tagSENT_CONTENT	5\tagSENT_CONTENT	labels\tagSENT_CONTENT	(\tagSENT_CONTENT	strongly\tagSENT_CONTENT	positive\tagSENT_CONTENT	,\tagSENT_CONTENT	positive\tagSENT_CONTENT	,\tagSENT_CONTENT	neutral\tagSENT_CONTENT	,\tagSENT_CONTENT	negative\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	strongly\tagSENT_CONTENT	negative\tagSENT_CONTENT	)\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_END	text_classification\tagtask	with\tagSENT_CONTENT	2\tagSENT_CONTENT	labels\tagSENT_CONTENT	(\tagSENT_CONTENT	positive\tagSENT_CONTENT	versus\tagSENT_CONTENT	negative\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	the\tagSENT_CONTENT	standard\tagSENT_CONTENT	split\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	,\tagSENT_CONTENT	validating\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	testing\tagSENT_CONTENT	,\tagSENT_CONTENT	containing\tagSENT_CONTENT	8544/1101/2210\tagSENT_CONTENT	sentences\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	text_classification\tagtask	does\tagSENT_CONTENT	not\tagSENT_CONTENT	contain\tagSENT_CONTENT	the\tagSENT_CONTENT	neutral\tagSENT_CONTENT	class\tagSENT_CONTENT	.\tagSENT_END	Training\tagSECTITLE_START	Details\tagSECTITLE_END	text_classification\tagtask	describes\tagSENT_CONTENT	training\tagSENT_CONTENT	details\tagSENT_CONTENT	for\tagSENT_CONTENT	d\tagSENT_CONTENT	-\tagSENT_CONTENT	TBCNN\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	hyperparameters\tagSENT_CONTENT	are\tagSENT_CONTENT	chosen\tagSENT_CONTENT	by\tagSENT_CONTENT	validation\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	use\tagSENT_CONTENT	as\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	For\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	add\tagSENT_CONTENT	2\tagSENT_CONTENT	penalty\tagSENT_CONTENT	for\tagSENT_CONTENT	weights\tagSENT_CONTENT	with\tagSENT_CONTENT	a\tagSENT_CONTENT	coefficient\tagSENT_CONTENT	of\tagSENT_CONTENT	10\tagSENT_CONTENT	−5\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	d\tagSENT_CONTENT	-\tagSENT_CONTENT	TBCNN\tagSENT_CONTENT	yields\tagSENT_CONTENT	51.4\tagSENT_CONTENT	%\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	,\tagSENT_CONTENT	outperforming\tagSENT_CONTENT	the\tagSENT_CONTENT	previous\tagSENT_CONTENT	state\tagSENT_CONTENT	-\tagSENT_CONTENT	of\tagSENT_CONTENT	-\tagSENT_CONTENT	the\tagSENT_CONTENT	-\tagSENT_CONTENT	art\tagSENT_CONTENT	result\tagSENT_CONTENT	,\tagSENT_CONTENT	achieved\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	RNN\tagSENT_CONTENT	based\tagSENT_CONTENT	on\tagSENT_CONTENT	long\tagSENT_CONTENT	-\tagSENT_CONTENT	short\tagSENT_CONTENT	term\tagSENT_CONTENT	memory\tagSENT_CONTENT	.\tagSENT_END	Performance\tagSECTITLE_END	Regarding\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	we\tagSENT_CONTENT	adopted\tagSENT_CONTENT	a\tagSENT_CONTENT	simple\tagSENT_CONTENT	strategy\tagSENT_CONTENT	in\tagSENT_CONTENT	,\tagSENT_CONTENT	where\tagSENT_CONTENT	text_classification\tagtask	is\tagSENT_CONTENT	"\tagSENT_CONTENT	transferred\tagSENT_CONTENT	"\tagSENT_CONTENT	directly\tagSENT_CONTENT	for\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	with\tagSENT_END	Ina\tagSENT_START	more\tagSENT_CONTENT	controlled\tagSENT_CONTENT	comparison\tagSENT_CONTENT	-\tagSENT_CONTENT	with\tagSENT_CONTENT	shallow\tagSENT_CONTENT	architectures\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	linearly\tagSENT_CONTENT	transformed\tagSENT_CONTENT	and\tagSENT_CONTENT	non\tagSENT_CONTENT	-\tagSENT_CONTENT	linearly\tagSENT_CONTENT	squashed)-TBCNNs\tagSENT_CONTENT	,\tagSENT_CONTENT	of\tagSENT_CONTENT	both\tagSENT_CONTENT	variants\tagSENT_CONTENT	,\tagSENT_CONTENT	consistently\tagSENT_CONTENT	outperform\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	(\tagSENT_CONTENT	)\tagSENT_CONTENT	to\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	extent\tagSENT_CONTENT	(\tagSENT_CONTENT	50.4\tagSENT_CONTENT	-\tagSENT_CONTENT	51.4\tagSENT_CONTENT	%\tagSENT_CONTENT	versus\tagSENT_CONTENT	43.2\tagSENT_CONTENT	%\tagSENT_CONTENT	)\tagSENT_CONTENT	;\tagSENT_CONTENT	they\tagSENT_CONTENT	also\tagSENT_CONTENT	consistently\tagSENT_CONTENT	outperform\tagSENT_CONTENT	"\tagSENT_CONTENT	flat\tagSENT_CONTENT	"\tagSENT_CONTENT	CNNs\tagSENT_CONTENT	by\tagSENT_CONTENT	more\tagSENT_CONTENT	than\tagSENT_CONTENT	10\tagSENT_CONTENT	%\tagSENT_CONTENT	.\tagSENT_END	Such\tagSENT_START	results\tagSENT_CONTENT	show\tagSENT_CONTENT	that\tagSENT_CONTENT	structures\tagSENT_CONTENT	are\tagSENT_CONTENT	important\tagSENT_CONTENT	when\tagSENT_CONTENT	modeling\tagSENT_CONTENT	sentences\tagSENT_CONTENT	;\tagSENT_CONTENT	tree\tagSENT_CONTENT	-\tagSENT_CONTENT	based\tagSENT_CONTENT	convolution\tagSENT_CONTENT	can\tagSENT_CONTENT	capture\tagSENT_CONTENT	text_classification\tagtask	more\tagSENT_CONTENT	effectively\tagSENT_CONTENT	than\tagSENT_CONTENT	RNNs\tagSENT_CONTENT	.\tagSENT_END	Question\tagSECTITLE_START	Classification\tagSECTITLE_END	We\tagSENT_START	further\tagSENT_CONTENT	evaluate\tagSENT_CONTENT	TBCNN\tagSENT_CONTENT	models\tagSENT_CONTENT	on\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSENT_START	dataset\tagSENT_CONTENT	contains\tagSENT_CONTENT	5452\tagSENT_CONTENT	annotated\tagSENT_CONTENT	sentences\tagSENT_CONTENT	plus\tagSENT_CONTENT	500\tagSENT_CONTENT	test\tagSENT_CONTENT	samples\tagSENT_CONTENT	in\tagSENT_CONTENT	TREC\tagdataset	10\tagSENT_CONTENT	.\tagSENT_END	Target\tagSENT_START	labels\tagSENT_CONTENT	contain\tagSENT_CONTENT	6\tagSENT_CONTENT	classes\tagSENT_CONTENT	,\tagSENT_CONTENT	namely\tagSENT_CONTENT	abbreviation\tagSENT_CONTENT	,\tagSENT_CONTENT	entity\tagSENT_CONTENT	,\tagSENT_CONTENT	description\tagSENT_CONTENT	,\tagSENT_CONTENT	human\tagSENT_CONTENT	,\tagSENT_CONTENT	text_classification\tagtask	,\tagSENT_CONTENT	and\tagSENT_CONTENT	numeric\tagSENT_CONTENT	.\tagSENT_END	We\tagSENT_START	do\tagSENT_CONTENT	not\tagSENT_CONTENT	back\tagSENT_CONTENT	-\tagSENT_CONTENT	propagate\tagSENT_CONTENT	gradient\tagSENT_CONTENT	to\tagSENT_CONTENT	embeddings\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	:\tagSENT_CONTENT	Accuracy\tagSENT_CONTENT	of\tagSENT_CONTENT	text_classification\tagtask	(\tagSENT_CONTENT	in\tagSENT_CONTENT	percentage\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	For\tagSENT_START	text_classification\tagtask	,\tagSENT_CONTENT	"\tagSENT_CONTENT	†\tagSENT_CONTENT	"\tagSENT_CONTENT	remarks\tagSENT_CONTENT	indicate\tagSENT_CONTENT	that\tagSENT_CONTENT	the\tagSENT_CONTENT	network\tagSENT_CONTENT	is\tagSENT_CONTENT	transferred\tagSENT_CONTENT	directly\tagSENT_CONTENT	from\tagSENT_CONTENT	that\tagSENT_CONTENT	of\tagSENT_CONTENT	5-class\tagSENT_CONTENT	.\tagSENT_CONTENT	 \tagSENT_END	To\tagSENT_START	the\tagSENT_CONTENT	best\tagSENT_CONTENT	of\tagSENT_CONTENT	our\tagSENT_CONTENT	knowledge\tagSENT_CONTENT	,\tagSENT_CONTENT	this\tagSENT_CONTENT	is\tagSENT_CONTENT	the\tagSENT_CONTENT	first\tagSENT_CONTENT	time\tagSENT_CONTENT	that\tagSENT_CONTENT	neural\tagSENT_CONTENT	networks\tagSENT_CONTENT	beat\tagSENT_CONTENT	dedicated\tagSENT_CONTENT	human\tagSENT_CONTENT	engineering\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSENT_START	result\tagSENT_CONTENT	also\tagSENT_CONTENT	shows\tagSENT_CONTENT	that\tagSENT_CONTENT	both\tagSENT_CONTENT	c\tagSENT_CONTENT	-\tagSENT_CONTENT	TBCNN\tagSENT_CONTENT	and\tagSENT_CONTENT	d\tagSENT_CONTENT	-\tagSENT_CONTENT	TBCNN\tagSENT_CONTENT	reduce\tagSENT_CONTENT	the\tagmetric	error\tagmetric	rate\tagmetric	to\tagSENT_CONTENT	a\tagSENT_CONTENT	large\tagSENT_CONTENT	extent\tagSENT_CONTENT	,\tagSENT_CONTENT	compared\tagSENT_CONTENT	with\tagSENT_CONTENT	other\tagSENT_CONTENT	neural\tagSENT_CONTENT	architectures\tagSENT_CONTENT	in\tagSENT_CONTENT	this\tagSENT_CONTENT	task\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_START	Analysis\tagSECTITLE_END	The\tagSECTITLE_START	Effect\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Pooling\tagSECTITLE_END	text_classification\tagtask	aims\tagSENT_CONTENT	to\tagSENT_CONTENT	provide\tagSENT_CONTENT	a\tagSENT_CONTENT	fair\tagSENT_CONTENT	comparison\tagSENT_CONTENT	among\tagSENT_CONTENT	these\tagSENT_CONTENT	pooling\tagSENT_CONTENT	methods\tagSENT_CONTENT	.\tagSENT_END	text_classification\tagtask	was\tagSENT_CONTENT	run\tagSENT_CONTENT	five\tagSENT_CONTENT	times\tagSENT_CONTENT	with\tagSENT_CONTENT	different\tagSENT_CONTENT	random\tagSENT_CONTENT	initializations\tagSENT_CONTENT	.\tagSENT_END	Model\tagSECTITLE_END	report\tagSENT_START	200\tagSENT_CONTENT	epochs\tagSENT_CONTENT	for\tagSENT_CONTENT	training\tagSENT_CONTENT	a\tagSENT_CONTENT	deep\tagSENT_CONTENT	RNN\tagSENT_CONTENT	,\tagSENT_CONTENT	which\tagSENT_CONTENT	achieves\tagSENT_CONTENT	49.8\tagSENT_CONTENT	%\tagSENT_CONTENT	accuracy\tagSENT_CONTENT	in\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	The\tagSECTITLE_START	Effect\tagSECTITLE_CONTENT	of\tagSECTITLE_CONTENT	Sentence\tagSECTITLE_CONTENT	Lengths\tagSECTITLE_END	Visualization\tagSECTITLE_END	Thus\tagSENT_START	,\tagSENT_CONTENT	we\tagSENT_CONTENT	can\tagSENT_CONTENT	count\tagSENT_CONTENT	text_classification\tagtask	in\tagSENT_CONTENT	which\tagSENT_CONTENT	a\tagSENT_CONTENT	node\tagSENT_CONTENT	's\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	gathered\tagSENT_CONTENT	by\tagSENT_CONTENT	pooling\tagSENT_CONTENT	.\tagSENT_END	Intuitively\tagSENT_START	,\tagSENT_CONTENT	if\tagSENT_CONTENT	a\tagSENT_CONTENT	node\tagSENT_CONTENT	's\tagSENT_CONTENT	features\tagSENT_CONTENT	are\tagSENT_CONTENT	more\tagSENT_CONTENT	related\tagSENT_CONTENT	to\tagSENT_CONTENT	the\tagSENT_CONTENT	task\tagSENT_CONTENT	,\tagSENT_CONTENT	text_classification\tagtask	tends\tagSENT_CONTENT	to\tagSENT_CONTENT	be\tagSENT_CONTENT	larger\tagSENT_CONTENT	,\tagSENT_CONTENT	and\tagSENT_CONTENT	vice\tagSENT_CONTENT	versa\tagSENT_CONTENT	.\tagSENT_END	"\tagSENT_START	The\tagSENT_CONTENT	numbers\tagSENT_CONTENT	in\tagSENT_CONTENT	brackets\tagSENT_CONTENT	denote\tagSENT_CONTENT	text_classification\tagtask	of\tagSENT_CONTENT	a\tagSENT_CONTENT	node\tagSENT_CONTENT	's\tagSENT_CONTENT	features\tagSENT_CONTENT	that\tagSENT_CONTENT	are\tagSENT_CONTENT	gathered\tagSENT_CONTENT	by\tagSENT_CONTENT	the\tagSENT_CONTENT	max\tagSENT_CONTENT	pooling\tagSENT_CONTENT	layer\tagSENT_CONTENT	(\tagSENT_CONTENT	also\tagSENT_CONTENT	indicated\tagSENT_CONTENT	by\tagSENT_CONTENT	colors\tagSENT_CONTENT	)\tagSENT_CONTENT	.\tagSENT_END	Conclusion\tagSECTITLE_END	Both\tagSENT_START	variants\tagSENT_CONTENT	have\tagSENT_CONTENT	achieved\tagSENT_CONTENT	high\tagSENT_CONTENT	performance\tagSENT_CONTENT	in\tagSENT_CONTENT	sentiment\tagSENT_CONTENT	analysis\tagSENT_CONTENT	and\tagSENT_CONTENT	text_classification\tagtask	.\tagSENT_END	
