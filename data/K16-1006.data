title	SECTITLE_END
context2vec	SEC_START
:	SEC_CONTENT
Learning	SEC_CONTENT
Generic	SEC_CONTENT
Context	SEC_CONTENT
Embedding	SEC_CONTENT
with	SEC_CONTENT
Bidirectional	SEC_CONTENT
LSTM	SEC_END
abstract	SECTITLE_END
Context	SEC_START
representations	SEC_CONTENT
are	SEC_CONTENT
central	SEC_CONTENT
to	SEC_CONTENT
various	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word	task
sense	task
disam	task
-	task
biguation	task
,	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
,	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
reference	SEC_CONTENT
resolution	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
many	SEC_CONTENT
more	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
efficiently	SEC_CONTENT
learning	SEC_CONTENT
a	SEC_CONTENT
generic	SEC_CONTENT
context	SEC_CONTENT
embedding	SEC_CONTENT
function	SEC_CONTENT
from	SEC_CONTENT
large	SEC_CONTENT
corpora	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
a	SEC_CONTENT
very	SEC_CONTENT
simple	SEC_CONTENT
application	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
manage	SEC_CONTENT
to	SEC_CONTENT
surpass	SEC_CONTENT
or	SEC_CONTENT
nearly	SEC_CONTENT
reach	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
,	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
sense	SEC_CONTENT
disambiguation	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
substantially	SEC_CONTENT
outperforming	SEC_CONTENT
the	SEC_CONTENT
popular	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
averaged	SEC_CONTENT
word	SEC_CONTENT
em	SEC_CONTENT
-	SEC_CONTENT
beddings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
release	SEC_CONTENT
our	SEC_CONTENT
code	SEC_CONTENT
and	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
suggesting	SEC_CONTENT
they	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
useful	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
wide	SEC_CONTENT
variety	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Generic	SEC_START
word	SEC_CONTENT
embeddings	SEC_CONTENT
capture	SEC_CONTENT
semantic	SEC_CONTENT
and	SEC_CONTENT
syntactic	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
individual	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
compact	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
optimize	SEC_CONTENT
a	SEC_CONTENT
generic	SEC_CONTENT
taskindependent	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
,	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
were	SEC_CONTENT
found	SEC_CONTENT
useful	SEC_CONTENT
in	SEC_CONTENT
abroad	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
making	SEC_CONTENT
an	SEC_CONTENT
overall	SEC_CONTENT
huge	SEC_CONTENT
impact	SEC_CONTENT
in	SEC_CONTENT
recent	SEC_CONTENT
years	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
major	SEC_CONTENT
advancement	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
field	SEC_CONTENT
was	SEC_CONTENT
the	SEC_CONTENT
introduction	SEC_CONTENT
of	SEC_CONTENT
highly	SEC_CONTENT
efficient	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word2vec	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
GloVe	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
learning	SEC_CONTENT
generic	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
from	SEC_CONTENT
very	SEC_CONTENT
large	SEC_CONTENT
corpora	SEC_CONTENT
.	SEC_CONTENT
Capturing	SEC_CONTENT
information	SEC_CONTENT
from	SEC_CONTENT
such	SEC_CONTENT
corpora	SEC_CONTENT
substantially	SEC_CONTENT
increased	SEC_CONTENT
the	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
both	SEC_CONTENT
unsupervised	SEC_CONTENT
and	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
To	SEC_START
make	SEC_CONTENT
inferences	SEC_CONTENT
regarding	SEC_CONTENT
a	SEC_CONTENT
concrete	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
instance	SEC_CONTENT
,	SEC_CONTENT
good	SEC_CONTENT
representations	SEC_CONTENT
of	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
type	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
given	SEC_CONTENT
context	SEC_CONTENT
are	SEC_CONTENT
helpful	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
"	SEC_CONTENT
I	SEC_CONTENT
ca	SEC_CONTENT
n't	SEC_CONTENT
find	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
consider	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
April	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
context	SEC_CONTENT
"	SEC_CONTENT
I	SEC_CONTENT
ca	SEC_CONTENT
n't	SEC_CONTENT
find	SEC_CONTENT
[	SEC_CONTENT
]	SEC_CONTENT
"	SEC_CONTENT
to	SEC_CONTENT
infer	SEC_CONTENT
that	SEC_CONTENT
April	SEC_CONTENT
probably	SEC_CONTENT
refers	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
person	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
principle	SEC_CONTENT
applies	SEC_CONTENT
to	SEC_CONTENT
various	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
word	task
sense	task
disambiguation	task
,	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
reference	SEC_CONTENT
resolution	SEC_CONTENT
and	SEC_CONTENT
named	SEC_CONTENT
entity	SEC_CONTENT
recognition	SEC_CONTENT
(	SEC_CONTENT
NER	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Like	SEC_START
target	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
contexts	SEC_CONTENT
are	SEC_CONTENT
commonly	SEC_CONTENT
represented	SEC_CONTENT
via	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
an	SEC_CONTENT
unsupervised	SEC_CONTENT
setting	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
representations	SEC_CONTENT
were	SEC_CONTENT
found	SEC_CONTENT
useful	SEC_CONTENT
for	SEC_CONTENT
measuring	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
sensitive	SEC_CONTENT
similarity	SEC_CONTENT
,	SEC_CONTENT
word	task
sense	task
disambiguation	task
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
word	SEC_CONTENT
sense	SEC_CONTENT
induction	SEC_CONTENT
,	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
more	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
such	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
commonly	SEC_CONTENT
just	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
individual	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
neighboring	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
window	SEC_CONTENT
around	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
a	SEC_CONTENT
(	SEC_CONTENT
sometimes	SEC_CONTENT
weighted	SEC_CONTENT
)	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
such	SEC_CONTENT
approaches	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
include	SEC_CONTENT
any	SEC_CONTENT
mechanism	SEC_CONTENT
for	SEC_CONTENT
optimizing	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
whole	SEC_CONTENT
.	SEC_END
In	SEC_START
supervised	SEC_CONTENT
settings	SEC_CONTENT
,	SEC_CONTENT
various	SEC_CONTENT
NLP	SEC_CONTENT
systems	SEC_CONTENT
use	SEC_CONTENT
labeled	SEC_CONTENT
data	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
how	SEC_CONTENT
to	SEC_CONTENT
consider	SEC_CONTENT
context	SEC_CONTENT
word	SEC_CONTENT
representations	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
optimized	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
way	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
was	SEC_CONTENT
done	SEC_CONTENT
in	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
chunking	SEC_CONTENT
,	SEC_CONTENT
NER	SEC_CONTENT
,	SEC_CONTENT
semantic	SEC_CONTENT
role	SEC_CONTENT
labeling	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
co	SEC_CONTENT
-	SEC_CONTENT
reference	SEC_CONTENT
resolution	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
mostly	SEC_CONTENT
by	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
window	SEC_CONTENT
around	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
of	SEC_CONTENT
interest	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
recently	SEC_CONTENT
,	SEC_CONTENT
bidirectional	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
specifically	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTMs	SEC_CONTENT
,	SEC_CONTENT
were	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
such	SEC_CONTENT
tasks	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
internal	SEC_CONTENT
representations	SEC_CONTENT
of	SEC_CONTENT
wider	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
supervised	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
limited	SEC_CONTENT
in	SEC_CONTENT
size	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
training	SEC_CONTENT
such	SEC_CONTENT
systems	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
that	SEC_CONTENT
were	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
large	SEC_CONTENT
corpora	SEC_CONTENT
,	SEC_CONTENT
improves	SEC_CONTENT
performance	SEC_CONTENT
significantly	SEC_CONTENT
.	SEC_CONTENT
Yet	SEC_CONTENT
,	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
carry	SEC_CONTENT
limited	SEC_CONTENT
information	SEC_CONTENT
regarding	SEC_CONTENT
the	SEC_CONTENT
inter	SEC_CONTENT
-	SEC_CONTENT
dependencies	SEC_CONTENT
between	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
whole	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
model	SEC_CONTENT
this	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
more	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
supervised	SEC_CONTENT
systems	SEC_CONTENT
still	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
rely	SEC_CONTENT
heavily	SEC_CONTENT
on	SEC_CONTENT
their	SEC_CONTENT
albeit	SEC_CONTENT
limited	SEC_CONTENT
supervised	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
work	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
context2vec	SEC_CONTENT
,	SEC_CONTENT
an	SEC_CONTENT
unsupervised	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
toolkit	SEC_CONTENT
1	SEC_CONTENT
for	SEC_CONTENT
efficiently	SEC_CONTENT
learning	SEC_CONTENT
generic	SEC_CONTENT
context	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
wide	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
Essentially	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
large	SEC_CONTENT
plain	SEC_CONTENT
text	SEC_CONTENT
corpora	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
embeds	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
and	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
space	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
optimized	SEC_CONTENT
to	SEC_CONTENT
reflect	SEC_CONTENT
inter	SEC_CONTENT
-	SEC_CONTENT
dependencies	SEC_CONTENT
between	SEC_CONTENT
targets	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
whole	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
demonstrate	SEC_CONTENT
their	SEC_CONTENT
high	SEC_CONTENT
quality	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
very	SEC_CONTENT
simple	SEC_CONTENT
application	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
surpass	SEC_CONTENT
or	SEC_CONTENT
nearly	SEC_CONTENT
reach	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
,	SEC_CONTENT
lexical	task
substitution	task
and	task
word	task
sense	task
disambiguation	task
tasks	task
,	SEC_CONTENT
while	SEC_CONTENT
substantially	SEC_CONTENT
outperforming	SEC_CONTENT
the	SEC_CONTENT
common	SEC_CONTENT
average	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
embeddings	SEC_CONTENT
representation	SEC_CONTENT
(	SEC_CONTENT
denoted	SEC_CONTENT
AWE	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
further	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
both	SEC_CONTENT
unsupervised	SEC_CONTENT
and	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
systems	SEC_CONTENT
may	SEC_CONTENT
benefit	SEC_CONTENT
from	SEC_CONTENT
using	SEC_CONTENT
our	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
instead	SEC_CONTENT
or	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
individual	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_END
Context2vec	SECTITLE_START
's	SECTITLE_CONTENT
Neural	SECTITLE_CONTENT
Model	SECTITLE_END
Model	SECTITLE_START
Overview	SECTITLE_END
The	SEC_START
main	SEC_CONTENT
goal	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
a	SEC_CONTENT
generic	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
independent	SEC_CONTENT
embedding	SEC_CONTENT
function	SEC_CONTENT
for	SEC_CONTENT
variable	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
around	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
do	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
word2vec	SEC_CONTENT
's	SEC_CONTENT
CBOW	SEC_CONTENT
architecture	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
replaces	SEC_CONTENT
its	SEC_CONTENT
naive	SEC_CONTENT
context	SEC_CONTENT
modeling	SEC_CONTENT
of	SEC_CONTENT
averaged	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
window	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
much	SEC_CONTENT
more	SEC_CONTENT
powerful	SEC_CONTENT
neural	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
proposed	SEC_CONTENT
architecture	SEC_CONTENT
is	SEC_CONTENT
illustrated	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
together	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
analogical	SEC_CONTENT
word2vec	SEC_CONTENT
architecture	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
models	SEC_CONTENT
learn	SEC_CONTENT
context	SEC_CONTENT
and	SEC_CONTENT
target	SEC_CONTENT
word	task
representations	task
at	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
embedding	SEC_CONTENT
them	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
low	SEC_CONTENT
-	SEC_CONTENT
dimensional	SEC_CONTENT
space	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
of	SEC_CONTENT
having	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
predict	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
via	SEC_CONTENT
a	SEC_CONTENT
log	SEC_CONTENT
linear	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
utilize	SEC_CONTENT
a	SEC_CONTENT
much	SEC_CONTENT
more	SEC_CONTENT
powerful	SEC_CONTENT
parametric	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
essence	SEC_CONTENT
of	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_END
The	SEC_START
left	SEC_CONTENT
-	SEC_CONTENT
hand	SEC_CONTENT
side	SEC_CONTENT
of	SEC_CONTENT
illustrates	SEC_CONTENT
how	SEC_CONTENT
context2vec	SEC_CONTENT
represents	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
feeding	SEC_CONTENT
one	SEC_CONTENT
LSTM	SEC_CONTENT
network	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
words	SEC_CONTENT
from	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
right	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
another	SEC_CONTENT
from	SEC_CONTENT
right	SEC_CONTENT
to	SEC_CONTENT
left	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
two	SEC_CONTENT
networks	SEC_CONTENT
are	SEC_CONTENT
completely	SEC_CONTENT
separate	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
two	SEC_CONTENT
separate	SEC_CONTENT
sets	SEC_CONTENT
of	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
and	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
left	SEC_CONTENT
context	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
represent	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
for	SEC_CONTENT
"	SEC_CONTENT
John	SEC_CONTENT
[	SEC_CONTENT
submitted	SEC_CONTENT
]	SEC_CONTENT
a	SEC_CONTENT
paper	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
concatenate	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
output	SEC_CONTENT
vector	SEC_CONTENT
representing	SEC_CONTENT
its	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
"	SEC_CONTENT
John	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
representing	SEC_CONTENT
its	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
left	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
"	SEC_CONTENT
a	SEC_CONTENT
paper	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
relevant	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
when	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
remote	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
Next	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
feed	SEC_CONTENT
this	SEC_CONTENT
concatenated	SEC_CONTENT
vector	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
perceptron	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
capable	SEC_CONTENT
of	SEC_CONTENT
representing	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
trivial	SEC_CONTENT
dependencies	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
sides	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
consider	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
layer	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
joint	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
around	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
itself	SEC_CONTENT
(	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
hand	SEC_CONTENT
side	SEC_CONTENT
of	SEC_CONTENT
is	SEC_CONTENT
represented	SEC_CONTENT
with	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
embedding	SEC_CONTENT
,	SEC_CONTENT
equal	SEC_CONTENT
in	SEC_CONTENT
dimensionality	SEC_CONTENT
to	SEC_CONTENT
that	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
only	SEC_CONTENT
(	SEC_CONTENT
yet	SEC_CONTENT
crucial	SEC_CONTENT
)	SEC_CONTENT
difference	SEC_CONTENT
between	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
word2vec	SEC_CONTENT
's	SEC_CONTENT
CBOW	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
CBOW	SEC_CONTENT
represents	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
around	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
window	SEC_CONTENT
around	SEC_CONTENT
it	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
context2vec	SEC_CONTENT
utilizes	SEC_CONTENT
a	SEC_CONTENT
full	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
neural	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
context	SEC_CONTENT
.	SEC_END
Finally	SEC_START
,	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
word2vec	SEC_CONTENT
's	SEC_CONTENT
negative	SEC_CONTENT
sampling	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
positive	SEC_CONTENT
pair	SEC_CONTENT
being	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
respective	SEC_CONTENT
k	SEC_CONTENT
negative	SEC_CONTENT
pairs	SEC_CONTENT
as	SEC_CONTENT
random	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
sampled	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
(	SEC_CONTENT
smoothed	SEC_CONTENT
)	SEC_CONTENT
unigram	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
,	SEC_CONTENT
paired	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
learn	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
embedding	SEC_CONTENT
network	SEC_CONTENT
parameters	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_END
In	SEC_START
contrast	SEC_CONTENT
to	SEC_CONTENT
word2vec	SEC_CONTENT
and	SEC_CONTENT
similar	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
models	SEC_CONTENT
that	SEC_CONTENT
use	SEC_CONTENT
context	SEC_CONTENT
modeling	SEC_CONTENT
mostly	SEC_CONTENT
internally	SEC_CONTENT
and	SEC_CONTENT
consider	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
as	SEC_CONTENT
their	SEC_CONTENT
main	SEC_CONTENT
output	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
primary	SEC_CONTENT
focus	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
its	SEC_CONTENT
objective	SEC_CONTENT
by	SEC_CONTENT
assigning	SEC_CONTENT
similar	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
and	SEC_CONTENT
their	SEC_CONTENT
associated	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Further	SEC_CONTENT
,	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
casein	SEC_CONTENT
word2vec	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
indirectly	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
assigning	SEC_CONTENT
similar	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
associated	SEC_CONTENT
with	SEC_CONTENT
similar	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
conversely	SEC_CONTENT
to	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
associated	SEC_CONTENT
with	SEC_CONTENT
similar	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
will	SEC_CONTENT
show	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
sections	SEC_CONTENT
how	SEC_CONTENT
these	SEC_CONTENT
properties	SEC_CONTENT
make	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
useful	SEC_CONTENT
.	SEC_END
Formal	SECTITLE_START
Specification	SECTITLE_CONTENT
and	SECTITLE_CONTENT
Analysis	SECTITLE_END
We	SEC_START
use	SEC_CONTENT
a	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
lLS	SEC_CONTENT
bean	SEC_CONTENT
LSTM	SEC_CONTENT
reading	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
sentence	SEC_CONTENT
from	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
right	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
let	SEC_CONTENT
rLS	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
reverse	SEC_CONTENT
one	SEC_CONTENT
reading	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
from	SEC_CONTENT
right	SEC_CONTENT
to	SEC_CONTENT
left	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
'	SEC_CONTENT
shallow	SEC_CONTENT
'	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
w	SEC_CONTENT
i	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
vector	SEC_CONTENT
concatenation	SEC_CONTENT
:	SEC_CONTENT
biLS(w	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
lLS(l	SEC_CONTENT
1	SEC_CONTENT
:	SEC_CONTENT
i−1	SEC_CONTENT
)	SEC_CONTENT
⊕	SEC_CONTENT
rLS(r	SEC_CONTENT
n	SEC_CONTENT
:	SEC_CONTENT
i+1	SEC_CONTENT
)	SEC_CONTENT
where	SEC_CONTENT
l	SEC_CONTENT
/	SEC_CONTENT
r	SEC_CONTENT
represent	SEC_CONTENT
distinct	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
/	SEC_CONTENT
right	SEC_CONTENT
-	SEC_CONTENT
toleft	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
definition	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
bit	SEC_CONTENT
different	SEC_CONTENT
than	SEC_CONTENT
standard	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
feed	SEC_CONTENT
the	SEC_CONTENT
LSTMs	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
itself	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
position	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Next	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
function	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
left	SEC_CONTENT
and	SEC_CONTENT
right	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
:	SEC_END
where	SEC_START
MLP	SEC_CONTENT
stands	SEC_CONTENT
for	SEC_CONTENT
Multi	SEC_CONTENT
Layer	SEC_CONTENT
Perceptron	SEC_CONTENT
,	SEC_CONTENT
ReLU	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
Rectified	SEC_CONTENT
Linear	SEC_CONTENT
Unit	SEC_CONTENT
activation	SEC_CONTENT
function	SEC_CONTENT
,	SEC_CONTENT
and	SEC_END
..	SEC_START
,	SEC_CONTENT
w	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
position	SEC_CONTENT
i.	SEC_CONTENT
We	SEC_CONTENT
define	SEC_CONTENT
context2vec	SEC_CONTENT
's	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
c	SEC_CONTENT
as	SEC_CONTENT
:	SEC_END
Next	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
t	SEC_CONTENT
as	SEC_CONTENT
t.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
embedding	SEC_CONTENT
dimensionality	SEC_CONTENT
for	SEC_CONTENT
target	SEC_CONTENT
and	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
learn	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
and	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
word2vec	SEC_CONTENT
negative	SEC_CONTENT
sampling	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
(	SEC_CONTENT
):	SEC_END
where	SEC_START
the	SEC_CONTENT
summation	SEC_CONTENT
goes	SEC_CONTENT
over	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
token	SEC_CONTENT
tin	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
corresponding	SEC_CONTENT
(	SEC_CONTENT
single	SEC_CONTENT
)	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
c	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
σ	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sigmoid	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
t	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
...	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
k	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
samples	SEC_CONTENT
,	SEC_CONTENT
independently	SEC_CONTENT
sampled	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
smoothed	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
unigram	SEC_CONTENT
distribution	SEC_CONTENT
:	SEC_CONTENT
p	SEC_CONTENT
α	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
∝	SEC_CONTENT
(	SEC_CONTENT
#	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
α	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
that	SEC_CONTENT
0	SEC_CONTENT
≤	SEC_CONTENT
α	SEC_CONTENT
<	SEC_CONTENT
1	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
smoothing	SEC_CONTENT
factor	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
increases	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
proved	SEC_CONTENT
that	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
is	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
single	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
optimized	SEC_CONTENT
when	SEC_CONTENT
:	SEC_END
where	SEC_START
PMI(t	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
log	SEC_CONTENT
p(t	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
pα(t)p(c	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
pointwise	SEC_CONTENT
mutual	SEC_CONTENT
information	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
t	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
word	SEC_CONTENT
c.	SEC_CONTENT
The	SEC_CONTENT
analysis	SEC_CONTENT
presented	SEC_CONTENT
in	SEC_CONTENT
is	SEC_CONTENT
valid	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
cooccurrence	SEC_CONTENT
matrix	SEC_CONTENT
that	SEC_CONTENT
describes	SEC_CONTENT
the	task
joint	task
distribution	task
of	SEC_CONTENT
two	SEC_CONTENT
random	SEC_CONTENT
variables	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
applied	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
just	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
word	SEC_CONTENT
but	SEC_CONTENT
an	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
Accordingly	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
view	SEC_CONTENT
the	SEC_CONTENT
targetcontext	SEC_CONTENT
embedding	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
our	SEC_CONTENT
algorithm	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
factorization	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
PMI	SEC_CONTENT
matrix	SEC_CONTENT
between	SEC_CONTENT
all	SEC_CONTENT
possible	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
all	SEC_CONTENT
possible	SEC_CONTENT
different	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
the	SEC_CONTENT
case	SEC_CONTENT
of	SEC_CONTENT
single	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
feasible	SEC_CONTENT
to	SEC_CONTENT
explicitly	SEC_CONTENT
compute	SEC_CONTENT
here	SEC_CONTENT
this	SEC_CONTENT
PMI	SEC_CONTENT
matrix	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
exponential	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
optimize	SEC_CONTENT
still	SEC_CONTENT
aims	SEC_CONTENT
to	SEC_CONTENT
best	SEC_CONTENT
approximate	SEC_CONTENT
it	SEC_CONTENT
.	SEC_CONTENT
Based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
analysis	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
expect	SEC_CONTENT
the	SEC_CONTENT
inner	SEC_CONTENT
-	SEC_CONTENT
product	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
target	SEC_CONTENT
and	SEC_CONTENT
context	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
approximate	SEC_CONTENT
PMI	SEC_CONTENT
α	SEC_CONTENT
(	SEC_CONTENT
c	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
accordingly	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
larger	SEC_CONTENT
values	SEC_CONTENT
of	SEC_CONTENT
α	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
more	SEC_CONTENT
bias	SEC_CONTENT
towards	SEC_CONTENT
placing	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
closer	SEC_CONTENT
to	SEC_CONTENT
their	SEC_CONTENT
associated	SEC_CONTENT
contexts	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
space	SEC_CONTENT
.	SEC_END
Model	SECTITLE_START
Illustration	SECTITLE_END
To	SEC_START
demonstrate	SEC_CONTENT
the	SEC_CONTENT
qualities	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
embedded	SEC_CONTENT
space	SEC_CONTENT
learned	SEC_CONTENT
by	SEC_CONTENT
context2vec	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
illustrate	SEC_CONTENT
three	SEC_CONTENT
types	SEC_CONTENT
of	SEC_CONTENT
similarity	SEC_CONTENT
metrics	SEC_CONTENT
in	SEC_CONTENT
that	SEC_CONTENT
space	SEC_CONTENT
:	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
tocontext	SEC_CONTENT
(	SEC_CONTENT
t2c	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
c2c	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
targetto	SEC_CONTENT
-	SEC_CONTENT
target	SEC_CONTENT
(	SEC_CONTENT
t2	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
these	SEC_CONTENT
are	SEC_CONTENT
measured	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
vector	SEC_CONTENT
cosine	SEC_CONTENT
value	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
respective	SEC_CONTENT
embedding	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
Only	SEC_CONTENT
the	SEC_CONTENT
latter	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
target	SEC_CONTENT
metric	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
typically	SEC_CONTENT
used	SEC_CONTENT
when	SEC_CONTENT
illustrating	SEC_CONTENT
and	SEC_CONTENT
evaluating	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word2vec	SEC_CONTENT
.	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
2D	SEC_CONTENT
illustration	SEC_CONTENT
of	SEC_CONTENT
such	SEC_CONTENT
a	SEC_CONTENT
space	SEC_CONTENT
and	SEC_CONTENT
respective	SEC_CONTENT
metrics	SEC_CONTENT
.	SEC_END
In	SEC_START
we	SEC_CONTENT
show	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
closest	SEC_CONTENT
to	SEC_CONTENT
them	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
similarity	SEC_CONTENT
metric	SEC_CONTENT
with	SEC_CONTENT
context2vec	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
modeling	SEC_CONTENT
of	SEC_CONTENT
context2vec	SEC_CONTENT
is	SEC_CONTENT
indeed	SEC_CONTENT
capable	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
case	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
long	SEC_CONTENT
range	SEC_CONTENT
dependencies	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
to	SEC_CONTENT
take	SEC_CONTENT
both	SEC_CONTENT
sides	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
into	SEC_CONTENT
account	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
closest	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
to	SEC_CONTENT
given	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
different	SEC_CONTENT
context2vec	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
learned	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
different	SEC_CONTENT
negative	SEC_CONTENT
sampling	SEC_CONTENT
smoothing	SEC_CONTENT
parameter	SEC_CONTENT
α	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
illustrates	SEC_CONTENT
the	SEC_CONTENT
bias	SEC_CONTENT
that	SEC_CONTENT
high	SEC_CONTENT
α	SEC_CONTENT
values	SEC_CONTENT
introduce	SEC_CONTENT
towards	SEC_CONTENT
rare	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
predicted	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
analysis	SEC_CONTENT
in	SEC_CONTENT
section	SEC_CONTENT
2.2	SEC_CONTENT
.	SEC_END
Next	SEC_START
,	SEC_CONTENT
to	SEC_CONTENT
illustrate	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
similarity	SEC_CONTENT
metric	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
took	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
contexts	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
lemma	SEC_CONTENT
add	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
an	SEC_CONTENT
example	SEC_CONTENT
fora	SEC_CONTENT
'	SEC_CONTENT
query	SEC_CONTENT
'	SEC_CONTENT
context	SEC_CONTENT
from	SEC_CONTENT
that	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
two	SEC_CONTENT
most	SEC_CONTENT
similar	SEC_CONTENT
contexts	SEC_CONTENT
to	SEC_CONTENT
it	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
context2vec	SEC_CONTENT
and	SEC_CONTENT
AWE	SEC_CONTENT
(	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
Skip	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
)	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
argues	SEC_CONTENT
that	SEC_CONTENT
since	SEC_CONTENT
contexts	SEC_CONTENT
induce	SEC_CONTENT
meanings	SEC_CONTENT
(	SEC_CONTENT
or	SEC_CONTENT
senses	dataset
)	SEC_CONTENT
for	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
context	SEC_CONTENT
similarity	SEC_CONTENT
measure	SEC_CONTENT
should	SEC_CONTENT
assign	SEC_CONTENT
high	SEC_CONTENT
similarity	SEC_CONTENT
values	SEC_CONTENT
to	SEC_CONTENT
contexts	SEC_CONTENT
that	SEC_CONTENT
induce	SEC_CONTENT
similar	SEC_CONTENT
senses	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
AWE	SEC_CONTENT
's	SEC_CONTENT
similarity	SEC_CONTENT
measure	SEC_CONTENT
seems	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
influenced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
presence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
location	SEC_CONTENT
names	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
though	SEC_CONTENT
they	SEC_CONTENT
have	SEC_CONTENT
little	SEC_CONTENT
effect	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
perceived	SEC_CONTENT
meaning	SEC_CONTENT
of	SEC_CONTENT
add	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
Indeed	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
sense	SEC_CONTENT
of	SEC_CONTENT
add	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
closest	SEC_CONTENT
contexts	SEC_CONTENT
retrieved	SEC_CONTENT
by	SEC_CONTENT
AWE	SEC_CONTENT
is	SEC_CONTENT
different	SEC_CONTENT
than	SEC_CONTENT
that	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
query	SEC_CONTENT
'	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
context2vec	SEC_CONTENT
's	SEC_CONTENT
similarity	SEC_CONTENT
measure	SEC_CONTENT
was	SEC_CONTENT
robust	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_END
Finally	SEC_START
,	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
closest	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
few	SEC_CONTENT
given	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
target	SEC_CONTENT
similarity	SEC_CONTENT
metric	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compare	SEC_CONTENT
context2vec	SEC_CONTENT
's	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
Skipgram	SEC_CONTENT
word2vec	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
2-word	SEC_CONTENT
and	SEC_CONTENT
10-word	SEC_CONTENT
windows	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
seems	SEC_CONTENT
to	SEC_CONTENT
better	SEC_CONTENT
preserve	SEC_CONTENT
the	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
given	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
including	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
and	SEC_CONTENT
even	SEC_CONTENT
tense	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
comparison	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
2-word	SEC_CONTENT
window	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
even	SEC_CONTENT
more	SEC_CONTENT
so	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
10-word	SEC_CONTENT
window	SEC_CONTENT
one	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
intuition	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
behavior	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
Skip	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
literally	SEC_CONTENT
skips	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_END
Sentential	SECTITLE_START
Context	SECTITLE_END
Closest	SEC_START
target	SEC_CONTENT
words	SEC_CONTENT
This	SEC_CONTENT
[	SEC_CONTENT
]	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
item	SEC_CONTENT
,	SEC_CONTENT
fact	SEC_CONTENT
-	SEC_CONTENT
sheet	SEC_CONTENT
,	SEC_CONTENT
offer	SEC_CONTENT
,	SEC_CONTENT
pack	SEC_CONTENT
,	SEC_CONTENT
card	SEC_CONTENT
This	SEC_CONTENT
[	SEC_CONTENT
]	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
not	SEC_CONTENT
just	SEC_CONTENT
to	SEC_CONTENT
mere	SEC_CONTENT
luck	SEC_CONTENT
offer	SEC_CONTENT
,	SEC_CONTENT
suggestion	SEC_CONTENT
,	SEC_CONTENT
announcement	SEC_CONTENT
,	SEC_CONTENT
item	SEC_CONTENT
,	SEC_CONTENT
prize	SEC_CONTENT
This	SEC_CONTENT
[	SEC_CONTENT
]	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
not	SEC_CONTENT
just	SEC_CONTENT
to	SEC_CONTENT
mere	SEC_CONTENT
luck	SEC_CONTENT
,	SEC_CONTENT
award	SEC_CONTENT
,	SEC_CONTENT
prize	SEC_CONTENT
,	SEC_CONTENT
turnabout	SEC_CONTENT
,	SEC_CONTENT
offer	SEC_CONTENT
,	SEC_CONTENT
gift	SEC_CONTENT
but	SEC_CONTENT
to	SEC_CONTENT
outstanding	SEC_CONTENT
work	SEC_CONTENT
and	SEC_CONTENT
dedication	task
[	SEC_CONTENT
]	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
not	SEC_CONTENT
just	SEC_CONTENT
to	SEC_CONTENT
mere	SEC_CONTENT
luck	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
,	SEC_CONTENT
success	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
victory	SEC_CONTENT
,	SEC_CONTENT
prize	SEC_CONTENT
-	SEC_CONTENT
money	SEC_CONTENT
but	SEC_CONTENT
to	SEC_CONTENT
outstanding	SEC_CONTENT
work	SEC_CONTENT
and	SEC_CONTENT
dedication	SEC_CONTENT
:	SEC_CONTENT
Closest	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
to	SEC_CONTENT
various	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
illustrating	SEC_CONTENT
context2vec	SEC_CONTENT
's	SEC_CONTENT
sensitivity	SEC_CONTENT
to	SEC_CONTENT
long	SEC_CONTENT
range	SEC_CONTENT
dependencies	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
both	SEC_CONTENT
sides	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_END
α	SECTITLE_END
John	SEC_START
was	SEC_CONTENT
[	SEC_CONTENT
]	SEC_CONTENT
last	SEC_CONTENT
year	SEC_CONTENT
0.25	SEC_CONTENT
born	SEC_CONTENT
,	SEC_CONTENT
late	SEC_CONTENT
,	SEC_CONTENT
married	SEC_CONTENT
,	SEC_CONTENT
out	SEC_CONTENT
,	SEC_CONTENT
back	SEC_CONTENT
0.50	SEC_CONTENT
born	SEC_CONTENT
,	SEC_CONTENT
back	SEC_CONTENT
,	SEC_CONTENT
married	SEC_CONTENT
,	SEC_CONTENT
released	SEC_CONTENT
,	SEC_CONTENT
elected	SEC_CONTENT
0.75	SEC_CONTENT
born	SEC_CONTENT
,	SEC_CONTENT
interviewed	SEC_CONTENT
,	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
elected	SEC_CONTENT
1.00	SEC_CONTENT
starstruck	SEC_CONTENT
,	SEC_CONTENT
goal	SEC_CONTENT
-	SEC_CONTENT
less	SEC_CONTENT
,	SEC_CONTENT
unwed	SEC_CONTENT
:	SEC_CONTENT
Closest	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
using	SEC_CONTENT
different	SEC_CONTENT
α	SEC_CONTENT
values	SEC_CONTENT
in	SEC_CONTENT
context2vec	SEC_CONTENT
.	SEC_END
around	SEC_START
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
and	SEC_CONTENT
therefore	SEC_CONTENT
may	SEC_CONTENT
find	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
instance	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
contexts	SEC_CONTENT
of	SEC_CONTENT
san	SEC_CONTENT
and	SEC_CONTENT
francisco	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
very	SEC_CONTENT
similar	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
considers	SEC_CONTENT
only	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
taking	SEC_CONTENT
context	SEC_CONTENT
word	SEC_CONTENT
order	SEC_CONTENT
and	SEC_CONTENT
position	SEC_CONTENT
into	SEC_CONTENT
consideration	SEC_CONTENT
.	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
learned	SEC_CONTENT
from	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
generated	SEC_CONTENT
using	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
also	SEC_CONTENT
exhibit	SEC_CONTENT
function	SEC_CONTENT
-	SEC_CONTENT
preserving	SEC_CONTENT
similarities	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
consistent	SEC_CONTENT
with	SEC_CONTENT
our	SEC_CONTENT
observations	SEC_CONTENT
.	SEC_END
Relation	SECTITLE_START
to	SECTITLE_CONTENT
Language	SECTITLE_CONTENT
Models	SECTITLE_END
Our	SEC_START
model	SEC_CONTENT
is	SEC_CONTENT
closely	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
in	SEC_CONTENT
section	SEC_CONTENT
2.2	SEC_CONTENT
and	SEC_CONTENT
tables	SEC_CONTENT
1	SEC_CONTENT
and	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
lot	SEC_CONTENT
in	SEC_CONTENT
common	SEC_CONTENT
with	SEC_CONTENT
LSTMbased	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
both	SEC_CONTENT
train	SEC_CONTENT
LSTM	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
objective	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
their	SEC_CONTENT
(	SEC_CONTENT
short	SEC_CONTENT
and	SEC_CONTENT
long	SEC_CONTENT
range	SEC_CONTENT
)	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
both	SEC_CONTENT
use	SEC_CONTENT
techniques	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
negative	SEC_CONTENT
sampling	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
address	SEC_CONTENT
large	SEC_CONTENT
vocabulary	SEC_CONTENT
computational	SEC_CONTENT
challenges	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
main	SEC_CONTENT
difference	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
LSTM	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
mainly	SEC_CONTENT
concerned	SEC_CONTENT
with	SEC_CONTENT
optimizing	SEC_CONTENT
predictions	SEC_CONTENT
of	SEC_CONTENT
conditional	SEC_CONTENT
probabilities	SEC_CONTENT
for	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
given	SEC_CONTENT
their	SEC_CONTENT
history	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
deriving	SEC_CONTENT
generally	SEC_CONTENT
useful	SEC_CONTENT
representations	SEC_CONTENT
to	SEC_CONTENT
whole	SEC_CONTENT
history	SEC_CONTENT
-	SEC_CONTENT
and	SEC_CONTENT
-	SEC_CONTENT
future	SEC_CONTENT
contexts	SEC_CONTENT
of	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
follow	SEC_CONTENT
word2vec	SEC_CONTENT
's	SEC_CONTENT
learning	SEC_CONTENT
framework	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
known	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
quality	SEC_CONTENT
representations	SEC_CONTENT
for	SEC_CONTENT
single	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
does	SEC_CONTENT
so	SEC_CONTENT
by	SEC_CONTENT
having	SEC_CONTENT
t	SEC_CONTENT
·	SEC_CONTENT
c	SEC_CONTENT
approximate	SEC_CONTENT
PMI(t	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
log	SEC_CONTENT
p(t|c	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Evaluation	SECTITLE_START
Settings	SECTITLE_END
We	SEC_START
intend	SEC_CONTENT
context2vec	SEC_CONTENT
's	SEC_CONTENT
generic	SEC_CONTENT
context	SEC_CONTENT
embedding	SEC_CONTENT
function	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
integrated	SEC_CONTENT
into	SEC_CONTENT
various	SEC_CONTENT
more	SEC_CONTENT
optimized	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
demonstrate	SEC_CONTENT
its	SEC_CONTENT
qualities	SEC_CONTENT
independently	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
address	SEC_CONTENT
three	SEC_CONTENT
different	SEC_CONTENT
types	SEC_CONTENT
of	SEC_CONTENT
tasks	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
simple	SEC_CONTENT
means	SEC_CONTENT
of	SEC_CONTENT
measuring	SEC_CONTENT
cosine	SEC_CONTENT
distances	SEC_CONTENT
between	SEC_CONTENT
its	SEC_CONTENT
embedded	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
Yet	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
our	SEC_CONTENT
performance	SEC_CONTENT
against	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
highly	SEC_CONTENT
competitive	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
optimized	SEC_CONTENT
systems	SEC_CONTENT
on	SEC_CONTENT
each	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
AWE	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
baseline	SEC_CONTENT
representing	SEC_CONTENT
a	SEC_CONTENT
commonly	SEC_CONTENT
used	SEC_CONTENT
generic	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
like	SEC_CONTENT
ours	SEC_CONTENT
,	SEC_CONTENT
can	SEC_CONTENT
represent	SEC_CONTENT
variable	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
contexts	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
size	SEC_CONTENT
vector	SEC_CONTENT
.	SEC_CONTENT
Our	task
evaluation	task
includes	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
,	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
and	SEC_CONTENT
supervised	SEC_CONTENT
word	SEC_CONTENT
sense	SEC_CONTENT
disambiguation	SEC_CONTENT
(	SEC_CONTENT
WSD	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Learning	SECTITLE_START
corpus	SECTITLE_END
With	SEC_START
the	SEC_CONTENT
exception	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
MSCC	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
comes	SEC_CONTENT
with	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
learning	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
billion	SEC_CONTENT
word	SEC_CONTENT
ukWaC	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
learning	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
speed	SEC_CONTENT
-	SEC_CONTENT
up	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
context2vec	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
discarded	SEC_CONTENT
all	SEC_CONTENT
sentences	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
longer	SEC_CONTENT
than	SEC_CONTENT
64	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
reducing	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
by	SEC_CONTENT
∼10	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
embeddings	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
AWE	SEC_CONTENT
baseline	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
corpus	SEC_CONTENT
to	SEC_CONTENT
not	SEC_CONTENT
penalize	SEC_CONTENT
it	SEC_CONTENT
on	SEC_CONTENT
account	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
lower	SEC_CONTENT
-	SEC_CONTENT
cased	SEC_CONTENT
all	SEC_CONTENT
text	SEC_CONTENT
and	SEC_CONTENT
considered	SEC_CONTENT
any	SEC_CONTENT
token	SEC_CONTENT
with	SEC_CONTENT
fewer	SEC_CONTENT
than	SEC_CONTENT
100	SEC_CONTENT
occurrences	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
unknown	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
yielded	SEC_CONTENT
a	SEC_CONTENT
vocabulary	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
little	SEC_CONTENT
over	SEC_CONTENT
180	SEC_CONTENT
K	SEC_CONTENT
words	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
160	SEC_CONTENT
K	SEC_CONTENT
words	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
trimmed	SEC_CONTENT
version	SEC_CONTENT
.	SEC_END
Compared	SECTITLE_START
Methods	SECTITLE_END
context2vec	SEC_START
We	SEC_CONTENT
implemented	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
Chainer	SEC_CONTENT
toolkit	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Adam	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
optimization	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
speed	SEC_CONTENT
-	SEC_CONTENT
up	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
time	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
only	SEC_CONTENT
sentences	SEC_CONTENT
of	SEC_CONTENT
equal	SEC_CONTENT
length	SEC_CONTENT
are	SEC_CONTENT
Query	SEC_CONTENT
Furthermore	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
in	SEC_CONTENT
Uganda	SEC_CONTENT
and	SEC_CONTENT
Romania	SEC_CONTENT
a	SEC_CONTENT
wider	SEC_CONTENT
perspective	SEC_CONTENT
.	SEC_CONTENT
...	SEC_CONTENT
themes	SEC_CONTENT
in	SEC_CONTENT
art	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
fascination	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
they	SEC_CONTENT
[	SEC_CONTENT
add	SEC_CONTENT
]	SEC_CONTENT
a	SEC_CONTENT
subject	SEC_CONTENT
interest	SEC_CONTENT
context2vec	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
viewer	SEC_CONTENT
's	SEC_CONTENT
enjoyment	SEC_CONTENT
of	SEC_CONTENT
artistic	SEC_CONTENT
qualities	SEC_CONTENT
.	SEC_CONTENT
closest	SEC_CONTENT
Richard	SEC_CONTENT
is	SEC_CONTENT
joining	SEC_CONTENT
us	SEC_CONTENT
every	SEC_CONTENT
month	SEC_CONTENT
to	SEC_CONTENT
pass	SEC_CONTENT
on	SEC_CONTENT
tips	SEC_CONTENT
,	SEC_CONTENT
ideas	SEC_CONTENT
and	SEC_CONTENT
news	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
world	SEC_CONTENT
of	SEC_CONTENT
horticulture	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
[	SEC_CONTENT
add	SEC_CONTENT
]	SEC_CONTENT
a	SEC_CONTENT
touch	SEC_CONTENT
of	SEC_CONTENT
humour	SEC_CONTENT
too	SEC_CONTENT
...	SEC_CONTENT
the	SEC_CONTENT
foreign	SEC_CONTENT
ministers	SEC_CONTENT
said	SEC_CONTENT
political	SEC_CONTENT
and	SEC_CONTENT
economic	SEC_CONTENT
reforms	SEC_CONTENT
in	SEC_CONTENT
Poland	SEC_CONTENT
and	SEC_CONTENT
Hungary	SEC_CONTENT
AWE	SEC_CONTENT
had	SEC_CONTENT
made	SEC_CONTENT
considerable	SEC_CONTENT
progress	SEC_CONTENT
but	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
process	SEC_CONTENT
remains	SEC_CONTENT
fragile	SEC_CONTENT
...	SEC_CONTENT
closest	SEC_CONTENT
...	SEC_CONTENT
Germany	SEC_CONTENT
had	SEC_CONTENT
announced	SEC_CONTENT
the	SEC_CONTENT
solution	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
humanitarian	SEC_CONTENT
act	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
government	SEC_CONTENT
,	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
hoped	SEC_CONTENT
Bonn	SEC_CONTENT
in	SEC_CONTENT
future	SEC_CONTENT
would	SEC_CONTENT
run	SEC_CONTENT
its	SEC_CONTENT
embassies	SEC_CONTENT
in	SEC_CONTENT
normal	SEC_CONTENT
manner	SEC_CONTENT
...	SEC_CONTENT
 	SEC_CONTENT
AWE	SEC_CONTENT
We	SEC_CONTENT
learned	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
popular	SEC_CONTENT
word2vec	SEC_CONTENT
Skip	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
model	SEC_CONTENT
using	SEC_CONTENT
standard	SEC_CONTENT
hyperparameters	SEC_CONTENT
:	SEC_CONTENT
600	SEC_CONTENT
dimensions	SEC_CONTENT
,	SEC_CONTENT
10	SEC_CONTENT
negative	SEC_CONTENT
samples	SEC_CONTENT
,	SEC_CONTENT
window	SEC_CONTENT
-	SEC_CONTENT
size	SEC_CONTENT
10	SEC_CONTENT
and	SEC_CONTENT
3/5	SEC_CONTENT
iterations	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
ukWaC	SEC_CONTENT
/	SEC_CONTENT
MSCC	SEC_CONTENT
learning	SEC_CONTENT
corpora	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
embeddings	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
AWE	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
experimented	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
variations	SEC_CONTENT
:	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
ignoring	SEC_CONTENT
stopwords	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
performing	SEC_CONTENT
a	SEC_CONTENT
weighted	SEC_CONTENT
average	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
using	SEC_CONTENT
tf	SEC_CONTENT
-	SEC_CONTENT
idf	SEC_CONTENT
weights	SEC_CONTENT
(	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
considering	SEC_CONTENT
just	SEC_CONTENT
the	SEC_CONTENT
5-word	SEC_CONTENT
window	SEC_CONTENT
around	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
WSD	SEC_CONTENT
experiment	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
provided	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
full	SEC_CONTENT
paragraph	SEC_CONTENT
.	SEC_CONTENT
Though	SEC_CONTENT
it	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
extended	SEC_CONTENT
,	SEC_CONTENT
context2vec	SEC_CONTENT
is	SEC_CONTENT
currently	SEC_CONTENT
not	SEC_CONTENT
designed	SEC_CONTENT
to	SEC_CONTENT
take	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
such	SEC_CONTENT
large	SEC_CONTENT
context	SEC_CONTENT
and	SEC_CONTENT
therefore	SEC_CONTENT
ignores	SEC_CONTENT
all	SEC_CONTENT
context	SEC_CONTENT
out	SEC_CONTENT
-	SEC_CONTENT
side	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
AWE	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
experimented	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
option	SEC_CONTENT
of	SEC_CONTENT
generating	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
paragraph	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
all	SEC_CONTENT
cases	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
(	SEC_CONTENT
dimensionality	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
AWE	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
was	SEC_CONTENT
equal	SEC_CONTENT
to	SEC_CONTENT
that	SEC_CONTENT
of	SEC_CONTENT
context2vec	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
target	SEC_CONTENT
and	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
similarities	SEC_CONTENT
were	SEC_CONTENT
computed	SEC_CONTENT
using	SEC_CONTENT
vector	SEC_CONTENT
cosine	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
respective	SEC_CONTENT
embedding	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
with	SEC_CONTENT
context2vec	SEC_CONTENT
.	SEC_END
Sentence	SECTITLE_START
Completion	SECTITLE_CONTENT
Challenge	SECTITLE_END
The	SEC_START
Microsoft	SEC_CONTENT
Sentence	SEC_CONTENT
Completion	SEC_CONTENT
Challenge	SEC_CONTENT
(	SEC_CONTENT
MSCC	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
Zweig	SEC_CONTENT
and	SEC_CONTENT
Burges	SEC_CONTENT
,	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
includes	SEC_CONTENT
1,040	SEC_CONTENT
items	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
item	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
with	SEC_CONTENT
one	SEC_CONTENT
word	SEC_CONTENT
replaced	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
gap	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
challenge	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
out	SEC_CONTENT
of	SEC_CONTENT
five	SEC_CONTENT
choices	SEC_CONTENT
,	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
most	SEC_CONTENT
meaningful	SEC_CONTENT
and	SEC_CONTENT
coherent	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
gap	SEC_CONTENT
-	SEC_CONTENT
filler	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
no	SEC_CONTENT
official	SEC_CONTENT
dev	SEC_CONTENT
/	SEC_CONTENT
test	SEC_CONTENT
split	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
followed	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
and	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
520	SEC_CONTENT
sentences	SEC_CONTENT
for	SEC_CONTENT
parameter	SEC_CONTENT
tuning	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
rest	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
MSCC	SEC_CONTENT
includes	SEC_CONTENT
a	SEC_CONTENT
learning	SEC_CONTENT
corpus	SEC_CONTENT
of	SEC_CONTENT
50	SEC_CONTENT
million	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
use	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
discarded	SEC_CONTENT
all	SEC_CONTENT
sentences	SEC_CONTENT
longer	SEC_CONTENT
than	SEC_CONTENT
128	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
resulted	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
negligible	SEC_CONTENT
reduction	SEC_CONTENT
of	SEC_CONTENT
∼	SEC_CONTENT
1	SEC_CONTENT
%	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
converted	SEC_CONTENT
all	SEC_CONTENT
text	SEC_CONTENT
to	SEC_CONTENT
lowercase	SEC_CONTENT
and	SEC_CONTENT
considered	SEC_CONTENT
all	SEC_CONTENT
words	SEC_CONTENT
with	SEC_CONTENT
frequency	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
3	SEC_CONTENT
as	SEC_CONTENT
unknown	SEC_CONTENT
,	SEC_CONTENT
yielding	SEC_CONTENT
a	SEC_CONTENT
vocabulary	SEC_CONTENT
of	SEC_CONTENT
about	SEC_CONTENT
100	SEC_CONTENT
K	SEC_CONTENT
word	SEC_CONTENT
types	SEC_CONTENT
.	SEC_END
Finally	SEC_START
,	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
gap	SEC_CONTENT
-	SEC_CONTENT
filler	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
simply	SEC_CONTENT
choose	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
whose	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
given	SEC_CONTENT
context	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
context	SEC_CONTENT
similarity	SEC_CONTENT
metric	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
achieved	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
Lexical	SECTITLE_START
Substitution	SECTITLE_CONTENT
Task	SECTITLE_END
The	SEC_START
lexical	SEC_CONTENT
substitution	SEC_CONTENT
task	SEC_CONTENT
requires	SEC_CONTENT
finding	SEC_CONTENT
a	SEC_CONTENT
substitute	SEC_CONTENT
word	SEC_CONTENT
fora	SEC_CONTENT
given	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
difference	SEC_CONTENT
between	SEC_CONTENT
this	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
substitute	SEC_CONTENT
word	SEC_CONTENT
needs	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
coherent	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
preserve	SEC_CONTENT
the	SEC_CONTENT
meaning	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
that	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
recent	SEC_CONTENT
works	SEC_CONTENT
evaluated	SEC_CONTENT
their	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
ranking	SEC_CONTENT
variant	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
uses	SEC_CONTENT
predefined	SEC_CONTENT
candidate	SEC_CONTENT
lists	SEC_CONTENT
provided	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
gold	SEC_CONTENT
standard	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
requires	SEC_CONTENT
to	SEC_CONTENT
rank	SEC_CONTENT
them	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Performance	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
reported	SEC_CONTENT
with	SEC_CONTENT
generalized	SEC_CONTENT
average	SEC_CONTENT
precision	SEC_CONTENT
(	SEC_CONTENT
GAP	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
in	SEC_CONTENT
MSCC	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
evaluation	SEC_CONTENT
we	SEC_CONTENT
rank	SEC_CONTENT
lexical	SEC_CONTENT
substitutes	SEC_CONTENT
according	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
measured	SEC_CONTENT
similarity	SEC_CONTENT
between	SEC_CONTENT
their	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
given	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_END
We	SEC_START
used	SEC_CONTENT
two	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
datasets	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
dataset	SEC_CONTENT
introduced	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
denoted	SEC_CONTENT
LST-07	SEC_CONTENT
,	SEC_CONTENT
split	SEC_CONTENT
into	SEC_CONTENT
300	SEC_CONTENT
dev	SEC_CONTENT
sentences	SEC_CONTENT
and	SEC_CONTENT
1,710	SEC_CONTENT
test	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
recent	SEC_CONTENT
'	SEC_CONTENT
all	SEC_CONTENT
-	SEC_CONTENT
words	SEC_CONTENT
'	SEC_CONTENT
dataset	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
denoted	SEC_CONTENT
LST-14	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
over	SEC_CONTENT
15	SEC_CONTENT
K	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
instances	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
comes	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
predefined	SEC_CONTENT
35%/65	SEC_CONTENT
%	SEC_CONTENT
split	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
smaller	SEC_CONTENT
set	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
parameter	SEC_CONTENT
tuning	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
larger	SEC_CONTENT
one	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Supervised	SECTITLE_START
WSD	SECTITLE_END
In	SEC_START
supervised	SEC_CONTENT
WSD	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
determine	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
sense	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
manually	SEC_CONTENT
tagged	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
classify	SEC_CONTENT
a	SEC_CONTENT
test	SEC_CONTENT
word	SEC_CONTENT
instance	SEC_CONTENT
in	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
consider	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
5	SEC_CONTENT
See	SEC_CONTENT
Melamud	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
2015a	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
more	SEC_CONTENT
of	SEC_CONTENT
their	SEC_CONTENT
setting	SEC_CONTENT
details	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
followed	SEC_CONTENT
here	SEC_CONTENT
.	SEC_CONTENT
:	SEC_CONTENT
context2vec	SEC_CONTENT
hyperparameters	SEC_CONTENT
tagged	SEC_CONTENT
instances	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
word	SEC_CONTENT
lemma	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
instance	SEC_CONTENT
whose	SEC_CONTENT
context	SEC_CONTENT
embedding	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
instance	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
-	SEC_CONTENT
tocontext	SEC_CONTENT
similarity	SEC_CONTENT
metric	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
tagged	SEC_CONTENT
senses	SEC_CONTENT
6	SEC_CONTENT
of	SEC_CONTENT
that	SEC_CONTENT
instance	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
essentially	SEC_CONTENT
the	SEC_CONTENT
simplest	SEC_CONTENT
form	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
k	SEC_CONTENT
-	SEC_CONTENT
nearest	SEC_CONTENT
-	SEC_CONTENT
neighbor	SEC_CONTENT
algorithm	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
k	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
.	SEC_END
As	SEC_START
our	SEC_CONTENT
supervised	SEC_CONTENT
WSD	SEC_CONTENT
dataset	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
Senseval-3	SEC_CONTENT
lexical	SEC_CONTENT
sample	SEC_CONTENT
dataset	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
denoted	SEC_CONTENT
SE-3	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
includes	SEC_CONTENT
7,860	SEC_CONTENT
train	SEC_CONTENT
and	SEC_CONTENT
3,944	SEC_CONTENT
test	SEC_CONTENT
instances	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
parameter	SEC_CONTENT
tuning	SEC_CONTENT
and	SEC_CONTENT
report	SEC_CONTENT
accuracy	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
Development	SECTITLE_START
Experiments	SECTITLE_END
The	SEC_START
hyperparameters	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
reported	SEC_CONTENT
experiments	SEC_CONTENT
with	SEC_CONTENT
context2vec	SEC_CONTENT
are	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
Table	SEC_CONTENT
5	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
preliminary	SEC_CONTENT
development	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
only	SEC_CONTENT
200	SEC_CONTENT
units	SEC_CONTENT
for	SEC_CONTENT
representing	SEC_CONTENT
sentential	SEC_CONTENT
contexts	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
saw	SEC_CONTENT
significant	SEC_CONTENT
improvement	SEC_CONTENT
in	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
moving	SEC_CONTENT
to	SEC_CONTENT
600	SEC_CONTENT
units	SEC_CONTENT
.	SEC_CONTENT
Increasing	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
1,000	SEC_CONTENT
units	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
seem	SEC_CONTENT
to	SEC_CONTENT
further	SEC_CONTENT
improve	SEC_CONTENT
results	SEC_CONTENT
.	SEC_END
With	SEC_START
mini	SEC_CONTENT
-	SEC_CONTENT
batches	SEC_CONTENT
of	SEC_CONTENT
1,000	SEC_CONTENT
sentences	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
started	SEC_CONTENT
by	SEC_CONTENT
training	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
a	task
single	task
iteration	task
over	SEC_CONTENT
the	SEC_CONTENT
2-billion	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
ukWaC	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
took	SEC_CONTENT
∼30	SEC_CONTENT
hours	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
Tesla	SEC_CONTENT
K80	SEC_CONTENT
GPU	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
smaller	SEC_CONTENT
50-million	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
MSCC	SEC_CONTENT
learning	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
full	SEC_CONTENT
iteration	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
100	SEC_CONTENT
took	SEC_CONTENT
only	SEC_CONTENT
about	SEC_CONTENT
3	SEC_CONTENT
hours	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
started	SEC_CONTENT
with	SEC_CONTENT
5	SEC_CONTENT
training	SEC_CONTENT
iterations	SEC_CONTENT
.	SEC_END
To	SEC_START
explore	SEC_CONTENT
the	SEC_CONTENT
rare	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
bias	SEC_CONTENT
effect	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
smoothing	SEC_CONTENT
factor	SEC_CONTENT
α	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
varied	SEC_CONTENT
its	SEC_CONTENT
value	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
development	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
appear	SEC_CONTENT
in	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
left	SEC_CONTENT
hand	SEC_CONTENT
side	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
we	SEC_CONTENT
preferred	SEC_CONTENT
to	SEC_CONTENT
keep	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
as	SEC_CONTENT
simple	SEC_CONTENT
as	SEC_CONTENT
possible	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
these	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
chose	SEC_CONTENT
the	SEC_CONTENT
single	SEC_CONTENT
context2vec	SEC_CONTENT
AWE	SEC_CONTENT
neg	SEC_CONTENT
sampling	SEC_CONTENT
parameter	SEC_CONTENT
α	SEC_CONTENT
iters+	SEC_CONTENT
best	SEC_CONTENT
best	SEC_CONTENT
worst	SEC_CONTENT
worst	SEC_CONTENT
0.25	SEC_CONTENT
0.50	SEC_CONTENT
0.75	SEC_CONTENT
1.00	SEC_CONTENT
0.75	SEC_CONTENT
config	SEC_CONTENT
result	SEC_CONTENT
config	SEC_CONTENT
result	SEC_CONTENT
MSCC	SEC_CONTENT
-	SEC_CONTENT
dev	SEC_CONTENT
52.5	SEC_CONTENT
56.5	SEC_CONTENT
60.0	SEC_CONTENT
52.7	SEC_END
66.2	SEC_START
sent+stop	SEC_CONTENT
51.0	SEC_CONTENT
W5	SEC_CONTENT
36.5	SEC_CONTENT
LST-07-dev	SEC_CONTENT
50.1	SEC_CONTENT
52.9	SEC_CONTENT
53.6	SEC_CONTENT
54.3	SEC_CONTENT
55.4	SEC_CONTENT
W5+stop	SEC_CONTENT
45.8	SEC_CONTENT
sent	SEC_CONTENT
40.0	SEC_CONTENT
LST-14-dev	SEC_CONTENT
48.2	SEC_CONTENT
48.9	SEC_CONTENT
48.0	SEC_CONTENT
46.1	SEC_CONTENT
48.3	SEC_CONTENT
sent+stop	SEC_CONTENT
40.4	SEC_CONTENT
sent	SEC_CONTENT
39.2	SEC_CONTENT
SE-3-dev	SEC_CONTENT
72.1	SEC_CONTENT
72.4	SEC_CONTENT
71.6	SEC_CONTENT
72.5	SEC_CONTENT
72.6	SEC_CONTENT
W5+tf	SEC_CONTENT
-	SEC_CONTENT
idf	SEC_CONTENT
62.4	SEC_CONTENT
sent	SEC_CONTENT
57.3	SEC_CONTENT
:	SEC_CONTENT
Development	SEC_CONTENT
set	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
iters+	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
model	SEC_CONTENT
found	SEC_CONTENT
when	SEC_CONTENT
running	SEC_CONTENT
more	SEC_CONTENT
training	SEC_CONTENT
iterations	SEC_CONTENT
with	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
0.75	SEC_CONTENT
.	SEC_CONTENT
AWE	SEC_CONTENT
config	SEC_CONTENT
:	SEC_CONTENT
W5	SEC_CONTENT
/	SEC_CONTENT
sent	SEC_CONTENT
denotes	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
5-word	SEC_CONTENT
-	SEC_CONTENT
window	SEC_CONTENT
/	SEC_CONTENT
full	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
stop	SEC_CONTENT
/	SEC_CONTENT
tf	SEC_CONTENT
-	SEC_CONTENT
idf	SEC_CONTENT
denotes	SEC_CONTENT
ignoring	SEC_CONTENT
stop	SEC_CONTENT
words	SEC_CONTENT
or	SEC_CONTENT
using	SEC_CONTENT
tf	SEC_CONTENT
-	SEC_CONTENT
idf	SEC_CONTENT
weights	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_END
value	SEC_START
α	SEC_CONTENT
=	SEC_CONTENT
0.75	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
this	SEC_CONTENT
choice	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
tried	SEC_CONTENT
training	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
more	SEC_CONTENT
iterations	SEC_CONTENT
and	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
with	SEC_CONTENT
3	SEC_CONTENT
iterations	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
ukWaC	SEC_CONTENT
corpus	SEC_CONTENT
and	SEC_CONTENT
10	SEC_CONTENT
iterations	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
MSCC	SEC_CONTENT
corpus	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
obtain	SEC_CONTENT
some	SEC_CONTENT
further	SEC_CONTENT
improvement	SEC_CONTENT
in	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
see	SEC_CONTENT
iters+	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
The	SEC_START
results	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
with	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
AWE	SEC_CONTENT
variants	SEC_CONTENT
,	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
section	SEC_CONTENT
3.2	SEC_CONTENT
,	SEC_CONTENT
appear	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
hand	SEC_CONTENT
side	SEC_CONTENT
of	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
brevity	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
and	SEC_CONTENT
worst	SEC_CONTENT
configuration	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
benchmark	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
two	SEC_CONTENT
out	SEC_CONTENT
of	SEC_CONTENT
four	SEC_CONTENT
benchmarks	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
window	SEC_CONTENT
of	SEC_CONTENT
5	SEC_CONTENT
words	SEC_CONTENT
yields	SEC_CONTENT
better	SEC_CONTENT
performance	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
full	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
suggesting	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
AWE	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
very	SEC_CONTENT
successful	SEC_CONTENT
in	SEC_CONTENT
leveraging	SEC_CONTENT
effectively	SEC_CONTENT
long	SEC_CONTENT
range	SEC_CONTENT
information	SEC_CONTENT
.	SEC_CONTENT
Removing	SEC_CONTENT
stop	SEC_CONTENT
words	SEC_CONTENT
or	SEC_CONTENT
using	SEC_CONTENT
tf	SEC_CONTENT
-	SEC_CONTENT
idf	SEC_CONTENT
weights	SEC_CONTENT
improves	SEC_CONTENT
performance	SEC_CONTENT
significantly	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
still	SEC_CONTENT
much	SEC_CONTENT
lower	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
ones	SEC_CONTENT
achieved	SEC_CONTENT
with	SEC_CONTENT
context2vec	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
raise	SEC_CONTENT
the	SEC_CONTENT
bar	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
test	SEC_CONTENT
-	SEC_CONTENT
set	SEC_CONTENT
experiment	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	task
best	task
AWE	task
configuration	task
found	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
development	SEC_CONTENT
-	SEC_CONTENT
set	SEC_CONTENT
experiment	SEC_CONTENT
.	SEC_END
Test	SECTITLE_START
Sets	SECTITLE_CONTENT
Results	SECTITLE_END
The	SEC_START
test	SEC_CONTENT
set	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
context2vec	SEC_CONTENT
substantially	SEC_CONTENT
outperforms	SEC_CONTENT
AWE	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
benchmarks	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
are	SEC_CONTENT
much	SEC_CONTENT
better	SEC_CONTENT
optimized	SEC_CONTENT
for	SEC_CONTENT
capturing	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
information	SEC_CONTENT
than	SEC_CONTENT
AWE	SEC_CONTENT
,	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
for	SEC_CONTENT
these	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Further	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
with	SEC_CONTENT
context2vec	SEC_CONTENT
we	SEC_CONTENT
either	SEC_CONTENT
surpass	SEC_CONTENT
or	SEC_CONTENT
almost	SEC_CONTENT
reach	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
benchmarks	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
quite	SEC_CONTENT
impressive	SEC_CONTENT
,	SEC_CONTENT
considering	SEC_CONTENT
that	SEC_CONTENT
all	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
was	SEC_CONTENT
measure	SEC_CONTENT
cosine	SEC_CONTENT
distances	SEC_CONTENT
between	SEC_CONTENT
context2vec	SEC_CONTENT
's	SEC_CONTENT
representations	SEC_CONTENT
to	SEC_CONTENT
compete	SEC_CONTENT
with	SEC_CONTENT
more	SEC_CONTENT
complex	SEC_CONTENT
and	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
optimized	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_END
More	SEC_START
specifically	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
completion	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
MSCC	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
prior	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
result	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
  	SEC_CONTENT
and	SEC_CONTENT
iters+	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
was	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
more	SEC_CONTENT
iterations	SEC_CONTENT
.	SEC_CONTENT
S-1	SEC_CONTENT
/	SEC_CONTENT
S-2	SEC_CONTENT
stand	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
/	SEC_CONTENT
secondbest	SEC_CONTENT
prior	SEC_CONTENT
result	SEC_CONTENT
reported	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
benchmark	SEC_CONTENT
.	SEC_END
weighted	SEC_START
combination	SEC_CONTENT
of	SEC_CONTENT
scores	SEC_CONTENT
from	SEC_CONTENT
two	SEC_CONTENT
different	SEC_CONTENT
models	SEC_CONTENT
:	SEC_CONTENT
a	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
Skip	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
-	SEC_CONTENT
best	SEC_CONTENT
result	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
learned	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
corpora	SEC_CONTENT
and	SEC_CONTENT
structured	SEC_CONTENT
knowledge	SEC_CONTENT
resources	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
WordNet	SEC_CONTENT
.	SEC_CONTENT
context2vec	SEC_CONTENT
outperforms	SEC_CONTENT
both	SEC_CONTENT
of	SEC_CONTENT
them	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
lexical	SEC_CONTENT
substitution	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
prior	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
employ	SEC_CONTENT
an	SEC_CONTENT
exemplar	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approach	SEC_CONTENT
that	SEC_CONTENT
requires	SEC_CONTENT
keeping	SEC_CONTENT
thousands	SEC_CONTENT
of	SEC_CONTENT
exemplar	SEC_CONTENT
contexts	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
type	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
-	SEC_CONTENT
best	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
it	SEC_CONTENT
requires	SEC_CONTENT
dependency	SEC_CONTENT
-	SEC_CONTENT
parsed	SEC_CONTENT
text	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
context2vec	SEC_CONTENT
achieves	SEC_CONTENT
comparable	SEC_CONTENT
results	SEC_CONTENT
with	SEC_CONTENT
these	SEC_CONTENT
works	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
learning	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_END
In	SEC_START
the	SEC_CONTENT
Senseval-3	SEC_CONTENT
supervised	SEC_CONTENT
WSD	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
result	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
-	SEC_CONTENT
best	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
context2vec	SEC_CONTENT
is	SEC_CONTENT
almost	SEC_CONTENT
on	SEC_CONTENT
par	SEC_CONTENT
with	SEC_CONTENT
these	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
were	SEC_CONTENT
achieved	SEC_CONTENT
with	SEC_CONTENT
dedicated	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
and	SEC_CONTENT
supervised	SEC_CONTENT
machine	SEC_CONTENT
learning	SEC_CONTENT
models	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
Substitute	SEC_START
vectors	SEC_CONTENT
)	SEC_CONTENT
represent	SEC_CONTENT
contexts	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
probabilistic	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
potential	SEC_CONTENT
gap	SEC_CONTENT
-	SEC_CONTENT
filler	SEC_CONTENT
words	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
slot	SEC_CONTENT
,	SEC_CONTENT
pruned	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
top	SEC_CONTENT
-	SEC_CONTENT
k	SEC_CONTENT
most	SEC_CONTENT
probable	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
using	SEC_CONTENT
this	SEC_CONTENT
representation	SEC_CONTENT
showed	SEC_CONTENT
interesting	SEC_CONTENT
potential	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
currently	SEC_CONTENT
be	SEC_CONTENT
generated	SEC_CONTENT
efficiently	SEC_CONTENT
only	SEC_CONTENT
with	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
and	SEC_CONTENT
hence	SEC_CONTENT
is	SEC_CONTENT
limited	SEC_CONTENT
to	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
size	SEC_CONTENT
context	SEC_CONTENT
windows	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
high	SEC_CONTENT
dimensional	SEC_CONTENT
and	SEC_CONTENT
sparse	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
contrast	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
Syntactic	SEC_CONTENT
dependency	SEC_CONTENT
context	SEC_CONTENT
embeddings	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
proposed	SEC_CONTENT
recently	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
depend	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
availability	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
quality	SEC_CONTENT
dependency	SEC_CONTENT
parser	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
viewed	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
'	SEC_CONTENT
bag	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
dependencies	SEC_CONTENT
'	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
representation	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
believe	SEC_CONTENT
that	SEC_CONTENT
incorporating	SEC_CONTENT
such	SEC_CONTENT
dependency	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
interesting	SEC_CONTENT
future	SEC_CONTENT
direction	SEC_CONTENT
.	SEC_END
A	SEC_START
couple	SEC_CONTENT
of	SEC_CONTENT
recent	SEC_CONTENT
works	SEC_CONTENT
extended	SEC_CONTENT
word2vec	SEC_CONTENT
's	SEC_CONTENT
CBOW	SEC_CONTENT
by	SEC_CONTENT
replacing	SEC_CONTENT
its	SEC_CONTENT
internal	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
proposed	SEC_CONTENT
a	SEC_CONTENT
continuous	SEC_CONTENT
window	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
linear	SEC_CONTENT
projection	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
window	SEC_CONTENT
embeddings	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
low	SEC_CONTENT
dimensional	SEC_CONTENT
vector	SEC_CONTENT
.	SEC_CONTENT
proposed	SEC_CONTENT
'	SEC_CONTENT
CBOW	SEC_CONTENT
with	SEC_CONTENT
attention	SEC_CONTENT
'	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
finding	SEC_CONTENT
the	SEC_CONTENT
relevant	SEC_CONTENT
features	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
window	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
both	SEC_CONTENT
approaches	SEC_CONTENT
confine	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
size	SEC_CONTENT
window	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
limit	SEC_CONTENT
their	SEC_CONTENT
scope	SEC_CONTENT
to	SEC_CONTENT
using	SEC_CONTENT
these	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
only	SEC_CONTENT
internally	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
of	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
evaluate	SEC_CONTENT
the	SEC_CONTENT
benefit	SEC_CONTENT
of	SEC_CONTENT
using	SEC_CONTENT
them	SEC_CONTENT
directly	SEC_CONTENT
in	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
.	SEC_CONTENT
 	SEC_CONTENT
represent	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
context	SEC_CONTENT
using	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTMs	SEC_CONTENT
and	SEC_CONTENT
multilingual	SEC_CONTENT
supervision	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
representing	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
alone	SEC_CONTENT
.	SEC_CONTENT
Yet	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
our	task
lexical	task
substitution	task
and	task
word	task
sense	task
disambiguation	task
evaluations	task
,	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
easily	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
modeling	SEC_CONTENT
the	SEC_CONTENT
meaning	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
context	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
.	SEC_END
Finally	SEC_START
,	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
considerable	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
using	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
to	SEC_CONTENT
represent	SEC_CONTENT
word	task
sequences	task
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
phrases	SEC_CONTENT
or	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
techniques	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
learning	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
have	SEC_CONTENT
much	SEC_CONTENT
in	SEC_CONTENT
common	SEC_CONTENT
with	SEC_CONTENT
those	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
for	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
Yet	SEC_CONTENT
,	SEC_CONTENT
sentential	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
reflect	SEC_CONTENT
the	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
only	SEC_CONTENT
inasmuch	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
relevant	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
slot	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
different	SEC_CONTENT
target	SEC_CONTENT
positions	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
sentence	SEC_CONTENT
can	SEC_CONTENT
yield	SEC_CONTENT
completely	SEC_CONTENT
different	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
reflect	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
contents	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
Conclusions	SECTITLE_START
and	SECTITLE_CONTENT
Future	SECTITLE_CONTENT
Potential	SECTITLE_END
We	SEC_START
presented	SEC_CONTENT
context2vec	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
learns	SEC_CONTENT
a	task
generic	task
embedding	task
function	task
for	SEC_CONTENT
variablelength	SEC_CONTENT
contexts	SEC_CONTENT
of	SEC_CONTENT
target	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
demonstrated	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
reasonable	SEC_CONTENT
time	SEC_CONTENT
over	SEC_CONTENT
billions	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
generate	SEC_CONTENT
high	SEC_CONTENT
quality	SEC_CONTENT
context	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
substantially	SEC_CONTENT
outperform	SEC_CONTENT
the	SEC_CONTENT
traditional	SEC_CONTENT
average	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
embeddings	SEC_CONTENT
approach	SEC_CONTENT
on	SEC_CONTENT
three	SEC_CONTENT
different	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
such	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
could	SEC_CONTENT
contribute	SEC_CONTENT
to	SEC_CONTENT
various	SEC_CONTENT
NLP	SEC_CONTENT
systems	SEC_CONTENT
that	SEC_CONTENT
model	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
semisupervised	SEC_CONTENT
systems	SEC_CONTENT
may	SEC_CONTENT
benefit	SEC_CONTENT
from	SEC_CONTENT
using	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
may	SEC_CONTENT
carry	SEC_CONTENT
more	SEC_CONTENT
useful	SEC_CONTENT
information	SEC_CONTENT
learned	SEC_CONTENT
from	SEC_CONTENT
large	SEC_CONTENT
corpora	SEC_CONTENT
,	SEC_CONTENT
than	SEC_CONTENT
individual	SEC_CONTENT
pretrained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
do	SEC_CONTENT
.	SEC_END
