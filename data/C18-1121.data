title	SECTITLE_END
Ensure	SEC_START
the	SEC_CONTENT
Correctness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Summary	SEC_CONTENT
:	SEC_CONTENT
Incorporate	SEC_CONTENT
Entailment	SEC_CONTENT
Knowledge	SEC_CONTENT
into	SEC_CONTENT
Abstractive	task
Sentence	task
Summarization	SEC_END
abstract	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
investigate	SEC_CONTENT
the	task
sentence	task
summarization	task
task	task
that	SEC_CONTENT
produces	SEC_CONTENT
a	SEC_CONTENT
summary	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
models	SEC_CONTENT
have	SEC_CONTENT
gained	SEC_CONTENT
considerable	SEC_CONTENT
success	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
most	SEC_CONTENT
existing	SEC_CONTENT
approaches	SEC_CONTENT
only	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
improving	SEC_CONTENT
word	SEC_CONTENT
overlap	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
generated	SEC_CONTENT
summary	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
reference	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
ignore	SEC_CONTENT
the	SEC_CONTENT
correctness	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
should	SEC_CONTENT
not	SEC_CONTENT
contain	SEC_CONTENT
error	SEC_CONTENT
messages	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
argue	SEC_CONTENT
that	SEC_CONTENT
correctness	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
essential	SEC_CONTENT
requirement	SEC_CONTENT
for	SEC_CONTENT
summarization	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
Considering	SEC_CONTENT
a	SEC_CONTENT
correct	SEC_CONTENT
summary	SEC_CONTENT
is	SEC_CONTENT
semantically	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
incorporate	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
into	SEC_CONTENT
abstractive	SEC_CONTENT
summarization	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
propose	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
under	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
framework	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
by	SEC_CONTENT
entailment	SEC_CONTENT
Reward	SEC_CONTENT
Augmented	SEC_CONTENT
Maximum	SEC_CONTENT
Likelihood	SEC_CONTENT
(	SEC_CONTENT
RAML	SEC_CONTENT
)	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Experimental	SEC_CONTENT
results	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
significantly	SEC_CONTENT
outperform	SEC_CONTENT
baselines	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
aspects	SEC_CONTENT
of	SEC_CONTENT
informative	SEC_CONTENT
-	SEC_CONTENT
ness	SEC_CONTENT
and	SEC_CONTENT
correctness	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Sentence	SEC_START
summarization	task
is	SEC_CONTENT
a	SEC_CONTENT
well	SEC_CONTENT
-	SEC_CONTENT
studied	SEC_CONTENT
task	SEC_CONTENT
that	SEC_CONTENT
creates	SEC_CONTENT
a	SEC_CONTENT
condensed	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
along	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Sequence	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
(	SEC_CONTENT
seq2seq	SEC_CONTENT
)	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
encodes	SEC_CONTENT
a	SEC_CONTENT
source	SEC_CONTENT
sequence	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
latent	SEC_CONTENT
representation	SEC_CONTENT
and	SEC_CONTENT
outputs	SEC_CONTENT
another	SEC_CONTENT
sequence	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
dominating	SEC_CONTENT
framework	SEC_CONTENT
for	SEC_CONTENT
sentence	SEC_CONTENT
summarization	SEC_CONTENT
.	SEC_CONTENT
Despite	SEC_CONTENT
substantial	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
existing	SEC_CONTENT
researches	SEC_CONTENT
typically	SEC_CONTENT
aim	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
word	SEC_CONTENT
overlap	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
generated	SEC_CONTENT
summary	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
references	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
measured	SEC_CONTENT
by	SEC_CONTENT
n	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
matching	SEC_CONTENT
metrics	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
ROUGE	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Hence	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
not	SEC_CONTENT
guarantee	SEC_CONTENT
the	SEC_CONTENT
semantic	SEC_CONTENT
correctness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
whole	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
some	SEC_CONTENT
cases	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
giving	SEC_CONTENT
high	SEC_CONTENT
matching	SEC_CONTENT
scores	SEC_CONTENT
may	SEC_CONTENT
contain	SEC_CONTENT
critical	SEC_CONTENT
error	SEC_CONTENT
messages	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
makes	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
fail	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
information	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Previous	SEC_CONTENT
study	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
about	SEC_CONTENT
30	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summaries	SEC_CONTENT
generated	SEC_CONTENT
by	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
seq2seq	SEC_CONTENT
system	SEC_CONTENT
are	SEC_CONTENT
subject	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Here	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
example	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
digits	SEC_CONTENT
are	SEC_CONTENT
replaced	SEC_CONTENT
by	SEC_CONTENT
"	SEC_CONTENT
#	SEC_CONTENT
")	SEC_CONTENT
:	SEC_END
Source	SEC_START
sentence	SEC_CONTENT
:	SEC_CONTENT
franch	SEC_CONTENT
won	SEC_CONTENT
the	SEC_CONTENT
gold	SEC_CONTENT
medal	SEC_CONTENT
at	SEC_CONTENT
women	SEC_CONTENT
's	SEC_CONTENT
epee	SEC_CONTENT
team	SEC_CONTENT
event	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
fie	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
world	SEC_CONTENT
championships	SEC_CONTENT
by	SEC_CONTENT
beating	SEC_CONTENT
china	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
-	SEC_CONTENT
#	SEC_CONTENT
#	SEC_CONTENT
.	SEC_END
Reference	SEC_START
:	SEC_CONTENT
france	SEC_CONTENT
beats	SEC_CONTENT
china	SEC_CONTENT
for	SEC_CONTENT
women	SEC_CONTENT
's	SEC_CONTENT
epee	SEC_CONTENT
team	SEC_CONTENT
gold	SEC_CONTENT
State	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
:	SEC_CONTENT
canada	SEC_CONTENT
wins	SEC_CONTENT
women	SEC_CONTENT
's	SEC_CONTENT
epee	SEC_CONTENT
team	SEC_CONTENT
event	SEC_END
For	SEC_START
the	SEC_CONTENT
example	SEC_CONTENT
shown	SEC_CONTENT
above	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
seq2seq	SEC_CONTENT
system	SEC_CONTENT
produces	SEC_CONTENT
a	SEC_CONTENT
fluent	SEC_CONTENT
summary	SEC_CONTENT
which	SEC_CONTENT
contains	SEC_CONTENT
an	SEC_CONTENT
obvious	SEC_CONTENT
mistake	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
true	SEC_CONTENT
winner	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
women	SEC_CONTENT
's	SEC_CONTENT
epee	SEC_CONTENT
team	SEC_CONTENT
event	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
"	SEC_CONTENT
france	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	task
summarization	task
model	task
wrongly	SEC_CONTENT
generates	SEC_CONTENT
"	SEC_CONTENT
canada	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
probably	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
similar	SEC_CONTENT
word	SEC_CONTENT
representations	SEC_CONTENT
for	SEC_CONTENT
country	SEC_CONTENT
names	SEC_CONTENT
.	SEC_CONTENT
Though	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
overlap	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
generated	SEC_CONTENT
summary	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
reference	SEC_CONTENT
is	SEC_CONTENT
considerable	SEC_CONTENT
,	SEC_CONTENT
leading	SEC_CONTENT
to	SEC_CONTENT
high	SEC_CONTENT
ROUGE	SEC_CONTENT
scores	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
is	SEC_CONTENT
invalid	SEC_CONTENT
.	SEC_END
We	SEC_START
argue	SEC_CONTENT
that	SEC_CONTENT
correctness	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
essential	SEC_CONTENT
requirement	SEC_CONTENT
for	SEC_CONTENT
summarization	task
systems	task
,	SEC_CONTENT
while	SEC_CONTENT
most	SEC_CONTENT
existing	SEC_CONTENT
systems	SEC_CONTENT
ignore	SEC_CONTENT
it	SEC_CONTENT
.	SEC_CONTENT
Generally	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
correct	SEC_CONTENT
summary	SEC_CONTENT
is	SEC_CONTENT
semantically	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
thus	SEC_CONTENT
we	SEC_CONTENT
believe	SEC_CONTENT
entailment	SEC_CONTENT
)	SEC_CONTENT
knowledge	SEC_CONTENT
is	SEC_CONTENT
beneficial	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
producing	SEC_CONTENT
contradictory	SEC_CONTENT
or	SEC_CONTENT
unrelated	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_END
To	SEC_START
incorporate	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
into	SEC_CONTENT
abstractive	task
summarization	task
models	task
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
and	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
share	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
system	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
system	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
can	SEC_CONTENT
grasp	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
gist	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
be	SEC_CONTENT
aware	SEC_CONTENT
of	SEC_CONTENT
entailment	SEC_CONTENT
relationships	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
Reward	SEC_CONTENT
Augmented	SEC_CONTENT
Maximum	SEC_CONTENT
Likelihood	SEC_CONTENT
(	SEC_CONTENT
RAML	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
training	SEC_CONTENT
that	SEC_CONTENT
encourages	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summarization	SEC_CONTENT
system	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
summary	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
.	SEC_CONTENT
Experimental	SEC_CONTENT
results	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
significantly	SEC_CONTENT
outperform	SEC_CONTENT
some	SEC_CONTENT
solid	SEC_CONTENT
baselines	SEC_CONTENT
on	SEC_CONTENT
objective	SEC_CONTENT
evaluation	SEC_CONTENT
for	SEC_CONTENT
informativeness	SEC_CONTENT
and	SEC_CONTENT
manual	SEC_CONTENT
evaluation	SEC_CONTENT
for	SEC_CONTENT
correctness	SEC_CONTENT
.	SEC_CONTENT
Further	SEC_CONTENT
analysis	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
summarization	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
aware	SEC_CONTENT
of	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_END
Our	SEC_START
main	task
contributions	task
are	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
•	SEC_START
We	SEC_CONTENT
incorporate	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
into	SEC_CONTENT
summarization	task
models	task
to	SEC_CONTENT
avoid	SEC_CONTENT
producing	SEC_CONTENT
unrelated	SEC_CONTENT
information	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
•	SEC_START
We	SEC_CONTENT
propose	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
by	SEC_CONTENT
jointly	SEC_CONTENT
modeling	SEC_CONTENT
summarization	task
generation	task
and	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_END
•	SEC_START
We	SEC_CONTENT
introduce	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
via	SEC_CONTENT
entailment	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
Background	SECTITLE_START
:	SECTITLE_CONTENT
Seq2seq	SECTITLE_CONTENT
Learning	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
describe	SEC_CONTENT
the	SEC_CONTENT
basic	SEC_CONTENT
seq2seq	SEC_CONTENT
learning	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
dataset	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
-	SEC_CONTENT
output	SEC_CONTENT
pairs	SEC_CONTENT
,	SEC_END
,	SEC_START
the	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
maximizes	SEC_CONTENT
the	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
sequence	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
:	SEC_CONTENT
p(y	SEC_CONTENT
*	SEC_CONTENT
|x	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Recurrent	SEC_CONTENT
Neural	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
RNN	SEC_CONTENT
)	SEC_CONTENT
encoder	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
reads	SEC_CONTENT
and	SEC_CONTENT
converts	SEC_CONTENT
a	SEC_CONTENT
variablelength	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
x	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
representation	SEC_CONTENT
c	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
where	SEC_START
ht	SEC_CONTENT
∈	SEC_CONTENT
Rn	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
at	SEC_CONTENT
time	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
ct	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
generated	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
.	SEC_CONTENT
f	SEC_CONTENT
enc	SEC_CONTENT
and	SEC_CONTENT
f	SEC_CONTENT
care	SEC_CONTENT
nonlinear	SEC_CONTENT
activation	SEC_CONTENT
functions	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
decoder	SEC_CONTENT
generates	SEC_CONTENT
wordy	dataset
t	dataset
given	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
ct	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
previously	SEC_CONTENT
generated	SEC_CONTENT
words	SEC_CONTENT
:	SEC_END
where	SEC_START
st	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
and	SEC_CONTENT
f	SEC_CONTENT
dec	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
nonlinear	SEC_CONTENT
activation	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
maximum	SEC_CONTENT
likelihood	SEC_CONTENT
(	SEC_CONTENT
ML	SEC_CONTENT
)	SEC_CONTENT
framework	SEC_CONTENT
tries	SEC_CONTENT
to	SEC_CONTENT
minimize	SEC_CONTENT
negative	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
3	SEC_START
Our	SEC_CONTENT
Proposed	SEC_CONTENT
Model	SEC_END
Overview	SECTITLE_END
In	SEC_START
order	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
generating	SEC_CONTENT
unrelated	SEC_CONTENT
summary	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
two	SEC_CONTENT
strategies	SEC_CONTENT
to	SEC_CONTENT
incorporate	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
into	SEC_CONTENT
seq2seq	task
summarization	task
model	task
.	SEC_CONTENT
We	SEC_CONTENT
first	SEC_CONTENT
introduce	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
using	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
for	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
introduce	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
by	SEC_CONTENT
entailment	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
:	SEC_CONTENT
The	SEC_CONTENT
framework	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
is	SEC_CONTENT
learned	SEC_CONTENT
by	SEC_CONTENT
jointly	SEC_CONTENT
training	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
(	SEC_CONTENT
left	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
(	SEC_CONTENT
right	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
sentence	SEC_CONTENT
pair	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
corpus	SEC_CONTENT
are	SEC_CONTENT
encoded	SEC_CONTENT
as	SEC_CONTENT
u	SEC_CONTENT
and	SEC_CONTENT
v	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Entailmentaware	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
learned	SEC_CONTENT
by	SEC_CONTENT
entailment	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
rewarded	SEC_CONTENT
if	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
Entailment	SECTITLE_START
-	SECTITLE_CONTENT
aware	SECTITLE_CONTENT
Encoder	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
for	SEC_CONTENT
abstractive	task
summarization	task
by	SEC_CONTENT
sharing	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_CONTENT
By	SEC_CONTENT
doing	SEC_CONTENT
so	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
learn	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
for	SEC_CONTENT
sentence	SEC_CONTENT
summarization	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
way	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
correctness	SEC_CONTENT
aspect	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summarization	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
maintaining	SEC_CONTENT
the	SEC_CONTENT
salient	SEC_CONTENT
information	SEC_CONTENT
extraction	SEC_CONTENT
aspects	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
for	SEC_CONTENT
summarization	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
from	SEC_CONTENT
summarization	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_END
Shared	SECTITLE_START
Sentence	SECTITLE_CONTENT
Encoder	SECTITLE_END
Given	SEC_START
a	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
x	SEC_CONTENT
=	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
·	SEC_CONTENT
·	SEC_CONTENT
·	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
employ	SEC_CONTENT
a	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
BiLSTM	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
build	SEC_CONTENT
its	SEC_CONTENT
hidden	SEC_CONTENT
representation	SEC_CONTENT
(	SEC_CONTENT
h	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
·	SEC_CONTENT
·	SEC_CONTENT
·	SEC_CONTENT
,	SEC_CONTENT
h	SEC_CONTENT
n	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
BiLSTM	SEC_CONTENT
encodes	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
forwardly	SEC_CONTENT
and	SEC_CONTENT
backwardly	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
two	SEC_CONTENT
sequences	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
:	SEC_END
The	SEC_START
final	SEC_CONTENT
sentence	SEC_CONTENT
representation	SEC_CONTENT
hi	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
vectors	SEC_CONTENT
:	SEC_END
Attention	SECTITLE_START
-	SECTITLE_CONTENT
based	SECTITLE_CONTENT
Summarization	SECTITLE_CONTENT
Decoder	SECTITLE_END
At	SEC_START
each	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
st	SEC_CONTENT
is	SEC_CONTENT
calculated	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
We	SEC_START
compute	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
ct	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
weighted	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
annotations	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
where	SEC_START
each	SEC_CONTENT
vector	SEC_CONTENT
is	SEC_CONTENT
weighted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
weight	SEC_CONTENT
α	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
calculated	SEC_CONTENT
in	SEC_CONTENT
Equations	task
10	SEC_CONTENT
and	SEC_CONTENT
11	SEC_CONTENT
:	SEC_END
The	SEC_START
probability	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
target	SEC_CONTENT
wordy	dataset
t	dataset
is	SEC_CONTENT
computed	SEC_CONTENT
using	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
st	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
previously	SEC_CONTENT
emitted	SEC_CONTENT
wordy	SEC_CONTENT
t−1	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
where	SEC_START
and	SEC_START
L	SEC_CONTENT
y	SEC_CONTENT
are	SEC_CONTENT
model	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
The	task
summarization	task
model	task
is	SEC_CONTENT
trained	SEC_CONTENT
by	SEC_CONTENT
minimizing	SEC_CONTENT
negative	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
loss	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
4	SEC_CONTENT
.	SEC_END
Matching	SECTITLE_START
-	SECTITLE_CONTENT
based	SECTITLE_CONTENT
Entailment	SECTITLE_CONTENT
Inference	SECTITLE_CONTENT
Model	SECTITLE_END
To	SEC_START
infer	SEC_CONTENT
entailment	SEC_CONTENT
relation	SEC_CONTENT
,	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
corpus	SEC_CONTENT
are	SEC_CONTENT
fed	SEC_CONTENT
into	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
hidden	SEC_CONTENT
representation	SEC_END
,	SEC_START
respectively	SEC_CONTENT
.	SEC_CONTENT
Next	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
absolute	SEC_CONTENT
difference	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
element	SEC_CONTENT
-	SEC_CONTENT
wise	SEC_CONTENT
product	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
tuple	SEC_CONTENT
are	SEC_CONTENT
concatenated	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
vectors	SEC_CONTENT
u	SEC_CONTENT
and	SEC_CONTENT
v	SEC_CONTENT
(	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
We	SEC_START
then	SEC_CONTENT
feed	SEC_CONTENT
q	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
3-layer	SEC_CONTENT
multilayer	SEC_CONTENT
perceptron	SEC_CONTENT
(	SEC_CONTENT
MLP	SEC_CONTENT
)	SEC_CONTENT
classifier	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
3-class	SEC_CONTENT
softmax	SEC_CONTENT
output	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
on	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
MLP	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
by	SEC_CONTENT
minimizing	SEC_CONTENT
cross	SEC_CONTENT
-	SEC_CONTENT
entropy	SEC_CONTENT
loss	SEC_CONTENT
.	SEC_END
Multi	SECTITLE_START
-	SECTITLE_CONTENT
Task	SECTITLE_CONTENT
Learning	SECTITLE_CONTENT
(	SECTITLE_CONTENT
MTL	SECTITLE_CONTENT
)	SECTITLE_END
In	SEC_START
our	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
setup	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
share	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
shown	SEC_CONTENT
in(a	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Traditional	SEC_CONTENT
MTL	SEC_CONTENT
considers	SEC_CONTENT
equal	task
contribution	task
for	SEC_CONTENT
all	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
two	SEC_CONTENT
tasks	SEC_CONTENT
are	SEC_CONTENT
significantly	SEC_CONTENT
different	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
summary	SEC_CONTENT
generation	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
more	SEC_CONTENT
complicated	SEC_CONTENT
than	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
,	SEC_CONTENT
leading	SEC_CONTENT
to	SEC_CONTENT
different	SEC_CONTENT
learning	SEC_CONTENT
difficulties	SEC_CONTENT
and	SEC_CONTENT
convergence	SEC_CONTENT
rates	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
,	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
is	SEC_CONTENT
regarded	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
task	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
goal	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
optimize	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
task	SEC_CONTENT
with	SEC_CONTENT
assistance	SEC_CONTENT
of	SEC_CONTENT
auxiliary	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
this	SEC_CONTENT
end	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
optimize	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
loss	SEC_CONTENT
functions	SEC_CONTENT
alternatively	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
α	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batches	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
after	SEC_CONTENT
100	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batches	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
adopt	SEC_CONTENT
α	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
and	SEC_CONTENT
performance	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
α	SEC_CONTENT
is	SEC_CONTENT
discussed	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
6.6.3	SEC_CONTENT
.	SEC_END
Entailment	SECTITLE_START
-	SECTITLE_CONTENT
aware	SECTITLE_CONTENT
Decoder	SECTITLE_END
In	SEC_START
order	SEC_CONTENT
to	SEC_CONTENT
encourage	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
of	SEC_CONTENT
the	task
summarization	task
system	task
to	SEC_CONTENT
produce	SEC_CONTENT
summary	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
by	SEC_CONTENT
entailment	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
Norouzi	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Reward	SECTITLE_START
Augmented	SECTITLE_CONTENT
Maximum	SECTITLE_CONTENT
Likelihood	SECTITLE_CONTENT
(	SECTITLE_CONTENT
RAML	SECTITLE_CONTENT
)	SECTITLE_CONTENT
Training	SECTITLE_END
RAML	SEC_START
provides	SEC_CONTENT
a	SEC_CONTENT
computationally	SEC_CONTENT
efficient	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
optimize	SEC_CONTENT
task	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
reward	SEC_CONTENT
(	SEC_CONTENT
loss	SEC_CONTENT
)	SEC_CONTENT
directly	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
RAML	SEC_CONTENT
to	SEC_CONTENT
incorporate	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
reward	SEC_CONTENT
into	SEC_CONTENT
our	task
summarization	task
model	task
,	SEC_CONTENT
as	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
The	SEC_START
RAML	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
q	SEC_START
where	SEC_START
Y	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
model	SEC_CONTENT
outputs	SEC_CONTENT
.	SEC_CONTENT
r(x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
)	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
reward	SEC_CONTENT
function	SEC_CONTENT
and	SEC_CONTENT
τ	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
parameter	SEC_CONTENT
.	SEC_END
Optimizing	SECTITLE_START
by	SECTITLE_CONTENT
Entailment	SECTITLE_CONTENT
-	SECTITLE_CONTENT
based	SECTITLE_CONTENT
Sampling	SECTITLE_END
We	SEC_START
can	SEC_CONTENT
express	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
of	SEC_CONTENT
L	SEC_CONTENT
RAML	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
expectation	SEC_CONTENT
over	SEC_CONTENT
samples	SEC_CONTENT
from	SEC_CONTENT
q	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
;	SEC_CONTENT
τ	SEC_CONTENT
):	SEC_END
RAML	SEC_START
training	SEC_CONTENT
adds	SEC_CONTENT
a	SEC_CONTENT
sampling	SEC_CONTENT
step	SEC_CONTENT
over	SEC_CONTENT
typical	SEC_CONTENT
ML	SEC_CONTENT
objective	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
of	SEC_CONTENT
optimizing	SEC_CONTENT
ML	SEC_CONTENT
on	SEC_CONTENT
training	SEC_CONTENT
samples	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
training	SEC_CONTENT
input	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
first	SEC_CONTENT
samples	SEC_CONTENT
an	SEC_CONTENT
output	SEC_CONTENT
y	SEC_CONTENT
proportionally	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
reward	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
RAML	SEC_CONTENT
optimizes	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
likelihood	SEC_CONTENT
on	SEC_CONTENT
such	SEC_CONTENT
sample	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
sample	SEC_CONTENT
auxiliary	SEC_CONTENT
outputs	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
exponentiated	SEC_CONTENT
payoff	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
q	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
;	SEC_CONTENT
τ	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
use	SEC_CONTENT
reward	SEC_CONTENT
values	SEC_CONTENT
defined	SEC_CONTENT
by	SEC_CONTENT
negative	SEC_CONTENT
Hamming	SEC_CONTENT
distance	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
weight	SEC_CONTENT
the	SEC_CONTENT
reward	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
entailment	SEC_CONTENT
reward	SEC_CONTENT
s(x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
of	SEC_CONTENT
length	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
count	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
within	SEC_CONTENT
an	SEC_CONTENT
edit	SEC_CONTENT
distance	SEC_CONTENT
d	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
d	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2	SEC_CONTENT
}	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
weight	SEC_CONTENT
the	SEC_CONTENT
counts	SEC_CONTENT
by	SEC_CONTENT
exp{−d	SEC_CONTENT
/	SEC_CONTENT
τ	SEC_CONTENT
}	SEC_CONTENT
and	SEC_CONTENT
perform	SEC_CONTENT
normalization	task
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
importance	SEC_CONTENT
sampling	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
weight	SEC_CONTENT
exp{(s(x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
)	SEC_CONTENT
+	SEC_CONTENT
d)/τ	SEC_CONTENT
}	SEC_CONTENT
and	SEC_CONTENT
perform	SEC_CONTENT
normalization	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
proposal	SEC_CONTENT
distribution	SEC_CONTENT
is	SEC_CONTENT
Hamming	SEC_CONTENT
distance	SEC_CONTENT
sampling	SEC_CONTENT
2	SEC_CONTENT
.	SEC_END
We	SEC_START
define	SEC_CONTENT
entailment	SEC_CONTENT
reward	SEC_CONTENT
s(x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
*	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
where	SEC_START
e(x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
)	SEC_CONTENT
denotes	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
sentence	SEC_CONTENT
pairs	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Our	metric
goal	metric
is	SEC_CONTENT
to	SEC_CONTENT
maximize	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
reward	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
towards	SEC_CONTENT
the	SEC_CONTENT
reference	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Here	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
of	SEC_END
Related	SECTITLE_START
work	SECTITLE_END
Text	SEC_START
summarization	task
methods	task
can	SEC_CONTENT
be	SEC_CONTENT
categorized	SEC_CONTENT
into	SEC_CONTENT
extraction	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
methods	SEC_CONTENT
(	SEC_CONTENT
solve	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
of	SEC_CONTENT
fake	SEC_CONTENT
facts	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
use	SEC_CONTENT
Open	SEC_CONTENT
Information	SEC_CONTENT
Extraction	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
fact	SEC_CONTENT
descriptions	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
propose	SEC_CONTENT
the	SEC_CONTENT
dual	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
seq2seq	SEC_CONTENT
framework	SEC_CONTENT
to	SEC_CONTENT
force	SEC_CONTENT
the	SEC_CONTENT
generation	SEC_CONTENT
conditioned	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
fact	SEC_CONTENT
descriptions	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
to	SEC_CONTENT
directly	SEC_CONTENT
explore	SEC_CONTENT
the	SEC_CONTENT
correctness	SEC_CONTENT
of	SEC_CONTENT
summary	SEC_CONTENT
without	SEC_CONTENT
any	SEC_CONTENT
preprocessing	SEC_CONTENT
.	SEC_CONTENT
Some	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
used	SEC_CONTENT
textual	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
to	SEC_CONTENT
reduce	SEC_CONTENT
redundancy	SEC_CONTENT
for	SEC_CONTENT
extractive	SEC_CONTENT
summarization	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
partially	SEC_CONTENT
inspired	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
of	SEC_CONTENT
with	SEC_CONTENT
following	SEC_CONTENT
differences	SEC_CONTENT
:	SEC_CONTENT
Pasunuru	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
model	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
task	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
seq2seq	SEC_CONTENT
generation	SEC_CONTENT
problem	SEC_CONTENT
and	SEC_CONTENT
enforce	SEC_CONTENT
sharing	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
decoder	SEC_CONTENT
between	SEC_CONTENT
summarization	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
reasonable	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
considered	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
label	SEC_CONTENT
classification	SEC_CONTENT
problem	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
generation	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
thus	SEC_CONTENT
design	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
framework	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
task	SEC_CONTENT
shares	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
encoder	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
Dataset	SECTITLE_END
We	SEC_START
conduct	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
English	dataset
Gigaword	dataset
and	SEC_CONTENT
DUC	SEC_CONTENT
2004	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_END
Gigaword	SEC_START
Corpus	dataset
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
annotated	SEC_CONTENT
Gigaword	SEC_CONTENT
corpus	SEC_CONTENT
provided	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
dataset	SEC_CONTENT
has	SEC_CONTENT
about	SEC_CONTENT
3.8	SEC_CONTENT
million	SEC_CONTENT
training	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
8	SEC_CONTENT
,	SEC_CONTENT
000	SEC_CONTENT
pairs	SEC_CONTENT
as	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
samples	SEC_CONTENT
provided	SEC_CONTENT
by	SEC_CONTENT
and	SEC_CONTENT
 	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_END
DUC	SEC_START
2004	dataset
Corpus	dataset
.	SEC_CONTENT
DUC-2004	SEC_CONTENT
corpus	SEC_CONTENT
for	SEC_CONTENT
tasks	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
500	SEC_CONTENT
documents	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
document	SEC_CONTENT
in	SEC_CONTENT
these	SEC_CONTENT
datasets	SEC_CONTENT
has	SEC_CONTENT
four	SEC_CONTENT
human	SEC_CONTENT
annotated	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
directly	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Gigaword	SEC_CONTENT
to	SEC_CONTENT
test	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
DUC	SEC_CONTENT
2004	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_END
Experiment	SECTITLE_END
Experimental	SECTITLE_START
Settings	SECTITLE_END
Word	SEC_START
embedding	SEC_CONTENT
size	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
300	SEC_CONTENT
and	SEC_CONTENT
LSTM	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
size	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
512	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
source	SEC_CONTENT
and	SEC_CONTENT
target	SEC_CONTENT
vocabularies	SEC_CONTENT
collected	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
have	SEC_CONTENT
119	SEC_CONTENT
,	SEC_CONTENT
505	SEC_CONTENT
and	SEC_CONTENT
68	SEC_CONTENT
,	SEC_CONTENT
885	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
Adam	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
optimizer	SEC_CONTENT
is	SEC_CONTENT
applied	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
0.001	SEC_CONTENT
,	SEC_CONTENT
momentum	SEC_CONTENT
parameters	SEC_CONTENT
β	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
0.9	SEC_CONTENT
and	SEC_CONTENT
β	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
0.999	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
−8	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
RAML	SEC_CONTENT
,	SEC_CONTENT
τ	SEC_CONTENT
=	SEC_CONTENT
0.85	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
is	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
64	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
test	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
performance	SEC_CONTENT
(	SEC_CONTENT
ROUGE-2	metric
F1	metric
score	metric
)	SEC_CONTENT
on	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
2,000	SEC_CONTENT
batches	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
halve	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
if	SEC_CONTENT
the	SEC_CONTENT
ROUGE-2	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
drops	SEC_CONTENT
for	SEC_CONTENT
twelve	SEC_CONTENT
consecutive	SEC_CONTENT
tests	SEC_CONTENT
on	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
apply	SEC_CONTENT
gradient	SEC_CONTENT
clipping	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
range	SEC_CONTENT
[	SEC_CONTENT
−5	SEC_CONTENT
,	SEC_CONTENT
5	SEC_CONTENT
]	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
entailmentaware	SEC_CONTENT
encode	SEC_CONTENT
requires	SEC_CONTENT
less	SEC_CONTENT
than	SEC_CONTENT
300,000	SEC_CONTENT
training	SEC_CONTENT
iterations	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
with	SEC_CONTENT
early	SEC_CONTENT
stopping	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
speedup	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
RAML	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
continue	SEC_CONTENT
the	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
ML	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
decayed	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
test	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
size	SEC_CONTENT
10	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
ROUGE	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
including	SEC_CONTENT
ROUGE-1	SEC_CONTENT
,	SEC_CONTENT
ROUGE-2	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
for	SEC_CONTENT
Gigaword	SEC_CONTENT
corpus	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
recall	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
DUC	SEC_CONTENT
2004	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_END
Comparative	SECTITLE_START
Methods	SECTITLE_END
We	SEC_START
compare	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
sentence	task
summarization	task
baselines	task
.	SEC_CONTENT
ABS	SEC_CONTENT
.	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
LSTMs	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
applies	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
MTL	SEC_CONTENT
)	SEC_CONTENT
framework	SEC_CONTENT
to	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
(	SEC_CONTENT
Share	SEC_CONTENT
decoder	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
MTL	SEC_CONTENT
)	SEC_CONTENT
framework	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
shared	SEC_CONTENT
for	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
generation	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
ERAML	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
our	SEC_CONTENT
proposed	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
conducts	SEC_CONTENT
an	SEC_CONTENT
Entailment	SEC_CONTENT
Reward	SEC_CONTENT
Augmented	SEC_CONTENT
Maximum	SEC_CONTENT
Likelihood	SEC_CONTENT
(	SEC_CONTENT
ERAML	SEC_CONTENT
)	SEC_CONTENT
training	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
ROUGE-2	SEC_CONTENT
RAML	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
apply	SEC_CONTENT
ROUGE-2	SEC_CONTENT
RAML	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
RL	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
implement	SEC_CONTENT
Reinforcement	SEC_CONTENT
Learning	SEC_CONTENT
(	SEC_CONTENT
RL	SEC_CONTENT
)	SEC_CONTENT
models	SEC_CONTENT
(	SEC_CONTENT
policy	SEC_CONTENT
gradient	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
reward	SEC_CONTENT
metrics	SEC_CONTENT
of	SEC_CONTENT
Entailment	SEC_CONTENT
and	SEC_CONTENT
ROUGE-2	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
selective	SEC_CONTENT
.	SEC_CONTENT
 	SEC_CONTENT
employ	SEC_CONTENT
a	SEC_CONTENT
selective	SEC_CONTENT
encoding	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
control	SEC_CONTENT
the	SEC_CONTENT
information	SEC_CONTENT
flow	SEC_CONTENT
from	SEC_CONTENT
encoder	SEC_CONTENT
to	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
verify	SEC_CONTENT
the	SEC_CONTENT
generalization	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
strategies	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
selective	SEC_CONTENT
encoding	SEC_CONTENT
mechanism	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
apply	SEC_CONTENT
MTL	SEC_CONTENT
and	SEC_CONTENT
RAML	SEC_CONTENT
to	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
selective	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
denoted	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
selective	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
+	SEC_CONTENT
RAML	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
:	SEC_CONTENT
Experimental	SEC_CONTENT
results	SEC_CONTENT
(	SEC_CONTENT
%	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
English	SEC_CONTENT
Gigaword	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
models	SEC_CONTENT
perform	SEC_CONTENT
significantly	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
baselines	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
95	SEC_CONTENT
%	SEC_CONTENT
confidence	SEC_CONTENT
interval	SEC_CONTENT
measured	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
official	SEC_CONTENT
ROUGE	SEC_CONTENT
script	SEC_CONTENT
.	SEC_END
Experimental	SECTITLE_START
Results	SECTITLE_CONTENT
:	SECTITLE_CONTENT
Gigaword	SECTITLE_CONTENT
Corpus	SECTITLE_END
In	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
ROUGE	SEC_CONTENT
F1	SEC_CONTENT
score	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
methods	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
English	SEC_CONTENT
Gigaword	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
provided	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
models	SEC_CONTENT
outperform	SEC_CONTENT
all	SEC_CONTENT
baseline	SEC_CONTENT
models	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
margin	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
final	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
selective	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
+	SEC_CONTENT
ERAML	SEC_CONTENT
,	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
improves	SEC_CONTENT
2.52	metric
(	metric
%	metric
)	metric
ROUGE-1	metric
,	SEC_CONTENT
2.32	SEC_CONTENT
ROUGE-2	SEC_CONTENT
and	SEC_CONTENT
2.33	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
over	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
encoder	SEC_CONTENT
(	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
)	SEC_CONTENT
surpasses	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
of	SEC_CONTENT
1.35	SEC_CONTENT
ROUGE-1	SEC_CONTENT
,	SEC_CONTENT
1.59	SEC_CONTENT
ROUGE-2	SEC_CONTENT
,	SEC_CONTENT
1.36	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
(	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
ER	SEC_CONTENT
-	SEC_CONTENT
AML	SEC_CONTENT
)	SEC_CONTENT
gains	SEC_CONTENT
improvement	SEC_CONTENT
of	SEC_CONTENT
0.95	SEC_CONTENT
ROUGE-1	SEC_CONTENT
,	SEC_CONTENT
1.46	SEC_CONTENT
ROUGE-2	SEC_CONTENT
,	SEC_CONTENT
0.97	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L.	SEC_CONTENT
Compared	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
another	SEC_CONTENT
MTL	SEC_CONTENT
model	SEC_CONTENT
via	SEC_CONTENT
sharing	SEC_CONTENT
decoder	SEC_CONTENT
for	SEC_CONTENT
entailment	SEC_CONTENT
generation	SEC_CONTENT
task	SEC_CONTENT
(	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
(	SEC_CONTENT
Share	SEC_CONTENT
decoder	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
MTL	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
obvious	SEC_CONTENT
ROUGE	SEC_CONTENT
score	SEC_CONTENT
gains	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
ROUGE-2	SEC_CONTENT
RAML	SEC_CONTENT
model	SEC_CONTENT
also	SEC_CONTENT
shows	SEC_CONTENT
promising	SEC_CONTENT
performance	SEC_CONTENT
,	SEC_CONTENT
especially	SEC_CONTENT
for	SEC_CONTENT
ROUGE-2	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
RAML	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
clear	SEC_CONTENT
advantage	SEC_CONTENT
over	SEC_CONTENT
RL	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
principle	SEC_CONTENT
,	SEC_CONTENT
RL	SEC_CONTENT
samples	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
distribution	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
slows	SEC_CONTENT
down	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
several	SEC_CONTENT
tricks	SEC_CONTENT
are	SEC_CONTENT
needed	SEC_CONTENT
to	SEC_CONTENT
get	SEC_CONTENT
better	SEC_CONTENT
estimates	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
comparison	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
of	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
selective	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
strategies	SEC_CONTENT
are	SEC_CONTENT
also	SEC_CONTENT
useful	SEC_CONTENT
for	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
selective	SEC_CONTENT
encoding	SEC_CONTENT
framework	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
demonstrates	SEC_CONTENT
the	SEC_CONTENT
good	SEC_CONTENT
generalization	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
method	SEC_CONTENT
.	SEC_END
The	SEC_START
results	SEC_CONTENT
on	SEC_CONTENT
English	SEC_CONTENT
Gigaword	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
provided	SEC_CONTENT
by	SEC_CONTENT
are	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
performs	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
works	SEC_CONTENT
.	SEC_END
Experimental	SECTITLE_START
Results	SECTITLE_CONTENT
:	SECTITLE_CONTENT
DUC	SECTITLE_CONTENT
2004	SECTITLE_CONTENT
Test	SECTITLE_CONTENT
Corpus	SECTITLE_END
We	SEC_START
evaluate	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
ROUGE	SEC_CONTENT
recall	SEC_CONTENT
score	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
reference	SEC_CONTENT
summaries	SEC_CONTENT
of	SEC_CONTENT
the	dataset
DUC	dataset
2004	dataset
test	dataset
set	dataset
are	SEC_CONTENT
fixed	SEC_CONTENT
to	SEC_CONTENT
75	SEC_CONTENT
bytes	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
maximum	SEC_CONTENT
length	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
to	SEC_CONTENT
18	SEC_CONTENT
following	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
,	SEC_CONTENT
experimental	SEC_CONTENT
results	SEC_CONTENT
also	SEC_CONTENT
show	SEC_CONTENT
our	SEC_CONTENT
Seq2seq	SEC_CONTENT
+	SEC_CONTENT
selective	SEC_CONTENT
+	SEC_CONTENT
MTL	SEC_CONTENT
+	SEC_CONTENT
ERAML	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
significant	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
baseline	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
surpassing	SEC_CONTENT
Feats2s	SEC_CONTENT
(	SEC_CONTENT
Nallapati	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2016	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
0.98	SEC_CONTENT
%	SEC_CONTENT
ROUGE-1	SEC_CONTENT
,	SEC_CONTENT
0.78	SEC_CONTENT
%	SEC_CONTENT
ROUGE-2	SEC_CONTENT
and	SEC_CONTENT
0.65	SEC_CONTENT
%	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
without	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
tuning	SEC_CONTENT
on	SEC_CONTENT
DUC	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Manual	SECTITLE_START
Evaluation	SECTITLE_END
Next	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
conduct	SEC_CONTENT
a	SEC_CONTENT
manual	SEC_CONTENT
evaluation	SEC_CONTENT
to	SEC_CONTENT
inspect	SEC_CONTENT
the	SEC_CONTENT
correctness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
generated	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
randomly	SEC_CONTENT
select	SEC_CONTENT
500	SEC_CONTENT
samples	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
employ	SEC_CONTENT
five	SEC_CONTENT
postgraduates	SEC_CONTENT
to	SEC_CONTENT
classify	SEC_CONTENT
the	SEC_CONTENT
generated	SEC_CONTENT
summaries	SEC_CONTENT
as	SEC_CONTENT
correct	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
not	SEC_CONTENT
contain	SEC_CONTENT
wrong	SEC_CONTENT
information	SEC_CONTENT
)	SEC_CONTENT
or	SEC_CONTENT
not	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
60.6	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	task
summaries	task
generated	SEC_CONTENT
by	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
are	SEC_CONTENT
correct	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
it	SEC_CONTENT
rises	SEC_CONTENT
to	SEC_CONTENT
69.4	SEC_CONTENT
%	SEC_CONTENT
and	SEC_CONTENT
74.2	SEC_CONTENT
%	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
selective	SEC_CONTENT
encoding	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
strategies	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
indicates	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
a	SEC_CONTENT
correct	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
:	SEC_CONTENT
Manual	SEC_CONTENT
evaluation	SEC_CONTENT
for	SEC_CONTENT
correctness	SEC_CONTENT
.	SEC_END
Further	SECTITLE_START
Analysis	SECTITLE_END
To	SEC_START
further	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
perform	SEC_CONTENT
analysis	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
improvement	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
abstraction	SEC_CONTENT
degree	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
for	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
Does	SECTITLE_START
our	SECTITLE_CONTENT
summarization	SECTITLE_CONTENT
model	SECTITLE_CONTENT
learn	SECTITLE_CONTENT
entailment	SECTITLE_CONTENT
knowledge	SECTITLE_CONTENT
?	SECTITLE_END
The	SEC_START
motivation	task
of	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
encourage	SEC_CONTENT
summarization	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
summaries	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
verify	SEC_CONTENT
this	SEC_CONTENT
goal	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
source	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
for	SEC_CONTENT
different	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
reference	SEC_CONTENT
is	SEC_CONTENT
0.72	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
basic	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
0.46	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
entailmentbased	SEC_CONTENT
strategies	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
rises	SEC_CONTENT
to	SEC_CONTENT
0.63	SEC_CONTENT
for	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
score	SEC_CONTENT
is	SEC_CONTENT
0.57	SEC_CONTENT
for	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
selective	SEC_CONTENT
encoding	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
believe	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
selective	SEC_CONTENT
mechanism	SEC_CONTENT
can	SEC_CONTENT
filter	SEC_CONTENT
out	SEC_CONTENT
secondary	SEC_CONTENT
information	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
will	SEC_CONTENT
reduce	SEC_CONTENT
the	SEC_CONTENT
possibility	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
irrelevant	SEC_CONTENT
information	SEC_CONTENT
.	SEC_CONTENT
Entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
selective	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
a	SEC_CONTENT
high	SEC_CONTENT
entailment	SEC_CONTENT
reward	SEC_CONTENT
of	SEC_CONTENT
0.71	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
part	SEC_CONTENT
at	SEC_CONTENT
least	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
conclude	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
successfully	SEC_CONTENT
learned	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
.	SEC_END
Is	SECTITLE_START
it	SECTITLE_CONTENT
less	SECTITLE_CONTENT
abstractive	SECTITLE_CONTENT
for	SECTITLE_CONTENT
our	SECTITLE_CONTENT
model	SECTITLE_CONTENT
?	SECTITLE_END
We	SEC_START
have	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
generate	SEC_CONTENT
correct	SEC_CONTENT
summaries	SEC_CONTENT
more	SEC_CONTENT
frequently	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
6.5	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Intuitively	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
likely	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
correct	SEC_CONTENT
if	SEC_CONTENT
summary	SEC_CONTENT
segments	SEC_CONTENT
are	SEC_CONTENT
directly	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
readers	SEC_CONTENT
may	SEC_CONTENT
wonder	SEC_CONTENT
whether	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
less	SEC_CONTENT
abstractive	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
produces	SEC_CONTENT
more	SEC_CONTENT
novel	SEC_CONTENT
words	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
appear	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
article	SEC_CONTENT
)	SEC_CONTENT
than	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
indicating	SEC_CONTENT
a	SEC_CONTENT
lower	SEC_CONTENT
degree	SEC_CONTENT
of	SEC_CONTENT
abstraction	task
for	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
we	SEC_CONTENT
exclude	SEC_CONTENT
all	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
not	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
reference	SEC_CONTENT
(	SEC_CONTENT
these	SEC_CONTENT
words	SEC_CONTENT
may	SEC_CONTENT
lead	SEC_CONTENT
to	SEC_CONTENT
wrong	SEC_CONTENT
information	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
generates	SEC_CONTENT
more	SEC_CONTENT
novel	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
suggesting	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
compromise	SEC_CONTENT
solution	SEC_CONTENT
for	SEC_CONTENT
informativeness	SEC_CONTENT
and	SEC_CONTENT
correctness	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
generate	SEC_CONTENT
summary	SEC_CONTENT
with	SEC_CONTENT
fewer	SEC_CONTENT
mistakes	SEC_CONTENT
.	SEC_CONTENT
  	SEC_CONTENT
6.6.3	SEC_CONTENT
Could	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
improved	SEC_CONTENT
?	SEC_CONTENT
Multi	SEC_CONTENT
-	SEC_CONTENT
task	SEC_CONTENT
learning	SEC_CONTENT
(	SEC_CONTENT
MTL	SEC_CONTENT
)	SEC_CONTENT
involves	SEC_CONTENT
sharing	SEC_CONTENT
parameters	SEC_CONTENT
between	SEC_CONTENT
related	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
whereby	SEC_CONTENT
each	SEC_CONTENT
task	SEC_CONTENT
can	SEC_CONTENT
benefit	SEC_CONTENT
from	SEC_CONTENT
extra	SEC_CONTENT
information	SEC_CONTENT
of	SEC_CONTENT
other	SEC_CONTENT
tasks	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
process	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
explore	SEC_CONTENT
whether	SEC_CONTENT
the	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
can	SEC_CONTENT
benefit	SEC_CONTENT
from	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
summarization	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
MTL	SEC_CONTENT
outperforms	SEC_CONTENT
basic	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
α	SEC_CONTENT
increases	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
improves	SEC_CONTENT
and	SEC_CONTENT
finally	SEC_CONTENT
exceeds	SEC_CONTENT
that	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
without	SEC_CONTENT
MTL	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
reveals	SEC_CONTENT
the	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
MTL	SEC_CONTENT
framework	SEC_CONTENT
.	SEC_END
Case	SECTITLE_START
Study	SECTITLE_END
We	SEC_START
illustrate	SEC_CONTENT
the	SEC_CONTENT
examples	SEC_CONTENT
of	SEC_CONTENT
outputs	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
table	SEC_CONTENT
,	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
generates	SEC_CONTENT
summaries	task
that	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
relevant	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
obtains	SEC_CONTENT
higher	SEC_CONTENT
entailment	SEC_CONTENT
scores	SEC_CONTENT
than	SEC_CONTENT
those	SEC_CONTENT
of	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
regards	SEC_CONTENT
the	SEC_CONTENT
reason	SEC_CONTENT
for	SEC_CONTENT
"	SEC_CONTENT
brazil	SEC_CONTENT
stocks	SEC_CONTENT
rise	SEC_CONTENT
"	SEC_CONTENT
as	SEC_CONTENT
"	SEC_CONTENT
consumer	SEC_CONTENT
credit	SEC_CONTENT
concerns	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
in	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
consumer	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
worried	SEC_CONTENT
because	SEC_CONTENT
"	SEC_CONTENT
government	SEC_CONTENT
said	SEC_CONTENT
it	SEC_CONTENT
would	SEC_CONTENT
n't	SEC_CONTENT
impose	SEC_CONTENT
restraints	SEC_CONTENT
on	SEC_CONTENT
consumer	SEC_CONTENT
credit	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
By	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
incorporates	SEC_CONTENT
entailment	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
reason	SEC_CONTENT
is	SEC_CONTENT
captured	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
similar	SEC_CONTENT
problem	SEC_CONTENT
happens	SEC_CONTENT
in	SEC_CONTENT
example	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
generates	SEC_CONTENT
a	SEC_CONTENT
summary	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
contradictory	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
"	SEC_CONTENT
demonstration	SEC_CONTENT
"	SEC_CONTENT
is	SEC_CONTENT
"	SEC_CONTENT
denied	SEC_CONTENT
"	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
authorities	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
seq2seq	SEC_CONTENT
model	SEC_CONTENT
confirms	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
demonstration	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
Example	SEC_CONTENT
3	SEC_CONTENT
,	SEC_CONTENT
neither	SEC_CONTENT
seq2seq	SEC_CONTENT
nor	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
performs	SEC_CONTENT
satisfactorily	SEC_CONTENT
.	SEC_CONTENT
Seq2seq	SEC_CONTENT
model	SEC_CONTENT
again	SEC_CONTENT
misunderstands	SEC_CONTENT
the	SEC_CONTENT
meaning	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
and	SEC_CONTENT
outputs	SEC_CONTENT
summary	SEC_CONTENT
containing	SEC_CONTENT
wrong	SEC_CONTENT
information	SEC_CONTENT
.	SEC_CONTENT
Though	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
generated	SEC_CONTENT
by	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
fails	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
an	SEC_CONTENT
integrated	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
misses	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
points	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
object	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
event	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
queens	SEC_CONTENT
taxi	SEC_CONTENT
driver	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
mixed	SEC_CONTENT
reward	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
combining	SEC_CONTENT
entailment	SEC_CONTENT
and	SEC_CONTENT
ROUGE-2	SEC_CONTENT
,	SEC_CONTENT
may	SEC_CONTENT
address	SEC_CONTENT
this	SEC_CONTENT
issue	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
leave	SEC_CONTENT
it	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
This	SEC_START
paper	SEC_CONTENT
investigates	SEC_CONTENT
the	SEC_CONTENT
correctness	SEC_CONTENT
problem	SEC_CONTENT
in	SEC_CONTENT
abstractive	task
summarization	task
.	SEC_CONTENT
We	SEC_CONTENT
propose	SEC_CONTENT
an	SEC_CONTENT
entailmentaware	SEC_CONTENT
encoder	SEC_CONTENT
by	SEC_CONTENT
jointly	SEC_CONTENT
learning	SEC_CONTENT
summarization	SEC_CONTENT
generation	SEC_CONTENT
and	SEC_CONTENT
entailment	SEC_CONTENT
recognition	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
present	SEC_CONTENT
an	SEC_CONTENT
entailment	SEC_CONTENT
-	SEC_CONTENT
aware	SEC_CONTENT
decoder	SEC_CONTENT
by	SEC_CONTENT
entailment	SEC_CONTENT
reward	SEC_CONTENT
augmented	SEC_CONTENT
maximum	SEC_CONTENT
likelihood	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
By	SEC_CONTENT
enriching	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
and	SEC_CONTENT
decoder	SEC_CONTENT
with	SEC_CONTENT
entailment	SEC_CONTENT
information	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
makes	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
more	SEC_CONTENT
likely	SEC_CONTENT
be	SEC_CONTENT
entailed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
Experimental	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
datasets	SEC_CONTENT
demonstrate	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
significant	SEC_CONTENT
improvements	SEC_CONTENT
over	SEC_CONTENT
strong	SEC_CONTENT
baselines	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
informativeness	SEC_CONTENT
and	SEC_CONTENT
correctness	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
code	SEC_CONTENT
is	SEC_CONTENT
available	SEC_CONTENT
online	SEC_CONTENT
4	SEC_CONTENT
.	SEC_END
