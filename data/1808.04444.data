title	SECTITLE_END
Character	SEC_START
-	SEC_CONTENT
Level	SEC_CONTENT
Language	SEC_CONTENT
Modeling	SEC_CONTENT
with	SEC_CONTENT
Deeper	SEC_CONTENT
Self	SEC_CONTENT
-	SEC_CONTENT
Attention	SEC_END
abstract	SECTITLE_END
LSTMs	SEC_START
and	SEC_CONTENT
other	SEC_CONTENT
RNN	SEC_CONTENT
variants	SEC_CONTENT
have	SEC_CONTENT
shown	SEC_CONTENT
strong	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
character	task
-	task
level	task
language	task
modeling	task
.	SEC_CONTENT
These	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
typically	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
truncated	SEC_CONTENT
backpropagation	SEC_CONTENT
through	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
common	SEC_CONTENT
to	SEC_CONTENT
assume	SEC_CONTENT
that	SEC_CONTENT
their	SEC_CONTENT
success	SEC_CONTENT
stems	SEC_CONTENT
from	SEC_CONTENT
their	SEC_CONTENT
ability	SEC_CONTENT
to	SEC_CONTENT
remember	SEC_CONTENT
long	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
contexts	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
(	SEC_CONTENT
64-layer	SEC_CONTENT
)	SEC_CONTENT
transformer	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
Vaswani	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
fixed	SEC_CONTENT
context	SEC_CONTENT
outperforms	SEC_CONTENT
RNN	SEC_CONTENT
variants	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
margin	SEC_CONTENT
,	SEC_CONTENT
achieving	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
two	SEC_CONTENT
popular	SEC_CONTENT
benchmarks	SEC_CONTENT
:	SEC_CONTENT
1.13	SEC_CONTENT
bits	SEC_CONTENT
per	SEC_CONTENT
character	SEC_CONTENT
on	SEC_CONTENT
text8	SEC_CONTENT
and	SEC_CONTENT
1.06	SEC_CONTENT
on	SEC_CONTENT
enwik8	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
get	SEC_CONTENT
good	SEC_CONTENT
results	SEC_CONTENT
at	SEC_CONTENT
this	SEC_CONTENT
depth	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
important	SEC_CONTENT
to	SEC_CONTENT
add	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
,	SEC_CONTENT
both	SEC_CONTENT
at	SEC_CONTENT
intermediate	SEC_CONTENT
network	SEC_CONTENT
layers	SEC_CONTENT
and	SEC_CONTENT
intermediate	SEC_CONTENT
sequence	SEC_CONTENT
positions	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Character	SEC_START
-	task
level	task
modeling	task
of	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
text	SEC_CONTENT
is	SEC_CONTENT
challenging	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
several	SEC_CONTENT
reasons	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
must	SEC_CONTENT
learn	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
vocabulary	SEC_CONTENT
of	SEC_CONTENT
words	SEC_CONTENT
"	SEC_CONTENT
from	SEC_CONTENT
scratch	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
natural	SEC_CONTENT
text	SEC_CONTENT
exhibits	SEC_CONTENT
dependencies	SEC_CONTENT
overlong	SEC_CONTENT
distances	SEC_CONTENT
of	SEC_CONTENT
hundreds	SEC_CONTENT
or	SEC_CONTENT
thousands	SEC_CONTENT
of	SEC_CONTENT
time	SEC_CONTENT
steps	SEC_CONTENT
.	SEC_CONTENT
Third	SEC_CONTENT
,	SEC_CONTENT
character	SEC_CONTENT
sequences	SEC_CONTENT
are	SEC_CONTENT
longer	SEC_CONTENT
than	SEC_CONTENT
word	SEC_CONTENT
sequences	SEC_CONTENT
and	SEC_CONTENT
thus	SEC_CONTENT
require	SEC_CONTENT
significantly	SEC_CONTENT
more	SEC_CONTENT
steps	SEC_CONTENT
of	SEC_CONTENT
computation	SEC_CONTENT
.	SEC_END
In	SEC_START
recent	SEC_CONTENT
years	SEC_CONTENT
,	SEC_CONTENT
strong	task
character	task
-	task
level	task
language	task
models	task
typically	SEC_CONTENT
follow	SEC_CONTENT
a	SEC_CONTENT
common	SEC_CONTENT
template	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
net	SEC_CONTENT
(	SEC_CONTENT
RNN	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
over	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batches	SEC_CONTENT
of	SEC_CONTENT
text	SEC_CONTENT
sequences	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
relatively	SEC_CONTENT
short	SEC_CONTENT
sequence	SEC_CONTENT
length	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
200	SEC_CONTENT
tokens	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
capture	SEC_CONTENT
context	SEC_CONTENT
longer	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
sequence	SEC_CONTENT
length	SEC_CONTENT
,	SEC_CONTENT
training	SEC_CONTENT
batches	SEC_CONTENT
are	SEC_CONTENT
provided	SEC_CONTENT
in	SEC_CONTENT
sequential	SEC_CONTENT
order	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
batch	SEC_CONTENT
are	SEC_CONTENT
passed	SEC_CONTENT
forward	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
batch	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
procedure	SEC_CONTENT
is	SEC_CONTENT
known	SEC_CONTENT
as	SEC_CONTENT
"	SEC_CONTENT
truncated	SEC_CONTENT
backpropagation	SEC_CONTENT
through	SEC_CONTENT
time	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
TBTT	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
computation	SEC_CONTENT
does	SEC_CONTENT
n't	SEC_CONTENT
proceed	SEC_CONTENT
further	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
batch	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
methods	SEC_CONTENT
have	SEC_CONTENT
arisen	SEC_CONTENT
for	SEC_CONTENT
unbiasing	SEC_CONTENT
and	SEC_CONTENT
improving	SEC_CONTENT
TBTT	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
While	SEC_START
this	SEC_CONTENT
technique	SEC_CONTENT
gets	SEC_CONTENT
good	SEC_CONTENT
results	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
adds	SEC_CONTENT
complexity	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
recent	SEC_CONTENT
work	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
models	SEC_CONTENT
trained	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
manner	SEC_CONTENT
do	SEC_CONTENT
n't	SEC_CONTENT
actually	SEC_CONTENT
make	SEC_CONTENT
"	SEC_CONTENT
strong	SEC_CONTENT
"	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
long	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
a	task
word	task
-	task
based	task
LSTM	task
language	task
model	task
only	SEC_CONTENT
effectively	SEC_CONTENT
uses	SEC_CONTENT
around	SEC_CONTENT
200	SEC_CONTENT
tokens	SEC_CONTENT
of	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
even	SEC_CONTENT
if	SEC_CONTENT
more	SEC_CONTENT
is	SEC_CONTENT
provided	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
that	SEC_CONTENT
word	SEC_CONTENT
order	SEC_CONTENT
only	SEC_CONTENT
has	SEC_CONTENT
an	SEC_CONTENT
effect	SEC_CONTENT
within	SEC_CONTENT
approximately	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
50	SEC_CONTENT
tokens	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
a	task
non	task
-	task
recurrent	task
model	task
can	SEC_CONTENT
achieve	SEC_CONTENT
strong	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
network	SEC_CONTENT
of	SEC_CONTENT
transformer	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
layers	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
causal	SEC_CONTENT
(	SEC_CONTENT
backward	SEC_CONTENT
-	SEC_CONTENT
looking	SEC_CONTENT
)	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
length	SEC_CONTENT
inputs	SEC_CONTENT
and	SEC_CONTENT
predict	SEC_CONTENT
upcoming	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batches	SEC_CONTENT
of	SEC_CONTENT
sequences	SEC_CONTENT
from	SEC_CONTENT
random	SEC_CONTENT
positions	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
no	SEC_CONTENT
information	SEC_CONTENT
passed	SEC_CONTENT
from	SEC_CONTENT
one	SEC_CONTENT
batch	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
.	SEC_END
Our	SEC_START
primary	SEC_CONTENT
finding	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
transformer	SEC_CONTENT
architecture	SEC_CONTENT
is	SEC_CONTENT
well	SEC_CONTENT
-	SEC_CONTENT
suited	SEC_CONTENT
to	SEC_CONTENT
language	task
modeling	SEC_CONTENT
overlong	SEC_CONTENT
sequences	SEC_CONTENT
and	SEC_CONTENT
could	SEC_CONTENT
replace	SEC_CONTENT
RNNs	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
domain	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
speculate	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
transformer	SEC_CONTENT
's	SEC_CONTENT
success	SEC_CONTENT
here	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
ability	SEC_CONTENT
to	SEC_CONTENT
"	SEC_CONTENT
quickly	SEC_CONTENT
"	SEC_CONTENT
propagate	SEC_CONTENT
information	SEC_CONTENT
over	SEC_CONTENT
arbitrary	SEC_CONTENT
distances	SEC_CONTENT
;	SEC_CONTENT
by	SEC_CONTENT
comparison	SEC_CONTENT
,	SEC_CONTENT
RNNs	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
to	SEC_CONTENT
pass	SEC_CONTENT
relevant	SEC_CONTENT
information	SEC_CONTENT
forward	SEC_CONTENT
step	SEC_CONTENT
by	SEC_CONTENT
step	SEC_CONTENT
.	SEC_END
We	SEC_START
also	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
some	SEC_CONTENT
modifications	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
basic	SEC_CONTENT
transformer	SEC_CONTENT
architecture	SEC_CONTENT
are	SEC_CONTENT
beneficial	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
domain	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
importantly	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
three	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
,	SEC_CONTENT
requiring	SEC_CONTENT
the	task
model	task
to	SEC_CONTENT
predict	SEC_CONTENT
upcoming	SEC_CONTENT
characters	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
at	SEC_CONTENT
intermediate	SEC_CONTENT
sequence	SEC_CONTENT
positions	SEC_CONTENT
,	SEC_CONTENT
(	SEC_CONTENT
ii	SEC_CONTENT
)	SEC_CONTENT
from	SEC_CONTENT
intermediate	SEC_CONTENT
hidden	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
iii	SEC_CONTENT
)	SEC_CONTENT
at	SEC_CONTENT
target	SEC_CONTENT
positions	SEC_CONTENT
multiple	SEC_CONTENT
steps	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
future	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
losses	SEC_CONTENT
speedup	SEC_CONTENT
convergence	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
make	SEC_CONTENT
it	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
deeper	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_END
Character	SECTITLE_START
Transformer	SECTITLE_CONTENT
Model	SECTITLE_END
Language	SEC_START
models	task
assign	SEC_CONTENT
a	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
token	SEC_CONTENT
sequences	SEC_CONTENT
t	SEC_CONTENT
0	SEC_CONTENT
:	SEC_CONTENT
L	SEC_CONTENT
by	SEC_CONTENT
factoring	SEC_CONTENT
out	SEC_CONTENT
the	SEC_CONTENT
joint	SEC_CONTENT
probability	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
L	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
length	SEC_CONTENT
:	SEC_END
To	SEC_START
model	SEC_CONTENT
the	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
Pr(t	SEC_CONTENT
i	SEC_CONTENT
|t	SEC_CONTENT
0	SEC_CONTENT
:	SEC_CONTENT
i−1	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
transformer	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
the	metric
character	metric
sequence	metric
t	metric
0	SEC_CONTENT
:	SEC_CONTENT
i−1	SEC_CONTENT
.	SEC_CONTENT
Transformer	SEC_CONTENT
networks	SEC_CONTENT
have	SEC_CONTENT
recently	SEC_CONTENT
showed	SEC_CONTENT
significant	SEC_CONTENT
gains	SEC_CONTENT
in	SEC_CONTENT
tasks	SEC_CONTENT
that	SEC_CONTENT
require	SEC_CONTENT
processing	SEC_CONTENT
sequences	SEC_CONTENT
accurately	SEC_CONTENT
and	SEC_CONTENT
efficiently	SEC_CONTENT
.	SEC_END
Our	SEC_START
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
transformer	SEC_CONTENT
architecture	SEC_CONTENT
has	SEC_CONTENT
64	SEC_CONTENT
transformer	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
"	SEC_CONTENT
transformer	SEC_CONTENT
layer	SEC_CONTENT
"	SEC_CONTENT
we	SEC_CONTENT
mean	SEC_CONTENT
a	SEC_CONTENT
block	SEC_CONTENT
containing	SEC_CONTENT
a	SEC_CONTENT
multihead	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
followed	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
network	SEC_CONTENT
of	SEC_CONTENT
two	SEC_CONTENT
fully	SEC_CONTENT
connected	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
more	SEC_CONTENT
details	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
transformer	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
tensor2tensor	SEC_CONTENT
library	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
ensure	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
predictions	SEC_CONTENT
are	SEC_CONTENT
only	SEC_CONTENT
conditioned	SEC_CONTENT
on	SEC_CONTENT
past	metric
characters	metric
,	SEC_CONTENT
we	SEC_CONTENT
mask	SEC_CONTENT
our	SEC_CONTENT
attention	SEC_CONTENT
layers	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
causal	SEC_CONTENT
attention	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
each	SEC_CONTENT
position	SEC_CONTENT
can	SEC_CONTENT
only	SEC_CONTENT
attend	SEC_CONTENT
leftward	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
masked	SEC_CONTENT
attention	SEC_CONTENT
"	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
component	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
transformer	SEC_CONTENT
architecture	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
sequence	SEC_CONTENT
problems	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
our	SEC_CONTENT
initial	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
causal	SEC_CONTENT
attention	SEC_CONTENT
mask	SEC_CONTENT
limiting	SEC_CONTENT
information	SEC_CONTENT
flow	SEC_CONTENT
from	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
right	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
character	SEC_CONTENT
prediction	SEC_CONTENT
is	SEC_CONTENT
conditioned	SEC_CONTENT
only	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
characters	SEC_CONTENT
that	SEC_CONTENT
appeared	SEC_CONTENT
earlier	SEC_CONTENT
.	SEC_END
Transformer	SEC_START
Layers	SEC_CONTENT
:	SEC_CONTENT
Character	SEC_CONTENT
transformer	SEC_CONTENT
network	SEC_CONTENT
of	SEC_CONTENT
two	SEC_CONTENT
layers	SEC_CONTENT
processing	SEC_CONTENT
a	metric
four	metric
character	metric
sequence	metric
to	SEC_CONTENT
predict	SEC_CONTENT
t	SEC_CONTENT
4	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
causal	SEC_CONTENT
attention	SEC_CONTENT
mask	SEC_CONTENT
limits	SEC_CONTENT
information	SEC_CONTENT
to	SEC_CONTENT
left	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
right	SEC_CONTENT
flow	SEC_CONTENT
.	SEC_CONTENT
Red	SEC_CONTENT
arrows	SEC_CONTENT
highlight	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
task	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
has	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
.	SEC_END
Auxiliary	SECTITLE_START
Losses	SECTITLE_END
Our	SEC_START
network	SEC_CONTENT
is	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
deeper	SEC_CONTENT
than	SEC_CONTENT
any	SEC_CONTENT
transformer	SEC_CONTENT
network	SEC_CONTENT
discussed	SEC_CONTENT
in	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
initial	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
network	SEC_CONTENT
deeper	SEC_CONTENT
than	SEC_CONTENT
ten	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
challenging	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
slow	SEC_CONTENT
convergence	SEC_CONTENT
and	SEC_CONTENT
poor	SEC_CONTENT
accuracy	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
were	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
deepen	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
better	SEC_CONTENT
effect	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
addition	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
sped	SEC_CONTENT
up	SEC_CONTENT
convergence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
significantly	SEC_CONTENT
.	SEC_END
We	SEC_START
add	SEC_CONTENT
several	SEC_CONTENT
types	SEC_CONTENT
of	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
,	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
intermediate	SEC_CONTENT
positions	SEC_CONTENT
,	SEC_CONTENT
intermediate	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
nonadjacent	SEC_CONTENT
targets	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
these	SEC_CONTENT
losses	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
speedup	SEC_CONTENT
convergence	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
serve	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
additional	SEC_CONTENT
regularizer	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
get	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
total	SEC_CONTENT
loss	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
with	SEC_CONTENT
discounted	SEC_CONTENT
weights	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
type	SEC_CONTENT
of	SEC_CONTENT
auxiliary	SEC_CONTENT
loss	SEC_CONTENT
has	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
schedule	SEC_CONTENT
of	SEC_CONTENT
decay	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
evaluation	SEC_CONTENT
and	SEC_CONTENT
inference	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
prediction	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
position	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
.	SEC_END
One	SEC_START
consequence	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
the	metric
network	metric
parameters	metric
are	SEC_CONTENT
only	SEC_CONTENT
used	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
-	SEC_CONTENT
specifically	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
classification	SEC_CONTENT
layers	SEC_CONTENT
associated	SEC_CONTENT
with	SEC_CONTENT
predictions	SEC_CONTENT
made	SEC_CONTENT
from	SEC_CONTENT
intermediate	SEC_CONTENT
layers	SEC_CONTENT
and	SEC_CONTENT
predictions	SEC_CONTENT
over	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
adjacent	SEC_CONTENT
targets	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
listing	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
distinguish	SEC_CONTENT
between	SEC_CONTENT
"	SEC_CONTENT
training	SEC_CONTENT
parameters	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
inference	SEC_CONTENT
parameters	SEC_CONTENT
"	SEC_CONTENT
.	SEC_END
Multiple	SEC_START
Positions	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
prediction	SEC_CONTENT
tasks	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
position	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
extending	SEC_CONTENT
our	SEC_CONTENT
predictions	SEC_CONTENT
from	SEC_CONTENT
one	SEC_CONTENT
per	SEC_CONTENT
example	SEC_CONTENT
to	SEC_CONTENT
|L|	SEC_CONTENT
(	SEC_CONTENT
sequence	SEC_CONTENT
length	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
,	SEC_CONTENT
predicting	SEC_CONTENT
overall	SEC_CONTENT
sequence	SEC_CONTENT
positions	SEC_CONTENT
is	SEC_CONTENT
standard	SEC_CONTENT
practice	SEC_CONTENT
in	SEC_CONTENT
RNNbased	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
case	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
no	SEC_CONTENT
information	SEC_CONTENT
is	SEC_CONTENT
passed	SEC_CONTENT
forward	SEC_CONTENT
across	SEC_CONTENT
batches	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
forcing	SEC_CONTENT
the	task
model	task
to	SEC_CONTENT
predict	SEC_CONTENT
given	SEC_CONTENT
smaller	SEC_CONTENT
contexts	SEC_CONTENT
-	SEC_CONTENT
sometimes	SEC_CONTENT
just	SEC_CONTENT
one	SEC_CONTENT
or	SEC_CONTENT
two	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
obvious	SEC_CONTENT
whether	SEC_CONTENT
these	SEC_CONTENT
secondary	SEC_CONTENT
training	SEC_CONTENT
tasks	SEC_CONTENT
should	SEC_CONTENT
help	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
primary	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
predicting	SEC_CONTENT
with	SEC_CONTENT
full	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
adding	SEC_CONTENT
this	SEC_CONTENT
auxiliary	SEC_CONTENT
loss	SEC_CONTENT
speeds	SEC_CONTENT
up	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
gives	SEC_CONTENT
better	SEC_CONTENT
results	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
Ablation	SEC_CONTENT
Experiments	SEC_CONTENT
below	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
illustrates	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
predicting	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
sequence	SEC_CONTENT
positions	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
add	SEC_CONTENT
these	SEC_CONTENT
losses	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
without	SEC_CONTENT
decaying	SEC_CONTENT
their	SEC_CONTENT
weights	SEC_CONTENT
.	SEC_CONTENT
Intermediate	SEC_CONTENT
Layer	SEC_CONTENT
Losses	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
prediction	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
predictions	SEC_CONTENT
made	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
intermediate	SEC_CONTENT
transformer	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
predictions	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
intermediate	SEC_CONTENT
positions	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Lower	SEC_CONTENT
layers	SEC_CONTENT
are	SEC_CONTENT
weighted	SEC_CONTENT
to	SEC_CONTENT
contribute	SEC_CONTENT
less	SEC_CONTENT
and	SEC_CONTENT
less	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
as	SEC_CONTENT
training	SEC_CONTENT
progresses	SEC_CONTENT
.	SEC_CONTENT
If	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
n	SEC_CONTENT
layers	SEC_CONTENT
total	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
l	SEC_CONTENT
th	SEC_CONTENT
intermediate	SEC_CONTENT
layer	SEC_CONTENT
stops	SEC_CONTENT
contributing	SEC_CONTENT
any	SEC_CONTENT
loss	SEC_CONTENT
after	SEC_CONTENT
finishing	SEC_CONTENT
l/2n	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
schedule	SEC_CONTENT
drops	SEC_CONTENT
all	SEC_CONTENT
intermediate	SEC_CONTENT
losses	SEC_CONTENT
after	SEC_CONTENT
half	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
done	SEC_CONTENT
.	SEC_END
Multiple	SEC_START
Targets	SEC_CONTENT
At	SEC_CONTENT
each	SEC_CONTENT
position	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
the	task
model	task
makes	SEC_CONTENT
two	SEC_CONTENT
(	SEC_CONTENT
or	SEC_CONTENT
more	SEC_CONTENT
)	SEC_CONTENT
predictions	SEC_CONTENT
of	SEC_CONTENT
future	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
each	SEC_CONTENT
new	SEC_CONTENT
target	SEC_CONTENT
we	SEC_CONTENT
introduce	SEC_CONTENT
a	SEC_CONTENT
separate	SEC_CONTENT
classifier	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
losses	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
extra	SEC_CONTENT
targets	SEC_CONTENT
get	SEC_CONTENT
weighted	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
multiplier	SEC_CONTENT
of	SEC_CONTENT
0.5	SEC_CONTENT
before	SEC_CONTENT
being	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
their	SEC_CONTENT
corresponding	SEC_CONTENT
layer	SEC_CONTENT
loss	SEC_CONTENT
.	SEC_END
Positional	SECTITLE_START
Embeddings	SECTITLE_END
In	SEC_START
the	SEC_CONTENT
basic	SEC_CONTENT
transformer	SEC_CONTENT
network	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
sinusoidal	SEC_CONTENT
timing	SEC_CONTENT
signal	SEC_CONTENT
is	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
prior	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
transformer	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
network	SEC_CONTENT
is	SEC_CONTENT
deeper	SEC_CONTENT
(	SEC_CONTENT
64	SEC_CONTENT
layers	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
timing	SEC_CONTENT
information	SEC_CONTENT
may	SEC_CONTENT
get	SEC_CONTENT
lost	SEC_CONTENT
during	SEC_CONTENT
the	SEC_CONTENT
propagation	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
address	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
replace	SEC_CONTENT
the	SEC_CONTENT
timing	SEC_CONTENT
signal	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
learned	SEC_CONTENT
per	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
positional	SEC_CONTENT
embedding	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
before	SEC_CONTENT
each	SEC_CONTENT
transformer	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
the	task
model	task
learns	SEC_CONTENT
a	SEC_CONTENT
unique	SEC_CONTENT
512-dimensional	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
L	SEC_CONTENT
context	SEC_CONTENT
positions	SEC_CONTENT
within	SEC_CONTENT
each	SEC_CONTENT
of	SEC_CONTENT
N	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
giving	SEC_CONTENT
a	SEC_CONTENT
total	SEC_CONTENT
of	SEC_CONTENT
L	SEC_CONTENT
×	SEC_CONTENT
N	SEC_CONTENT
×	SEC_CONTENT
512	SEC_CONTENT
additional	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
safely	SEC_CONTENT
use	SEC_CONTENT
positional	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
n't	SEC_CONTENT
require	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
generalize	SEC_CONTENT
to	SEC_CONTENT
longer	SEC_CONTENT
contexts	SEC_CONTENT
than	SEC_CONTENT
those	SEC_CONTENT
seen	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
Experimental	SECTITLE_START
Setup	SECTITLE_CONTENT
Datasets	SECTITLE_END
For	SEC_START
evaluation	SEC_CONTENT
we	SEC_CONTENT
focus	SEC_CONTENT
mainly	SEC_CONTENT
on	SEC_CONTENT
text8	dataset
(	SEC_CONTENT
Mahoney	SEC_CONTENT
2009	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
dataset	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
English	SEC_CONTENT
Wikipedia	SEC_CONTENT
articles	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
superfluous	SEC_CONTENT
content	SEC_CONTENT
removed	SEC_CONTENT
(	SEC_CONTENT
tables	SEC_CONTENT
,	SEC_CONTENT
links	SEC_CONTENT
to	SEC_CONTENT
foreign	SEC_CONTENT
language	SEC_CONTENT
versions	SEC_CONTENT
,	SEC_CONTENT
citations	SEC_CONTENT
,	SEC_CONTENT
footnotes	SEC_CONTENT
,	SEC_CONTENT
markup	SEC_CONTENT
,	SEC_CONTENT
punctuation	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
remaining	SEC_CONTENT
text	SEC_CONTENT
is	SEC_CONTENT
processed	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
minimal	SEC_CONTENT
character	SEC_CONTENT
vocabulary	SEC_CONTENT
of	SEC_CONTENT
27	SEC_CONTENT
unique	SEC_CONTENT
characters	SEC_CONTENT
-	SEC_CONTENT
lowercase	SEC_CONTENT
letters	SEC_CONTENT
a	SEC_CONTENT
through	SEC_CONTENT
z	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
Digits	SEC_CONTENT
are	SEC_CONTENT
replaced	SEC_CONTENT
by	SEC_CONTENT
their	SEC_CONTENT
spelled	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
equivalents	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
"	SEC_CONTENT
20	SEC_CONTENT
"	SEC_CONTENT
becomes	SEC_CONTENT
"	SEC_CONTENT
two	SEC_CONTENT
zero	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
Character	SEC_CONTENT
sequences	SEC_CONTENT
not	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
range	SEC_CONTENT
[	SEC_CONTENT
a	SEC_CONTENT
-	SEC_CONTENT
zA	SEC_CONTENT
-	SEC_CONTENT
Z	SEC_CONTENT
]	SEC_CONTENT
are	SEC_CONTENT
converted	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
text	SEC_CONTENT
is	SEC_CONTENT
lowercased	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
is	SEC_CONTENT
100	SEC_CONTENT
M	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
and	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
split	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
into	SEC_CONTENT
90	SEC_CONTENT
M	SEC_CONTENT
characters	SEC_CONTENT
for	SEC_CONTENT
train	SEC_CONTENT
,	SEC_CONTENT
5	SEC_CONTENT
M	SEC_CONTENT
characters	SEC_CONTENT
for	SEC_CONTENT
dev	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
M	SEC_CONTENT
characters	SEC_CONTENT
for	SEC_CONTENT
test	SEC_CONTENT
.	SEC_END
To	SEC_START
aid	SEC_CONTENT
in	SEC_CONTENT
comparison	SEC_CONTENT
with	SEC_CONTENT
other	SEC_CONTENT
recent	SEC_CONTENT
approaches	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
evaluate	SEC_CONTENT
our	task
model	task
on	SEC_CONTENT
enwik8	SEC_CONTENT
(	SEC_CONTENT
Mahoney	SEC_CONTENT
2009	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
100	SEC_CONTENT
M	SEC_CONTENT
bytes	SEC_CONTENT
of	SEC_CONTENT
unprocessed	SEC_CONTENT
Wikipedia	SEC_CONTENT
text	SEC_CONTENT
,	SEC_CONTENT
including	SEC_CONTENT
markup	SEC_CONTENT
and	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
Latin	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
are	SEC_CONTENT
205	SEC_CONTENT
unique	SEC_CONTENT
bytes	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
text8	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
split	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
into	SEC_CONTENT
90	SEC_CONTENT
M	SEC_CONTENT
,	SEC_CONTENT
5	SEC_CONTENT
M	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
M	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
dev	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_END
Training	SECTITLE_END
Compared	SEC_START
to	SEC_CONTENT
most	SEC_CONTENT
models	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
transformers	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
our	task
model	task
is	SEC_CONTENT
very	SEC_CONTENT
deep	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
64	SEC_CONTENT
transformer	SEC_CONTENT
layers	SEC_CONTENT
and	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
using	SEC_CONTENT
two	SEC_CONTENT
attention	SEC_CONTENT
heads	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
transformer	SEC_CONTENT
layer	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
hidden	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
512	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
filter	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
2048	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
feed	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
sequences	SEC_CONTENT
of	SEC_CONTENT
length	SEC_CONTENT
512	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
item	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
represents	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
byte	SEC_CONTENT
(	SEC_CONTENT
or	SEC_CONTENT
equivalently	SEC_CONTENT
,	SEC_CONTENT
one	SEC_CONTENT
character	SEC_CONTENT
in	SEC_CONTENT
text8	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
gets	SEC_CONTENT
replaced	SEC_CONTENT
by	SEC_CONTENT
its	SEC_CONTENT
embedding	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
512	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
add	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
byte	SEC_CONTENT
embeddings	SEC_CONTENT
a	SEC_CONTENT
separate	SEC_CONTENT
learned	SEC_CONTENT
positional	SEC_CONTENT
embedding	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
512	SEC_CONTENT
token	SEC_CONTENT
positions	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
Positional	SEC_CONTENT
Embeddings	SEC_CONTENT
section	SEC_CONTENT
above	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
do	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
addition	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
activation	SEC_CONTENT
throughout	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
positional	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
shared	SEC_CONTENT
across	SEC_CONTENT
the	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
two	SEC_CONTENT
predictions	SEC_CONTENT
per	SEC_CONTENT
position	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
learns	SEC_CONTENT
to	SEC_CONTENT
predict	SEC_CONTENT
1024	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
Because	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
primarily	SEC_CONTENT
interested	SEC_CONTENT
in	SEC_CONTENT
predicting	SEC_CONTENT
the	SEC_CONTENT
immediately	SEC_CONTENT
following	SEC_CONTENT
character	SEC_CONTENT
(	SEC_CONTENT
one	SEC_CONTENT
step	SEC_CONTENT
away	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
halve	SEC_CONTENT
the	SEC_CONTENT
loss	SEC_CONTENT
of	SEC_CONTENT
predicting	SEC_CONTENT
characters	SEC_CONTENT
two	SEC_CONTENT
steps	SEC_CONTENT
away	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
prediction	SEC_CONTENT
layers	SEC_CONTENT
are	SEC_CONTENT
logistic	SEC_CONTENT
regression	SEC_CONTENT
layers	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
256	SEC_CONTENT
outputs	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
unique	SEC_CONTENT
bytes	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
demonstrate	SEC_CONTENT
the	SEC_CONTENT
generality	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
always	SEC_CONTENT
train	SEC_CONTENT
and	SEC_CONTENT
predict	SEC_CONTENT
overall	SEC_CONTENT
256	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
on	SEC_CONTENT
datasets	SEC_CONTENT
that	SEC_CONTENT
cover	SEC_CONTENT
a	SEC_CONTENT
smaller	SEC_CONTENT
vocabulary	SEC_CONTENT
.	SEC_CONTENT
Despite	SEC_CONTENT
this	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
in	SEC_CONTENT
practice	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
never	SEC_CONTENT
predicted	SEC_CONTENT
a	SEC_CONTENT
byte	SEC_CONTENT
value	SEC_CONTENT
outside	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
ones	SEC_CONTENT
observed	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
The	SEC_START
model	task
has	SEC_CONTENT
approximately	SEC_CONTENT
235	SEC_CONTENT
million	SEC_CONTENT
parameters	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
larger	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
characters	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
text8	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
regularize	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
dropout	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
and	SEC_CONTENT
ReLU	SEC_CONTENT
layers	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
0.55	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
momentum	SEC_CONTENT
optimizer	SEC_CONTENT
with	SEC_CONTENT
0.99	SEC_CONTENT
momentum	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
is	SEC_CONTENT
fixed	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
to	SEC_CONTENT
0.003	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
4	SEC_CONTENT
million	SEC_CONTENT
steps	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
each	SEC_CONTENT
step	SEC_CONTENT
processing	SEC_CONTENT
a	SEC_CONTENT
batch	SEC_CONTENT
of	SEC_CONTENT
16	SEC_CONTENT
randomly	SEC_CONTENT
selected	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
drop	SEC_CONTENT
the	SEC_CONTENT
intermediate	SEC_CONTENT
layer	SEC_CONTENT
losses	SEC_CONTENT
consecutively	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
Intermediate	SEC_CONTENT
Layer	SEC_CONTENT
Losses	SEC_CONTENT
section	SEC_CONTENT
above	SEC_CONTENT
.	SEC_CONTENT
Starting	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
after	SEC_CONTENT
every	SEC_CONTENT
62.5	SEC_CONTENT
K	SEC_CONTENT
(=	SEC_CONTENT
4M×	SEC_CONTENT
1	SEC_CONTENT
2	SEC_CONTENT
*	SEC_CONTENT
64	SEC_CONTENT
)	SEC_CONTENT
steps	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
drop	SEC_CONTENT
the	SEC_CONTENT
losses	SEC_CONTENT
introduced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
According	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
schedule	SEC_CONTENT
,	SEC_CONTENT
after	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
halfway	SEC_CONTENT
complete	SEC_CONTENT
,	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
losses	SEC_CONTENT
are	SEC_CONTENT
present	SEC_CONTENT
.	SEC_END
Evaluation	SECTITLE_END
At	SEC_START
inference	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
prediction	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
position	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
a	metric
character	metric
given	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
512	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
is	SEC_CONTENT
no	SEC_CONTENT
state	SEC_CONTENT
passed	SEC_CONTENT
between	SEC_CONTENT
predictions	SEC_CONTENT
as	SEC_CONTENT
would	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
case	SEC_CONTENT
with	SEC_CONTENT
RNN	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
character	SEC_CONTENT
predicted	SEC_CONTENT
we	SEC_CONTENT
have	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
from	SEC_CONTENT
scratch	SEC_CONTENT
.	SEC_CONTENT
Because	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
no	SEC_CONTENT
reused	SEC_CONTENT
 	SEC_CONTENT
computation	SEC_CONTENT
from	SEC_CONTENT
previous	SEC_CONTENT
steps	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
requires	SEC_CONTENT
expensive	SEC_CONTENT
computational	SEC_CONTENT
resources	SEC_CONTENT
for	SEC_CONTENT
evaluation	SEC_CONTENT
and	SEC_CONTENT
inference	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
measure	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
checkpoints	SEC_CONTENT
(	SEC_CONTENT
roughly	SEC_CONTENT
every	SEC_CONTENT
10,000	SEC_CONTENT
steps	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
evaluating	SEC_CONTENT
bits	SEC_CONTENT
per	SEC_CONTENT
character	SEC_CONTENT
(	SEC_CONTENT
bpc	SEC_CONTENT
)	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
save	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
that	SEC_CONTENT
perform	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
best	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
achieved	SEC_CONTENT
after	SEC_CONTENT
around	SEC_CONTENT
2.5	SEC_CONTENT
million	SEC_CONTENT
steps	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
takes	SEC_CONTENT
175	SEC_CONTENT
hours	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
Google	SEC_CONTENT
Cloud	SEC_CONTENT
TPU	SEC_CONTENT
v2	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
We	SEC_START
report	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
our	task
best	task
model	task
(	SEC_CONTENT
T64	SEC_CONTENT
)	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
given	SEC_CONTENT
different	SEC_CONTENT
context	SEC_CONTENT
sizes	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
once	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
increases	SEC_CONTENT
beyond	SEC_CONTENT
128	SEC_CONTENT
characters	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
1.06	SEC_CONTENT
bpc	SEC_CONTENT
at	SEC_CONTENT
512	SEC_CONTENT
characters	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
expected	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
performs	SEC_CONTENT
better	SEC_CONTENT
when	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
more	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
this	SEC_CONTENT
trend	SEC_CONTENT
levels	SEC_CONTENT
off	SEC_CONTENT
after	SEC_CONTENT
512	SEC_CONTENT
characters	SEC_CONTENT
;	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
see	SEC_CONTENT
better	SEC_CONTENT
results	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
1024	SEC_CONTENT
.	SEC_END
Using	SEC_START
the	SEC_CONTENT
same	SEC_CONTENT
hyperparameters	SEC_CONTENT
and	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
for	SEC_CONTENT
text8	dataset
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
train	SEC_CONTENT
and	SEC_CONTENT
evaluate	SEC_CONTENT
the	SEC_CONTENT
T12	SEC_CONTENT
and	SEC_CONTENT
T64	SEC_CONTENT
architectures	SEC_CONTENT
on	SEC_CONTENT
enwik8	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
,	SEC_CONTENT
several	SEC_CONTENT
previous	SEC_CONTENT
authors	SEC_CONTENT
discuss	SEC_CONTENT
"	SEC_CONTENT
bits	SEC_CONTENT
per	SEC_CONTENT
character	SEC_CONTENT
"	SEC_CONTENT
on	SEC_CONTENT
enwik8	SEC_CONTENT
but	SEC_CONTENT
are	SEC_CONTENT
in	SEC_CONTENT
fact	SEC_CONTENT
reporting	SEC_CONTENT
bits	SEC_CONTENT
per	SEC_CONTENT
byte	SEC_CONTENT
.	SEC_CONTENT
Without	SEC_CONTENT
retuning	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
still	SEC_CONTENT
achieve	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
Ablation	SECTITLE_START
Experiments	SECTITLE_END
To	SEC_START
better	SEC_CONTENT
understand	SEC_CONTENT
the	SEC_CONTENT
relative	SEC_CONTENT
importance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
several	SEC_CONTENT
modifications	SEC_CONTENT
we	SEC_CONTENT
proposed	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
run	SEC_CONTENT
an	SEC_CONTENT
ablation	SEC_CONTENT
analysis	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
start	SEC_CONTENT
from	SEC_CONTENT
our	task
best	task
model	task
T64	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
remove	SEC_CONTENT
one	SEC_CONTENT
modification	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
when	SEC_CONTENT
we	SEC_CONTENT
disable	SEC_CONTENT
Multiple	SEC_CONTENT
Positions	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
gets	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
position	SEC_CONTENT
loss	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
corresponds	SEC_CONTENT
to	SEC_CONTENT
calculating	SEC_CONTENT
{	SEC_CONTENT
L(t	SEC_CONTENT
4	SEC_CONTENT
|	SEC_CONTENT
t	SEC_CONTENT
0:3	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
L(t	SEC_CONTENT
5	SEC_CONTENT
|	SEC_CONTENT
t	SEC_CONTENT
0:3	SEC_CONTENT
)	SEC_CONTENT
}	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
example	SEC_CONTENT
shown	SEC_CONTENT
in	SEC_CONTENT
for	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
disabling	SEC_CONTENT
Positional	SEC_CONTENT
Embeddings	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
the	SEC_CONTENT
default	SEC_CONTENT
transformer	SEC_CONTENT
sinusoidal	SEC_CONTENT
timing	SEC_CONTENT
signal	SEC_CONTENT
before	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
 	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
replace	SEC_CONTENT
momentum	SEC_CONTENT
with	SEC_CONTENT
SGD	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
optimizer	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
learning	SEC_CONTENT
rates	SEC_CONTENT
(	SEC_CONTENT
0.3	SEC_CONTENT
,	SEC_CONTENT
0.1	SEC_CONTENT
,	SEC_CONTENT
0.03	SEC_CONTENT
,	SEC_CONTENT
0.01	SEC_CONTENT
,	SEC_CONTENT
0.003	SEC_CONTENT
,	SEC_CONTENT
0.001	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
ablation	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
SGD	SEC_CONTENT
produces	SEC_CONTENT
competitive	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
0.1	SEC_CONTENT
giving	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_CONTENT
Despite	SEC_CONTENT
the	SEC_CONTENT
depth	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
SGD	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
efficiently	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
help	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
.	SEC_END
Description	SECTITLE_END
Type	SEC_START
Model	task
bpb	SEC_CONTENT
ppl	SEC_CONTENT
Word	SEC_CONTENT
-23.7	SEC_CONTENT
Byte	SEC_CONTENT
T64	SEC_CONTENT
1.03	SEC_CONTENT
40.6	SEC_CONTENT
:	SEC_CONTENT
Performance	SEC_CONTENT
of	SEC_CONTENT
T64	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
lm1b	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
Comparison	SECTITLE_START
with	SECTITLE_CONTENT
Word	SECTITLE_CONTENT
-	SECTITLE_CONTENT
Level	SECTITLE_CONTENT
Models	SECTITLE_END
To	SEC_START
understand	SEC_CONTENT
how	SEC_CONTENT
byte	task
-	task
level	task
language	task
models	task
perform	SEC_CONTENT
in	SEC_CONTENT
comparison	SEC_CONTENT
to	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
T64	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
lm1b	SEC_CONTENT
corpus	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
lm1b	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
train	SEC_CONTENT
/	SEC_CONTENT
test	SEC_CONTENT
split	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
preprocessed	SEC_CONTENT
corpus	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
out	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
vocab	SEC_CONTENT
words	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
replaced	SEC_CONTENT
with	SEC_CONTENT
UNK	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
allow	SEC_CONTENT
comparison	SEC_CONTENT
to	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
piece	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
word	SEC_CONTENT
perplexity	SEC_CONTENT
(	SEC_CONTENT
ppl	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
converting	SEC_CONTENT
bitsper	SEC_CONTENT
-	SEC_CONTENT
byte	SEC_CONTENT
(	SEC_CONTENT
bpb	SEC_CONTENT
)	SEC_CONTENT
into	SEC_CONTENT
ppl	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
training	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
shard	SEC_CONTENT
(	SEC_CONTENT
01	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
heldout	SEC_CONTENT
dataset	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
shard	SEC_CONTENT
(	SEC_CONTENT
00	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
significantly	SEC_CONTENT
larger	SEC_CONTENT
dataset	SEC_CONTENT
than	SEC_CONTENT
text8	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
all	SEC_CONTENT
dropouts	SEC_CONTENT
to	SEC_CONTENT
zero	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
a	SEC_CONTENT
gap	SEC_CONTENT
in	SEC_CONTENT
performance	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
classes	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
comparison	SEC_CONTENT
can	SEC_CONTENT
serve	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
starting	SEC_CONTENT
point	SEC_CONTENT
for	SEC_CONTENT
researching	SEC_CONTENT
possible	SEC_CONTENT
ways	SEC_CONTENT
to	SEC_CONTENT
bridge	SEC_CONTENT
the	SEC_CONTENT
gap	SEC_CONTENT
.	SEC_END
Qualitative	SECTITLE_START
Analysis	SECTITLE_END
To	SEC_START
probe	SEC_CONTENT
the	SEC_CONTENT
strengths	SEC_CONTENT
and	SEC_CONTENT
weaknesses	SEC_CONTENT
of	SEC_CONTENT
our	task
best	task
model	task
(	SEC_CONTENT
T64	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
run	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
forward	SEC_CONTENT
,	SEC_CONTENT
starting	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
512	SEC_CONTENT
characters	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
taken	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
text8	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
several	SEC_CONTENT
per	SEC_CONTENT
-	SEC_CONTENT
character	SEC_CONTENT
metrics	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
predictions	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
continuation	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
seed	SEC_CONTENT
text	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
each	SEC_CONTENT
position	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
measure	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
prediction	SEC_CONTENT
entropy	SEC_CONTENT
in	SEC_CONTENT
bits	SEC_CONTENT
across	SEC_CONTENT
all	SEC_CONTENT
256	SEC_CONTENT
output	SEC_CONTENT
classes	SEC_CONTENT
,	SEC_CONTENT
ii	SEC_CONTENT
)	SEC_CONTENT
its	SEC_CONTENT
lossthe	SEC_CONTENT
negative	SEC_CONTENT
log	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
label	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
bits	SEC_CONTENT
per	SEC_CONTENT
character	SEC_CONTENT
"	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
position	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
iii	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
rank	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
list	SEC_CONTENT
of	SEC_CONTENT
output	SEC_CONTENT
classes	SEC_CONTENT
sorted	SEC_CONTENT
by	SEC_CONTENT
likelihood	SEC_CONTENT
.	SEC_CONTENT
Unsurprisingly	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
least	SEC_CONTENT
certain	SEC_CONTENT
when	SEC_CONTENT
predicting	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
character	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
becomes	SEC_CONTENT
progressively	SEC_CONTENT
more	SEC_CONTENT
confident	SEC_CONTENT
and	SEC_CONTENT
correct	SEC_CONTENT
as	SEC_CONTENT
subsequent	SEC_CONTENT
characters	SEC_CONTENT
are	SEC_CONTENT
seen	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
degree	SEC_CONTENT
to	SEC_CONTENT
which	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
prefers	SEC_CONTENT
actual	SEC_CONTENT
English	SEC_CONTENT
words	SEC_CONTENT
over	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
existent	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
likelihood	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
assigns	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
continuations	SEC_CONTENT
after	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
cutoff	SEC_CONTENT
continuations	SEC_CONTENT
when	SEC_CONTENT
they	SEC_CONTENT
reach	SEC_CONTENT
a	SEC_CONTENT
space	SEC_CONTENT
character	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
total	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
continuation	SEC_CONTENT
falls	SEC_CONTENT
below	SEC_CONTENT
0.001	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
completions	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
of	SEC_CONTENT
probability	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
pr	SEC_CONTENT
-	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
is	SEC_CONTENT
repeated	SEC_CONTENT
for	SEC_CONTENT
readability	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
these	SEC_CONTENT
are	SEC_CONTENT
all	SEC_CONTENT
real	SEC_CONTENT
or	SEC_CONTENT
plausible	SEC_CONTENT
(	SEC_CONTENT
proofed	SEC_CONTENT
)	SEC_CONTENT
English	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
that	SEC_CONTENT
even	SEC_CONTENT
short	SEC_CONTENT
but	SEC_CONTENT
bad	SEC_CONTENT
continuations	SEC_CONTENT
like	SEC_CONTENT
prz	SEC_CONTENT
are	SEC_CONTENT
assigned	SEC_CONTENT
a	SEC_CONTENT
lower	SEC_CONTENT
cumulative	SEC_CONTENT
probability	SEC_CONTENT
than	SEC_CONTENT
long	SEC_CONTENT
realistic	SEC_CONTENT
word	SEC_CONTENT
completions	SEC_CONTENT
like	SEC_CONTENT
predictable	SEC_CONTENT
.	SEC_END
We	SEC_START
expect	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
transformer	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
attention	SEC_CONTENT
should	SEC_CONTENT
make	SEC_CONTENT
it	SEC_CONTENT
easy	SEC_CONTENT
for	SEC_CONTENT
our	task
model	task
to	SEC_CONTENT
copy	SEC_CONTENT
sequences	SEC_CONTENT
observed	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
overlong	SEC_CONTENT
distances	SEC_CONTENT
(	SEC_CONTENT
up	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
512	SEC_CONTENT
characters	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
test	SEC_CONTENT
this	SEC_CONTENT
expectation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
corrupt	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
and	SEC_CONTENT
continuation	SEC_CONTENT
from	SEC_CONTENT
above	SEC_CONTENT
by	SEC_CONTENT
introducing	SEC_CONTENT
a	SEC_CONTENT
fake	SEC_CONTENT
name	SEC_CONTENT
zjakdmu	SEC_CONTENT
bmijwxn	SEC_CONTENT
.	SEC_CONTENT
Specifically	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
change	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
occurrence	SEC_CONTENT
of	SEC_CONTENT
elizabeth	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
to	SEC_CONTENT
zjakdmu	SEC_CONTENT
bmijwxn	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
Seed	SEC_CONTENT
mary	SEC_CONTENT
was	SEC_CONTENT
not	SEC_CONTENT
permitted	SEC_CONTENT
to	SEC_CONTENT
see	SEC_CONTENT
them	SEC_CONTENT
or	SEC_CONTENT
to	SEC_CONTENT
speak	SEC_CONTENT
in	SEC_CONTENT
her	SEC_CONTENT
own	SEC_CONTENT
defence	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
tribunal	SEC_CONTENT
she	SEC_CONTENT
refused	SEC_CONTENT
to	SEC_CONTENT
offer	SEC_CONTENT
a	SEC_CONTENT
written	SEC_CONTENT
defence	SEC_CONTENT
unless	SEC_CONTENT
elizabeth	SEC_CONTENT
would	SEC_CONTENT
guarantee	SEC_CONTENT
a	SEC_CONTENT
verdict	SEC_CONTENT
of	SEC_CONTENT
not	SEC_CONTENT
guilty	SEC_CONTENT
which	SEC_CONTENT
elizabeth	SEC_CONTENT
would	SEC_CONTENT
not	SEC_CONTENT
do	SEC_CONTENT
although	SEC_CONTENT
the	SEC_CONTENT
casket	SEC_CONTENT
letters	SEC_CONTENT
were	SEC_CONTENT
accepted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
inquiry	SEC_CONTENT
as	SEC_CONTENT
genuine	SEC_CONTENT
after	SEC_CONTENT
a	SEC_CONTENT
study	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
handwriting	SEC_CONTENT
and	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
information	SEC_CONTENT
contained	SEC_CONTENT
therein	SEC_CONTENT
and	SEC_CONTENT
were	SEC_CONTENT
generally	SEC_CONTENT
held	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
certain	SEC_CONTENT
proof	SEC_CONTENT
of	SEC_CONTENT
guilt	SEC_CONTENT
if	SEC_CONTENT
authentic	SEC_CONTENT
the	SEC_CONTENT
inquiry	SEC_CONTENT
reached	SEC_CONTENT
the	SEC_CONTENT
conclusion	SEC_CONTENT
that	SEC_CONTENT
nothing	SEC_CONTENT
was	SEC_CONTENT
proven	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
start	SEC_CONTENT
this	SEC_CONTENT
could	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
pr	SEC_CONTENT
Figure	SEC_CONTENT
5	SEC_CONTENT
:	SEC_CONTENT
A	SEC_CONTENT
seed	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
512	SEC_CONTENT
characters	SEC_CONTENT
taken	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
text8	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
all	SEC_CONTENT
word	SEC_CONTENT
completions	SEC_CONTENT
assigned	SEC_CONTENT
cumulative	SEC_CONTENT
probability	SEC_CONTENT
above	SEC_CONTENT
0.001	SEC_CONTENT
to	SEC_CONTENT
follow	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
from	SEC_CONTENT
most	SEC_CONTENT
likely	SEC_CONTENT
(	SEC_CONTENT
0.529	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
least	SEC_CONTENT
likely	SEC_CONTENT
(	SEC_CONTENT
0.001	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Word	SECTITLE_START
Completions	SECTITLE_END
second	SEC_START
occurrence	SEC_CONTENT
to	SEC_CONTENT
she	SEC_CONTENT
.	SEC_CONTENT
Similarly	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
continuation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
change	SEC_CONTENT
elizabeth	SEC_CONTENT
to	SEC_CONTENT
zjakdmu	SEC_CONTENT
bmijwxn	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
resulting	SEC_CONTENT
distance	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
occurrences	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
fake	SEC_CONTENT
name	SEC_CONTENT
is	SEC_CONTENT
434	metric
characters	metric
.	SEC_CONTENT
confirms	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
successfully	SEC_CONTENT
copy	SEC_CONTENT
over	SEC_CONTENT
this	SEC_CONTENT
long	SEC_CONTENT
distance	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
z	SEC_CONTENT
in	SEC_CONTENT
zjakdmu	SEC_CONTENT
is	SEC_CONTENT
unexpected	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
immediately	SEC_CONTENT
chooses	SEC_CONTENT
to	SEC_CONTENT
copy	SEC_CONTENT
the	SEC_CONTENT
remainder	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
word	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
opposed	SEC_CONTENT
to	SEC_CONTENT
predicting	SEC_CONTENT
any	SEC_CONTENT
real	SEC_CONTENT
z	SEC_CONTENT
-	SEC_CONTENT
words	SEC_CONTENT
learned	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
Similarly	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
somewhat	SEC_CONTENT
unsure	SEC_CONTENT
whether	SEC_CONTENT
the	SEC_CONTENT
fake	SEC_CONTENT
surname	SEC_CONTENT
bmijwxn	SEC_CONTENT
will	SEC_CONTENT
appear	SEC_CONTENT
(	SEC_CONTENT
assigning	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
b	SEC_CONTENT
a	SEC_CONTENT
rank	SEC_CONTENT
of	SEC_CONTENT
two	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
immediately	SEC_CONTENT
picks	SEC_CONTENT
upon	SEC_CONTENT
the	SEC_CONTENT
correspondence	SEC_CONTENT
after	SEC_CONTENT
the	SEC_CONTENT
b	SEC_CONTENT
is	SEC_CONTENT
observed	SEC_CONTENT
,	SEC_CONTENT
correctly	SEC_CONTENT
predicting	SEC_CONTENT
the	SEC_CONTENT
remainder	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
fake	SEC_CONTENT
surname	SEC_CONTENT
.	SEC_END
For	SEC_START
comparison	SEC_CONTENT
,	SEC_CONTENT
shows	SEC_CONTENT
how	SEC_CONTENT
the	task
model	task
would	SEC_CONTENT
rank	SEC_CONTENT
the	SEC_CONTENT
targets	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
fake	SEC_CONTENT
continuation	SEC_CONTENT
if	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
seed	SEC_CONTENT
with	SEC_CONTENT
elizabeth	SEC_CONTENT
were	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
confirms	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
fake	SEC_CONTENT
name	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
predictable	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
knowledge	SEC_CONTENT
gained	SEC_CONTENT
through	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
indeed	SEC_CONTENT
being	SEC_CONTENT
copied	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
preceding	SEC_CONTENT
context	SEC_CONTENT
.	SEC_END
Generation	SECTITLE_END
For	SEC_START
generating	SEC_CONTENT
samples	SEC_CONTENT
using	SEC_CONTENT
our	task
language	task
model	task
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
larger	SEC_CONTENT
and	SEC_CONTENT
less	SEC_CONTENT
processed	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
enwik9	SEC_CONTENT
(	SEC_CONTENT
Mahoney	SEC_CONTENT
2009	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
split	SEC_CONTENT
enwik9	SEC_CONTENT
into	SEC_CONTENT
900	SEC_CONTENT
M	SEC_CONTENT
,	SEC_CONTENT
50	SEC_CONTENT
M	SEC_CONTENT
and	SEC_CONTENT
50	SEC_CONTENT
M	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
dev	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
.	SEC_CONTENT
Using	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
dataset	SEC_CONTENT
to	SEC_CONTENT
tune	SEC_CONTENT
our	SEC_CONTENT
dropout	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
dropout=0.1	SEC_CONTENT
performs	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
dataset	SEC_CONTENT
,	SEC_CONTENT
T64	SEC_CONTENT
achieves	SEC_CONTENT
0.85	SEC_CONTENT
bpb	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
different	SEC_CONTENT
generated	SEC_CONTENT
samples	SEC_CONTENT
following	SEC_CONTENT
the	SEC_CONTENT
seed	SEC_CONTENT
text	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
sampling	SEC_CONTENT
temperature	SEC_CONTENT
of	SEC_CONTENT
1.0	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
Character	SEC_START
-	task
level	task
modeling	task
has	SEC_CONTENT
shown	SEC_CONTENT
promise	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
areas	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
sentiment	SEC_CONTENT
analysis	SEC_CONTENT
(	SEC_CONTENT
Radford	SEC_CONTENT
,	SEC_CONTENT
Józefowicz	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
exciting	SEC_CONTENT
area	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
simplicity	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
ability	SEC_CONTENT
to	SEC_CONTENT
easily	SEC_CONTENT
adapt	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
languages	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
network	SEC_CONTENT
based	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
heavily	SEC_CONTENT
researched	SEC_CONTENT
since	SEC_CONTENT
its	SEC_CONTENT
effectiveness	SEC_CONTENT
was	SEC_CONTENT
shown	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
By	SEC_CONTENT
far	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
popular	SEC_CONTENT
architecture	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
area	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
RNN	SEC_CONTENT
and	SEC_CONTENT
variants	SEC_CONTENT
,	SEC_CONTENT
first	SEC_CONTENT
studied	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Much	SEC_START
of	SEC_CONTENT
the	SEC_CONTENT
progress	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
area	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
made	SEC_CONTENT
by	SEC_CONTENT
mitigating	SEC_CONTENT
the	SEC_CONTENT
vanishing	SEC_CONTENT
gradients	SEC_CONTENT
problem	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
architectures	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
LSTMs	SEC_CONTENT
(	SEC_CONTENT
Hochreiter	SEC_CONTENT
and	SEC_CONTENT
Schmidhuber	SEC_CONTENT
1997	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
GRU	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
Recurrent	SEC_CONTENT
Highway	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
Unitary	SEC_CONTENT
RNNs	SEC_CONTENT
(	SEC_CONTENT
Arjovsky	SEC_CONTENT
,	SEC_CONTENT
Shah	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Bengio	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
others	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
issue	SEC_CONTENT
that	SEC_CONTENT
transformers	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
,	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
attention	SEC_CONTENT
allowing	SEC_CONTENT
short	SEC_CONTENT
paths	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_CONTENT
Methods	SEC_CONTENT
of	SEC_CONTENT
normalizing	SEC_CONTENT
activation	SEC_CONTENT
functions	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
Batch	SEC_CONTENT
Normalization	SEC_CONTENT
and	SEC_CONTENT
Layer	SEC_CONTENT
Normalization	SEC_CONTENT
have	SEC_CONTENT
also	SEC_CONTENT
demonstrated	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
language	task
modeling	task
tasks	task
.	SEC_CONTENT
As	SEC_CONTENT
with	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
progress	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
made	SEC_CONTENT
with	SEC_CONTENT
discovering	SEC_CONTENT
ways	SEC_CONTENT
to	SEC_CONTENT
regularize	SEC_CONTENT
sequential	SEC_CONTENT
architectures	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
techniques	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
Recurrent	SEC_CONTENT
Dropout	SEC_CONTENT
(	SEC_CONTENT
Zaremba	SEC_CONTENT
,	SEC_CONTENT
Sutskever	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Vinyals	SEC_CONTENT
2014	SEC_CONTENT
;	SEC_CONTENT
Gal	SEC_CONTENT
and	SEC_CONTENT
Ghahramani	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
Zoneout	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
A	SEC_START
closely	SEC_CONTENT
related	SEC_CONTENT
architecture	SEC_CONTENT
is	SEC_CONTENT
the	task
Neural	task
Cache	task
Model	task
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
RNN	SEC_CONTENT
is	SEC_CONTENT
allowed	SEC_CONTENT
to	SEC_CONTENT
attend	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
its	SEC_CONTENT
previous	SEC_CONTENT
hidden	SEC_CONTENT
states	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
step	SEC_CONTENT
.	SEC_CONTENT
Another	SEC_CONTENT
similar	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
)	SEC_CONTENT
where	SEC_CONTENT
a	SEC_CONTENT
key	SEC_CONTENT
-	SEC_CONTENT
value	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
transformers	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
approaches	SEC_CONTENT
show	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
level	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
Memory	SEC_CONTENT
Networks	SEC_CONTENT
have	SEC_CONTENT
a	SEC_CONTENT
similarity	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
transformer	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
design	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
also	SEC_CONTENT
has	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
attention	SEC_CONTENT
for	SEC_CONTENT
processing	SEC_CONTENT
a	SEC_CONTENT
fix	SEC_CONTENT
memory	SEC_CONTENT
representing	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
doc-	SEC_CONTENT
 	SEC_CONTENT
Per	SEC_CONTENT
-	SEC_CONTENT
character	SEC_CONTENT
rank	SEC_CONTENT
assigned	SEC_CONTENT
by	SEC_CONTENT
T64	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
fake	SEC_CONTENT
continuation	SEC_CONTENT
,	SEC_CONTENT
after	SEC_CONTENT
being	SEC_CONTENT
seeded	SEC_CONTENT
on	SEC_CONTENT
either	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
fake	SEC_CONTENT
context	SEC_CONTENT
where	SEC_CONTENT
elizabeth	SEC_CONTENT
is	SEC_CONTENT
replaced	SEC_CONTENT
with	SEC_CONTENT
zjakdmu	SEC_CONTENT
bmijwxn	SEC_CONTENT
,	SEC_CONTENT
or	SEC_CONTENT
(	SEC_CONTENT
b	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
ument	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
shown	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
for	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
ByteNet	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
related	SEC_CONTENT
but	SEC_CONTENT
uses	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
dilated	SEC_CONTENT
convolutions	SEC_CONTENT
rather	SEC_CONTENT
than	SEC_CONTENT
attention	SEC_CONTENT
,	SEC_CONTENT
showed	SEC_CONTENT
promising	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
byte	SEC_CONTENT
level	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
Gated	SEC_CONTENT
Convolutional	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
was	SEC_CONTENT
an	SEC_CONTENT
early	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
recurrent	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
show	SEC_CONTENT
superior	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
level	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_END
Language	SEC_START
models	task
are	SEC_CONTENT
not	SEC_CONTENT
usually	SEC_CONTENT
very	SEC_CONTENT
deep	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
computational	SEC_CONTENT
constraints	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
RNNs	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
also	SEC_CONTENT
limits	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
transformer	SEC_CONTENT
architecture	SEC_CONTENT
allowed	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
build	SEC_CONTENT
very	SEC_CONTENT
deep	SEC_CONTENT
(	SEC_CONTENT
64	SEC_CONTENT
layer	SEC_CONTENT
)	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
recent	SEC_CONTENT
CNN	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
text	SEC_CONTENT
classification	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
at	SEC_CONTENT
29	SEC_CONTENT
layers	SEC_CONTENT
is	SEC_CONTENT
considered	SEC_CONTENT
deep	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
NLP	SEC_CONTENT
community	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
Sparsely	SEC_CONTENT
-	SEC_CONTENT
Gated	SEC_CONTENT
Mixture	SEC_CONTENT
-	SEC_CONTENT
ofExperts	SEC_CONTENT
Layer	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
allowed	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
experiments	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
greatly	SEC_CONTENT
increased	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
by	SEC_CONTENT
only	SEC_CONTENT
accessing	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
portion	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
every	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
showing	SEC_CONTENT
a	SEC_CONTENT
reduction	SEC_CONTENT
in	SEC_CONTENT
bits	SEC_CONTENT
per	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
Exploring	SEC_CONTENT
the	SEC_CONTENT
Limits	SEC_CONTENT
of	SEC_CONTENT
Language	SEC_CONTENT
Modeling	SEC_CONTENT
,	SEC_CONTENT
an	SEC_CONTENT
increase	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
was	SEC_CONTENT
achieved	SEC_CONTENT
by	SEC_CONTENT
mixing	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
and	SEC_CONTENT
word	SEC_CONTENT
level	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
specialized	SEC_CONTENT
softmaxes	SEC_CONTENT
and	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
computational	SEC_CONTENT
resources	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
.	SEC_CONTENT
IndRNN	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
simplified	SEC_CONTENT
RNN	SEC_CONTENT
architecture	SEC_CONTENT
that	SEC_CONTENT
allows	SEC_CONTENT
deeper	SEC_CONTENT
stacking	SEC_CONTENT
with	SEC_CONTENT
21-layers	SEC_CONTENT
,	SEC_CONTENT
achieving	SEC_CONTENT
near	SEC_CONTENT
SOTA	SEC_CONTENT
character	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
language	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
Fast	SEC_CONTENT
-	SEC_CONTENT
Slow	SEC_CONTENT
Recurrent	SEC_CONTENT
Neural	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
Mujika	SEC_CONTENT
,	SEC_CONTENT
Meier	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
Steger	SEC_CONTENT
2017	SEC_CONTENT
)	SEC_CONTENT
also	SEC_CONTENT
achieved	SEC_CONTENT
near	SEC_CONTENT
SOTA	SEC_CONTENT
by	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
recurrent	SEC_CONTENT
steps	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
character	SEC_CONTENT
processed	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
Character	SEC_START
language	task
modeling	task
has	SEC_CONTENT
been	SEC_CONTENT
dominated	SEC_CONTENT
by	SEC_CONTENT
recurrent	SEC_CONTENT
network	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
network	SEC_CONTENT
of	SEC_CONTENT
12	SEC_CONTENT
stacked	SEC_CONTENT
transformer	SEC_CONTENT
layers	SEC_CONTENT
achieves	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
ofthe	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
gain	SEC_CONTENT
further	SEC_CONTENT
improvements	SEC_CONTENT
in	SEC_CONTENT
quality	SEC_CONTENT
by	SEC_CONTENT
deepening	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
64	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
utilizing	SEC_CONTENT
capacity	SEC_CONTENT
and	SEC_CONTENT
depth	SEC_CONTENT
efficiently	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
auxiliary	SEC_CONTENT
losses	SEC_CONTENT
at	SEC_CONTENT
intermediate	SEC_CONTENT
layers	SEC_CONTENT
and	SEC_CONTENT
positions	SEC_CONTENT
is	SEC_CONTENT
critical	SEC_CONTENT
for	SEC_CONTENT
reaching	SEC_CONTENT
this	SEC_CONTENT
performance	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
these	SEC_CONTENT
losses	SEC_CONTENT
allow	SEC_CONTENT
us	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
much	SEC_CONTENT
deeper	SEC_CONTENT
transformer	SEC_CONTENT
networks	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
analyze	SEC_CONTENT
the	SEC_CONTENT
behavior	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
network	SEC_CONTENT
and	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
exploit	SEC_CONTENT
dependencies	SEC_CONTENT
in	SEC_CONTENT
structure	SEC_CONTENT
and	SEC_CONTENT
content	SEC_CONTENT
overlong	SEC_CONTENT
distances	SEC_CONTENT
,	SEC_CONTENT
over	SEC_CONTENT
400	SEC_CONTENT
characters	SEC_CONTENT
apart	SEC_CONTENT
.	SEC_END
