title	SECTITLE_END
Abstractive	SEC_START
Sentence	task
Summarization	task
with	SEC_CONTENT
Attentive	SEC_CONTENT
Recurrent	SEC_CONTENT
Neural	SEC_CONTENT
Networks	SEC_END
abstract	SECTITLE_END
i	SEC_START
ve	SEC_CONTENT
Sentence	task
Summarization	task
generates	SEC_CONTENT
a	SEC_CONTENT
shorter	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
sentence	SEC_CONTENT
while	SEC_CONTENT
attempting	SEC_CONTENT
to	SEC_CONTENT
preserve	SEC_CONTENT
its	SEC_CONTENT
meaning	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
introduce	SEC_CONTENT
a	SEC_CONTENT
conditional	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
RNN	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
generates	SEC_CONTENT
a	SEC_CONTENT
summary	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
conditioning	SEC_CONTENT
is	SEC_CONTENT
provided	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
convolutional	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
encoder	SEC_CONTENT
which	SEC_CONTENT
ensures	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
focuses	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
appropriate	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
step	SEC_CONTENT
of	SEC_CONTENT
generation	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
relies	SEC_CONTENT
only	SEC_CONTENT
on	SEC_CONTENT
learned	SEC_CONTENT
features	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
easy	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
in	SEC_CONTENT
an	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
fashion	SEC_CONTENT
on	SEC_CONTENT
large	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
experiments	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
significantly	SEC_CONTENT
outperforms	SEC_CONTENT
the	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
method	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Giga	SEC_CONTENT
-	SEC_CONTENT
word	SEC_CONTENT
corpus	SEC_CONTENT
while	SEC_CONTENT
performing	SEC_CONTENT
competitively	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
DUC-2004	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Generating	SEC_START
a	SEC_CONTENT
condensed	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
passage	SEC_CONTENT
while	SEC_CONTENT
preserving	SEC_CONTENT
its	SEC_CONTENT
meaning	SEC_CONTENT
is	SEC_CONTENT
known	SEC_CONTENT
as	SEC_CONTENT
text	task
summarization	task
.	SEC_CONTENT
Tackling	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
important	SEC_CONTENT
step	SEC_CONTENT
towards	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
.	SEC_CONTENT
Summarization	SEC_CONTENT
systems	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
broadly	SEC_CONTENT
classified	SEC_CONTENT
into	SEC_CONTENT
two	SEC_CONTENT
categories	SEC_CONTENT
.	SEC_CONTENT
Extractive	SEC_CONTENT
models	SEC_CONTENT
generate	SEC_CONTENT
summaries	SEC_CONTENT
by	SEC_CONTENT
cropping	SEC_CONTENT
important	SEC_CONTENT
segments	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
text	SEC_CONTENT
and	SEC_CONTENT
putting	SEC_CONTENT
them	SEC_CONTENT
together	SEC_CONTENT
to	SEC_CONTENT
form	SEC_CONTENT
a	SEC_CONTENT
coherent	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_CONTENT
Abstractive	SEC_CONTENT
models	SEC_CONTENT
generate	SEC_CONTENT
summaries	SEC_CONTENT
from	SEC_CONTENT
scratch	SEC_CONTENT
without	SEC_CONTENT
being	SEC_CONTENT
constrained	SEC_CONTENT
to	SEC_CONTENT
reuse	SEC_CONTENT
phrases	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
original	SEC_CONTENT
text	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
paper	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
of	SEC_CONTENT
abstractive	task
sentence	task
summarization	task
.	SEC_CONTENT
Inspired	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
architectures	SEC_CONTENT
for	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
conditional	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
acts	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
decoder	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
much	SEC_CONTENT
like	SEC_CONTENT
a	SEC_CONTENT
standard	SEC_CONTENT
recurrent	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
at	SEC_CONTENT
every	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
also	SEC_CONTENT
takes	SEC_CONTENT
a	SEC_CONTENT
conditioning	SEC_CONTENT
input	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
an	SEC_CONTENT
encoder	SEC_CONTENT
module	SEC_CONTENT
.	SEC_CONTENT
Depending	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
RNN	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
computes	SEC_CONTENT
scores	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
scores	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
interpreted	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
soft	SEC_CONTENT
alignment	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
text	SEC_CONTENT
,	SEC_CONTENT
informing	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
which	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
it	SEC_CONTENT
should	SEC_CONTENT
focus	SEC_CONTENT
onto	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
and	SEC_CONTENT
encoder	SEC_CONTENT
are	SEC_CONTENT
jointly	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
data	SEC_CONTENT
set	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
extension	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
problem	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
they	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
neural	SEC_CONTENT
language	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
generation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
encoder	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
sophisticated	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
explicitly	SEC_CONTENT
encodes	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
information	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Lastly	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
encoder	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
convolutional	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
encode	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
extensions	SEC_CONTENT
result	SEC_CONTENT
in	SEC_CONTENT
improved	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
The	SEC_START
main	SEC_CONTENT
contribution	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
convolutional	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
conditional	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
of	SEC_CONTENT
abstractive	task
sentence	task
summarization	task
.	SEC_CONTENT
Empirically	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
beats	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
systems	SEC_CONTENT
of	SEC_CONTENT
on	SEC_CONTENT
multiple	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
notable	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
fact	SEC_CONTENT
that	SEC_CONTENT
even	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
generation	SEC_CONTENT
module	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
use	SEC_CONTENT
any	SEC_CONTENT
extractive	SEC_CONTENT
feature	SEC_CONTENT
tuning	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
manages	SEC_CONTENT
to	SEC_CONTENT
significantly	SEC_CONTENT
outperform	SEC_CONTENT
their	SEC_CONTENT
ABS+	SEC_CONTENT
system	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Gigaword	SEC_CONTENT
data	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
comparable	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
DUC-2004	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
93	SECTITLE_END
While	SEC_START
there	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
body	SEC_CONTENT
of	SEC_CONTENT
work	SEC_CONTENT
for	SEC_CONTENT
generating	SEC_CONTENT
extractive	SEC_CONTENT
summaries	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
much	SEC_CONTENT
less	SEC_CONTENT
research	SEC_CONTENT
on	SEC_CONTENT
abstractive	task
summarization	task
.	SEC_CONTENT
A	SEC_CONTENT
count	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
noisy	SEC_CONTENT
-	SEC_CONTENT
channel	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
proposed	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
abstractive	SEC_CONTENT
sentence	SEC_CONTENT
summarization	SEC_CONTENT
was	SEC_CONTENT
later	SEC_CONTENT
formalized	SEC_CONTENT
around	SEC_CONTENT
the	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
TOP	SEC_CONTENT
-	SEC_CONTENT
IARY	SEC_CONTENT
system	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
was	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
ofthe	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
.	SEC_CONTENT
More	SEC_CONTENT
recently	SEC_CONTENT
and	SEC_CONTENT
later	SEC_CONTENT
proposed	SEC_CONTENT
systems	SEC_CONTENT
which	SEC_CONTENT
made	SEC_CONTENT
heavy	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
syntactic	SEC_CONTENT
features	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
Later	SEC_CONTENT
,	SEC_CONTENT
along	SEC_CONTENT
the	SEC_CONTENT
lines	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
MOSES	SEC_CONTENT
was	SEC_CONTENT
used	SEC_CONTENT
directly	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
method	SEC_CONTENT
for	SEC_CONTENT
text	SEC_CONTENT
simplification	SEC_CONTENT
by	SEC_CONTENT
.	SEC_CONTENT
Other	SEC_CONTENT
works	SEC_CONTENT
which	SEC_CONTENT
have	SEC_CONTENT
recently	SEC_CONTENT
been	SEC_CONTENT
proposed	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
summarization	SEC_CONTENT
include	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Very	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
attention	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
using	SEC_CONTENT
anew	SEC_CONTENT
data	SEC_CONTENT
set	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
showing	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
DUC	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
an	SEC_CONTENT
extension	SEC_CONTENT
of	SEC_CONTENT
their	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Attentive	SECTITLE_START
Recurrent	SECTITLE_CONTENT
Architecture	SECTITLE_END
Let	SEC_START
x	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
M	dataset
words	dataset
x	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
x	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
M	SEC_CONTENT
]	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
xi	SEC_CONTENT
is	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
vocabulary	SEC_CONTENT
V	SEC_CONTENT
,	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
|V|	SEC_CONTENT
=	SEC_CONTENT
V	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
a	SEC_CONTENT
target	SEC_CONTENT
sequence	SEC_CONTENT
y	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
y	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
N	SEC_CONTENT
]	SEC_CONTENT
,	SEC_CONTENT
of	SEC_CONTENT
N	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
N	SEC_CONTENT
<	SEC_CONTENT
M	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
meaning	SEC_CONTENT
of	SEC_CONTENT
x	SEC_CONTENT
is	SEC_CONTENT
preserved	SEC_CONTENT
:	SEC_CONTENT
y	SEC_CONTENT
=	SEC_CONTENT
argmax	SEC_CONTENT
y	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
y	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
random	SEC_CONTENT
variable	SEC_CONTENT
denoting	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
N	SEC_CONTENT
words	SEC_CONTENT
.	SEC_END
Typically	SEC_START
the	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
is	SEC_CONTENT
modeled	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
parametric	SEC_CONTENT
function	SEC_CONTENT
with	SEC_CONTENT
parameters	SEC_CONTENT
θ	SEC_CONTENT
:	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
;	SEC_CONTENT
θ	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Training	SEC_CONTENT
involves	SEC_CONTENT
finding	SEC_CONTENT
the	SEC_CONTENT
θ	SEC_CONTENT
which	SEC_CONTENT
maximizes	SEC_CONTENT
the	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
If	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
word	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
,	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
conditional	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
factorized	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
product	SEC_CONTENT
of	SEC_CONTENT
individual	SEC_CONTENT
conditional	SEC_CONTENT
probabilities	SEC_CONTENT
:	SEC_END
In	SEC_START
this	SEC_CONTENT
work	SEC_CONTENT
we	SEC_CONTENT
model	SEC_CONTENT
this	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
using	SEC_CONTENT
an	SEC_CONTENT
RNN	SEC_CONTENT
Encoder	SEC_CONTENT
-	SEC_CONTENT
Decoder	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
inspired	SEC_CONTENT
by	SEC_CONTENT
 	SEC_CONTENT
and	SEC_CONTENT
subsequently	SEC_CONTENT
extended	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
call	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
RAS	SEC_CONTENT
(	SEC_CONTENT
Recurrent	SEC_CONTENT
Attentive	SEC_CONTENT
Summarizer	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Recurrent	SECTITLE_START
Decoder	SECTITLE_END
The	SEC_START
above	SEC_CONTENT
conditional	SEC_CONTENT
is	SEC_CONTENT
modeled	SEC_CONTENT
using	SEC_CONTENT
an	SEC_CONTENT
RNN	SEC_CONTENT
:	SEC_END
where	SEC_START
ht	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
RNN	SEC_CONTENT
:	SEC_END
Here	SEC_START
ct	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
module	SEC_CONTENT
(	SEC_CONTENT
detailed	SEC_CONTENT
in	SEC_CONTENT
§	SEC_CONTENT
3.2	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
computed	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
state	SEC_CONTENT
h	SEC_CONTENT
t−1	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
x.	SEC_END
Our	SEC_START
Elman	SEC_CONTENT
RNN	SEC_CONTENT
takes	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
form	SEC_CONTENT
(	SEC_CONTENT
Elman	SEC_CONTENT
,	SEC_CONTENT
1990	SEC_CONTENT
)	SEC_CONTENT
:	SEC_END
where	SEC_START
σ	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sigmoid	SEC_CONTENT
function	SEC_CONTENT
and	SEC_CONTENT
ρ	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
,	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
:	SEC_CONTENT
ρ(o	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
e	SEC_CONTENT
ot	SEC_CONTENT
/	SEC_CONTENT
j	SEC_CONTENT
e	SEC_CONTENT
o	SEC_CONTENT
j	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
i	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
5	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
matrices	SEC_CONTENT
of	SEC_CONTENT
learnable	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
sizes	SEC_CONTENT
W	SEC_CONTENT
{	SEC_CONTENT
1,2,3	SEC_CONTENT
}	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×d	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
{	SEC_CONTENT
4,5	SEC_CONTENT
}	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×V	SEC_CONTENT
.	SEC_END
The	SEC_START
LSTM	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
:	SEC_END
Operator	SEC_START
refers	SEC_CONTENT
to	SEC_CONTENT
component	SEC_CONTENT
-	SEC_CONTENT
wise	SEC_CONTENT
multiplication	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
i	SEC_CONTENT
(	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
14	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
matrices	SEC_CONTENT
of	SEC_CONTENT
learnable	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
sizes	SEC_CONTENT
W	SEC_CONTENT
{	SEC_CONTENT
1,	SEC_CONTENT
...	SEC_CONTENT
,12	SEC_CONTENT
}	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×d	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
{	SEC_CONTENT
13,14	SEC_CONTENT
}	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
d×V	SEC_CONTENT
.	SEC_END
Attentive	SECTITLE_START
Encoder	SECTITLE_END
We	SEC_START
now	SEC_CONTENT
give	SEC_CONTENT
the	SEC_CONTENT
details	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
which	SEC_CONTENT
computes	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
ct	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
t	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
above	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
a	SEC_CONTENT
slight	SEC_CONTENT
overload	SEC_CONTENT
of	SEC_CONTENT
notation	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
x	SEC_CONTENT
we	SEC_CONTENT
denote	SEC_CONTENT
by	SEC_CONTENT
xi	SEC_CONTENT
the	SEC_CONTENT
d	SEC_CONTENT
dimensional	SEC_CONTENT
learnable	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
i	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
word	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
i	SEC_CONTENT
∈	SEC_CONTENT
Rd	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	task
the	SEC_CONTENT
position	SEC_CONTENT
i	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
xi	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
associated	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
learnable	SEC_CONTENT
embedding	SEC_CONTENT
l	SEC_CONTENT
i	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
d	SEC_CONTENT
(	SEC_CONTENT
l	SEC_CONTENT
i	SEC_CONTENT
∈	SEC_CONTENT
Rd	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
embedding	SEC_CONTENT
for	SEC_CONTENT
i	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
x	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
xi	SEC_CONTENT
+	SEC_CONTENT
l	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
us	SEC_CONTENT
denote	SEC_CONTENT
by	SEC_CONTENT
Bk	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
q×d	SEC_CONTENT
a	SEC_CONTENT
learnable	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
convolve	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
consecutive	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Let	SEC_CONTENT
there	SEC_CONTENT
bed	SEC_CONTENT
such	SEC_CONTENT
matrices	SEC_CONTENT
(	SEC_CONTENT
k	SEC_CONTENT
∈	SEC_CONTENT
{	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
d	SEC_CONTENT
}	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
convolution	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
by	SEC_CONTENT
:	SEC_END
where	SEC_START
bk	SEC_CONTENT
j	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
j	SEC_CONTENT
-	SEC_CONTENT
th	SEC_CONTENT
column	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
matrix	SEC_CONTENT
Bk	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
the	SEC_CONTENT
d	SEC_CONTENT
dimensional	SEC_CONTENT
aggregate	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
z	SEC_CONTENT
i1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
d	SEC_CONTENT
]	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
each	dataset
word	dataset
xi	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
is	SEC_CONTENT
associated	SEC_CONTENT
with	SEC_CONTENT
one	SEC_CONTENT
aggregate	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
vectors	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
which	SEC_CONTENT
captures	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
it	SEC_CONTENT
occurs	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
also	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
in	SEC_CONTENT
which	SEC_CONTENT
it	SEC_CONTENT
appears	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
In	SEC_START
our	SEC_CONTENT
experiments	SEC_CONTENT
the	SEC_CONTENT
width	SEC_CONTENT
q	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
convolution	SEC_CONTENT
matrix	SEC_CONTENT
Bk	SEC_CONTENT
was	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
5	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
account	SEC_CONTENT
for	SEC_CONTENT
words	dataset
at	SEC_CONTENT
the	SEC_CONTENT
boundaries	SEC_CONTENT
of	SEC_CONTENT
x	SEC_CONTENT
we	SEC_CONTENT
first	SEC_CONTENT
pad	SEC_CONTENT
the	SEC_CONTENT
sequence	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
sides	SEC_CONTENT
with	SEC_CONTENT
dummy	SEC_CONTENT
words	SEC_CONTENT
before	SEC_CONTENT
computing	SEC_CONTENT
the	SEC_CONTENT
aggregate	SEC_CONTENT
vectors	SEC_CONTENT
z	SEC_CONTENT
i	SEC_CONTENT
'	SEC_CONTENT
s.	SEC_END
Given	SEC_START
these	SEC_CONTENT
aggregate	SEC_CONTENT
vectors	SEC_CONTENT
of	SEC_CONTENT
words	dataset
,	SEC_CONTENT
we	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
vector	SEC_CONTENT
ct	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
output	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
:	SEC_END
where	SEC_START
the	SEC_CONTENT
weights	SEC_CONTENT
α	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
t−1	SEC_CONTENT
are	SEC_CONTENT
computed	SEC_CONTENT
as	SEC_END
Training	SECTITLE_START
and	SECTITLE_CONTENT
Generation	SECTITLE_END
Given	SEC_START
a	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
S	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
(	SEC_CONTENT
x	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
}	SEC_CONTENT
S	SEC_CONTENT
i=1	SEC_CONTENT
of	SEC_CONTENT
S	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
above	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
using	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
by	SEC_CONTENT
minimizing	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
conditional	SEC_CONTENT
log	SEC_CONTENT
likelihood	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
θ	SEC_CONTENT
:	SEC_END
where	SEC_START
the	SEC_CONTENT
parameters	SEC_CONTENT
θ	SEC_CONTENT
constitute	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_END
Once	SEC_START
the	SEC_CONTENT
parametric	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
a	SEC_CONTENT
summary	SEC_CONTENT
fora	SEC_CONTENT
new	SEC_CONTENT
sentence	SEC_CONTENT
x	SEC_CONTENT
through	SEC_CONTENT
a	SEC_CONTENT
wordbased	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
such	SEC_CONTENT
that	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
y|x	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
maximized	SEC_CONTENT
,	SEC_CONTENT
argmax	SEC_CONTENT
P	SEC_CONTENT
(	SEC_CONTENT
y	SEC_CONTENT
t	SEC_CONTENT
|{y	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
t−1	SEC_CONTENT
}	SEC_CONTENT
,	SEC_CONTENT
x	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
search	SEC_CONTENT
is	SEC_CONTENT
parameterized	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
paths	SEC_CONTENT
k	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
pursued	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
.	SEC_END
Experimental	SECTITLE_START
Setup	SECTITLE_END
Datasets	SECTITLE_START
and	SECTITLE_CONTENT
Evaluation	SECTITLE_END
Our	SEC_START
models	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
annotated	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Gigaword	dataset
corpus	dataset
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
annotations	SEC_CONTENT
for	SEC_CONTENT
tokenization	SEC_CONTENT
and	SEC_CONTENT
sentence	SEC_CONTENT
separation	SEC_CONTENT
while	SEC_CONTENT
discarding	SEC_CONTENT
other	SEC_CONTENT
annotations	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
tags	SEC_CONTENT
and	SEC_CONTENT
parses	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
pair	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
article	SEC_CONTENT
with	SEC_CONTENT
its	SEC_CONTENT
headline	SEC_CONTENT
to	SEC_CONTENT
form	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
processed	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
way	SEC_CONTENT
as	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
splits	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
validation	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
testing	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
Gigaword	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
randomly	SEC_CONTENT
held	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
2000	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
summary	SEC_CONTENT
pairs	SEC_CONTENT
as	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
evaluate	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
DUC-2004	SEC_CONTENT
evaluation	SEC_CONTENT
data	SEC_CONTENT
set	SEC_CONTENT
comprising	SEC_CONTENT
500	SEC_CONTENT
pairs	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
evaluation	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
three	SEC_CONTENT
variants	SEC_CONTENT
of	SEC_CONTENT
ROUGE	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
namely	SEC_CONTENT
,	SEC_CONTENT
ROUGE-1	SEC_CONTENT
(	SEC_CONTENT
unigrams	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
ROUGE-2	SEC_CONTENT
(	SEC_CONTENT
bigrams	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
(	SEC_CONTENT
longest	SEC_CONTENT
-	SEC_CONTENT
common	SEC_CONTENT
substring	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Architectural	SECTITLE_START
Choices	SECTITLE_END
We	SEC_START
implemented	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
Torch	SEC_CONTENT
library	SEC_CONTENT
(	SEC_CONTENT
http://torch.ch/	SEC_CONTENT
)	SEC_CONTENT
2	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
optimize	SEC_CONTENT
our	SEC_CONTENT
loss	SEC_CONTENT
(	SEC_CONTENT
Equation	task
5	SEC_CONTENT
)	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
with	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batches	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
32	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
training	SEC_CONTENT
we	SEC_CONTENT
measure	SEC_CONTENT
the	SEC_CONTENT
perplexity	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
summaries	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
adjust	SEC_CONTENT
our	SEC_CONTENT
hyper	SEC_CONTENT
-	SEC_CONTENT
parameters	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
,	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
number	SEC_CONTENT
.	SEC_END
Model	SECTITLE_END
Perplexity	SECTITLE_END
Bag	SEC_START
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
Words	SEC_END
Convolutional	SECTITLE_START
(	SECTITLE_CONTENT
TDNN	SECTITLE_CONTENT
)	SECTITLE_CONTENT
35.9	SECTITLE_CONTENT
Attention	SECTITLE_CONTENT
-	SECTITLE_CONTENT
based	SECTITLE_CONTENT
(	SECTITLE_CONTENT
ABS	SECTITLE_CONTENT
)	SECTITLE_CONTENT
27.1	SECTITLE_CONTENT
RAS	SECTITLE_CONTENT
-	SECTITLE_CONTENT
Elman	SECTITLE_END
18.9	SEC_START
RAS	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
20.3	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
we	SEC_CONTENT
experimented	SEC_CONTENT
with	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
Elman	SEC_CONTENT
RNN	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
Long	SEC_CONTENT
-	SEC_CONTENT
Short	SEC_CONTENT
Term	SEC_CONTENT
Memory	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
architecture	SEC_CONTENT
(	SEC_CONTENT
as	SEC_CONTENT
discussed	SEC_CONTENT
in	SEC_CONTENT
§	SEC_CONTENT
3.1	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
chose	SEC_CONTENT
hyper	SEC_CONTENT
-	SEC_CONTENT
parameters	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
grid	SEC_CONTENT
search	SEC_CONTENT
and	SEC_CONTENT
picked	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
which	SEC_CONTENT
gave	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
perplexity	SEC_CONTENT
on	SEC_CONTENT
the	task
validation	task
set	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
we	SEC_CONTENT
searched	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
H	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
recurrent	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
η	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
annealing	SEC_CONTENT
schedule	SEC_CONTENT
γ	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
factor	SEC_CONTENT
by	SEC_CONTENT
which	SEC_CONTENT
to	SEC_CONTENT
decrease	SEC_CONTENT
η	SEC_CONTENT
if	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
perplexity	SEC_CONTENT
increases	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
gradient	SEC_CONTENT
clipping	SEC_CONTENT
threshold	SEC_CONTENT
κ	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
final	SEC_CONTENT
Elman	SEC_CONTENT
architecture	SEC_CONTENT
(	SEC_CONTENT
RASElman	SEC_CONTENT
)	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
layer	SEC_CONTENT
with	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
512	SEC_CONTENT
,	SEC_CONTENT
η	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
,	SEC_CONTENT
γ	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
κ	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
LSTM	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
also	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
layer	SEC_CONTENT
with	SEC_CONTENT
H	SEC_CONTENT
=	SEC_CONTENT
512	SEC_CONTENT
,	SEC_CONTENT
η	SEC_CONTENT
=	SEC_CONTENT
0.1	SEC_CONTENT
,	SEC_CONTENT
γ	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
κ	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
On	SEC_START
the	dataset
Gigaword	dataset
corpus	dataset
we	SEC_CONTENT
evaluate	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
perplexity	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
held	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
then	SEC_CONTENT
pick	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
best	SEC_CONTENT
perplexity	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
held	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
it	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
the	SEC_CONTENT
F1-score	SEC_CONTENT
of	SEC_CONTENT
ROUGE-1	SEC_CONTENT
,	SEC_CONTENT
ROUGE-2	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
ROUGE	SEC_CONTENT
-	SEC_CONTENT
L	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
,	SEC_CONTENT
all	SEC_CONTENT
of	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
DUC	SEC_CONTENT
corpus	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
inline	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
recall	SEC_CONTENT
-	SEC_CONTENT
only	SEC_CONTENT
ROUGE	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
baseline	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
system	SEC_CONTENT
(	SEC_CONTENT
ABS	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
which	SEC_CONTENT
relies	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
network	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
an	SEC_CONTENT
enhanced	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
their	SEC_CONTENT
system	SEC_CONTENT
(	SEC_CONTENT
ABS+	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
relies	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
separate	SEC_CONTENT
extractive	SEC_CONTENT
summarization	SEC_CONTENT
features	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
added	SEC_CONTENT
as	SEC_CONTENT
log	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
features	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
secondary	SEC_CONTENT
learning	SEC_CONTENT
step	SEC_CONTENT
with	SEC_CONTENT
minimum	SEC_CONTENT
error	SEC_CONTENT
rate	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
that	SEC_CONTENT
both	SEC_CONTENT
our	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
and	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
models	SEC_CONTENT
achieve	SEC_CONTENT
lower	SEC_CONTENT
perplexity	SEC_CONTENT
than	SEC_CONTENT
  	SEC_CONTENT
ABS	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
other	SEC_CONTENT
models	SEC_CONTENT
reported	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
performs	SEC_CONTENT
slightly	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
,	SEC_CONTENT
most	SEC_CONTENT
likely	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
over	SEC_CONTENT
-	SEC_CONTENT
fitting	SEC_CONTENT
.	SEC_END
We	SEC_START
attribute	SEC_CONTENT
this	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
relatively	SEC_CONTENT
simple	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
which	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
framed	SEC_CONTENT
as	SEC_CONTENT
English	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
English	SEC_CONTENT
translation	SEC_CONTENT
with	SEC_CONTENT
few	SEC_CONTENT
long	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
dependencies	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
ROUGE	SEC_CONTENT
results	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
comfortably	SEC_CONTENT
outperform	SEC_CONTENT
both	SEC_CONTENT
ABS	SEC_CONTENT
and	SEC_CONTENT
ABS+	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
wide	SEC_CONTENT
margin	SEC_CONTENT
on	SEC_CONTENT
all	SEC_CONTENT
metrics	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
even	SEC_CONTENT
the	SEC_CONTENT
case	SEC_CONTENT
when	SEC_CONTENT
we	SEC_CONTENT
rely	SEC_CONTENT
only	SEC_CONTENT
on	SEC_CONTENT
very	SEC_CONTENT
fast	SEC_CONTENT
greedy	SEC_CONTENT
search	SEC_CONTENT
(	SEC_CONTENT
k	SEC_CONTENT
=	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
as	SEC_CONTENT
ABS	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
much	SEC_CONTENT
wider	SEC_CONTENT
beam	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
k	SEC_CONTENT
=	SEC_CONTENT
50	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
stronger	SEC_CONTENT
ABS+	SEC_CONTENT
system	SEC_CONTENT
also	SEC_CONTENT
uses	SEC_CONTENT
additional	SEC_CONTENT
extractive	SEC_CONTENT
features	SEC_CONTENT
which	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
features	SEC_CONTENT
cause	SEC_CONTENT
ABS+	SEC_CONTENT
to	SEC_CONTENT
copy	SEC_CONTENT
92	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
words	dataset
from	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
summary	SEC_CONTENT
,	SEC_CONTENT
whereas	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
copies	SEC_CONTENT
only	SEC_CONTENT
74	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
leading	SEC_CONTENT
to	SEC_CONTENT
more	SEC_CONTENT
abstractive	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
DUC-2004	SEC_CONTENT
we	SEC_CONTENT
report	SEC_CONTENT
recall	SEC_CONTENT
ROUGE	SEC_CONTENT
as	SEC_CONTENT
is	SEC_CONTENT
customary	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
(	SEC_CONTENT
Table	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
ABS+	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
the	SEC_CONTENT
improvements	SEC_CONTENT
are	SEC_CONTENT
smaller	SEC_CONTENT
than	SEC_CONTENT
for	SEC_CONTENT
Gi	SEC_CONTENT
-	SEC_CONTENT
gaword	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
likely	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
two	SEC_CONTENT
reasons	SEC_CONTENT
:	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
tokenization	SEC_CONTENT
of	SEC_CONTENT
DUC-2004	SEC_CONTENT
differs	SEC_CONTENT
slightly	SEC_CONTENT
from	SEC_CONTENT
our	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
headlines	SEC_CONTENT
in	SEC_CONTENT
Gigaword	SEC_CONTENT
are	SEC_CONTENT
much	SEC_CONTENT
shorter	SEC_CONTENT
than	SEC_CONTENT
in	SEC_CONTENT
DUC-2004	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
sake	SEC_CONTENT
of	SEC_CONTENT
completeness	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
compare	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
recently	SEC_CONTENT
proposed	SEC_CONTENT
standard	SEC_CONTENT
Neural	SEC_CONTENT
Machine	SEC_CONTENT
Translation	SEC_CONTENT
(	SEC_CONTENT
NMT	SEC_CONTENT
)	SEC_CONTENT
systems	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
smaller	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
implementation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
attentive	SEC_CONTENT
stacked	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
of	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
implementation	SEC_CONTENT
uses	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
LSTMs	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
with	SEC_CONTENT
500	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
report	SEC_CONTENT
ROUGE	SEC_CONTENT
scores	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
From	SEC_CONTENT
the	SEC_CONTENT
tables	SEC_CONTENT
we	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
match	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
NMT	SEC_CONTENT
model	SEC_CONTENT
of	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
noteworthy	SEC_CONTENT
because	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
is	SEC_CONTENT
significantly	SEC_CONTENT
simpler	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
NMT	SEC_CONTENT
model	SEC_CONTENT
at	SEC_CONTENT
multiple	SEC_CONTENT
levels	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
used	SEC_CONTENT
by	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
is	SEC_CONTENT
extremely	SEC_CONTENT
light	SEC_CONTENT
-	SEC_CONTENT
weight	SEC_CONTENT
(	SEC_CONTENT
attention	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
convolutional	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
Luong	SEC_CONTENT
's	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
2	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
used	SEC_CONTENT
by	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
layer	SEC_CONTENT
standard	SEC_CONTENT
(	SEC_CONTENT
Elman	SEC_CONTENT
)	SEC_CONTENT
RNN	SEC_CONTENT
as	SEC_CONTENT
opposed	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
an	SEC_CONTENT
independent	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
Nallapati	SEC_CONTENT
et	SEC_CONTENT
.	SEC_CONTENT
al	SEC_CONTENT
also	SEC_CONTENT
trained	SEC_CONTENT
a	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
standard	SEC_CONTENT
NMT	SEC_CONTENT
models	SEC_CONTENT
and	SEC_CONTENT
report	SEC_CONTENT
numbers	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
ballpark	SEC_CONTENT
as	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
datasets	SEC_CONTENT
.	SEC_END
In	SEC_START
order	SEC_CONTENT
to	SEC_CONTENT
better	SEC_CONTENT
understand	SEC_CONTENT
which	SEC_CONTENT
component	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
architecture	SEC_CONTENT
is	SEC_CONTENT
responsible	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
improvements	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
trained	SEC_CONTENT
the	SEC_CONTENT
recurrent	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
's	SEC_CONTENT
ABS	SEC_CONTENT
encoder	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
subset	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Gigaword	dataset
dataset	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
ABS	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
achieves	SEC_CONTENT
a	SEC_CONTENT
final	SEC_CONTENT
validation	SEC_CONTENT
perplexity	SEC_CONTENT
of	SEC_CONTENT
38	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
29	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
encoder	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
uses	SEC_CONTENT
position	SEC_CONTENT
features	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
context	SEC_CONTENT
information	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
clearly	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
benefits	SEC_CONTENT
of	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
position	SEC_CONTENT
feature	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
proposed	SEC_CONTENT
encoder	SEC_CONTENT
.	SEC_END
Finally	SEC_START
in	SEC_CONTENT
we	SEC_CONTENT
highlight	SEC_CONTENT
anecdotal	SEC_CONTENT
examples	SEC_CONTENT
of	SEC_CONTENT
summaries	task
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
Elman	SEC_CONTENT
system	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Gigaword	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
two	SEC_CONTENT
examples	SEC_CONTENT
highlight	SEC_CONTENT
typical	SEC_CONTENT
improvements	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
RAS	SEC_CONTENT
model	SEC_CONTENT
over	SEC_CONTENT
ABS+	SEC_CONTENT
.	SEC_CONTENT
Generally	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
produces	SEC_CONTENT
more	SEC_CONTENT
fluent	SEC_CONTENT
summaries	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
better	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
actors	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
instance	SEC_CONTENT
in	SEC_CONTENT
Sentence	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
RASElman	SEC_CONTENT
correctly	SEC_CONTENT
distinguishes	SEC_CONTENT
the	SEC_CONTENT
actions	SEC_CONTENT
of	SEC_CONTENT
"	SEC_CONTENT
pepe	SEC_CONTENT
"	SEC_CONTENT
from	SEC_CONTENT
"	SEC_CONTENT
ferreira	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
in	SEC_CONTENT
Sentence	SEC_CONTENT
2	SEC_CONTENT
it	SEC_CONTENT
identifies	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
role	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
think	SEC_CONTENT
tank	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
final	SEC_CONTENT
two	SEC_CONTENT
ex	SEC_CONTENT
-	SEC_CONTENT
I(1	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
brazilian	SEC_CONTENT
defender	SEC_CONTENT
pepe	SEC_CONTENT
is	SEC_CONTENT
out	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
rest	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
season	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
knee	SEC_CONTENT
injury	SEC_CONTENT
,	SEC_CONTENT
his	SEC_CONTENT
porto	SEC_CONTENT
coach	SEC_CONTENT
jesualdo	SEC_CONTENT
ferreira	SEC_CONTENT
said	SEC_CONTENT
saturday	SEC_CONTENT
.	SEC_CONTENT
G	SEC_CONTENT
:	SEC_CONTENT
football	SEC_CONTENT
:	SEC_CONTENT
pepe	SEC_CONTENT
out	SEC_CONTENT
for	SEC_CONTENT
season	SEC_CONTENT
A+	SEC_CONTENT
:	SEC_CONTENT
ferreira	SEC_CONTENT
out	SEC_CONTENT
for	SEC_CONTENT
rest	SEC_CONTENT
of	SEC_CONTENT
season	SEC_CONTENT
with	SEC_CONTENT
knee	SEC_CONTENT
injury	SEC_CONTENT
R	SEC_CONTENT
:	SEC_CONTENT
brazilian	SEC_CONTENT
defender	SEC_CONTENT
pepe	SEC_CONTENT
out	SEC_CONTENT
for	SEC_CONTENT
rest	SEC_CONTENT
of	SEC_CONTENT
season	SEC_CONTENT
with	SEC_CONTENT
knee	SEC_CONTENT
injury	SEC_CONTENT
I(2	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
economic	SEC_CONTENT
growth	SEC_CONTENT
in	SEC_CONTENT
toronto	SEC_CONTENT
will	SEC_CONTENT
suffer	SEC_CONTENT
this	SEC_CONTENT
year	SEC_CONTENT
because	SEC_CONTENT
of	SEC_CONTENT
sars	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
think	SEC_CONTENT
tank	SEC_CONTENT
said	SEC_CONTENT
friday	SEC_CONTENT
as	SEC_CONTENT
health	SEC_CONTENT
authorities	SEC_CONTENT
insisted	SEC_CONTENT
the	SEC_CONTENT
illness	SEC_CONTENT
was	SEC_CONTENT
under	SEC_CONTENT
control	SEC_CONTENT
in	SEC_CONTENT
canada	SEC_CONTENT
's	SEC_CONTENT
largest	SEC_CONTENT
city	SEC_CONTENT
.	SEC_CONTENT
G	SEC_CONTENT
:	SEC_CONTENT
sars	SEC_CONTENT
toll	SEC_CONTENT
on	SEC_CONTENT
toronto	SEC_CONTENT
economy	SEC_CONTENT
estimated	SEC_CONTENT
at	SEC_CONTENT
c$	SEC_CONTENT
#	SEC_CONTENT
billion	SEC_CONTENT
A+	SEC_CONTENT
:	SEC_CONTENT
think	SEC_CONTENT
tank	SEC_CONTENT
under	SEC_CONTENT
control	SEC_CONTENT
in	SEC_CONTENT
canada	SEC_CONTENT
's	SEC_CONTENT
largest	SEC_CONTENT
city	SEC_CONTENT
R	SEC_CONTENT
:	SEC_CONTENT
think	SEC_CONTENT
tank	SEC_CONTENT
says	SEC_CONTENT
economic	SEC_CONTENT
growth	SEC_CONTENT
in	SEC_CONTENT
toronto	SEC_CONTENT
will	SEC_CONTENT
suffer	SEC_CONTENT
this	SEC_CONTENT
year	SEC_CONTENT
I(3	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
colin	SEC_CONTENT
l.	SEC_CONTENT
powell	SEC_CONTENT
said	SEC_CONTENT
nothing	SEC_CONTENT
-a	SEC_CONTENT
silence	SEC_CONTENT
that	SEC_CONTENT
spoke	SEC_CONTENT
volumes	SEC_CONTENT
to	SEC_CONTENT
many	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
white	SEC_CONTENT
house	SEC_CONTENT
on	SEC_CONTENT
thursday	SEC_CONTENT
morning	SEC_CONTENT
.	SEC_CONTENT
G	SEC_CONTENT
:	SEC_CONTENT
in	SEC_CONTENT
meeting	SEC_CONTENT
with	SEC_CONTENT
former	SEC_CONTENT
officials	SEC_CONTENT
bush	SEC_CONTENT
defends	SEC_CONTENT
iraq	SEC_CONTENT
policy	SEC_CONTENT
A+	SEC_CONTENT
:	SEC_CONTENT
colin	SEC_CONTENT
powell	SEC_CONTENT
speaks	SEC_CONTENT
volumes	SEC_CONTENT
about	SEC_CONTENT
silence	SEC_CONTENT
in	SEC_CONTENT
white	SEC_CONTENT
house	SEC_CONTENT
R	SEC_CONTENT
:	SEC_CONTENT
powell	SEC_CONTENT
speaks	SEC_CONTENT
volumes	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
white	SEC_CONTENT
house	SEC_CONTENT
I(4	SEC_CONTENT
)	SEC_CONTENT
:	SEC_CONTENT
an	SEC_CONTENT
international	SEC_CONTENT
terror	SEC_CONTENT
suspect	SEC_CONTENT
who	SEC_CONTENT
had	SEC_CONTENT
been	SEC_CONTENT
under	SEC_CONTENT
a	SEC_CONTENT
controversial	SEC_CONTENT
loose	SEC_CONTENT
form	SEC_CONTENT
of	SEC_CONTENT
house	SEC_CONTENT
arrest	SEC_CONTENT
is	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
run	SEC_CONTENT
,	SEC_CONTENT
british	SEC_CONTENT
home	SEC_CONTENT
secretary	SEC_CONTENT
john	SEC_CONTENT
reid	SEC_CONTENT
said	SEC_CONTENT
tuesday	SEC_CONTENT
.	SEC_CONTENT
G	SEC_CONTENT
:	SEC_CONTENT
international	SEC_CONTENT
terror	SEC_CONTENT
suspect	SEC_CONTENT
slips	SEC_CONTENT
net	SEC_CONTENT
in	SEC_CONTENT
britain	SEC_CONTENT
A+	SEC_CONTENT
:	SEC_CONTENT
reid	SEC_CONTENT
under	SEC_CONTENT
house	SEC_CONTENT
arrest	SEC_CONTENT
terror	SEC_CONTENT
suspect	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
run	SEC_CONTENT
R	SEC_CONTENT
:	SEC_CONTENT
international	SEC_CONTENT
terror	SEC_CONTENT
suspect	SEC_CONTENT
under	SEC_CONTENT
house	SEC_CONTENT
arrest	SEC_CONTENT
:	SEC_CONTENT
Example	SEC_CONTENT
sentence	SEC_CONTENT
summaries	SEC_CONTENT
produced	SEC_CONTENT
on	SEC_CONTENT
Gigaword	SEC_CONTENT
.	SEC_CONTENT
I	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
,	SEC_CONTENT
G	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
true	SEC_CONTENT
headline	SEC_CONTENT
,	SEC_CONTENT
A	SEC_CONTENT
is	SEC_CONTENT
ABS+	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
R	SEC_CONTENT
is	SEC_CONTENT
RAS	SEC_CONTENT
-	SEC_CONTENT
ELMAN	SEC_CONTENT
.	SEC_END
amples	SEC_START
highlight	SEC_CONTENT
typical	SEC_CONTENT
mistakes	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
Sentence	SEC_CONTENT
3	SEC_CONTENT
both	SEC_CONTENT
models	SEC_CONTENT
take	SEC_CONTENT
literally	SEC_CONTENT
the	SEC_CONTENT
figurative	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
idiom	SEC_CONTENT
"	SEC_CONTENT
a	SEC_CONTENT
silence	SEC_CONTENT
that	SEC_CONTENT
spoke	SEC_CONTENT
volumes	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
produce	SEC_CONTENT
fluent	SEC_CONTENT
but	SEC_CONTENT
nonsensical	SEC_CONTENT
summaries	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
Sentence	SEC_CONTENT
4	SEC_CONTENT
the	SEC_CONTENT
RAS	SEC_CONTENT
model	SEC_CONTENT
mistakes	SEC_CONTENT
the	SEC_CONTENT
content	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
relative	SEC_CONTENT
clause	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
verb	SEC_CONTENT
,	SEC_CONTENT
leading	SEC_CONTENT
to	SEC_CONTENT
a	task
summary	task
with	SEC_CONTENT
the	SEC_CONTENT
opposite	SEC_CONTENT
meaning	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
difficult	SEC_CONTENT
cases	SEC_CONTENT
are	SEC_CONTENT
somewhat	SEC_CONTENT
rare	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
Gigaword	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
they	SEC_CONTENT
highlight	SEC_CONTENT
future	SEC_CONTENT
challenges	SEC_CONTENT
for	SEC_CONTENT
obtaining	SEC_CONTENT
human	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
sentence	SEC_CONTENT
summary	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
extend	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
abstractive	task
sentence	task
summarization	task
(	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
architecture	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
simplified	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
framework	SEC_CONTENT
for	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Gigaword	SEC_CONTENT
corpus	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
headlines	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
line	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
news	SEC_CONTENT
article	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
comfortably	SEC_CONTENT
outperform	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
Gigaword	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
DUC-2004	SEC_CONTENT
challenge	SEC_CONTENT
even	SEC_CONTENT
though	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
additional	SEC_CONTENT
extractive	SEC_CONTENT
features	SEC_CONTENT
.	SEC_END
