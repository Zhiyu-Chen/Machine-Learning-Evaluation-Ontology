title	SECTITLE_END
Neural	SEC_START
Semantic	SEC_CONTENT
Encoders	SEC_END
abstract	SECTITLE_END
We	SEC_START
present	SEC_CONTENT
a	SEC_CONTENT
memory	SEC_CONTENT
augmented	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
for	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
:	SEC_CONTENT
Neural	SEC_CONTENT
Semantic	SEC_CONTENT
Encoders	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
equipped	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
rule	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
sized	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
that	SEC_CONTENT
evolves	SEC_CONTENT
overtime	SEC_CONTENT
and	SEC_CONTENT
maintains	SEC_CONTENT
the	SEC_CONTENT
understanding	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
sequences	SEC_CONTENT
through	SEC_CONTENT
read	SEC_CONTENT
,	SEC_CONTENT
compose	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
operations	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
access	SEC_CONTENT
1	SEC_CONTENT
multiple	SEC_CONTENT
and	SEC_CONTENT
shared	SEC_CONTENT
memories	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
demonstrated	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
flexibility	SEC_CONTENT
of	SEC_CONTENT
NSE	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
different	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
tasks	SEC_CONTENT
:	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
,	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
,	SEC_CONTENT
sentence	SEC_CONTENT
classification	SEC_CONTENT
,	SEC_CONTENT
document	task
sentiment	task
analysis	task
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
where	SEC_CONTENT
NSE	SEC_CONTENT
achieved	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
when	SEC_CONTENT
evaluated	SEC_CONTENT
on	SEC_CONTENT
publically	SEC_CONTENT
available	SEC_CONTENT
benchmarks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
shared	SEC_CONTENT
-	SEC_CONTENT
memory	SEC_CONTENT
model	SEC_CONTENT
showed	SEC_CONTENT
an	SEC_CONTENT
encouraging	SEC_CONTENT
result	SEC_CONTENT
on	SEC_CONTENT
neural	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
improving	SEC_CONTENT
an	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
baseline	SEC_CONTENT
by	SEC_CONTENT
approximately	SEC_CONTENT
1.0	SEC_CONTENT
BLEU	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Recurrent	SEC_START
neural	SEC_CONTENT
networks	SEC_CONTENT
(	SEC_CONTENT
RNNs	SEC_CONTENT
)	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
successful	SEC_CONTENT
for	SEC_CONTENT
modeling	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
,	SEC_CONTENT
RNNs	SEC_CONTENT
equipped	SEC_CONTENT
with	SEC_CONTENT
internal	SEC_CONTENT
short	SEC_CONTENT
memories	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
long	SEC_CONTENT
short	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
memories	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
)	SEC_CONTENT
have	SEC_CONTENT
achieved	SEC_CONTENT
a	SEC_CONTENT
notable	SEC_CONTENT
success	SEC_CONTENT
in	SEC_CONTENT
sequential	task
tasks	task
(	SEC_CONTENT
.	SEC_CONTENT
LSTM	SEC_CONTENT
is	SEC_CONTENT
powerful	SEC_CONTENT
because	SEC_CONTENT
it	SEC_CONTENT
learns	SEC_CONTENT
to	SEC_CONTENT
control	SEC_CONTENT
its	SEC_CONTENT
short	SEC_CONTENT
term	SEC_CONTENT
memories	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
short	SEC_CONTENT
term	SEC_CONTENT
memories	SEC_CONTENT
in	SEC_CONTENT
LSTM	SEC_CONTENT
area	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
imposes	SEC_CONTENT
some	SEC_CONTENT
practical	SEC_CONTENT
difficulties	SEC_CONTENT
in	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
modeling	SEC_CONTENT
long	SEC_CONTENT
sequences	SEC_CONTENT
with	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_END
Recently	SEC_START
several	SEC_CONTENT
studies	SEC_CONTENT
have	SEC_CONTENT
explored	SEC_CONTENT
ways	SEC_CONTENT
of	SEC_CONTENT
extending	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
external	SEC_CONTENT
memory	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
short	SEC_CONTENT
term	SEC_CONTENT
memories	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
such	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
are	SEC_CONTENT
no	SEC_CONTENT
longer	SEC_CONTENT
coupled	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
adapted	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
we	SEC_CONTENT
propose	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
class	SEC_CONTENT
of	SEC_CONTENT
memory	SEC_CONTENT
augmented	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
called	SEC_CONTENT
Neural	SEC_CONTENT
Semantic	SEC_CONTENT
Encoders	SEC_CONTENT
(	SEC_CONTENT
NSE	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
offers	SEC_CONTENT
several	SEC_CONTENT
desirable	SEC_CONTENT
properties	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
sized	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
which	SEC_CONTENT
allows	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
access	SEC_CONTENT
entire	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
during	SEC_CONTENT
the	SEC_CONTENT
reading	SEC_CONTENT
process	SEC_CONTENT
;	SEC_CONTENT
therefore	SEC_CONTENT
efficiently	SEC_CONTENT
delivering	SEC_CONTENT
long	SEC_CONTENT
-	SEC_CONTENT
term	SEC_CONTENT
dependencies	SEC_CONTENT
overtime	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
evolves	SEC_CONTENT
overtime	SEC_CONTENT
and	SEC_CONTENT
maintains	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
through	SEC_CONTENT
read	SEC_CONTENT
,	SEC_CONTENT
compose	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
operations	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
sequentially	SEC_CONTENT
processes	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
and	SEC_CONTENT
supports	SEC_CONTENT
word	SEC_CONTENT
compositionality	SEC_CONTENT
inheriting	SEC_CONTENT
both	SEC_CONTENT
temporal	SEC_CONTENT
and	SEC_CONTENT
hierarchical	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
human	SEC_CONTENT
language	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
can	SEC_CONTENT
read	SEC_CONTENT
from	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
relevant	SEC_CONTENT
encoding	SEC_CONTENT
memories	SEC_CONTENT
simultaneously	SEC_CONTENT
or	SEC_CONTENT
multiple	SEC_CONTENT
NSEs	SEC_CONTENT
can	SEC_CONTENT
access	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
effectively	SEC_CONTENT
supporting	SEC_CONTENT
knowledge	SEC_CONTENT
and	SEC_CONTENT
representation	SEC_CONTENT
sharing	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
flexible	SEC_CONTENT
,	SEC_CONTENT
robust	SEC_CONTENT
and	SEC_CONTENT
suitable	SEC_CONTENT
for	SEC_CONTENT
practical	SEC_CONTENT
NLU	SEC_CONTENT
tasks	SEC_CONTENT
and	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
easily	SEC_CONTENT
by	SEC_CONTENT
any	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
optimizer	SEC_CONTENT
.	SEC_END
We	SEC_START
evaluate	SEC_CONTENT
NSE	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
different	SEC_CONTENT
real	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
four	SEC_CONTENT
of	SEC_CONTENT
them	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
set	SEC_CONTENT
new	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
ofthe	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
results	SEC_CONTENT
suggest	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
NN	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
between	SEC_CONTENT
encoder	SEC_CONTENT
and	SEC_CONTENT
decoder	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
promising	SEC_CONTENT
approach	SEC_CONTENT
for	SEC_CONTENT
sequence	SEC_CONTENT
transduction	SEC_CONTENT
problems	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
and	SEC_CONTENT
abstractive	SEC_CONTENT
summarization	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
neural	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
further	SEC_CONTENT
improved	SEC_CONTENT
by	SEC_CONTENT
sharedmemory	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
analyze	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
pattern	SEC_CONTENT
and	SEC_CONTENT
compositionality	SEC_CONTENT
in	SEC_CONTENT
NSE	SEC_CONTENT
and	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
captures	SEC_CONTENT
semantic	SEC_CONTENT
and	SEC_CONTENT
syntactic	SEC_CONTENT
structures	SEC_CONTENT
of	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_END
Related	SECTITLE_START
Work	SECTITLE_END
One	SEC_START
of	SEC_CONTENT
the	SEC_CONTENT
pioneering	SEC_CONTENT
work	SEC_CONTENT
that	SEC_CONTENT
attempts	SEC_CONTENT
to	SEC_CONTENT
extend	SEC_CONTENT
deep	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
external	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
Neural	SEC_CONTENT
Turing	SEC_CONTENT
Machines	SEC_CONTENT
(	SEC_CONTENT
NTM	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
NTM	SEC_CONTENT
implements	SEC_CONTENT
a	SEC_CONTENT
centralized	SEC_CONTENT
controller	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
sized	SEC_CONTENT
random	SEC_CONTENT
access	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NTM	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
addressable	SEC_CONTENT
by	SEC_CONTENT
both	SEC_CONTENT
content	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
location	SEC_CONTENT
based	SEC_CONTENT
access	SEC_CONTENT
mechanisms	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
authors	SEC_CONTENT
evaluated	SEC_CONTENT
NTM	SEC_CONTENT
on	SEC_CONTENT
algorithmic	SEC_CONTENT
tasks	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
copying	SEC_CONTENT
and	SEC_CONTENT
sorting	SEC_CONTENT
sequences	SEC_CONTENT
.	SEC_END
Comparison	SEC_START
with	SEC_CONTENT
Neural	SEC_CONTENT
Turing	SEC_CONTENT
Machines	SEC_CONTENT
:	SEC_CONTENT
NSE	SEC_CONTENT
addresses	SEC_CONTENT
certain	SEC_CONTENT
drawbacks	SEC_CONTENT
of	SEC_CONTENT
NTM	SEC_CONTENT
.	SEC_CONTENT
NTM	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
centralized	SEC_CONTENT
controller	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
usually	SEC_CONTENT
an	SEC_CONTENT
MLP	SEC_CONTENT
or	SEC_CONTENT
RNN	SEC_CONTENT
while	SEC_CONTENT
NSE	SEC_CONTENT
takes	SEC_CONTENT
a	SEC_CONTENT
modular	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
main	SEC_CONTENT
controller	SEC_CONTENT
in	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
decomposed	SEC_CONTENT
into	SEC_CONTENT
three	SEC_CONTENT
separate	SEC_CONTENT
modules	SEC_CONTENT
,	SEC_CONTENT
each	SEC_CONTENT
of	SEC_CONTENT
which	SEC_CONTENT
performs	SEC_CONTENT
for	SEC_CONTENT
read	SEC_CONTENT
,	SEC_CONTENT
compose	SEC_CONTENT
or	SEC_CONTENT
write	SEC_CONTENT
operation	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
NSE	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
compose	SEC_CONTENT
module	SEC_CONTENT
is	SEC_CONTENT
introduced	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
operations	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
read	SEC_CONTENT
-	SEC_CONTENT
write	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
entries	SEC_CONTENT
and	SEC_CONTENT
input	SEC_CONTENT
information	SEC_CONTENT
.	SEC_END
The	SEC_START
main	SEC_CONTENT
advantage	SEC_CONTENT
of	SEC_CONTENT
NSE	SEC_CONTENT
over	SEC_CONTENT
NTM	SEC_CONTENT
is	SEC_CONTENT
in	SEC_CONTENT
its	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
.	SEC_CONTENT
Despite	SEC_CONTENT
its	SEC_CONTENT
sophisticated	SEC_CONTENT
addressing	SEC_CONTENT
mechanism	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
NTM	SEC_CONTENT
controller	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
have	SEC_CONTENT
mechanism	SEC_CONTENT
to	SEC_CONTENT
avoid	SEC_CONTENT
information	SEC_CONTENT
collision	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
the	SEC_CONTENT
NTM	SEC_CONTENT
controller	SEC_CONTENT
emits	SEC_CONTENT
two	SEC_CONTENT
separate	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
access	SEC_CONTENT
weights	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
read	SEC_CONTENT
weight	SEC_CONTENT
and	SEC_CONTENT
erase	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
weights	SEC_CONTENT
)	SEC_CONTENT
that	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
explicitly	SEC_CONTENT
encode	SEC_CONTENT
the	SEC_CONTENT
knowledge	SEC_CONTENT
about	SEC_CONTENT
where	SEC_CONTENT
information	SEC_CONTENT
is	SEC_CONTENT
read	SEC_CONTENT
from	SEC_CONTENT
and	SEC_CONTENT
written	SEC_CONTENT
to	SEC_CONTENT
.	SEC_CONTENT
Moreover	SEC_CONTENT
the	SEC_CONTENT
fixed	SEC_CONTENT
-	SEC_CONTENT
size	SEC_CONTENT
memory	SEC_CONTENT
in	SEC_CONTENT
NTM	SEC_CONTENT
has	SEC_CONTENT
no	SEC_CONTENT
memory	SEC_CONTENT
allocation	SEC_CONTENT
or	SEC_CONTENT
de	SEC_CONTENT
-	SEC_CONTENT
allocation	SEC_CONTENT
protocol	SEC_CONTENT
.	SEC_CONTENT
Therefore	SEC_CONTENT
unless	SEC_CONTENT
the	SEC_CONTENT
controller	SEC_CONTENT
is	SEC_CONTENT
intelligent	SEC_CONTENT
enough	SEC_CONTENT
to	SEC_CONTENT
track	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
read	SEC_CONTENT
/	SEC_CONTENT
write	SEC_CONTENT
information	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
hard	SEC_CONTENT
for	SEC_CONTENT
an	SEC_CONTENT
RNN	SEC_CONTENT
when	SEC_CONTENT
processing	SEC_CONTENT
long	SEC_CONTENT
sequences	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
content	SEC_CONTENT
is	SEC_CONTENT
overlapped	SEC_CONTENT
and	SEC_CONTENT
information	SEC_CONTENT
is	SEC_CONTENT
overwritten	SEC_CONTENT
throughout	SEC_CONTENT
different	task
time	task
scales	task
.	SEC_CONTENT
We	SEC_CONTENT
think	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
potential	SEC_CONTENT
reason	SEC_CONTENT
that	SEC_CONTENT
makes	SEC_CONTENT
NTM	SEC_CONTENT
hard	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
and	SEC_CONTENT
makes	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
not	SEC_CONTENT
stable	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
effectiveness	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
location	SEC_CONTENT
based	SEC_CONTENT
addressing	SEC_CONTENT
introduced	SEC_CONTENT
in	SEC_CONTENT
NTM	SEC_CONTENT
is	SEC_CONTENT
unclear	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
NSE	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
introduce	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
and	SEC_CONTENT
systematic	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
approach	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
writes	SEC_CONTENT
new	SEC_CONTENT
information	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
recently	SEC_CONTENT
read	SEC_CONTENT
memory	SEC_CONTENT
locations	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
accomplished	SEC_CONTENT
by	SEC_CONTENT
sharing	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
memory	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
read	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
modules	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
is	SEC_CONTENT
scalable	SEC_CONTENT
and	SEC_CONTENT
potentially	SEC_CONTENT
more	SEC_CONTENT
robust	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
provided	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
sized	SEC_CONTENT
memory	SEC_CONTENT
and	SEC_CONTENT
thus	SEC_CONTENT
unlike	SEC_CONTENT
NTM	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
relaxed	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
novel	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
mechanism	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
variable	SEC_CONTENT
sized	SEC_CONTENT
memory	SEC_CONTENT
together	SEC_CONTENT
prevent	SEC_CONTENT
NSE	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
information	SEC_CONTENT
collision	SEC_CONTENT
issue	SEC_CONTENT
and	SEC_CONTENT
avoid	SEC_CONTENT
the	SEC_CONTENT
need	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
allocation	SEC_CONTENT
and	SEC_CONTENT
de	SEC_CONTENT
-	SEC_CONTENT
allocation	SEC_CONTENT
protocols	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
memory	SEC_CONTENT
location	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
stores	SEC_CONTENT
a	SEC_CONTENT
token	SEC_CONTENT
representation	SEC_CONTENT
in	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
during	SEC_CONTENT
encoding	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
provides	SEC_CONTENT
NSE	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
anytime	SEC_CONTENT
-	SEC_CONTENT
access	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
including	SEC_CONTENT
the	SEC_CONTENT
tokens	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
future	SEC_CONTENT
time	SEC_CONTENT
scales	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
permitted	SEC_CONTENT
in	SEC_CONTENT
NTM	SEC_CONTENT
,	SEC_CONTENT
RNN	SEC_CONTENT
and	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
encoders	SEC_CONTENT
.	SEC_END
Lastly	SEC_START
,	SEC_CONTENT
NTM	SEC_CONTENT
addresses	SEC_CONTENT
small	SEC_CONTENT
algorithmic	SEC_CONTENT
problems	SEC_CONTENT
while	SEC_CONTENT
NSE	SEC_CONTENT
focuses	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
large	SEC_CONTENT
-	SEC_CONTENT
scale	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_END
The	SEC_START
RNNSearch	SEC_CONTENT
model	SEC_CONTENT
proposed	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
variation	SEC_CONTENT
of	SEC_CONTENT
memory	SEC_CONTENT
augmented	SEC_CONTENT
networks	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
ability	SEC_CONTENT
to	SEC_CONTENT
read	SEC_CONTENT
the	SEC_CONTENT
historic	SEC_CONTENT
output	SEC_CONTENT
states	SEC_CONTENT
of	SEC_CONTENT
RNNs	SEC_CONTENT
with	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
work	SEC_CONTENT
of	SEC_CONTENT
combines	SEC_CONTENT
the	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
with	SEC_CONTENT
Memory	SEC_CONTENT
Networks	SEC_CONTENT
(	SEC_CONTENT
MemNNs	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Similar	SEC_CONTENT
to	SEC_CONTENT
RNNSearch	SEC_CONTENT
,	SEC_CONTENT
MemNNs	SEC_CONTENT
are	SEC_CONTENT
designed	SEC_CONTENT
with	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
writable	SEC_CONTENT
memories	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
constructs	SEC_CONTENT
layered	SEC_CONTENT
memory	SEC_CONTENT
representa	SEC_CONTENT
-	SEC_CONTENT
tions	SEC_CONTENT
and	SEC_CONTENT
showed	SEC_CONTENT
promising	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
artificial	SEC_CONTENT
and	SEC_CONTENT
real	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
RNNSearch	SEC_CONTENT
and	SEC_CONTENT
MemNNs	SEC_CONTENT
avoid	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
update	SEC_CONTENT
and	SEC_CONTENT
management	SEC_CONTENT
overhead	SEC_CONTENT
by	SEC_CONTENT
simply	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
writable	SEC_CONTENT
memory	SEC_CONTENT
storage	SEC_CONTENT
.	SEC_CONTENT
Another	SEC_CONTENT
variation	SEC_CONTENT
of	SEC_CONTENT
MemNNs	SEC_CONTENT
is	SEC_CONTENT
Dynamic	SEC_CONTENT
Memory	SEC_CONTENT
Network	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
equipped	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
episodic	SEC_CONTENT
memory	SEC_CONTENT
and	SEC_CONTENT
seems	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
flexible	SEC_CONTENT
in	SEC_CONTENT
different	SEC_CONTENT
settings	SEC_CONTENT
.	SEC_END
Although	SEC_START
NSE	SEC_CONTENT
differs	SEC_CONTENT
from	SEC_CONTENT
other	SEC_CONTENT
memoryaugumented	SEC_CONTENT
NN	SEC_CONTENT
models	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
aspects	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
all	SEC_CONTENT
use	SEC_CONTENT
soft	task
attention	task
mechanism	task
with	SEC_CONTENT
a	SEC_CONTENT
type	SEC_CONTENT
of	SEC_CONTENT
similarity	SEC_CONTENT
measures	SEC_CONTENT
to	SEC_CONTENT
retrieve	SEC_CONTENT
relevant	SEC_CONTENT
information	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
external	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
NTM	SEC_CONTENT
implements	SEC_CONTENT
cosine	SEC_CONTENT
similarity	SEC_CONTENT
and	SEC_CONTENT
MemNNs	SEC_CONTENT
use	SEC_CONTENT
vector	SEC_CONTENT
dot	SEC_CONTENT
product	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
vector	SEC_CONTENT
dot	SEC_CONTENT
product	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
similarity	SEC_CONTENT
measure	SEC_CONTENT
in	SEC_CONTENT
NSE	SEC_CONTENT
because	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
faster	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
.	SEC_END
Other	SEC_START
related	SEC_CONTENT
work	SEC_CONTENT
includes	SEC_CONTENT
Neural	SEC_CONTENT
ProgramInterpreters	SEC_CONTENT
(	SEC_CONTENT
Reed	SEC_CONTENT
and	SEC_CONTENT
de	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
learns	SEC_CONTENT
to	SEC_CONTENT
run	SEC_CONTENT
sub	SEC_CONTENT
-	SEC_CONTENT
programs	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
compose	SEC_CONTENT
them	SEC_CONTENT
for	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
programs	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
uses	SEC_CONTENT
execution	SEC_CONTENT
traces	SEC_CONTENT
to	SEC_CONTENT
provide	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
supervision	SEC_CONTENT
.	SEC_CONTENT
Researchers	SEC_CONTENT
have	SEC_CONTENT
also	SEC_CONTENT
explored	SEC_CONTENT
ways	SEC_CONTENT
to	SEC_CONTENT
add	SEC_CONTENT
unbounded	SEC_CONTENT
memory	SEC_CONTENT
to	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
particular	SEC_CONTENT
data	SEC_CONTENT
structure	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
this	SEC_CONTENT
type	SEC_CONTENT
of	SEC_CONTENT
architecture	SEC_CONTENT
provides	SEC_CONTENT
a	SEC_CONTENT
flexible	SEC_CONTENT
capacity	SEC_CONTENT
to	SEC_CONTENT
store	SEC_CONTENT
information	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
is	SEC_CONTENT
constrained	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
structure	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
bank	SEC_CONTENT
,	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
stack	SEC_CONTENT
and	SEC_CONTENT
queue	SEC_CONTENT
.	SEC_END
Overall	SEC_START
it	SEC_CONTENT
is	SEC_CONTENT
expensive	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
scale	SEC_CONTENT
the	SEC_CONTENT
previously	SEC_CONTENT
proposed	SEC_CONTENT
memory	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
models	SEC_CONTENT
required	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
clever	SEC_CONTENT
engineering	SEC_CONTENT
tricks	SEC_CONTENT
to	SEC_CONTENT
work	SEC_CONTENT
successfully	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
aforementioned	SEC_CONTENT
memory	SEC_CONTENT
augmented	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
tested	SEC_CONTENT
on	SEC_CONTENT
synthetic	task
tasks	task
whereas	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
we	SEC_CONTENT
evaluated	SEC_CONTENT
NSE	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
wide	SEC_CONTENT
range	SEC_CONTENT
of	SEC_CONTENT
real	SEC_CONTENT
and	SEC_CONTENT
largescale	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
applications	SEC_CONTENT
.	SEC_END
Proposed	SECTITLE_START
Approach	SECTITLE_END
Our	SEC_START
training	SEC_CONTENT
set	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
N	SEC_CONTENT
examples	SEC_END
,	SEC_START
where	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
X	SEC_CONTENT
i	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_END
of	SEC_START
tokens	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
Y	SEC_CONTENT
i	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
either	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
target	SEC_CONTENT
or	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
transform	SEC_CONTENT
each	SEC_CONTENT
input	SEC_CONTENT
token	SEC_CONTENT
wt	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
.	SEC_END
Our	SEC_START
Neural	SEC_CONTENT
Semantic	SEC_CONTENT
Encoders	SEC_CONTENT
(	SEC_CONTENT
NSE	SEC_CONTENT
)	SEC_CONTENT
model	SEC_CONTENT
has	SEC_CONTENT
four	SEC_CONTENT
main	SEC_CONTENT
components	SEC_CONTENT
:	SEC_CONTENT
read	SEC_CONTENT
,	SEC_CONTENT
compose	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
modules	SEC_CONTENT
and	SEC_CONTENT
an	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
M	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
k×l	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
slots	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
k	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
dimension	SEC_CONTENT
and	SEC_CONTENT
l	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
length	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
vector	SEC_CONTENT
mt	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
k	SEC_CONTENT
corresponds	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
vector	SEC_CONTENT
representation	SEC_CONTENT
of	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
word	SEC_CONTENT
wt	SEC_CONTENT
in	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
initialized	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
vectors	SEC_CONTENT
{	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
}	SEC_CONTENT
l	SEC_CONTENT
t=1	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
evolved	SEC_CONTENT
overtime	SEC_CONTENT
,	SEC_CONTENT
through	SEC_CONTENT
read	SEC_CONTENT
,	SEC_CONTENT
compose	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
operations	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
illustrates	SEC_CONTENT
the	SEC_CONTENT
architecture	SEC_CONTENT
of	SEC_CONTENT
NSE	SEC_CONTENT
.	SEC_END
Read	SECTITLE_START
,	SECTITLE_CONTENT
Compose	SECTITLE_CONTENT
and	SECTITLE_CONTENT
Write	SECTITLE_END
NSE	SEC_START
performs	SEC_CONTENT
three	SEC_CONTENT
main	SEC_CONTENT
operations	SEC_CONTENT
in	SEC_CONTENT
every	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
.	SEC_CONTENT
After	SEC_CONTENT
initializing	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
slots	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
corresponding	SEC_CONTENT
input	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
NSE	SEC_CONTENT
processes	SEC_CONTENT
an	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
and	SEC_CONTENT
retrieves	SEC_CONTENT
a	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
m	SEC_CONTENT
r	SEC_CONTENT
,	SEC_CONTENT
t	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
expected	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
associatively	SEC_CONTENT
coherent	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
semantically	SEC_CONTENT
associated	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
wt	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
slot	SEC_CONTENT
location	SEC_CONTENT
r	SEC_CONTENT
(	SEC_CONTENT
ranging	SEC_CONTENT
from	SEC_CONTENT
1	SEC_CONTENT
to	SEC_CONTENT
l	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
t	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
read	SEC_CONTENT
module	SEC_CONTENT
emits	SEC_CONTENT
by	SEC_CONTENT
attending	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
slots	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
compose	SEC_CONTENT
module	SEC_CONTENT
implements	SEC_CONTENT
a	SEC_CONTENT
composition	SEC_CONTENT
operation	SEC_CONTENT
that	SEC_CONTENT
combines	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
input	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
write	SEC_CONTENT
module	SEC_CONTENT
then	SEC_CONTENT
transforms	SEC_CONTENT
the	SEC_CONTENT
composition	SEC_CONTENT
output	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
space	SEC_CONTENT
and	SEC_CONTENT
writes	SEC_CONTENT
the	SEC_CONTENT
resulting	SEC_CONTENT
new	SEC_CONTENT
representation	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
slot	SEC_CONTENT
location	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
of	SEC_CONTENT
composing	SEC_CONTENT
the	SEC_CONTENT
raw	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
x	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
o	SEC_CONTENT
t	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
read	SEC_CONTENT
module	SEC_CONTENT
at	SEC_CONTENT
time	SEC_CONTENT
t	SEC_CONTENT
Concretely	SEC_CONTENT
,	SEC_CONTENT
let	SEC_CONTENT
e	SEC_CONTENT
l	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
land	SEC_CONTENT
e	SEC_CONTENT
k	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
k	SEC_CONTENT
be	SEC_CONTENT
vectors	SEC_CONTENT
of	SEC_CONTENT
ones	SEC_CONTENT
and	SEC_CONTENT
given	SEC_CONTENT
a	SEC_CONTENT
read	SEC_CONTENT
function	SEC_CONTENT
f	SEC_CONTENT
LST	SEC_CONTENT
Mr	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
composition	SEC_CONTENT
f	SEC_CONTENT
M	SEC_CONTENT
LP	SEC_CONTENT
c	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
write	SEC_CONTENT
f	SEC_CONTENT
LST	SEC_CONTENT
M	SEC_CONTENT
w	SEC_CONTENT
NSE	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
computes	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
t	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
state	SEC_CONTENT
ht	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
Mt	SEC_CONTENT
in	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
t	SEC_CONTENT
as	SEC_END
(	SEC_START
1	SEC_CONTENT
)	SEC_END
where	SEC_START
1	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
of	SEC_CONTENT
ones	SEC_CONTENT
,	SEC_CONTENT
⊗	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
outer	SEC_CONTENT
product	SEC_CONTENT
which	SEC_CONTENT
duplicates	SEC_CONTENT
its	SEC_CONTENT
left	SEC_CONTENT
vector	SEC_CONTENT
l	SEC_CONTENT
or	SEC_CONTENT
k	SEC_CONTENT
times	SEC_CONTENT
to	SEC_CONTENT
form	SEC_CONTENT
a	SEC_CONTENT
matrix	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
read	SEC_CONTENT
function	SEC_CONTENT
f	SEC_CONTENT
LST	SEC_CONTENT
Mr	SEC_CONTENT
sequentially	SEC_CONTENT
maps	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
internal	SEC_CONTENT
space	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
M	SEC_CONTENT
t−1	SEC_CONTENT
.	SEC_CONTENT
Then	SEC_CONTENT
Equation	SEC_CONTENT
2	SEC_CONTENT
looks	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
slots	SEC_CONTENT
related	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
by	SEC_CONTENT
computing	SEC_CONTENT
association	SEC_CONTENT
degree	SEC_CONTENT
between	SEC_CONTENT
each	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
o	SEC_CONTENT
t	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
calculate	SEC_CONTENT
the	SEC_CONTENT
association	SEC_CONTENT
degree	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
dot	SEC_CONTENT
product	SEC_CONTENT
and	SEC_CONTENT
transform	SEC_CONTENT
this	SEC_CONTENT
scores	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
fuzzy	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
t	SEC_CONTENT
by	SEC_CONTENT
normalizing	SEC_CONTENT
with	SEC_CONTENT
sof	SEC_CONTENT
tmax	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
our	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
is	SEC_CONTENT
fuzzy	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
slot	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
composed	SEC_CONTENT
is	SEC_CONTENT
retrieved	SEC_CONTENT
by	SEC_CONTENT
taking	SEC_CONTENT
weighted	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
all	SEC_CONTENT
slots	SEC_CONTENT
as	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
3	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
process	SEC_CONTENT
can	SEC_CONTENT
also	SEC_CONTENT
be	SEC_CONTENT
seen	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
mechanism	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
Equation	SEC_CONTENT
4	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compose	SEC_CONTENT
and	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
retrieved	SEC_CONTENT
slot	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
hidden	SEC_CONTENT
state	SEC_CONTENT
and	SEC_CONTENT
map	SEC_CONTENT
the	SEC_CONTENT
resulting	SEC_CONTENT
vector	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
output	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
write	SEC_CONTENT
the	SEC_CONTENT
new	SEC_CONTENT
representation	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
location	SEC_CONTENT
pointed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
in	SEC_CONTENT
Equation	SEC_CONTENT
6	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
t	SEC_CONTENT
emitted	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
read	SEC_CONTENT
module	SEC_CONTENT
is	SEC_CONTENT
reused	SEC_CONTENT
to	SEC_CONTENT
inform	SEC_CONTENT
the	SEC_CONTENT
write	SEC_CONTENT
module	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
recently	SEC_CONTENT
read	SEC_CONTENT
slots	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
the	SEC_CONTENT
slot	SEC_CONTENT
information	SEC_CONTENT
that	SEC_CONTENT
was	SEC_CONTENT
retrieved	SEC_CONTENT
is	SEC_CONTENT
erased	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
new	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
located	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
performs	SEC_CONTENT
this	SEC_CONTENT
iterative	SEC_CONTENT
process	SEC_CONTENT
until	SEC_CONTENT
all	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
are	SEC_CONTENT
read	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
encoding	SEC_CONTENT
memories	SEC_CONTENT
{	SEC_CONTENT
M	SEC_CONTENT
}	SEC_CONTENT
T	SEC_CONTENT
t=1	SEC_CONTENT
and	SEC_CONTENT
output	SEC_CONTENT
states	SEC_CONTENT
{	SEC_CONTENT
h	SEC_CONTENT
}	SEC_CONTENT
T	SEC_CONTENT
t=1	SEC_CONTENT
are	SEC_CONTENT
further	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
NSE	SEC_CONTENT
reads	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
word	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
an	SEC_CONTENT
anytime	SEC_CONTENT
-	SEC_CONTENT
access	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
sequence	SEC_CONTENT
stored	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
,	SEC_CONTENT
NSE	SEC_CONTENT
maintains	SEC_CONTENT
a	SEC_CONTENT
mental	SEC_CONTENT
image	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
initialized	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
raw	SEC_CONTENT
embedding	SEC_CONTENT
vector	SEC_CONTENT
at	SEC_CONTENT
time	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
0	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
term	SEC_CONTENT
such	SEC_CONTENT
a	SEC_CONTENT
freshly	SEC_CONTENT
initialized	SEC_CONTENT
memory	SEC_CONTENT
a	SEC_CONTENT
baby	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
NSE	SEC_CONTENT
reads	SEC_CONTENT
more	SEC_CONTENT
input	SEC_CONTENT
content	SEC_CONTENT
in	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
baby	SEC_CONTENT
memory	SEC_CONTENT
evolves	SEC_CONTENT
and	SEC_CONTENT
refines	SEC_CONTENT
the	SEC_CONTENT
encoded	SEC_CONTENT
mental	SEC_CONTENT
image	SEC_CONTENT
.	SEC_END
The	SEC_START
read	SEC_CONTENT
f	SEC_CONTENT
LST	SEC_CONTENT
Mr	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
composition	SEC_CONTENT
f	SEC_CONTENT
M	SEC_CONTENT
LP	SEC_CONTENT
c	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
write	SEC_CONTENT
f	SEC_CONTENT
LST	SEC_CONTENT
M	SEC_CONTENT
w	SEC_CONTENT
functions	SEC_CONTENT
are	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
and	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
parameters	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
NSE	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
the	SEC_CONTENT
name	SEC_CONTENT
suggests	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
multi	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
perceptron	SEC_CONTENT
(	SEC_CONTENT
MLP	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
fully	SEC_CONTENT
differentiable	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
any	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
optimizer	SEC_CONTENT
.	SEC_END
Shared	SECTITLE_START
and	SECTITLE_CONTENT
Multiple	SECTITLE_CONTENT
Memory	SECTITLE_CONTENT
Accesses	SECTITLE_END
For	SEC_START
sequence	SEC_CONTENT
to	SEC_CONTENT
sequence	SEC_CONTENT
transduction	SEC_CONTENT
tasks	SEC_CONTENT
like	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
,	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
beneficial	SEC_CONTENT
to	SEC_CONTENT
access	SEC_CONTENT
other	SEC_CONTENT
relevant	SEC_CONTENT
memories	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
one	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
shared	SEC_CONTENT
or	SEC_CONTENT
the	SEC_CONTENT
multiple	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
allows	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
NSEs	SEC_CONTENT
to	SEC_CONTENT
exchange	SEC_CONTENT
knowledge	SEC_CONTENT
representations	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
communicate	SEC_CONTENT
with	SEC_CONTENT
each	SEC_CONTENT
other	SEC_CONTENT
to	SEC_CONTENT
accomplish	SEC_CONTENT
a	SEC_CONTENT
particular	SEC_CONTENT
task	SEC_CONTENT
throughout	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_END
NSE	SEC_START
can	SEC_CONTENT
be	SEC_CONTENT
extended	SEC_CONTENT
easily	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
read	SEC_CONTENT
from	SEC_CONTENT
and	SEC_CONTENT
write	SEC_CONTENT
to	SEC_CONTENT
multiple	SEC_CONTENT
memories	SEC_CONTENT
simultaneously	SEC_CONTENT
or	SEC_CONTENT
multiple	SEC_CONTENT
NSEs	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
access	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
b	SEC_CONTENT
)	SEC_CONTENT
depicts	SEC_CONTENT
a	SEC_CONTENT
highlevel	SEC_CONTENT
architectural	SEC_CONTENT
diagram	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
multiple	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
(	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
memory	SEC_CONTENT
(	SEC_CONTENT
in	SEC_CONTENT
green	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
accessed	SEC_CONTENT
by	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
one	SEC_CONTENT
NSEs	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
Mn	SEC_CONTENT
∈	SEC_CONTENT
R	SEC_CONTENT
k×n	SEC_CONTENT
that	SEC_CONTENT
has	SEC_CONTENT
been	SEC_CONTENT
encoded	SEC_CONTENT
by	SEC_CONTENT
processing	SEC_CONTENT
a	SEC_CONTENT
relevant	SEC_CONTENT
sequence	SEC_CONTENT
with	SEC_CONTENT
length	SEC_CONTENT
n	SEC_CONTENT
,	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
access	SEC_CONTENT
to	SEC_CONTENT
one	SEC_CONTENT
relevant	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
defined	SEC_CONTENT
as	SEC_END
and	SEC_START
this	SEC_CONTENT
is	SEC_CONTENT
almost	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
as	SEC_CONTENT
standard	SEC_CONTENT
NSE	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
read	SEC_CONTENT
module	SEC_CONTENT
now	SEC_CONTENT
emits	SEC_CONTENT
the	SEC_CONTENT
additional	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
z	SEC_CONTENT
n	SEC_CONTENT
t	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
composition	SEC_CONTENT
function	SEC_CONTENT
f	SEC_CONTENT
M	SEC_CONTENT
LP	SEC_CONTENT
c	SEC_CONTENT
combines	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
one	SEC_CONTENT
slots	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
different	SEC_CONTENT
memory	SEC_CONTENT
slots	SEC_CONTENT
are	SEC_CONTENT
retrieved	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
memories	SEC_CONTENT
depending	SEC_CONTENT
on	SEC_CONTENT
their	SEC_CONTENT
encoded	SEC_CONTENT
semantic	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
are	SEC_CONTENT
then	SEC_CONTENT
composed	SEC_CONTENT
together	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
input	SEC_CONTENT
and	SEC_CONTENT
written	SEC_CONTENT
back	SEC_CONTENT
to	SEC_CONTENT
their	SEC_CONTENT
corresponding	SEC_CONTENT
slots	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
capable	SEC_CONTENT
of	SEC_CONTENT
accessing	SEC_CONTENT
a	SEC_CONTENT
variable	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
relevant	SEC_CONTENT
shared	SEC_CONTENT
memories	SEC_CONTENT
once	SEC_CONTENT
a	SEC_CONTENT
composition	SEC_CONTENT
function	SEC_CONTENT
that	SEC_CONTENT
takes	SEC_CONTENT
in	SEC_CONTENT
dynamic	SEC_CONTENT
inputs	SEC_CONTENT
is	SEC_CONTENT
chosen	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
We	SEC_START
describe	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
different	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
NSE	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
effective	SEC_CONTENT
and	SEC_CONTENT
flexible	SEC_CONTENT
in	SEC_CONTENT
different	SEC_CONTENT
settings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
,	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
(	SEC_CONTENT
QA	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
sentence	SEC_CONTENT
classification	SEC_CONTENT
,	SEC_CONTENT
document	SEC_CONTENT
sentiment	SEC_CONTENT
analysis	SEC_CONTENT
and	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
five	SEC_CONTENT
tasks	SEC_CONTENT
challenge	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
and	SEC_CONTENT
semantic	SEC_CONTENT
reasoning	SEC_CONTENT
.	SEC_END
The	SEC_START
models	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
hyperparameters	SEC_CONTENT
selected	SEC_CONTENT
on	SEC_CONTENT
The	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
fixed	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
out	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
vocabulary	SEC_CONTENT
words	SEC_CONTENT
were	SEC_CONTENT
set	SEC_CONTENT
to	SEC_CONTENT
zero	SEC_CONTENT
vector	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
crop	SEC_CONTENT
or	SEC_CONTENT
pad	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
fixed	SEC_CONTENT
length	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
padding	SEC_CONTENT
vector	SEC_CONTENT
was	SEC_CONTENT
inserted	SEC_CONTENT
when	SEC_CONTENT
padding	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
models	SEC_CONTENT
were	SEC_CONTENT
regularized	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
dropouts	SEC_CONTENT
and	SEC_CONTENT
an	SEC_CONTENT
l	SEC_CONTENT
2	SEC_CONTENT
weight	SEC_CONTENT
decay	SEC_CONTENT
.	SEC_CONTENT
5	SEC_END
Natural	SECTITLE_START
Language	SECTITLE_CONTENT
Inference	SECTITLE_END
The	SEC_START
natural	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
is	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
tasks	SEC_CONTENT
in	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
task	SEC_CONTENT
tests	SEC_CONTENT
the	SEC_CONTENT
ability	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
reason	SEC_CONTENT
about	SEC_CONTENT
the	SEC_CONTENT
semantic	SEC_CONTENT
relationship	SEC_CONTENT
between	SEC_CONTENT
two	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
well	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
NSE	SEC_CONTENT
should	SEC_CONTENT
be	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
sentence	task
semantics	task
and	SEC_CONTENT
be	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
reason	SEC_CONTENT
the	SEC_CONTENT
relation	SEC_CONTENT
between	SEC_CONTENT
a	task
sentence	task
pair	task
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
whether	SEC_CONTENT
a	SEC_CONTENT
premise	SEC_CONTENT
-	SEC_CONTENT
hypothesis	SEC_CONTENT
pair	SEC_CONTENT
is	SEC_CONTENT
entailing	SEC_CONTENT
,	SEC_CONTENT
contradictory	SEC_CONTENT
or	SEC_CONTENT
neutral	SEC_CONTENT
.	SEC_CONTENT
ReLU	SEC_CONTENT
activation	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
sof	SEC_CONTENT
tmax	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
128	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
to	SEC_CONTENT
3e-4	SEC_CONTENT
and	SEC_CONTENT
l	SEC_CONTENT
2	SEC_CONTENT
regularizer	SEC_CONTENT
strength	SEC_CONTENT
to	SEC_CONTENT
3e-5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
each	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
40	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
write	SEC_CONTENT
/	SEC_CONTENT
read	SEC_CONTENT
neural	SEC_CONTENT
nets	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
linear	SEC_CONTENT
layer	SEC_CONTENT
were	SEC_CONTENT
regularized	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
30	SEC_CONTENT
%	SEC_CONTENT
dropouts	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
evaluated	SEC_CONTENT
three	SEC_CONTENT
different	SEC_CONTENT
variations	SEC_CONTENT
of	SEC_CONTENT
NSE	SEC_CONTENT
show	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NSE	SEC_CONTENT
model	SEC_CONTENT
encodes	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
simultaneously	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
separate	SEC_CONTENT
memory	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
model	SEC_CONTENT
-MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
first	SEC_CONTENT
encodes	SEC_CONTENT
the	SEC_CONTENT
premise	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
sentence	SEC_CONTENT
by	SEC_CONTENT
sharing	SEC_CONTENT
the	SEC_CONTENT
premise	SEC_CONTENT
encoded	SEC_CONTENT
memory	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
third	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
inter	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
attention	SEC_CONTENT
which	SEC_CONTENT
selectively	SEC_CONTENT
reconstructs	SEC_CONTENT
the	SEC_CONTENT
premise	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
along	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
published	SEC_CONTENT
methods	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
classifier	SEC_CONTENT
with	SEC_CONTENT
handcrafted	SEC_CONTENT
features	SEC_CONTENT
extracts	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
lexical	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
next	SEC_CONTENT
group	SEC_CONTENT
of	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
sentence	task
encoding	task
.	SEC_CONTENT
While	SEC_CONTENT
most	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
encoder	SEC_CONTENT
models	SEC_CONTENT
rely	SEC_CONTENT
solely	SEC_CONTENT
on	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
dependency	SEC_CONTENT
tree	SEC_CONTENT
CNN	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
SPINN	SEC_CONTENT
-	SEC_CONTENT
PI	SEC_CONTENT
models	SEC_CONTENT
make	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
parser	SEC_CONTENT
output	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
SPINN	SEC_CONTENT
-	SEC_CONTENT
PI	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
NSE	SEC_CONTENT
in	SEC_CONTENT
spirit	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
also	SEC_CONTENT
explicitly	SEC_CONTENT
computes	SEC_CONTENT
word	SEC_CONTENT
composition	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
composition	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
SPINN	SEC_CONTENT
-	SEC_CONTENT
PI	SEC_CONTENT
is	SEC_CONTENT
guided	SEC_CONTENT
by	SEC_CONTENT
supervisions	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
dependency	SEC_CONTENT
parser	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
sentence	SEC_CONTENT
encoders	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
SNE	SEC_CONTENT
further	SEC_CONTENT
slightly	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
result	SEC_CONTENT
,	SEC_CONTENT
indicating	SEC_CONTENT
that	SEC_CONTENT
reading	SEC_CONTENT
the	SEC_CONTENT
premise	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
helpful	SEC_CONTENT
while	SEC_CONTENT
encoding	SEC_CONTENT
the	SEC_CONTENT
hypothesis	SEC_CONTENT
.	SEC_END
The	SEC_START
last	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
methods	SEC_CONTENT
designs	SEC_CONTENT
inter	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
relation	SEC_CONTENT
with	SEC_CONTENT
parameterized	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
(	SEC_CONTENT
Bahdanau	SEC_CONTENT
et	SEC_CONTENT
al	SEC_CONTENT
.	SEC_CONTENT
,	SEC_CONTENT
2015	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
attention	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
attention	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Particularly	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
attends	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
premise	SEC_CONTENT
encoder	SEC_CONTENT
outputs	SEC_CONTENT
{	SEC_CONTENT
h	SEC_CONTENT
p	SEC_CONTENT
}	SEC_CONTENT
T	SEC_CONTENT
t=1	SEC_CONTENT
in	SEC_CONTENT
respect	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hypothesis	SEC_CONTENT
representation	SEC_CONTENT
h	SEC_CONTENT
h	SEC_CONTENT
land	SEC_CONTENT
constructs	SEC_CONTENT
an	SEC_CONTENT
attentively	SEC_CONTENT
blended	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
premise	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
model	SEC_CONTENT
obtained	SEC_CONTENT
85.4	metric
%	metric
accuracy	metric
score	metric
.	SEC_CONTENT
The	SEC_CONTENT
best	SEC_CONTENT
performing	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
performs	SEC_CONTENT
tree	SEC_CONTENT
matching	SEC_CONTENT
with	SEC_CONTENT
attention	task
mechanism	task
and	SEC_CONTENT
LSTM	SEC_CONTENT
.	SEC_END
Answer	SECTITLE_START
Sentence	SECTITLE_CONTENT
Selection	SECTITLE_END
Answer	SEC_START
sentence	SEC_CONTENT
selection	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
integral	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
open	SEC_CONTENT
-	SEC_CONTENT
domain	SEC_CONTENT
question	SEC_CONTENT
answering	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
the	SEC_CONTENT
correct	SEC_CONTENT
sentences	SEC_CONTENT
that	SEC_CONTENT
answer	SEC_CONTENT
a	SEC_CONTENT
factual	SEC_CONTENT
question	SEC_CONTENT
,	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
candidate	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
experiment	SEC_CONTENT
on	SEC_CONTENT
WikiQA	SEC_CONTENT
dataset	SEC_CONTENT
constructed	SEC_CONTENT
from	SEC_CONTENT
Wikipedia	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
dataset	SEC_CONTENT
contains	SEC_CONTENT
20,360/2,733/6,165	SEC_CONTENT
QA	SEC_CONTENT
pairs	SEC_CONTENT
for	SEC_CONTENT
train	SEC_CONTENT
/	SEC_CONTENT
dev	SEC_CONTENT
/	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_END
The	SEC_START
MLP	SEC_CONTENT
setup	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
language	SEC_CONTENT
inference	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
kept	SEC_CONTENT
same	SEC_CONTENT
,	SEC_CONTENT
except	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
now	SEC_CONTENT
replace	SEC_CONTENT
the	SEC_CONTENT
sof	SEC_CONTENT
tmax	SEC_CONTENT
layer	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
sigmoid	SEC_CONTENT
layer	SEC_CONTENT
and	SEC_CONTENT
model	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
conditional	SEC_CONTENT
probability	SEC_CONTENT
distribution	SEC_CONTENT
.	SEC_END
where	SEC_START
h	SEC_CONTENT
q	SEC_CONTENT
land	SEC_CONTENT
ha	SEC_CONTENT
l	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
question	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
answer	SEC_CONTENT
encoded	SEC_CONTENT
vectors	SEC_CONTENT
and	SEC_CONTENT
o	SEC_CONTENT
QA	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
MLP	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
the	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
attention	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
minimize	SEC_CONTENT
the	SEC_CONTENT
sigmoid	SEC_CONTENT
cross	SEC_CONTENT
entropy	SEC_CONTENT
loss	SEC_CONTENT
.	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
first	SEC_CONTENT
encodes	SEC_CONTENT
the	SEC_CONTENT
answers	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
the	SEC_CONTENT
questions	SEC_CONTENT
by	SEC_CONTENT
accessing	SEC_CONTENT
its	SEC_CONTENT
own	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
answer	SEC_CONTENT
encoding	SEC_CONTENT
memories	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
our	SEC_CONTENT
preliminary	SEC_CONTENT
experiment	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
multiple	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
over	SEC_CONTENT
answer	SEC_CONTENT
encoder	SEC_CONTENT
outputs	SEC_CONTENT
{	SEC_CONTENT
h	SEC_CONTENT
a	SEC_CONTENT
}	SEC_CONTENT
T	SEC_CONTENT
t=1	SEC_CONTENT
are	SEC_CONTENT
crucial	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
previous	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
MAP	SEC_CONTENT
and	SEC_CONTENT
MRR	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
evaluation	SEC_CONTENT
metrics	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
4	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
to	SEC_CONTENT
1e-5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
10	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
40	SEC_CONTENT
%	SEC_CONTENT
dropouts	SEC_CONTENT
afterword	SEC_CONTENT
embeddings	SEC_CONTENT
and	SEC_CONTENT
no	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
trec	SEC_CONTENT
eval	SEC_CONTENT
script	SEC_CONTENT
to	SEC_CONTENT
calculate	SEC_CONTENT
the	SEC_CONTENT
evaluation	SEC_CONTENT
metrics	SEC_CONTENT
 	SEC_CONTENT
l	SEC_CONTENT
2	SEC_CONTENT
weight	SEC_CONTENT
decay	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
pretrained	SEC_CONTENT
300-D	SEC_CONTENT
Glove	SEC_CONTENT
840B	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
linear	SEC_CONTENT
mapping	SEC_CONTENT
layer	SEC_CONTENT
transforms	SEC_CONTENT
the	SEC_CONTENT
300-D	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
512-D	SEC_CONTENT
LSTM	SEC_CONTENT
inputs	SEC_CONTENT
.	SEC_CONTENT
presents	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
classifier	SEC_CONTENT
with	SEC_CONTENT
handcrafted	SEC_CONTENT
features	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
SVM	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
Bigram	SEC_CONTENT
-	SEC_CONTENT
CNN	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
convolutional	SEC_CONTENT
neural	SEC_CONTENT
net	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
LSTM	SEC_CONTENT
attention	SEC_CONTENT
models	SEC_CONTENT
outperform	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
best	SEC_CONTENT
result	SEC_CONTENT
by	SEC_CONTENT
nearly	SEC_CONTENT
5	SEC_CONTENT
-	SEC_CONTENT
6	SEC_CONTENT
%	SEC_CONTENT
by	SEC_CONTENT
implementing	SEC_CONTENT
deep	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
three	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
NASM	SEC_CONTENT
improves	SEC_CONTENT
it	SEC_CONTENT
further	SEC_CONTENT
and	SEC_CONTENT
sets	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
baseline	SEC_CONTENT
by	SEC_CONTENT
combining	SEC_CONTENT
variational	SEC_CONTENT
auto	SEC_CONTENT
-	SEC_CONTENT
encoder	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
MMA	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
attention	SEC_CONTENT
model	SEC_CONTENT
exceeds	SEC_CONTENT
the	SEC_CONTENT
NASM	SEC_CONTENT
by	SEC_CONTENT
approximately	SEC_CONTENT
1	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
MAP	SEC_CONTENT
and	SEC_CONTENT
0.8	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
MRR	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
Sentence	SECTITLE_START
Classification	SECTITLE_END
We	SEC_START
evaluated	SEC_CONTENT
NSE	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Stanford	SEC_CONTENT
Sentiment	SEC_CONTENT
Treebank	SEC_CONTENT
(	dataset
SST	dataset
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
dataset	SEC_CONTENT
comes	SEC_CONTENT
with	SEC_CONTENT
standard	SEC_CONTENT
train	SEC_CONTENT
/	SEC_CONTENT
dev	SEC_CONTENT
/	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
and	SEC_CONTENT
two	SEC_CONTENT
subtasks	SEC_CONTENT
:	SEC_CONTENT
binary	SEC_CONTENT
sentence	SEC_CONTENT
classification	SEC_CONTENT
or	SEC_CONTENT
finegrained	SEC_CONTENT
classification	SEC_CONTENT
of	SEC_CONTENT
five	SEC_CONTENT
classes	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
trained	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
text	SEC_CONTENT
spans	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
labeled	SEC_CONTENT
phrases	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
evaluated	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_END
The	SEC_START
sentence	SEC_CONTENT
representations	SEC_CONTENT
were	SEC_CONTENT
passed	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
MLP	SEC_CONTENT
for	SEC_CONTENT
classification	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
MLP	SEC_CONTENT
has	SEC_CONTENT
ReLU	SEC_CONTENT
activation	SEC_CONTENT
and	SEC_CONTENT
1024	SEC_CONTENT
or	SEC_CONTENT
300	SEC_CONTENT
units	SEC_CONTENT
for	SEC_CONTENT
binary	SEC_CONTENT
or	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
grained	SEC_CONTENT
setting	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sof	SEC_CONTENT
tmax	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
read	SEC_CONTENT
/	SEC_CONTENT
write	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
two	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
300	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
300-D	SEC_CONTENT
Glove	SEC_CONTENT
840B	SEC_CONTENT
vectors	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
64	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
to	SEC_CONTENT
3e-4	SEC_CONTENT
and	SEC_CONTENT
l	SEC_CONTENT
2	SEC_CONTENT
regularizer	SEC_CONTENT
strength	SEC_CONTENT
to	SEC_CONTENT
3e-5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
each	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
25	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
write	SEC_CONTENT
/	SEC_CONTENT
read	SEC_CONTENT
neural	SEC_CONTENT
nets	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
linear	SEC_CONTENT
layer	SEC_CONTENT
were	SEC_CONTENT
regularized	SEC_CONTENT
by	SEC_CONTENT
50	SEC_CONTENT
%	SEC_CONTENT
dropouts	SEC_CONTENT
.	SEC_CONTENT
compares	SEC_CONTENT
the	SEC_CONTENT
result	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
methods	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
subtasks	SEC_CONTENT
.	SEC_CONTENT
Most	SEC_CONTENT
best	SEC_CONTENT
performing	SEC_CONTENT
methods	SEC_CONTENT
exploited	SEC_CONTENT
the	SEC_CONTENT
parse	SEC_CONTENT
tree	SEC_CONTENT
provided	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
treebank	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
exception	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
DMN	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
Dynamic	SEC_CONTENT
Memory	SEC_CONTENT
Network	SEC_CONTENT
(	SEC_CONTENT
DMN	SEC_CONTENT
)	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
memory	SEC_CONTENT
-	SEC_CONTENT
augmented	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
DMN	SEC_CONTENT
and	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
subtasks	SEC_CONTENT
.	SEC_END
Model	SECTITLE_END
Bin	SEC_START
FG	SEC_CONTENT
RNTN	SEC_CONTENT
(	SEC_CONTENT
85.4	SEC_CONTENT
45.7	SEC_CONTENT
Paragraph	SEC_CONTENT
Vector	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
87.8	SEC_CONTENT
48.7	SEC_CONTENT
CNN	SEC_CONTENT
-	SEC_CONTENT
MC	SEC_CONTENT
88.1	SEC_CONTENT
47.4	SEC_CONTENT
DRNN	SEC_CONTENT
(	SEC_CONTENT
86.6	SEC_CONTENT
49.8	SEC_CONTENT
2-layer	SEC_CONTENT
LSTM	SEC_CONTENT
86.3	SEC_CONTENT
46.0	SEC_CONTENT
Bi	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
87.5	SEC_CONTENT
49.1	SEC_CONTENT
CT	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
(	SEC_CONTENT
88.0	SEC_CONTENT
51.0	SEC_CONTENT
DMN	SEC_CONTENT
(	SEC_CONTENT
88.6	SEC_CONTENT
52.1	SEC_CONTENT
NSE	SEC_CONTENT
89.7	SEC_CONTENT
52.8	SEC_CONTENT
:	SEC_CONTENT
Test	metric
accuracy	metric
for	SEC_CONTENT
sentence	SEC_CONTENT
classification	SEC_CONTENT
.	SEC_CONTENT
Bin	SEC_CONTENT
:	SEC_CONTENT
Binary	SEC_CONTENT
,	SEC_CONTENT
FG	SEC_CONTENT
:	SEC_CONTENT
fine	SEC_CONTENT
-	SEC_CONTENT
grained	SEC_CONTENT
5	SEC_CONTENT
classes	SEC_CONTENT
.	SEC_END
Document	SECTITLE_START
Sentiment	SECTITLE_CONTENT
Analysis	SECTITLE_END
We	SEC_START
evaluated	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
for	SEC_CONTENT
document	task
-	task
level	task
sentiment	task
analysis	task
on	SEC_CONTENT
two	SEC_CONTENT
publically	SEC_CONTENT
available	SEC_CONTENT
largescale	SEC_CONTENT
datasets	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
IMDB	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
335,018	SEC_CONTENT
movie	SEC_CONTENT
reviews	SEC_CONTENT
and	SEC_CONTENT
10	SEC_CONTENT
different	SEC_CONTENT
classes	SEC_CONTENT
and	SEC_CONTENT
Yelp	SEC_CONTENT
13	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
348,415	SEC_CONTENT
restaurant	SEC_CONTENT
reviews	SEC_CONTENT
and	SEC_CONTENT
5	SEC_CONTENT
different	SEC_CONTENT
classes	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
document	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
datasets	SEC_CONTENT
is	SEC_CONTENT
associated	SEC_CONTENT
with	SEC_CONTENT
human	SEC_CONTENT
ratings	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
these	SEC_CONTENT
ratings	SEC_CONTENT
as	SEC_CONTENT
gold	SEC_CONTENT
labels	SEC_CONTENT
for	SEC_CONTENT
sentiment	task
classification	task
.	SEC_CONTENT
Particularly	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
split	SEC_CONTENT
datasets	SEC_CONTENT
of	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
stack	SEC_CONTENT
a	SEC_CONTENT
NSE	SEC_CONTENT
or	SEC_CONTENT
LSTM	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
of	SEC_CONTENT
another	SEC_CONTENT
NSE	SEC_CONTENT
for	SEC_CONTENT
document	SEC_CONTENT
modeling	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
NSE	SEC_CONTENT
encodes	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
second	SEC_CONTENT
NSE	SEC_CONTENT
or	SEC_CONTENT
LSTM	SEC_CONTENT
takes	SEC_CONTENT
sentence	SEC_CONTENT
encoded	SEC_CONTENT
outputs	SEC_CONTENT
and	SEC_CONTENT
constructs	SEC_CONTENT
document	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
document	SEC_CONTENT
representation	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
output	SEC_CONTENT
sof	SEC_CONTENT
tmax	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
whole	SEC_CONTENT
network	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
jointly	SEC_CONTENT
by	SEC_CONTENT
backpropagating	SEC_CONTENT
the	SEC_CONTENT
cross	SEC_CONTENT
entropy	SEC_CONTENT
loss	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
100	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
read	SEC_CONTENT
/	SEC_CONTENT
write	SEC_CONTENT
modules	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
100-D	SEC_CONTENT
Glove	SEC_CONTENT
6B	SEC_CONTENT
vectors	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
32	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
to	SEC_CONTENT
3e-4	SEC_CONTENT
and	SEC_CONTENT
l	SEC_CONTENT
2	SEC_CONTENT
regularizer	SEC_CONTENT
strength	SEC_CONTENT
to	SEC_CONTENT
1e-5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
trained	SEC_CONTENT
each	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
50	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
write	SEC_CONTENT
/	SEC_CONTENT
read	SEC_CONTENT
neural	SEC_CONTENT
nets	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
NSE	SEC_CONTENT
/	SEC_CONTENT
LSTM	SEC_CONTENT
were	SEC_CONTENT
regularized	SEC_CONTENT
by	SEC_CONTENT
15	SEC_CONTENT
%	SEC_CONTENT
dropouts	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
by	SEC_CONTENT
20	SEC_CONTENT
%	SEC_CONTENT
dropouts	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
speedup	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
created	SEC_CONTENT
document	SEC_CONTENT
buckets	SEC_CONTENT
by	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
sentences	task
per	SEC_CONTENT
document	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
documents	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
sentences	task
were	SEC_CONTENT
put	SEC_CONTENT
together	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
bucket	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
buckets	SEC_CONTENT
were	SEC_CONTENT
shuffled	SEC_CONTENT
and	SEC_CONTENT
updated	SEC_CONTENT
per	SEC_CONTENT
epoch	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
use	SEC_CONTENT
curriculum	SEC_CONTENT
scheduling	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
observed	SEC_CONTENT
to	SEC_CONTENT
help	SEC_CONTENT
sequence	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
our	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
two	SEC_CONTENT
performance	SEC_CONTENT
metrics	SEC_CONTENT
:	SEC_CONTENT
accuracy	metric
and	SEC_CONTENT
MSE	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
best	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
were	SEC_CONTENT
previously	SEC_CONTENT
obtained	SEC_CONTENT
by	SEC_CONTENT
Conv	SEC_CONTENT
-	SEC_CONTENT
GRNN	SEC_CONTENT
and	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
GRNN	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
are	SEC_CONTENT
also	SEC_CONTENT
:	SEC_CONTENT
BLEU	SEC_CONTENT
scores	SEC_CONTENT
for	SEC_CONTENT
English	SEC_CONTENT
-	SEC_CONTENT
German	SEC_CONTENT
translation	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
stacked	SEC_START
models	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
models	SEC_CONTENT
first	SEC_CONTENT
learn	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
representations	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
CNN	SEC_CONTENT
or	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
combine	SEC_CONTENT
them	SEC_CONTENT
for	SEC_CONTENT
document	SEC_CONTENT
representation	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
gated	SEC_CONTENT
recurrent	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
GRNN	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
NSE	SEC_CONTENT
models	SEC_CONTENT
outperformed	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
stateof	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
models	SEC_CONTENT
in	SEC_CONTENT
terms	SEC_CONTENT
of	SEC_CONTENT
both	metric
accuracy	metric
and	SEC_CONTENT
MSE	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
approximately	SEC_CONTENT
2	SEC_CONTENT
-	SEC_CONTENT
3	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
hand	SEC_CONTENT
,	SEC_CONTENT
all	SEC_CONTENT
systems	SEC_CONTENT
tend	SEC_CONTENT
to	SEC_CONTENT
show	SEC_CONTENT
poor	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
IMDB	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
That	SEC_CONTENT
is	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
IMDB	SEC_CONTENT
dataset	SEC_CONTENT
contains	SEC_CONTENT
longer	SEC_CONTENT
documents	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
Yelp	SEC_CONTENT
13	SEC_CONTENT
and	SEC_CONTENT
it	SEC_CONTENT
has	SEC_CONTENT
10	SEC_CONTENT
classes	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
Yelp	SEC_CONTENT
13	SEC_CONTENT
dataset	SEC_CONTENT
has	SEC_CONTENT
five	SEC_CONTENT
classes	SEC_CONTENT
to	SEC_CONTENT
distinguish	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
stacked	SEC_CONTENT
NSEs	SEC_CONTENT
(	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
)	SEC_CONTENT
performed	SEC_CONTENT
slightly	SEC_CONTENT
better	SEC_CONTENT
than	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
IMDB	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
possibly	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
document	SEC_CONTENT
level	SEC_CONTENT
NSE	SEC_CONTENT
that	SEC_CONTENT
preserves	SEC_CONTENT
the	SEC_CONTENT
long	SEC_CONTENT
dependency	SEC_CONTENT
in	SEC_CONTENT
documents	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
sentences	task
.	SEC_END
Machine	SECTITLE_START
Translation	SECTITLE_END
Lastly	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
conducted	SEC_CONTENT
an	SEC_CONTENT
experiment	SEC_CONTENT
on	SEC_CONTENT
neural	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
(	SEC_CONTENT
NMT	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NMT	SEC_CONTENT
problem	SEC_CONTENT
is	SEC_CONTENT
mostly	SEC_CONTENT
defined	SEC_CONTENT
within	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
framework	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
encoder	SEC_CONTENT
provides	SEC_CONTENT
the	SEC_CONTENT
semantic	SEC_CONTENT
and	SEC_CONTENT
syntactic	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentences	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
generates	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
sentences	SEC_CONTENT
by	SEC_CONTENT
conditioning	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
information	SEC_CONTENT
and	SEC_CONTENT
its	SEC_CONTENT
partially	SEC_CONTENT
produced	SEC_CONTENT
translation	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
an	SEC_CONTENT
efficient	SEC_CONTENT
encoding	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
NTM	SEC_CONTENT
was	SEC_CONTENT
introduced	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
For	SEC_START
NTM	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
implemented	SEC_CONTENT
three	SEC_CONTENT
different	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
first	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
baseline	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
one	SEC_CONTENT
proposed	SEC_CONTENT
in	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
has	SEC_CONTENT
two	SEC_CONTENT
LSTM	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
/	SEC_CONTENT
decoder	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
the	SEC_CONTENT
soft	SEC_CONTENT
attention	SEC_CONTENT
neural	SEC_CONTENT
net	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
attends	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
constructs	SEC_CONTENT
a	SEC_CONTENT
focused	SEC_CONTENT
encoding	SEC_CONTENT
vector	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
target	SEC_CONTENT
word	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
second	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
which	SEC_CONTENT
encodes	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
with	SEC_CONTENT
NSE	SEC_CONTENT
and	SEC_CONTENT
generates	SEC_CONTENT
the	SEC_CONTENT
targets	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
network	SEC_CONTENT
by	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
output	SEC_CONTENT
states	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
last	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
setup	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
part	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
NSE	SEC_CONTENT
now	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
state	SEC_CONTENT
and	SEC_CONTENT
has	SEC_CONTENT
an	SEC_CONTENT
access	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
memory	SEC_CONTENT
,	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
NSEs	SEC_CONTENT
access	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
encoded	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
NSEs	SEC_CONTENT
and	SEC_CONTENT
then	SEC_CONTENT
read	SEC_CONTENT
/	SEC_CONTENT
written	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
decoder	SEC_CONTENT
NSEs	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
English	SEC_CONTENT
-	SEC_CONTENT
German	SEC_CONTENT
translation	SEC_CONTENT
corpus	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
IWSLT	SEC_CONTENT
2014	SEC_CONTENT
evaluation	SEC_CONTENT
campaign	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
corpus	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
-	SEC_CONTENT
aligned	SEC_CONTENT
translation	SEC_CONTENT
of	SEC_CONTENT
TED	SEC_CONTENT
talks	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
data	SEC_CONTENT
was	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
processed	SEC_CONTENT
and	SEC_CONTENT
lowercased	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
Moses	SEC_CONTENT
toolkit	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
merged	SEC_CONTENT
the	SEC_CONTENT
dev2010	SEC_CONTENT
and	SEC_CONTENT
dev2012	SEC_CONTENT
sets	SEC_CONTENT
for	SEC_CONTENT
development	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
tst2010	SEC_CONTENT
,	SEC_CONTENT
tst2011	SEC_CONTENT
and	SEC_CONTENT
tst2012	SEC_CONTENT
sets	SEC_CONTENT
for	SEC_CONTENT
test	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Sentence	task
pairs	task
with	SEC_CONTENT
length	SEC_CONTENT
longer	SEC_CONTENT
than	SEC_CONTENT
25	SEC_CONTENT
words	SEC_CONTENT
were	SEC_CONTENT
filtered	SEC_CONTENT
out	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
resulted	SEC_CONTENT
in	SEC_CONTENT
110,439/4,998/4,793	SEC_CONTENT
pairs	SEC_CONTENT
for	SEC_CONTENT
train	SEC_CONTENT
/	SEC_CONTENT
dev	SEC_CONTENT
/	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
kept	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
frequent	SEC_CONTENT
25,000	SEC_CONTENT
words	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
German	SEC_CONTENT
dictionary	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
English	SEC_CONTENT
dictionary	SEC_CONTENT
has	SEC_CONTENT
51,821	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
300-D	SEC_CONTENT
Glove	SEC_CONTENT
840B	SEC_CONTENT
vectors	SEC_CONTENT
were	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
embedding	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
source	SEC_CONTENT
sentence	SEC_CONTENT
whereas	SEC_CONTENT
a	SEC_CONTENT
lookup	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
was	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
German	SEC_CONTENT
words	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
usually	SEC_CONTENT
optimized	SEC_CONTENT
along	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
NMT	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
evaluation	SEC_CONTENT
purpose	SEC_CONTENT
we	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
experiment	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
optimize	SEC_CONTENT
the	SEC_CONTENT
English	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
Besides	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
use	SEC_CONTENT
abeam	SEC_CONTENT
search	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_END
The	SEC_START
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
/	SEC_CONTENT
decoders	SEC_CONTENT
have	SEC_CONTENT
two	SEC_CONTENT
layers	SEC_CONTENT
with	SEC_CONTENT
300	SEC_CONTENT
units	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NSE	SEC_CONTENT
read	SEC_CONTENT
/	SEC_CONTENT
write	SEC_CONTENT
modules	SEC_CONTENT
are	SEC_CONTENT
two	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
units	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
/	SEC_CONTENT
decoders	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
ensures	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
parameters	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
is	SEC_CONTENT
roughly	SEC_CONTENT
the	SEC_CONTENT
equal	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
models	SEC_CONTENT
were	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
minimize	SEC_CONTENT
word	SEC_CONTENT
-	SEC_CONTENT
level	SEC_CONTENT
cross	SEC_CONTENT
entropy	SEC_CONTENT
loss	SEC_CONTENT
and	SEC_CONTENT
were	SEC_CONTENT
regularized	SEC_CONTENT
by	SEC_CONTENT
20	SEC_CONTENT
%	SEC_CONTENT
input	SEC_CONTENT
dropouts	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
9	SEC_CONTENT
https://github.com/moses-smt/mosesdecoder	SEC_CONTENT
We	SEC_CONTENT
modified	SEC_CONTENT
prepareData.sh	SEC_CONTENT
script	SEC_CONTENT
:	SEC_CONTENT
https://github.com/facebookresearch/MIXER	SEC_CONTENT
30	SEC_CONTENT
%	SEC_CONTENT
output	SEC_CONTENT
dropouts	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
set	SEC_CONTENT
the	SEC_CONTENT
batch	SEC_CONTENT
size	SEC_CONTENT
to	SEC_CONTENT
128	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
to	SEC_CONTENT
1e-3	SEC_CONTENT
for	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
and	SEC_CONTENT
3e-4	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
models	SEC_CONTENT
and	SEC_CONTENT
l	SEC_CONTENT
2	SEC_CONTENT
regularizer	SEC_CONTENT
strength	SEC_CONTENT
to	SEC_CONTENT
3e-5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
train	SEC_CONTENT
each	SEC_CONTENT
model	SEC_CONTENT
for	SEC_CONTENT
40	SEC_CONTENT
epochs	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
BLEU	SEC_CONTENT
score	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
11	SEC_CONTENT
reports	SEC_CONTENT
our	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
baseline	SEC_CONTENT
LSTM	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
(	SEC_CONTENT
with	SEC_CONTENT
attention	SEC_CONTENT
)	SEC_CONTENT
obtained	SEC_CONTENT
17.02	SEC_CONTENT
BLEU	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
improved	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
slightly	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
this	SEC_CONTENT
very	SEC_CONTENT
small	SEC_CONTENT
improvement	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
unclear	SEC_CONTENT
whether	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
encoder	SEC_CONTENT
is	SEC_CONTENT
helpful	SEC_CONTENT
in	SEC_CONTENT
NMT	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
replace	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
decoder	SEC_CONTENT
with	SEC_CONTENT
another	SEC_CONTENT
NSE	SEC_CONTENT
and	SEC_CONTENT
introduce	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
result	SEC_CONTENT
by	SEC_CONTENT
almost	SEC_CONTENT
1.0	SEC_CONTENT
BLEU	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
NSE	SEC_CONTENT
-	SEC_CONTENT
NSE	SEC_CONTENT
model	SEC_CONTENT
also	SEC_CONTENT
yields	SEC_CONTENT
an	SEC_CONTENT
increasing	SEC_CONTENT
BLEU	SEC_CONTENT
score	SEC_CONTENT
on	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
result	SEC_CONTENT
demonstrates	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
attention	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
NMT	SEC_CONTENT
systems	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
improved	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
shared	SEC_CONTENT
-	SEC_CONTENT
memory	SEC_CONTENT
encoder	SEC_CONTENT
-	SEC_CONTENT
decoder	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
memory	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
NMT	SEC_CONTENT
systems	SEC_CONTENT
should	SEC_CONTENT
perform	SEC_CONTENT
well	SEC_CONTENT
on	SEC_CONTENT
translation	SEC_CONTENT
of	SEC_CONTENT
long	SEC_CONTENT
sequences	SEC_CONTENT
by	SEC_CONTENT
preserving	SEC_CONTENT
long	SEC_CONTENT
term	SEC_CONTENT
dependencies	SEC_CONTENT
.	SEC_END
Qualitative	SECTITLE_START
Analysis	SECTITLE_END
Memory	SECTITLE_START
Access	SECTITLE_CONTENT
and	SECTITLE_CONTENT
Compositionality	SECTITLE_END
NSE	SEC_START
is	SEC_CONTENT
capabable	SEC_CONTENT
of	SEC_CONTENT
performing	SEC_CONTENT
multiscale	SEC_CONTENT
composition	SEC_CONTENT
by	SEC_CONTENT
retrieving	SEC_CONTENT
associative	SEC_CONTENT
slots	SEC_CONTENT
fora	SEC_CONTENT
particular	SEC_CONTENT
input	SEC_CONTENT
at	SEC_CONTENT
a	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
analyzed	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
order	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
compositionality	SEC_CONTENT
of	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
SNLI	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
association	SEC_CONTENT
graphs	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
sentence	SEC_CONTENT
picked	SEC_CONTENT
from	SEC_CONTENT
SNLI	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
association	SEC_CONTENT
graph	SEC_CONTENT
was	SEC_CONTENT
constructed	SEC_CONTENT
by	SEC_CONTENT
inspecting	SEC_CONTENT
the	SEC_CONTENT
key	SEC_CONTENT
vector	SEC_CONTENT
z.	SEC_CONTENT
For	SEC_CONTENT
an	SEC_CONTENT
input	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
connect	SEC_CONTENT
it	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
active	SEC_CONTENT
slot	SEC_CONTENT
pointed	SEC_CONTENT
by	SEC_CONTENT
z	SEC_CONTENT
12	SEC_CONTENT
.	SEC_END
Note	SEC_START
the	SEC_CONTENT
graph	SEC_CONTENT
components	SEC_CONTENT
clustered	SEC_CONTENT
around	SEC_CONTENT
the	SEC_CONTENT
semantically	SEC_CONTENT
rich	SEC_CONTENT
words	SEC_CONTENT
:	SEC_CONTENT
"	SEC_CONTENT
sits	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
wall	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
autumn	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
Three	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
puppies	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
tub	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
vet	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
b	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
memory	SEC_CONTENT
slots	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
semantically	SEC_CONTENT
rich	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
context	SEC_CONTENT
are	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
frequently	SEC_CONTENT
accessed	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
graph	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
certain	SEC_CONTENT
syntactic	SEC_CONTENT
structures	SEC_CONTENT
including	SEC_CONTENT
phrases	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
hand	SEC_CONTENT
built	SEC_CONTENT
rock	SEC_CONTENT
wall	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
modifier	SEC_CONTENT
relations	SEC_CONTENT
(	SEC_CONTENT
between	SEC_CONTENT
"	SEC_CONTENT
sits	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
quietly	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
:	SEC_CONTENT
Word	SEC_CONTENT
association	SEC_CONTENT
or	SEC_CONTENT
composition	SEC_CONTENT
graphs	SEC_CONTENT
produced	SEC_CONTENT
by	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
directed	SEC_CONTENT
arcs	SEC_CONTENT
connect	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
composed	SEC_CONTENT
via	SEC_CONTENT
compose	SEC_CONTENT
module	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
source	SEC_CONTENT
nodes	SEC_CONTENT
are	SEC_CONTENT
input	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
destination	SEC_CONTENT
nodes	SEC_CONTENT
(	SEC_CONTENT
pointed	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
arrows	SEC_CONTENT
)	SEC_CONTENT
correspond	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
accessed	SEC_CONTENT
memory	SEC_CONTENT
slots	SEC_CONTENT
.	SEC_CONTENT
<	SEC_CONTENT
S	SEC_CONTENT
>	SEC_CONTENT
denotes	SEC_CONTENT
the	SEC_CONTENT
beginning	SEC_CONTENT
of	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
between	SEC_CONTENT
"	SEC_CONTENT
tub	SEC_CONTENT
"	SEC_CONTENT
and	SEC_CONTENT
"	SEC_CONTENT
sprayed	SEC_CONTENT
with	SEC_CONTENT
water	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Another	SEC_CONTENT
interesting	SEC_CONTENT
property	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
tends	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
sensible	SEC_CONTENT
compositions	SEC_CONTENT
while	SEC_CONTENT
processing	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
NSE	SEC_CONTENT
retrieved	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
corresponding	SEC_CONTENT
to	SEC_CONTENT
"	SEC_CONTENT
wall	SEC_CONTENT
"	SEC_CONTENT
or	SEC_CONTENT
"	SEC_CONTENT
Three	SEC_CONTENT
"	SEC_CONTENT
when	SEC_CONTENT
reading	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
"	SEC_CONTENT
rock	SEC_CONTENT
"	SEC_CONTENT
or	SEC_CONTENT
"	SEC_CONTENT
are	SEC_CONTENT
"	SEC_CONTENT
.	SEC_END
In	SEC_START
Appendix	SEC_CONTENT
A	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
a	SEC_CONTENT
step	SEC_CONTENT
-	SEC_CONTENT
by	SEC_CONTENT
-	SEC_CONTENT
step	SEC_CONTENT
visualization	SEC_CONTENT
of	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
states	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
how	SEC_CONTENT
the	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
is	SEC_CONTENT
evolved	SEC_CONTENT
overtime	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
four	SEC_CONTENT
(	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
4	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
slot	SEC_CONTENT
for	SEC_CONTENT
"	SEC_CONTENT
quietly	SEC_CONTENT
"	SEC_CONTENT
encodes	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
"	SEC_CONTENT
quiet(ly	SEC_CONTENT
)	SEC_CONTENT
little	SEC_CONTENT
child	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
6	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
forms	SEC_CONTENT
another	SEC_CONTENT
composition	SEC_CONTENT
involving	SEC_CONTENT
"	SEC_CONTENT
quietly	SEC_CONTENT
"	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
quietly	SEC_CONTENT
sits	SEC_CONTENT
"	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
time	SEC_CONTENT
step	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
the	SEC_CONTENT
most	SEC_CONTENT
or	SEC_CONTENT
the	SEC_CONTENT
least	SEC_CONTENT
frequently	SEC_CONTENT
accessed	SEC_CONTENT
slots	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
least	SEC_CONTENT
accessed	SEC_CONTENT
slots	SEC_CONTENT
correspond	SEC_CONTENT
to	SEC_CONTENT
function	SEC_CONTENT
words	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
frequently	SEC_CONTENT
accessed	SEC_CONTENT
slots	SEC_CONTENT
are	SEC_CONTENT
content	SEC_CONTENT
words	SEC_CONTENT
and	SEC_CONTENT
tend	SEC_CONTENT
to	SEC_CONTENT
carryout	SEC_CONTENT
rich	SEC_CONTENT
semantics	SEC_CONTENT
and	SEC_CONTENT
intrinsic	SEC_CONTENT
compositions	SEC_CONTENT
found	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sentence	SEC_CONTENT
.	SEC_CONTENT
Overall	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
less	SEC_CONTENT
constrained	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
compose	SEC_CONTENT
multiword	SEC_CONTENT
expressions	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
Our	SEC_START
proposed	SEC_CONTENT
memory	SEC_CONTENT
augmented	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
have	SEC_CONTENT
achieved	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
results	SEC_CONTENT
when	SEC_CONTENT
evaluated	SEC_CONTENT
on	SEC_CONTENT
five	SEC_CONTENT
representative	SEC_CONTENT
NLP	SEC_CONTENT
tasks	SEC_CONTENT
.	SEC_CONTENT
NSE	SEC_CONTENT
is	SEC_CONTENT
capable	SEC_CONTENT
of	SEC_CONTENT
building	SEC_CONTENT
an	SEC_CONTENT
efficient	SEC_CONTENT
architecture	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
single	SEC_CONTENT
,	SEC_CONTENT
shared	SEC_CONTENT
and	SEC_CONTENT
multiple	SEC_CONTENT
memory	SEC_CONTENT
accesses	SEC_CONTENT
fora	SEC_CONTENT
specific	SEC_CONTENT
NLP	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
NLI	SEC_CONTENT
task	SEC_CONTENT
NSE	SEC_CONTENT
accesses	SEC_CONTENT
premise	SEC_CONTENT
encoded	SEC_CONTENT
memory	SEC_CONTENT
when	SEC_CONTENT
processing	SEC_CONTENT
hypothesis	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
QA	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
NSE	SEC_CONTENT
accesses	SEC_CONTENT
answer	SEC_CONTENT
encoded	SEC_CONTENT
memory	SEC_CONTENT
when	SEC_CONTENT
reading	SEC_CONTENT
question	SEC_CONTENT
for	SEC_CONTENT
QA	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
machine	SEC_CONTENT
translation	SEC_CONTENT
,	SEC_CONTENT
NSE	SEC_CONTENT
shares	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
encoded	SEC_CONTENT
memory	SEC_CONTENT
between	SEC_CONTENT
encoder	SEC_CONTENT
and	SEC_CONTENT
decoder	SEC_CONTENT
.	SEC_CONTENT
Such	SEC_CONTENT
flexibility	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
architectural	SEC_CONTENT
choice	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
access	SEC_CONTENT
allows	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
robust	SEC_CONTENT
models	SEC_CONTENT
fora	SEC_CONTENT
better	SEC_CONTENT
performance	SEC_CONTENT
.	SEC_END
The	SEC_START
initial	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
NSE	SEC_CONTENT
memory	SEC_CONTENT
stores	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
used	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
represent	SEC_CONTENT
the	SEC_CONTENT
words	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
memory	SEC_CONTENT
.	SEC_CONTENT
Different	SEC_CONTENT
variations	SEC_CONTENT
of	SEC_CONTENT
word	SEC_CONTENT
representations	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
characterbased	SEC_CONTENT
models	SEC_CONTENT
are	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
evaluated	SEC_CONTENT
for	SEC_CONTENT
memory	SEC_CONTENT
initialization	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
future	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
plan	SEC_CONTENT
to	SEC_CONTENT
extend	SEC_CONTENT
NSE	SEC_CONTENT
so	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
learns	SEC_CONTENT
to	SEC_CONTENT
select	SEC_CONTENT
and	SEC_CONTENT
access	SEC_CONTENT
a	SEC_CONTENT
relevant	SEC_CONTENT
subset	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
memory	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
could	SEC_CONTENT
also	SEC_CONTENT
explore	SEC_CONTENT
unsupervised	SEC_CONTENT
variations	SEC_CONTENT
of	SEC_CONTENT
NSE	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
them	SEC_CONTENT
to	SEC_CONTENT
produce	SEC_CONTENT
encoding	SEC_CONTENT
memory	SEC_CONTENT
and	SEC_CONTENT
representation	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
entire	task
sentences	task
or	SEC_CONTENT
documents	SEC_CONTENT
using	SEC_CONTENT
either	SEC_CONTENT
new	SEC_CONTENT
or	SEC_CONTENT
existing	SEC_CONTENT
models	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
gram	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
