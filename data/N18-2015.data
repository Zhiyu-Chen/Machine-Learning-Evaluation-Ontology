title	SECTITLE_END
A	SEC_START
Simple	SEC_CONTENT
and	SEC_CONTENT
Effective	SEC_CONTENT
Approach	SEC_CONTENT
to	SEC_CONTENT
the	dataset
Story	dataset
Cloze	dataset
Test	SEC_END
abstract	SECTITLE_END
In	SEC_START
the	dataset
Story	dataset
Cloze	dataset
Test	dataset
,	SEC_CONTENT
a	SEC_CONTENT
system	SEC_CONTENT
is	SEC_CONTENT
presented	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
4-sentence	SEC_CONTENT
prompt	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
story	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
must	SEC_CONTENT
determine	SEC_CONTENT
which	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
two	SEC_CONTENT
potential	SEC_CONTENT
endings	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
.	SEC_CONTENT
Previous	SEC_CONTENT
work	SEC_CONTENT
has	SEC_CONTENT
shown	SEC_CONTENT
that	SEC_CONTENT
ignoring	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
can	SEC_CONTENT
achieve	SEC_CONTENT
high	metric
accuracy	metric
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
stylistic	SEC_CONTENT
differences	SEC_CONTENT
between	SEC_CONTENT
the	task
story	task
endings	task
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
a	SEC_CONTENT
simpler	SEC_CONTENT
fully	SEC_CONTENT
-	SEC_CONTENT
neural	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
the	dataset
Story	dataset
Cloze	dataset
Test	dataset
using	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
stories	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
network	SEC_CONTENT
that	SEC_CONTENT
achieves	SEC_CONTENT
close	SEC_CONTENT
to	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
without	SEC_CONTENT
any	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
considering	SEC_CONTENT
just	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
prompt	SEC_CONTENT
instead	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
prompt	SEC_CONTENT
yields	SEC_CONTENT
higher	metric
accuracy	metric
with	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
introduced	SEC_START
the	dataset
Story	dataset
Cloze	dataset
Test	dataset
:	SEC_CONTENT
given	SEC_CONTENT
a	SEC_CONTENT
four	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
story	SEC_CONTENT
prompt	SEC_CONTENT
(	SEC_CONTENT
or	SEC_CONTENT
'	SEC_CONTENT
context	SEC_CONTENT
'	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
pick	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
commonsense	SEC_CONTENT
ending	SEC_CONTENT
from	SEC_CONTENT
two	SEC_CONTENT
options	SEC_CONTENT
.	SEC_CONTENT
The	dataset
Cloze	dataset
Test	dataset
is	SEC_CONTENT
intended	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
a	SEC_CONTENT
general	SEC_CONTENT
framework	SEC_CONTENT
for	SEC_CONTENT
evaluating	SEC_CONTENT
story	task
understanding	task
,	SEC_CONTENT
since	SEC_CONTENT
it	SEC_CONTENT
ostensibly	SEC_CONTENT
requires	SEC_CONTENT
combining	SEC_CONTENT
semantic	SEC_CONTENT
understanding	SEC_CONTENT
and	SEC_CONTENT
commonsense	SEC_CONTENT
knowledge	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
world	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
accompanied	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
Rochester	SEC_CONTENT
story	SEC_CONTENT
(	SEC_CONTENT
ROCstory	SEC_CONTENT
)	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
crowdsourced	SEC_CONTENT
five	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
stories	SEC_CONTENT
designed	SEC_CONTENT
to	SEC_CONTENT
capture	SEC_CONTENT
common	SEC_CONTENT
events	SEC_CONTENT
in	SEC_CONTENT
daily	SEC_CONTENT
life	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
testing	SEC_CONTENT
sets	SEC_CONTENT
consist	SEC_CONTENT
of	SEC_CONTENT
four	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
prompts	SEC_CONTENT
and	SEC_CONTENT
labeled	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
and	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
story	SEC_CONTENT
endings	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
such	SEC_CONTENT
a	SEC_CONTENT
sample	SEC_CONTENT
story	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Rochester	SEC_CONTENT
corpus	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
labeled	SEC_CONTENT
right	SEC_CONTENT
and	SEC_CONTENT
wrong	SEC_CONTENT
ending	SEC_CONTENT
.	SEC_END
Many	SEC_START
previous	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
the	dataset
Cloze	dataset
Test	dataset
have	SEC_CONTENT
ignored	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
entirely	SEC_CONTENT
and	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
former	SEC_CONTENT
lacks	SEC_CONTENT
'	SEC_CONTENT
negative	SEC_CONTENT
'	SEC_CONTENT
examples	SEC_CONTENT
;	SEC_CONTENT
although	SEC_CONTENT
this	SEC_CONTENT
greatly	SEC_CONTENT
reduces	SEC_CONTENT
the	SEC_CONTENT
available	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
circumvents	SEC_CONTENT
the	SEC_CONTENT
issue	SEC_CONTENT
of	SEC_CONTENT
obtaining	SEC_CONTENT
negative	SEC_CONTENT
examples	SEC_CONTENT
during	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
 	SEC_CONTENT
Our	SEC_CONTENT
contribution	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
is	SEC_CONTENT
two	SEC_CONTENT
-	SEC_CONTENT
fold	SEC_CONTENT
.	SEC_CONTENT
First	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
achieve	SEC_CONTENT
near	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
(	SEC_CONTENT
within	SEC_CONTENT
1.1	SEC_CONTENT
%	SEC_CONTENT
)	SEC_CONTENT
but	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
much	SEC_CONTENT
simpler	SEC_CONTENT
,	SEC_CONTENT
fullyneural	SEC_CONTENT
approach	SEC_CONTENT
.	SEC_CONTENT
Where	SEC_CONTENT
previous	SEC_CONTENT
approaches	SEC_CONTENT
rely	SEC_CONTENT
on	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
or	SEC_CONTENT
involved	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
architectures	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
achieve	SEC_CONTENT
high	metric
accuracy	metric
with	SEC_CONTENT
a	SEC_CONTENT
fully	SEC_CONTENT
neural	SEC_CONTENT
approach	SEC_CONTENT
involving	SEC_CONTENT
only	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
feedforward	SEC_CONTENT
network	SEC_CONTENT
and	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
.	SEC_CONTENT
Second	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
considering	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
context	SEC_CONTENT
outperforms	SEC_CONTENT
models	SEC_CONTENT
that	SEC_CONTENT
consider	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
Previous	SEC_CONTENT
approaches	SEC_CONTENT
focused	SEC_CONTENT
on	SEC_CONTENT
the	metric
accuracy	metric
achieved	SEC_CONTENT
by	SEC_CONTENT
either	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
context	SEC_CONTENT
or	SEC_CONTENT
ignoring	SEC_CONTENT
the	SEC_CONTENT
whole	SEC_CONTENT
context	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
sum	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
differs	SEC_CONTENT
from	SEC_CONTENT
previous	SEC_CONTENT
efforts	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
joint	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
three	SEC_CONTENT
strategies	SEC_CONTENT
:	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
using	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
provided	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
endings	SEC_CONTENT
with	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
prompt	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
paper	SEC_CONTENT
is	SEC_CONTENT
structured	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
discuss	SEC_CONTENT
previous	SEC_CONTENT
approaches	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
problem	SEC_CONTENT
and	SEC_CONTENT
how	SEC_CONTENT
they	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
describe	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
experiments	SEC_CONTENT
we	SEC_CONTENT
ran	SEC_CONTENT
in	SEC_CONTENT
detail	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
finally	SEC_CONTENT
discuss	SEC_CONTENT
reasons	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
superior	SEC_CONTENT
performance	SEC_CONTENT
and	SEC_CONTENT
why	SEC_CONTENT
ignoring	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
three	SEC_CONTENT
sentences	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
produces	SEC_CONTENT
better	metric
accuracy	metric
.	SEC_CONTENT
presented	SEC_CONTENT
the	dataset
original	dataset
Story	dataset
Cloze	dataset
Test	dataset
,	SEC_CONTENT
and	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
while	SEC_CONTENT
humans	SEC_CONTENT
could	SEC_CONTENT
achieve	SEC_CONTENT
100	metric
%	metric
accuracy	metric
on	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
deep	SEC_CONTENT
structured	SEC_CONTENT
semantic	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
was	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
performing	SEC_CONTENT
artificial	SEC_CONTENT
baseline	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	metric
test	metric
-	metric
set	metric
accuracy	metric
of	SEC_CONTENT
58.5	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
they	SEC_CONTENT
do	SEC_CONTENT
consider	SEC_CONTENT
using	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
do	SEC_CONTENT
so	SEC_CONTENT
by	SEC_CONTENT
choosing	SEC_CONTENT
the	SEC_CONTENT
ending	SEC_CONTENT
whose	SEC_CONTENT
embedding	SEC_CONTENT
was	SEC_CONTENT
closer	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	dataset
context	dataset
.	SEC_CONTENT
This	SEC_CONTENT
only	SEC_CONTENT
achieves	SEC_CONTENT
a	metric
test	metric
-	metric
set	metric
accuracy	metric
of	SEC_CONTENT
55.2	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
hand	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
a	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
network	SEC_CONTENT
using	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_END
Story	SECTITLE_START
Context	SECTITLE_END
Related	SECTITLE_START
Work	SECTITLE_END
The	SEC_START
Story	dataset
Cloze	dataset
Test	dataset
was	SEC_CONTENT
the	SEC_CONTENT
shared	SEC_CONTENT
task	SEC_CONTENT
at	SEC_CONTENT
LSDSem	SEC_CONTENT
2017	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
summarize	SEC_CONTENT
the	SEC_CONTENT
approaches	SEC_CONTENT
by	SEC_CONTENT
various	SEC_CONTENT
teams	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
best	SEC_CONTENT
-	SEC_CONTENT
performing	SEC_CONTENT
system	SEC_CONTENT
by	SEC_CONTENT
achieved	SEC_CONTENT
a	metric
test	metric
-	metric
set	metric
accuracy	metric
of	SEC_CONTENT
75.2	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
Like	SEC_CONTENT
us	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
train	SEC_CONTENT
their	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
their	SEC_CONTENT
approach	SEC_CONTENT
relies	SEC_CONTENT
more	SEC_CONTENT
heavily	SEC_CONTENT
on	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
find	SEC_CONTENT
that	SEC_CONTENT
they	SEC_CONTENT
could	SEC_CONTENT
achieve	SEC_CONTENT
72.4	metric
%	metric
accuracy	metric
using	SEC_CONTENT
just	SEC_CONTENT
the	SEC_CONTENT
stylistic	SEC_CONTENT
features	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
endings	SEC_CONTENT
,	SEC_CONTENT
suggesting	SEC_CONTENT
that	SEC_CONTENT
many	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
endings	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
identified	SEC_CONTENT
independent	SEC_CONTENT
of	SEC_CONTENT
the	dataset
story	dataset
context	dataset
.	SEC_CONTENT
Upon	SEC_CONTENT
further	SEC_CONTENT
investigation	SEC_CONTENT
,	SEC_CONTENT
find	SEC_CONTENT
differences	SEC_CONTENT
not	SEC_CONTENT
only	SEC_CONTENT
between	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
and	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
endings	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
also	SEC_CONTENT
between	SEC_CONTENT
these	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
endings	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
providing	SEC_CONTENT
some	SEC_CONTENT
explanation	SEC_CONTENT
for	SEC_CONTENT
why	SEC_CONTENT
models	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
outperform	SEC_CONTENT
models	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
-their	SEC_CONTENT
data	SEC_CONTENT
distributions	SEC_CONTENT
are	SEC_CONTENT
somewhat	SEC_CONTENT
different	SEC_CONTENT
.	SEC_END
Further	SEC_START
work	SEC_CONTENT
by	SEC_CONTENT
established	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
baseline	SEC_CONTENT
for	SEC_CONTENT
models	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	metric
test	metric
-	metric
set	metric
accuracy	metric
of	SEC_CONTENT
74.7	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
were	SEC_CONTENT
also	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
achieve	SEC_CONTENT
a	SEC_CONTENT
marginally	SEC_CONTENT
better	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
72.5	SEC_CONTENT
%	SEC_CONTENT
(	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
)	SEC_CONTENT
when	SEC_CONTENT
using	SEC_CONTENT
just	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
endings	SEC_CONTENT
and	SEC_CONTENT
ignoring	SEC_CONTENT
the	dataset
context	dataset
;	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
require	SEC_CONTENT
any	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
human	SEC_CONTENT
can	SEC_CONTENT
distinguish	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
from	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
endings	SEC_CONTENT
without	SEC_CONTENT
the	dataset
context	dataset
with	SEC_CONTENT
78	metric
%	metric
accuracy	metric
,	SEC_CONTENT
further	SEC_CONTENT
backing	SEC_CONTENT
the	SEC_CONTENT
claim	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
importance	SEC_CONTENT
of	SEC_CONTENT
context	SEC_CONTENT
in	SEC_CONTENT
determining	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
ending	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
limited	SEC_CONTENT
than	SEC_CONTENT
desirable	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Their	SEC_CONTENT
approach	SEC_CONTENT
involves	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
hierarchical	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
first	dataset
encode	dataset
sentences	dataset
and	SEC_CONTENT
then	SEC_CONTENT
stories	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
hinge	SEC_CONTENT
-	SEC_CONTENT
loss	SEC_CONTENT
objective	SEC_CONTENT
function	SEC_CONTENT
.	SEC_CONTENT
use	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
they	SEC_CONTENT
encode	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
context	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
GRU	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
binary	SEC_CONTENT
classifier	SEC_CONTENT
to	SEC_CONTENT
determine	SEC_CONTENT
if	SEC_CONTENT
an	SEC_CONTENT
ending	SEC_CONTENT
was	SEC_CONTENT
right	SEC_CONTENT
or	SEC_CONTENT
wrong	SEC_CONTENT
.	SEC_CONTENT
They	SEC_CONTENT
train	SEC_CONTENT
their	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
provided	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
sampling	SEC_CONTENT
negative	SEC_CONTENT
examples	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
itself	SEC_CONTENT
.	SEC_CONTENT
Their	SEC_CONTENT
best	SEC_CONTENT
model	SEC_CONTENT
achieves	SEC_CONTENT
67.2	metric
%	metric
accuracy	metric
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Currently	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
comprehensive	SEC_CONTENT
approach	SEC_CONTENT
taken	SEC_CONTENT
by	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
they	SEC_CONTENT
model	SEC_CONTENT
event	SEC_CONTENT
sequence	SEC_CONTENT
,	SEC_CONTENT
sentiment	SEC_CONTENT
trajectory	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
topical	SEC_CONTENT
consistency	SEC_CONTENT
fora	SEC_CONTENT
hidden	SEC_CONTENT
coherence	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
achieves	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
performance	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	metric
test	metric
-	metric
set	metric
accuracy	metric
of	SEC_CONTENT
77.6	SEC_CONTENT
%	SEC_CONTENT
.	SEC_END
Approach	SECTITLE_END
We	SEC_START
trained	SEC_CONTENT
several	SEC_CONTENT
models	SEC_CONTENT
on	SEC_CONTENT
both	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
the	dataset
ROCStory	dataset
corpus	dataset
.	SEC_CONTENT
When	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
obtain	SEC_CONTENT
'	SEC_CONTENT
negative	SEC_CONTENT
'	SEC_CONTENT
examples	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
wrong	SEC_CONTENT
endings	SEC_CONTENT
)	SEC_CONTENT
by	SEC_CONTENT
randomly	SEC_CONTENT
choosing	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
from	SEC_CONTENT
another	SEC_CONTENT
story	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
describe	SEC_CONTENT
the	SEC_CONTENT
choice	SEC_CONTENT
of	SEC_CONTENT
sentence	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
architecture	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
we	SEC_CONTENT
trained	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
experimental	SEC_CONTENT
setup	SEC_CONTENT
.	SEC_END
Embeddings	SECTITLE_END
Key	SEC_START
to	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
feedforward	SEC_CONTENT
network	SEC_CONTENT
(	SEC_CONTENT
denoted	SEC_CONTENT
skip	SEC_CONTENT
in	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
are	SEC_CONTENT
4800-dimensional	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
sentences	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
task	SEC_CONTENT
of	SEC_CONTENT
predicting	SEC_CONTENT
their	dataset
context	dataset
using	SEC_CONTENT
the	SEC_CONTENT
BookCorpus	SEC_CONTENT
dataset	SEC_CONTENT
(	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
dataset	SEC_CONTENT
of	SEC_CONTENT
books	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
encoder	SEC_CONTENT
1	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
the	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
sentences	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_END
To	SEC_START
isolate	SEC_CONTENT
the	metric
increase	metric
inaccuracy	metric
from	SEC_CONTENT
using	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
vectors	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
experiment	SEC_CONTENT
with	SEC_CONTENT
learning	SEC_CONTENT
sentence	SEC_CONTENT
embeddings	SEC_CONTENT
directly	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_CONTENT
Unlike	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
encoder	SEC_CONTENT
that	SEC_CONTENT
directly	SEC_CONTENT
gives	SEC_CONTENT
sentence	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
bidirectional	SEC_CONTENT
LSTM	SEC_CONTENT
that	SEC_CONTENT
takes	SEC_CONTENT
in	SEC_CONTENT
GloVe	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
word	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
and	SEC_CONTENT
returns	SEC_CONTENT
a	SEC_CONTENT
4800	SEC_CONTENT
dimensional	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
denoted	SEC_CONTENT
GloVe	SEC_CONTENT
in	SEC_CONTENT
)	SEC_CONTENT
formed	SEC_CONTENT
by	SEC_CONTENT
concatenating	SEC_CONTENT
the	SEC_CONTENT
outputs	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
forward	SEC_CONTENT
and	SEC_CONTENT
backward	SEC_CONTENT
LSTMs	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
GloVe	SEC_CONTENT
model	SEC_CONTENT
pretrained	SEC_CONTENT
on	SEC_CONTENT
Wikipedia	SEC_CONTENT
2014	SEC_CONTENT
and	SEC_CONTENT
Gigaword	SEC_CONTENT
5	SEC_CONTENT
data	SEC_CONTENT
2	SEC_CONTENT
.	SEC_END
Models	SECTITLE_END
Common	SEC_START
to	SEC_CONTENT
all	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
softmax	SEC_CONTENT
-	SEC_CONTENT
layer	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
that	SEC_CONTENT
acts	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
binary	SEC_CONTENT
classifier	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
takes	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
4800-dimensional	SEC_CONTENT
input	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
dimensionality	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
returns	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
endings	SEC_CONTENT
being	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
and	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
inference	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
make	SEC_CONTENT
a	SEC_CONTENT
forward	SEC_CONTENT
pass	SEC_CONTENT
with	SEC_CONTENT
each	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
possible	SEC_CONTENT
endings	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
select	SEC_CONTENT
the	SEC_CONTENT
ending	SEC_CONTENT
that	SEC_CONTENT
has	SEC_CONTENT
a	SEC_CONTENT
higher	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
being	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
two	SEC_CONTENT
layer	SEC_CONTENT
and	SEC_CONTENT
three	SEC_CONTENT
layer	SEC_CONTENT
fully	SEC_CONTENT
connected	SEC_CONTENT
networks	SEC_CONTENT
with	SEC_CONTENT
Rectified	SEC_CONTENT
Linear	SEC_CONTENT
(	SEC_CONTENT
ReLU	SEC_CONTENT
)	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
linearities	SEC_CONTENT
(	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
Appendix	SEC_CONTENT
A	SEC_CONTENT
for	SEC_CONTENT
model	SEC_CONTENT
-	SEC_CONTENT
specific	SEC_CONTENT
architecture	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
then	SEC_CONTENT
experiment	SEC_CONTENT
with	SEC_CONTENT
different	SEC_CONTENT
inputs	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
below	SEC_CONTENT
.	SEC_END
No	SEC_START
Context	dataset
(	SEC_CONTENT
NC	SEC_CONTENT
)	SEC_CONTENT
This	SEC_CONTENT
model	SEC_CONTENT
attempts	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
story	SEC_CONTENT
by	SEC_CONTENT
ignoring	SEC_CONTENT
the	dataset
story	dataset
context	dataset
and	SEC_CONTENT
looking	SEC_CONTENT
only	SEC_CONTENT
at	SEC_CONTENT
examples	SEC_CONTENT
of	SEC_CONTENT
right	SEC_CONTENT
and	SEC_CONTENT
wrong	SEC_CONTENT
endings	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
such	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
is	SEC_CONTENT
just	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
ending	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
0/1	SEC_CONTENT
label	SEC_CONTENT
indicating	SEC_CONTENT
whether	SEC_CONTENT
it	SEC_CONTENT
was	SEC_CONTENT
the	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
or	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
.	SEC_END
Last	SEC_START
Sentence	SEC_CONTENT
(	SEC_CONTENT
LS	SEC_CONTENT
)	SEC_CONTENT
In	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
sum	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
prompt	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
fourth	SEC_CONTENT
sentence	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
ending	SEC_CONTENT
.	SEC_CONTENT
Essentially	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
are	SEC_CONTENT
attempting	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
ending	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
ending	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
preceding	SEC_CONTENT
sentence	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
.	SEC_END
Full	SEC_START
Context	SEC_CONTENT
(	SEC_CONTENT
FC	SEC_CONTENT
)	SEC_CONTENT
Here	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
Gated	SEC_CONTENT
Recurrent	SEC_CONTENT
Unit	SEC_CONTENT
(	SEC_CONTENT
GRU	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
encode	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
story	SEC_CONTENT
prompt	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
4800-dimensional	SEC_CONTENT
vector	SEC_CONTENT
,	SEC_CONTENT
add	SEC_CONTENT
it	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
skipthought	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
ending	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
pass	SEC_CONTENT
it	SEC_CONTENT
as	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
input	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
GRU	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embedding	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
attempts	SEC_CONTENT
to	SEC_CONTENT
identify	SEC_CONTENT
the	SEC_CONTENT
right	SEC_CONTENT
ending	SEC_CONTENT
by	SEC_CONTENT
considering	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
story	SEC_CONTENT
prompt	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
Dataset	SECTITLE_END
For	SEC_START
all	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	dataset
ROCStory	dataset
corpus	dataset
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
corpus	SEC_CONTENT
consists	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
98,161	SEC_CONTENT
five	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
stories	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
1,871	SEC_CONTENT
foursentence	SEC_CONTENT
stories	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
1,871	SEC_CONTENT
foursentence	SEC_CONTENT
stories	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
sets	SEC_CONTENT
providing	SEC_CONTENT
labeled	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
and	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
story	SEC_CONTENT
endings	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
story	SEC_CONTENT
.	SEC_CONTENT
(	SEC_CONTENT
crowdsourced	SEC_CONTENT
the	SEC_CONTENT
collection	SEC_CONTENT
of	SEC_CONTENT
stories	dataset
on	SEC_CONTENT
Amazon	SEC_CONTENT
Mechanical	SEC_CONTENT
Turk	SEC_CONTENT
;	SEC_CONTENT
workers	SEC_CONTENT
were	SEC_CONTENT
asked	SEC_CONTENT
to	SEC_CONTENT
compose	SEC_CONTENT
five	SEC_CONTENT
-	SEC_CONTENT
sentence	SEC_CONTENT
stories	SEC_CONTENT
about	SEC_CONTENT
common	SEC_CONTENT
daily	SEC_CONTENT
situations	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
clear	SEC_CONTENT
beginning	SEC_CONTENT
and	SEC_CONTENT
end	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
create	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
testing	SEC_CONTENT
sets	SEC_CONTENT
,	SEC_CONTENT
endings	SEC_CONTENT
were	SEC_CONTENT
removed	SEC_CONTENT
from	SEC_CONTENT
stories	dataset
and	SEC_CONTENT
an	SEC_CONTENT
additional	SEC_CONTENT
group	SEC_CONTENT
of	SEC_CONTENT
workers	SEC_CONTENT
on	SEC_CONTENT
Mechanical	SEC_CONTENT
Turk	SEC_CONTENT
were	SEC_CONTENT
asked	SEC_CONTENT
to	SEC_CONTENT
provide	SEC_CONTENT
a	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
or	SEC_CONTENT
a	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
.	SEC_END
Although	SEC_START
models	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
score	SEC_CONTENT
higher	SEC_CONTENT
than	SEC_CONTENT
those	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
as	SEC_CONTENT
previously	SEC_CONTENT
discussed	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
provide	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
(	SEC_CONTENT
denoted	SEC_CONTENT
val	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
(	SEC_CONTENT
denoted	SEC_CONTENT
trn	SEC_CONTENT
)	SEC_CONTENT
in	SEC_CONTENT
for	SEC_CONTENT
comparison	SEC_CONTENT
.	SEC_END
Experimental	SECTITLE_START
Method	SECTITLE_END
When	SEC_START
training	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
tuned	SEC_CONTENT
hyperparameters	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
holdout	SEC_CONTENT
10	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
tune	SEC_CONTENT
hyper	SEC_CONTENT
-	SEC_CONTENT
parameters	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
a	SEC_CONTENT
configuration	SEC_CONTENT
that	SEC_CONTENT
maximizes	SEC_CONTENT
the	metric
accuracy	metric
on	SEC_CONTENT
the	dataset
model	dataset
val	dataset
test	dataset
trn	SEC_CONTENT
-	SEC_CONTENT
NC	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
60.3	SEC_CONTENT
%	SEC_CONTENT
60.8	SEC_CONTENT
%	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
NC	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
73.9	SEC_CONTENT
%	SEC_CONTENT
72.6	SEC_CONTENT
%	SEC_CONTENT
trn	SEC_CONTENT
-	SEC_CONTENT
FC	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
62.4	SEC_CONTENT
%	SEC_CONTENT
62.6	SEC_CONTENT
%	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
FC	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
73.8	SEC_CONTENT
%	SEC_CONTENT
71.6	SEC_CONTENT
%	SEC_CONTENT
trn	SEC_CONTENT
-	SEC_CONTENT
LS	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
62.8	SEC_CONTENT
%	SEC_CONTENT
62.7	SEC_CONTENT
%	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
LS	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
77.2	SEC_CONTENT
%	SEC_CONTENT
76.5	SEC_CONTENT
%	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
LS	SEC_CONTENT
-	SEC_CONTENT
GloVe	SEC_CONTENT
69.7	SEC_CONTENT
%	SEC_CONTENT
63.0	SEC_CONTENT
%	SEC_CONTENT
-77.6	SEC_CONTENT
%	SEC_CONTENT
-75.2	SEC_CONTENT
%	SEC_CONTENT
-74.7	SEC_CONTENT
%	SEC_CONTENT
held	SEC_CONTENT
out	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
cross	SEC_CONTENT
-	SEC_CONTENT
entropy	SEC_CONTENT
loss	SEC_CONTENT
and	SEC_CONTENT
SGD	SEC_CONTENT
with	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
of	SEC_CONTENT
0.01	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
save	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
every	SEC_CONTENT
3000	SEC_CONTENT
iterations	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
calculate	SEC_CONTENT
the	metric
validation	metric
accuracy	metric
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
each	SEC_CONTENT
model	SEC_CONTENT
five	SEC_CONTENT
times	SEC_CONTENT
(	SEC_CONTENT
except	SEC_CONTENT
the	SEC_CONTENT
FC	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
once	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
time	SEC_CONTENT
considerations	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
report	SEC_CONTENT
the	SEC_CONTENT
average	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
accuracy	metric
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
validation	SEC_CONTENT
accuracy	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
round	SEC_CONTENT
to	SEC_CONTENT
calculate	SEC_CONTENT
the	dataset
test	dataset
set	metric
accuracy	metric
for	SEC_CONTENT
that	SEC_CONTENT
round	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
present	SEC_CONTENT
our	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
.	SEC_END
Results	SECTITLE_START
and	SECTITLE_CONTENT
Discussion	SECTITLE_END
The	SEC_START
3-layer	SEC_CONTENT
feed	SEC_CONTENT
-	SEC_CONTENT
forward	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
set	SEC_CONTENT
by	SEC_CONTENT
summing	SEC_CONTENT
the	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
LS	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
story	SEC_CONTENT
prompt	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
ending	SEC_CONTENT
gives	SEC_CONTENT
the	metric
best	metric
accuracy	metric
(	SEC_CONTENT
76.5	SEC_CONTENT
%	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
far	SEC_CONTENT
simpler	SEC_CONTENT
than	SEC_CONTENT
previous	SEC_CONTENT
approaches	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
;	SEC_CONTENT
it	SEC_CONTENT
requires	SEC_CONTENT
no	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
,	SEC_CONTENT
nor	SEC_CONTENT
intricate	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
achieves	SEC_CONTENT
close	SEC_CONTENT
to	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
accuracy	SEC_CONTENT
.	SEC_CONTENT
Comparing	SEC_CONTENT
'	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
LS	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
'	SEC_CONTENT
to	SEC_CONTENT
'	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
LSGloVe	SEC_CONTENT
'	SEC_CONTENT
(	SEC_CONTENT
i.e.	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
for	SEC_CONTENT
sentences	SEC_CONTENT
vs.	SEC_CONTENT
GloVe	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
confirm	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
success	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
lies	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
sizable	SEC_CONTENT
boost	SEC_CONTENT
to	SEC_CONTENT
accuracy	metric
from	SEC_CONTENT
the	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
pretrained	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
perhaps	SEC_CONTENT
unsurprising	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
success	SEC_CONTENT
of	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
embeddings	SEC_CONTENT
in	SEC_CONTENT
story	dataset
-	dataset
related	dataset
tasks	dataset
(	SEC_CONTENT
,	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
corpus	SEC_CONTENT
of	SEC_CONTENT
fiction	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
the	SEC_CONTENT
BookCorpus	SEC_CONTENT
and	SEC_CONTENT
ROCStories	SEC_CONTENT
draw	SEC_CONTENT
from	SEC_CONTENT
different	SEC_CONTENT
distributions	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
possible	SEC_CONTENT
that	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
vectors	SEC_CONTENT
implicitly	SEC_CONTENT
encode	SEC_CONTENT
a	SEC_CONTENT
general	SEC_CONTENT
notion	SEC_CONTENT
of	SEC_CONTENT
typical	SEC_CONTENT
story	SEC_CONTENT
continuation	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
absence	SEC_CONTENT
of	SEC_CONTENT
such	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
dataset	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
such	SEC_CONTENT
associations	SEC_CONTENT
from	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
LSTM	SEC_CONTENT
with	SEC_CONTENT
GloVe	SEC_CONTENT
embedding	SEC_CONTENT
inputs	SEC_CONTENT
is	SEC_CONTENT
unable	SEC_CONTENT
to	SEC_CONTENT
encode	SEC_CONTENT
the	SEC_CONTENT
necessary	SEC_CONTENT
information	SEC_CONTENT
to	SEC_CONTENT
do	SEC_CONTENT
well	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
task	SEC_CONTENT
.	SEC_END
We	SEC_START
note	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
(	SEC_CONTENT
LS	SEC_CONTENT
)	SEC_CONTENT
of	SEC_CONTENT
the	dataset
story	dataset
context	dataset
has	SEC_CONTENT
higher	metric
accuracy	metric
compared	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
GRU	SEC_CONTENT
to	SEC_CONTENT
encode	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
context	SEC_CONTENT
(	SEC_CONTENT
FC	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
even	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
which	SEC_CONTENT
encodes	SEC_CONTENT
the	SEC_CONTENT
entire	SEC_CONTENT
context	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
unclear	SEC_CONTENT
from	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
why	SEC_CONTENT
this	SEC_CONTENT
might	SEC_CONTENT
be	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
hypothesis	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
as	SEC_CONTENT
stories	dataset
near	SEC_CONTENT
conclusion	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
space	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
continuations	SEC_CONTENT
contracts	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
the	SEC_CONTENT
absence	SEC_CONTENT
of	SEC_CONTENT
further	dataset
context	dataset
,	SEC_CONTENT
a	SEC_CONTENT
default	SEC_CONTENT
prior	SEC_CONTENT
is	SEC_CONTENT
assumed	SEC_CONTENT
-as	SEC_CONTENT
implicitly	SEC_CONTENT
encoded	SEC_CONTENT
in	SEC_CONTENT
skip	SEC_CONTENT
-	SEC_CONTENT
thought	SEC_CONTENT
vectors	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
BookCorpus	SEC_CONTENT
-that	SEC_CONTENT
is	SEC_CONTENT
often	SEC_CONTENT
correct	SEC_CONTENT
.	SEC_CONTENT
Providing	SEC_CONTENT
more	dataset
context	dataset
may	SEC_CONTENT
conflict	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
default	SEC_CONTENT
prior	SEC_CONTENT
,	SEC_CONTENT
introducing	SEC_CONTENT
uncertainty	SEC_CONTENT
.	SEC_CONTENT
Another	SEC_CONTENT
hypothesis	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
Mechanical	SEC_CONTENT
Turk	SEC_CONTENT
workers	SEC_CONTENT
creating	SEC_CONTENT
the	SEC_CONTENT
validation	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
data	SEC_CONTENT
sets	SEC_CONTENT
focused	SEC_CONTENT
more	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
fourth	SEC_CONTENT
sentence	SEC_CONTENT
when	SEC_CONTENT
writing	SEC_CONTENT
their	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
and	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
endings	SEC_CONTENT
,	SEC_CONTENT
so	SEC_CONTENT
once	SEC_CONTENT
again	SEC_CONTENT
,	SEC_CONTENT
adding	SEC_CONTENT
context	SEC_CONTENT
introduces	SEC_CONTENT
error	SEC_CONTENT
.	SEC_END
Finally	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
observe	SEC_CONTENT
that	SEC_CONTENT
the	dataset
Story	dataset
Cloze	dataset
Test	dataset
is	SEC_CONTENT
an	SEC_CONTENT
easier	SEC_CONTENT
task	SEC_CONTENT
than	SEC_CONTENT
identifying	SEC_CONTENT
whether	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
ending	SEC_CONTENT
is	SEC_CONTENT
coherent	SEC_CONTENT
or	SEC_CONTENT
not	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
former	SEC_CONTENT
involves	SEC_CONTENT
a	SEC_CONTENT
forced	SEC_CONTENT
choice	SEC_CONTENT
between	SEC_CONTENT
two	SEC_CONTENT
endings	SEC_CONTENT
.	SEC_CONTENT
During	SEC_CONTENT
test	SEC_CONTENT
time	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
need	SEC_CONTENT
to	SEC_CONTENT
classify	SEC_CONTENT
whether	SEC_CONTENT
a	SEC_CONTENT
given	SEC_CONTENT
ending	SEC_CONTENT
is	SEC_CONTENT
'	SEC_CONTENT
right	SEC_CONTENT
'	SEC_CONTENT
or	SEC_CONTENT
'	SEC_CONTENT
wrong	SEC_CONTENT
'	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
it	SEC_CONTENT
learns	SEC_CONTENT
to	SEC_CONTENT
do	SEC_CONTENT
during	SEC_CONTENT
train	SEC_CONTENT
time	SEC_CONTENT
;	SEC_CONTENT
instead	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
simply	SEC_CONTENT
needs	SEC_CONTENT
to	SEC_CONTENT
correctly	SEC_CONTENT
predict	SEC_CONTENT
which	SEC_CONTENT
ending	SEC_CONTENT
is	SEC_CONTENT
less	SEC_CONTENT
wrong	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
have	SEC_CONTENT
shown	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
yet	SEC_CONTENT
effective	SEC_CONTENT
neural	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
achieves	SEC_CONTENT
high	metric
accuracy	metric
on	SEC_CONTENT
the	dataset
Cloze	dataset
Test	dataset
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
within	SEC_CONTENT
1.1	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
approach	SEC_CONTENT
that	SEC_CONTENT
relies	SEC_CONTENT
on	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
.	SEC_CONTENT
Additionally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
make	SEC_CONTENT
a	SEC_CONTENT
minor	SEC_CONTENT
improvement	SEC_CONTENT
on	SEC_CONTENT
's	SEC_CONTENT
'	SEC_CONTENT
ending	SEC_CONTENT
-	SEC_CONTENT
only	SEC_CONTENT
'	SEC_CONTENT
baseline	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
72.5	SEC_CONTENT
%	SEC_CONTENT
with	SEC_CONTENT
our	SEC_CONTENT
val	SEC_CONTENT
-	SEC_CONTENT
NC	SEC_CONTENT
-	SEC_CONTENT
skip	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
tested	SEC_CONTENT
here	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
context	SEC_CONTENT
actually	SEC_CONTENT
performs	SEC_CONTENT
worse	SEC_CONTENT
than	SEC_CONTENT
using	SEC_CONTENT
just	SEC_CONTENT
the	SEC_CONTENT
last	SEC_CONTENT
sentence	SEC_CONTENT
of	SEC_CONTENT
the	dataset
context	dataset
.	SEC_CONTENT
Future	SEC_CONTENT
investigation	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
needed	SEC_CONTENT
to	SEC_CONTENT
determine	SEC_CONTENT
whether	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
property	SEC_CONTENT
inherent	SEC_CONTENT
to	SEC_CONTENT
human	SEC_CONTENT
storytelling	SEC_CONTENT
or	SEC_CONTENT
a	SEC_CONTENT
form	SEC_CONTENT
of	SEC_CONTENT
bias	SEC_CONTENT
introduced	SEC_CONTENT
during	SEC_CONTENT
data	SEC_CONTENT
collection	SEC_CONTENT
.	SEC_END
