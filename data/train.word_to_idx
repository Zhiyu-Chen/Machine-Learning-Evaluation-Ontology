<PAD>
<SOS>
<EOS>
<UNK>
title
targeted
aspect
-<punct>
based
sentiment
analysis
via
embedding
commonsense
knowledge
into
an
attentive
lstm
abstract
analyzing
people
's
opinions
and
sentiments
towards
certain
aspects
is
important
task
of
natural
language
understanding
.<punct>
in
this
paper
,<punct>
we
propose
a<punct>
novel
solution
to
which
tackles
the
challenges
both
by
exploiting
augment
long
short
term
memory
(<punct>
)<punct>
network
with
hierarchical
attention
mechanism
consisting
target
level
sentence
related
concepts
incorporated
end
training
deep
neural
for
classification
order
tightly
integrate
common
sense
recurrent
encoder
extension
termed
sentic
conduct
experiments
on
two
publicly
released
datasets
show
that
combination
proposed
architecture
sen
tic
can
outperform
state
art
methods
tasks
introduction
recent
years
has
become
increasingly
popular
processing
social
media
data
online
communities
blogs
wikis
microblogging
platforms
other
collaborative
branch
affective
computing
research
aims
classify
text
either
positive
or
negative
but
sometimes
also
neutral
most
literature
english
recently
increasing
number
publications
tackling
multilinguality
issue
while
works
approach
it
as
simple
categorization
problem
actually
suitcase
requires
many
nlp
including
named
entity
recognition
word
polarity
disambiguation
personality
sarcasm
detection
extraction
last
one
particular
extremely
subtask
if
ignored
consistently
reduce
accuracy
presence
multiple
opinion
targets
copyright
©<punct>
2018
association
advancement
artificial
intelligence
www.aaai.org
all
rights
reserved
hence
absa
extends
typical
setting
more
realistic
assumption
associated
specific
product
features
rather
than
whole
unit
example
"<punct>
design
space
good
service
horrible
expressed
completely
opposite
through
aggregating
allows
model
produce
fine
grained
dependent
instead
resolves
given
its
context
assuming
might
express
different
entities
instance
i<punct>
just
logon
my
boring
there
no
clear
attempted
tackle
jointly
detect
category
resolve
respect
learning
have
achieved
great
when
applied
especially
sequential
models
such
networks
hochreiter
schmidhuber
1997
are
growing
interest
their
capacity
representing
information
moreover
these
sequence
incorporate
root
alignment
machine
translation
bahdanau
cho
bengio
2014
takes
external
representations
input
produces
probability
distribution
quantifying
concerns
each
position
despite
advances
identify
three
problems
remaining
unsolved
current
theart
firstly
consist
instances
mentions
same
words
existing
assumes
equal
importance
simply
computes
average
vector
thirty
second
aaai
conference
over
oversimplification
conflicts
fact
often
tied
others
secondly
exploited
only
implicitly
process
inferring
bearing
black
box
not
least
falls
effectively
incorporating
e.g.
could
directly
contribute
identification
without
any
constraints
global
tend
encode
irrelevant
address
our
method
simultaneously
learns
well
contribution
fold
:<punct>
1<punct>
explicitly
attends
first
then
;<punct>
2<punct>
extend
classic
cell
components
accounting
integration
3<punct>
work
section
survey
areas
framework
namely
finally
classifying
set
biggest
challenge
faced
how
represent
early
mainly
relied
feature
engineering
characterize
sentences
motivated
success
representation
utilize
generate
embeddings
dense
fed
classifier
lowdimensional
be
enhanced
using
typically
multi
layer
taking
quantifies
salience
relevance
resulting
benefits
from
overcomes
shortcoming
rnns
suffer
loss
single
output
at
used
analyze
thus
critical
targetdependent
tdlstm
connection
tclstm
interaction
between
obtain
tdl
stm
uses
hidden
outputs
bidirectional
encoders
panning
concatenating
similar
applicable
tang
qin
liu
2016
superior
performance
singlelevel
passes
hops
refine
attended
again
find
approaches
averaging
expressions
unlike
weights
weight
so
represented
informative
baseline
systems
together
sentihood
logistic
regression
templates
n<punct>
grams
tokens
pos
tags
extracted
seen
adaptation
equally
base
been
source
methodology
describe
detail
definition
followed
overview
afterwards
lastly
embedded
s<punct>
consists
consider
t<punct>
composed
m<punct>
denoted
=<punct>
{<punct>
⋯<punct>
ti
}<punct>
referring
ith
expression
divided
subtasks
categories
oft
belonging
predefined
classifies
t.
live
[<punct>
west
london
]<punct>
like
safe
much
except
maybe
contains
objective
desired
'<punct>
general':positive
safety':positive
should
general':negative
safety':negative
provide
component
illustrates
w<punct>
l<punct>
look
up
operation
performed
convert
v<punct>
transforms
built
top
positions
highlighted
brown
selfattention
transforming
returns
pair
corresponding
class
none
fora
4-class
3-class
encoded
rnn
was
introduced
solve
vanishing
exploding
gradient
vanilla
gates
forget
gate
determine
flow
out
time
step
mathematical
follows
where
f<punct>
oi
respectively
wi
o<punct>
bf
b<punct>
matrix
bias
scalar
ci
hi
encodes
direction
however
lstms
stacked
referred
element
h<punct>
concatenation
forward
backward
cells
calculate
consecutive
non
location
individual
compute
α<punct>
distributed
self
nothing
itself
computed
feeding
bi
perceptron
shown
equation
∈<punct>
r<punct>
1×dm
parameters
following
overall
length
linear
vectors
i.e.
β<punct>
called
sentencelevel
mostly
terms
queries
transformed
ad
dimensional
tanh
activation
function
softmax
improve
use
senticnet
50,000
rich
properties
concept
semantic
links
rotten
fish
property
kindoffood
relates
restaurant
food
quality
emotions
joy
support
high
dimensionality
hinders
being
affectivespace
map
continuous
low
losing
relatedness
original
new
embed
better
leverage
efficiently
reasonable
assume
contain
complementary
textual
about
usually
taken
granted
absent
entitle
roles
assisting
filtering
flowing
onetime
next
providing
candidates
triggered
mapped
c<punct>
denote
k<punct>
μ<punct>
i,1
i,2
combine
candidate
realized
4<punct>
although
sophisticated
easily
employed
replace
illustrated
7<punct>
meaningful
cues
control
token
indicate
modifier
less
filtered
add
standard
help
expected
prevent
affected
conflicting
pre
similarly
filter
stored
another
therefore
extended
regular
additional
since
learned
independently
transformation
rd
×dμ
relative
contributions
notice
*<punct>
tanh(w
resembles
functionality
sentinel
choose
whether
prediction
parameter
train
classier
defined
minimizing
sum
cross
entropy
losses
pa
gold
p<punct>
label
a.
avoid
overfitting
dropout
0.5
after
stop
10
epochs
select
achieves
best
development
dataset
resources
evaluate
subset
semeval
2015
querying
yahoo
!<punct>
answers
names
city
shows
statistics
split
test
authors
entire
5,215
3,862
containing
1,353
approximately
third
annotated
2476
2977
set:1241
1898
619
955
sentimentbearing
1.37
generalizability
build
semeval-2015
remove
null
comparable
surface
form
within
total
1,197
left
542
testing
1.06
<punct><punct>
inject
syntaxbased
parser
extract
case
zero
experiment
sub
treat
classes
highest
ignore
scores
evaluating
averaged
results
loose
strict
metrics
report
widely
evaluation
macro
f1
micro
d<punct>
ground
truth
dis
y<punct>
predicted
̂<punct>
σ(⋅
indicator
•<punct>
ma
p×ma
p+ma
macroprecision
recall
r=
microprecision
mi
p=
comparison
compare
furthermore
performances
several
variants
highlight
technical
run
times
perform
final
epoch
adopts
structure
represents
+<punct>
ta
sa
addition
dmn
replaced
dynamic
numbers
result
exclude
corresponds
semeval-15
lstm+avg
significantly
improves
20
%<punct>
notable
improvement
relatively
smaller
conjecture
reason
masked
special
loca
tion
resulted
full
name
regarding
does
suffice
compared
some
even
though
significant
capable
identifying
part
higher
hand
indicating
retrieve
relevant
surprise
fails
bring
down
larger
increases
learn
makes
small
sparse
visualization
visualize
transition
price
quite
expressing
cheap
say
distinguishing
visualized
selecting
easier
resolved
injecting
general
semantically
outperforms
outcome
kb
feat
confirms
efficacy
background
kba
indicates
activated
conclusion
modeled
attend
salient
generates
accurate
searches
evidence
encoding
future
would
collectively
co
occurring
investigate
role
modeling
relation
semi
supervised
view
unsupervised
algorithms
word2vec
elmo
because
they
take
advantage
large
amounts
unlabeled
labeled
during
main
phase
cvt
algorithm
mix
examples
teaches
auxiliary
modules
see
restricted
views
match
predictions
seeing
share
intermediate
turn
particularly
effective
combined
five
tagging
dependency
parsing
achieving
trained
acquiring
labels
costly
motivating
need
techniques
successful
strategy
trains
do
incorporates
sensitive
code
available
https://github.com/
tensorflow
/<punct>
tree
master
research/
cvt_text
corpus
key
disadvantage
-the
attempts
generally
ones
older
continually
selftraining
historically
commonly
presents
anew
normal
acts
teacher
student
those
value
somewhat
tautological
already
computer
vision
addresses
adding
noise
robust
perturbations
applying
difficult
discrete
inputs
inspiration
multiview
consistent
across
adds
-neural
transform
-to
them
students
module
rep
resentations
attached
right
improving
unrestricted
make
shared
combines
idea
variety
architectures
focus
taggers
graph
parsers
combinatory
categorial
grammar
supertagging
partof
speech
chunking
vietnamese
previously
published
unified
outperforming
decreasing
present
pro-
agree
primary
washington
refers
reach
doing
contextual
produced
traveled
duced
θ<punct>
xi
alternates
minibatch
j<punct>
x<punct>
y|x
chosen
apart
choice
depend
come
soft
performing
inference
distance
distributions
kl
divergence
hold
fixed
back
propagate
imitate
vice
versa
enhancing
useful
making
sup
minimize
stochastic
descent
alternate
few
computationally
portion
building
cnn
contributes
little
overhead
change
fullytrained
combining
randomly
update
optimize
once
running
before
minibatches
benefit
creates
efficiency
slower
substantially
speedup
convergence
six
converge
50
decrease
relies
constructions
tosequence
bilstm
character
convolutional
applies
twolayer
runs
−t+1
sequences
producing
v.
th
onehidden
four
predicting
comes
predicts
past
analogous
ina
parse
treated
nodes
typed
directed
edges
connect
forming
describing
syntactic
receives
exactly
going
edge
u<punct>
head
type
treats
goal
predict
connects
gets
propagated
passed
separate
layers
bilinear
score
probabilities
mathematically
sis
scoring
relations
note
inmost
prior
missing
preceding
decoder
...
states
∝<punct>
eh
wα
¯<punct>
ht
weighted
ct
p(y
|y
<<punct>
softmax(w
decoders
mechanisms
restrict
zeroing
fraction
apply
forcing
get
vocabulary
hard
beam
search
distillation
procedure
backtranslation
against
strong
baselines
seven
ccg
ccgbank
conll-2000
ner
conll-2003
fgn
ontonotes
wall
street
journal
penn
treebank
converted
stanford
dependencies
version
3.3.0
englishvietnamese
iwslt
tokenized
bleu
tst2013
billion
benchmark
pool
details
listed
slightly
sees
unless
indicated
otherwise
1024-sized
512-sized
projection
appendix
hyperparameters
acting
removed
exposes
efficient
carefully
designing
possible
virtual
adversarial
vat
miyato
et
al
dropping
notably
adversarially
changes
successfully
separately
implementaiton
allow
own
found
crucial
win
taglm
enormous
1024
units
4096
require
fewer
steps
around
pass
pipelined
correctly
warner
occurs
bros
person
mistakenly
start
thousands
organization
par
faster
simpler
size
cvt+multi
further
elmo+multi
suspect
gains
leave
sharedencoder
margins
complicated
sharing
enough
big
amount
interestingly
conjunction
hypothesize
quickly
fit
primarily
perhaps
transfer
believe
alleviates
danger
forgetting
known
creating
plus
keep
old
unchanged
parallel
performs
worse
dev
generalization
generalize
plot
vs.
purely
continues
close
100
ac-
curacy
still
generalizes
halts
progress
earlier
suggests
sufficiently
multitask
ablation
briefly
explore
kinds
challenging
grows
decreases
25
fully
demonstrating
sizes
300
yield
greatly
contrast
scales
finding
appropriate
may
enable
limited
generalizable
freezing
sixth
tests
very
fast
far
slowest
sets
mt
frozen
means
pretrain
showing
skip
thought
slow
applications
noteworthy
pretraining
studied
earliest
round
retrained
consistentency
regularization
discussed
below
akin
tri
consistency
drawn
gaussian
transformations
horizontally
flipping
image
give
nearby
points
encouraging
distributional
smoothness
alterations
2017a
changing
separated
distinct
subsets
disjoint
necessarily
independent
supervision
measured
human
provided
classifiers
colorization
reinforcement
agents
environment
labeling
deterministically
constructed
extensive
focused
closely
manytask
developed
collobert
weston
2008
system
hashimoto
2017
arranged
hierarchically
according
linguistic
subramanian
purpose
downstream
achieve
excellent
minor
covered
bioes
scheme
smoothing
rate
0.1
omit
punctuation
practice
ptb
sd
coming
scored
way
implementation
heavily
off
google
nmt
tutorial
attribute
stronger
hyperparameter
tuning
5<punct>
unk
abeam
beneficial
provides
splits
ensure
never
overlaps
discarding
overlapping
exponential
moving
ema
variance
inaccuracy
random
initializations
sgd
momentum
initialized
glove
finetuned
were
worked
norm
perturbation
1.5
1.0
values
described
unable
rest
normalized
emeddings
competitively
rely
specifically
imagespecific
cropping
gans
due
nature
mixup
away
smoothly
interpolating
h(x
n×n×d
dimensions
index
spatial
coordinates
shallower
cnns
region
0,0
upper
corner
deeper
mean
jth
evaluated
cifar-10
previous
semisupervised
36
6<punct>
×<punct>
collection
patch
ranging
21
pixels
29
center
32
pixel
images
unsurprisingly
naturally
competitive
augmentation
translations
expose
manner
ideas
implemented
did
seem
initial
findings
pursue
pan
proper
adjustments
vs
hot
decreased
confidence
thresholding
confident
tried
ignores
versions
tracks
selfensembling
effect
attest
explored
hoped
act
regularizer
improved
regularizing
91.62
±<punct>
0.33
86.28
0.26
id
crf
90.65
0.15
86.84
0.19
94.7
shortcut
95.08
97.53
jmt
95.77
97.55
94.67
92.90
lm
95.96
0.08
91.71
0.10
0.03
†<punct>
96.37
0.05
91.93
92
deviations
included
choe
charniak
zhang
constituency
parses
access
annotations
denotes
14.41
0.30
-vat
13.15
10.55
vadd
-11.68
-10.07
0.11
sngt
π<punct>
13.62
0.17
11.00
0.36
12.49
9.89
0.34
wgan
-9.98
0.21
manifold
-10.26
0.32
23.61
0.60
19.61
0.56
ours
13.29
10.90
0.31
14.63
0.20
12.44
0.27
13.80
11.10
12.01
10.11
error
rates
done
estimation
grammatical
correction
gec
deployed
environments
accurately
correct
errors
learners
writing
spurious
corrections
fail
thereby
misleading
necessitates
instructors
selectively
intervene
re
poorly
corrected
feedback
automatic
employ
crafted
learner
references
improvements
ranking
automatically
correcting
various
written
aimed
corrective
precise
ability
mistakes
reality
precision
70
40
impressive
diversity
complexity
real
world
cases
erroneous
potentially
mislead
instructor
necessary
having
estimates
decide
check
fix
altogether
recorrect
lower
post
editing
users
extent
trusted
seek
assistance
sources
needed
refer
fluency
grammaticality
adequacy
effort
reference
maxmatch
dahlmeier
ng
2012
gleu
addressing
qe
predictor
estimator
transferred
implementing
release
summary
estimating
metric
utilized
became
studies
later
workshop
wmt
campaigns
onwards
assessment
simplification
generation
interpreters
misspellings
etc
manually
subjective
assess
gbms
gbm
detected
party
tools
determined
judges
https://github.com/nusnlp/neuqe
account
faithfulness
measurement
meaning
preservation
annotation
contrary
predictorestimator
quest
pairs
scorê
q<punct>
sand
hypothesis
h.
formulate
estimated
thatˆqthatˆ
thatˆq
utilizing
hypotheses
blackbox
neither
nor
internal
will
obtained
comparing
interested
hter
minimum
edit
operations
insertions
deletions
substitutions
shifts
edits
created
translated
highquality
experts
minimal
actual
substituted
edited
-score
phrase
made
nqe
places
behind
preliminary
texts
humancorrected
estimate
scorêscorê
pretrained
place
intuition
likely
assigned
minimally
rnn)-based
cnn)-based
tn
excluding
−j
vt
node
tin
|vt|
traditional
side
capture
additionally
employs
originally
gated
grus
multilayer
subsequently
enables
capturing
local
create
variant
helps
parallelization
speed
explained
secondary
−<punct>
paddings
beginning
kernel
width
ensures
include
computation
multistep
j−1
j+1
maxout
linearity
log
likelihood
every
rh
wt
column
h×|vt|
projects
wise
multiplication
§<punct>
4.1
gru
aggregate
concatenated
aggregated
projected
affine
clipped
range
0<punct>
sigmoid
filters
rectified
relu
nair
hinton
2010
sufficient
added
residual
connections
window
..
pooling
e<punct>
trainable
wu
×h
biases
bu
projecting
×1
σ<punct>
limit
square
mse
updated
rnnbased
cnnbased
stabilized
strategies
initialization
normalization
controlling
activations
experimental
setup
generated
lang-8
5,000
aside
validation
2.15
25.47
28.94
segmentation
1.28
18.50
21.88
decoding
12
nus
nucle
scripts
cambridge
certificate
examination
fce
yannakoudakis
2011
5.1
conll-2013
conll-2014
terp
scorer
src
hyp
lowest
among
xy
rr
replication
validated
5000
30,000
500-dimensional
700-dimensional
adadelta
optimizer
zeiler
batch
64
clip
gradients
-norm
threshold
5.0
dimension
adam
0.0005
averages
cr
cc
rc
17
quest++
lexical
descriptions
pearson
correlation
coefficient
pcc
recommendations
aggregates
absolute
mae
rmse
tail
ends
samples
weakness
william
significance
reflects
deviation
0.01
turns
appears
phraselevel
measure
boundaries
matching
hyper
settings
ensemble
smoothed
nlm
million
1.42
crawl
corpora
reported
12-best
document
chollampatt
5.4k
nu
cle
g&j
grundkiewicz
junczys
dowmunt
jggh
junczys-
c&n
spelling
spellcheck
56.43
public
alone
3.6k
rescorer
biased
observe
slight
drop
upon
retraining
logarithmic
scale
1.18
0.25
0.001
sign
bootstrap
sampling
margin
48.70
56.52
fce+conll
oracle
80.74
76.70
rescoring
discussion
whose
looking
you
answer
rightly
identified
giving
preposition
0.038
matches
your
suitable
0.003
0.322
grammatically
considers
faithful
impractical
coverall
coverage
noted
measures
study
able
count
basis
14
incredible
chance
watch
substitute
arbitrary
linearly
true
straight
line
reasonably
rankings
intuitions
underlying
judgments
christopher
qa
question
answering
substantial
complex
conceived
neu
ral
justify
heuristic
guides
ex
tractive
ingredients
awareness
composition
goes
beyond
bag
fastqa
meets
requirements
argue
surprising
puts
perspective
user
intersection
retrieval
ir
bridge
gap
engines
intelligent
assistants
aim
precisely
piece
sought
documents
snippets
extractive
deals
direct
creation
sparked
embedding-
encoding-
innovations
developing
powerful
builtin
what
calla
proposes
validates
decisions
lack
raises
justified
solely
empirical
observation
seemingly
questions
answerable
heuristics
let
activity
occur
st.
kazimierz
church
?<punct>
occurred
numerous
noble
palaces
churches
krasinski
palace
wilanow
1677
1696
seems
synthesis
understand
spans
st
1688
1692
aforementioned
guideline
derive
develop
bow)-and
crucially
computable
necessity
exhibited
impact
extending
fastqaext
n't
lead
systematic
bow
guided
ii
bottom
architectural
revealing
application
stateof
iii
depth
usefulness
iv
qualitative
constitutes
begin
defining
span
correspond
surrounded
fits
frequently
merely
construction
responsible
mapping
x.
lookup
s.t
max
overtime
reader
em-
lat
extracting
word(s
who
why
noun
year
leads
connected
intõ
z<punct>
rn
fc
potential
specified
maximum
surrounding
clues
nominal
modifiers
president
obama
")
apposition
concatenate
comprises
elementwise
˜<punct>
serve
feed
g<punct>
introduce
binary
wiq
else
formally
defines
eq
basic
similarity
rarely
appear
morphological
synonyms
latter
captured
softly
themselves
whereas
former
infrequent
occurrences
derivation
termfrequencies
prominent
band
windows
respective
e)-span
features)×3
windows)×2
summed
contextmatching
ctxt
intended
shortcomings
compositionality
sensible
harder
semantics
dramatically
reduced
directional
birnn
separates
demonstrated
birnns
recognizing
informing
locations
appearing
recognize
2.1
illustration
archi-
tecture
highway
want
aware
2.3
complete
input˜xinput˜
input˜x
n+2×l
accumulated
initialize
identity
mentioned
identical
wordby
2-layer
feedforward
conditional
conditioned
p(s
·<punct>
e|s
employing
k.
starts
broken
embedder
ndimensional
exception
coattention
gating
enriching
gathered
individually
omitted
divide
ranges
architecturally
fusion
exchange
passages
intra
inter
retrieved
fused
sake
brevity
serves
representative
100k
120k
news
stories
collected
squad
newsqa
exact
per
partial
tractable
bound
95
87
lowercase
tokenize
spacy
lemmas
alphanumeric
stopwords
throughout
150
mask
0.2
300-dimensional
optimization
−3
halved
whenever
dropped
mini
batches
whitespaces
exclusive
characters
inclusive
variational
checkpoints
1000
cutting
contexts
1500
cut
400
restriction
incrementally
plain
boost
stems
≈<punct>
15
extensions
probable
interesting
ways
dramatic
asked
track
informed
concrete
types
needs
remember
observed
differences
offer
nearly
reaches
half
partially
20%f1
73.7
64.7
chunk
71.0
62.5
73.3
75
78.9
70.8
clearly
demonstrate
strength
established
considering
simplicity
putting
submitting
3-layer
inline
observations
byword
dcn
timeand
reimplementation
twice
4×
looked
advantages
answered
incorrectly
589
wins
415
difference
kind
reasoning
aligns
marginal
incremental
presented
7.2
exist
besides
evaluations
inspection
analyse
55
abilities
alack
distinction
lexemes
meanings
preferences
ambiguities
temperature
fresno
july
8<punct>
1905
official
record
january
mistake
finegrained
resolution
binding
abbreviations
struggles
nested
separators
conjunctions
manual
reveals
35
attributed
44
88
analyzed
wrt
ofthe
cloze
dailymail
children
book
paved
reading
comprehension
thorough
revealed
too
easy
noisy
eliminate
mctest
trec
required
statistical
pipelines
exploitation
bases
paradigms
template
passage
bean
currently
linguistically
7.4
frequency
explain
tf
facilitate
repeat
equations
point
us
define
sim
tf(z|c
tf(z|q
derived
formula
frequencies
redefined
holds
finite
b.1
limitation
bottleneck
posed
synthesizing
referent
events
brittanee
drexel
mother
17-year
rochester
york
school
says
she
her
daughter
permission
goon
trip
marie
mom
mention
fusing
mentioning
11
fuse
13
call
associative
ˆ<punct>
initially
dot
sequentially
neighbouring
adapted
history
causing
assign
patterns
comparisons
perplexities
wikitext-2
51.1
44.3
entropies
text8
hutter
prize
1.19
bits
char
1.08
modes
audio
modelling
timeseries
dialogue
forecasting
music
elements
conditioning
autoregressive
successes
adapt
parts
repetition
pattern
handwriting
stay
style
voice
summarize
exploit
repeatedly
adapts
7.1
practical
wider
situations
7.3
varying
dynamically
motivation
generative
factorization
rule
factorizes
|x
t−1
longer
static
domains
generating
adapting
infer
approximate
i.
characterised
scenario
above
continuously
excerpt
topic
benchmarks
distinguish
pl
l)p
dl
along
shorter
n.
segments
segment
|θ
gives
l(s
truncated
propagation
repeated
backpropagated
computational
cost
conditions
evaluates
valid
regularities
adaptive
considered
caching
cache
pointer
parametric
fly
paired
i+1
tuple
adjusted
coincided
inner
xi+1
ω<punct>
scaling
interpolated
abase
nearest
neighbours
factorisation
observing
drawback
adjust
dynamics
successive
capability
updates
backpropagation
equivalent
modification
reduces
timesteps
decay
constantly
desirable
accomplishes
exponentially
η<punct>
λ<punct>
rmsprop
squared
near
had
collect
ms
nb
kth
becomes
rms
stabilization
proportionally
affect
greater
/λ
sure
exceed
batching
store
zeros
multiplies
replaces
avoids
intensive
tune
followup
lengths
marcus
1993
merity
2017b
articles
929k
vocab
10k
awd
chainer
650
regularized
eval
default
tables
asgd
optimisation
roughly
33k
shuffled
92.0
charcnn
perplexity
500
500×500
250k
starting
processed
spanish
european
parliament
timescales
gained
10000
plots
sequenced
handles
gave
noticeable
hundred
continued
grow
maximized
viewing
3k
drew
switched
resembled
characteristics
entirety
sample
explores
develops
broadcast
paragraph
occurrence
translating
relational
relationships
spaces
canonical
databases
transe
interpreting
operating
proves
link
25k
graphs
exists
relationship
play
pivotal
members
friendship
recommender
products
buying
rating
reviewing
searching
kbs
freebase
geneontology
predicates
facts
involving
focuses
wordnet
tool
requiring
extra
boils
connectivity
notion
locality
structural
friend
liked
star
wars
mayor
titanic
hoc
assumptions
descriptive
difficulty
involve
generic
heterogeneous
item
clustering
trivial
similarities
singlerelational
designed
latent
attributes
pointed
constituents
domain
nonparametric
bayesian
blockmodel
tensor
collective
expressivity
universality
frameworks
energy
expense
interpret
costs
subject
underfitting
convex
minima
solved
matter
almost
expressive
yet
trade
offs
scalability
depends
parameterization
indeed
trees
siblings
height
organized
axis
parent
child
equivalence
sibling
chose
budget
free
1-to-1
capital
countries
cities
coincidentally
willingly
intention
enforce
hierarchies
realworld
light
remainder
discuss
conclude
sketching
directions
rel
γ<punct>
dim
loop
←<punct>
e/
←sample(s
//
∅<punct>
triplets
9<punct>
h,,,t
corrupted
triplet
w.r.t
h,,,t),(h
letters
boldface
functional
induced
-labeled
neighbor
faraway
d(h
dissimilarity
criterion
><punct>
favors
carried
mode
constraint
prevents
trivially
artificially
norms
detailed
iteration
sampled
constant
stopped
body
here
structured
se
fb15k
millions
rare
belong
subspace
matrices
asymmetry
d(x
g(x
→<punct>
strictly
operators
reproduce
constraining
+1th
transe.
expressiveness
synonymous
4.3
confirm
s(h
k×k
depending
euclidean
involves
simplify
compensate
nevertheless
formulation
series
2-way
interactions
drawbacks
3-way
tare
smallscale
kinships
area
under
curve
ternary
handling
properly
frequent
intuitively
usable
dictionary
thesaurus
synsets
senses
wn
nn
hypernym
musical
notation
huge
1.2
80
selected
wikilinks
database
/people
nationality
reverses
592,213
14,951
1,345
wanted
led
fb1m.
protocol
dissimilarities
energies
sorted
ascending
rank
removing
ranks
hits@10
proportion
ranked
indicative
flawed
counted
behavior
list
possibly
raw
newer
filt
unstructured
aversion
mono
rescal
sme(linear)/sme(bilinear
lfm
alternating
compares
theoretical
magnitude
sme(linear
sme(bilinear
rapidly
fb1
reasons
duration
250
2000
stopping
1,000
factors
200
optimal
configurations
000
open
project
webpage
displays
clearer
trends
counterparts
wide
promising
89
40k
34
runner
optimized
showed
proposal
165
35.5
50k
127
42.7
managed
capabilities
poor
yields
clusters
cooccurring
involved
guesses
tails
argument
categorized
cardinalities
arguments
1-to
to-1
ahead
heads
classified
3.2
26.2
22.7
28.3
22.8
expect
must
uncover
linked
upgrading
brings
move
cluster
spectacular
depicted
always
reflect
checking
fb15k-40rel
contained
353,788
53,266
40,000
45,159
conducted
fresh
unseen
unknown
course
fastest
18
monotonically
modify
focusing
parametrization
competing
highly
scalable
whereby
remains
unclear
adequately
breaking
concentrates
inspired
prove
fruitfully
inserted
delayed
tabsa)-extraction
augmented
utilising
chains
tabsa
demonstrates
expectation
overt
safety
loc1
loc2
bet
secure
expensive
nomalised
locn
t)absa
keeping
ineffective
gram
captures
sequencing
leveraging
largely
occupies
slot
accessed
suggest
granularity
cbt
centred
operate
until
phrases
triggers
succeeding
bear
signal
equipped
effectiveness
description
interleaved
frame
loc1,safety
goldstandard
loc1,transit
tracking
updating
maintains
progresses
delay
recurrence
chain
φ<punct>
circled
depict
content
hadamard
resp
controlled
i−1
v·d
carries
differ
causes
keys
turned
influence
arrows
denoting
ware
intensity
˚<punct>
unnormalised
essentially
determines
factoring
tracked
normalisation
allowing
constrained
cosine
deemed
date
directionality
enabling
polarityˆypolarityˆ
polarityˆy
watt
transit
constituent
comparision
entnet
entnets
henaff
differs
respects
opposed
responsibility
admittedly
babi
coarse
demand
obvious
decouple
duty
transitions
now
dedicated
burden
monitoring
tailoring
trying
detecting
targetaspect
215
862
tuples
bold
s.
ultimately
configuration
initialise
300-d
42b
1.9
pennington
tokenisation
nltk
folding
800
ftrl
optimiser
128
300×3
300×300
technique
curb
regularise
penalty
λr
empirically
http://nlp.stanford.edu/data/glove
42b.300d.zip
tying
damages
deterioration
experimented
unbalanced
lr
tag
loc
lstm+ta+sa
senticlstm
implement
adopt
70/10/20
auc
ignoring
hybrid
gt
domainindependent
reliant
domainspecific
esp
underlining
visualise
colour
lovely
town
plenty
restaurants
dinning
importantly
recognises
keeps
overlooked
ultimate
false
distant
76
77
78
79
#<punct>
sensitivity
tends
tendency
apparent
unconstrained
suffers
insufficient
drops
76.6
0.4
≥<punct>
stable
multimodal
actively
field
opportunity
proceeds
fashion
modalities
utterances
conventional
reduction
utterance
video
clips
2.4
-but
-into
booming
languages
chinese
broadly
symbolic
lexicons
ontologies
multiword
cooccurrence
subjectivity
microtext
raised
scientific
community
leading
exciting
business
remarkable
financial
political
health
tourism
profiling
manufacturing
supply
communication
emotion
de
silva
chen
visual
bimodal
yielded
unimodal
decision
exploring
wollmer
eyben
liang
poria
mkl
forth
extracts
fuses
zadeh
tensors
trimodal
correlations
accomplish
plugged
solving
majority
simplistic
redundant
major
devise
t+v
t+a
a+v.
3.4
penultimate
3.3
subsections
transcripts
videos
maps
neurons
convolution
subsequent
expands
30
hz
sliding
opensmile
pitch
signals
standardization
normaliza-
quartile
slope
is13-compare
file
purposes
6392
try
temporal
frames
3d
specially
object
motivates
vid
3×f
×h×w
rgb
channels
cardinality
flt
fm×3×f
×f
×fw
2d
fil
ter
translates
conv
selects
receive
3×3×3
consideration
items
pad
dummy
modality
eqs
av
d2
nt
c×d
categorical
fm
grum(fm
19
22
estm
odel(v
23
maptospace(xz
24
gz
tanh(wzxz
bz
return
26
bimodalfusion(gz
27
fz
31
trimodalfusion(fz
testmodel(v
37
learnt
3.6
eight
speakers
svm
clm
speaker
fair
reran
discouraged
hfusion
cmu
mosi
sections
forwarded
chfusion
4.1.1
font
signifies
stands
sot
outperformed
scenarios
1.8
inferior
trend
4.2
supports
strongest
indication
dampens
aligned
expectations
facial
muscle
movements
carry
emotional
nuances
thanks
power
think
incapable
formed
outer
wherein
1,2
utilizes
iemocap
4.1.2
integrated
helped
combinations
a+v
evident
3.5
moon
bigger
budgets
huh
discusses
movie
twilight
textually
abundant
frown
out-
put
4×d
andˆyandˆ
andˆy
imbalanced
richer
2.2
superiority
degree
calculations
tfn
a+v+t
inclusion
levels
hierarchy
comprehensive
plan
ncsu
sas
ning
hinder
twitter
string
participated
nut
ization
competition
baldwin
customer
reviews
forum
discussions
messages
discovery
crowdsourcing
posted
company
advertising
amazon
shopper
lot
manufacturers
retailers
unfortunately
ungrammatical
structures
nonstandard
automated
ark
tagger
usage
lexicon
describes
lists
concludes
tweet
…<punct>
processes
normalize
forms
calculates
loveyourcar
à
love
car
subsection
ur
looove
niiice
nice
luv
welcme
welcome
strings
jaccard
ngrams
contiguous
gaps
prepend
append
$<punct>
|<punct>
cat
n=2
k=1
lo
ov
ve$
l|v
o|e
oo
l|o
o|o
o|v
ca
ar$
c|r
at$
c|t
f(s
í<punct>
µí±
µí±í
µí±í
µí±í
µí±í
µí±í
µí±¡í
¦<punct>
µí
°<punct>
½í
µí±í
µí±í
¼í
µí±í
µí±í
µí±¥
µí±
union
4/9
0.44
calculating
bigrams
8/13
0.615
calculation
trigrams
1-skip
2-skip
penalizes
insertion
deletion
substitution
levenshtein
aaabaa
aaaabaa
aa
ab
ba
aa$
a|a
a|b
b|a
mitigate
fortunately
repetitive
penalizing
denominator
loooooove
heavier
bounded
o(l(s
quadratic
preprocessing
repetitions
calculated
handle
lolol
hash
table
sorting
o(l*log(l
query
narrow
approximating
imposing
restrictions
forest
insensitive
percentage
normalizing
2/3
0.67
1/3
caused
misspelling
seperate
abbreviation
lol
laughing
loud
motivations
90
gimpel
i-1
empty
inversely
proportional
train_data_20150430.json
scowl.american.70
occupying
builds
top-3
dictionaries
leak
splitting
67
33
wnut
selection
test_truth.json
concealed
0.0521
constitute
0.0129
counterintuitive
conservative
mere
increase
brooklyn
brklyn
helpful
differentiate
favor
yes
assigns
conclusions
participants
room
includes
choosing
reinforced
abstractive
summarization
attentional
summaries
incoherent
rl
exhibit
exposure
bias"-they
readable
daily
mail
obtains
41.16
rouge-1
retaining
condensing
quantities
aid
digests
copying
rephrasing
rouge
summarizing
duc-2004
multisentence
unnatural
nyt
functions
marked
attending
repeating
records
rewards
policy
article
operator
reads
fwd
bwd
emb
he
previouslygenerated
sames
overlong
returning
decoded
intradecoder
modifying
copy
switch
decides
stated
p(u
1)p(y
|u
0)p(y
ofvocabulary
tokengeneration
inan
2.5
avoidance
trigram
force
outputting
minimizes
minimization
ml
phenomenon
captioning
cider
rennie
discrepancy
accumulating
arrange
paraphrases
orders
flexibility
remedy
maximizes
maximizing
greedy
r(y
reward
baselinê
mixed
optimizing
guarantee
readability
game
overlap
assist
factor
performant
onto
agent
interact
maximize
actions
obtaining
differentiable
meteor
reinforce
arranging
degrees
freedom
duc
varied
group
wording
abstracts
abstraction
paraphrase
formats
complement
disable
intraattention
ml+rl
16
options
f-1
rouge-2
porter
stemmer
option
reached
ending
abruptly
quantitative
explains
lead-3
beats
mixedobjective
theirs
inhuman
know
evaluator
rated
evaluators
mechanical
turk
detrimental
rl+ml
issues
measurements
judgment
suited
saw
a.1
headline
byline
tokenizer
marks
singular
plural
semicolons
photo
chart
drawing
periods
format
549
limiting
a.2
publication
chronological
589,284
32,736
32,739
reproducible
production
a.3
recognizer
misc
supervise
're
0.9984
200-dimensional
400-dimensional
150,000
100-dimensional
16.9
0.0001
