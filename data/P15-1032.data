title	SECTITLE_END
Structured	SEC_START
Training	SEC_CONTENT
for	SEC_CONTENT
Neural	SEC_CONTENT
Network	SEC_CONTENT
Transition	SEC_CONTENT
-	SEC_CONTENT
Based	SEC_CONTENT
Parsing	SEC_END
abstract	SECTITLE_END
We	SEC_START
present	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
neural	task
network	task
transition	task
-	task
based	task
dependency	task
parsing	task
.	SEC_CONTENT
We	SEC_CONTENT
learn	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
representation	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
gold	SEC_CONTENT
corpus	SEC_CONTENT
augmented	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
automatically	SEC_CONTENT
parsed	SEC_CONTENT
sentences	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
this	SEC_CONTENT
fixed	SEC_CONTENT
network	SEC_CONTENT
representation	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
learn	SEC_CONTENT
a	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
struc	SEC_CONTENT
-	SEC_CONTENT
tured	SEC_CONTENT
perceptron	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
-	SEC_CONTENT
search	SEC_CONTENT
decoding	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
parser	SEC_CONTENT
reaches	SEC_CONTENT
94.26	SEC_CONTENT
%	SEC_CONTENT
un	SEC_CONTENT
-	SEC_CONTENT
labeled	SEC_CONTENT
and	SEC_CONTENT
92.41	SEC_CONTENT
%	SEC_CONTENT
labeled	SEC_CONTENT
attachment	SEC_CONTENT
accuracy	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
knowledge	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
Stanford	SEC_CONTENT
Dependencies	SEC_CONTENT
to	SEC_CONTENT
date	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
provide	SEC_CONTENT
in	SEC_CONTENT
-	SEC_CONTENT
depth	SEC_CONTENT
ablative	SEC_CONTENT
analysis	SEC_CONTENT
to	SEC_CONTENT
determine	SEC_CONTENT
which	SEC_CONTENT
aspects	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
provide	SEC_CONTENT
the	SEC_CONTENT
largest	SEC_CONTENT
gains	SEC_CONTENT
inaccuracy	SEC_CONTENT
.	SEC_END
Introduction	SECTITLE_END
Syntactic	SEC_START
analysis	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
central	SEC_CONTENT
problem	SEC_CONTENT
in	SEC_CONTENT
language	SEC_CONTENT
understanding	SEC_CONTENT
that	SEC_CONTENT
has	SEC_CONTENT
received	SEC_CONTENT
a	SEC_CONTENT
tremendous	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
attention	SEC_CONTENT
.	SEC_CONTENT
Lately	SEC_CONTENT
,	SEC_CONTENT
dependency	task
parsing	task
has	SEC_CONTENT
emerged	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
popular	SEC_CONTENT
approach	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
problem	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
availability	SEC_CONTENT
of	SEC_CONTENT
dependency	SEC_CONTENT
treebanks	SEC_CONTENT
in	SEC_CONTENT
many	SEC_CONTENT
languages	SEC_CONTENT
(	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
efficiency	SEC_CONTENT
of	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
.	SEC_END
Transition	SEC_START
-	SEC_CONTENT
based	SEC_CONTENT
parsers	SEC_CONTENT
)	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
shown	SEC_CONTENT
to	SEC_CONTENT
provide	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
balance	SEC_CONTENT
between	SEC_CONTENT
efficiency	SEC_CONTENT
and	SEC_CONTENT
accuracy	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
transition	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
parsing	SEC_CONTENT
,	SEC_CONTENT
sentences	SEC_CONTENT
are	SEC_CONTENT
processed	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
linear	SEC_CONTENT
left	SEC_CONTENT
to	SEC_CONTENT
right	SEC_CONTENT
pass	SEC_CONTENT
;	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
position	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
parser	SEC_CONTENT
needs	SEC_CONTENT
to	SEC_CONTENT
choose	SEC_CONTENT
from	SEC_CONTENT
a	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
actions	SEC_CONTENT
defined	SEC_CONTENT
by	SEC_CONTENT
the	SEC_CONTENT
transition	SEC_CONTENT
strategy	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
greedy	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
classifier	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
independently	SEC_CONTENT
decide	SEC_CONTENT
which	SEC_CONTENT
transition	SEC_CONTENT
to	SEC_CONTENT
take	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
local	SEC_CONTENT
features	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
parse	SEC_CONTENT
configuration	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
classifier	SEC_CONTENT
typically	SEC_CONTENT
uses	SEC_CONTENT
hand	SEC_CONTENT
-	SEC_CONTENT
engineered	SEC_CONTENT
features	SEC_CONTENT
and	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
individual	SEC_CONTENT
transitions	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
gold	SEC_CONTENT
transition	SEC_CONTENT
sequence	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
extremely	SEC_CONTENT
fast	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
greedy	SEC_CONTENT
models	SEC_CONTENT
typically	SEC_CONTENT
suffer	SEC_CONTENT
from	SEC_CONTENT
search	SEC_CONTENT
errors	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
inability	SEC_CONTENT
to	SEC_CONTENT
recover	SEC_CONTENT
from	SEC_CONTENT
incorrect	SEC_CONTENT
decisions	SEC_CONTENT
.	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
beamsearch	SEC_CONTENT
decoding	SEC_CONTENT
algorithm	SEC_CONTENT
utilizing	SEC_CONTENT
the	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
algorithm	SEC_CONTENT
can	SEC_CONTENT
greatly	SEC_CONTENT
improve	SEC_CONTENT
accuracy	SEC_CONTENT
.	SEC_CONTENT
Nonetheless	SEC_CONTENT
,	SEC_CONTENT
significant	SEC_CONTENT
manual	SEC_CONTENT
feature	SEC_CONTENT
engineering	SEC_CONTENT
was	SEC_CONTENT
required	SEC_CONTENT
before	SEC_CONTENT
transitionbased	SEC_CONTENT
systems	SEC_CONTENT
provided	SEC_CONTENT
competitive	SEC_CONTENT
accuracy	SEC_CONTENT
with	SEC_CONTENT
graph	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
parsers	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
only	SEC_CONTENT
by	SEC_CONTENT
incorporating	SEC_CONTENT
graph	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
scoring	SEC_CONTENT
functions	SEC_CONTENT
were	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
exceed	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
graph	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_END
In	SEC_START
contrast	SEC_CONTENT
to	SEC_CONTENT
these	SEC_CONTENT
carefully	SEC_CONTENT
hand	SEC_CONTENT
-	SEC_CONTENT
tuned	SEC_CONTENT
approaches	SEC_CONTENT
,	SEC_CONTENT
recently	SEC_CONTENT
presented	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
version	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
greedy	SEC_CONTENT
transition	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
parser	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
their	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
feedforward	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
make	SEC_CONTENT
the	SEC_CONTENT
transition	SEC_CONTENT
decisions	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
has	SEC_CONTENT
the	SEC_CONTENT
power	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
arbitrary	SEC_CONTENT
combinations	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
atomic	SEC_CONTENT
inputs	SEC_CONTENT
,	SEC_CONTENT
thereby	SEC_CONTENT
eliminating	SEC_CONTENT
the	SEC_CONTENT
need	SEC_CONTENT
for	SEC_CONTENT
hand	SEC_CONTENT
-	SEC_CONTENT
engineered	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
Furthermore	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
uses	SEC_CONTENT
a	SEC_CONTENT
distributed	SEC_CONTENT
representation	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
model	SEC_CONTENT
lexical	SEC_CONTENT
,	SEC_CONTENT
part	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
speech	SEC_CONTENT
(	SEC_CONTENT
POS	metric
)	SEC_CONTENT
tag	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
arc	SEC_CONTENT
label	SEC_CONTENT
similarities	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
continuous	SEC_CONTENT
space	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
although	SEC_CONTENT
their	SEC_CONTENT
model	SEC_CONTENT
outperforms	SEC_CONTENT
its	SEC_CONTENT
greedy	SEC_CONTENT
hand	SEC_CONTENT
-	SEC_CONTENT
engineered	SEC_CONTENT
counterparts	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
competitive	SEC_CONTENT
with	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
for	SEC_CONTENT
structured	SEC_CONTENT
search	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
combine	SEC_CONTENT
the	SEC_CONTENT
representational	SEC_CONTENT
power	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
superior	SEC_CONTENT
search	SEC_CONTENT
enabled	SEC_CONTENT
by	SEC_CONTENT
structured	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
inference	SEC_CONTENT
,	SEC_CONTENT
making	SEC_CONTENT
our	SEC_CONTENT
parser	SEC_CONTENT
one	SEC_CONTENT
of	SEC_CONTENT
the	task
most	task
accurate	task
dependency	task
parsers	task
to	SEC_CONTENT
date	SEC_CONTENT
.	SEC_CONTENT
Training	SEC_CONTENT
and	SEC_CONTENT
testing	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
transition	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
parser	SEC_CONTENT
achieves	SEC_CONTENT
93.99	SEC_CONTENT
%	SEC_CONTENT
unlabeled	SEC_CONTENT
(	SEC_CONTENT
UAS	SEC_CONTENT
)	SEC_CONTENT
/	SEC_CONTENT
92.05	SEC_CONTENT
%	SEC_CONTENT
labeled	SEC_CONTENT
(	SEC_CONTENT
LAS	SEC_CONTENT
)	SEC_CONTENT
attachment	SEC_CONTENT
accuracy	SEC_CONTENT
,	SEC_CONTENT
outperforming	SEC_CONTENT
the	SEC_CONTENT
93.22	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
/	SEC_CONTENT
91.02	SEC_CONTENT
%	SEC_CONTENT
LAS	SEC_CONTENT
of	SEC_CONTENT
and	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
by	SEC_CONTENT
incorporating	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
into	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
further	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
94.26	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
/	SEC_CONTENT
92.41	SEC_CONTENT
%	SEC_CONTENT
LAS	SEC_CONTENT
(	SEC_CONTENT
93.46	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
/	SEC_CONTENT
91.49	SEC_CONTENT
%	SEC_CONTENT
LAS	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
greedy	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
In	SEC_START
our	SEC_CONTENT
approach	SEC_CONTENT
we	SEC_CONTENT
start	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
basic	SEC_CONTENT
structure	SEC_CONTENT
of	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
deeper	SEC_CONTENT
architecture	SEC_CONTENT
and	SEC_CONTENT
improvements	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
optimization	SEC_CONTENT
procedure	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
modifications	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
increase	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
greedy	SEC_CONTENT
model	SEC_CONTENT
by	SEC_CONTENT
as	SEC_CONTENT
much	SEC_CONTENT
as	SEC_CONTENT
1	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
in	SEC_CONTENT
prior	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
model	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
individual	SEC_CONTENT
parse	SEC_CONTENT
actions	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
use	SEC_CONTENT
these	SEC_CONTENT
probabilities	SEC_CONTENT
directly	SEC_CONTENT
for	SEC_CONTENT
prediction	SEC_CONTENT
.	SEC_CONTENT
Instead	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
activations	SEC_CONTENT
from	SEC_CONTENT
all	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
and	SEC_CONTENT
early	SEC_CONTENT
updates	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
,	SEC_CONTENT
this	SEC_CONTENT
structured	SEC_CONTENT
learning	SEC_CONTENT
approach	SEC_CONTENT
significantly	SEC_CONTENT
improves	SEC_CONTENT
parsing	SEC_CONTENT
accuracy	SEC_CONTENT
by	SEC_CONTENT
0.8	SEC_CONTENT
%	SEC_CONTENT
.	SEC_END
An	SEC_START
additional	SEC_CONTENT
contribution	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
effective	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
leverage	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
networks	SEC_CONTENT
are	SEC_CONTENT
known	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
very	SEC_CONTENT
well	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
presence	SEC_CONTENT
of	SEC_CONTENT
large	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
;	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
obtaining	SEC_CONTENT
more	SEC_CONTENT
expert	SEC_CONTENT
-	SEC_CONTENT
annotated	SEC_CONTENT
parse	SEC_CONTENT
trees	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
expensive	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
this	SEC_CONTENT
end	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
large	SEC_CONTENT
quantities	SEC_CONTENT
of	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
confidence	SEC_CONTENT
parse	SEC_CONTENT
trees	SEC_CONTENT
by	SEC_CONTENT
parsing	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
two	SEC_CONTENT
different	SEC_CONTENT
parsers	SEC_CONTENT
and	SEC_CONTENT
selecting	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
for	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
parsers	SEC_CONTENT
produced	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
trees	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
approach	SEC_CONTENT
is	SEC_CONTENT
known	SEC_CONTENT
as	SEC_CONTENT
"	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
benefits	SEC_CONTENT
our	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
parser	SEC_CONTENT
significantly	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
other	SEC_CONTENT
approaches	SEC_CONTENT
.	SEC_CONTENT
By	SEC_CONTENT
adding	SEC_CONTENT
10	SEC_CONTENT
million	SEC_CONTENT
automatically	SEC_CONTENT
parsed	SEC_CONTENT
tokens	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
improve	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
parsers	SEC_CONTENT
by	SEC_CONTENT
almost	SEC_CONTENT
∼1.0	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
web	SEC_CONTENT
domain	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
We	SEC_START
provide	SEC_CONTENT
an	SEC_CONTENT
extensive	SEC_CONTENT
exploration	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
Section	SEC_CONTENT
5	SEC_CONTENT
through	SEC_CONTENT
ablative	SEC_CONTENT
analysis	SEC_CONTENT
and	SEC_CONTENT
other	SEC_CONTENT
retrospective	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
goals	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
provide	SEC_CONTENT
guidance	SEC_CONTENT
for	SEC_CONTENT
future	SEC_CONTENT
refinements	SEC_CONTENT
and	SEC_CONTENT
improvements	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
architecture	SEC_CONTENT
and	SEC_CONTENT
modeling	SEC_CONTENT
choices	SEC_CONTENT
we	SEC_CONTENT
introduce	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
.	SEC_END
Finally	SEC_START
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
representations	SEC_CONTENT
have	SEC_CONTENT
along	SEC_CONTENT
history	SEC_CONTENT
in	SEC_CONTENT
syntactic	task
parsing	task
;	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
like	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
network	SEC_CONTENT
avoids	SEC_CONTENT
any	SEC_CONTENT
recurrent	SEC_CONTENT
structure	SEC_CONTENT
so	SEC_CONTENT
as	SEC_CONTENT
to	SEC_CONTENT
keep	SEC_CONTENT
inference	SEC_CONTENT
fast	SEC_CONTENT
and	SEC_CONTENT
efficient	SEC_CONTENT
and	SEC_CONTENT
to	SEC_CONTENT
allow	SEC_CONTENT
the	SEC_CONTENT
use	SEC_CONTENT
of	SEC_CONTENT
simple	SEC_CONTENT
backpropagation	SEC_CONTENT
to	SEC_CONTENT
compute	SEC_CONTENT
gradients	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
not	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
to	SEC_CONTENT
apply	SEC_CONTENT
structured	SEC_CONTENT
training	SEC_CONTENT
to	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
e.g.	SEC_CONTENT
and	SEC_CONTENT
for	SEC_CONTENT
Conditional	SEC_CONTENT
Random	SEC_CONTENT
Field	SEC_CONTENT
(	SEC_CONTENT
CRF	SEC_CONTENT
)	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
neural	SEC_CONTENT
networks	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
paper	SEC_CONTENT
ex-	SEC_CONTENT
Features	SEC_CONTENT
Extracted	SEC_CONTENT
early	SEC_CONTENT
updates	SEC_CONTENT
(	SEC_CONTENT
section	SEC_CONTENT
3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Structured	SEC_CONTENT
learning	SEC_CONTENT
reduces	SEC_CONTENT
bias	SEC_CONTENT
and	SEC_CONTENT
significantly	SEC_CONTENT
improves	SEC_CONTENT
parsing	SEC_CONTENT
accuracy	SEC_CONTENT
by	SEC_CONTENT
0.6	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
demonstrate	SEC_CONTENT
empirically	SEC_CONTENT
that	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
scores	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
does	SEC_CONTENT
notwork	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
,	SEC_CONTENT
perhaps	SEC_CONTENT
because	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
bias	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_END
A	SEC_START
second	SEC_CONTENT
contribution	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
effective	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
leverage	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
other	SEC_CONTENT
parsers	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
networks	SEC_CONTENT
are	SEC_CONTENT
known	SEC_CONTENT
to	SEC_CONTENT
perform	SEC_CONTENT
very	SEC_CONTENT
well	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
presence	SEC_CONTENT
of	SEC_CONTENT
large	SEC_CONTENT
amounts	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
however	SEC_CONTENT
unlikely	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
hand	SEC_CONTENT
parsed	SEC_CONTENT
data	SEC_CONTENT
will	SEC_CONTENT
increase	SEC_CONTENT
significantly	SEC_CONTENT
because	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
high	SEC_CONTENT
cost	SEC_CONTENT
for	SEC_CONTENT
syntactic	SEC_CONTENT
annotations	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
this	SEC_CONTENT
end	SEC_CONTENT
we	SEC_CONTENT
generate	SEC_CONTENT
large	SEC_CONTENT
quantities	SEC_CONTENT
of	SEC_CONTENT
high	SEC_CONTENT
-	SEC_CONTENT
confidence	SEC_CONTENT
parse	SEC_CONTENT
trees	SEC_CONTENT
by	SEC_CONTENT
parsing	SEC_CONTENT
an	SEC_CONTENT
unlabeled	SEC_CONTENT
corpus	SEC_CONTENT
and	SEC_CONTENT
selecting	SEC_CONTENT
only	SEC_CONTENT
the	SEC_CONTENT
sentences	SEC_CONTENT
on	SEC_CONTENT
which	SEC_CONTENT
two	SEC_CONTENT
different	SEC_CONTENT
parsers	SEC_CONTENT
produced	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
parse	SEC_CONTENT
trees	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
idea	SEC_CONTENT
comes	SEC_CONTENT
from	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
while	SEC_CONTENT
applicable	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
parsers	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
benefits	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
parsers	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
models	SEC_CONTENT
with	SEC_CONTENT
discrete	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
Adding	SEC_CONTENT
10	SEC_CONTENT
million	SEC_CONTENT
automatically	SEC_CONTENT
parsed	SEC_CONTENT
tokens	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
improves	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
parsers	SEC_CONTENT
further	SEC_CONTENT
by	SEC_CONTENT
0.7	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
final	SEC_CONTENT
greedy	SEC_CONTENT
parser	SEC_CONTENT
achieves	SEC_CONTENT
an	SEC_CONTENT
unlabeled	SEC_CONTENT
attachment	SEC_CONTENT
score	SEC_CONTENT
(	SEC_CONTENT
UAS	metric
)	SEC_CONTENT
of	SEC_CONTENT
93.46	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
a	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
abeam	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
8	SEC_CONTENT
produces	SEC_CONTENT
an	SEC_CONTENT
UAS	SEC_CONTENT
of	SEC_CONTENT
94.08	SEC_CONTENT
%	SEC_CONTENT
(	SEC_CONTENT
section	SEC_CONTENT
4	SEC_CONTENT
.	SEC_CONTENT
To	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
knowledge	SEC_CONTENT
,	SEC_CONTENT
these	SEC_CONTENT
are	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
very	SEC_CONTENT
best	SEC_CONTENT
dependency	SEC_CONTENT
accuracies	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_END
We	SEC_START
provide	SEC_CONTENT
an	SEC_CONTENT
extensive	SEC_CONTENT
exploration	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
in	SEC_CONTENT
section	SEC_CONTENT
5	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
ablation	SEC_CONTENT
experiments	SEC_CONTENT
we	SEC_CONTENT
tease	SEC_CONTENT
apart	SEC_CONTENT
our	SEC_CONTENT
various	SEC_CONTENT
contributions	SEC_CONTENT
and	SEC_CONTENT
modeling	SEC_CONTENT
choices	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
shed	SEC_CONTENT
some	SEC_CONTENT
light	SEC_CONTENT
on	SEC_CONTENT
what	SEC_CONTENT
matters	SEC_CONTENT
in	SEC_CONTENT
practice	SEC_CONTENT
.	SEC_CONTENT
Neural	SEC_CONTENT
network	SEC_CONTENT
representations	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
structured	SEC_CONTENT
models	SEC_CONTENT
before	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
have	SEC_CONTENT
also	SEC_CONTENT
been	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
syntactic	task
parsing	task
,	SEC_CONTENT
alas	SEC_CONTENT
with	SEC_CONTENT
fairly	SEC_CONTENT
complex	SEC_CONTENT
architectures	SEC_CONTENT
and	SEC_CONTENT
constraints	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
work	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
hand	SEC_CONTENT
introduces	SEC_CONTENT
a	SEC_CONTENT
general	SEC_CONTENT
approach	SEC_CONTENT
for	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
representation	SEC_CONTENT
and	SEC_CONTENT
achieves	SEC_CONTENT
stateof	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
parsing	SEC_CONTENT
results	SEC_CONTENT
for	SEC_CONTENT
English	SEC_CONTENT
.	SEC_END
Neural	SECTITLE_START
Network	SECTITLE_CONTENT
Model	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
describe	SEC_CONTENT
the	SEC_CONTENT
architecture	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
separate	SEC_CONTENT
the	task
embedding	task
processing	task
to	SEC_CONTENT
a	SEC_CONTENT
distinct	SEC_CONTENT
"	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
"	SEC_CONTENT
for	SEC_CONTENT
clarity	SEC_CONTENT
of	SEC_CONTENT
presentation	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
upon	SEC_CONTENT
that	SEC_CONTENT
of	SEC_CONTENT
Chen	SEC_CONTENT
and	SEC_CONTENT
Manning	SEC_CONTENT
Feature	SEC_CONTENT
extraction	SEC_END
Embedding	SEC_START
Layer	SEC_END
Configuration	SECTITLE_END
Hidden	SEC_START
Layers	SEC_END
Softmax	SECTITLE_START
Layer	SECTITLE_END
Perceptron	SEC_START
Layer	SEC_CONTENT
argmax	SEC_CONTENT
:	SEC_CONTENT
Schematic	SEC_CONTENT
overview	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
:	SEC_CONTENT
Features	SEC_CONTENT
used	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
si	SEC_CONTENT
and	SEC_CONTENT
bi	SEC_CONTENT
are	SEC_CONTENT
elements	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
stack	SEC_CONTENT
and	SEC_CONTENT
buffer	SEC_CONTENT
,	SEC_CONTENT
respectively	SEC_CONTENT
.	SEC_CONTENT
lci	SEC_CONTENT
indicates	SEC_CONTENT
i'th	SEC_CONTENT
leftmost	SEC_CONTENT
child	SEC_CONTENT
and	SEC_CONTENT
rci	SEC_CONTENT
the	SEC_CONTENT
i'th	SEC_CONTENT
rightmost	SEC_CONTENT
child	SEC_CONTENT
.	SEC_CONTENT
Features	SEC_CONTENT
that	SEC_CONTENT
are	SEC_CONTENT
included	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
those	SEC_CONTENT
from	SEC_CONTENT
Chen	SEC_CONTENT
and	SEC_CONTENT
Manning	SEC_CONTENT
are	SEC_CONTENT
marked	SEC_CONTENT
with	SEC_CONTENT
?	SEC_CONTENT
.	SEC_CONTENT
Groups	SEC_CONTENT
indicates	SEC_CONTENT
which	SEC_CONTENT
values	SEC_CONTENT
were	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
each	SEC_CONTENT
feature	SEC_CONTENT
location	SEC_CONTENT
(	SEC_CONTENT
e.g.	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
tags	SEC_CONTENT
,	SEC_CONTENT
labels	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
(	SEC_START
2014	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
discuss	SEC_CONTENT
the	SEC_CONTENT
differences	SEC_CONTENT
between	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
theirs	SEC_CONTENT
in	SEC_CONTENT
detail	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
.	SEC_END
Input	SECTITLE_START
layer	SECTITLE_END
Given	SEC_START
a	SEC_CONTENT
parse	SEC_CONTENT
configuration	SEC_CONTENT
c	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
extract	SEC_CONTENT
a	SEC_CONTENT
rich	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
discrete	SEC_CONTENT
features	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
feed	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
group	SEC_CONTENT
these	SEC_CONTENT
features	SEC_CONTENT
by	SEC_CONTENT
their	SEC_CONTENT
input	SEC_CONTENT
source	SEC_CONTENT
:	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
POS	metric
tags	metric
,	SEC_CONTENT
and	SEC_CONTENT
arc	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
full	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
is	SEC_CONTENT
given	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
features	SEC_CONTENT
extracted	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
group	SEC_CONTENT
are	SEC_CONTENT
represented	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
sparse	SEC_CONTENT
F	SEC_CONTENT
⇥	SEC_CONTENT
V	SEC_CONTENT
matrix	SEC_CONTENT
X	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
V	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
group	SEC_CONTENT
and	SEC_CONTENT
F	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
:	SEC_CONTENT
the	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
element	SEC_CONTENT
X	SEC_CONTENT
fv	SEC_CONTENT
is	SEC_CONTENT
1	SEC_CONTENT
if	SEC_CONTENT
the	SEC_CONTENT
f	SEC_CONTENT
'	SEC_CONTENT
th	SEC_CONTENT
feature	SEC_CONTENT
takes	SEC_CONTENT
on	SEC_CONTENT
value	SEC_CONTENT
v.	SEC_CONTENT
We	SEC_CONTENT
produce	SEC_CONTENT
three	SEC_CONTENT
input	SEC_CONTENT
matrices	SEC_CONTENT
:	SEC_CONTENT
X	SEC_CONTENT
word	SEC_CONTENT
for	SEC_CONTENT
words	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
Xtag	SEC_CONTENT
for	SEC_CONTENT
POS	SEC_CONTENT
tag	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
X	SEC_CONTENT
label	SEC_CONTENT
for	SEC_CONTENT
arc	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_END
For	SEC_START
all	SEC_CONTENT
feature	SEC_CONTENT
groups	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
additional	SEC_CONTENT
special	SEC_CONTENT
…	SEC_CONTENT
:	SEC_CONTENT
Schematic	SEC_CONTENT
overview	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
Atomic	SEC_CONTENT
features	SEC_CONTENT
are	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
i'th	SEC_CONTENT
elements	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
stack	SEC_CONTENT
(	SEC_CONTENT
s	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
buffer	SEC_CONTENT
(	SEC_CONTENT
b	SEC_CONTENT
i	SEC_CONTENT
)	SEC_CONTENT
;	SEC_CONTENT
lc	SEC_CONTENT
i	SEC_CONTENT
indicates	SEC_CONTENT
the	SEC_CONTENT
i'th	SEC_CONTENT
leftmost	SEC_CONTENT
child	SEC_CONTENT
and	SEC_CONTENT
rc	SEC_CONTENT
i	SEC_CONTENT
the	SEC_CONTENT
i'th	SEC_CONTENT
rightmost	SEC_CONTENT
child	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
two	SEC_CONTENT
elements	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
stack	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
arc	SEC_CONTENT
features	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
top	SEC_CONTENT
four	SEC_CONTENT
tokens	SEC_CONTENT
on	SEC_CONTENT
stack	SEC_CONTENT
and	SEC_CONTENT
buffer	SEC_CONTENT
for	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
tags	metric
and	SEC_CONTENT
arc	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_END
tends	SEC_START
this	SEC_CONTENT
line	SEC_CONTENT
of	SEC_CONTENT
work	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
setting	SEC_CONTENT
of	SEC_CONTENT
inexact	SEC_CONTENT
search	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
decoding	SEC_CONTENT
for	SEC_CONTENT
dependency	task
parsing	task
;	SEC_CONTENT
concurrently	SEC_CONTENT
explored	SEC_CONTENT
a	SEC_CONTENT
similar	SEC_CONTENT
approach	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
structured	SEC_CONTENT
probabilistic	SEC_CONTENT
ranking	SEC_CONTENT
objective	SEC_CONTENT
.	SEC_CONTENT
concurrently	SEC_CONTENT
developed	SEC_CONTENT
the	SEC_CONTENT
Stack	SEC_CONTENT
Long	SEC_CONTENT
Short	SEC_CONTENT
-	SEC_CONTENT
Term	SEC_CONTENT
Memory	SEC_CONTENT
(	SEC_CONTENT
S	SEC_CONTENT
-	SEC_CONTENT
LSTM	SEC_CONTENT
)	SEC_CONTENT
architecture	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
does	SEC_CONTENT
incorporate	SEC_CONTENT
recurrent	SEC_CONTENT
architecture	SEC_CONTENT
and	SEC_CONTENT
look	SEC_CONTENT
-	SEC_CONTENT
ahead	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
which	SEC_CONTENT
yields	SEC_CONTENT
comparable	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Penn	SEC_CONTENT
Treebank	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
greedy	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Neural	SECTITLE_START
Network	SECTITLE_CONTENT
Model	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
describe	SEC_CONTENT
the	SEC_CONTENT
architecture	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
is	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
separate	SEC_CONTENT
the	task
embedding	task
processing	task
to	SEC_CONTENT
a	SEC_CONTENT
distinct	SEC_CONTENT
"	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
"	SEC_CONTENT
for	SEC_CONTENT
clarity	SEC_CONTENT
of	SEC_CONTENT
presentation	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
based	SEC_CONTENT
upon	SEC_CONTENT
that	SEC_CONTENT
of	SEC_CONTENT
Chen	SEC_CONTENT
and	SEC_CONTENT
Manning	SEC_CONTENT
(	SEC_CONTENT
2014	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
discuss	SEC_CONTENT
the	SEC_CONTENT
differences	SEC_CONTENT
between	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
theirs	SEC_CONTENT
in	SEC_CONTENT
detail	SEC_CONTENT
at	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
of	SEC_CONTENT
this	SEC_CONTENT
section	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
arc	SEC_CONTENT
-	SEC_CONTENT
standard	SEC_CONTENT
(	SEC_CONTENT
Nivre	SEC_CONTENT
,	SEC_CONTENT
2004	SEC_CONTENT
)	SEC_CONTENT
transition	SEC_CONTENT
system	SEC_CONTENT
.	SEC_END
Input	SECTITLE_START
layer	SECTITLE_END
Given	SEC_START
a	SEC_CONTENT
parse	SEC_CONTENT
configuration	SEC_CONTENT
c	SEC_CONTENT
(	SEC_CONTENT
consisting	SEC_CONTENT
of	SEC_CONTENT
a	SEC_CONTENT
stack	SEC_CONTENT
sand	SEC_CONTENT
a	SEC_CONTENT
buffer	SEC_CONTENT
b	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
extract	SEC_CONTENT
a	SEC_CONTENT
rich	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
discrete	SEC_CONTENT
features	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
feed	SEC_CONTENT
into	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
group	SEC_CONTENT
these	SEC_CONTENT
features	SEC_CONTENT
by	SEC_CONTENT
their	SEC_CONTENT
input	SEC_CONTENT
source	SEC_CONTENT
:	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
POS	metric
tags	metric
,	SEC_CONTENT
and	SEC_CONTENT
arc	SEC_CONTENT
labels	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
features	SEC_CONTENT
extracted	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
group	SEC_CONTENT
are	SEC_CONTENT
represented	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
sparse	SEC_CONTENT
F	SEC_CONTENT
×	SEC_CONTENT
V	SEC_CONTENT
matrix	SEC_CONTENT
X	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
V	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
vocabulary	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
feature	SEC_CONTENT
group	SEC_CONTENT
and	SEC_CONTENT
F	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
features	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
value	SEC_CONTENT
of	SEC_CONTENT
element	SEC_CONTENT
X	SEC_CONTENT
f	SEC_CONTENT
v	SEC_CONTENT
is	SEC_CONTENT
1	SEC_CONTENT
if	SEC_CONTENT
the	SEC_CONTENT
f	SEC_CONTENT
'	SEC_CONTENT
th	SEC_CONTENT
feature	SEC_CONTENT
takes	SEC_CONTENT
on	SEC_CONTENT
value	SEC_CONTENT
v.	SEC_CONTENT
We	SEC_CONTENT
produce	SEC_CONTENT
three	SEC_CONTENT
input	SEC_CONTENT
matrices	SEC_CONTENT
:	SEC_CONTENT
X	SEC_CONTENT
word	SEC_CONTENT
for	SEC_CONTENT
words	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
X	SEC_CONTENT
tag	SEC_CONTENT
for	SEC_CONTENT
POS	SEC_CONTENT
tag	SEC_CONTENT
features	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
X	SEC_CONTENT
label	SEC_CONTENT
for	SEC_CONTENT
arc	SEC_CONTENT
labels	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
F	SEC_CONTENT
word	SEC_CONTENT
=	SEC_CONTENT
F	SEC_CONTENT
tag	SEC_CONTENT
=	SEC_CONTENT
20	SEC_CONTENT
and	SEC_CONTENT
F	SEC_CONTENT
label	SEC_CONTENT
=	SEC_CONTENT
12	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
all	SEC_CONTENT
feature	SEC_CONTENT
groups	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
add	SEC_CONTENT
additional	SEC_CONTENT
special	SEC_CONTENT
values	SEC_CONTENT
for	SEC_CONTENT
"	SEC_CONTENT
ROOT	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
indicating	SEC_CONTENT
the	metric
POS	metric
or	SEC_CONTENT
word	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
root	SEC_CONTENT
token	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
"	SEC_CONTENT
NULL	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
indicating	SEC_CONTENT
no	SEC_CONTENT
valid	SEC_CONTENT
feature	SEC_CONTENT
value	SEC_CONTENT
could	SEC_CONTENT
be	SEC_CONTENT
computed	SEC_CONTENT
)	SEC_CONTENT
or	SEC_CONTENT
"	SEC_CONTENT
UNK	SEC_CONTENT
"	SEC_CONTENT
(	SEC_CONTENT
indicating	SEC_CONTENT
an	SEC_CONTENT
out	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
vocabulary	SEC_CONTENT
item	SEC_CONTENT
)	SEC_CONTENT
.	SEC_END
Embedding	SECTITLE_START
layer	SECTITLE_END
The	SEC_START
first	SEC_CONTENT
learned	SEC_CONTENT
layer	SEC_CONTENT
h	SEC_CONTENT
0	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
transforms	SEC_CONTENT
the	SEC_CONTENT
sparse	SEC_CONTENT
,	SEC_CONTENT
discrete	SEC_CONTENT
features	SEC_CONTENT
X	SEC_CONTENT
into	SEC_CONTENT
a	SEC_CONTENT
dense	SEC_CONTENT
,	SEC_CONTENT
continuous	SEC_CONTENT
embedded	SEC_CONTENT
representation	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
each	SEC_CONTENT
feature	SEC_CONTENT
group	SEC_CONTENT
X	SEC_CONTENT
g	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
learn	SEC_CONTENT
a	SEC_CONTENT
V	SEC_CONTENT
g	SEC_CONTENT
×	SEC_CONTENT
D	SEC_CONTENT
g	SEC_CONTENT
embedding	SEC_CONTENT
matrix	SEC_CONTENT
E	SEC_CONTENT
g	SEC_CONTENT
that	SEC_CONTENT
applies	SEC_CONTENT
the	SEC_CONTENT
conversion	SEC_CONTENT
:	SEC_END
where	SEC_START
we	SEC_CONTENT
apply	SEC_CONTENT
the	SEC_CONTENT
computation	SEC_CONTENT
separately	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
group	SEC_CONTENT
g	SEC_CONTENT
and	SEC_CONTENT
concatenate	SEC_CONTENT
the	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
layer	SEC_CONTENT
has	SEC_CONTENT
E	SEC_CONTENT
=	SEC_CONTENT
g	SEC_CONTENT
F	SEC_CONTENT
g	SEC_CONTENT
D	SEC_CONTENT
g	SEC_CONTENT
outputs	SEC_CONTENT
,	SEC_CONTENT
which	SEC_CONTENT
we	SEC_CONTENT
reshape	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
vector	SEC_CONTENT
h	SEC_CONTENT
0	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
can	SEC_CONTENT
choose	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
dimensionality	SEC_CONTENT
D	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
group	SEC_CONTENT
freely	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
and	SEC_CONTENT
arc	SEC_CONTENT
labels	SEC_CONTENT
have	SEC_CONTENT
much	SEC_CONTENT
smaller	SEC_CONTENT
vocabularies	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
5.1	SEC_CONTENT
)	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
use	SEC_CONTENT
smaller	SEC_CONTENT
D	SEC_CONTENT
tag	SEC_CONTENT
and	SEC_CONTENT
D	SEC_CONTENT
label	SEC_CONTENT
,	SEC_CONTENT
without	SEC_CONTENT
a	SEC_CONTENT
loss	SEC_CONTENT
inaccuracy	SEC_CONTENT
.	SEC_END
Hidden	SECTITLE_START
layers	SECTITLE_END
We	SEC_START
experimented	SEC_CONTENT
with	SEC_CONTENT
one	SEC_CONTENT
and	SEC_CONTENT
two	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
composed	SEC_CONTENT
of	SEC_CONTENT
M	SEC_CONTENT
rectified	SEC_CONTENT
linear	SEC_CONTENT
(	SEC_CONTENT
Relu	SEC_CONTENT
)	SEC_CONTENT
units	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
unit	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
is	SEC_CONTENT
fully	SEC_CONTENT
connected	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
layer	SEC_CONTENT
:	SEC_END
where	SEC_START
W	SEC_CONTENT
1	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
M	SEC_CONTENT
1	SEC_CONTENT
×	SEC_CONTENT
E	SEC_CONTENT
weight	SEC_CONTENT
matrix	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
and	SEC_CONTENT
W	SEC_CONTENT
i	SEC_CONTENT
are	SEC_CONTENT
M	SEC_CONTENT
i	SEC_CONTENT
×	SEC_CONTENT
M	SEC_CONTENT
i−1	SEC_CONTENT
matrices	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
subsequent	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
weights	SEC_CONTENT
bi	SEC_CONTENT
are	SEC_CONTENT
bias	SEC_CONTENT
terms	SEC_CONTENT
.	SEC_CONTENT
Relu	SEC_CONTENT
layers	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
well	SEC_CONTENT
studied	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
literature	SEC_CONTENT
and	SEC_CONTENT
have	SEC_CONTENT
been	SEC_CONTENT
shown	SEC_CONTENT
to	SEC_CONTENT
work	SEC_CONTENT
well	SEC_CONTENT
fora	SEC_CONTENT
wide	SEC_CONTENT
domain	SEC_CONTENT
of	SEC_CONTENT
problems	metric
(	SEC_CONTENT
.	SEC_CONTENT
Through	SEC_CONTENT
most	SEC_CONTENT
of	SEC_CONTENT
development	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
kept	SEC_CONTENT
M	SEC_CONTENT
i	SEC_CONTENT
=	SEC_CONTENT
200	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
significantly	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
improved	SEC_CONTENT
our	SEC_CONTENT
results	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
comparison	SEC_CONTENT
.	SEC_END
Relationship	SECTITLE_START
to	SECTITLE_CONTENT
Chen	SECTITLE_CONTENT
and	SECTITLE_CONTENT
Manning	SECTITLE_CONTENT
(	SECTITLE_CONTENT
2014	SECTITLE_CONTENT
)	SECTITLE_END
Our	SEC_START
model	SEC_CONTENT
is	SEC_CONTENT
clearly	SEC_CONTENT
inspired	SEC_CONTENT
by	SEC_CONTENT
and	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
work	SEC_CONTENT
of	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
area	SEC_CONTENT
few	SEC_CONTENT
structural	SEC_CONTENT
differences	SEC_CONTENT
:	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
we	SEC_CONTENT
allow	SEC_CONTENT
for	SEC_CONTENT
much	SEC_CONTENT
smaller	SEC_CONTENT
embeddings	SEC_CONTENT
of	SEC_CONTENT
POS	metric
tags	metric
and	SEC_CONTENT
labels	metric
,	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
Relu	SEC_CONTENT
units	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
deeper	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
two	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
Somewhat	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
surprise	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
these	SEC_CONTENT
changes	SEC_CONTENT
combined	SEC_CONTENT
with	SEC_CONTENT
an	SEC_CONTENT
SGD	SEC_CONTENT
training	SEC_CONTENT
scheme	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
3.1	SEC_CONTENT
)	SEC_CONTENT
during	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
"	SEC_CONTENT
phase	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
lead	SEC_CONTENT
to	SEC_CONTENT
an	SEC_CONTENT
almost	SEC_CONTENT
1	SEC_CONTENT
%	SEC_CONTENT
accuracy	SEC_CONTENT
gain	SEC_CONTENT
over	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
trend	SEC_CONTENT
held	SEC_CONTENT
despite	SEC_CONTENT
carefully	SEC_CONTENT
tuning	SEC_CONTENT
hyperparameters	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
method	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
structure	SEC_CONTENT
combination	SEC_CONTENT
.	SEC_CONTENT
Our	SEC_CONTENT
main	SEC_CONTENT
contribution	SEC_CONTENT
from	SEC_CONTENT
an	SEC_CONTENT
algorithmic	SEC_CONTENT
perspective	SEC_CONTENT
is	SEC_CONTENT
our	SEC_CONTENT
training	SEC_CONTENT
procedure	SEC_CONTENT
:	SEC_CONTENT
as	SEC_CONTENT
described	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
next	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
for	SEC_CONTENT
learning	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
thus	SEC_CONTENT
present	SEC_CONTENT
a	SEC_CONTENT
novel	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
leverage	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
representation	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
structured	SEC_CONTENT
prediction	SEC_CONTENT
setting	SEC_CONTENT
.	SEC_END
Semi	SECTITLE_START
-	SECTITLE_CONTENT
Supervised	SECTITLE_CONTENT
Structured	SECTITLE_CONTENT
Learning	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
investigate	SEC_CONTENT
a	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
structured	SEC_CONTENT
learning	SEC_CONTENT
scheme	SEC_CONTENT
that	SEC_CONTENT
yields	SEC_CONTENT
substantial	SEC_CONTENT
improvements	SEC_CONTENT
inaccuracy	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
are	SEC_CONTENT
two	SEC_CONTENT
complementary	SEC_CONTENT
contributions	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
:	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
incorporating	SEC_CONTENT
structured	SEC_CONTENT
learning	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
2	SEC_CONTENT
)	SEC_CONTENT
utilizing	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
both	SEC_CONTENT
cases	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
model	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
of	SEC_CONTENT
each	task
parsing	task
action	task
y	task
as	SEC_CONTENT
a	SEC_CONTENT
soft	SEC_CONTENT
-	SEC_CONTENT
max	SEC_CONTENT
function	SEC_CONTENT
taking	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
as	SEC_CONTENT
its	SEC_CONTENT
input	SEC_CONTENT
:	SEC_END
where	SEC_START
β	SEC_CONTENT
y	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
M	SEC_CONTENT
i	SEC_CONTENT
dimensional	SEC_CONTENT
vector	SEC_CONTENT
of	SEC_CONTENT
weights	SEC_CONTENT
for	SEC_CONTENT
classy	metric
and	SEC_CONTENT
i	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
index	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
.	SEC_CONTENT
At	SEC_CONTENT
a	SEC_CONTENT
high	SEC_CONTENT
level	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
summarized	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
•	SEC_START
First	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
's	SEC_CONTENT
hidden	SEC_CONTENT
representations	SEC_CONTENT
by	SEC_CONTENT
learning	SEC_CONTENT
probabilities	SEC_CONTENT
of	SEC_CONTENT
parsing	SEC_CONTENT
actions	SEC_CONTENT
.	SEC_CONTENT
Fixing	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
learn	SEC_CONTENT
an	SEC_CONTENT
additional	SEC_CONTENT
final	SEC_CONTENT
output	SEC_CONTENT
layer	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
that	SEC_CONTENT
uses	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
's	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
practice	SEC_CONTENT
this	SEC_CONTENT
improves	SEC_CONTENT
accuracy	SEC_CONTENT
by	SEC_CONTENT
∼0.6	SEC_CONTENT
%	SEC_CONTENT
absolute	SEC_CONTENT
.	SEC_END
•	SEC_START
Next	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
can	SEC_CONTENT
supplement	SEC_CONTENT
the	SEC_CONTENT
gold	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
corpus	SEC_CONTENT
of	SEC_CONTENT
high	SEC_CONTENT
quality	SEC_CONTENT
automatic	SEC_CONTENT
parses	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
show	SEC_CONTENT
that	SEC_CONTENT
incorporating	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
way	SEC_CONTENT
improves	SEC_CONTENT
accuracy	SEC_CONTENT
by	SEC_CONTENT
as	SEC_CONTENT
much	SEC_CONTENT
as	SEC_CONTENT
1	SEC_CONTENT
%	SEC_CONTENT
absolute	SEC_CONTENT
.	SEC_END
Backpropagation	SECTITLE_START
Pretraining	SECTITLE_END
To	SEC_START
learn	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
mini	SEC_CONTENT
-	SEC_CONTENT
batched	SEC_CONTENT
averaged	SEC_CONTENT
stochastic	SEC_CONTENT
gradient	SEC_CONTENT
descent	SEC_CONTENT
(	SEC_CONTENT
ASGD	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
Bottou	SEC_CONTENT
,	SEC_CONTENT
2010	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
momentum	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
Θ	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
Θ	SEC_CONTENT
=	SEC_CONTENT
{	SEC_CONTENT
E	SEC_CONTENT
g	SEC_CONTENT
,	SEC_CONTENT
W	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
bi	SEC_CONTENT
,	SEC_CONTENT
β	SEC_CONTENT
y	SEC_CONTENT
|	SEC_CONTENT
∀g	SEC_CONTENT
,	SEC_CONTENT
i	SEC_CONTENT
,	SEC_CONTENT
y	SEC_CONTENT
}	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
backpropagation	SEC_CONTENT
to	SEC_CONTENT
minimize	SEC_CONTENT
the	SEC_CONTENT
multinomial	SEC_CONTENT
logistic	SEC_CONTENT
loss	SEC_CONTENT
:	SEC_END
where	SEC_START
λ	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
regularization	SEC_CONTENT
hyper	SEC_CONTENT
-	SEC_CONTENT
parameter	SEC_CONTENT
over	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
parameters	SEC_CONTENT
(	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
λ	SEC_CONTENT
=	SEC_CONTENT
10	SEC_CONTENT
−4	SEC_CONTENT
in	SEC_CONTENT
all	SEC_CONTENT
experiments	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
j	SEC_CONTENT
sums	SEC_CONTENT
overall	SEC_CONTENT
decisions	SEC_CONTENT
and	SEC_CONTENT
configurations	SEC_CONTENT
{	SEC_CONTENT
y	SEC_CONTENT
j	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
j	SEC_CONTENT
}	SEC_CONTENT
extracted	SEC_CONTENT
from	SEC_CONTENT
gold	SEC_CONTENT
parse	SEC_CONTENT
trees	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
dataset	SEC_CONTENT
.	SEC_END
The	SEC_START
specific	SEC_CONTENT
update	SEC_CONTENT
rule	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
at	SEC_CONTENT
iteration	SEC_CONTENT
t	SEC_CONTENT
is	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
:	SEC_END
where	SEC_START
the	SEC_CONTENT
descent	SEC_CONTENT
direction	SEC_CONTENT
gt	SEC_CONTENT
is	SEC_CONTENT
computed	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
weighted	SEC_CONTENT
combination	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
previous	SEC_CONTENT
direction	SEC_CONTENT
g	SEC_CONTENT
t−1	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
gradient	SEC_CONTENT
∆L(Θ	SEC_CONTENT
t	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
parameter	SEC_CONTENT
µ	SEC_CONTENT
∈	SEC_CONTENT
[	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
momentum	SEC_CONTENT
parameter	SEC_CONTENT
while	SEC_CONTENT
η	SEC_CONTENT
t	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
traditional	SEC_CONTENT
learning	SEC_CONTENT
rate	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
addition	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
we	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
tune	SEC_CONTENT
the	SEC_CONTENT
regularization	SEC_CONTENT
parameter	SEC_CONTENT
λ	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
apply	SEC_CONTENT
a	SEC_CONTENT
simple	SEC_CONTENT
exponential	SEC_CONTENT
step	SEC_CONTENT
-	SEC_CONTENT
wise	SEC_CONTENT
decay	SEC_CONTENT
to	SEC_CONTENT
η	SEC_CONTENT
t	SEC_CONTENT
;	SEC_CONTENT
for	SEC_CONTENT
every	SEC_CONTENT
γ	SEC_CONTENT
rounds	SEC_CONTENT
of	SEC_CONTENT
updates	metric
,	SEC_CONTENT
we	SEC_CONTENT
multiply	SEC_CONTENT
η	SEC_CONTENT
t	SEC_CONTENT
=	SEC_CONTENT
0.96η	SEC_CONTENT
t−1	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
final	SEC_CONTENT
component	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
update	SEC_CONTENT
is	SEC_CONTENT
parameter	SEC_CONTENT
averaging	SEC_CONTENT
:	SEC_CONTENT
we	SEC_CONTENT
maintain	SEC_CONTENT
averaged	SEC_CONTENT
parameters	SEC_END
where	SEC_START
α	SEC_CONTENT
t	SEC_CONTENT
is	SEC_CONTENT
an	SEC_CONTENT
averaging	SEC_CONTENT
weight	SEC_CONTENT
that	SEC_CONTENT
increases	SEC_CONTENT
from	SEC_CONTENT
0.1	SEC_CONTENT
to	SEC_CONTENT
0.9999	SEC_CONTENT
with	SEC_CONTENT
1	SEC_CONTENT
/	SEC_CONTENT
t	SEC_CONTENT
.	SEC_CONTENT
Combined	SEC_CONTENT
with	SEC_CONTENT
averaging	SEC_CONTENT
,	SEC_CONTENT
careful	SEC_CONTENT
tuning	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
three	SEC_CONTENT
hyperparameters	SEC_CONTENT
µ	SEC_CONTENT
,	SEC_CONTENT
η	SEC_CONTENT
0	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
γ	SEC_CONTENT
using	SEC_CONTENT
heldout	SEC_CONTENT
data	SEC_CONTENT
was	SEC_CONTENT
crucial	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_END
Structured	SECTITLE_START
Perceptron	SECTITLE_CONTENT
Training	SECTITLE_END
Given	SEC_START
the	SEC_CONTENT
hidden	SEC_CONTENT
representations	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
now	SEC_CONTENT
describe	SEC_CONTENT
how	SEC_CONTENT
the	SEC_CONTENT
perceptron	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
to	SEC_CONTENT
utilize	SEC_CONTENT
these	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
perceptron	SEC_CONTENT
algorithm	SEC_CONTENT
with	SEC_CONTENT
early	SEC_CONTENT
updates	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
requires	SEC_CONTENT
a	SEC_CONTENT
feature	SEC_CONTENT
-	SEC_CONTENT
vector	SEC_CONTENT
definition	SEC_CONTENT
φ	SEC_CONTENT
that	SEC_CONTENT
maps	SEC_CONTENT
a	SEC_CONTENT
sentence	SEC_CONTENT
x	SEC_CONTENT
together	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
configuration	SEC_CONTENT
c	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
feature	SEC_CONTENT
vector	SEC_CONTENT
φ(x	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
∈	SEC_CONTENT
Rd	SEC_CONTENT
.	SEC_CONTENT
There	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
one	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
one	SEC_CONTENT
mapping	SEC_CONTENT
between	SEC_CONTENT
configurations	SEC_CONTENT
c	SEC_CONTENT
and	SEC_CONTENT
decision	SEC_CONTENT
sequences	SEC_CONTENT
y	SEC_END
For	SEC_START
a	SEC_CONTENT
sentence	SEC_CONTENT
x	SEC_CONTENT
,	SEC_CONTENT
define	SEC_CONTENT
GEN(x	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
parse	dataset
trees	dataset
for	SEC_CONTENT
x.	SEC_CONTENT
Each	SEC_CONTENT
y	SEC_CONTENT
∈	SEC_CONTENT
GEN(x	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
a	SEC_CONTENT
sequence	SEC_CONTENT
of	SEC_CONTENT
decisions	SEC_CONTENT
y	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
y	SEC_CONTENT
m	SEC_CONTENT
for	SEC_CONTENT
some	SEC_CONTENT
integer	SEC_CONTENT
m.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
Y	SEC_CONTENT
to	SEC_CONTENT
denote	SEC_CONTENT
the	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
possible	SEC_CONTENT
decisions	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
parsing	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
each	SEC_CONTENT
decision	SEC_CONTENT
y	SEC_CONTENT
∈	SEC_CONTENT
Y	SEC_CONTENT
we	SEC_CONTENT
assume	SEC_CONTENT
a	SEC_CONTENT
parameter	SEC_CONTENT
vector	SEC_CONTENT
v(y	SEC_CONTENT
)	SEC_CONTENT
∈	SEC_CONTENT
Rd	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
parameters	SEC_CONTENT
will	SEC_CONTENT
be	SEC_CONTENT
trained	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
perceptron	SEC_CONTENT
.	SEC_END
In	SEC_START
decoding	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
perceptron	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
use	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
to	SEC_CONTENT
attempt	SEC_CONTENT
to	SEC_CONTENT
find	SEC_CONTENT
:	SEC_END
Thus	SEC_START
each	SEC_CONTENT
decision	SEC_CONTENT
y	SEC_CONTENT
j	SEC_CONTENT
receives	SEC_CONTENT
a	SEC_CONTENT
score	SEC_CONTENT
:	SEC_END
In	SEC_START
the	SEC_CONTENT
perceptron	SEC_CONTENT
with	SEC_CONTENT
early	SEC_CONTENT
updates	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
v(y	SEC_CONTENT
)	SEC_CONTENT
are	SEC_CONTENT
trained	SEC_CONTENT
as	SEC_CONTENT
follows	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
each	SEC_CONTENT
training	SEC_CONTENT
example	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
run	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
until	SEC_CONTENT
the	SEC_CONTENT
goldstandard	SEC_CONTENT
parse	SEC_CONTENT
tree	SEC_CONTENT
falls	SEC_CONTENT
out	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
beam	SEC_CONTENT
.	SEC_CONTENT
1	SEC_CONTENT
Define	SEC_CONTENT
j	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
the	SEC_CONTENT
length	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
beam	SEC_CONTENT
at	SEC_CONTENT
this	SEC_CONTENT
point	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
update	SEC_CONTENT
is	SEC_CONTENT
performed	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
gold	SEC_CONTENT
-	SEC_CONTENT
standard	SEC_CONTENT
decisions	SEC_CONTENT
y	SEC_CONTENT
1	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
.	SEC_CONTENT
y	SEC_CONTENT
j	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
target	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
scoring	SEC_CONTENT
(	SEC_CONTENT
incorrect	SEC_CONTENT
)	SEC_CONTENT
member	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
beam	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
negative	SEC_CONTENT
example	SEC_CONTENT
.	SEC_END
A	SEC_START
key	SEC_CONTENT
idea	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
paper	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
define	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
φ(x	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Given	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
x	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
configuration	SEC_CONTENT
c	SEC_CONTENT
,	SEC_CONTENT
assuming	SEC_CONTENT
two	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
defines	SEC_CONTENT
values	SEC_CONTENT
for	SEC_CONTENT
h	SEC_CONTENT
1	SEC_CONTENT
,	SEC_CONTENT
h	SEC_CONTENT
2	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
P(y	SEC_CONTENT
)	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
decision	SEC_CONTENT
y.	SEC_CONTENT
We	SEC_CONTENT
experimented	SEC_CONTENT
with	SEC_CONTENT
various	SEC_CONTENT
definitions	SEC_CONTENT
of	SEC_CONTENT
φ	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
5.2	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
φ(x	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
h	SEC_CONTENT
1	SEC_CONTENT
h	SEC_CONTENT
2	SEC_CONTENT
P(y	SEC_CONTENT
)	SEC_CONTENT
]	SEC_CONTENT
(	SEC_CONTENT
the	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
outputs	SEC_CONTENT
from	SEC_CONTENT
both	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
probabilities	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
decisions	SEC_CONTENT
y	SEC_CONTENT
possible	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
current	SEC_CONTENT
configuration	SEC_CONTENT
)	SEC_CONTENT
had	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
development	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Note	SEC_START
that	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
possible	SEC_CONTENT
to	SEC_CONTENT
continue	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
backpropagation	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
φ(x	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
during	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
;	SEC_CONTENT
however	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
using	SEC_CONTENT
ASGD	metric
to	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
representation	SEC_CONTENT
always	SEC_CONTENT
led	SEC_CONTENT
to	SEC_CONTENT
faster	SEC_CONTENT
,	SEC_CONTENT
more	SEC_CONTENT
accurate	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
preliminary	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
we	SEC_CONTENT
left	SEC_CONTENT
further	SEC_CONTENT
investigation	SEC_CONTENT
for	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
.	SEC_END
Incorporating	SECTITLE_START
Unlabeled	SECTITLE_CONTENT
Data	SECTITLE_END
Given	SEC_START
the	SEC_CONTENT
high	SEC_CONTENT
capacity	SEC_CONTENT
,	SEC_CONTENT
non	SEC_CONTENT
-	SEC_CONTENT
linear	SEC_CONTENT
nature	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
deep	SEC_CONTENT
network	SEC_CONTENT
we	SEC_CONTENT
hypothesize	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
can	SEC_CONTENT
If	SEC_CONTENT
the	SEC_CONTENT
gold	SEC_CONTENT
parse	SEC_CONTENT
tree	SEC_CONTENT
stays	SEC_CONTENT
within	SEC_CONTENT
the	SEC_CONTENT
beam	SEC_CONTENT
until	SEC_CONTENT
the	SEC_CONTENT
end	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
sentence	SEC_CONTENT
,	SEC_CONTENT
conventional	SEC_CONTENT
perceptron	SEC_CONTENT
updates	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
be	SEC_CONTENT
significantly	SEC_CONTENT
improved	SEC_CONTENT
by	SEC_CONTENT
incorporating	SEC_CONTENT
more	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
use	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
through	SEC_CONTENT
unsupervised	SEC_CONTENT
methods	SEC_CONTENT
such	SEC_CONTENT
as	SEC_CONTENT
word	SEC_CONTENT
clusters	SEC_CONTENT
(;	SEC_CONTENT
we	SEC_CONTENT
follow	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
pretrained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
to	SEC_CONTENT
initialize	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
capture	SEC_CONTENT
similar	SEC_CONTENT
distributional	SEC_CONTENT
information	SEC_CONTENT
as	SEC_CONTENT
word	SEC_CONTENT
clusters	SEC_CONTENT
and	SEC_CONTENT
give	SEC_CONTENT
consistent	SEC_CONTENT
improvements	SEC_CONTENT
by	SEC_CONTENT
providing	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
initialization	SEC_CONTENT
and	SEC_CONTENT
information	SEC_CONTENT
about	SEC_CONTENT
words	SEC_CONTENT
not	SEC_CONTENT
seen	SEC_CONTENT
in	SEC_CONTENT
the	dataset
treebank	dataset
data	dataset
.	SEC_END
However	SEC_START
,	SEC_CONTENT
obtaining	SEC_CONTENT
more	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
even	SEC_CONTENT
more	SEC_CONTENT
important	SEC_CONTENT
than	SEC_CONTENT
a	SEC_CONTENT
good	SEC_CONTENT
initialization	SEC_CONTENT
.	SEC_CONTENT
One	SEC_CONTENT
potential	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
obtain	SEC_CONTENT
additional	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
is	SEC_CONTENT
by	SEC_CONTENT
parsing	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
with	SEC_CONTENT
previously	SEC_CONTENT
trained	SEC_CONTENT
models	SEC_CONTENT
.	SEC_CONTENT
and	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
iteratively	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
a	SEC_CONTENT
single	SEC_CONTENT
model	SEC_CONTENT
(	SEC_CONTENT
"	SEC_CONTENT
self	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
improve	SEC_CONTENT
parsers	SEC_CONTENT
in	SEC_CONTENT
certain	SEC_CONTENT
settings	SEC_CONTENT
;	SEC_CONTENT
built	SEC_CONTENT
on	SEC_CONTENT
this	SEC_CONTENT
work	SEC_CONTENT
and	SEC_CONTENT
showed	SEC_CONTENT
that	SEC_CONTENT
a	SEC_CONTENT
slow	SEC_CONTENT
and	SEC_CONTENT
accurate	SEC_CONTENT
parser	SEC_CONTENT
can	SEC_CONTENT
be	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
"	SEC_CONTENT
up	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
"	SEC_CONTENT
a	SEC_CONTENT
faster	SEC_CONTENT
but	SEC_CONTENT
less	SEC_CONTENT
accurate	SEC_CONTENT
parser	SEC_CONTENT
.	SEC_END
In	SEC_START
this	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
adopt	SEC_CONTENT
the	SEC_CONTENT
"	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
"	SEC_CONTENT
approach	SEC_CONTENT
of	SEC_CONTENT
:	SEC_CONTENT
Two	SEC_CONTENT
parsers	SEC_CONTENT
are	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
process	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
corpus	SEC_CONTENT
and	SEC_CONTENT
only	SEC_CONTENT
sentences	SEC_CONTENT
for	SEC_CONTENT
which	SEC_CONTENT
both	SEC_CONTENT
parsers	SEC_CONTENT
produced	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
parse	SEC_CONTENT
tree	SEC_CONTENT
are	SEC_CONTENT
added	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
intuition	SEC_CONTENT
behind	SEC_CONTENT
this	SEC_CONTENT
idea	SEC_CONTENT
is	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
chance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
parse	SEC_CONTENT
being	SEC_CONTENT
correct	SEC_CONTENT
is	SEC_CONTENT
much	SEC_CONTENT
higher	SEC_CONTENT
when	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
parsers	SEC_CONTENT
agree	SEC_CONTENT
:	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
only	SEC_CONTENT
one	SEC_CONTENT
way	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
correct	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
many	SEC_CONTENT
possible	SEC_CONTENT
incorrect	SEC_CONTENT
parses	SEC_CONTENT
.	SEC_CONTENT
Of	SEC_CONTENT
course	SEC_CONTENT
,	SEC_CONTENT
this	SEC_CONTENT
reasoning	SEC_CONTENT
holds	SEC_CONTENT
only	SEC_CONTENT
as	SEC_CONTENT
long	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
parsers	SEC_CONTENT
suffer	SEC_CONTENT
from	SEC_CONTENT
different	SEC_CONTENT
biases	SEC_CONTENT
.	SEC_END
We	SEC_START
show	SEC_CONTENT
that	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
far	SEC_CONTENT
more	SEC_CONTENT
effective	SEC_CONTENT
than	SEC_CONTENT
vanilla	SEC_CONTENT
up	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
same	SEC_CONTENT
setup	SEC_CONTENT
as	SEC_CONTENT
,	SEC_CONTENT
intersecting	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
BerkeleyParser	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
reimplementation	SEC_CONTENT
of	SEC_CONTENT
ZPar	SEC_CONTENT
(	SEC_CONTENT
Zhang	SEC_CONTENT
and	SEC_CONTENT
Nivre	SEC_CONTENT
,	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
baseline	SEC_CONTENT
parsers	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
two	SEC_CONTENT
parsers	SEC_CONTENT
agree	SEC_CONTENT
only	SEC_CONTENT
36	SEC_CONTENT
%	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
time	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
their	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
those	SEC_CONTENT
sentences	SEC_CONTENT
is	SEC_CONTENT
97.26	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
,	SEC_CONTENT
approaching	SEC_CONTENT
the	SEC_CONTENT
inter	SEC_CONTENT
annotator	SEC_CONTENT
agreement	SEC_CONTENT
rate	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
sentences	SEC_CONTENT
are	SEC_CONTENT
of	SEC_CONTENT
course	SEC_CONTENT
easier	SEC_CONTENT
to	SEC_CONTENT
parse	SEC_CONTENT
,	SEC_CONTENT
having	SEC_CONTENT
an	SEC_CONTENT
average	SEC_CONTENT
length	SEC_CONTENT
of	SEC_CONTENT
15	SEC_CONTENT
words	SEC_CONTENT
,	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
24	SEC_CONTENT
words	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
overall	SEC_CONTENT
.	SEC_CONTENT
However	SEC_CONTENT
,	SEC_CONTENT
because	SEC_CONTENT
we	SEC_CONTENT
only	SEC_CONTENT
use	SEC_CONTENT
these	SEC_CONTENT
sentences	SEC_CONTENT
to	SEC_CONTENT
extract	SEC_CONTENT
individual	SEC_CONTENT
transition	SEC_CONTENT
decisions	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
shorter	SEC_CONTENT
length	SEC_CONTENT
does	SEC_CONTENT
not	SEC_CONTENT
seem	SEC_CONTENT
to	SEC_CONTENT
hurt	SEC_CONTENT
their	SEC_CONTENT
utility	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
generate	SEC_CONTENT
10	SEC_CONTENT
7	SEC_CONTENT
tokens	SEC_CONTENT
worth	SEC_CONTENT
of	SEC_CONTENT
new	SEC_CONTENT
parses	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
this	SEC_CONTENT
data	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
backpropagation	SEC_CONTENT
stage	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
Experiments	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
we	SEC_CONTENT
present	SEC_CONTENT
our	SEC_CONTENT
experimental	SEC_CONTENT
setup	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
main	SEC_CONTENT
results	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
work	SEC_CONTENT
.	SEC_END
Experimental	SECTITLE_START
Setup	SECTITLE_END
We	SEC_START
conduct	SEC_CONTENT
our	SEC_CONTENT
experiments	SEC_CONTENT
on	SEC_CONTENT
two	SEC_CONTENT
English	SEC_CONTENT
language	SEC_CONTENT
benchmarks	SEC_CONTENT
:	SEC_CONTENT
(	SEC_CONTENT
1	SEC_CONTENT
)	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
Wall	SEC_CONTENT
Street	SEC_CONTENT
Journal	SEC_CONTENT
(	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
part	SEC_CONTENT
of	SEC_CONTENT
the	dataset
Penn	dataset
Treebank	dataset
(	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
comprehensive	SEC_CONTENT
union	SEC_CONTENT
of	SEC_CONTENT
publicly	SEC_CONTENT
available	SEC_CONTENT
treebanks	SEC_CONTENT
spanning	SEC_CONTENT
multiple	SEC_CONTENT
domains	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
follow	SEC_CONTENT
standard	SEC_CONTENT
practice	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
sections	SEC_CONTENT
2	SEC_CONTENT
-	SEC_CONTENT
21	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
section	SEC_CONTENT
22	SEC_CONTENT
for	SEC_CONTENT
development	SEC_CONTENT
and	SEC_CONTENT
section	SEC_CONTENT
23	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
many	SEC_CONTENT
hyperparameters	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
models	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
additionally	SEC_CONTENT
use	SEC_CONTENT
section	SEC_CONTENT
24	SEC_CONTENT
for	SEC_CONTENT
tuning	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
convert	SEC_CONTENT
the	SEC_CONTENT
constituency	SEC_CONTENT
trees	SEC_CONTENT
to	SEC_CONTENT
Stanford	SEC_CONTENT
style	SEC_CONTENT
dependencies	SEC_CONTENT
)	SEC_CONTENT
using	SEC_CONTENT
version	SEC_CONTENT
3.3.0	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
converter	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
use	SEC_CONTENT
a	SEC_CONTENT
CRF	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
5-fold	SEC_CONTENT
jack	SEC_CONTENT
-	SEC_CONTENT
knifed	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
predicted	SEC_CONTENT
tags	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
,	SEC_CONTENT
test	SEC_CONTENT
and	SEC_CONTENT
tune	SEC_CONTENT
sets	SEC_CONTENT
;	SEC_CONTENT
our	SEC_CONTENT
tagger	SEC_CONTENT
gets	SEC_CONTENT
comparable	SEC_CONTENT
accuracy	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
Stanford	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
with	SEC_CONTENT
97.44	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
report	SEC_CONTENT
unlabeled	SEC_CONTENT
attachment	SEC_CONTENT
score	SEC_CONTENT
(	SEC_CONTENT
UAS	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
labeled	SEC_CONTENT
attachment	SEC_CONTENT
score	SEC_CONTENT
(	SEC_CONTENT
LAS	SEC_CONTENT
)	SEC_CONTENT
excluding	SEC_CONTENT
punctuation	SEC_CONTENT
on	SEC_CONTENT
predicted	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
,	SEC_CONTENT
as	SEC_CONTENT
is	SEC_CONTENT
standard	SEC_CONTENT
for	SEC_CONTENT
English	SEC_CONTENT
.	SEC_END
For	SEC_START
the	SEC_CONTENT
second	SEC_CONTENT
set	SEC_CONTENT
of	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
follow	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
procedure	SEC_CONTENT
as	SEC_CONTENT
above	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
diverse	SEC_CONTENT
dataset	SEC_CONTENT
for	SEC_CONTENT
training	SEC_CONTENT
and	SEC_CONTENT
evaluation	SEC_CONTENT
.	SEC_CONTENT
Following	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
(	SEC_CONTENT
in	SEC_CONTENT
addition	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
OntoNotes	SEC_CONTENT
corpus	SEC_CONTENT
version	SEC_CONTENT
5	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
English	SEC_CONTENT
Web	SEC_CONTENT
Treebank	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
updated	SEC_CONTENT
and	SEC_CONTENT
corrected	SEC_CONTENT
Question	SEC_CONTENT
Treebank	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
train	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
union	SEC_CONTENT
of	SEC_CONTENT
each	SEC_CONTENT
corpora	SEC_CONTENT
's	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
test	SEC_CONTENT
on	SEC_CONTENT
each	SEC_CONTENT
domain	SEC_CONTENT
separately	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
refer	SEC_CONTENT
to	SEC_CONTENT
this	SEC_CONTENT
setup	SEC_CONTENT
as	SEC_CONTENT
the	dataset
"	dataset
Treebank	dataset
Union	dataset
"	dataset
setup	dataset
.	SEC_END
In	SEC_START
our	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
the	SEC_CONTENT
corpus	SEC_CONTENT
from	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
source	SEC_CONTENT
of	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
process	SEC_CONTENT
it	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
BerkeleyParser	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
latent	SEC_CONTENT
variable	SEC_CONTENT
constituency	SEC_CONTENT
parser	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
reimplementation	SEC_CONTENT
of	SEC_CONTENT
ZPar	SEC_CONTENT
(	SEC_CONTENT
Zhang	SEC_CONTENT
and	SEC_CONTENT
Nivre	SEC_CONTENT
,	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
a	SEC_CONTENT
transition	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
parser	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
.	SEC_CONTENT
Both	SEC_CONTENT
parsers	SEC_CONTENT
are	SEC_CONTENT
included	SEC_CONTENT
as	SEC_CONTENT
baselines	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
evaluation	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
select	SEC_CONTENT
the	SEC_CONTENT
first	SEC_CONTENT
10	SEC_CONTENT
7	SEC_CONTENT
tokens	SEC_CONTENT
for	SEC_CONTENT
which	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
parsers	SEC_CONTENT
agree	SEC_CONTENT
as	SEC_CONTENT
additional	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
our	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
assigned	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Berkeley	SEC_CONTENT
constituency	SEC_CONTENT
parser	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
increases	SEC_CONTENT
POS	SEC_END
Method	SECTITLE_END
UAS	SECTITLE_START
LAS	SECTITLE_CONTENT
Beam	SECTITLE_END
Graph	SECTITLE_START
-	SECTITLE_CONTENT
based	SECTITLE_END
Bohnet	SEC_START
92.88	SEC_CONTENT
90.71	SEC_CONTENT
n	SEC_CONTENT
/	SEC_CONTENT
a	SEC_CONTENT
92.89	SEC_CONTENT
90.55	SEC_CONTENT
n	SEC_CONTENT
/	SEC_CONTENT
a	SEC_CONTENT
:	SEC_CONTENT
Final	SEC_CONTENT
WSJ	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compare	SEC_CONTENT
our	SEC_CONTENT
system	SEC_CONTENT
to	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
graph	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
and	SEC_CONTENT
transition	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
.	SEC_CONTENT
denotes	SEC_CONTENT
our	SEC_CONTENT
own	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
implementation	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
system	SEC_CONTENT
so	SEC_CONTENT
we	SEC_CONTENT
could	SEC_CONTENT
compare	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
competitive	SEC_CONTENT
baseline	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
methods	SEC_CONTENT
except	SEC_CONTENT
and	SEC_CONTENT
were	SEC_CONTENT
run	SEC_CONTENT
using	SEC_CONTENT
predicted	SEC_CONTENT
tags	SEC_CONTENT
from	SEC_CONTENT
our	SEC_CONTENT
POS	SEC_CONTENT
tagger	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
reference	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Berkeley	SEC_CONTENT
constituency	SEC_CONTENT
parser	SEC_CONTENT
(	SEC_CONTENT
after	SEC_CONTENT
conversion	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
93.61	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
/	SEC_CONTENT
91.51	SEC_CONTENT
%	SEC_CONTENT
LAS	SEC_CONTENT
.	SEC_END
accuracy	SEC_START
slightly	SEC_CONTENT
to	SEC_CONTENT
97.57	SEC_CONTENT
%	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
.	SEC_END
Model	SECTITLE_START
Initialization	SECTITLE_CONTENT
&	SECTITLE_CONTENT
Hyperparameters	SECTITLE_END
In	SEC_START
all	SEC_CONTENT
cases	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
initialized	SEC_CONTENT
W	SEC_CONTENT
i	SEC_CONTENT
and	SEC_CONTENT
β	SEC_CONTENT
randomly	SEC_CONTENT
using	SEC_CONTENT
a	SEC_CONTENT
Gaussian	SEC_CONTENT
distribution	SEC_CONTENT
with	SEC_CONTENT
variance	SEC_CONTENT
10	SEC_CONTENT
−4	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
fixed	SEC_CONTENT
initialization	SEC_CONTENT
with	SEC_CONTENT
bi	SEC_CONTENT
=	SEC_CONTENT
0.2	SEC_CONTENT
,	SEC_CONTENT
to	SEC_CONTENT
ensure	SEC_CONTENT
that	SEC_CONTENT
most	SEC_CONTENT
Relu	SEC_CONTENT
units	SEC_CONTENT
are	SEC_CONTENT
activated	SEC_CONTENT
during	SEC_CONTENT
the	SEC_CONTENT
initial	SEC_CONTENT
rounds	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
systematically	SEC_CONTENT
compare	SEC_CONTENT
this	SEC_CONTENT
random	SEC_CONTENT
scheme	SEC_CONTENT
to	SEC_CONTENT
others	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
it	SEC_CONTENT
was	SEC_CONTENT
sufficient	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
purposes	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embedding	SEC_CONTENT
matrix	SEC_CONTENT
E	SEC_CONTENT
word	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
initialized	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
using	SEC_CONTENT
pretrained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
used	SEC_CONTENT
the	SEC_CONTENT
publicly	SEC_CONTENT
available	SEC_CONTENT
word2vec	SEC_CONTENT
2	SEC_CONTENT
tool	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
to	SEC_CONTENT
learn	SEC_CONTENT
CBOW	SEC_CONTENT
embeddings	SEC_CONTENT
following	SEC_CONTENT
the	SEC_CONTENT
sample	SEC_CONTENT
configuration	SEC_CONTENT
provided	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
tool	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
words	SEC_CONTENT
not	SEC_CONTENT
appearing	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
unsupervised	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
the	SEC_CONTENT
special	SEC_CONTENT
"	SEC_CONTENT
NULL	SEC_CONTENT
"	SEC_CONTENT
etc	SEC_CONTENT
.	SEC_CONTENT
tokens	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
random	SEC_CONTENT
initialization	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
preliminary	SEC_CONTENT
experiments	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
no	SEC_CONTENT
difference	SEC_CONTENT
between	SEC_CONTENT
training	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
on	SEC_CONTENT
1	SEC_CONTENT
billion	SEC_CONTENT
or	SEC_CONTENT
10	SEC_CONTENT
billion	SEC_CONTENT
tokens	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
therefore	SEC_CONTENT
trained	SEC_CONTENT
the	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
corpus	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
for	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
(	SEC_CONTENT
.	SEC_END
We	SEC_START
set	SEC_CONTENT
D	SEC_CONTENT
word	SEC_CONTENT
=	SEC_CONTENT
64	SEC_CONTENT
and	SEC_CONTENT
D	SEC_CONTENT
tag	SEC_CONTENT
=	SEC_CONTENT
D	SEC_CONTENT
label	SEC_CONTENT
=	SEC_CONTENT
32	SEC_CONTENT
for	SEC_CONTENT
embedding	SEC_CONTENT
dimensions	SEC_CONTENT
and	SEC_CONTENT
M	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
M	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
2048	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
final	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	SEC_CONTENT
percep	SEC_CONTENT
-	SEC_CONTENT
News	SEC_CONTENT
Web	SEC_CONTENT
QTB	SEC_END
Graph	SECTITLE_START
-	SECTITLE_CONTENT
based	SECTITLE_END
Bohnet	SEC_START
91.38	SEC_CONTENT
85.22	SEC_CONTENT
91.49	SEC_CONTENT
91.13	SEC_CONTENT
85.04	SEC_CONTENT
91.54	SEC_CONTENT
  	SEC_CONTENT
tron	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
φ(x	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
h	SEC_CONTENT
1	SEC_CONTENT
h	SEC_CONTENT
2	SEC_CONTENT
P(y	SEC_CONTENT
)	SEC_CONTENT
]	SEC_CONTENT
(	SEC_CONTENT
concatenation	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
intermediate	SEC_CONTENT
layers	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
All	SEC_CONTENT
hyperparameters	SEC_CONTENT
(	SEC_CONTENT
including	SEC_CONTENT
structure	SEC_CONTENT
)	SEC_CONTENT
were	SEC_CONTENT
tuned	SEC_CONTENT
using	SEC_CONTENT
Section	SEC_CONTENT
24	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
only	SEC_CONTENT
.	SEC_CONTENT
When	SEC_CONTENT
not	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
used	SEC_CONTENT
hyperparameters	SEC_CONTENT
of	SEC_CONTENT
γ	SEC_CONTENT
=	SEC_CONTENT
0.2	SEC_CONTENT
,	SEC_CONTENT
η	SEC_CONTENT
0	SEC_CONTENT
=	SEC_CONTENT
0.05	SEC_CONTENT
,	SEC_CONTENT
µ	SEC_CONTENT
=	SEC_CONTENT
0.9	SEC_CONTENT
,	SEC_CONTENT
early	SEC_CONTENT
stopping	SEC_CONTENT
after	SEC_CONTENT
roughly	SEC_CONTENT
16	SEC_CONTENT
hours	SEC_CONTENT
of	SEC_CONTENT
training	SEC_CONTENT
time	SEC_CONTENT
.	SEC_CONTENT
With	SEC_CONTENT
the	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
decreased	SEC_CONTENT
η	SEC_CONTENT
0	SEC_CONTENT
=	SEC_CONTENT
0.05	SEC_CONTENT
,	SEC_CONTENT
increased	SEC_CONTENT
γ	SEC_CONTENT
=	SEC_CONTENT
0.5	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
decreased	SEC_CONTENT
the	SEC_CONTENT
size	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
to	SEC_CONTENT
M	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
1024	SEC_CONTENT
,	SEC_CONTENT
M	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
256	SEC_CONTENT
for	SEC_CONTENT
run	SEC_CONTENT
-	SEC_CONTENT
time	SEC_CONTENT
efficiency	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
trained	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
for	SEC_CONTENT
approximately	SEC_CONTENT
4	SEC_CONTENT
days	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
the	dataset
Treebank	dataset
Union	dataset
setup	dataset
,	SEC_CONTENT
we	SEC_CONTENT
set	SEC_CONTENT
M	SEC_CONTENT
1	SEC_CONTENT
=	SEC_CONTENT
M	SEC_CONTENT
2	SEC_CONTENT
=	SEC_CONTENT
1024	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
standard	SEC_CONTENT
training	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
setup	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
our	SEC_CONTENT
final	SEC_CONTENT
results	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
cross	SEC_CONTENT
-	SEC_CONTENT
domain	SEC_CONTENT
results	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
Treebank	SEC_CONTENT
Union	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
best	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
literature	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
(	SEC_CONTENT
Chen	SEC_CONTENT
and	SEC_CONTENT
Manning	SEC_CONTENT
,	SEC_CONTENT
2014	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
(	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
reported	SEC_CONTENT
results	SEC_CONTENT
;	SEC_CONTENT
the	SEC_CONTENT
other	SEC_CONTENT
baselines	SEC_CONTENT
were	SEC_CONTENT
run	SEC_CONTENT
by	SEC_CONTENT
Bernd	SEC_CONTENT
Bohnet	SEC_CONTENT
using	SEC_CONTENT
version	SEC_CONTENT
3.3.0	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
Stanford	SEC_CONTENT
dependencies	SEC_CONTENT
and	SEC_CONTENT
our	SEC_CONTENT
predicted	SEC_CONTENT
POS	SEC_CONTENT
tags	SEC_CONTENT
for	SEC_CONTENT
all	SEC_CONTENT
datasets	SEC_CONTENT
to	SEC_CONTENT
make	SEC_CONTENT
comparisons	SEC_CONTENT
as	SEC_CONTENT
fair	SEC_CONTENT
as	SEC_CONTENT
possible	SEC_CONTENT
.	SEC_CONTENT
On	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
and	SEC_CONTENT
Web	SEC_CONTENT
tasks	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
parser	SEC_CONTENT
outperforms	SEC_CONTENT
all	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
in	SEC_CONTENT
our	SEC_CONTENT
comparison	SEC_CONTENT
by	SEC_CONTENT
a	SEC_CONTENT
substantial	SEC_CONTENT
margin	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
Question	SEC_CONTENT
(	SEC_CONTENT
QTB	SEC_CONTENT
)	SEC_CONTENT
dataset	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
sensitive	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
smaller	SEC_CONTENT
beam	SEC_CONTENT
size	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
models	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
reasonable	SEC_CONTENT
time	SEC_CONTENT
;	SEC_CONTENT
if	SEC_CONTENT
we	SEC_CONTENT
increase	SEC_CONTENT
to	SEC_CONTENT
B	SEC_CONTENT
=	SEC_CONTENT
32	SEC_CONTENT
at	SEC_CONTENT
inference	SEC_CONTENT
time	SEC_CONTENT
only	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
perceptron	SEC_CONTENT
performance	SEC_CONTENT
goes	SEC_CONTENT
up	SEC_CONTENT
to	SEC_CONTENT
92.29	SEC_CONTENT
%	SEC_CONTENT
LAS	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
many	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
baselines	SEC_CONTENT
could	SEC_CONTENT
not	SEC_CONTENT
be	SEC_CONTENT
directly	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
our	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
re	SEC_CONTENT
-	SEC_CONTENT
implemented	SEC_CONTENT
Zhang	SEC_CONTENT
and	SEC_CONTENT
Nivre	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
trained	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
corpus	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
tritraining	SEC_CONTENT
did	SEC_CONTENT
help	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
performance	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
improve	SEC_CONTENT
significantly	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
contrast	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
quite	SEC_CONTENT
exciting	SEC_CONTENT
to	SEC_CONTENT
see	SEC_CONTENT
that	SEC_CONTENT
after	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
our	SEC_CONTENT
greedy	SEC_CONTENT
parser	SEC_CONTENT
is	SEC_CONTENT
more	SEC_CONTENT
accurate	SEC_CONTENT
than	SEC_CONTENT
any	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
and	SEC_CONTENT
competitive	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
BerkeleyParser	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
.	SEC_CONTENT
As	SEC_CONTENT
expected	SEC_CONTENT
,	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
helps	SEC_CONTENT
most	SEC_CONTENT
dramatically	SEC_CONTENT
to	SEC_CONTENT
increase	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
Treebank	SEC_CONTENT
Union	SEC_CONTENT
setup	SEC_CONTENT
with	SEC_CONTENT
diverse	SEC_CONTENT
domains	SEC_CONTENT
,	SEC_CONTENT
yielding	SEC_CONTENT
0.4	SEC_CONTENT
-	SEC_CONTENT
1.0	SEC_CONTENT
%	SEC_CONTENT
absolute	SEC_CONTENT
LAS	SEC_CONTENT
improvement	SEC_CONTENT
gains	SEC_CONTENT
for	SEC_CONTENT
our	SEC_CONTENT
most	SEC_CONTENT
accurate	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Results	SECTITLE_END
Unfortunately	SEC_START
we	SEC_CONTENT
are	SEC_CONTENT
notable	SEC_CONTENT
to	SEC_CONTENT
compare	SEC_CONTENT
to	SEC_CONTENT
several	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
dependency	SEC_CONTENT
parsers	SEC_CONTENT
that	SEC_CONTENT
achieve	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
reported	SEC_CONTENT
accuracies	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
WSJ	SEC_CONTENT
,	SEC_CONTENT
in	SEC_CONTENT
particular	SEC_CONTENT
,	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
parsers	SEC_CONTENT
use	SEC_CONTENT
the	task
dependency	task
conversion	task
and	SEC_CONTENT
the	SEC_CONTENT
accuracies	SEC_CONTENT
are	SEC_CONTENT
therefore	SEC_CONTENT
not	SEC_CONTENT
directly	SEC_CONTENT
comparable	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
highest	SEC_CONTENT
of	SEC_CONTENT
these	SEC_CONTENT
is	SEC_CONTENT
,	SEC_CONTENT
with	SEC_CONTENT
a	SEC_CONTENT
reported	SEC_CONTENT
accuracy	SEC_CONTENT
of	SEC_CONTENT
94.22	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
.	SEC_CONTENT
Even	SEC_CONTENT
though	SEC_CONTENT
the	SEC_CONTENT
UAS	SEC_CONTENT
is	SEC_CONTENT
not	SEC_CONTENT
directly	SEC_CONTENT
comparable	SEC_CONTENT
,	SEC_CONTENT
it	SEC_CONTENT
is	SEC_CONTENT
typically	SEC_CONTENT
similar	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
this	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
our	SEC_CONTENT
model	SEC_CONTENT
is	SEC_CONTENT
competitive	SEC_CONTENT
with	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
reported	SEC_CONTENT
accuries	SEC_CONTENT
for	SEC_CONTENT
dependencies	SEC_CONTENT
on	SEC_CONTENT
WSJ	SEC_CONTENT
.	SEC_END
Discussion	SECTITLE_END
In	SEC_START
this	SEC_CONTENT
section	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
investigate	SEC_CONTENT
the	SEC_CONTENT
contribution	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
various	SEC_CONTENT
components	SEC_CONTENT
of	SEC_CONTENT
our	SEC_CONTENT
approach	SEC_CONTENT
through	SEC_CONTENT
ablation	SEC_CONTENT
studies	SEC_CONTENT
and	SEC_CONTENT
other	SEC_CONTENT
systematic	SEC_CONTENT
experiments	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
tune	SEC_CONTENT
on	SEC_CONTENT
Section	SEC_CONTENT
24	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
use	SEC_CONTENT
Section	SEC_CONTENT
22	SEC_CONTENT
for	SEC_CONTENT
comparisons	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
not	SEC_CONTENT
pollute	SEC_CONTENT
the	SEC_CONTENT
official	SEC_CONTENT
test	SEC_CONTENT
set	SEC_CONTENT
(	SEC_CONTENT
Section	SEC_CONTENT
23	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
focus	SEC_CONTENT
on	SEC_CONTENT
UAS	metric
as	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
the	SEC_CONTENT
LAS	SEC_CONTENT
scores	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
strongly	SEC_CONTENT
correlated	SEC_CONTENT
.	SEC_CONTENT
Unless	SEC_CONTENT
otherwise	SEC_CONTENT
specified	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
200	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
in	SEC_CONTENT
each	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
able	SEC_CONTENT
to	SEC_CONTENT
run	SEC_CONTENT
more	SEC_CONTENT
ablative	SEC_CONTENT
experiments	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
reasonable	SEC_CONTENT
amount	SEC_CONTENT
of	SEC_CONTENT
time	SEC_CONTENT
.	SEC_END
Impact	SECTITLE_START
of	SECTITLE_CONTENT
Network	SECTITLE_CONTENT
Structure	SECTITLE_END
In	SEC_START
addition	SEC_CONTENT
to	SEC_CONTENT
initialization	SEC_CONTENT
and	SEC_CONTENT
hyperparameter	SEC_CONTENT
tuning	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
several	SEC_CONTENT
additional	SEC_CONTENT
choices	SEC_CONTENT
about	SEC_CONTENT
model	SEC_CONTENT
structure	SEC_CONTENT
and	SEC_CONTENT
size	SEC_CONTENT
a	SEC_CONTENT
practitioner	SEC_CONTENT
faces	SEC_CONTENT
when	SEC_CONTENT
implementing	SEC_CONTENT
a	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
explore	SEC_CONTENT
these	SEC_CONTENT
questions	SEC_CONTENT
and	SEC_CONTENT
justify	SEC_CONTENT
the	SEC_CONTENT
particular	SEC_CONTENT
choices	SEC_CONTENT
we	SEC_CONTENT
use	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
following	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
we	SEC_CONTENT
do	SEC_CONTENT
 	SEC_CONTENT
Figure	SEC_CONTENT
2	SEC_CONTENT
:	SEC_CONTENT
Effect	SEC_CONTENT
of	SEC_CONTENT
hidden	task
layers	task
and	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
variance	SEC_CONTENT
of	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
.	SEC_CONTENT
Initialization	SEC_CONTENT
was	SEC_CONTENT
either	SEC_CONTENT
completely	SEC_CONTENT
random	SEC_CONTENT
or	SEC_CONTENT
initialized	SEC_CONTENT
with	SEC_CONTENT
word2vec	SEC_CONTENT
embeddings	SEC_CONTENT
(	SEC_CONTENT
"	SEC_CONTENT
Pretrained	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
either	SEC_CONTENT
one	SEC_CONTENT
or	SEC_CONTENT
two	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
of	SEC_CONTENT
size	SEC_CONTENT
200	SEC_CONTENT
were	SEC_CONTENT
used	SEC_CONTENT
(	SEC_CONTENT
"	SEC_CONTENT
200	SEC_CONTENT
"	SEC_CONTENT
vs	SEC_CONTENT
"	SEC_CONTENT
200x200	SEC_CONTENT
"	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Each	SEC_CONTENT
point	SEC_CONTENT
represents	SEC_CONTENT
maximization	SEC_CONTENT
over	SEC_CONTENT
a	SEC_CONTENT
small	SEC_CONTENT
hyperparameter	SEC_CONTENT
grid	SEC_CONTENT
with	SEC_CONTENT
early	SEC_CONTENT
stopping	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
WSJ	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
UAS	SEC_CONTENT
score	SEC_CONTENT
.	SEC_END
not	SEC_START
use	SEC_CONTENT
abeam	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
analysis	SEC_CONTENT
and	SEC_CONTENT
therefore	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
train	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
perceptron	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
done	SEC_CONTENT
in	SEC_CONTENT
order	SEC_CONTENT
to	SEC_CONTENT
reduce	SEC_CONTENT
training	SEC_CONTENT
times	SEC_CONTENT
and	SEC_CONTENT
because	SEC_CONTENT
the	dataset
trends	dataset
persist	SEC_CONTENT
across	SEC_CONTENT
settings	SEC_CONTENT
.	SEC_END
Variance	SEC_START
reduction	SEC_CONTENT
with	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
embeddings	SEC_CONTENT
.	SEC_CONTENT
Since	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
problem	SEC_CONTENT
is	SEC_CONTENT
nonconvex	SEC_CONTENT
,	SEC_CONTENT
different	SEC_CONTENT
initializations	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
parameters	SEC_CONTENT
yield	SEC_CONTENT
different	SEC_CONTENT
solutions	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
learning	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
Thus	SEC_CONTENT
,	SEC_CONTENT
for	SEC_CONTENT
any	SEC_CONTENT
given	SEC_CONTENT
experiment	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
ran	SEC_CONTENT
multiple	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
for	SEC_CONTENT
every	task
setting	task
of	SEC_CONTENT
our	SEC_CONTENT
hyperparameters	SEC_CONTENT
and	SEC_CONTENT
picked	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
that	SEC_CONTENT
performed	SEC_CONTENT
best	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
held	SEC_CONTENT
-	SEC_CONTENT
out	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
found	SEC_CONTENT
it	SEC_CONTENT
important	SEC_CONTENT
to	SEC_CONTENT
allow	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
to	SEC_CONTENT
stop	SEC_CONTENT
training	SEC_CONTENT
early	SEC_CONTENT
if	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
accuracy	SEC_CONTENT
decreased	SEC_CONTENT
.	SEC_END
We	SEC_START
visualize	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
32	SEC_CONTENT
random	SEC_CONTENT
restarts	SEC_CONTENT
with	SEC_CONTENT
one	SEC_CONTENT
or	SEC_CONTENT
two	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
and	SEC_CONTENT
with	SEC_CONTENT
and	SEC_CONTENT
without	SEC_CONTENT
pretrained	SEC_CONTENT
word	SEC_CONTENT
embeddings	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
a	SEC_CONTENT
summary	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
figure	SEC_CONTENT
in	SEC_CONTENT
.	SEC_CONTENT
While	SEC_CONTENT
adding	SEC_CONTENT
a	SEC_CONTENT
second	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
results	SEC_CONTENT
in	SEC_CONTENT
a	SEC_CONTENT
large	SEC_CONTENT
gain	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
,	SEC_CONTENT
there	SEC_CONTENT
is	SEC_CONTENT
no	SEC_CONTENT
gain	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
if	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
fact	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
the	SEC_CONTENT
overall	SEC_CONTENT
UAS	SEC_CONTENT
scores	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
tune	SEC_CONTENT
set	SEC_CONTENT
and	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
are	SEC_CONTENT
strongly	SEC_CONTENT
correlated	SEC_CONTENT
(	SEC_CONTENT
ρ	SEC_CONTENT
=	SEC_CONTENT
0.64	SEC_CONTENT
,	SEC_CONTENT
p	SEC_CONTENT
<	SEC_CONTENT
10	SEC_CONTENT
−10	SEC_CONTENT
)	SEC_CONTENT
,	SEC_CONTENT
they	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
significantly	SEC_CONTENT
correlated	SEC_CONTENT
if	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
embeddings	SEC_CONTENT
are	SEC_CONTENT
not	SEC_CONTENT
used	SEC_CONTENT
(	SEC_CONTENT
ρ	SEC_CONTENT
=	SEC_CONTENT
0.12	SEC_CONTENT
,	SEC_CONTENT
p	SEC_CONTENT
>	SEC_CONTENT
0.3	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
an	SEC_CONTENT
additional	SEC_CONTENT
benefit	SEC_CONTENT
of	SEC_CONTENT
pre	SEC_CONTENT
-	SEC_CONTENT
trained	SEC_CONTENT
embeddings	SEC_CONTENT
,	SEC_CONTENT
aside	SEC_CONTENT
from	SEC_CONTENT
allowing	SEC_CONTENT
learning	SEC_CONTENT
to	SEC_CONTENT
reach	SEC_CONTENT
a	SEC_CONTENT
more	SEC_CONTENT
accurate	SEC_CONTENT
solution	SEC_CONTENT
,	SEC_CONTENT
is	SEC_CONTENT
to	SEC_CONTENT
push	SEC_CONTENT
learning	SEC_CONTENT
towards	SEC_CONTENT
a	SEC_CONTENT
solution	SEC_CONTENT
that	SEC_CONTENT
generalizes	SEC_CONTENT
to	SEC_CONTENT
more	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Pre	SECTITLE_END
Hidden	SEC_START
WSJ	SEC_CONTENT
§	SEC_CONTENT
24	SEC_CONTENT
(	SEC_CONTENT
Max	SEC_CONTENT
)	SEC_CONTENT
WSJ	SEC_CONTENT
§	SEC_CONTENT
22	SEC_CONTENT
Y	SEC_CONTENT
200	SEC_CONTENT
×	SEC_CONTENT
200	SEC_CONTENT
92.10	SEC_CONTENT
±	SEC_CONTENT
0.11	SEC_CONTENT
92.58	SEC_CONTENT
±0.12	SEC_CONTENT
Y	SEC_CONTENT
200	SEC_CONTENT
91.76	SEC_CONTENT
±	SEC_CONTENT
0.09	SEC_CONTENT
92.30	SEC_CONTENT
±	SEC_CONTENT
0.10	SEC_CONTENT
N	SEC_CONTENT
200	SEC_CONTENT
×	SEC_CONTENT
200	SEC_CONTENT
91.84	SEC_CONTENT
±	SEC_CONTENT
0.11	SEC_CONTENT
92.19	SEC_CONTENT
±	SEC_CONTENT
0.13	SEC_CONTENT
N	SEC_CONTENT
200	SEC_CONTENT
91.55	SEC_CONTENT
±	SEC_CONTENT
0.10	SEC_CONTENT
92.20	SEC_CONTENT
±	SEC_CONTENT
0.12	SEC_CONTENT
 	SEC_CONTENT
Diminishing	SEC_CONTENT
returns	SEC_CONTENT
with	SEC_CONTENT
increasing	SEC_CONTENT
embedding	SEC_CONTENT
dimensions	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
these	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
fixed	SEC_CONTENT
one	SEC_CONTENT
embedding	SEC_CONTENT
type	SEC_CONTENT
to	SEC_CONTENT
a	SEC_CONTENT
high	SEC_CONTENT
value	SEC_CONTENT
and	SEC_CONTENT
reduced	SEC_CONTENT
the	SEC_CONTENT
dimensionality	SEC_CONTENT
of	SEC_CONTENT
all	SEC_CONTENT
others	SEC_CONTENT
to	SEC_CONTENT
very	SEC_CONTENT
small	SEC_CONTENT
values	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
plotted	SEC_CONTENT
in	SEC_CONTENT
,	SEC_CONTENT
suggesting	SEC_CONTENT
larger	SEC_CONTENT
embeddings	SEC_CONTENT
do	SEC_CONTENT
not	SEC_CONTENT
significantly	SEC_CONTENT
improve	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
ran	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
very	SEC_CONTENT
compact	SEC_CONTENT
model	SEC_CONTENT
with	SEC_CONTENT
D	SEC_CONTENT
word	SEC_CONTENT
=	SEC_CONTENT
8	SEC_CONTENT
and	SEC_CONTENT
D	SEC_CONTENT
tag	SEC_CONTENT
=	SEC_CONTENT
D	SEC_CONTENT
label	SEC_CONTENT
=	SEC_CONTENT
2	SEC_CONTENT
(	SEC_CONTENT
8×	SEC_CONTENT
fewer	SEC_CONTENT
parameters	SEC_CONTENT
than	SEC_CONTENT
our	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
)	SEC_CONTENT
which	SEC_CONTENT
resulted	SEC_CONTENT
in	SEC_CONTENT
92.33	SEC_CONTENT
%	SEC_CONTENT
UAS	SEC_CONTENT
accuracy	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
dev	SEC_CONTENT
set	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
is	SEC_CONTENT
comparable	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
full	SEC_CONTENT
model	SEC_CONTENT
without	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
suggesting	SEC_CONTENT
that	SEC_CONTENT
more	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
can	SEC_CONTENT
compensate	SEC_CONTENT
for	SEC_CONTENT
fewer	SEC_CONTENT
parameters	SEC_CONTENT
.	SEC_END
Increasing	SEC_START
hidden	SEC_CONTENT
units	SEC_CONTENT
yields	SEC_CONTENT
large	SEC_CONTENT
gains	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
these	SEC_CONTENT
experiments	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
fixed	SEC_CONTENT
the	SEC_CONTENT
embedding	SEC_CONTENT
sizes	SEC_CONTENT
D	SEC_CONTENT
word	SEC_CONTENT
=	SEC_CONTENT
64	SEC_CONTENT
,	SEC_CONTENT
D	SEC_CONTENT
tag	SEC_CONTENT
=	SEC_CONTENT
D	SEC_CONTENT
label	SEC_CONTENT
=	SEC_CONTENT
32	SEC_CONTENT
and	SEC_CONTENT
tried	SEC_CONTENT
increasing	SEC_CONTENT
and	SEC_CONTENT
decreasing	SEC_CONTENT
the	SEC_CONTENT
dimensionality	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
on	SEC_CONTENT
a	SEC_CONTENT
logarthmic	SEC_CONTENT
scale	SEC_CONTENT
.	SEC_CONTENT
Improvements	SEC_CONTENT
inaccuracy	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
appear	SEC_CONTENT
to	SEC_CONTENT
saturate	SEC_CONTENT
even	SEC_CONTENT
with	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
number	SEC_CONTENT
of	SEC_CONTENT
hidden	SEC_CONTENT
units	SEC_CONTENT
by	SEC_CONTENT
an	SEC_CONTENT
order	SEC_CONTENT
of	SEC_CONTENT
magnitude	SEC_CONTENT
,	SEC_CONTENT
though	SEC_CONTENT
the	SEC_CONTENT
network	SEC_CONTENT
became	SEC_CONTENT
too	SEC_CONTENT
slow	SEC_CONTENT
to	SEC_CONTENT
train	SEC_CONTENT
effectively	SEC_CONTENT
past	SEC_CONTENT
M	SEC_CONTENT
=	SEC_CONTENT
2048	SEC_CONTENT
.	SEC_CONTENT
These	SEC_CONTENT
results	SEC_CONTENT
suggest	SEC_CONTENT
that	SEC_CONTENT
there	SEC_CONTENT
are	SEC_CONTENT
still	SEC_CONTENT
gains	SEC_CONTENT
to	SEC_CONTENT
be	SEC_CONTENT
made	SEC_CONTENT
by	SEC_CONTENT
increasing	SEC_CONTENT
the	SEC_CONTENT
efficiency	SEC_CONTENT
of	SEC_CONTENT
larger	SEC_CONTENT
networks	SEC_CONTENT
,	SEC_CONTENT
even	SEC_CONTENT
for	SEC_CONTENT
greedy	SEC_CONTENT
shift	SEC_CONTENT
-	SEC_CONTENT
reduce	SEC_CONTENT
parsers	SEC_CONTENT
.	SEC_END
Impact	SECTITLE_START
of	SECTITLE_CONTENT
Structured	SECTITLE_CONTENT
Perceptron	SECTITLE_END
We	SEC_START
now	SEC_CONTENT
turn	SEC_CONTENT
our	SEC_CONTENT
attention	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
importance	SEC_CONTENT
of	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
different	SEC_CONTENT
latent	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_END
Bias	SEC_START
reduction	SEC_CONTENT
through	SEC_CONTENT
structured	SEC_CONTENT
training	SEC_CONTENT
.	SEC_END
To	SEC_START
evaluate	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
structured	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
  	SEC_CONTENT
compare	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
estimates	SEC_CONTENT
P(y	SEC_CONTENT
)	SEC_CONTENT
from	SEC_CONTENT
the	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
directly	SEC_CONTENT
for	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
to	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
activations	SEC_CONTENT
from	SEC_CONTENT
all	SEC_CONTENT
layers	SEC_CONTENT
as	SEC_CONTENT
features	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
.	SEC_CONTENT
Using	SEC_CONTENT
the	SEC_CONTENT
probability	SEC_CONTENT
estimates	SEC_CONTENT
directly	SEC_CONTENT
is	SEC_CONTENT
very	SEC_CONTENT
similar	SEC_CONTENT
to	SEC_CONTENT
,	SEC_CONTENT
where	SEC_CONTENT
a	SEC_CONTENT
maximum	SEC_CONTENT
-	SEC_CONTENT
entropy	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
model	SEC_CONTENT
the	SEC_CONTENT
distribution	SEC_CONTENT
over	SEC_CONTENT
possible	SEC_CONTENT
actions	SEC_CONTENT
at	SEC_CONTENT
each	SEC_CONTENT
parser	SEC_CONTENT
state	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
was	SEC_CONTENT
used	SEC_CONTENT
to	SEC_CONTENT
search	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
highest	SEC_CONTENT
probability	SEC_CONTENT
parse	SEC_CONTENT
.	SEC_CONTENT
A	SEC_CONTENT
known	SEC_CONTENT
problem	SEC_CONTENT
with	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
in	SEC_CONTENT
this	SEC_CONTENT
setting	SEC_CONTENT
is	SEC_CONTENT
the	SEC_CONTENT
label	SEC_CONTENT
-	SEC_CONTENT
bias	SEC_CONTENT
problem	SEC_CONTENT
.	SEC_CONTENT
shows	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
using	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
over	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
function	SEC_CONTENT
during	SEC_CONTENT
beam	SEC_CONTENT
search	SEC_CONTENT
as	SEC_CONTENT
a	SEC_CONTENT
function	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
beam	SEC_CONTENT
size	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
For	SEC_CONTENT
reference	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
reimplementation	SEC_CONTENT
of	SEC_CONTENT
Zhang	SEC_CONTENT
and	SEC_CONTENT
Nivre	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
is	SEC_CONTENT
trained	SEC_CONTENT
equivalently	SEC_CONTENT
for	SEC_CONTENT
each	SEC_CONTENT
setting	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
show	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
on	SEC_CONTENT
beam	SEC_CONTENT
size	SEC_CONTENT
when	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
.	SEC_CONTENT
Although	SEC_CONTENT
the	SEC_CONTENT
beam	SEC_CONTENT
does	SEC_CONTENT
marginally	SEC_CONTENT
improve	SEC_CONTENT
accuracy	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
much	SEC_CONTENT
greater	SEC_CONTENT
gains	SEC_CONTENT
are	SEC_CONTENT
achieved	SEC_CONTENT
when	SEC_CONTENT
perceptron	SEC_CONTENT
training	SEC_CONTENT
is	SEC_CONTENT
used	SEC_CONTENT
.	SEC_END
Using	SEC_START
all	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
crucial	SEC_CONTENT
for	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
also	SEC_CONTENT
investigated	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
connecting	SEC_CONTENT
the	SEC_CONTENT
final	SEC_CONTENT
perceptron	SEC_CONTENT
layer	SEC_CONTENT
to	SEC_CONTENT
all	SEC_CONTENT
prior	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
(	SEC_CONTENT
 	SEC_CONTENT
quired	SEC_CONTENT
to	SEC_CONTENT
reduce	SEC_CONTENT
the	SEC_CONTENT
bias	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
not	SEC_CONTENT
when	SEC_CONTENT
filtered	SEC_CONTENT
through	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
.	SEC_CONTENT
Finally	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
also	SEC_CONTENT
experimented	SEC_CONTENT
with	SEC_CONTENT
connecting	SEC_CONTENT
both	SEC_CONTENT
hidden	SEC_CONTENT
layers	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
layer	SEC_CONTENT
during	SEC_CONTENT
backpropagation	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
but	SEC_CONTENT
we	SEC_CONTENT
found	SEC_CONTENT
this	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
significantly	SEC_CONTENT
affect	SEC_CONTENT
the	SEC_CONTENT
performance	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
greedy	SEC_CONTENT
model	SEC_CONTENT
.	SEC_END
Impact	SECTITLE_START
of	SECTITLE_CONTENT
Tri	SECTITLE_CONTENT
-	SECTITLE_CONTENT
Training	SECTITLE_END
To	SEC_START
evaluate	SEC_CONTENT
the	SEC_CONTENT
impact	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
approach	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
compared	SEC_CONTENT
to	SEC_CONTENT
up	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
BerkelyParser	SEC_CONTENT
(	SEC_CONTENT
)	SEC_CONTENT
alone	SEC_CONTENT
.	SEC_CONTENT
The	SEC_CONTENT
results	SEC_CONTENT
are	SEC_CONTENT
summarized	SEC_CONTENT
in	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
greedy	SEC_CONTENT
and	SEC_CONTENT
perceptron	SEC_CONTENT
neural	SEC_CONTENT
net	SEC_CONTENT
models	SEC_CONTENT
as	SEC_CONTENT
well	SEC_CONTENT
as	SEC_CONTENT
our	SEC_CONTENT
reimplementated	SEC_CONTENT
Zhang	SEC_CONTENT
and	SEC_CONTENT
Nivre	SEC_CONTENT
(	SEC_CONTENT
2011	SEC_CONTENT
)	SEC_CONTENT
baseline	SEC_CONTENT
.	SEC_END
For	SEC_START
our	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
output	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
BerkeleyParser	SEC_CONTENT
yields	SEC_CONTENT
only	SEC_CONTENT
modest	SEC_CONTENT
gains	SEC_CONTENT
,	SEC_CONTENT
while	SEC_CONTENT
training	SEC_CONTENT
on	SEC_CONTENT
the	SEC_CONTENT
data	SEC_CONTENT
where	SEC_CONTENT
the	SEC_CONTENT
two	SEC_CONTENT
parsers	SEC_CONTENT
agree	SEC_CONTENT
produces	SEC_CONTENT
significantly	SEC_CONTENT
better	SEC_CONTENT
results	SEC_CONTENT
.	SEC_CONTENT
This	SEC_CONTENT
was	SEC_CONTENT
especially	SEC_CONTENT
pronounced	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
greedy	SEC_CONTENT
models	SEC_CONTENT
:	SEC_CONTENT
after	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
greedy	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
model	SEC_CONTENT
surpasses	SEC_CONTENT
the	SEC_CONTENT
BerkeleyParser	SEC_CONTENT
inaccuracy	SEC_CONTENT
.	SEC_CONTENT
It	SEC_CONTENT
is	SEC_CONTENT
also	SEC_CONTENT
interesting	SEC_CONTENT
to	SEC_CONTENT
note	SEC_CONTENT
that	SEC_CONTENT
up	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
improved	SEC_CONTENT
results	SEC_CONTENT
far	SEC_CONTENT
more	SEC_CONTENT
than	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
baseline	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
speculate	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
is	SEC_CONTENT
due	SEC_CONTENT
to	SEC_CONTENT
the	SEC_CONTENT
alack	SEC_CONTENT
of	SEC_CONTENT
diversity	SEC_CONTENT
in	SEC_CONTENT
the	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
data	SEC_CONTENT
for	SEC_CONTENT
this	SEC_CONTENT
model	SEC_CONTENT
,	SEC_CONTENT
since	SEC_CONTENT
the	SEC_CONTENT
same	SEC_CONTENT
baseline	SEC_CONTENT
model	SEC_CONTENT
was	SEC_CONTENT
intersected	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
BerkeleyParser	SEC_CONTENT
to	SEC_CONTENT
generate	SEC_CONTENT
the	SEC_CONTENT
tritraining	SEC_CONTENT
data	SEC_CONTENT
.	SEC_END
Error	SECTITLE_START
Analysis	SECTITLE_END
Regardless	SEC_START
of	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
,	SEC_CONTENT
using	SEC_CONTENT
the	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
improved	SEC_CONTENT
error	SEC_CONTENT
rates	SEC_CONTENT
on	SEC_CONTENT
some	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
common	SEC_CONTENT
and	SEC_CONTENT
difficult	SEC_CONTENT
labels	SEC_CONTENT
:	SEC_CONTENT
ROOT	SEC_CONTENT
,	SEC_CONTENT
ccomp	SEC_CONTENT
,	SEC_CONTENT
cc	SEC_CONTENT
,	SEC_CONTENT
conj	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
nsubj	SEC_CONTENT
all	SEC_CONTENT
improved	SEC_CONTENT
by	SEC_CONTENT
>	SEC_CONTENT
1	SEC_CONTENT
%	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
inspected	SEC_CONTENT
the	SEC_CONTENT
learned	SEC_CONTENT
perceptron	SEC_CONTENT
weights	SEC_CONTENT
v	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
probabilities	SEC_CONTENT
P(y	SEC_CONTENT
)	SEC_CONTENT
(	SEC_CONTENT
see	SEC_CONTENT
Appendix	SEC_CONTENT
)	SEC_CONTENT
and	SEC_CONTENT
found	SEC_CONTENT
that	SEC_CONTENT
the	SEC_CONTENT
perceptron	SEC_CONTENT
reweights	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
probabilities	SEC_CONTENT
based	SEC_CONTENT
on	SEC_CONTENT
common	SEC_CONTENT
confusions	SEC_CONTENT
;	SEC_CONTENT
e.g.	SEC_CONTENT
a	SEC_CONTENT
strong	SEC_CONTENT
negative	SEC_CONTENT
weight	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
action	SEC_CONTENT
RIGHT(ccomp	SEC_CONTENT
)	SEC_CONTENT
given	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
model	SEC_CONTENT
outputs	SEC_CONTENT
RIGHT(conj	SEC_CONTENT
)	SEC_CONTENT
.	SEC_CONTENT
Note	SEC_CONTENT
that	SEC_CONTENT
this	SEC_CONTENT
trend	SEC_CONTENT
did	SEC_CONTENT
not	SEC_CONTENT
hold	SEC_CONTENT
when	SEC_CONTENT
φ(x	SEC_CONTENT
,	SEC_CONTENT
c	SEC_CONTENT
)	SEC_CONTENT
=	SEC_CONTENT
[	SEC_CONTENT
P(y	SEC_CONTENT
)	SEC_CONTENT
]	SEC_CONTENT
;	SEC_CONTENT
without	SEC_CONTENT
the	SEC_CONTENT
hidden	SEC_CONTENT
layer	SEC_CONTENT
,	SEC_CONTENT
the	SEC_CONTENT
perceptron	SEC_CONTENT
was	SEC_CONTENT
notable	SEC_CONTENT
to	SEC_CONTENT
reweight	SEC_CONTENT
the	SEC_CONTENT
softmax	SEC_CONTENT
probabilities	SEC_CONTENT
to	SEC_CONTENT
account	SEC_CONTENT
for	SEC_CONTENT
the	SEC_CONTENT
greedy	SEC_CONTENT
model	SEC_CONTENT
's	SEC_CONTENT
biases	SEC_CONTENT
.	SEC_END
Conclusion	SECTITLE_END
We	SEC_START
presented	SEC_CONTENT
anew	SEC_CONTENT
state	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
art	SEC_CONTENT
in	SEC_CONTENT
dependency	task
parsing	task
:	SEC_CONTENT
a	SEC_CONTENT
transition	SEC_CONTENT
-	SEC_CONTENT
based	SEC_CONTENT
neural	SEC_CONTENT
network	SEC_CONTENT
parser	SEC_CONTENT
trained	SEC_CONTENT
with	SEC_CONTENT
the	SEC_CONTENT
structured	SEC_CONTENT
perceptron	SEC_CONTENT
and	SEC_CONTENT
ASGD	SEC_CONTENT
.	SEC_CONTENT
We	SEC_CONTENT
then	SEC_CONTENT
combined	SEC_CONTENT
this	SEC_CONTENT
approach	SEC_CONTENT
with	SEC_CONTENT
unlabeled	SEC_CONTENT
data	SEC_CONTENT
and	SEC_CONTENT
tri	SEC_CONTENT
-	SEC_CONTENT
training	SEC_CONTENT
to	SEC_CONTENT
further	SEC_CONTENT
push	SEC_CONTENT
state	SEC_CONTENT
-	SEC_CONTENT
of	SEC_CONTENT
-	SEC_CONTENT
the	SEC_CONTENT
-	SEC_CONTENT
art	SEC_CONTENT
in	SEC_CONTENT
semi	SEC_CONTENT
-	SEC_CONTENT
supervised	SEC_CONTENT
dependency	SEC_CONTENT
parsing	SEC_CONTENT
.	SEC_CONTENT
Nonetheless	SEC_CONTENT
,	SEC_CONTENT
our	SEC_CONTENT
ablative	SEC_CONTENT
analysis	SEC_CONTENT
suggests	SEC_CONTENT
that	SEC_CONTENT
further	SEC_CONTENT
gains	SEC_CONTENT
are	SEC_CONTENT
possible	SEC_CONTENT
simply	SEC_CONTENT
by	SEC_CONTENT
scaling	SEC_CONTENT
up	SEC_CONTENT
our	SEC_CONTENT
system	SEC_CONTENT
to	SEC_CONTENT
even	SEC_CONTENT
larger	SEC_CONTENT
representations	SEC_CONTENT
.	SEC_CONTENT
In	SEC_CONTENT
future	SEC_CONTENT
work	SEC_CONTENT
,	SEC_CONTENT
we	SEC_CONTENT
will	SEC_CONTENT
apply	SEC_CONTENT
our	SEC_CONTENT
method	SEC_CONTENT
to	SEC_CONTENT
other	SEC_CONTENT
languages	SEC_CONTENT
,	SEC_CONTENT
explore	SEC_CONTENT
end	SEC_CONTENT
-	SEC_CONTENT
to	SEC_CONTENT
-	SEC_CONTENT
end	SEC_CONTENT
training	SEC_CONTENT
of	SEC_CONTENT
the	SEC_CONTENT
system	SEC_CONTENT
using	SEC_CONTENT
structured	SEC_CONTENT
learning	SEC_CONTENT
,	SEC_CONTENT
and	SEC_CONTENT
scale	SEC_CONTENT
up	SEC_CONTENT
the	SEC_CONTENT
method	SEC_CONTENT
to	SEC_CONTENT
larger	SEC_CONTENT
datasets	SEC_CONTENT
and	SEC_CONTENT
network	SEC_CONTENT
structures	SEC_CONTENT
.	SEC_END
